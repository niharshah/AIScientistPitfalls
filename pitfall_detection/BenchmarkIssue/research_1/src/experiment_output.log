Loaded SFRFG dataset:
DatasetDict({
    train: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 2000
    })
    dev: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 500
    })
    test: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 1000
    })
})
Loaded IJSJF dataset:
DatasetDict({
    train: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 2000
    })
    dev: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 500
    })
    test: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 1000
    })
})
Loaded GURSG dataset:
DatasetDict({
    train: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 2000
    })
    dev: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 500
    })
    test: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 1000
    })
})
Loaded TSHUY dataset:
DatasetDict({
    train: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 2000
    })
    dev: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 500
    })
    test: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 1000
    })
})

Starting experiments on the four SPR benchmark datasets using a Logistic Regression classifier.
For each dataset, the classifier is trained on the 'train' split, tuned on the 'dev' split, and evaluated on the 'test' split.
This experiment intends to assess the model's ability to capture hidden symbolic patterns in the SPR task by vectorizing the sequence data with a revised token pattern that includes single character tokens, training a logistic regression classifier, and comparing test set performance against predefined SOTA baselines.

============================================================
Starting experiment on dataset: SFRFG
This experiment demonstrates the performance of a logistic regression classifier on the SPR task.
Step 1: Load the train, dev, and test splits and extract sequences and labels.
Step 2: Vectorize the sequences using CountVectorizer with a token pattern that captures even single character tokens to avoid an empty vocabulary error.
Step 3: Train the classifier on the training split, verify on the dev split, and then evaluate on the test split to ensure the model's efficacy compared to the SOTA baseline.

Validation Results on Dev Set for SFRFG:
  Dev Accuracy: 0.5740

Final Evaluation Results on Test Set for SFRFG:
  Test Accuracy: 0.5760

============================================================
Starting experiment on dataset: IJSJF
This experiment demonstrates the performance of a logistic regression classifier on the SPR task.
Step 1: Load the train, dev, and test splits and extract sequences and labels.
Step 2: Vectorize the sequences using CountVectorizer with a token pattern that captures even single character tokens to avoid an empty vocabulary error.
Step 3: Train the classifier on the training split, verify on the dev split, and then evaluate on the test split to ensure the model's efficacy compared to the SOTA baseline.

Validation Results on Dev Set for IJSJF:
  Dev Accuracy: 0.5740

Final Evaluation Results on Test Set for IJSJF:
  Test Accuracy: 0.5850

============================================================
Starting experiment on dataset: GURSG
This experiment demonstrates the performance of a logistic regression classifier on the SPR task.
Step 1: Load the train, dev, and test splits and extract sequences and labels.
Step 2: Vectorize the sequences using CountVectorizer with a token pattern that captures even single character tokens to avoid an empty vocabulary error.
Step 3: Train the classifier on the training split, verify on the dev split, and then evaluate on the test split to ensure the model's efficacy compared to the SOTA baseline.

Validation Results on Dev Set for GURSG:
  Dev Accuracy: 0.5520

Final Evaluation Results on Test Set for GURSG:
  Test Accuracy: 0.5850

============================================================
Starting experiment on dataset: TSHUY
This experiment demonstrates the performance of a logistic regression classifier on the SPR task.
Step 1: Load the train, dev, and test splits and extract sequences and labels.
Step 2: Vectorize the sequences using CountVectorizer with a token pattern that captures even single character tokens to avoid an empty vocabulary error.
Step 3: Train the classifier on the training split, verify on the dev split, and then evaluate on the test split to ensure the model's efficacy compared to the SOTA baseline.

Validation Results on Dev Set for TSHUY:
  Dev Accuracy: 0.5740

Final Evaluation Results on Test Set for TSHUY:
  Test Accuracy: 0.5940

Generating Figure_1.png: A bar chart summarizing test accuracies across all SPR benchmark datasets.
Figure_1.png saved.

Generating Figure_2.png: Comparative bar chart of Model Accuracy vs. SOTA Baseline Accuracy for each dataset.
Figure_2.png saved.

============================================================
Experiment Summary for each SPR benchmark dataset:
Dataset SFRFG:
  - Model Test Accuracy: 0.5760
  - SOTA Baseline Accuracy: 0.8500

Dataset IJSJF:
  - Model Test Accuracy: 0.5850
  - SOTA Baseline Accuracy: 0.8000

Dataset GURSG:
  - Model Test Accuracy: 0.5850
  - SOTA Baseline Accuracy: 0.8300

Dataset TSHUY:
  - Model Test Accuracy: 0.5940
  - SOTA Baseline Accuracy: 0.8200

All experiments completed successfully.
