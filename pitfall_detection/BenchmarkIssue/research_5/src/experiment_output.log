Benchmark SFRFG loaded:
  Train size: 2000
  Dev size: 500
  Test size: 1000
Benchmark IJSJF loaded:
  Train size: 2000
  Dev size: 500
  Test size: 1000
Benchmark GURSG loaded:
  Train size: 2000
  Dev size: 500
  Test size: 1000
Benchmark TEXHE loaded:
  Train size: 2000
  Dev size: 500
  Test size: 1000

Example from SFRFG train split:
{'id': 'B17_train_0', 'sequence': '●g ▲r ●y ■r ▲b ■b ●b ▲y ◆y ●r ●y ◆y ●b ◆r ●r ▲y ■b ■y ■r ◆y', 'label': 0}
Loading datasets from benchmark directories:
Benchmark SFRFG loaded:
  Train size: 2000
  Dev size: 500
  Test size: 1000
Benchmark IJSJF loaded:
  Train size: 2000
  Dev size: 500
  Test size: 1000
Benchmark GURSG loaded:
  Train size: 2000
  Dev size: 500
  Test size: 1000
Benchmark TEXHE loaded:
  Train size: 2000
  Dev size: 500
  Test size: 1000

Example from SFRFG train split:
{'id': 'B17_train_0', 'sequence': '●g ▲r ●y ■r ▲b ■b ●b ▲y ◆y ●r ●y ◆y ●b ◆r ●r ▲y ■b ■y ■r ◆y', 'label': 0}

Starting experiments: For each benchmark we train a classifier to decide if the sequence satisfies the target rule (SPR task).
The classifier is trained on the Train split, tuned on the Dev split, and evaluated on the Test split (labels withheld).
We then compare our classifier's performance with the SOTA baseline accuracies.

========================================================
Experiment on benchmark SFRFG:
This experiment trains a logistic regression classifier on the train split using TF-IDF feature extraction on the sequence data.
The model is then evaluated on the dev split for tuning and finally on the test split. The printed outputs include dev and test accuracies, which should be compared with printed SOTA baseline scores (assumed to be provided externally).
Development set accuracy for benchmark SFRFG: 90.20%
Test set accuracy for benchmark SFRFG: 94.70%

========================================================
Experiment on benchmark IJSJF:
This experiment trains a logistic regression classifier on the train split using TF-IDF feature extraction on the sequence data.
The model is then evaluated on the dev split for tuning and finally on the test split. The printed outputs include dev and test accuracies, which should be compared with printed SOTA baseline scores (assumed to be provided externally).
Development set accuracy for benchmark IJSJF: 71.40%
Test set accuracy for benchmark IJSJF: 71.30%

========================================================
Experiment on benchmark GURSG:
This experiment trains a logistic regression classifier on the train split using TF-IDF feature extraction on the sequence data.
The model is then evaluated on the dev split for tuning and finally on the test split. The printed outputs include dev and test accuracies, which should be compared with printed SOTA baseline scores (assumed to be provided externally).
Development set accuracy for benchmark GURSG: 93.40%
Test set accuracy for benchmark GURSG: 94.40%

========================================================
Experiment on benchmark TEXHE:
This experiment trains a logistic regression classifier on the train split using TF-IDF feature extraction on the sequence data.
The model is then evaluated on the dev split for tuning and finally on the test split. The printed outputs include dev and test accuracies, which should be compared with printed SOTA baseline scores (assumed to be provided externally).
Development set accuracy for benchmark TEXHE: 72.80%
Test set accuracy for benchmark TEXHE: 76.40%

Generating figures to illustrate experimental results.
Figure_1.png generated: Bar chart showing test accuracies for each benchmark.
Figure_2.png generated: Confusion matrix for benchmark SFRFG test split.

All experiments completed. The results are printed above and figures have been generated and saved.
