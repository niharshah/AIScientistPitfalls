Loaded SFRFG dataset: Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 2000
}) Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 500
}) Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 1000
})
Loaded IJSJF dataset: Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 2000
}) Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 500
}) Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 1000
})
Loaded GURSG dataset: Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 2000
}) Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 500
}) Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 1000
})
Loaded TSHUY dataset: Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 2000
}) Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 500
}) Dataset({
    features: ['id', 'sequence', 'label'],
    num_rows: 1000
})
Training the neural grammar symbolic model... [This would be detailed with epochs and optimizer]
Decision Tree Accuracy: 0.497
Random Forest Accuracy: 0.507
SVM Accuracy: 0.496
Neural Grammar Symbolic Model Accuracy: 0.478
