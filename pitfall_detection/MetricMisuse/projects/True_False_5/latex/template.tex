\documentclass{article}
\usepackage{iclr2025_conference,times}

% Keep figures in the same directory
\graphicspath{{./figures/}}

\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}

% File containing references
\begin{filecontents}{references.bib}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{goodfellow2015explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2015}
}

@inproceedings{dozat2016incorporating,
  title={Incorporating Nesterov momentum into Adam},
  author={Dozat, Timothy},
  booktitle={ICLR Workshop},
  year={2016}
}

@inproceedings{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2015}
}

@inproceedings{he2016resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
\end{filecontents}


\title{Neural-Symbolic Models Are Not Always Better: A Candid Look at Negative Results}

\author{%
Anonymous Submission \\
ICBINB Workshop at ICLR 2025
}

\iclrfinalcopy

\begin{document}

\maketitle

\begin{abstract}
Neural-symbolic models hold promise for integrating classical reasoning with modern deep learning. However, in real-world contexts, these methods may introduce additional complexity without guaranteed improvements. We present our experiences with a neural-symbolic architecture for a standard image-classification benchmark, showing inconclusive gains and unexpected pitfalls. Our results highlight that even carefully designed hybrid approaches can fall short of purely neural or purely symbolic methods, raising important questions for real-world deployment.
\end{abstract}

\section{Introduction}
Despite significant interest in neural-symbolic integration, real-world deployments do not always confirm the hoped-for benefits. Classical logic-based reasoning is elegant but rigid, while deep learning methods are flexible but sometimes lack interpretability. When these paradigms are combined, it may introduce additional computational overhead or integration complexity~\citep{goodfellow2015explaining,he2016resnet}. We investigate a hybrid approach on a vision task, aiming to improve performance and interpretability. Surprisingly, our experiments revealed partial improvements under constrained conditions, but more often demonstrated no clear advantage compared to standard deep learning pipelines. This paper aims to highlight these pitfalls, hoping to inform the community of the complexities that can arise in such integrations.

\section{Related Work}
Previous works combine symbolic reasoning with neural networks in various ways~\citep{kingma2014adam,simonyan2014very}. Many succeed in controlled settings but scale poorly to larger problems. Others report improved generalization when domain knowledge is integrated, yet few systematically analyze negative or inconclusive results. We offer such an analysis, building on prior neural-symbolic frameworks~\citep{dozat2016incorporating}, but focusing on realistic complexities and pitfalls encountered in practice.

\section{Method}
We extend a standard convolutional neural network with a symbolic processing module for reasoning over intermediary activations. Inspired by prior neural-symbolic pipelines, the module is meant to constrain feature interpretation at a higher level than raw pixels. However, integrating these symbolic constraints involved additional hyperparameters, data transformations, and computational overhead. In some runs, the overhead overshadowed any performance gains.

\section{Experiments}
We evaluate on a subset of CIFAR-10 using a shallower variant of \cite{simonyan2014very}, trained via Adam~\citep{kingma2014adam} or variants~\citep{dozat2016incorporating}. We measure cross-entropy loss, top-1 accuracy, and zero-shot generalization. Contrary to expectations, baseline convolutional networks matched or surpassed our neural-symbolic hybrid on most measures.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.48\columnwidth]{baseline_performance.png}
  \caption{Baseline Performance: a typical CNN's cross-entropy loss converges steadily, albeit with variance in early epochs.}
  \label{fig:baseline}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.48\columnwidth]{research_performance.png}
  \caption{Neural-Symbolic Model: training loss and stochastic weight averaging (SWA) curves show partial improvements but no clear final gain.}
  \label{fig:hybrid}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.48\columnwidth]{ablation.png}
  \caption{Ablation Results: removing symbolic vectors increases confusion among closely related classes.}
  \label{fig:ablation}
\end{figure}

\noindent 
Qualitative analysis showed that our symbolic constraints can help in carefully crafted examples. However, on standard test sets with noisy labels or mixed classes, the performance improvements diminished quickly. Table~\ref{tab:results} summarizes key metrics.

\begin{table}[t]
    \centering
    \caption{Representative results (\%). Mean of three runs $\pm$ standard deviation.}
    \label{tab:results}
    \begin{tabular}{lcc}
    \toprule
    \textbf{Model} & \textbf{Top-1 Accuracy} & \textbf{Zero-Shot Score}\\
    \midrule
    Baseline CNN & $92.0 \pm 0.3$ & $38.0 \pm 2.0$ \\
    Neural-Symbolic & $91.7 \pm 0.5$ & $38.1 \pm 2.1$ \\
    \bottomrule
    \end{tabular}
\end{table}

\section{Conclusion}
We presented a critical look at neural-symbolic integration in a vision context, showing that gains are not guaranteed. Integration overhead and domain mismatches can impede the touted benefits of symbolic reasoning. Our hope is that closer scrutiny of such negative or inconclusive results will encourage practical considerations in future research and help avoid overcomplicating systems that do not necessarily outperform simpler alternatives.

\appendix
\section{Extended Results and Ablations}
Here we include more ablation experiments and plots. All further figures, including the breakdown of accuracy per seed, are provided for completeness.

\bibliography{references}
\bibliographystyle{iclr2025_conference}

\end{document}