{"edges": [[0, 2], [0, 3], [0, 4], [0, 1], [3, 6], [3, 5], [3, 8], [3, 7], [8, 9], [8, 11], [8, 10], [8, 12]], "layout": [[0.3, 0.0], [0.0, 0.33333333333333337], [0.2, 0.33333333333333337], [0.4, 0.33333333333333337], [0.6, 0.33333333333333337], [0.1, 0.6666666666666667], [0.3, 0.6666666666666667], [0.5, 0.6666666666666667], [0.7, 0.6666666666666667], [0.4, 1.0], [0.6, 1.0], [0.8, 1.0], [1.0, 1.0]], "plan": ["Hyperparam tuning name: EPOCHS. We extend the baseline by allowing up-to-30\ntraining epochs while monitoring validation RCWA. The best model (highest\nvalidation RCWA) is kept; if no improvement is observed for `patience=4`\nconsecutive epochs, training stops early. All per-epoch losses/metrics and the\ntest-set predictions from the best checkpoint are stored in `experiment_data`\nand written to `experiment_data.npy`, fulfilling the requested format.", "We enhance zero-shot reasoning by fusing lightweight symbolic cues with a neural\nencoder: every sequence is encoded with a small Transformer, then concatenated\nwith three rule-aware features (number of shapes, number of colours, length).\nThis neural-symbolic vector is fed to a classifier.  We optimize cross-entropy,\nmonitor Shape-Weighted Accuracy (SWA) on the dev set for early stopping, and\nreport SWA on the hidden test split.  The script builds its own vocabulary,\nhandles padding masks, logs per-epoch losses/metrics, stores all results in\n./working/experiment_data.npy, and fully respects GPU use rules.", "We propose a lightweight neural-symbolic classifier that fuses two complementary\nviews of each SPR sequence: (i) a neural mean-pooled embedding of raw tokens\n(capturing unknown patterns) and (ii) an explicit symbolic bag-of-shapes / bag-\nof-colors vector (capturing rule-level statistics).  Concatenating these\nrepresentations lets the model reason with both learned distributed features and\ndiscrete count features, enabling better zero-shot generalisation.  We tune on\nthe dev set with early-stopping using Shape-Weighted Accuracy (SWA) as the\nsingle evaluation metric.  The code below loads SPR_BENCH, builds separate\nvocabularies for tokens, shapes and colours, trains the hybrid model, tracks SWA\neach epoch, applies patience-based stopping and finally reports test-set SWA.\nAll losses/metrics are stored in \u201cworking/experiment_data.npy\u201d for later\nanalysis.", "We augment the mean-pool text encoder with explicit symbolic statistics of each\nsequence, creating a lightweight neural-symbolic hybrid.   For every sequence we\nextract a vector of normalized counts for each distinct shape character and\ncolor character; this \u201csymbolic\u201d vector is concatenated with the mean-pooled\nembedding from a token lookup table.   The combined representation is passed\nthrough an MLP to predict the rule label, letting the network attend both to raw\ntoken order (neural) and rule-level abstractions (symbolic).   Because rule\ncorrectness in zero-shot SPR strongly correlates with structural diversity, we\nchoose Shape-Weighted Accuracy (SWA) as the single metric and monitor it on the\ndev split for early stopping.   Hyper-parameters are modest (embedding 64,\nhidden 128, lr 1e-3, batch 128, patience 5) to keep runtime <30 min while still\nallowing the symbolic branch to guide generalisation.   All tensors, model, and\noptimizer reside on GPU when available; metrics/losses are logged each epoch and\nsaved to \u201cworking/experiment_data.npy\u201d for later analysis.   This experiment\nprovides a first neural-symbolic baseline whose zero-shot capability derives\nfrom explicitly injected rule statistics rather than pure pattern memorisation.\nThe code below is self-contained and runs immediately.", "We enrich the baseline by adding symbolic counts (shape & color variety) as\nexplicit features and replace mean-pooling with a light Transformer encoder that\ncaptures order relations.  Each sequence is embedded, passed through a 2-layer\nTransformer, mean-pooled, concatenated with a learned projection of the two\nsymbolic counts, and classified.  Early-stopping on dev Shape-Weighted Accuracy\n(SWA) is used, and all per-epoch losses/metrics are stored.  This blends neural\nrepresentation learning with symbolic priors, probing zero-shot rule\ngeneralization via SWA.", "To strengthen zero-shot generalisation I (1) switch the mean-pool bag-of-words\nencoder to a small Transformer that keeps token order, (2) expand symbolic\nfeatures with shape/color histograms plus their variety counts, and (3) add a\nlight rule-lookup module learnt purely from training statistics; at inference a\nconfidence gate (>0.8 class probability) decides whether to trust this symbolic\nrule or the neural logits. The two branches are fused by simple overriding, so\nthe system can exactly follow easy rules while the Transformer handles harder,\nunforeseen ones. We train only the neural part with cross-entropy, monitor\nvalidation Shape-Weighted Accuracy (SWA) for early stopping, and finally report\n/ save all metrics and predictions. Despite the architectural upgrade the whole\nmodel is <300 k parameters and trains in a few minutes on GPU or CPU. All\nrequired GPU/CPU handling, logging, checkpointing and data saving are included\nbelow.", "To improve zero-shot generalization we replace the mean-pool baseline with a\nlightweight Transformer encoder, add a learnable gating-fusion layer that lets\nthe network adaptively weight neural and symbolic representations, and introduce\ntoken-dropout data augmentation to regularise the encoder.  We keep Shape-\nWeighted Accuracy (SWA) as the sole optimisation metric and use early stopping\non dev-SWA.  Training now uses weight-decay and dropout for further\nregularisation and all metrics / losses are logged in the required\n`experiment_data` dict and saved to disk.  The whole script remains self-\ncontained, automatically handles GPU/CPU, prints per-epoch validation loss, and\ncompletes within 30 minutes on a single GPU.  Below is the full runnable code.", "We enhance the first-attempt model by adding a lightweight 2-layer Transformer\nencoder and a multi-task auxiliary loss that requires the network to predict the\nnumber of distinct shapes in the sequence.  The Transformer lets the network\nattend to rule-relevant token patterns, while the auxiliary regression signal\nencourages it to internalise shape-diversity information that SWA later rewards,\nimproving zero-shot generalisation.  Input tokens are embedded, enriched with\nlearned positional encodings, passed through the encoder, then mean-pooled and\nconcatenated with explicit symbolic frequency features before feeding two\nseparate heads (classification + shape-count).  The total loss is CE + 0.1\u00b7MSE.\nEarly stopping is based on dev-set SWA.  All metrics, losses and predictions are\nlogged to experiment_data.npy for reproducibility.", "To boost zero-shot generalisation we represent every SPR token compositionally,\nsplitting it into a \u201cshape\u201d character and an optional \u201ccolor\u201d character and\nlearning separate embeddings for each.  These two embeddings are summed with a\npositional embedding and processed by a light 2-layer Transformer encoder,\nproviding contextual token representations that can generalise to unseen\nshape\u2013color combinations.  A sequence embedding is obtained by mean-pooling the\ncontextual tokens, then fused (concatenated) with the explicit symbolic feature\nvector (normalised shape/color counts).  A small MLP head predicts the label.\nBecause symbolic features are still present, we can ablate them later simply by\nzeroing this input.  We keep the evaluation focus on Shape-Weighted Accuracy\n(SWA) and apply early stopping on the dev set.  The new compositional embedding\nplus self-attention typically improves rule abstraction while remaining\nlightweight enough to train in minutes on a single GPU/CPU.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, time, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import DatasetDict\nfrom typing import List, Dict\n\n# ------------------ reproducibility & device ------------------\ntorch.manual_seed(0)\nnp.random.seed(0)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------ experiment data dict ------------------\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_rcwa\": [], \"val_rcwa\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"]\n\n\n# ------------------ helper functions ------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    from datasets import load_dataset\n\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(t[0] for t in sequence.strip().split() if t))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(t[1] for t in sequence.strip().split() if len(t) > 1))\n\n\ndef rcwa(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) * count_color_variety(s) for s in seqs]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / (sum(weights) if sum(weights) else 1.0)\n\n\n# ------------------ load dataset ------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ------------------ vocabulary ------------------\ndef build_vocab(dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\n# ------------------ torch dataset ------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split, vocab):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.vocab = vocab\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def encode(self, seq: str) -> List[int]:\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.encode(self.seqs[idx]), dtype=torch.long),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"sequence_str\": self.seqs[idx],\n        }\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab)\n\n\n# ------------------ collate fn ------------------\ndef collate_fn(batch):\n    ids = [b[\"input_ids\"] for b in batch]\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    seq_str = [b[\"sequence_str\"] for b in batch]\n    padded = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=0)\n    mask = (padded != 0).float()\n    return {\n        \"input_ids\": padded,\n        \"attention_mask\": mask,\n        \"labels\": labels,\n        \"sequence_str\": seq_str,\n    }\n\n\nBATCH_SIZE = 128\ntrain_loader = DataLoader(\n    train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    dev_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn\n)\ntest_loader = DataLoader(\n    test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ------------------ model ------------------\nclass MeanPoolClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.fc = nn.Linear(emb_dim, num_classes)\n\n    def forward(self, ids, mask):\n        emb = self.embed(ids)  # B x T x D\n        masked = emb * mask.unsqueeze(-1)\n        sum_emb = masked.sum(dim=1)\n        lengths = mask.sum(dim=1).clamp(min=1e-6)\n        mean_emb = sum_emb / lengths.unsqueeze(-1)\n        return self.fc(mean_emb)\n\n\nnum_classes = int(max(train_ds.labels)) + 1\nmodel = MeanPoolClassifier(len(vocab), 64, num_classes).to(device)\n\n# ------------------ train setup ------------------\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\ndef evaluate(loader):\n    model.eval()\n    total_loss, preds, gts, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch_t[\"input_ids\"], batch_t[\"attention_mask\"])\n            loss = criterion(logits, batch_t[\"labels\"])\n            total_loss += loss.item() * batch_t[\"labels\"].size(0)\n            pred = logits.argmax(dim=-1).cpu().tolist()\n            gt = batch_t[\"labels\"].cpu().tolist()\n            preds.extend(pred)\n            gts.extend(gt)\n            seqs.extend(batch[\"sequence_str\"])\n    rcwa_val = rcwa(seqs, gts, preds)\n    return total_loss / len(loader.dataset), rcwa_val, preds, gts, seqs\n\n\n# ------------------ training loop with early stopping ------------------\nMAX_EPOCHS = 30\npatience = 4\nbest_val_rcwa = -1.0\nepochs_without_improve = 0\nbest_state = None\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"input_ids\"], batch_t[\"attention_mask\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = epoch_loss / len(train_loader.dataset)\n    train_loss_eval, train_rcwa, *_ = evaluate(train_loader)\n    val_loss, val_rcwa, *_ = evaluate(dev_loader)\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train_rcwa\"].append(train_rcwa)\n    exp_rec[\"metrics\"][\"val_rcwa\"].append(val_rcwa)\n    exp_rec[\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  val_RCWA={val_rcwa:.4f}\"\n    )\n\n    if val_rcwa > best_val_rcwa:\n        best_val_rcwa = val_rcwa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        epochs_without_improve = 0\n    else:\n        epochs_without_improve += 1\n        if epochs_without_improve >= patience:\n            print(f\"No improvement for {patience} epochs, early stopping.\")\n            break\n\n# ------------------ load best model & final test evaluation ------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_rcwa, test_preds, test_gts, test_seqs = evaluate(test_loader)\nswa = (\n    lambda seqs, y, p: sum(\n        count_shape_variety(s) if yt == pt else 0 for s, yt, pt in zip(seqs, y, p)\n    )\n    / sum(count_shape_variety(s) for s in seqs)\n)(test_seqs, test_gts, test_preds)\ncwa = (\n    lambda seqs, y, p: sum(\n        count_color_variety(s) if yt == pt else 0 for s, yt, pt in zip(seqs, y, p)\n    )\n    / sum(count_color_variety(s) for s in seqs)\n)(test_seqs, test_gts, test_preds)\nprint(f\"TEST  loss={test_loss:.4f}  RCWA={test_rcwa:.4f}  SWA={swa:.4f}  CWA={cwa:.4f}\")\n\nexp_rec[\"predictions\"] = np.array(test_preds)\nexp_rec[\"ground_truth\"] = np.array(test_gts)\n\n# ------------------ save experiment data ------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, time, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- boiler-plate working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- experiment data dict ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_SWA\": [], \"val_SWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\nexp_rec = experiment_data[\"SPR_BENCH\"]\n\n\n# ---------- metric helpers (symbolic) ----------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    wts = [count_shape_variety(s) for s in seqs]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(wts, y_true, y_pred)]\n    return sum(correct) / (sum(wts) if sum(wts) else 1.0)\n\n\n# ---------- data loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- vocabulary ----------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(\"Vocab size:\", len(vocab))\n\n\n# ---------- Torch Dataset ----------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split, vocab):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.vocab = vocab\n\n    def encode(self, seq):\n        return [self.vocab.get(tok, 1) for tok in seq.split()]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq_str = self.seqs[idx]\n        return {\n            \"input_ids\": torch.tensor(self.encode(seq_str), dtype=torch.long),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"sym_feats\": torch.tensor(\n                [\n                    count_shape_variety(seq_str),\n                    count_color_variety(seq_str),\n                    len(seq_str.split()),\n                ],\n                dtype=torch.float,\n            ),\n            \"sequence_str\": seq_str,\n        }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[spl], vocab) for spl in [\"train\", \"dev\", \"test\"]\n)\n\n\n# ---------- collate ----------\ndef collate_fn(batch):\n    ids = [b[\"input_ids\"] for b in batch]\n    padded = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=0)\n    mask = (padded != 0).float()\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    sym = torch.stack([b[\"sym_feats\"] for b in batch])\n    seqs = [b[\"sequence_str\"] for b in batch]\n    return {\n        \"input_ids\": padded,\n        \"attention_mask\": mask,\n        \"sym_feats\": sym,\n        \"labels\": labels,\n        \"sequence_str\": seqs,\n    }\n\n\nB = 128\ntrain_loader = DataLoader(train_ds, batch_size=B, shuffle=True, collate_fn=collate_fn)\ndev_loader = DataLoader(dev_ds, batch_size=B, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(test_ds, batch_size=B, shuffle=False, collate_fn=collate_fn)\n\n\n# ---------- Model ----------\nclass SymbolicTransformer(nn.Module):\n    def __init__(self, vocab_size, emb_dim, n_heads, ff_dim, num_classes):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=emb_dim,\n            nhead=n_heads,\n            dim_feedforward=ff_dim,\n            dropout=0.1,\n            batch_first=True,\n        )\n        self.enc = nn.TransformerEncoder(encoder_layer, num_layers=1)\n        self.sym_proj = nn.Linear(3, emb_dim)\n        self.classifier = nn.Linear(emb_dim * 2, num_classes)\n\n    def forward(self, ids, mask, sym):\n        x = self.emb(ids)\n        x = self.enc(x, src_key_padding_mask=(mask == 0))\n        pooled = (x * mask.unsqueeze(-1)).sum(1) / mask.sum(1, keepdim=True).clamp(\n            min=1e-6\n        )\n        sym_emb = torch.relu(self.sym_proj(sym))\n        out = torch.cat([pooled, sym_emb], dim=1)\n        return self.classifier(out)\n\n\nnum_classes = int(max(train_ds.labels)) + 1\nmodel = SymbolicTransformer(\n    len(vocab), emb_dim=64, n_heads=4, ff_dim=128, num_classes=num_classes\n).to(device)\n\n# ---------- training setup ----------\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\ndef evaluate(loader):\n    model.eval()\n    tot_loss, preds, gts, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"input_ids\"], batch_t[\"attention_mask\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            tot_loss += loss.item() * batch_t[\"labels\"].size(0)\n            pred = logits.argmax(-1).cpu().tolist()\n            gts.extend(batch[\"labels\"].tolist())\n            preds.extend(pred)\n            seqs.extend(batch[\"sequence_str\"])\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    return tot_loss / len(loader.dataset), swa, preds, gts, seqs\n\n\n# ---------- training loop ----------\nmax_epochs = 25\npatience = 3\nbest_val_swa = -1.0\nno_improve = 0\nbest_state = None\nfor epoch in range(1, max_epochs + 1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(\n            batch_t[\"input_ids\"], batch_t[\"attention_mask\"], batch_t[\"sym_feats\"]\n        )\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = epoch_loss / len(train_loader.dataset)\n    train_loss_eval, train_swa, *_ = evaluate(train_loader)\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train_SWA\"].append(train_swa)\n    exp_rec[\"metrics\"][\"val_SWA\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}  val_SWA={val_swa:.4f}\")\n    if val_swa > best_val_swa:\n        best_val_swa = val_swa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_improve = 0\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ---------- test evaluation ----------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_preds, test_gts, _ = evaluate(test_loader)\nprint(f\"TEST  loss={test_loss:.4f}  SWA={test_swa:.4f}\")\n\nexp_rec[\"predictions\"] = np.array(test_preds)\nexp_rec[\"ground_truth\"] = np.array(test_gts)\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, time, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# -------------------- workspace & device --------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# -------------------- experiment data container --------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_swa\": [], \"val_swa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\nexp_rec = experiment_data[\"SPR_BENCH\"]\n\n\n# -------------------- helper metrics --------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(correct) / (sum(w) if sum(w) else 1.0)\n\n\n# -------------------- load SPR_BENCH --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):  # read one csv as a split\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# -------------------- build vocabularies --------------------\ntoken_vocab = {\"<pad>\": 0, \"<unk>\": 1}\nshape_vocab, color_vocab = {}, {}\n\n\ndef register_token(tok):\n    if tok not in token_vocab:\n        token_vocab[tok] = len(token_vocab)\n    if tok:\n        shape = tok[0]\n        if shape not in shape_vocab:\n            shape_vocab[shape] = len(shape_vocab)\n        if len(tok) > 1:\n            color = tok[1]\n            if color not in color_vocab:\n                color_vocab[color] = len(color_vocab)\n\n\nfor seq in spr[\"train\"][\"sequence\"]:\n    for t in seq.strip().split():\n        register_token(t)\n\nprint(\n    f\"Token vocab: {len(token_vocab)}, Shapes: {len(shape_vocab)}, Colors: {len(color_vocab)}\"\n)\n\n\n# -------------------- dataset --------------------\nclass SPRDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n\n    def _encode_tokens(self, seq):\n        return [\n            token_vocab.get(tok, token_vocab[\"<unk>\"]) for tok in seq.strip().split()\n        ]\n\n    def _shape_color_counts(self, seq):\n        s_vec = np.zeros(len(shape_vocab), dtype=np.float32)\n        c_vec = np.zeros(len(color_vocab), dtype=np.float32)\n        for tok in seq.strip().split():\n            if not tok:\n                continue\n            s_vec[shape_vocab[tok[0]]] += 1.0\n            if len(tok) > 1:\n                c_vec[color_vocab[tok[1]]] += 1.0\n        return np.concatenate([s_vec, c_vec])\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        return {\n            \"input_ids\": torch.tensor(self._encode_tokens(seq), dtype=torch.long),\n            \"sym_feats\": torch.tensor(\n                self._shape_color_counts(seq), dtype=torch.float32\n            ),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"seq_str\": seq,\n        }\n\n\ntrain_ds = SPRDataset(spr[\"train\"])\ndev_ds = SPRDataset(spr[\"dev\"])\ntest_ds = SPRDataset(spr[\"test\"])\n\n# -------------------- collate --------------------\nPAD_IDX = token_vocab[\"<pad>\"]\n\n\ndef collate(batch):\n    ids = [b[\"input_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    seqs = [b[\"seq_str\"] for b in batch]\n    padded = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=PAD_IDX)\n    mask = (padded != PAD_IDX).float()\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"seq_str\": seqs,\n    }\n\n\nBATCH = 256\ntrain_loader = DataLoader(train_ds, BATCH, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, BATCH, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, BATCH, shuffle=False, collate_fn=collate)\n\n\n# -------------------- model --------------------\nclass HybridClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, sym_dim, num_classes):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_IDX)\n        self.fc = nn.Sequential(\n            nn.Linear(emb_dim + sym_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n\n    def forward(self, ids, mask, sym_feats):\n        emb = self.emb(ids) * mask.unsqueeze(-1)  # B,T,D\n        mean_emb = emb.sum(1) / (mask.sum(1, keepdim=True) + 1e-6)\n        out = torch.cat([mean_emb, sym_feats], dim=-1)\n        return self.fc(out)\n\n\nnum_classes = int(max(train_ds.labels)) + 1\nmodel = HybridClassifier(\n    len(token_vocab), 64, len(shape_vocab) + len(color_vocab), num_classes\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n\n\n# -------------------- evaluation --------------------\ndef run_epoch(loader, train=False):\n    if train:\n        model.train()\n    else:\n        model.eval()\n    total_loss, preds, gts, seqs = 0.0, [], [], []\n    for batch in loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym_feats\"])\n        loss = criterion(logits, batch[\"labels\"])\n        if train:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        total_loss += loss.item() * batch[\"labels\"].size(0)\n        pred = logits.argmax(-1).cpu().tolist()\n        gt = batch[\"labels\"].cpu().tolist()\n        preds.extend(pred)\n        gts.extend(gt)\n        seqs.extend(batch[\"seq_str\"])\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    return total_loss / len(loader.dataset), swa, preds, gts, seqs\n\n\n# -------------------- training loop --------------------\nEPOCHS, PATIENCE = 20, 3\nbest_val_swa, patience_cnt, best_state = -1.0, 0, None\n\nfor epoch in range(1, EPOCHS + 1):\n    tr_loss, tr_swa, *_ = run_epoch(train_loader, train=True)\n    val_loss, val_swa, *_ = run_epoch(dev_loader, train=False)\n\n    exp_rec[\"losses\"][\"train\"].append(tr_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train_swa\"].append(tr_swa)\n    exp_rec[\"metrics\"][\"val_swa\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    print(\n        f\"Epoch {epoch:02d}: train_loss={tr_loss:.4f} val_loss={val_loss:.4f} val_SWA={val_swa:.4f}\"\n    )\n\n    if val_swa > best_val_swa:\n        best_val_swa = val_swa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        patience_cnt = 0\n    else:\n        patience_cnt += 1\n        if patience_cnt >= PATIENCE:\n            print(f\"Early stopping (no val_SWA improvement for {PATIENCE} epochs)\")\n            break\n\n# -------------------- test evaluation --------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_preds, test_gts, _ = run_epoch(test_loader, train=False)\nprint(f\"TEST: loss={test_loss:.4f}  SWA={test_swa:.4f}\")\n\nexp_rec[\"predictions\"] = np.array(test_preds)\nexp_rec[\"ground_truth\"] = np.array(test_gts)\n\n# -------------------- save --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, time, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom typing import Dict, List\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- experiment data dict ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_swa\": [], \"val_swa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\nexp_rec = experiment_data[\"SPR_BENCH\"]\n\n\n# ---------- helper functions ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    d[\"train\"] = _load(\"train.csv\")\n    d[\"dev\"] = _load(\"dev.csv\")\n    d[\"test\"] = _load(\"test.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\n# ---------- data path ----------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- build vocab & symbolic maps ----------\ndef build_vocab_and_maps(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    shape_set, color_set = set(), set()\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n            if len(tok) >= 1:\n                shape_set.add(tok[0])\n            if len(tok) >= 2:\n                color_set.add(tok[1])\n    shape_map = {s: i for i, s in enumerate(sorted(shape_set))}\n    color_map = {c: i for i, c in enumerate(sorted(color_set))}\n    return vocab, shape_map, color_map\n\n\nvocab, shape_map, color_map = build_vocab_and_maps(spr[\"train\"])\nprint(f\"Vocab: {len(vocab)}  shapes:{len(shape_map)} colors:{len(color_map)}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, shape_map, color_map):\n        self.seqs = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.vocab = vocab\n        self.shape_map = shape_map\n        self.color_map = color_map\n        self.n_shape = len(shape_map)\n        self.n_color = len(color_map)\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def encode_tokens(self, seq: str) -> List[int]:\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n    def symbolic_vec(self, seq: str) -> np.ndarray:\n        s_vec = np.zeros(self.n_shape, dtype=np.float32)\n        c_vec = np.zeros(self.n_color, dtype=np.float32)\n        for tok in seq.strip().split():\n            if tok and tok[0] in self.shape_map:\n                s_vec[self.shape_map[tok[0]]] += 1.0\n            if len(tok) > 1 and tok[1] in self.color_map:\n                c_vec[self.color_map[tok[1]]] += 1.0\n        # normalise by length\n        total = max(len(seq.strip().split()), 1)\n        return np.concatenate([s_vec, c_vec]) / total\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        return {\n            \"input_ids\": torch.tensor(self.encode_tokens(seq), dtype=torch.long),\n            \"sym_feats\": torch.tensor(self.symbolic_vec(seq), dtype=torch.float32),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"sequence_str\": seq,\n        }\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, shape_map, color_map)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, shape_map, color_map)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, shape_map, color_map)\n\n\n# ---------- collate ----------\ndef collate_fn(batch):\n    ids = [b[\"input_ids\"] for b in batch]\n    padded = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=0)\n    mask = (padded != 0).float()\n    sym = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    seqs = [b[\"sequence_str\"] for b in batch]\n    return {\n        \"input_ids\": padded,\n        \"attention_mask\": mask,\n        \"sym_feats\": sym,\n        \"labels\": labels,\n        \"sequence_str\": seqs,\n    }\n\n\nBATCH = 128\ntrain_loader = DataLoader(\n    train_ds, batch_size=BATCH, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(dev_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(\n    test_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ---------- model ----------\nclass NeuralSymbolic(nn.Module):\n    def __init__(self, vocab_size, emb_dim, sym_dim, hidden_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.mlp = nn.Sequential(\n            nn.Linear(emb_dim + sym_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, num_classes),\n        )\n\n    def forward(self, ids, mask, sym):\n        emb = self.embed(ids)  # B x T x D\n        mean_emb = (emb * mask.unsqueeze(-1)).sum(dim=1) / mask.sum(\n            dim=1, keepdim=True\n        ).clamp(min=1e-6)\n        x = torch.cat([mean_emb, sym], dim=-1)\n        return self.mlp(x)\n\n\nnum_classes = int(max(train_ds.labels)) + 1\nsym_dim = len(shape_map) + len(color_map)\nmodel = NeuralSymbolic(len(vocab), 64, sym_dim, 128, num_classes).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------- eval ----------\ndef evaluate(loader):\n    model.eval()\n    total_loss, preds, gts, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"input_ids\"], batch_t[\"attention_mask\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            total_loss += loss.item() * batch_t[\"labels\"].size(0)\n            pred = logits.argmax(dim=-1).cpu().tolist()\n            gt = batch_t[\"labels\"].cpu().tolist()\n            preds.extend(pred)\n            gts.extend(gt)\n            seqs.extend(batch[\"sequence_str\"])\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    return total_loss / len(loader.dataset), swa, preds, gts, seqs\n\n\n# ---------- training ----------\nMAX_EPOCHS, patience = 25, 5\nbest_val_swa, best_state, epochs_no_imp = -1.0, None, 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(\n            batch_t[\"input_ids\"], batch_t[\"attention_mask\"], batch_t[\"sym_feats\"]\n        )\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = epoch_loss / len(train_loader.dataset)\n    train_loss_eval, train_swa, *_ = evaluate(train_loader)\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train_swa\"].append(train_swa)\n    exp_rec[\"metrics\"][\"val_swa\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    print(f\"Epoch {epoch:02d}: val_loss={val_loss:.4f}  val_SWA={val_swa:.4f}\")\n\n    if val_swa > best_val_swa:\n        best_val_swa = val_swa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        epochs_no_imp = 0\n    else:\n        epochs_no_imp += 1\n        if epochs_no_imp >= patience:\n            print(f\"Early stopping after {epoch} epochs.\")\n            break\n\n# ---------- test ----------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_preds, test_gts, test_seqs = evaluate(test_loader)\nprint(f\"TEST   loss={test_loss:.4f}  SWA={test_swa:.4f}\")\n\nexp_rec[\"predictions\"] = np.array(test_preds)\nexp_rec[\"ground_truth\"] = np.array(test_gts)\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, time, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\nfrom typing import List, Dict\n\n# ---- working dir & device ---------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---- helper metrics ---------------------------------------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / (sum(weights) if sum(weights) else 1.0)\n\n\n# ---- load SPR_BENCH ---------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(fname):\n        return load_dataset(\n            \"csv\", data_files=str(root / fname), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---- vocabulary -------------------------------------------------------------\ndef build_vocab(hf_dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in hf_dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(\"Vocab size:\", len(vocab))\n\n\n# ---- Torch Dataset ----------------------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split, vocab):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.vocab = vocab\n\n    def encode(self, seq: str) -> List[int]:\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq_str = self.seqs[idx]\n        return {\n            \"input_ids\": torch.tensor(self.encode(seq_str), dtype=torch.long),\n            \"sym_counts\": torch.tensor(\n                [count_shape_variety(seq_str), count_color_variety(seq_str)],\n                dtype=torch.float,\n            ),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"sequence_str\": seq_str,\n        }\n\n\ntrain_ds, dev_ds, test_ds = [\n    SPRTorchDataset(spr[s], vocab) for s in (\"train\", \"dev\", \"test\")\n]\n\n\n# ---- collate ---------------------------------------------------------------\ndef collate(batch):\n    ids = [b[\"input_ids\"] for b in batch]\n    counts = torch.stack([b[\"sym_counts\"] for b in batch])\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    seqs = [b[\"sequence_str\"] for b in batch]\n    padded = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=0)\n    mask = (padded != 0).float()\n    return {\n        \"input_ids\": padded,\n        \"attention_mask\": mask,\n        \"sym_counts\": counts,\n        \"labels\": labels,\n        \"sequence_str\": seqs,\n    }\n\n\nBATCH = 128\ntrain_loader = DataLoader(train_ds, BATCH, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, BATCH, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, BATCH, shuffle=False, collate_fn=collate)\n\n\n# ---- model -----------------------------------------------------------------\nclass NeuralSymbolicClassifier(nn.Module):\n    def __init__(\n        self, vocab_size, num_classes, emb_dim=128, nhead=4, depth=2, dim_feed=256\n    ):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=emb_dim, nhead=nhead, dim_feedforward=dim_feed, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=depth)\n        self.count_proj = nn.Sequential(nn.Linear(2, 32), nn.ReLU())\n        self.classifier = nn.Linear(emb_dim + 32, num_classes)\n\n    def forward(self, ids, mask, counts):\n        x = self.embed(ids) * mask.unsqueeze(-1)\n        x = self.encoder(x, src_key_padding_mask=(mask == 0))\n        pooled = x.sum(1) / mask.sum(1, keepdim=True).clamp(min=1e-6)\n        c_feat = self.count_proj(counts)\n        logits = self.classifier(torch.cat([pooled, c_feat], dim=-1))\n        return logits\n\n\nnum_classes = int(max(train_ds.labels)) + 1\nmodel = NeuralSymbolicClassifier(len(vocab), num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n\n# ---- experiment data dict ---------------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_swa\": [], \"val_swa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\nrec = experiment_data[\"SPR_BENCH\"]\n\n\n# ---- evaluation -------------------------------------------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, preds, gts, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            bt = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(bt[\"input_ids\"], bt[\"attention_mask\"], bt[\"sym_counts\"])\n            loss = criterion(logits, bt[\"labels\"])\n            tot_loss += loss.item() * bt[\"labels\"].size(0)\n            pred = logits.argmax(-1).cpu().tolist()\n            gt = bt[\"labels\"].cpu().tolist()\n            preds.extend(pred)\n            gts.extend(gt)\n            seqs.extend(batch[\"sequence_str\"])\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    return tot_loss / len(loader.dataset), swa, preds, gts, seqs\n\n\n# ---- training loop with early stopping -------------------------------------\nMAX_EPOCHS = 20\npatience = 3\nbest_val_swa = -1\nwait = 0\nbest_state = None\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    ep_loss = 0.0\n    for batch in train_loader:\n        bt = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(bt[\"input_ids\"], bt[\"attention_mask\"], bt[\"sym_counts\"])\n        loss = criterion(logits, bt[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * bt[\"labels\"].size(0)\n    train_loss = ep_loss / len(train_loader.dataset)\n    val_loss, val_swa, _, _, _ = evaluate(dev_loader)\n    train_loss_eval, train_swa, _, _, _ = evaluate(train_loader)\n\n    rec[\"losses\"][\"train\"].append(train_loss)\n    rec[\"losses\"][\"val\"].append(val_loss)\n    rec[\"metrics\"][\"train_swa\"].append(train_swa)\n    rec[\"metrics\"][\"val_swa\"].append(val_swa)\n    rec[\"timestamps\"].append(time.time())\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f} | val_SWA = {val_swa:.4f}\")\n\n    if val_swa > best_val_swa:\n        best_val_swa = val_swa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        wait = 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n\n# ---- final test evaluation --------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_preds, test_gts, test_seqs = evaluate(test_loader)\nprint(f\"TEST: loss={test_loss:.4f}  SWA={test_swa:.4f}\")\n\nrec[\"predictions\"] = np.array(test_preds)\nrec[\"ground_truth\"] = np.array(test_gts)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, time, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\nfrom typing import Dict, List, Tuple\n\n# ------------------------------------------------------------------\n# working directory & device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------------------------------------------------------\n# experiment log dict\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_swa\": [], \"val_swa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\nexp_rec = experiment_data[\"SPR_BENCH\"]\n\n\n# ------------------------------------------------------------------\n# helpers for dataset ------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _ld(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    d[\"train\"] = _ld(\"train.csv\")\n    d[\"dev\"] = _ld(\"dev.csv\")\n    d[\"test\"] = _ld(\"test.csv\")\n    return d\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.strip().split() if tok))\n\n\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1e-8)\n\n\n# ------------------------------------------------------------------\n# load dataset ------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # fallback\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------------------- vocab & maps ------------------------------\ndef build_vocab(train_split) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1, \"<cls>\": 2}\n    for seq in train_split[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\npad_id, unk_id, cls_id = 0, 1, 2\nprint(f\"Vocab size: {len(vocab)}\")\n\n# ---------------- symbolic feature length -------------------------\n# Build shape & color bins for histogram encoding\nshape_set, color_set = set(), set()\nfor seq in spr[\"train\"][\"sequence\"]:\n    for tok in seq.strip().split():\n        if tok:\n            shape_set.add(tok[0])\n        if len(tok) > 1:\n            color_set.add(tok[1])\nshape_map = {s: i for i, s in enumerate(sorted(shape_set))}\ncolor_map = {c: i for i, c in enumerate(sorted(color_set))}\nSYM_DIM = len(shape_map) + len(color_map) + 2  # +2 for variety counts\nprint(f\"Symbolic feature dim: {SYM_DIM}\")\n\n\n# ------------------------------------------------------------------\n# torch dataset -----------------------------------------------------\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seq = split[\"sequence\"]\n        self.lab = split[\"label\"]\n\n    def encode(self, s: str) -> List[int]:\n        tokens = s.strip().split()\n        ids = [cls_id] + [vocab.get(tok, unk_id) for tok in tokens]\n        return ids\n\n    def sym_features(self, s: str) -> np.ndarray:\n        shp_hist = np.zeros(len(shape_map), dtype=np.float32)\n        col_hist = np.zeros(len(color_map), dtype=np.float32)\n        tokens = s.strip().split()\n        for tok in tokens:\n            if tok and tok[0] in shape_map:\n                shp_hist[shape_map[tok[0]]] += 1.0\n            if len(tok) > 1 and tok[1] in color_map:\n                col_hist[color_map[tok[1]]] += 1.0\n        total = max(len(tokens), 1)\n        vec = np.concatenate([shp_hist, col_hist]) / total\n        var_shape = np.array(\n            [count_shape_variety(s) / 10.0], dtype=np.float32\n        )  # scaled\n        var_color = np.array([count_color_variety(s) / 10.0], dtype=np.float32)\n        return np.concatenate([vec, var_shape, var_color])\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        s = self.seq[idx]\n        return {\n            \"input_ids\": torch.tensor(self.encode(s), dtype=torch.long),\n            \"sym_feats\": torch.tensor(self.sym_features(s), dtype=torch.float32),\n            \"labels\": torch.tensor(self.lab[idx], dtype=torch.long),\n            \"sequence_str\": s,\n        }\n\n\ndef collate(batch):\n    ids = [b[\"input_ids\"] for b in batch]\n    padded = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=pad_id)\n    mask = padded != pad_id\n    sym = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    seqs = [b[\"sequence_str\"] for b in batch]\n    return {\n        \"input_ids\": padded,\n        \"attention_mask\": mask,\n        \"sym_feats\": sym,\n        \"labels\": labels,\n        \"sequence_str\": seqs,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRDataset(spr[\"train\"]),\n    SPRDataset(spr[\"dev\"]),\n    SPRDataset(spr[\"test\"]),\n)\nBATCH = 128\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=BATCH, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=BATCH, shuffle=False, collate_fn=collate)\n\n# ------------------------------------------------------------------\n# Rule-lookup majority baseline ------------------------------------\n# key = (shape_variety, color_variety) -> {label:count}\nrule_counts: Dict[Tuple[int, int], Dict[int, int]] = {}\nfor s, l in zip(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"]):\n    key = (count_shape_variety(s), count_color_variety(s))\n    rule_counts.setdefault(key, {})\n    rule_counts[key][l] = rule_counts[key].get(l, 0) + 1\n\n\ndef rule_predict(key):\n    if key not in rule_counts:\n        return None, 0.0\n    d = rule_counts[key]\n    total = sum(d.values())\n    label = max(d, key=d.get)\n    conf = d[label] / total\n    return label, conf\n\n\n# ------------------------------------------------------------------\n# Model -------------------------------------------------------------\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=512):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div = torch.exp(\n            torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model)\n        )\n        pe[:, 0::2] = torch.sin(pos * div)\n        pe[:, 1::2] = torch.cos(pos * div)\n        self.register_buffer(\"pe\", pe.unsqueeze(0))\n\n    def forward(self, x):\n        # x: B x T x D\n        T = x.size(1)\n        return x + self.pe[:, :T]\n\n\nclass NeuralSymbolicTransformer(nn.Module):\n    def __init__(self, vocab_size, emb_dim, sym_dim, nhead, layers, num_classes):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n        self.posenc = PositionalEncoding(emb_dim)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=emb_dim,\n            nhead=nhead,\n            dim_feedforward=emb_dim * 2,\n            dropout=0.1,\n            activation=\"relu\",\n            batch_first=True,\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=layers)\n        self.fc = nn.Linear(emb_dim + sym_dim, num_classes)\n\n    def forward(self, ids, mask, sym):\n        x = self.embedding(ids)\n        x = self.posenc(x)\n        x = self.encoder(x, src_key_padding_mask=~mask)  # batch_first\n        cls_vec = x[:, 0]  # CLS token representation\n        out = torch.cat([cls_vec, sym], dim=-1)\n        return self.fc(out)\n\n\nnum_classes = int(max(train_ds.lab)) + 1\nmodel = NeuralSymbolicTransformer(\n    len(vocab), 64, SYM_DIM, nhead=4, layers=2, num_classes=num_classes\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n\n\n# ------------------------------------------------------------------\n# evaluation function ----------------------------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, preds, gts, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_gpu = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(\n                batch_gpu[\"input_ids\"],\n                batch_gpu[\"attention_mask\"],\n                batch_gpu[\"sym_feats\"],\n            )\n            loss = criterion(logits, batch_gpu[\"labels\"])\n            tot_loss += loss.item() * batch_gpu[\"labels\"].size(0)\n            neural_pred = logits.argmax(dim=-1).cpu().tolist()\n            # combine with rule lookup\n            for i, seq in enumerate(batch[\"sequence_str\"]):\n                key = (count_shape_variety(seq), count_color_variety(seq))\n                label_rule, conf = rule_predict(key)\n                if conf > 0.8:\n                    preds.append(label_rule)\n                else:\n                    preds.append(neural_pred[i])\n            gts.extend(batch_gpu[\"labels\"].cpu().tolist())\n            seqs.extend(batch[\"sequence_str\"])\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    return tot_loss / len(loader.dataset), swa, preds, gts\n\n\n# ------------------------------------------------------------------\n# training loop -----------------------------------------------------\nMAX_EPOCHS, patience = 20, 4\nbest_val_swa, best_state, no_imp = -1.0, None, 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    ep_loss = 0.0\n    for batch in train_loader:\n        batch_gpu = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(\n            batch_gpu[\"input_ids\"], batch_gpu[\"attention_mask\"], batch_gpu[\"sym_feats\"]\n        )\n        loss = criterion(logits, batch_gpu[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * batch_gpu[\"labels\"].size(0)\n    train_loss = ep_loss / len(train_loader.dataset)\n    train_loss_e, train_swa, _, _ = evaluate(train_loader)\n    val_loss, val_swa, _, _ = evaluate(dev_loader)\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train_swa\"].append(train_swa)\n    exp_rec[\"metrics\"][\"val_swa\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f} | val_SWA = {val_swa:.4f}\")\n\n    if val_swa > best_val_swa:\n        best_val_swa = val_swa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ------------------------------------------------------------------\n# test --------------------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_preds, test_gts = evaluate(test_loader)\nprint(f\"TEST loss={test_loss:.4f} | TEST SWA={test_swa:.4f}\")\n\nexp_rec[\"predictions\"] = np.array(test_preds)\nexp_rec[\"ground_truth\"] = np.array(test_gts)\n\n# ------------------------------------------------------------------\n# save experiment data ---------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, time, pathlib, random, numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- experiment data dict ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_swa\": [], \"val_swa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\nexp_rec = experiment_data[\"SPR_BENCH\"]\n\n\n# ---------- util funcs ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\n# ---------- dataset path ----------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- vocab & maps ----------\ndef build_vocab_and_maps(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    shapes, colors = set(), set()\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n            shapes.add(tok[0])\n            if len(tok) > 1:\n                colors.add(tok[1])\n    shape_map = {s: i for i, s in enumerate(sorted(shapes))}\n    color_map = {c: i for i, c in enumerate(sorted(colors))}\n    return vocab, shape_map, color_map\n\n\nvocab, shape_map, color_map = build_vocab_and_maps(spr[\"train\"])\nsym_dim = len(shape_map) + len(color_map)\nprint(f\"vocab={len(vocab)} shapes={len(shape_map)} colors={len(color_map)}\")\n\n\n# ---------- torch Dataset ----------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, shape_map, color_map):\n        self.seqs = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.vocab = vocab\n        self.shape_map = shape_map\n        self.color_map = color_map\n        self.sym_len = len(shape_map) + len(color_map)\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def encode(self, seq):\n        return [self.vocab.get(tok, 1) for tok in seq.strip().split()]\n\n    def sym_vec(self, seq):\n        s = np.zeros(len(self.shape_map), dtype=np.float32)\n        c = np.zeros(len(self.color_map), dtype=np.float32)\n        for tok in seq.strip().split():\n            s[self.shape_map[tok[0]]] += 1\n            if len(tok) > 1:\n                c[self.color_map[tok[1]]] += 1\n        tot = max(1, len(seq.strip().split()))\n        return np.concatenate([s, c]) / tot\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        return {\n            \"input_ids\": torch.tensor(self.encode(seq), dtype=torch.long),\n            \"sym\": torch.tensor(self.sym_vec(seq), dtype=torch.float32),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"seq_str\": seq,\n        }\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, shape_map, color_map)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, shape_map, color_map)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, shape_map, color_map)\n\n\n# ---------- collate ----------\ndef collate_fn(batch):\n    ids = [b[\"input_ids\"] for b in batch]\n    padded = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=0)\n    mask = (padded != 0).float()\n    sym = torch.stack([b[\"sym\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"sym\": sym,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nBATCH = 128\ntrain_loader = DataLoader(\n    train_ds, batch_size=BATCH, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(dev_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(\n    test_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ---------- model ----------\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=200):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        pos = torch.arange(0, max_len).unsqueeze(1)\n        div = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(pos * div)\n        pe[:, 1::2] = torch.cos(pos * div)\n        self.register_buffer(\"pe\", pe.unsqueeze(0))  # 1 x L x D\n\n    def forward(self, x):\n        x = x + self.pe[:, : x.size(1)]\n        return x\n\n\nclass NeuralSymbolicTransformer(nn.Module):\n    def __init__(\n        self,\n        vocab_size,\n        emb_dim,\n        sym_dim,\n        n_heads,\n        n_layers,\n        hidden_dim,\n        n_cls,\n        p_drop=0.1,\n    ):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.pos = PositionalEncoding(emb_dim)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=emb_dim,\n            nhead=n_heads,\n            dim_feedforward=hidden_dim,\n            dropout=p_drop,\n            batch_first=True,\n        )\n        self.tr_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n        self.dropout = nn.Dropout(p_drop)\n        # gating fusion\n        self.gate = nn.Linear(emb_dim + sym_dim, emb_dim + sym_dim)\n        self.classifier = nn.Linear(emb_dim + sym_dim, n_cls)\n\n    def forward(self, ids, mask, sym, token_dropout=0.0):\n        if self.training and token_dropout > 0:\n            # randomly drop tokens (set to pad)\n            drop_mask = (torch.rand(ids.shape, device=ids.device) < token_dropout) & (\n                ids != 0\n            )\n            ids = ids.masked_fill(drop_mask, 0)\n            mask = (ids != 0).float()\n        x = self.emb(ids)\n        x = self.pos(x)\n        x = self.tr_encoder(x, src_key_padding_mask=(mask == 0))\n        # mean pool\n        pooled = (x * mask.unsqueeze(-1)).sum(1) / mask.sum(1, keepdim=True).clamp(\n            min=1e-6\n        )\n        fused = torch.cat([pooled, sym], dim=-1)\n        g = torch.sigmoid(self.gate(fused))\n        fused = fused * g  # gated features\n        fused = self.dropout(fused)\n        return self.classifier(fused)\n\n\nnum_classes = int(max(train_ds.labels)) + 1\nmodel = NeuralSymbolicTransformer(\n    vocab_size=len(vocab),\n    emb_dim=64,\n    sym_dim=sym_dim,\n    n_heads=4,\n    n_layers=2,\n    hidden_dim=128,\n    n_cls=num_classes,\n    p_drop=0.1,\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n\n# ---------- evaluation ----------\ndef evaluate(loader):\n    model.eval()\n    total_loss, preds, gts, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n            loss = criterion(logits, batch[\"labels\"])\n            total_loss += loss.item() * batch[\"labels\"].size(0)\n            pred = logits.argmax(-1).cpu().tolist()\n            preds.extend(pred)\n            gts.extend(batch[\"labels\"].cpu().tolist())\n            seqs.extend(batch[\"seqs\"])\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    return total_loss / len(loader.dataset), swa, preds, gts, seqs\n\n\n# ---------- training ----------\nMAX_EPOCHS, patience = 25, 5\nbest_val_swa, best_state, no_imp = -1.0, None, 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(\n            batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"], token_dropout=0.1\n        )\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = epoch_loss / len(train_loader.dataset)\n    train_loss_eval, train_swa, *_ = evaluate(train_loader)\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train_swa\"].append(train_swa)\n    exp_rec[\"metrics\"][\"val_swa\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    print(\n        f\"Epoch {epoch:02d}: validation_loss = {val_loss:.4f}, val_SWA = {val_swa:.4f}\"\n    )\n\n    if val_swa > best_val_swa:\n        best_val_swa = val_swa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ---------- test ----------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_preds, test_gts, _ = evaluate(test_loader)\nprint(f\"TEST: loss={test_loss:.4f}  SWA={test_swa:.4f}\")\n\nexp_rec[\"predictions\"] = np.array(test_preds)\nexp_rec[\"ground_truth\"] = np.array(test_gts)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, time, pathlib, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\nfrom typing import List\n\n# ----------------- working dir -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- device -----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ----------------- experiment data dict -----------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_swa\": [], \"val_swa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\nexp_rec = experiment_data[\"SPR_BENCH\"]\n\n\n# ----------------- util funcs -----------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# ----------------- data path -----------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ----------------- vocab & maps -----------------\ndef build_vocab_maps(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    shape_set, color_set = set(), set()\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n            if tok:\n                shape_set.add(tok[0])\n            if len(tok) > 1:\n                color_set.add(tok[1])\n    shape_map = {s: i for i, s in enumerate(sorted(shape_set))}\n    color_map = {c: i for i, c in enumerate(sorted(color_set))}\n    return vocab, shape_map, color_map\n\n\nvocab, shape_map, color_map = build_vocab_maps(spr[\"train\"])\n\n\n# ----------------- torch dataset -----------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, shape_map, color_map):\n        self.seqs = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.vocab = vocab\n        self.shape_map, self.color_map = shape_map, color_map\n        self.sym_dim = len(shape_map) + len(color_map)\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def tok_ids(self, seq: str) -> List[int]:\n        return [self.vocab.get(tok, 1) for tok in seq.strip().split()]\n\n    def sym_feats(self, seq: str) -> np.ndarray:\n        s_vec = np.zeros(len(self.shape_map), dtype=np.float32)\n        c_vec = np.zeros(len(self.color_map), dtype=np.float32)\n        for tok in seq.strip().split():\n            if tok[0] in self.shape_map:\n                s_vec[self.shape_map[tok[0]]] += 1\n            if len(tok) > 1 and tok[1] in self.color_map:\n                c_vec[self.color_map[tok[1]]] += 1\n        total = max(len(seq.strip().split()), 1)\n        return np.concatenate([s_vec, c_vec]) / total\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        return {\n            \"input_ids\": torch.tensor(self.tok_ids(seq), dtype=torch.long),\n            \"sym\": torch.tensor(self.sym_feats(seq), dtype=torch.float32),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"shape_cnt\": torch.tensor(count_shape_variety(seq), dtype=torch.float32),\n            \"seq_str\": seq,\n        }\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, shape_map, color_map)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, shape_map, color_map)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, shape_map, color_map)\n\n\ndef collate(batch):\n    ids = [b[\"input_ids\"] for b in batch]\n    padded = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=0)\n    mask = (padded != 0).float()\n    sym = torch.stack([b[\"sym\"] for b in batch])\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    scnt = torch.stack([b[\"shape_cnt\"] for b in batch])\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"sym\": sym,\n        \"labels\": labels,\n        \"shape_cnt\": scnt,\n        \"seqs\": seqs,\n    }\n\n\nBATCH = 128\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=BATCH, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=BATCH, shuffle=False, collate_fn=collate)\n\n\n# ----------------- model -----------------\nclass NeuralSymbolicTransformer(nn.Module):\n    def __init__(\n        self,\n        vocab_size,\n        emb_dim,\n        sym_dim,\n        num_classes,\n        max_len=128,\n        n_heads=4,\n        n_layers=2,\n        aux_coef=0.1,\n    ):\n        super().__init__()\n        self.aux_coef = aux_coef\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.pos = nn.Embedding(max_len, emb_dim)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=emb_dim,\n            nhead=n_heads,\n            dim_feedforward=emb_dim * 2,\n            batch_first=True,\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n        self.classifier = nn.Sequential(\n            nn.Linear(emb_dim + sym_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n        self.reg_head = nn.Sequential(\n            nn.Linear(emb_dim + sym_dim, 64), nn.ReLU(), nn.Linear(64, 1)\n        )\n\n    def forward(self, ids, mask, sym):\n        pos_ids = (\n            torch.arange(ids.size(1), device=ids.device)\n            .unsqueeze(0)\n            .expand(ids.size(0), -1)\n        )\n        x = self.emb(ids) + self.pos(pos_ids)\n        x = self.encoder(x, src_key_padding_mask=(ids == 0))\n        mean_emb = (x * mask.unsqueeze(-1)).sum(1) / mask.sum(1, keepdim=True).clamp(\n            min=1e-6\n        )\n        feats = torch.cat([mean_emb, sym], dim=-1)\n        logits = self.classifier(feats)\n        shape_pred = self.reg_head(feats).squeeze(-1)\n        return logits, shape_pred\n\n\nnum_classes = int(max(train_ds.labels)) + 1\nsym_dim = len(shape_map) + len(color_map)\nmodel = NeuralSymbolicTransformer(\n    len(vocab), emb_dim=64, sym_dim=sym_dim, num_classes=num_classes, max_len=200\n).to(device)\n\ncrit_cls = nn.CrossEntropyLoss()\ncrit_reg = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ----------------- evaluation -----------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, preds, gts, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits, scnt_pred = model(\n                batch_t[\"input_ids\"], batch_t[\"mask\"], batch_t[\"sym\"]\n            )\n            loss = crit_cls(logits, batch_t[\"labels\"]) + model.aux_coef * crit_reg(\n                scnt_pred, batch_t[\"shape_cnt\"]\n            )\n            tot_loss += loss.item() * batch_t[\"labels\"].size(0)\n            preds.extend(logits.argmax(-1).cpu().tolist())\n            gts.extend(batch_t[\"labels\"].cpu().tolist())\n            seqs.extend(batch[\"seqs\"])\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    return tot_loss / len(loader.dataset), swa, preds, gts, seqs\n\n\n# ----------------- training loop -----------------\nMAX_EPOCHS, patience = 30, 6\nbest_val_swa, best_state, no_imp = -1.0, None, 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits, scnt_pred = model(batch_t[\"input_ids\"], batch_t[\"mask\"], batch_t[\"sym\"])\n        loss = crit_cls(logits, batch_t[\"labels\"]) + model.aux_coef * crit_reg(\n            scnt_pred, batch_t[\"shape_cnt\"]\n        )\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = epoch_loss / len(train_loader.dataset)\n    _, train_swa, *_ = evaluate(train_loader)\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train_swa\"].append(train_swa)\n    exp_rec[\"metrics\"][\"val_swa\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch:02d}: validation_loss = {val_loss:.4f}  val_SWA = {val_swa:.4f}\"\n    )\n    if val_swa > best_val_swa:\n        best_val_swa = val_swa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n\n# ----------------- test -----------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, preds, gts, seqs = evaluate(test_loader)\nprint(f\"TEST loss={test_loss:.4f}  SWA={test_swa:.4f}\")\nexp_rec[\"predictions\"] = np.array(preds)\nexp_rec[\"ground_truth\"] = np.array(gts)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, time, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ------------- working dir -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------- device ----------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------- experiment store ------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_swa\": [], \"val_swa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\nexp_rec = experiment_data[\"SPR_BENCH\"]\n\n\n# ------------- helper: benchmark loader ----\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\n# ------------- metric helpers --------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ------------- data path -------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # fallback for local tests\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ------------- build vocab sets ------------\ndef build_shape_color_sets(dataset):\n    shapes, colors = set(), set()\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok:\n                shapes.add(tok[0])\n                if len(tok) > 1:\n                    colors.add(tok[1])\n    colors.add(\"<none>\")  # placeholder for single-char tokens\n    shapes = {\"<pad>\": 0, **{ch: i + 1 for i, ch in enumerate(sorted(shapes))}}\n    colors = {\"<pad>\": 0, **{ch: i + 1 for i, ch in enumerate(sorted(colors))}}\n    return shapes, colors\n\n\nshape_map, color_map = build_shape_color_sets(spr[\"train\"])\nprint(f\"n_shapes={len(shape_map)}  n_colors={len(color_map)}\")\n\n# ------------- symbolic feature size -------\nn_shape_sym = len({k for k in shape_map if k not in (\"<pad>\")})\nn_color_sym = len({k for k in color_map if k not in (\"<pad>\")})\nsym_dim = n_shape_sym + n_color_sym\n\n\n# ------------- torch dataset ---------------\nclass SPRDataset(Dataset):\n    def __init__(self, split, shape_map, color_map):\n        self.seq = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.shape_map = shape_map\n        self.color_map = color_map\n        self.n_shape_sym = n_shape_sym\n        self.n_color_sym = n_color_sym\n\n    def encode_token(self, tok):\n        s_idx = self.shape_map.get(tok[0], self.shape_map[\"<pad>\"])\n        if len(tok) > 1:\n            c_idx = self.color_map.get(tok[1], self.color_map[\"<pad>\"])\n        else:\n            c_idx = self.color_map.get(\"<none>\", self.color_map[\"<pad>\"])\n        return s_idx, c_idx\n\n    def symbolic_vec(self, seq):\n        s_vec = np.zeros(self.n_shape_sym, dtype=np.float32)\n        c_vec = np.zeros(self.n_color_sym, dtype=np.float32)\n        for tok in seq.strip().split():\n            if tok:\n                if tok[0] in shape_map and tok[0] != \"<pad>\":\n                    s_vec[shape_map[tok[0]] - 1] += 1\n                if len(tok) > 1 and tok[1] in color_map and tok[1] != \"<pad>\":\n                    c_vec[color_map[tok[1]] - 1] += 1\n        total = max(len(seq.strip().split()), 1)\n        return np.concatenate([s_vec, c_vec]) / total\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        seq_str = self.seq[idx]\n        shape_ids, color_ids = zip(\n            *[self.encode_token(tok) for tok in seq_str.strip().split()]\n        )\n        return {\n            \"shape_ids\": torch.tensor(shape_ids, dtype=torch.long),\n            \"color_ids\": torch.tensor(color_ids, dtype=torch.long),\n            \"sym_feats\": torch.tensor(self.symbolic_vec(seq_str), dtype=torch.float32),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"sequence_str\": seq_str,\n        }\n\n\ntrain_ds = SPRDataset(spr[\"train\"], shape_map, color_map)\ndev_ds = SPRDataset(spr[\"dev\"], shape_map, color_map)\ntest_ds = SPRDataset(spr[\"test\"], shape_map, color_map)\n\n\n# ------------- collate ---------------------\ndef collate_fn(batch):\n    shape_list = [b[\"shape_ids\"] for b in batch]\n    color_list = [b[\"color_ids\"] for b in batch]\n    pad_shape = nn.utils.rnn.pad_sequence(shape_list, batch_first=True, padding_value=0)\n    pad_color = nn.utils.rnn.pad_sequence(color_list, batch_first=True, padding_value=0)\n    mask = pad_shape != 0  # B x T boolean\n    sym = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    seqs = [b[\"sequence_str\"] for b in batch]\n    return {\n        \"shape_ids\": pad_shape,\n        \"color_ids\": pad_color,\n        \"attention_mask\": mask,\n        \"sym_feats\": sym,\n        \"labels\": labels,\n        \"sequence_str\": seqs,\n    }\n\n\nBATCH = 256\ntrain_loader = DataLoader(\n    train_ds, batch_size=BATCH, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(dev_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(\n    test_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ------------- model -----------------------\nclass NeuralSymbolicTransformer(nn.Module):\n    def __init__(\n        self,\n        n_shape,\n        n_color,\n        sym_dim,\n        num_classes,\n        d_model=64,\n        nhead=4,\n        num_layers=2,\n        max_len=64,\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(max_len, d_model)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n        self.mlp = nn.Sequential(\n            nn.Linear(d_model + sym_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n\n    def forward(self, shape_ids, color_ids, attn_mask, sym_feats):\n        B, T = shape_ids.size()\n        pos = torch.arange(T, device=shape_ids.device).unsqueeze(0).expand(B, T)\n        tok_emb = (\n            self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        )\n        enc_out = self.encoder(tok_emb, src_key_padding_mask=~attn_mask)\n        seq_emb = (enc_out * attn_mask.unsqueeze(-1)).sum(1) / attn_mask.sum(\n            1, keepdim=True\n        ).clamp(min=1e-6)\n        x = torch.cat([seq_emb, sym_feats], dim=-1)\n        return self.mlp(x)\n\n\nnum_classes = int(max(train_ds.labels)) + 1\nmodel = NeuralSymbolicTransformer(\n    len(shape_map), len(color_map), sym_dim, num_classes\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ------------- evaluation ------------------\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss, preds, gts, seqs = 0.0, [], [], []\n    for batch in loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        logits = model(\n            batch[\"shape_ids\"],\n            batch[\"color_ids\"],\n            batch[\"attention_mask\"],\n            batch[\"sym_feats\"],\n        )\n        loss = criterion(logits, batch[\"labels\"])\n        tot_loss += loss.item() * batch[\"labels\"].size(0)\n        p = logits.argmax(-1).cpu().tolist()\n        g = batch[\"labels\"].cpu().tolist()\n        preds.extend(p)\n        gts.extend(g)\n        seqs.extend(batch[\"sequence_str\"])\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    return tot_loss / len(loader.dataset), swa, preds, gts, seqs\n\n\n# ------------- training --------------------\nMAX_EPOCHS, patience = 20, 4\nbest_val_swa, best_state, no_imp = -1.0, None, 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(\n            batch[\"shape_ids\"],\n            batch[\"color_ids\"],\n            batch[\"attention_mask\"],\n            batch[\"sym_feats\"],\n        )\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = epoch_loss / len(train_loader.dataset)\n    train_loss_eval, train_swa, _, _, _ = evaluate(train_loader)\n    val_loss, val_swa, _, _, _ = evaluate(dev_loader)\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train_swa\"].append(train_swa)\n    exp_rec[\"metrics\"][\"val_swa\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    print(f\"Epoch {epoch:02d}: val_loss = {val_loss:.4f}  val_SWA = {val_swa:.4f}\")\n\n    if val_swa > best_val_swa:\n        best_val_swa = val_swa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ------------- test ------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_preds, test_gts, _ = evaluate(test_loader)\nprint(f\"TEST loss = {test_loss:.4f}  SWA = {test_swa:.4f}\")\n\nexp_rec[\"predictions\"] = np.array(test_preds)\nexp_rec[\"ground_truth\"] = np.array(test_gts)\n\n# ------------- save all --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, time, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ------------- working dir -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------- device ----------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------- experiment store ------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_swa\": [], \"val_swa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\nexp_rec = experiment_data[\"SPR_BENCH\"]\n\n\n# ------------- helper: benchmark loader ----\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\n# ------------- metric helpers --------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ------------- data path -------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # fallback for local tests\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ------------- build vocab sets ------------\ndef build_shape_color_sets(dataset):\n    shapes, colors = set(), set()\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok:\n                shapes.add(tok[0])\n                if len(tok) > 1:\n                    colors.add(tok[1])\n    colors.add(\"<none>\")  # placeholder for single-char tokens\n    shapes = {\"<pad>\": 0, **{ch: i + 1 for i, ch in enumerate(sorted(shapes))}}\n    colors = {\"<pad>\": 0, **{ch: i + 1 for i, ch in enumerate(sorted(colors))}}\n    return shapes, colors\n\n\nshape_map, color_map = build_shape_color_sets(spr[\"train\"])\nprint(f\"n_shapes={len(shape_map)}  n_colors={len(color_map)}\")\n\n# ------------- symbolic feature size -------\nn_shape_sym = len({k for k in shape_map if k not in (\"<pad>\")})\nn_color_sym = len({k for k in color_map if k not in (\"<pad>\")})\nsym_dim = n_shape_sym + n_color_sym\n\n\n# ------------- torch dataset ---------------\nclass SPRDataset(Dataset):\n    def __init__(self, split, shape_map, color_map):\n        self.seq = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.shape_map = shape_map\n        self.color_map = color_map\n        self.n_shape_sym = n_shape_sym\n        self.n_color_sym = n_color_sym\n\n    def encode_token(self, tok):\n        s_idx = self.shape_map.get(tok[0], self.shape_map[\"<pad>\"])\n        if len(tok) > 1:\n            c_idx = self.color_map.get(tok[1], self.color_map[\"<pad>\"])\n        else:\n            c_idx = self.color_map.get(\"<none>\", self.color_map[\"<pad>\"])\n        return s_idx, c_idx\n\n    def symbolic_vec(self, seq):\n        s_vec = np.zeros(self.n_shape_sym, dtype=np.float32)\n        c_vec = np.zeros(self.n_color_sym, dtype=np.float32)\n        for tok in seq.strip().split():\n            if tok:\n                if tok[0] in shape_map and tok[0] != \"<pad>\":\n                    s_vec[shape_map[tok[0]] - 1] += 1\n                if len(tok) > 1 and tok[1] in color_map and tok[1] != \"<pad>\":\n                    c_vec[color_map[tok[1]] - 1] += 1\n        total = max(len(seq.strip().split()), 1)\n        return np.concatenate([s_vec, c_vec]) / total\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        seq_str = self.seq[idx]\n        shape_ids, color_ids = zip(\n            *[self.encode_token(tok) for tok in seq_str.strip().split()]\n        )\n        return {\n            \"shape_ids\": torch.tensor(shape_ids, dtype=torch.long),\n            \"color_ids\": torch.tensor(color_ids, dtype=torch.long),\n            \"sym_feats\": torch.tensor(self.symbolic_vec(seq_str), dtype=torch.float32),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"sequence_str\": seq_str,\n        }\n\n\ntrain_ds = SPRDataset(spr[\"train\"], shape_map, color_map)\ndev_ds = SPRDataset(spr[\"dev\"], shape_map, color_map)\ntest_ds = SPRDataset(spr[\"test\"], shape_map, color_map)\n\n\n# ------------- collate ---------------------\ndef collate_fn(batch):\n    shape_list = [b[\"shape_ids\"] for b in batch]\n    color_list = [b[\"color_ids\"] for b in batch]\n    pad_shape = nn.utils.rnn.pad_sequence(shape_list, batch_first=True, padding_value=0)\n    pad_color = nn.utils.rnn.pad_sequence(color_list, batch_first=True, padding_value=0)\n    mask = pad_shape != 0  # B x T boolean\n    sym = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    seqs = [b[\"sequence_str\"] for b in batch]\n    return {\n        \"shape_ids\": pad_shape,\n        \"color_ids\": pad_color,\n        \"attention_mask\": mask,\n        \"sym_feats\": sym,\n        \"labels\": labels,\n        \"sequence_str\": seqs,\n    }\n\n\nBATCH = 256\ntrain_loader = DataLoader(\n    train_ds, batch_size=BATCH, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(dev_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(\n    test_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ------------- model -----------------------\nclass NeuralSymbolicTransformer(nn.Module):\n    def __init__(\n        self,\n        n_shape,\n        n_color,\n        sym_dim,\n        num_classes,\n        d_model=64,\n        nhead=4,\n        num_layers=2,\n        max_len=64,\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(max_len, d_model)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n        self.mlp = nn.Sequential(\n            nn.Linear(d_model + sym_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n\n    def forward(self, shape_ids, color_ids, attn_mask, sym_feats):\n        B, T = shape_ids.size()\n        pos = torch.arange(T, device=shape_ids.device).unsqueeze(0).expand(B, T)\n        tok_emb = (\n            self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        )\n        enc_out = self.encoder(tok_emb, src_key_padding_mask=~attn_mask)\n        seq_emb = (enc_out * attn_mask.unsqueeze(-1)).sum(1) / attn_mask.sum(\n            1, keepdim=True\n        ).clamp(min=1e-6)\n        x = torch.cat([seq_emb, sym_feats], dim=-1)\n        return self.mlp(x)\n\n\nnum_classes = int(max(train_ds.labels)) + 1\nmodel = NeuralSymbolicTransformer(\n    len(shape_map), len(color_map), sym_dim, num_classes\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ------------- evaluation ------------------\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss, preds, gts, seqs = 0.0, [], [], []\n    for batch in loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        logits = model(\n            batch[\"shape_ids\"],\n            batch[\"color_ids\"],\n            batch[\"attention_mask\"],\n            batch[\"sym_feats\"],\n        )\n        loss = criterion(logits, batch[\"labels\"])\n        tot_loss += loss.item() * batch[\"labels\"].size(0)\n        p = logits.argmax(-1).cpu().tolist()\n        g = batch[\"labels\"].cpu().tolist()\n        preds.extend(p)\n        gts.extend(g)\n        seqs.extend(batch[\"sequence_str\"])\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    return tot_loss / len(loader.dataset), swa, preds, gts, seqs\n\n\n# ------------- training --------------------\nMAX_EPOCHS, patience = 20, 4\nbest_val_swa, best_state, no_imp = -1.0, None, 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(\n            batch[\"shape_ids\"],\n            batch[\"color_ids\"],\n            batch[\"attention_mask\"],\n            batch[\"sym_feats\"],\n        )\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = epoch_loss / len(train_loader.dataset)\n    train_loss_eval, train_swa, _, _, _ = evaluate(train_loader)\n    val_loss, val_swa, _, _, _ = evaluate(dev_loader)\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train_swa\"].append(train_swa)\n    exp_rec[\"metrics\"][\"val_swa\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    print(f\"Epoch {epoch:02d}: val_loss = {val_loss:.4f}  val_SWA = {val_swa:.4f}\")\n\n    if val_swa > best_val_swa:\n        best_val_swa = val_swa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ------------- test ------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_preds, test_gts, _ = evaluate(test_loader)\nprint(f\"TEST loss = {test_loss:.4f}  SWA = {test_swa:.4f}\")\n\nexp_rec[\"predictions\"] = np.array(test_preds)\nexp_rec[\"ground_truth\"] = np.array(test_gts)\n\n# ------------- save all --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, time, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ------------- working dir -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------- device ----------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------- experiment store ------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_swa\": [], \"val_swa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\nexp_rec = experiment_data[\"SPR_BENCH\"]\n\n\n# ------------- helper: benchmark loader ----\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\n# ------------- metric helpers --------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ------------- data path -------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # fallback for local tests\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ------------- build vocab sets ------------\ndef build_shape_color_sets(dataset):\n    shapes, colors = set(), set()\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok:\n                shapes.add(tok[0])\n                if len(tok) > 1:\n                    colors.add(tok[1])\n    colors.add(\"<none>\")  # placeholder for single-char tokens\n    shapes = {\"<pad>\": 0, **{ch: i + 1 for i, ch in enumerate(sorted(shapes))}}\n    colors = {\"<pad>\": 0, **{ch: i + 1 for i, ch in enumerate(sorted(colors))}}\n    return shapes, colors\n\n\nshape_map, color_map = build_shape_color_sets(spr[\"train\"])\nprint(f\"n_shapes={len(shape_map)}  n_colors={len(color_map)}\")\n\n# ------------- symbolic feature size -------\nn_shape_sym = len({k for k in shape_map if k not in (\"<pad>\")})\nn_color_sym = len({k for k in color_map if k not in (\"<pad>\")})\nsym_dim = n_shape_sym + n_color_sym\n\n\n# ------------- torch dataset ---------------\nclass SPRDataset(Dataset):\n    def __init__(self, split, shape_map, color_map):\n        self.seq = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.shape_map = shape_map\n        self.color_map = color_map\n        self.n_shape_sym = n_shape_sym\n        self.n_color_sym = n_color_sym\n\n    def encode_token(self, tok):\n        s_idx = self.shape_map.get(tok[0], self.shape_map[\"<pad>\"])\n        if len(tok) > 1:\n            c_idx = self.color_map.get(tok[1], self.color_map[\"<pad>\"])\n        else:\n            c_idx = self.color_map.get(\"<none>\", self.color_map[\"<pad>\"])\n        return s_idx, c_idx\n\n    def symbolic_vec(self, seq):\n        s_vec = np.zeros(self.n_shape_sym, dtype=np.float32)\n        c_vec = np.zeros(self.n_color_sym, dtype=np.float32)\n        for tok in seq.strip().split():\n            if tok:\n                if tok[0] in shape_map and tok[0] != \"<pad>\":\n                    s_vec[shape_map[tok[0]] - 1] += 1\n                if len(tok) > 1 and tok[1] in color_map and tok[1] != \"<pad>\":\n                    c_vec[color_map[tok[1]] - 1] += 1\n        total = max(len(seq.strip().split()), 1)\n        return np.concatenate([s_vec, c_vec]) / total\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        seq_str = self.seq[idx]\n        shape_ids, color_ids = zip(\n            *[self.encode_token(tok) for tok in seq_str.strip().split()]\n        )\n        return {\n            \"shape_ids\": torch.tensor(shape_ids, dtype=torch.long),\n            \"color_ids\": torch.tensor(color_ids, dtype=torch.long),\n            \"sym_feats\": torch.tensor(self.symbolic_vec(seq_str), dtype=torch.float32),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"sequence_str\": seq_str,\n        }\n\n\ntrain_ds = SPRDataset(spr[\"train\"], shape_map, color_map)\ndev_ds = SPRDataset(spr[\"dev\"], shape_map, color_map)\ntest_ds = SPRDataset(spr[\"test\"], shape_map, color_map)\n\n\n# ------------- collate ---------------------\ndef collate_fn(batch):\n    shape_list = [b[\"shape_ids\"] for b in batch]\n    color_list = [b[\"color_ids\"] for b in batch]\n    pad_shape = nn.utils.rnn.pad_sequence(shape_list, batch_first=True, padding_value=0)\n    pad_color = nn.utils.rnn.pad_sequence(color_list, batch_first=True, padding_value=0)\n    mask = pad_shape != 0  # B x T boolean\n    sym = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    seqs = [b[\"sequence_str\"] for b in batch]\n    return {\n        \"shape_ids\": pad_shape,\n        \"color_ids\": pad_color,\n        \"attention_mask\": mask,\n        \"sym_feats\": sym,\n        \"labels\": labels,\n        \"sequence_str\": seqs,\n    }\n\n\nBATCH = 256\ntrain_loader = DataLoader(\n    train_ds, batch_size=BATCH, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(dev_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(\n    test_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ------------- model -----------------------\nclass NeuralSymbolicTransformer(nn.Module):\n    def __init__(\n        self,\n        n_shape,\n        n_color,\n        sym_dim,\n        num_classes,\n        d_model=64,\n        nhead=4,\n        num_layers=2,\n        max_len=64,\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(max_len, d_model)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n        self.mlp = nn.Sequential(\n            nn.Linear(d_model + sym_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n\n    def forward(self, shape_ids, color_ids, attn_mask, sym_feats):\n        B, T = shape_ids.size()\n        pos = torch.arange(T, device=shape_ids.device).unsqueeze(0).expand(B, T)\n        tok_emb = (\n            self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        )\n        enc_out = self.encoder(tok_emb, src_key_padding_mask=~attn_mask)\n        seq_emb = (enc_out * attn_mask.unsqueeze(-1)).sum(1) / attn_mask.sum(\n            1, keepdim=True\n        ).clamp(min=1e-6)\n        x = torch.cat([seq_emb, sym_feats], dim=-1)\n        return self.mlp(x)\n\n\nnum_classes = int(max(train_ds.labels)) + 1\nmodel = NeuralSymbolicTransformer(\n    len(shape_map), len(color_map), sym_dim, num_classes\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ------------- evaluation ------------------\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss, preds, gts, seqs = 0.0, [], [], []\n    for batch in loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        logits = model(\n            batch[\"shape_ids\"],\n            batch[\"color_ids\"],\n            batch[\"attention_mask\"],\n            batch[\"sym_feats\"],\n        )\n        loss = criterion(logits, batch[\"labels\"])\n        tot_loss += loss.item() * batch[\"labels\"].size(0)\n        p = logits.argmax(-1).cpu().tolist()\n        g = batch[\"labels\"].cpu().tolist()\n        preds.extend(p)\n        gts.extend(g)\n        seqs.extend(batch[\"sequence_str\"])\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    return tot_loss / len(loader.dataset), swa, preds, gts, seqs\n\n\n# ------------- training --------------------\nMAX_EPOCHS, patience = 20, 4\nbest_val_swa, best_state, no_imp = -1.0, None, 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(\n            batch[\"shape_ids\"],\n            batch[\"color_ids\"],\n            batch[\"attention_mask\"],\n            batch[\"sym_feats\"],\n        )\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = epoch_loss / len(train_loader.dataset)\n    train_loss_eval, train_swa, _, _, _ = evaluate(train_loader)\n    val_loss, val_swa, _, _, _ = evaluate(dev_loader)\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train_swa\"].append(train_swa)\n    exp_rec[\"metrics\"][\"val_swa\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    print(f\"Epoch {epoch:02d}: val_loss = {val_loss:.4f}  val_SWA = {val_swa:.4f}\")\n\n    if val_swa > best_val_swa:\n        best_val_swa = val_swa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ------------- test ------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_preds, test_gts, _ = evaluate(test_loader)\nprint(f\"TEST loss = {test_loss:.4f}  SWA = {test_swa:.4f}\")\n\nexp_rec[\"predictions\"] = np.array(test_preds)\nexp_rec[\"ground_truth\"] = np.array(test_gts)\n\n# ------------- save all --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, time, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ------------- working dir -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------- device ----------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------- experiment store ------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_swa\": [], \"val_swa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\nexp_rec = experiment_data[\"SPR_BENCH\"]\n\n\n# ------------- helper: benchmark loader ----\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\n# ------------- metric helpers --------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ------------- data path -------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif not DATA_PATH.exists():\n    DATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # fallback for local tests\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ------------- build vocab sets ------------\ndef build_shape_color_sets(dataset):\n    shapes, colors = set(), set()\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok:\n                shapes.add(tok[0])\n                if len(tok) > 1:\n                    colors.add(tok[1])\n    colors.add(\"<none>\")  # placeholder for single-char tokens\n    shapes = {\"<pad>\": 0, **{ch: i + 1 for i, ch in enumerate(sorted(shapes))}}\n    colors = {\"<pad>\": 0, **{ch: i + 1 for i, ch in enumerate(sorted(colors))}}\n    return shapes, colors\n\n\nshape_map, color_map = build_shape_color_sets(spr[\"train\"])\nprint(f\"n_shapes={len(shape_map)}  n_colors={len(color_map)}\")\n\n# ------------- symbolic feature size -------\nn_shape_sym = len({k for k in shape_map if k not in (\"<pad>\")})\nn_color_sym = len({k for k in color_map if k not in (\"<pad>\")})\nsym_dim = n_shape_sym + n_color_sym\n\n\n# ------------- torch dataset ---------------\nclass SPRDataset(Dataset):\n    def __init__(self, split, shape_map, color_map):\n        self.seq = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.shape_map = shape_map\n        self.color_map = color_map\n        self.n_shape_sym = n_shape_sym\n        self.n_color_sym = n_color_sym\n\n    def encode_token(self, tok):\n        s_idx = self.shape_map.get(tok[0], self.shape_map[\"<pad>\"])\n        if len(tok) > 1:\n            c_idx = self.color_map.get(tok[1], self.color_map[\"<pad>\"])\n        else:\n            c_idx = self.color_map.get(\"<none>\", self.color_map[\"<pad>\"])\n        return s_idx, c_idx\n\n    def symbolic_vec(self, seq):\n        s_vec = np.zeros(self.n_shape_sym, dtype=np.float32)\n        c_vec = np.zeros(self.n_color_sym, dtype=np.float32)\n        for tok in seq.strip().split():\n            if tok:\n                if tok[0] in shape_map and tok[0] != \"<pad>\":\n                    s_vec[shape_map[tok[0]] - 1] += 1\n                if len(tok) > 1 and tok[1] in color_map and tok[1] != \"<pad>\":\n                    c_vec[color_map[tok[1]] - 1] += 1\n        total = max(len(seq.strip().split()), 1)\n        return np.concatenate([s_vec, c_vec]) / total\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        seq_str = self.seq[idx]\n        shape_ids, color_ids = zip(\n            *[self.encode_token(tok) for tok in seq_str.strip().split()]\n        )\n        return {\n            \"shape_ids\": torch.tensor(shape_ids, dtype=torch.long),\n            \"color_ids\": torch.tensor(color_ids, dtype=torch.long),\n            \"sym_feats\": torch.tensor(self.symbolic_vec(seq_str), dtype=torch.float32),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"sequence_str\": seq_str,\n        }\n\n\ntrain_ds = SPRDataset(spr[\"train\"], shape_map, color_map)\ndev_ds = SPRDataset(spr[\"dev\"], shape_map, color_map)\ntest_ds = SPRDataset(spr[\"test\"], shape_map, color_map)\n\n\n# ------------- collate ---------------------\ndef collate_fn(batch):\n    shape_list = [b[\"shape_ids\"] for b in batch]\n    color_list = [b[\"color_ids\"] for b in batch]\n    pad_shape = nn.utils.rnn.pad_sequence(shape_list, batch_first=True, padding_value=0)\n    pad_color = nn.utils.rnn.pad_sequence(color_list, batch_first=True, padding_value=0)\n    mask = pad_shape != 0  # B x T boolean\n    sym = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    seqs = [b[\"sequence_str\"] for b in batch]\n    return {\n        \"shape_ids\": pad_shape,\n        \"color_ids\": pad_color,\n        \"attention_mask\": mask,\n        \"sym_feats\": sym,\n        \"labels\": labels,\n        \"sequence_str\": seqs,\n    }\n\n\nBATCH = 256\ntrain_loader = DataLoader(\n    train_ds, batch_size=BATCH, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(dev_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(\n    test_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ------------- model -----------------------\nclass NeuralSymbolicTransformer(nn.Module):\n    def __init__(\n        self,\n        n_shape,\n        n_color,\n        sym_dim,\n        num_classes,\n        d_model=64,\n        nhead=4,\n        num_layers=2,\n        max_len=64,\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(max_len, d_model)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n        self.mlp = nn.Sequential(\n            nn.Linear(d_model + sym_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n\n    def forward(self, shape_ids, color_ids, attn_mask, sym_feats):\n        B, T = shape_ids.size()\n        pos = torch.arange(T, device=shape_ids.device).unsqueeze(0).expand(B, T)\n        tok_emb = (\n            self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        )\n        enc_out = self.encoder(tok_emb, src_key_padding_mask=~attn_mask)\n        seq_emb = (enc_out * attn_mask.unsqueeze(-1)).sum(1) / attn_mask.sum(\n            1, keepdim=True\n        ).clamp(min=1e-6)\n        x = torch.cat([seq_emb, sym_feats], dim=-1)\n        return self.mlp(x)\n\n\nnum_classes = int(max(train_ds.labels)) + 1\nmodel = NeuralSymbolicTransformer(\n    len(shape_map), len(color_map), sym_dim, num_classes\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ------------- evaluation ------------------\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss, preds, gts, seqs = 0.0, [], [], []\n    for batch in loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        logits = model(\n            batch[\"shape_ids\"],\n            batch[\"color_ids\"],\n            batch[\"attention_mask\"],\n            batch[\"sym_feats\"],\n        )\n        loss = criterion(logits, batch[\"labels\"])\n        tot_loss += loss.item() * batch[\"labels\"].size(0)\n        p = logits.argmax(-1).cpu().tolist()\n        g = batch[\"labels\"].cpu().tolist()\n        preds.extend(p)\n        gts.extend(g)\n        seqs.extend(batch[\"sequence_str\"])\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    return tot_loss / len(loader.dataset), swa, preds, gts, seqs\n\n\n# ------------- training --------------------\nMAX_EPOCHS, patience = 20, 4\nbest_val_swa, best_state, no_imp = -1.0, None, 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(\n            batch[\"shape_ids\"],\n            batch[\"color_ids\"],\n            batch[\"attention_mask\"],\n            batch[\"sym_feats\"],\n        )\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = epoch_loss / len(train_loader.dataset)\n    train_loss_eval, train_swa, _, _, _ = evaluate(train_loader)\n    val_loss, val_swa, _, _, _ = evaluate(dev_loader)\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train_swa\"].append(train_swa)\n    exp_rec[\"metrics\"][\"val_swa\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    print(f\"Epoch {epoch:02d}: val_loss = {val_loss:.4f}  val_SWA = {val_swa:.4f}\")\n\n    if val_swa > best_val_swa:\n        best_val_swa = val_swa\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ------------- test ------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_preds, test_gts, _ = evaluate(test_loader)\nprint(f\"TEST loss = {test_loss:.4f}  SWA = {test_swa:.4f}\")\n\nexp_rec[\"predictions\"] = np.array(test_preds)\nexp_rec[\"ground_truth\"] = np.array(test_gts)\n\n# ------------- save all --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 353149.53\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 161473.41\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 228649.68\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize: 18', '\\n', 'Epoch 01: train_loss=0.6021  val_loss=0.5456\nval_RCWA=0.7240', '\\n', 'Epoch 02: train_loss=0.5306  val_loss=0.5228\nval_RCWA=0.7240', '\\n', 'Epoch 03: train_loss=0.5208  val_loss=0.5221\nval_RCWA=0.7648', '\\n', 'Epoch 04: train_loss=0.5204  val_loss=0.5215\nval_RCWA=0.7447', '\\n', 'Epoch 05: train_loss=0.5198  val_loss=0.5210\nval_RCWA=0.7273', '\\n', 'Epoch 06: train_loss=0.5198  val_loss=0.5217\nval_RCWA=0.7576', '\\n', 'Epoch 07: train_loss=0.5198  val_loss=0.5222\nval_RCWA=0.7563', '\\n', 'No improvement for 4 epochs, early stopping.', '\\n',\n'TEST  loss=0.7260  RCWA=0.5965  SWA=0.5944  CWA=0.6221', '\\n', 'Execution time:\n7 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 314029.53\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 153691.55\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 444227.16\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize:', ' ', '18', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: validation_loss = 0.3232\nval_SWA=0.8859', '\\n', 'Epoch 2: validation_loss = 0.2546  val_SWA=0.9187',\n'\\n', 'Epoch 3: validation_loss = 0.2266  val_SWA=0.9289', '\\n', 'Epoch 4:\nvalidation_loss = 0.1966  val_SWA=0.9420', '\\n', 'Epoch 5: validation_loss =\n0.1968  val_SWA=0.9390', '\\n', 'Epoch 6: validation_loss = 0.1772\nval_SWA=0.9441', '\\n', 'Epoch 7: validation_loss = 0.1754  val_SWA=0.9438',\n'\\n', 'Epoch 8: validation_loss = 0.1730  val_SWA=0.9442', '\\n', 'Epoch 9:\nvalidation_loss = 0.1716  val_SWA=0.9444', '\\n', 'Epoch 10: validation_loss =\n0.1745  val_SWA=0.9442', '\\n', 'Epoch 11: validation_loss = 0.1754\nval_SWA=0.9444', '\\n', 'Epoch 12: validation_loss = 0.1783  val_SWA=0.9447',\n'\\n', 'Epoch 13: validation_loss = 0.1866  val_SWA=0.9445', '\\n', 'Epoch 14:\nvalidation_loss = 0.1740  val_SWA=0.9437', '\\n', 'Epoch 15: validation_loss =\n0.1727  val_SWA=0.9439', '\\n', 'Early stopping.', '\\n', 'TEST  loss=1.4559\nSWA=0.6500', '\\n', 'Execution time: 23 seconds seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 488895.05\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 187225.65\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 354632.03\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Token\nvocab: 18, Shapes: 4, Colors: 4', '\\n', 'Epoch 01: train_loss=0.4299\nval_loss=0.2561 val_SWA=0.9184', '\\n', 'Epoch 02: train_loss=0.2161\nval_loss=0.1970 val_SWA=0.9404', '\\n', 'Epoch 03: train_loss=0.1871\nval_loss=0.1814 val_SWA=0.9433', '\\n', 'Epoch 04: train_loss=0.1782\nval_loss=0.1758 val_SWA=0.9437', '\\n', 'Epoch 05: train_loss=0.1729\nval_loss=0.1741 val_SWA=0.9438', '\\n', 'Epoch 06: train_loss=0.1707\nval_loss=0.1701 val_SWA=0.9447', '\\n', 'Epoch 07: train_loss=0.1701\nval_loss=0.1686 val_SWA=0.9447', '\\n', 'Epoch 08: train_loss=0.1672\nval_loss=0.1681 val_SWA=0.9447', '\\n', 'Epoch 09: train_loss=0.1661\nval_loss=0.1684 val_SWA=0.9441', '\\n', 'Early stopping (no val_SWA improvement\nfor 3 epochs)', '\\n', 'TEST: loss=1.4540  SWA=0.6500', '\\n', 'Execution time: 12\nseconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 279145.72\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 224337.52\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 283949.55\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n',\n'Vocab: 18  shapes:4 colors:4', '\\n', 'Epoch 01: val_loss=0.2936\nval_SWA=0.8933', '\\n', 'Epoch 02: val_loss=0.2148  val_SWA=0.9262', '\\n', 'Epoch\n03: val_loss=0.1911  val_SWA=0.9392', '\\n', 'Epoch 04: val_loss=0.1821\nval_SWA=0.9431', '\\n', 'Epoch 05: val_loss=0.1781  val_SWA=0.9435', '\\n', 'Epoch\n06: val_loss=0.1738  val_SWA=0.9433', '\\n', 'Epoch 07: val_loss=0.1723\nval_SWA=0.9440', '\\n', 'Epoch 08: val_loss=0.1712  val_SWA=0.9443', '\\n', 'Epoch\n09: val_loss=0.1707  val_SWA=0.9447', '\\n', 'Epoch 10: val_loss=0.1684\nval_SWA=0.9437', '\\n', 'Epoch 11: val_loss=0.1671  val_SWA=0.9447', '\\n', 'Epoch\n12: val_loss=0.1669  val_SWA=0.9447', '\\n', 'Epoch 13: val_loss=0.1678\nval_SWA=0.9443', '\\n', 'Epoch 14: val_loss=0.1660  val_SWA=0.9447', '\\n', 'Early\nstopping after 14 epochs.', '\\n', 'TEST   loss=1.6784  SWA=0.6499', '\\n',\n'Execution time: 34 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 333458.21\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 330228.95\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 848877.56\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize:', ' ', '18', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: validation_loss = 0.3627\n| val_SWA = 0.8277', '\\n', 'Epoch 2: validation_loss = 0.2167 | val_SWA =\n0.9297', '\\n', 'Epoch 3: validation_loss = 0.1951 | val_SWA = 0.9352', '\\n',\n'Epoch 4: validation_loss = 0.1837 | val_SWA = 0.9405', '\\n', 'Epoch 5:\nvalidation_loss = 0.1755 | val_SWA = 0.9431', '\\n', 'Epoch 6: validation_loss =\n0.1707 | val_SWA = 0.9442', '\\n', 'Epoch 7: validation_loss = 0.1743 | val_SWA =\n0.9447', '\\n', 'Epoch 8: validation_loss = 0.1706 | val_SWA = 0.9447', '\\n',\n'Epoch 9: validation_loss = 0.1772 | val_SWA = 0.9445', '\\n', 'Epoch 10:\nvalidation_loss = 0.1716 | val_SWA = 0.9447', '\\n', 'Early stopping at epoch\n10', '\\n', 'TEST: loss=1.3505  SWA=0.6494', '\\n', 'Execution time: 20 seconds\nseconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Vocab size: 19', '\\n', 'Symbolic feature dim: 10', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: validation_loss = 0.1661\n| val_SWA = 0.9534', '\\n', 'Epoch 2: validation_loss = 0.1259 | val_SWA =\n0.9646', '\\n', 'Epoch 3: validation_loss = 0.0731 | val_SWA = 0.9780', '\\n',\n'Epoch 4: validation_loss = 0.0451 | val_SWA = 0.9908', '\\n', 'Epoch 5:\nvalidation_loss = 0.0431 | val_SWA = 0.9921', '\\n', 'Epoch 6: validation_loss =\n0.0444 | val_SWA = 0.9902', '\\n', 'Epoch 7: validation_loss = 0.0401 | val_SWA =\n0.9915', '\\n', 'Epoch 8: validation_loss = 0.0360 | val_SWA = 0.9920', '\\n',\n'Epoch 9: validation_loss = 0.0240 | val_SWA = 0.9940', '\\n', 'Epoch 10:\nvalidation_loss = 0.0279 | val_SWA = 0.9928', '\\n', 'Epoch 11: validation_loss =\n0.0203 | val_SWA = 0.9957', '\\n', 'Epoch 12: validation_loss = 0.0226 | val_SWA\n= 0.9949', '\\n', 'Epoch 13: validation_loss = 0.0239 | val_SWA = 0.9944', '\\n',\n'Epoch 14: validation_loss = 0.0184 | val_SWA = 0.9955', '\\n', 'Epoch 15:\nvalidation_loss = 0.0171 | val_SWA = 0.9960', '\\n', 'Epoch 16: validation_loss =\n0.0154 | val_SWA = 0.9963', '\\n', 'Epoch 17: validation_loss = 0.0177 | val_SWA\n= 0.9958', '\\n', 'Epoch 18: validation_loss = 0.0162 | val_SWA = 0.9963', '\\n',\n'Epoch 19: validation_loss = 0.0201 | val_SWA = 0.9956', '\\n', 'Epoch 20:\nvalidation_loss = 0.0160 | val_SWA = 0.9960', '\\n', 'Early stopping.', '\\n',\n'TEST loss=2.2486 | TEST SWA=0.6541', '\\n', 'Execution time: a minute seconds\n(time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'vocab=18 shapes=4 colors=4', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: validation_loss =\n0.1772, val_SWA = 0.9422', '\\n', 'Epoch 02: validation_loss = 0.1336, val_SWA =\n0.9491', '\\n', 'Epoch 03: validation_loss = 0.1065, val_SWA = 0.9567', '\\n',\n'Epoch 04: validation_loss = 0.0723, val_SWA = 0.9732', '\\n', 'Epoch 05:\nvalidation_loss = 0.0737, val_SWA = 0.9715', '\\n', 'Epoch 06: validation_loss =\n0.0642, val_SWA = 0.9733', '\\n', 'Epoch 07: validation_loss = 0.0648, val_SWA =\n0.9745', '\\n', 'Epoch 08: validation_loss = 0.0648, val_SWA = 0.9738', '\\n',\n'Epoch 09: validation_loss = 0.0467, val_SWA = 0.9795', '\\n', 'Epoch 10:\nvalidation_loss = 0.0410, val_SWA = 0.9808', '\\n', 'Epoch 11: validation_loss =\n0.0555, val_SWA = 0.9752', '\\n', 'Epoch 12: validation_loss = 0.0430, val_SWA =\n0.9795', '\\n', 'Epoch 13: validation_loss = 0.0471, val_SWA = 0.9755', '\\n',\n'Epoch 14: validation_loss = 0.0350, val_SWA = 0.9858', '\\n', 'Epoch 15:\nvalidation_loss = 0.0354, val_SWA = 0.9828', '\\n', 'Epoch 16: validation_loss =\n0.0282, val_SWA = 0.9882', '\\n', 'Epoch 17: validation_loss = 0.0191, val_SWA =\n0.9913', '\\n', 'Epoch 18: validation_loss = 0.0277, val_SWA = 0.9881', '\\n',\n'Epoch 19: validation_loss = 0.0179, val_SWA = 0.9952', '\\n', 'Epoch 20:\nvalidation_loss = 0.0217, val_SWA = 0.9905', '\\n', 'Epoch 21: validation_loss =\n0.0201, val_SWA = 0.9928', '\\n', 'Epoch 22: validation_loss = 0.0233, val_SWA =\n0.9892', '\\n', 'Epoch 23: validation_loss = 0.0151, val_SWA = 0.9948', '\\n',\n'Epoch 24: validation_loss = 0.0138, val_SWA = 0.9960', '\\n', 'Epoch 25:\nvalidation_loss = 0.0190, val_SWA = 0.9924', '\\n', 'TEST: loss=3.1689\nSWA=0.6509', '\\n', 'Execution time: a minute seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', '/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: validation_loss = 0.1770\nval_SWA = 0.9577', '\\n', 'Epoch 02: validation_loss = 0.1367  val_SWA = 0.9679',\n'\\n', 'Epoch 03: validation_loss = 0.0588  val_SWA = 0.9847', '\\n', 'Epoch 04:\nvalidation_loss = 0.0449  val_SWA = 0.9906', '\\n', 'Epoch 05: validation_loss =\n0.0195  val_SWA = 0.9961', '\\n', 'Epoch 06: validation_loss = 0.0224  val_SWA =\n0.9944', '\\n', 'Epoch 07: validation_loss = 0.0082  val_SWA = 0.9974', '\\n',\n'Epoch 08: validation_loss = 0.0130  val_SWA = 0.9965', '\\n', 'Epoch 09:\nvalidation_loss = 0.0106  val_SWA = 0.9969', '\\n', 'Epoch 10: validation_loss =\n0.0045  val_SWA = 0.9991', '\\n', 'Epoch 11: validation_loss = 0.0042  val_SWA =\n0.9991', '\\n', 'Epoch 12: validation_loss = 0.0049  val_SWA = 0.9991', '\\n',\n'Epoch 13: validation_loss = 0.0057  val_SWA = 0.9986', '\\n', 'Epoch 14:\nvalidation_loss = 0.0043  val_SWA = 0.9998', '\\n', 'Epoch 15: validation_loss =\n0.0074  val_SWA = 0.9981', '\\n', 'Epoch 16: validation_loss = 0.0079  val_SWA =\n0.9982', '\\n', 'Epoch 17: validation_loss = 0.0044  val_SWA = 0.9988', '\\n',\n'Epoch 18: validation_loss = 0.0029  val_SWA = 0.9993', '\\n', 'Epoch 19:\nvalidation_loss = 0.0017  val_SWA = 0.9998', '\\n', 'Epoch 20: validation_loss =\n0.0065  val_SWA = 0.9986', '\\n', 'Early stopping at epoch 20', '\\n', 'TEST\nloss=4.4515  SWA=0.6518', '\\n', 'Execution time: a minute seconds (time limit is\n30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'n_shapes=5  n_colors=6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: val_loss = 0.1261\nval_SWA = 0.9657', '\\n', 'Epoch 02: val_loss = 0.0549  val_SWA = 0.9804', '\\n',\n'Epoch 03: val_loss = 0.0341  val_SWA = 0.9910', '\\n', 'Epoch 04: val_loss =\n0.0198  val_SWA = 0.9937', '\\n', 'Epoch 05: val_loss = 0.0230  val_SWA =\n0.9944', '\\n', 'Epoch 06: val_loss = 0.0137  val_SWA = 0.9956', '\\n', 'Epoch 07:\nval_loss = 0.0095  val_SWA = 0.9974', '\\n', 'Epoch 08: val_loss = 0.0494\nval_SWA = 0.9808', '\\n', 'Epoch 09: val_loss = 0.0038  val_SWA = 0.9991', '\\n',\n'Epoch 10: val_loss = 0.0032  val_SWA = 0.9991', '\\n', 'Epoch 11: val_loss =\n0.0015  val_SWA = 0.9993', '\\n', 'Epoch 12: val_loss = 0.0051  val_SWA =\n0.9979', '\\n', 'Epoch 13: val_loss = 0.0003  val_SWA = 1.0000', '\\n', 'Epoch 14:\nval_loss = 0.0027  val_SWA = 0.9985', '\\n', 'Epoch 15: val_loss = 0.0029\nval_SWA = 0.9988', '\\n', 'Epoch 16: val_loss = 0.0020  val_SWA = 0.9995', '\\n',\n'Epoch 17: val_loss = 0.0019  val_SWA = 0.9988', '\\n', 'Early stopping.', '\\n',\n'TEST loss = 4.4368  SWA = 0.6520', '\\n', 'Execution time: 55 seconds seconds\n(time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'n_shapes=5  n_colors=6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: val_loss = 0.1256\nval_SWA = 0.9661', '\\n', 'Epoch 02: val_loss = 0.0846  val_SWA = 0.9817', '\\n',\n'Epoch 03: val_loss = 0.0618  val_SWA = 0.9807', '\\n', 'Epoch 04: val_loss =\n0.0266  val_SWA = 0.9921', '\\n', 'Epoch 05: val_loss = 0.0101  val_SWA =\n0.9976', '\\n', 'Epoch 06: val_loss = 0.0074  val_SWA = 0.9983', '\\n', 'Epoch 07:\nval_loss = 0.0065  val_SWA = 0.9985', '\\n', 'Epoch 08: val_loss = 0.0064\nval_SWA = 0.9981', '\\n', 'Epoch 09: val_loss = 0.0079  val_SWA = 0.9980', '\\n',\n'Epoch 10: val_loss = 0.0047  val_SWA = 0.9985', '\\n', 'Epoch 11: val_loss =\n0.0030  val_SWA = 0.9993', '\\n', 'Epoch 12: val_loss = 0.0046  val_SWA =\n0.9984', '\\n', 'Epoch 13: val_loss = 0.0026  val_SWA = 0.9991', '\\n', 'Epoch 14:\nval_loss = 0.0037  val_SWA = 0.9990', '\\n', 'Epoch 15: val_loss = 0.0018\nval_SWA = 0.9991', '\\n', 'Early stopping.', '\\n', 'TEST loss = 3.8347  SWA =\n0.6528', '\\n', 'Execution time: 51 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'n_shapes=5  n_colors=6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: val_loss = 0.1154\nval_SWA = 0.9693', '\\n', 'Epoch 02: val_loss = 0.0610  val_SWA = 0.9848', '\\n',\n'Epoch 03: val_loss = 0.0280  val_SWA = 0.9929', '\\n', 'Epoch 04: val_loss =\n0.0186  val_SWA = 0.9946', '\\n', 'Epoch 05: val_loss = 0.0148  val_SWA =\n0.9955', '\\n', 'Epoch 06: val_loss = 0.0220  val_SWA = 0.9952', '\\n', 'Epoch 07:\nval_loss = 0.0086  val_SWA = 0.9982', '\\n', 'Epoch 08: val_loss = 0.0086\nval_SWA = 0.9981', '\\n', 'Epoch 09: val_loss = 0.0031  val_SWA = 0.9995', '\\n',\n'Epoch 10: val_loss = 0.0060  val_SWA = 0.9988', '\\n', 'Epoch 11: val_loss =\n0.0055  val_SWA = 0.9984', '\\n', 'Epoch 12: val_loss = 0.0078  val_SWA =\n0.9980', '\\n', 'Epoch 13: val_loss = 0.0046  val_SWA = 0.9984', '\\n', 'Early\nstopping.', '\\n', 'TEST loss = 4.1082  SWA = 0.6525', '\\n', 'Execution time: 44\nseconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'n_shapes=5  n_colors=6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: val_loss = 0.1377\nval_SWA = 0.9598', '\\n', 'Epoch 02: val_loss = 0.0580  val_SWA = 0.9847', '\\n',\n'Epoch 03: val_loss = 0.0394  val_SWA = 0.9901', '\\n', 'Epoch 04: val_loss =\n0.0334  val_SWA = 0.9909', '\\n', 'Epoch 05: val_loss = 0.0211  val_SWA =\n0.9930', '\\n', 'Epoch 06: val_loss = 0.0208  val_SWA = 0.9933', '\\n', 'Epoch 07:\nval_loss = 0.0050  val_SWA = 0.9992', '\\n', 'Epoch 08: val_loss = 0.0051\nval_SWA = 0.9982', '\\n', 'Epoch 09: val_loss = 0.0038  val_SWA = 0.9986', '\\n',\n'Epoch 10: val_loss = 0.0026  val_SWA = 0.9988', '\\n', 'Epoch 11: val_loss =\n0.0018  val_SWA = 0.9994', '\\n', 'Epoch 12: val_loss = 0.0047  val_SWA =\n0.9988', '\\n', 'Epoch 13: val_loss = 0.0042  val_SWA = 0.9989', '\\n', 'Epoch 14:\nval_loss = 0.0025  val_SWA = 0.9994', '\\n', 'Epoch 15: val_loss = 0.0016\nval_SWA = 0.9992', '\\n', 'Early stopping.', '\\n', 'TEST loss = 4.4325  SWA =\n0.6525', '\\n', 'Execution time: 49 seconds seconds (time limit is 30 minutes).']", ""], "analysis": ["", "", "The code executed successfully without any errors. The training loop ran\nsmoothly, and the model achieved a validation Shape-Weighted Accuracy (SWA) of\n94.47% before early stopping. However, the test SWA was significantly lower at\n65.00%, indicating a potential generalization issue. Future experiments could\nfocus on improving the model's ability to generalize to unseen data, possibly\nthrough regularization techniques, data augmentation, or architecture\nimprovements.", "", "", "The model training and validation on the development set show excellent\nperformance, achieving a high Shape-Weighted Accuracy (SWA) of 0.9963 on the\nvalidation set. However, the test set evaluation results in a significantly\nlower SWA of 0.6541, indicating a severe overfitting problem. The model\ngeneralizes poorly to unseen data, which is critical for zero-shot learning in\nSynthetic PolyRule Reasoning (SPR). To address this, consider implementing\nregularization techniques such as dropout or weight decay, using data\naugmentation, or experimenting with a simpler model architecture to reduce\noverfitting. Additionally, hyperparameter tuning for learning rate or early\nstopping criteria may also help improve generalization.", "", "The training and validation processes show promising results with high Shape-\nWeighted Accuracy (SWA). However, the test set evaluation reveals a significant\ndrop in SWA (0.6518), indicating potential overfitting. The model performs well\non the training and validation datasets but fails to generalize to unseen test\ndata. To address this, consider implementing regularization techniques such as\ndropout or weight decay, early stopping based on test set performance, or\naugmenting the dataset to improve generalization. Additionally, the test loss\n(4.4515) is unusually high and needs further investigation to ensure there are\nno data preprocessing issues or model design flaws.", "", "", "", "", ""], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "Training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5198, "best_value": 0.5198}]}, {"metric_name": "Validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.521, "best_value": 0.521}]}, {"metric_name": "Training RCWA", "lower_is_better": false, "description": "The RCWA metric during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7518, "best_value": 0.7518}]}, {"metric_name": "Validation RCWA", "lower_is_better": false, "description": "The RCWA metric during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7648, "best_value": 0.7648}]}, {"metric_name": "Test accuracy", "lower_is_better": false, "description": "The accuracy metric on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6204, "best_value": 0.6204}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The final or best loss value achieved on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1716961413383484, "best_value": 0.1716961413383484}]}, {"metric_name": "training SWA", "lower_is_better": false, "description": "The final or best Stochastic Weight Averaging value achieved on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9443855855332859, "best_value": 0.9443855855332859}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The final or best loss value achieved on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.17271616201996803, "best_value": 0.17271616201996803}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "The final or best Stochastic Weight Averaging value achieved on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9446575979537263, "best_value": 0.9446575979537263}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "The accuracy achieved on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6951, "best_value": 0.6951}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is fitting the training data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.166078, "best_value": 0.166078}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, used to evaluate the model's performance on unseen data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.168127, "best_value": 0.168127}]}, {"metric_name": "training shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy during training, weighted by the importance of different shapes in the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.944487, "best_value": 0.944487}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy during validation, weighted by the importance of different shapes in the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.944658, "best_value": 0.944658}]}]}, {"metric_names": [{"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy weighted by the shape of the data.", "data": [{"dataset_name": "training", "final_value": 0.9446, "best_value": 0.9446}, {"dataset_name": "validation", "final_value": 0.9447, "best_value": 0.9447}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Measures the error in prediction.", "data": [{"dataset_name": "training", "final_value": 0.1642, "best_value": 0.1642}, {"dataset_name": "validation", "final_value": 0.166, "best_value": 0.166}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1738, "best_value": 0.1738}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1706, "best_value": 0.1706}]}, {"metric_name": "training swa", "lower_is_better": false, "description": "Measures the stochastic weight averaging accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9446, "best_value": 0.9446}]}, {"metric_name": "validation swa", "lower_is_better": false, "description": "Measures the stochastic weight averaging accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9447, "best_value": 0.9447}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.017313, "best_value": 0.017313}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.016038, "best_value": 0.016038}]}, {"metric_name": "training shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.997213, "best_value": 0.997213}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.996047, "best_value": 0.996047}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "The accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7015, "best_value": 0.7015}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is performing.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0691, "best_value": 0.0691}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, indicating how well the model is generalizing.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0138, "best_value": 0.0138}]}, {"metric_name": "train shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy during training, weighted by shape.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9971, "best_value": 0.9971}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy during validation, weighted by shape.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.996, "best_value": 0.996}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0023, "best_value": 0.0023}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0065, "best_value": 0.0065}]}, {"metric_name": "training shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9988, "best_value": 0.9988}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9986, "best_value": 0.9998}]}, {"metric_name": "test classification accuracy", "lower_is_better": false, "description": "The accuracy of classification on the test set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6995, "best_value": 0.6995}]}]}, {"metric_names": [{"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of the model, weighted by the shapes in the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Measures the error of the model. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0003, "best_value": 0.0003}]}]}, {"metric_names": [{"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by shape, used to evaluate model performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9993, "best_value": 1.0}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss metric indicating model error.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0018, "best_value": 0.0018}]}]}, {"metric_names": [{"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions weighted by shape.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9995, "best_value": 0.9995}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Measures the error between predicted and actual values.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0031, "best_value": 0.0031}]}]}, {"metric_names": [{"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by shape.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9994, "best_value": 0.9999}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss metric indicating the error in predictions.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0016, "best_value": 0.0016}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, false, false, false, false, true, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_1191d2f2e9884009aa1dda0d5ea5ad3c_proc_2676156/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_1191d2f2e9884009aa1dda0d5ea5ad3c_proc_2676156/SPR_BENCH_rcwa_curves.png", "../../logs/0-run/experiment_results/experiment_1191d2f2e9884009aa1dda0d5ea5ad3c_proc_2676156/SPR_BENCH_test_accuracy.png"], ["../../logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_swa_curves.png", "../../logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_test_accuracy.png", "../../logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_e5752af97c7d4c91a07720339ec93594_proc_2678327/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_e5752af97c7d4c91a07720339ec93594_proc_2678327/SPR_BENCH_swa_curves.png", "../../logs/0-run/experiment_results/experiment_e5752af97c7d4c91a07720339ec93594_proc_2678327/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_0fed72df1e084fb5a19ad0492a0c3cb1_proc_2678329/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_0fed72df1e084fb5a19ad0492a0c3cb1_proc_2678329/SPR_BENCH_swa_curves.png", "../../logs/0-run/experiment_results/experiment_0fed72df1e084fb5a19ad0492a0c3cb1_proc_2678329/SPR_BENCH_test_accuracy.png"], ["../../logs/0-run/experiment_results/experiment_ed1eb1544fbc4d0185df01ab2da98020_proc_2678330/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_ed1eb1544fbc4d0185df01ab2da98020_proc_2678330/SPR_BENCH_swa_curves.png", "../../logs/0-run/experiment_results/experiment_ed1eb1544fbc4d0185df01ab2da98020_proc_2678330/SPR_BENCH_test_accuracy.png"], [], ["../../logs/0-run/experiment_results/experiment_8cbb9d8e398d4085bd30059326355efe_proc_2678327/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8cbb9d8e398d4085bd30059326355efe_proc_2678327/SPR_BENCH_swa_curves.png", "../../logs/0-run/experiment_results/experiment_8cbb9d8e398d4085bd30059326355efe_proc_2678327/SPR_BENCH_test_metrics.png"], [], ["../../logs/0-run/experiment_results/experiment_107634f1a9f24333ab304c876afd3618_proc_2678329/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_107634f1a9f24333ab304c876afd3618_proc_2678329/SPR_BENCH_swa_curves.png", "../../logs/0-run/experiment_results/experiment_107634f1a9f24333ab304c876afd3618_proc_2678329/SPR_BENCH_test_accuracy.png"], ["../../logs/0-run/experiment_results/experiment_546edabd52824f229314bd6b7b3be332_proc_2678330/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_546edabd52824f229314bd6b7b3be332_proc_2678330/SPR_BENCH_swa_curves.png", "../../logs/0-run/experiment_results/experiment_546edabd52824f229314bd6b7b3be332_proc_2678330/SPR_BENCH_test_accuracy.png"], ["../../logs/0-run/experiment_results/experiment_36155d2e83cb4768991eb1f7e94bbfb6_proc_2678329/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_36155d2e83cb4768991eb1f7e94bbfb6_proc_2678329/SPR_BENCH_swa_curves.png", "../../logs/0-run/experiment_results/experiment_36155d2e83cb4768991eb1f7e94bbfb6_proc_2678329/SPR_BENCH_test_accuracy.png"], ["../../logs/0-run/experiment_results/experiment_1ced583751a54325a68a1d07df49decf_proc_2678328/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_1ced583751a54325a68a1d07df49decf_proc_2678328/SPR_BENCH_swa_curves.png", "../../logs/0-run/experiment_results/experiment_1ced583751a54325a68a1d07df49decf_proc_2678328/SPR_BENCH_test_accuracy.png"], ["../../logs/0-run/experiment_results/seed_aggregation_c893a3e8ba4b40a9bafb9d34a2eeb33d/SPR_BENCH_aggregated_loss_curves.png", "../../logs/0-run/experiment_results/seed_aggregation_c893a3e8ba4b40a9bafb9d34a2eeb33d/SPR_BENCH_aggregated_swa_curves.png", "../../logs/0-run/experiment_results/seed_aggregation_c893a3e8ba4b40a9bafb9d34a2eeb33d/SPR_BENCH_aggregated_test_accuracy.png"]], "plot_paths": [["experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1191d2f2e9884009aa1dda0d5ea5ad3c_proc_2676156/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1191d2f2e9884009aa1dda0d5ea5ad3c_proc_2676156/SPR_BENCH_rcwa_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1191d2f2e9884009aa1dda0d5ea5ad3c_proc_2676156/SPR_BENCH_test_accuracy.png"], ["experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_swa_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_test_accuracy.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e5752af97c7d4c91a07720339ec93594_proc_2678327/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e5752af97c7d4c91a07720339ec93594_proc_2678327/SPR_BENCH_swa_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e5752af97c7d4c91a07720339ec93594_proc_2678327/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0fed72df1e084fb5a19ad0492a0c3cb1_proc_2678329/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0fed72df1e084fb5a19ad0492a0c3cb1_proc_2678329/SPR_BENCH_swa_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0fed72df1e084fb5a19ad0492a0c3cb1_proc_2678329/SPR_BENCH_test_accuracy.png"], ["experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ed1eb1544fbc4d0185df01ab2da98020_proc_2678330/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ed1eb1544fbc4d0185df01ab2da98020_proc_2678330/SPR_BENCH_swa_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ed1eb1544fbc4d0185df01ab2da98020_proc_2678330/SPR_BENCH_test_accuracy.png"], [], ["experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_8cbb9d8e398d4085bd30059326355efe_proc_2678327/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_8cbb9d8e398d4085bd30059326355efe_proc_2678327/SPR_BENCH_swa_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_8cbb9d8e398d4085bd30059326355efe_proc_2678327/SPR_BENCH_test_metrics.png"], [], ["experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_107634f1a9f24333ab304c876afd3618_proc_2678329/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_107634f1a9f24333ab304c876afd3618_proc_2678329/SPR_BENCH_swa_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_107634f1a9f24333ab304c876afd3618_proc_2678329/SPR_BENCH_test_accuracy.png"], ["experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_546edabd52824f229314bd6b7b3be332_proc_2678330/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_546edabd52824f229314bd6b7b3be332_proc_2678330/SPR_BENCH_swa_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_546edabd52824f229314bd6b7b3be332_proc_2678330/SPR_BENCH_test_accuracy.png"], ["experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_36155d2e83cb4768991eb1f7e94bbfb6_proc_2678329/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_36155d2e83cb4768991eb1f7e94bbfb6_proc_2678329/SPR_BENCH_swa_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_36155d2e83cb4768991eb1f7e94bbfb6_proc_2678329/SPR_BENCH_test_accuracy.png"], ["experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1ced583751a54325a68a1d07df49decf_proc_2678328/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1ced583751a54325a68a1d07df49decf_proc_2678328/SPR_BENCH_swa_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1ced583751a54325a68a1d07df49decf_proc_2678328/SPR_BENCH_test_accuracy.png"], ["experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_c893a3e8ba4b40a9bafb9d34a2eeb33d/SPR_BENCH_aggregated_loss_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_c893a3e8ba4b40a9bafb9d34a2eeb33d/SPR_BENCH_aggregated_swa_curves.png", "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_c893a3e8ba4b40a9bafb9d34a2eeb33d/SPR_BENCH_aggregated_test_accuracy.png"]], "plot_analyses": [[{"analysis": "The plot shows the training and validation cross-entropy loss over 7 epochs. The training loss decreases rapidly in the first three epochs and then stabilizes, indicating that the model is learning effectively during this initial phase. Validation loss follows a similar trend, suggesting that the model generalizes well to unseen data without overfitting. However, the slight increase in validation loss after epoch 5 could indicate the onset of overfitting, which might require further regularization or early stopping.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1191d2f2e9884009aa1dda0d5ea5ad3c_proc_2676156/SPR_BENCH_loss_curves.png"}, {"analysis": "The plot depicts the Relative Color-Weighted Accuracy (RCWA) for both training and validation sets over 7 epochs. Both metrics improve significantly in the first three epochs, peak around epoch 3, and then decline, suggesting potential overfitting or instability in the model's ability to generalize. The recovery in RCWA after epoch 5 indicates some stabilization, but the gap between training and validation RCWA at the peak and the drop-off afterward warrants further investigation, such as tuning hyperparameters or analyzing the model's sensitivity to different data distributions.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1191d2f2e9884009aa1dda0d5ea5ad3c_proc_2676156/SPR_BENCH_rcwa_curves.png"}, {"analysis": "The bar chart shows the test accuracy for the model, which is approximately 0.6. While this indicates moderate performance, it is unclear how this compares to baseline or state-of-the-art results. Further improvements may be necessary, potentially through better hyperparameter tuning, enhanced data preprocessing, or modifications to the training strategy.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1191d2f2e9884009aa1dda0d5ea5ad3c_proc_2676156/SPR_BENCH_test_accuracy.png"}], [{"analysis": "This plot shows the training and validation cross-entropy loss over epochs. Both losses decrease significantly during the early epochs, indicating effective learning. The validation loss closely tracks the training loss, suggesting the model generalizes well and does not overfit.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot compares Shape-Weighted Accuracy (SWA) for training and validation over epochs. Both metrics improve rapidly in the early epochs and stabilize around 94%, demonstrating the model's strong performance and consistent generalization to unseen validation data.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_swa_curves.png"}, {"analysis": "This plot displays the test accuracy, which is approximately 65%. While this is a reasonable result, it indicates that there is room for improvement in generalizing to unseen test data, especially compared to the higher SWA during training and validation.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_test_accuracy.png"}, {"analysis": "The confusion matrix provides insights into the model's classification performance. It shows a slight imbalance in correct predictions across classes, suggesting potential improvements in handling certain rule-based sequences. The color intensity highlights areas where the model performs better or worse.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_9c19939fe4bf40b5a9484bb09a46fb10_proc_2678328/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "This plot shows that the training and validation losses decrease consistently over the epochs, with both converging to a similar value. This indicates that the model is learning well and there is no significant overfitting, as the validation loss does not diverge from the training loss. The rapid decrease in loss during the first few epochs suggests that the model quickly captures the main patterns in the data.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e5752af97c7d4c91a07720339ec93594_proc_2678327/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot demonstrates that the Shape-Weighted Accuracy (SWA) for both training and validation increases rapidly in the initial epochs and stabilizes at a high value. The small gap between training and validation SWA indicates good generalization. The model achieves consistent performance across both datasets, suggesting effective learning of the shape-related features and rules.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e5752af97c7d4c91a07720339ec93594_proc_2678327/SPR_BENCH_swa_curves.png"}, {"analysis": "The confusion matrix indicates that the model performs well on the test set, with a high number of correct predictions (dark diagonal cells). However, there are some misclassifications, as seen in the off-diagonal cells. The intensity of the off-diagonal cells is relatively low compared to the diagonal, suggesting that the model has strong predictive performance but could still benefit from further fine-tuning to reduce errors.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e5752af97c7d4c91a07720339ec93594_proc_2678327/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The plot shows the cross-entropy loss for both training and validation over 15 epochs. The training and validation losses decrease steadily and converge after around 10 epochs, indicating that the model is learning effectively without significant overfitting. The small gap between the training and validation losses further supports the model's generalization capability.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0fed72df1e084fb5a19ad0492a0c3cb1_proc_2678329/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the Shape-Weighted Accuracy (SWA) for both training and validation over 15 epochs. Both training and validation SWA improve rapidly in the initial epochs and stabilize around 0.94 after epoch 5. The close alignment of the training and validation SWA suggests strong generalization and minimal overfitting, indicating that the model is effectively learning and applying the rules in the SPR_BENCH benchmark.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0fed72df1e084fb5a19ad0492a0c3cb1_proc_2678329/SPR_BENCH_swa_curves.png"}, {"analysis": "The bar plot indicates the test accuracy of the model, which appears to be approximately 0.65. While this suggests the model has some ability to generalize to unseen rules, the performance is moderate and leaves room for improvement. This could be due to the complexity of zero-shot reasoning tasks or limitations in the model's architecture.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0fed72df1e084fb5a19ad0492a0c3cb1_proc_2678329/SPR_BENCH_test_accuracy.png"}], [{"analysis": "The plot shows the training and validation loss over 10 epochs. Both losses decrease steadily, with the validation loss closely following the training loss, indicating that the model is learning effectively without significant overfitting. The convergence of the two curves towards the end suggests that the model generalizes well to unseen data.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ed1eb1544fbc4d0185df01ab2da98020_proc_2678330/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the Shape-Weighted Accuracy (SWA) for both training and validation sets over 10 epochs. The SWA improves rapidly in the first few epochs and then plateaus, reaching a high value (approximately 0.94). The close alignment of the training and validation SWA curves indicates that the model performs consistently across both datasets, demonstrating strong generalization capabilities.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ed1eb1544fbc4d0185df01ab2da98020_proc_2678330/SPR_BENCH_swa_curves.png"}, {"analysis": "The bar chart represents the test accuracy achieved by the model. The accuracy is approximately 0.65, which is moderately high but leaves room for improvement. This suggests that while the model performs reasonably well on unseen test data, further optimization or enhancements may be required to achieve state-of-the-art performance.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ed1eb1544fbc4d0185df01ab2da98020_proc_2678330/SPR_BENCH_test_accuracy.png"}], [], [{"analysis": "This plot shows the training and validation loss over epochs. Both curves exhibit a consistent decline, indicating effective learning of the model. The training loss decreases more rapidly and reaches a slightly lower value compared to the validation loss, which suggests that the model is fitting the training data well. The close alignment between the two curves indicates that overfitting is minimal, and the model generalizes well to unseen data.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_8cbb9d8e398d4085bd30059326355efe_proc_2678327/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot demonstrates the Shape-Weighted Accuracy (SWA) for both training and validation sets across epochs. Both curves increase steadily, with the validation SWA closely tracking the training SWA. This indicates that the model is learning to generalize well to unseen data. The SWA values nearing 1.0 suggest that the model achieves high performance in the task, effectively leveraging shape information for accurate predictions.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_8cbb9d8e398d4085bd30059326355efe_proc_2678327/SPR_BENCH_swa_curves.png"}, {"analysis": "This bar chart presents the test accuracy and SWA. The high value of the bar indicates strong performance on the test set, confirming the model's ability to generalize to unseen data. This supports the hypothesis that the neural-symbolic integration enables effective zero-shot reasoning in Synthetic PolyRule Reasoning.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_8cbb9d8e398d4085bd30059326355efe_proc_2678327/SPR_BENCH_test_metrics.png"}], [], [{"analysis": "The training and validation loss decrease consistently over the epochs, indicating that the model is learning effectively. The validation loss closely follows the training loss, suggesting minimal overfitting. However, there is a slight spike in the validation loss around epoch 8, which could indicate some instability or sensitivity to certain data points. The final convergence to near-zero loss for both training and validation demonstrates strong model performance on the given dataset.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_107634f1a9f24333ab304c876afd3618_proc_2678329/SPR_BENCH_loss_curves.png"}, {"analysis": "The Shape-Weighted Accuracy (SWA) for both training and validation improves rapidly in the initial epochs and stabilizes at a high level close to 1.0. This indicates that the model is highly effective at generalizing to the validation set. The sharp dip in accuracy around epoch 8 aligns with the spike in validation loss observed earlier, suggesting a temporary disruption in learning. The subsequent recovery and stabilization of SWA show that the model is robust and capable of recovering from such disruptions.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_107634f1a9f24333ab304c876afd3618_proc_2678329/SPR_BENCH_swa_curves.png"}, {"analysis": "The test accuracy is approximately 0.65, which is significantly lower than the near-perfect SWA observed during training and validation. This disparity highlights a potential issue with generalization to unseen test data, possibly due to differences in the test set distribution or limitations in the zero-shot reasoning capabilities of the model. This result calls for further investigation into the model's generalization ability and the characteristics of the test set.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_107634f1a9f24333ab304c876afd3618_proc_2678329/SPR_BENCH_test_accuracy.png"}], [{"analysis": "The plot demonstrates the convergence of the model's training and validation loss over epochs. The training loss decreases sharply in the initial epochs and stabilizes near zero, suggesting effective learning during training. The validation loss closely follows the training loss, indicating minimal overfitting and a good generalization capability of the model.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_546edabd52824f229314bd6b7b3be332_proc_2678330/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot shows the progression of Shape-Weighted Accuracy (SWA) for both training and validation sets. Both metrics improve significantly during the initial epochs and plateau near perfect accuracy. The close alignment of training and validation SWA suggests that the model generalizes well and avoids overfitting, achieving high performance on unseen validation data.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_546edabd52824f229314bd6b7b3be332_proc_2678330/SPR_BENCH_swa_curves.png"}, {"analysis": "The test accuracy is approximately 0.65. While this is a reasonable result, it is significantly lower than the near-perfect training and validation SWA, suggesting that the model may struggle to generalize to entirely unseen test data governed by new rules. This discrepancy highlights potential limitations in the zero-shot reasoning capability of the model.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_546edabd52824f229314bd6b7b3be332_proc_2678330/SPR_BENCH_test_accuracy.png"}], [{"analysis": "This plot shows the training and validation loss over epochs. The training loss decreases steadily, indicating that the model is learning effectively from the training data. The validation loss also decreases and stabilizes at a low value, which suggests that the model generalizes well to unseen data. There is no indication of overfitting as the validation loss does not increase after reaching a minimum.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_36155d2e83cb4768991eb1f7e94bbfb6_proc_2678329/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot depicts the Shape-Weighted Accuracy (SWA) for both training and validation sets over epochs. Both training and validation SWA improve rapidly and converge close to 1.0, demonstrating that the model achieves near-perfect performance on the SPR_BENCH benchmark. The close alignment of training and validation SWA indicates good generalization and suggests that the model is not overfitting.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_36155d2e83cb4768991eb1f7e94bbfb6_proc_2678329/SPR_BENCH_swa_curves.png"}, {"analysis": "This plot shows the test accuracy of the model on the SPR_BENCH benchmark. The accuracy appears to be around 0.65, which is significantly lower than the near-perfect SWA observed during training and validation. This discrepancy suggests that the model struggles to generalize to completely unseen test data, potentially due to differences in rule complexity or other characteristics between the test set and the training/validation sets.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_36155d2e83cb4768991eb1f7e94bbfb6_proc_2678329/SPR_BENCH_test_accuracy.png"}], [{"analysis": "The plot shows the train and validation loss decreasing steadily over the epochs, with both losses converging to a very low value near zero. This indicates that the model is learning effectively during training and that there is no significant overfitting, as the validation loss closely follows the train loss. The convergence of the two curves suggests that the model generalizes well to unseen data.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1ced583751a54325a68a1d07df49decf_proc_2678328/SPR_BENCH_loss_curves.png"}, {"analysis": "The plot illustrates the Shape-Weighted Accuracy (SWA) for both training and validation datasets over the epochs. Both accuracies increase rapidly in the initial epochs and plateau near 1.0, demonstrating excellent performance and minimal overfitting. The close alignment of the two curves further confirms the model's ability to generalize well across the datasets.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1ced583751a54325a68a1d07df49decf_proc_2678328/SPR_BENCH_swa_curves.png"}, {"analysis": "This bar chart shows the test accuracy of the model, which appears to be approximately 0.65. While this is a decent result, it is significantly lower than the near-perfect SWA observed during training and validation, suggesting a potential gap in the model's ability to generalize to entirely unseen rules or sequences. This discrepancy warrants further investigation, such as exploring the distribution of the test data or conducting additional ablation studies to identify any weaknesses in the neural-symbolic integration.", "plot_path": "experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1ced583751a54325a68a1d07df49decf_proc_2678328/SPR_BENCH_test_accuracy.png"}], []], "vlm_feedback_summary": ["The training and validation loss indicate good initial learning with potential\noverfitting after epoch 5. RCWA trends suggest instability and overfitting,\nrequiring further analysis and hyperparameter tuning. Test accuracy is moderate\nand may need improvement to surpass state-of-the-art benchmarks.", "The plots indicate that the model performs well on training and validation data,\nwith strong Shape-Weighted Accuracy and low cross-entropy loss. However, the\ntest accuracy suggests room for improvement in generalization. The confusion\nmatrix highlights imbalances in predictions, which could be further analyzed to\nrefine the model.", "The provided plots indicate that the model is learning effectively, with\ndecreasing losses, high accuracy, and strong performance on the test set. There\nis no significant overfitting, and the model generalizes well to unseen data.\nHowever, there is room for improvement in reducing misclassifications in the\ntest set.", "The plots indicate that the model is learning effectively with minimal\noverfitting, as evidenced by the convergence of training and validation losses\nand the alignment of training and validation SWA. However, the test accuracy\nsuggests room for improvement in generalization to unseen rules.", "The provided plots indicate that the model demonstrates effective learning and\ngeneralization, as evidenced by the decreasing loss curves and the high SWA\nvalues for both training and validation sets. However, the test accuracy plot\nhighlights an opportunity for further improvements to achieve higher performance\non unseen data.", "[]", "The plots indicate successful training and evaluation of the model. The training\nand validation losses decrease consistently, showing effective learning without\noverfitting. The SWA metrics for training and validation are closely aligned and\nachieve near-optimal performance, demonstrating strong generalization. The test\naccuracy and SWA confirm that the model performs well on unseen data, supporting\nthe hypothesis of effective zero-shot reasoning.", "[]", "The results demonstrate strong training and validation performance, with minimal\noverfitting and high SWA scores. However, the test accuracy is relatively low,\nindicating challenges in generalization to unseen data. Further analysis is\nneeded to address this discrepancy and improve the model's zero-shot reasoning\ncapabilities.", "The plots indicate strong performance during training and validation, with\nminimal overfitting and high Shape-Weighted Accuracy (SWA). However, the test\naccuracy reveals a gap in generalization to unseen rules, which may indicate\nlimitations in zero-shot reasoning.", "The plots indicate that the model performs well during training and validation,\nachieving near-perfect SWA. However, the lower test accuracy highlights\nchallenges in generalizing to unseen data, suggesting room for improvement in\nzero-shot reasoning capabilities.", "The provided plots indicate that the model performs exceptionally well on\ntraining and validation data, achieving near-perfect Shape-Weighted Accuracy\n(SWA). However, the test accuracy is notably lower, suggesting that while the\nmodel generalizes well within the training and validation datasets, it struggles\nwith unseen rules in the test set. Further analysis is needed to address this\ngap and improve generalization for zero-shot reasoning tasks.", "[]"], "exec_time": [7.848413705825806, 23.803874492645264, 12.887491226196289, 34.36606812477112, 20.53842258453369, 81.8202531337738, 95.0504035949707, 77.21500444412231, 55.255675315856934, 51.595794439315796, 44.2942168712616, 49.759238481521606, null], "exec_time_feedback": ["", "", "", "", "Implementation works but runs too quickly (0.57 minutes).We have up to 60\nminutes available for each experiment.Make sure to scale up the experiment by\nincreasing the number of epochs, using a larger model, or working with bigger\ndatasets.Given that the current execution time is {exec_time_minutes:.2f}\nminutes, think about how changing the number of epochs to run, or using a larger\nmodel, or working with bigger datasets to runwill affect the execution time, and\nmake sure to scale up the experiment accordingly.", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[\"SPR_BENCH\"]"], ["[]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[]"], [], ["\"\""], [], ["[]"], ["[]"], ["[]"], ["[]"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ----- paths -----\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----- load experiment data -----\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp_rec = experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp_rec = None\n\nif exp_rec is not None:\n    # extract arrays\n    train_loss = np.asarray(exp_rec[\"losses\"][\"train\"])\n    val_loss = np.asarray(exp_rec[\"losses\"][\"val\"])\n    train_rcwa = np.asarray(exp_rec[\"metrics\"][\"train_rcwa\"])\n    val_rcwa = np.asarray(exp_rec[\"metrics\"][\"val_rcwa\"])\n    preds = np.asarray(exp_rec[\"predictions\"])\n    gts = np.asarray(exp_rec[\"ground_truth\"])\n    epochs = np.arange(1, len(train_loss) + 1)\n\n    # --------- plot 1: loss curves ---------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH: Train vs Validation Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # --------- plot 2: RCWA curves ---------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_rcwa, label=\"Train RCWA\")\n        plt.plot(epochs, val_rcwa, label=\"Validation RCWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"RCWA\")\n        plt.title(\"SPR_BENCH: Train vs Validation RCWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_rcwa_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating RCWA plot: {e}\")\n        plt.close()\n\n    # --------- plot 3: Test accuracy bar ---------\n    try:\n        test_acc = (preds == gts).mean() if len(preds) else np.nan\n        plt.figure()\n        plt.bar([\"Accuracy\"], [test_acc])\n        plt.ylim(0, 1)\n        plt.title(\"SPR_BENCH: Test Accuracy\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_test_accuracy.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot: {e}\")\n        plt.close()\n\n    # ----- print evaluation metric -----\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nval_swa_collect = {}  # for cross-dataset comparison\nif experiment_data:\n    for dname, rec in experiment_data.items():\n        # -------- extract arrays ----------\n        train_loss = np.asarray(rec[\"losses\"].get(\"train\", []))\n        val_loss = np.asarray(rec[\"losses\"].get(\"val\", []))\n        train_swa = np.asarray(rec[\"metrics\"].get(\"train_SWA\", []))\n        val_swa = np.asarray(rec[\"metrics\"].get(\"val_SWA\", []))\n        preds = np.asarray(rec.get(\"predictions\", []))\n        gts = np.asarray(rec.get(\"ground_truth\", []))\n        epochs = np.arange(1, len(train_loss) + 1)\n\n        val_swa_collect[dname] = val_swa\n\n        # -------- plot 1: loss curves --------\n        try:\n            plt.figure()\n            plt.plot(epochs, train_loss, label=\"Train\")\n            plt.plot(epochs, val_loss, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{dname}: Train vs Validation Loss\")\n            plt.legend()\n            plt.savefig(os.path.join(working_dir, f\"{dname}_loss_curves.png\"))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {dname}: {e}\")\n            plt.close()\n\n        # -------- plot 2: SWA curves --------\n        try:\n            plt.figure()\n            plt.plot(epochs, train_swa, label=\"Train SWA\")\n            plt.plot(epochs, val_swa, label=\"Validation SWA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Shape-Weighted Accuracy\")\n            plt.title(f\"{dname}: Train vs Validation SWA\")\n            plt.legend()\n            plt.savefig(os.path.join(working_dir, f\"{dname}_swa_curves.png\"))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating SWA plot for {dname}: {e}\")\n            plt.close()\n\n        # -------- plot 3: test accuracy bar --------\n        try:\n            test_acc = float(np.mean(preds == gts)) if len(preds) else np.nan\n            plt.figure()\n            plt.bar([\"Accuracy\"], [test_acc])\n            plt.ylim(0, 1)\n            plt.title(f\"{dname}: Test Accuracy\")\n            plt.savefig(os.path.join(working_dir, f\"{dname}_test_accuracy.png\"))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating accuracy plot for {dname}: {e}\")\n            plt.close()\n\n        # -------- plot 4: confusion matrix --------\n        try:\n            if len(preds) and len(gts):\n                num_cls = int(max(np.max(preds), np.max(gts))) + 1\n                cm = np.zeros((num_cls, num_cls), dtype=int)\n                for t, p in zip(gts, preds):\n                    cm[int(t), int(p)] += 1\n                plt.figure(figsize=(4, 4))\n                plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n                plt.xlabel(\"Predicted\")\n                plt.ylabel(\"Ground Truth\")\n                plt.title(f\"{dname}: Confusion Matrix\")\n                plt.colorbar()\n                plt.savefig(os.path.join(working_dir, f\"{dname}_confusion_matrix.png\"))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating confusion matrix for {dname}: {e}\")\n            plt.close()\n\n        # ----- print evaluation metrics -----\n        if len(preds):\n            print(f\"{dname} - Test Accuracy: {np.mean(preds==gts):.4f}\")\n\n# -------- comparison plot across datasets (val SWA) --------\ntry:\n    if len(val_swa_collect) > 1:\n        plt.figure()\n        for dname, vswa in val_swa_collect.items():\n            plt.plot(np.arange(1, len(vswa) + 1), vswa, label=dname)\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation SWA\")\n        plt.title(\"Validation SWA Comparison Across Datasets\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"datasets_val_swa_comparison.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating cross-dataset SWA plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ----- paths -----\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----- load experiment data -----\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp_rec = experiment_data.get(\"SPR_BENCH\", None)\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp_rec = None\n\nif exp_rec is not None:\n    # -------- extract arrays --------\n    train_loss = np.asarray(exp_rec[\"losses\"][\"train\"])\n    val_loss = np.asarray(exp_rec[\"losses\"][\"val\"])\n    train_swa = np.asarray(exp_rec[\"metrics\"][\"train_swa\"])\n    val_swa = np.asarray(exp_rec[\"metrics\"][\"val_swa\"])\n    preds = np.asarray(exp_rec.get(\"predictions\", []))\n    gts = np.asarray(exp_rec.get(\"ground_truth\", []))\n    epochs = np.arange(1, len(train_loss) + 1)\n\n    # -------- plot 1: loss curves --------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH: Train vs Validation Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # -------- plot 2: SWA curves --------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_swa, label=\"Train SWA\")\n        plt.plot(epochs, val_swa, label=\"Validation SWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(\"SPR_BENCH: Train vs Validation SWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_swa_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot: {e}\")\n        plt.close()\n\n    # -------- plot 3: confusion matrix --------\n    try:\n        if preds.size and gts.size:\n            num_classes = int(max(preds.max(), gts.max())) + 1\n            cm = np.zeros((num_classes, num_classes), dtype=int)\n            for p, g in zip(preds, gts):\n                cm[g, p] += 1\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted Label\")\n            plt.ylabel(\"Ground Truth Label\")\n            plt.title(\"SPR_BENCH: Confusion Matrix (Test Set)\")\n            plt.savefig(os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix plot: {e}\")\n        plt.close()\n\n    # -------- evaluation metrics --------\n    test_acc = (preds == gts).mean() if preds.size else np.nan\n    print(f\"Test Accuracy: {test_acc:.4f}\")\nelse:\n    print(\"No experiment data found.\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nbest_val_swa_all = {}\nfor dname, rec in experiment_data.items():\n    # -------- extract with robust fallback --------\n    train_loss = np.asarray(rec[\"losses\"].get(\"train\", []), dtype=float)\n    val_loss = np.asarray(rec[\"losses\"].get(\"val\", []), dtype=float)\n    train_swa = np.asarray(rec[\"metrics\"].get(\"train_swa\", []), dtype=float)\n    val_swa = np.asarray(rec[\"metrics\"].get(\"val_swa\", []), dtype=float)\n    preds = np.asarray(rec.get(\"predictions\", []))\n    gts = np.asarray(rec.get(\"ground_truth\", []))\n    epochs = np.arange(1, len(train_loss) + 1)\n\n    # cache best val swa for later comparison\n    if len(val_swa):\n        best_val_swa_all[dname] = float(np.nanmax(val_swa))\n\n    # -------- plot 1: loss curves --------\n    try:\n        plt.figure()\n        if len(train_loss):\n            plt.plot(epochs, train_loss, label=\"Train\")\n        if len(val_loss):\n            plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dname}: Train vs Validation Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {dname}: {e}\")\n        plt.close()\n\n    # -------- plot 2: SWA curves --------\n    try:\n        plt.figure()\n        if len(train_swa):\n            plt.plot(epochs, train_swa, label=\"Train SWA\")\n        if len(val_swa):\n            plt.plot(epochs, val_swa, label=\"Validation SWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(f\"{dname}: Train vs Validation SWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_swa_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot for {dname}: {e}\")\n        plt.close()\n\n    # -------- plot 3: test accuracy --------\n    try:\n        acc = float(np.mean(preds == gts)) if len(preds) else np.nan\n        plt.figure()\n        plt.bar([\"Accuracy\"], [acc])\n        plt.ylim(0, 1)\n        plt.title(f\"{dname}: Test Accuracy\")\n        plt.savefig(os.path.join(working_dir, f\"{dname}_test_accuracy.png\"))\n        plt.close()\n        print(f\"{dname}  Test Accuracy: {acc:.4f}\")\n    except Exception as e:\n        print(f\"Error creating accuracy plot for {dname}: {e}\")\n        plt.close()\n\n# -------- comparison plot (best val SWA across datasets) --------\nif len(best_val_swa_all) > 1:\n    try:\n        plt.figure()\n        names = list(best_val_swa_all.keys())\n        vals = [best_val_swa_all[n] for n in names]\n        plt.bar(names, vals)\n        plt.ylim(0, 1)\n        plt.xticks(rotation=45, ha=\"right\")\n        plt.title(\"Best Validation SWA Comparison Across Datasets\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"comparison_best_val_swa.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ----- paths -----\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----- load experiment data -----\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    def count_shape_variety(sequence: str) -> int:\n        return len(\n            set(tok.split()[0] if tok else \"\" for tok in sequence.strip().split())\n        )\n\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / (sum(weights) if sum(weights) else 1.0)\n\n\nfor dname, rec in experiment_data.items():\n    # ---- extract arrays safely ----\n    train_loss = np.asarray(rec.get(\"losses\", {}).get(\"train\", []))\n    val_loss = np.asarray(rec.get(\"losses\", {}).get(\"val\", []))\n    train_swa = np.asarray(rec.get(\"metrics\", {}).get(\"train_swa\", []))\n    val_swa = np.asarray(rec.get(\"metrics\", {}).get(\"val_swa\", []))\n    preds = np.asarray(rec.get(\"predictions\", []))\n    gts = np.asarray(rec.get(\"ground_truth\", []))\n    epochs = np.arange(1, len(train_loss) + 1)\n\n    # --------- plot 1: loss curves ---------\n    try:\n        if train_loss.size and val_loss.size:\n            plt.figure()\n            plt.plot(epochs, train_loss, label=\"Train\")\n            plt.plot(epochs, val_loss, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{dname}: Train vs Validation Loss\")\n            plt.legend()\n            plt.savefig(os.path.join(working_dir, f\"{dname}_loss_curves.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {dname}: {e}\")\n        plt.close()\n\n    # --------- plot 2: SWA curves ---------\n    try:\n        if train_swa.size and val_swa.size:\n            plt.figure()\n            plt.plot(epochs, train_swa, label=\"Train SWA\")\n            plt.plot(epochs, val_swa, label=\"Validation SWA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Shape-Weighted Accuracy\")\n            plt.title(f\"{dname}: Train vs Validation SWA\")\n            plt.legend()\n            plt.savefig(os.path.join(working_dir, f\"{dname}_swa_curves.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot for {dname}: {e}\")\n        plt.close()\n\n    # --------- plot 3: Test accuracy bar ---------\n    try:\n        if preds.size and gts.size:\n            test_acc = (preds == gts).mean()\n            plt.figure()\n            plt.bar([\"Accuracy\"], [test_acc])\n            plt.ylim(0, 1)\n            plt.title(f\"{dname}: Test Accuracy\")\n            plt.savefig(os.path.join(working_dir, f\"{dname}_test_accuracy.png\"))\n            plt.close()\n\n            # also compute and print SWA on test if sequences available\n            seqs = rec.get(\"test_sequences\", [])\n            if len(seqs) == len(preds):\n                test_swa = shape_weighted_accuracy(seqs, gts, preds)\n            else:\n                test_swa = np.nan\n            print(f\"{dname} - Test Accuracy: {test_acc:.4f} | Test SWA: {test_swa:.4f}\")\n        else:\n            print(f\"{dname} - No prediction data available.\")\n    except Exception as e:\n        print(f\"Error creating accuracy plot for {dname}: {e}\")\n        plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ----- paths -----\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----- load experiment data -----\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ----- container for comparison plot -----\nval_swa_curves = {}\n\nfor ds_name, rec in experiment_data.items():\n    # ---------------- extract arrays ----------------\n    try:\n        train_loss = np.asarray(rec[\"losses\"][\"train\"])\n        val_loss = np.asarray(rec[\"losses\"][\"val\"])\n    except Exception:\n        train_loss = val_loss = np.array([])\n    try:\n        train_swa = np.asarray(rec[\"metrics\"][\"train_swa\"])\n        val_swa = np.asarray(rec[\"metrics\"][\"val_swa\"])\n    except Exception:\n        train_swa = val_swa = np.array([])\n    preds = np.asarray(rec.get(\"predictions\", []))\n    gts = np.asarray(rec.get(\"ground_truth\", []))\n    epochs = np.arange(1, len(train_loss) + 1)\n\n    # store for comparison\n    if len(val_swa):\n        val_swa_curves[ds_name] = (epochs, val_swa)\n\n    # --------- plot 1: loss curves ---------\n    try:\n        if len(train_loss) and len(val_loss):\n            plt.figure()\n            plt.plot(epochs, train_loss, label=\"Train\")\n            plt.plot(epochs, val_loss, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{ds_name}: Train vs Validation Loss\")\n            plt.legend()\n            plt.savefig(os.path.join(working_dir, f\"{ds_name}_loss_curves.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- plot 2: SWA curves ---------\n    try:\n        if len(train_swa) and len(val_swa):\n            plt.figure()\n            plt.plot(epochs, train_swa, label=\"Train SWA\")\n            plt.plot(epochs, val_swa, label=\"Validation SWA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Shape-Weighted Accuracy\")\n            plt.title(f\"{ds_name}: Train vs Validation SWA\")\n            plt.legend()\n            plt.savefig(os.path.join(working_dir, f\"{ds_name}_swa_curves.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- plot 3: Test metrics bar ---------\n    try:\n        if len(preds) and len(gts):\n            acc = (preds == gts).mean()\n            swa_test = rec[\"metrics\"].get(\"test_swa\", np.nan)\n            plt.figure()\n            plt.bar([\"Accuracy\", \"SWA\"], [acc, swa_test])\n            plt.ylim(0, 1)\n            plt.title(f\"{ds_name}: Test Accuracy & SWA\")\n            plt.savefig(os.path.join(working_dir, f\"{ds_name}_test_metrics.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating test metrics plot for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- print evaluation metrics ---------\n    if len(preds) and len(gts):\n        print(\n            f\"{ds_name} - Test Accuracy: {(preds==gts).mean():.4f}, Test SWA: {rec['metrics'].get('test_swa', np.nan):.4f}\"\n        )\n\n# --------- comparison plot across datasets ---------\ntry:\n    if len(val_swa_curves) > 1:\n        plt.figure()\n        for i, (ds_name, (ep, curve)) in enumerate(val_swa_curves.items()):\n            if i >= 5:  # plot at most 5 datasets\n                break\n            plt.plot(ep, curve, label=f\"{ds_name}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation SWA\")\n        plt.title(\"Validation SWA Comparison Across Datasets\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_val_swa.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating comparison plot: {e}\")\n    plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------- paths --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- load data ----\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    for dset_name, rec in experiment_data.items():\n        # pull arrays safely\n        train_loss = np.asarray(rec[\"losses\"].get(\"train\", []), dtype=float)\n        val_loss = np.asarray(rec[\"losses\"].get(\"val\", []), dtype=float)\n        train_swa = np.asarray(rec[\"metrics\"].get(\"train_swa\", []), dtype=float)\n        val_swa = np.asarray(rec[\"metrics\"].get(\"val_swa\", []), dtype=float)\n        preds = np.asarray(rec.get(\"predictions\", []))\n        gts = np.asarray(rec.get(\"ground_truth\", []))\n        epochs = np.arange(1, len(train_loss) + 1)\n\n        # ---- 1: loss curves ----\n        try:\n            plt.figure()\n            plt.plot(epochs, train_loss, label=\"Train\")\n            plt.plot(epochs, val_loss, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{dset_name}: Train vs Validation Loss\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset_name}_loss_curves.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- 2: SWA curves ----\n        try:\n            plt.figure()\n            plt.plot(epochs, train_swa, label=\"Train SWA\")\n            plt.plot(epochs, val_swa, label=\"Validation SWA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Shape-Weighted Accuracy\")\n            plt.title(f\"{dset_name}: Train vs Validation SWA\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset_name}_swa_curves.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating SWA plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- 3: test accuracy bar ----\n        try:\n            test_acc = float(np.mean(preds == gts)) if len(preds) else np.nan\n            plt.figure()\n            plt.bar([\"Accuracy\"], [test_acc])\n            plt.ylim(0, 1)\n            plt.title(f\"{dset_name}: Test Accuracy\")\n            fname = os.path.join(working_dir, f\"{dset_name}_test_accuracy.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating accuracy plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- print summary ----\n        best_val_swa = float(np.max(val_swa)) if len(val_swa) else np.nan\n        test_swa = (\n            float(np.mean(train_swa[-1:])) if len(train_swa) else np.nan\n        )  # placeholder\n        print(f\"{dset_name}: best_val_SWA={best_val_swa:.4f}, test_acc={test_acc:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------- paths --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- load data ----\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    for dset_name, rec in experiment_data.items():\n        # pull arrays safely\n        train_loss = np.asarray(rec[\"losses\"].get(\"train\", []), dtype=float)\n        val_loss = np.asarray(rec[\"losses\"].get(\"val\", []), dtype=float)\n        train_swa = np.asarray(rec[\"metrics\"].get(\"train_swa\", []), dtype=float)\n        val_swa = np.asarray(rec[\"metrics\"].get(\"val_swa\", []), dtype=float)\n        preds = np.asarray(rec.get(\"predictions\", []))\n        gts = np.asarray(rec.get(\"ground_truth\", []))\n        epochs = np.arange(1, len(train_loss) + 1)\n\n        # ---- 1: loss curves ----\n        try:\n            plt.figure()\n            plt.plot(epochs, train_loss, label=\"Train\")\n            plt.plot(epochs, val_loss, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{dset_name}: Train vs Validation Loss\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset_name}_loss_curves.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- 2: SWA curves ----\n        try:\n            plt.figure()\n            plt.plot(epochs, train_swa, label=\"Train SWA\")\n            plt.plot(epochs, val_swa, label=\"Validation SWA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Shape-Weighted Accuracy\")\n            plt.title(f\"{dset_name}: Train vs Validation SWA\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset_name}_swa_curves.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating SWA plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- 3: test accuracy bar ----\n        try:\n            test_acc = float(np.mean(preds == gts)) if len(preds) else np.nan\n            plt.figure()\n            plt.bar([\"Accuracy\"], [test_acc])\n            plt.ylim(0, 1)\n            plt.title(f\"{dset_name}: Test Accuracy\")\n            fname = os.path.join(working_dir, f\"{dset_name}_test_accuracy.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating accuracy plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- print summary ----\n        best_val_swa = float(np.max(val_swa)) if len(val_swa) else np.nan\n        test_swa = (\n            float(np.mean(train_swa[-1:])) if len(train_swa) else np.nan\n        )  # placeholder\n        print(f\"{dset_name}: best_val_SWA={best_val_swa:.4f}, test_acc={test_acc:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------- paths --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- load data ----\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    for dset_name, rec in experiment_data.items():\n        # pull arrays safely\n        train_loss = np.asarray(rec[\"losses\"].get(\"train\", []), dtype=float)\n        val_loss = np.asarray(rec[\"losses\"].get(\"val\", []), dtype=float)\n        train_swa = np.asarray(rec[\"metrics\"].get(\"train_swa\", []), dtype=float)\n        val_swa = np.asarray(rec[\"metrics\"].get(\"val_swa\", []), dtype=float)\n        preds = np.asarray(rec.get(\"predictions\", []))\n        gts = np.asarray(rec.get(\"ground_truth\", []))\n        epochs = np.arange(1, len(train_loss) + 1)\n\n        # ---- 1: loss curves ----\n        try:\n            plt.figure()\n            plt.plot(epochs, train_loss, label=\"Train\")\n            plt.plot(epochs, val_loss, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{dset_name}: Train vs Validation Loss\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset_name}_loss_curves.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- 2: SWA curves ----\n        try:\n            plt.figure()\n            plt.plot(epochs, train_swa, label=\"Train SWA\")\n            plt.plot(epochs, val_swa, label=\"Validation SWA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Shape-Weighted Accuracy\")\n            plt.title(f\"{dset_name}: Train vs Validation SWA\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset_name}_swa_curves.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating SWA plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- 3: test accuracy bar ----\n        try:\n            test_acc = float(np.mean(preds == gts)) if len(preds) else np.nan\n            plt.figure()\n            plt.bar([\"Accuracy\"], [test_acc])\n            plt.ylim(0, 1)\n            plt.title(f\"{dset_name}: Test Accuracy\")\n            fname = os.path.join(working_dir, f\"{dset_name}_test_accuracy.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating accuracy plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- print summary ----\n        best_val_swa = float(np.max(val_swa)) if len(val_swa) else np.nan\n        test_swa = (\n            float(np.mean(train_swa[-1:])) if len(train_swa) else np.nan\n        )  # placeholder\n        print(f\"{dset_name}: best_val_SWA={best_val_swa:.4f}, test_acc={test_acc:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------- paths --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- load data ----\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    for dset_name, rec in experiment_data.items():\n        # pull arrays safely\n        train_loss = np.asarray(rec[\"losses\"].get(\"train\", []), dtype=float)\n        val_loss = np.asarray(rec[\"losses\"].get(\"val\", []), dtype=float)\n        train_swa = np.asarray(rec[\"metrics\"].get(\"train_swa\", []), dtype=float)\n        val_swa = np.asarray(rec[\"metrics\"].get(\"val_swa\", []), dtype=float)\n        preds = np.asarray(rec.get(\"predictions\", []))\n        gts = np.asarray(rec.get(\"ground_truth\", []))\n        epochs = np.arange(1, len(train_loss) + 1)\n\n        # ---- 1: loss curves ----\n        try:\n            plt.figure()\n            plt.plot(epochs, train_loss, label=\"Train\")\n            plt.plot(epochs, val_loss, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{dset_name}: Train vs Validation Loss\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset_name}_loss_curves.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- 2: SWA curves ----\n        try:\n            plt.figure()\n            plt.plot(epochs, train_swa, label=\"Train SWA\")\n            plt.plot(epochs, val_swa, label=\"Validation SWA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Shape-Weighted Accuracy\")\n            plt.title(f\"{dset_name}: Train vs Validation SWA\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset_name}_swa_curves.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating SWA plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- 3: test accuracy bar ----\n        try:\n            test_acc = float(np.mean(preds == gts)) if len(preds) else np.nan\n            plt.figure()\n            plt.bar([\"Accuracy\"], [test_acc])\n            plt.ylim(0, 1)\n            plt.title(f\"{dset_name}: Test Accuracy\")\n            fname = os.path.join(working_dir, f\"{dset_name}_test_accuracy.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating accuracy plot for {dset_name}: {e}\")\n            plt.close()\n\n        # ---- print summary ----\n        best_val_swa = float(np.max(val_swa)) if len(val_swa) else np.nan\n        test_swa = (\n            float(np.mean(train_swa[-1:])) if len(train_swa) else np.nan\n        )  # placeholder\n        print(f\"{dset_name}: best_val_SWA={best_val_swa:.4f}, test_acc={test_acc:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------- paths --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- experiment files to aggregate --------\nexperiment_data_path_list = [\n    \"experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_546edabd52824f229314bd6b7b3be332_proc_2678330/experiment_data.npy\",\n    \"experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_36155d2e83cb4768991eb1f7e94bbfb6_proc_2678329/experiment_data.npy\",\n    \"experiments/2025-08-14_15-47-52_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1ced583751a54325a68a1d07df49decf_proc_2678328/experiment_data.npy\",\n]\n\n# -------- load data from all runs --------\nall_runs = []\nfor p in experiment_data_path_list:\n    try:\n        data = np.load(\n            os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p), allow_pickle=True\n        ).item()\n        all_runs.append(data)\n    except Exception as e:\n        print(f\"Error loading {p}: {e}\")\n\n# -------- merge by dataset --------\ndatasets = {}\nfor run in all_runs:\n    for dset_name, rec in run.items():\n        bucket = datasets.setdefault(\n            dset_name,\n            {\n                \"train_loss\": [],\n                \"val_loss\": [],\n                \"train_swa\": [],\n                \"val_swa\": [],\n                \"test_acc\": [],\n            },\n        )\n        # losses & metrics\n        bucket[\"train_loss\"].append(\n            np.asarray(rec[\"losses\"].get(\"train\", []), dtype=float)\n        )\n        bucket[\"val_loss\"].append(np.asarray(rec[\"losses\"].get(\"val\", []), dtype=float))\n        bucket[\"train_swa\"].append(\n            np.asarray(rec[\"metrics\"].get(\"train_swa\", []), dtype=float)\n        )\n        bucket[\"val_swa\"].append(\n            np.asarray(rec[\"metrics\"].get(\"val_swa\", []), dtype=float)\n        )\n        preds = np.asarray(rec.get(\"predictions\", []))\n        gts = np.asarray(rec.get(\"ground_truth\", []))\n        acc = float(np.mean(preds == gts)) if len(preds) else np.nan\n        bucket[\"test_acc\"].append(acc)\n\n\n# -------- helper to stack to common length --------\ndef stack_trim(arr_list):\n    lens = [len(a) for a in arr_list if len(a)]\n    if not lens:\n        return None\n    min_len = min(lens)\n    trimmed = np.stack([a[:min_len] for a in arr_list], axis=0)  # (runs, epochs)\n    return trimmed\n\n\n# -------- plotting --------\nfor dset_name, rec in datasets.items():\n    n_runs = len(rec[\"train_loss\"])\n    # Aggregate curves\n    train_loss_stack = stack_trim(rec[\"train_loss\"])\n    val_loss_stack = stack_trim(rec[\"val_loss\"])\n    train_swa_stack = stack_trim(rec[\"train_swa\"])\n    val_swa_stack = stack_trim(rec[\"val_swa\"])\n    epochs_loss = (\n        np.arange(1, train_loss_stack.shape[1] + 1)\n        if train_loss_stack is not None\n        else None\n    )\n    epochs_swa = (\n        np.arange(1, train_swa_stack.shape[1] + 1)\n        if train_swa_stack is not None\n        else None\n    )\n\n    # ---- 1: aggregated loss curves ----\n    try:\n        if train_loss_stack is not None and val_loss_stack is not None:\n            plt.figure()\n            m_tr = train_loss_stack.mean(axis=0)\n            m_val = val_loss_stack.mean(axis=0)\n            if n_runs > 1:\n                se_tr = train_loss_stack.std(axis=0, ddof=1) / np.sqrt(n_runs)\n                se_val = val_loss_stack.std(axis=0, ddof=1) / np.sqrt(n_runs)\n                plt.fill_between(\n                    epochs_loss, m_tr - se_tr, m_tr + se_tr, alpha=0.3, label=\"Train SE\"\n                )\n                plt.fill_between(\n                    epochs_loss,\n                    m_val - se_val,\n                    m_val + se_val,\n                    alpha=0.3,\n                    label=\"Val SE\",\n                )\n            plt.plot(epochs_loss, m_tr, label=\"Train Mean\", color=\"tab:blue\")\n            plt.plot(epochs_loss, m_val, label=\"Val Mean\", color=\"tab:orange\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{dset_name}: Mean Train vs Val Loss (n={n_runs})\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset_name}_aggregated_loss_curves.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated loss plot for {dset_name}: {e}\")\n        plt.close()\n\n    # ---- 2: aggregated SWA curves ----\n    try:\n        if train_swa_stack is not None and val_swa_stack is not None:\n            plt.figure()\n            m_tr = train_swa_stack.mean(axis=0)\n            m_val = val_swa_stack.mean(axis=0)\n            if n_runs > 1:\n                se_tr = train_swa_stack.std(axis=0, ddof=1) / np.sqrt(n_runs)\n                se_val = val_swa_stack.std(axis=0, ddof=1) / np.sqrt(n_runs)\n                plt.fill_between(\n                    epochs_swa, m_tr - se_tr, m_tr + se_tr, alpha=0.3, label=\"Train SE\"\n                )\n                plt.fill_between(\n                    epochs_swa,\n                    m_val - se_val,\n                    m_val + se_val,\n                    alpha=0.3,\n                    label=\"Val SE\",\n                )\n            plt.plot(epochs_swa, m_tr, label=\"Train Mean\", color=\"tab:green\")\n            plt.plot(epochs_swa, m_val, label=\"Val Mean\", color=\"tab:red\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Shape-Weighted Accuracy\")\n            plt.title(f\"{dset_name}: Mean Train vs Val SWA (n={n_runs})\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset_name}_aggregated_swa_curves.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated SWA plot for {dset_name}: {e}\")\n        plt.close()\n\n    # ---- 3: aggregated test accuracy bar ----\n    try:\n        acc_arr = np.asarray(rec[\"test_acc\"], dtype=float)\n        if len(acc_arr):\n            mean_acc = np.nanmean(acc_arr)\n            se_acc = (\n                np.nanstd(acc_arr, ddof=1) / np.sqrt(len(acc_arr))\n                if len(acc_arr) > 1\n                else 0.0\n            )\n            plt.figure()\n            plt.bar(\n                [0], [mean_acc], yerr=[se_acc], capsize=5, color=\"tab:purple\", alpha=0.7\n            )\n            plt.ylim(0, 1)\n            plt.xticks([0], [\"Accuracy\"])\n            plt.title(f\"{dset_name}: Test Accuracy Mean \u00b1 SE (n={n_runs})\")\n            fname = os.path.join(\n                working_dir, f\"{dset_name}_aggregated_test_accuracy.png\"\n            )\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated accuracy plot for {dset_name}: {e}\")\n        plt.close()\n\n    # ---- console summary ----\n    try:\n        best_val_swa_per_run = [\n            np.nanmax(v) if len(v) else np.nan for v in rec[\"val_swa\"]\n        ]\n        mean_best_val_swa = np.nanmean(best_val_swa_per_run)\n        se_best_val_swa = (\n            np.nanstd(best_val_swa_per_run, ddof=1) / np.sqrt(n_runs)\n            if n_runs > 1\n            else 0.0\n        )\n        print(\n            f\"{dset_name}: best_val_SWA={mean_best_val_swa:.4f} \u00b1 {se_best_val_swa:.4f}, \"\n            f\"test_acc={mean_acc:.4f} \u00b1 {se_acc:.4f}\"\n        )\n    except Exception as e:\n        print(f\"Error computing summary for {dset_name}: {e}\")\n"], "plot_plan": ["We will first load experiment_data.npy, then extract the SPR_BENCH record to access the stored training/validation losses and RCWA scores, together with the final test predictions and ground-truth labels. Epoch indices are reconstructed from the length of the loss arrays. We will generate three plots: (1) cross-entropy loss curves for train vs. validation, (2) RCWA curves for train vs. validation, and (3) a simple bar chart summarising the final test set accuracy (using the saved predictions/labels). Each plot is wrapped in its own try-except block, saved with a descriptive filename to working_dir, and the figure is always closed afterwards. We also compute and print the test accuracy so the script outputs a quantitative metric. No data are invented: everything comes directly from experiment_data.npy. At most three figures are produced, satisfying the \u201c\u22645 plots\u201d guideline. All standard matplotlib functions are used without custom styles, and every figure has an informative title. Finally, the code respects the directory structure and runs in a concise self-contained manner.", "We will load experiment_data.npy, iterate over every dataset stored, and for each one extract the recorded training/validation losses, shape-weighted accuracies (SWA), predictions, and ground-truth labels. For each dataset we create up to four separate plots\u2014loss curves, SWA curves, test-set accuracy bar, and a confusion-matrix heat-map\u2014each enclosed in its own try/except so that failures in one plot do not affect the others. All figures are saved in the working directory with descriptive filenames that include the dataset name and plot type, and the figures are always closed after saving. After per-dataset plots we optionally generate a comparison plot that overlays the validation SWA curves of all datasets if more than one dataset is present, again guarded by try/except. We keep the total number of figures \u22645 by limiting to these key visualizations. The code finishes by printing the per-dataset test accuracy (and SWA of the best epoch if desired) so that numeric results are available in logs. Everything relies solely on the data contained in experiment_data.npy; no synthetic values are created. All plotting uses basic Matplotlib without custom styling for portability.", "We first load experiment_data.npy from the working directory and pull out the single stored experiment record \u201cSPR_BENCH\u201d.  From it we extract the arrays for training/validation loss, training/validation shape-weighted accuracy (SWA), test\u2010set predictions and ground-truth labels, plus an epoch index.  Using basic matplotlib, three figures are generated inside independent try-except blocks: (1) loss curves, (2) SWA curves, and (3) a confusion-matrix heat-map on the test set.  Each figure gets a descriptive title, axes labels and legend where necessary, is saved into working_dir with an informative filename, and is always closed afterwards regardless of errors.  If predictions are present we also compute and print overall test accuracy; SWA on the test set is not recomputed because the required original sequences were not persisted.  All plotting strictly relies on values stored in the numpy file\u2014no synthetic data are introduced.  The code is concise, contains the required imports at the top, ensures the working directory exists, and follows the formatting/naming conventions requested.  Running it will both save the plots and echo the key evaluation metric to stdout.", "We will load experiment_data.npy, iterate over every dataset present, and for each one extract arrays for training/validation loss, training/validation SWA, and test predictions vs ground-truth.  For every dataset we create three plots inside separate try-except blocks: (1) loss curves, (2) SWA curves, and (3) a bar chart of overall test accuracy.  Figures are saved under descriptive names that embed the dataset name and plot type, all inside working_dir, and every figure is explicitly closed.  While iterating we also record the best validation SWA of each dataset; after finishing the per-dataset plots, we create one additional comparison bar chart (again wrapped in try-except) that juxtaposes the best validation SWA across datasets\u2014this plot is skipped if there is only a single dataset.  No values are fabricated; we only plot what exists in the numpy file, and we guard against missing keys with safe .get calls and NaNs.  Finally the script prints each dataset\u2019s test accuracy and, if available, the comparison figure path.  The entire plotting logic is concise, self-contained and begins with the required imports.", "We first load experiment_data.npy, loop over every dataset stored, and for each extract training/validation losses, shape-weighted accuracies, predictions and ground-truth. For every dataset we then create at most three figures: (1) loss curves, (2) SWA curves, and (3) a single-bar test accuracy plot. Each figure is wrapped in its own try-except to satisfy robustness requirements, given clear titles/subtitles and saved to working_dir with descriptive filenames. We make sure to only plot keys that are actually present in the record, skipping otherwise. Figures are closed in both success and failure cases. After plotting we compute and print overall test accuracy (plain) and shape-weighted accuracy so the notebook shows numeric evaluation too. No additional synthetic data are generated; everything comes from experiment_data.npy. This produces a concise, extensible visualization script that respects the 5-figure limit and developer guidelines.", null, "We load experiment_data.npy, iterate over every dataset key, and for each we pull train/val loss, train/val shape-weighted accuracy (SWA), predictions and labels. We build an epoch index and create up to three figures per dataset: (1) train vs. validation loss, (2) train vs. validation SWA, and (3) a simple bar plot of test accuracy together with SWA. Each figure is wrapped in its own try-except, saved to working_dir with descriptive names, and then closed. While iterating, we also cache each dataset\u2019s validation SWA so that, if more than one dataset exists, we can generate a fourth \u201ccomparison\u201d plot that overlays all validation SWA curves (at most five datasets shown). The plotting code uses only data that exists in the numpy file and skips any missing arrays gracefully. Finally, after plotting, we print the computed test accuracy and SWA for every dataset so the notebook/console displays key metrics. The entire script starts with the mandated imports and working_dir setup and keeps the code concise.", null, "We will load the stored experiment_data.npy, loop over every dataset key it contains, and for each dataset extract the loss arrays, SWA (shape-weighted accuracy) arrays, predictions and ground-truth.  For every dataset three plots are generated in separate try-except blocks: (1) train vs. validation loss curve, (2) train vs. validation SWA curve, and (3) a simple bar plot of test accuracy.  All plots are titled clearly, saved inside working_dir with filenames that include the dataset name and plot type, and the figures are always closed even on error.  When predictions exist the script computes overall test accuracy and prints it; if they are absent the value is reported as NaN.  The code starts with the mandated imports, creates working_dir, attempts to load the numpy dictionary, and silently exits if loading fails.  Only keys that are actually present in the numpy structure are accessed, preventing KeyErrors.  Finally, for quick inspection the script prints a small summary line per dataset showing the best validation SWA and the test SWA.  The entire logic is packed into concise, readable blocks while fully respecting the plotting guidelines.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": ["EPOCHS", null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["The script loads the saved experiment_data.npy from the working directory,\niterates through every dataset stored under the epochs_tuning key, and gathers\nthe recorded losses, RCWA scores, and, when available, test predictions. For\nevery dataset it prints: the final training loss, the best (minimum) validation\nloss, the final training RCWA, the best (maximum) validation RCWA, and the test\naccuracy computed from saved predictions and ground-truth labels. Each value is\nclearly labeled to avoid ambiguity. The code runs immediately at import and\nrequires no special entry point.", "The script will locate the saved NumPy file in the working directory, load it\ninto a Python dictionary, and iterate over every stored dataset. For each\ndataset it extracts the recorded metric lists, chooses either the final entry\n(for training-phase metrics) or the best value (for validation accuracy), and\ncomputes a simple test-set accuracy from the stored predictions and ground-truth\nlabels. All results are printed with explicit metric names so that it is clear\nwhat each number represents.", "Below is the plan followed by code.  We first load the numpy file located in the\nworking directory, recovering the dictionary that stores all experimental\ninformation.   For every dataset key (e.g. \u201cSPR_BENCH\u201d) we compute and print   \u2022\nthe last training loss,   \u2022 the best (minimum) validation loss,   \u2022 the last\ntraining shape-weighted accuracy, and   \u2022 the best (maximum) validation shape-\nweighted accuracy.   Each metric is clearly labelled, and no plotting or special\nentry point is used.", "The code will locate the working directory, load the numpy file that stores the\nexperiment dictionary, and iterate over every dataset it contains.   For each\ndataset it will look inside the \"metrics\" and \"losses\" sub-dictionaries, decide\nwhether to report the best (min for losses, max for scores) or the final value\n(for training metrics and losses), and print them with clear, explicit names.\nThis produces a concise textual summary so you can quickly see the most\nimportant results without generating any plots.", "The script below loads the saved experiment_data.npy file from the \u201cworking\u201d\ndirectory, iterates over every dataset it contains, and prints the key\nperformance numbers.   For every loss curve it reports the minimum (best) loss,\nwhile for every accuracy-like metric it reports the maximum (best) value; the\nscript also handles simple name-to-label conversion so the printed metric names\nare human-readable and unambiguous.   Because nothing is placed inside an if\n__name__ == \"__main__\": guard, the code executes immediately when run.", "The script loads the saved numpy file from the \u201cworking\u201d directory, iterates\nthrough every dataset entry (e.g., \u201cSPR_BENCH\u201d), and extracts the stored\ntraining/validation losses and shape-weighted accuracies.   It then selects the\nfinal logged value for each loss/accuracy list and prints them with fully-\nqualified metric names (e.g., \u201ctraining loss\u201d).   For the test split, the script\nderives a plain test accuracy from the saved prediction and ground-truth arrays.\nAll code runs immediately at the global scope, requires no special entry point,\nand produces only textual metric summaries\u2014no plots.", "The script will load the experiment_data.npy file from the working directory,\niterate over every stored dataset, and print the best value for each logged\nmetric. For losses it reports the minimum (lower is better), while for\naccuracy\u2010type metrics it reports the maximum (higher is better). Descriptive\nnames are used so it is clear whether the number refers to training loss,\nvalidation loss, or shape-weighted accuracy.", "Below is a small utility that immediately loads the experiment record, pulls out\nthe arrays that were filled during training, and prints the final (or best)\nresult for every stored metric.  For training and validation losses/SWA we take\nthe last recorded value, whereas for the validation SWA we also show the best\n(maximum) value reached.  When test-set predictions and labels are present, we\nadditionally report the overall test classification accuracy.  The script\nfollows the directory/layout conventions of the original training code and\ncontains no special entry point \u2013 it runs as soon as the file is executed.", "This script loads the saved experiment_data.npy file from the \u201cworking\u201d\ndirectory, iterates over every dataset entry, and reports the best value\nobserved for each stored metric.  For accuracy\u2013type metrics (the names contain\n\u201cswa\u201d) the maximum value is selected, while for loss metrics the minimum value\nis selected.  Outputs are clearly labeled with both the dataset name and an\nexplicit metric name such as \u201ctrain shape-weighted accuracy\u201d or \u201cvalidation\nloss\u201d.  No plots are generated and the code executes immediately when run.", "This script loads the saved experiment_data.npy file from the \u201cworking\u201d\ndirectory, iterates over every dataset entry, and reports the best value\nobserved for each stored metric.  For accuracy\u2013type metrics (the names contain\n\u201cswa\u201d) the maximum value is selected, while for loss metrics the minimum value\nis selected.  Outputs are clearly labeled with both the dataset name and an\nexplicit metric name such as \u201ctrain shape-weighted accuracy\u201d or \u201cvalidation\nloss\u201d.  No plots are generated and the code executes immediately when run.", "This script loads the saved experiment_data.npy file from the \u201cworking\u201d\ndirectory, iterates over every dataset entry, and reports the best value\nobserved for each stored metric.  For accuracy\u2013type metrics (the names contain\n\u201cswa\u201d) the maximum value is selected, while for loss metrics the minimum value\nis selected.  Outputs are clearly labeled with both the dataset name and an\nexplicit metric name such as \u201ctrain shape-weighted accuracy\u201d or \u201cvalidation\nloss\u201d.  No plots are generated and the code executes immediately when run.", "This script loads the saved experiment_data.npy file from the \u201cworking\u201d\ndirectory, iterates over every dataset entry, and reports the best value\nobserved for each stored metric.  For accuracy\u2013type metrics (the names contain\n\u201cswa\u201d) the maximum value is selected, while for loss metrics the minimum value\nis selected.  Outputs are clearly labeled with both the dataset name and an\nexplicit metric name such as \u201ctrain shape-weighted accuracy\u201d or \u201cvalidation\nloss\u201d.  No plots are generated and the code executes immediately when run.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ------------------ load experiment data ------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy in {working_dir}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------ parse and report metrics ------------------\nepochs_tuning = experiment_data.get(\"epochs_tuning\", {})\n\nfor dataset_name, record in epochs_tuning.items():\n    print(f\"Dataset: {dataset_name}\")\n\n    # Gather stored series\n    train_losses = record.get(\"losses\", {}).get(\"train\", [])\n    val_losses = record.get(\"losses\", {}).get(\"val\", [])\n    train_rcwa = record.get(\"metrics\", {}).get(\"train_rcwa\", [])\n    val_rcwa = record.get(\"metrics\", {}).get(\"val_rcwa\", [])\n\n    # Compute desired values (handle missing data gracefully)\n    if train_losses:\n        final_train_loss = train_losses[-1]\n        print(f\"Training loss (final): {final_train_loss:.4f}\")\n\n    if val_losses:\n        best_val_loss = min(val_losses)\n        print(f\"Validation loss (best): {best_val_loss:.4f}\")\n\n    if train_rcwa:\n        final_train_rcwa = train_rcwa[-1]\n        print(f\"Training RCWA (final): {final_train_rcwa:.4f}\")\n\n    if val_rcwa:\n        best_val_rcwa = max(val_rcwa)\n        print(f\"Validation RCWA (best): {best_val_rcwa:.4f}\")\n\n    preds = record.get(\"predictions\", None)\n    gts = record.get(\"ground_truth\", None)\n    if (\n        preds is not None\n        and gts is not None\n        and len(preds) == len(gts)\n        and len(preds) > 0\n    ):\n        test_accuracy = (preds == gts).mean()\n        print(f\"Test accuracy: {test_accuracy:.4f}\")\n\n    print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper ----------\ndef accuracy(preds, gts):\n    preds = np.asarray(preds)\n    gts = np.asarray(gts)\n    if preds.size == 0:\n        return float(\"nan\")\n    return (preds == gts).mean()\n\n\n# ---------- iterate and report ----------\nfor dset_name, rec in experiment_data.items():\n    print(dset_name)  # dataset header\n\n    # training metrics (take last entry)\n    if rec[\"losses\"][\"train\"]:\n        print(\"final training loss:\", rec[\"losses\"][\"train\"][-1])\n    if rec[\"metrics\"][\"train_SWA\"]:\n        print(\"final training SWA:\", rec[\"metrics\"][\"train_SWA\"][-1])\n\n    # validation metrics (use best SWA, last loss)\n    if rec[\"losses\"][\"val\"]:\n        print(\"final validation loss:\", rec[\"losses\"][\"val\"][-1])\n    if rec[\"metrics\"][\"val_SWA\"]:\n        best_val_swa = max(rec[\"metrics\"][\"val_SWA\"])\n        print(\"best validation SWA:\", best_val_swa)\n\n    # test metrics (compute accuracy if predictions are saved)\n    preds = rec.get(\"predictions\", [])\n    gts = rec.get(\"ground_truth\", [])\n    if len(preds) and len(gts):\n        print(\"test accuracy:\", accuracy(preds, gts))\n\n    # blank line between datasets\n    print()\n", "import os\nimport numpy as np\n\n# -------------------- load the saved experiment --------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------------------- helper for pretty print --------------------\ndef print_metric(name: str, value: float):\n    print(f\"    {name}: {value:.6f}\")\n\n\n# -------------------- iterate over datasets & report --------------------\nfor dataset_name, rec in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # Losses\n    train_losses = rec.get(\"losses\", {}).get(\"train\", [])\n    val_losses = rec.get(\"losses\", {}).get(\"val\", [])\n\n    if train_losses:\n        print_metric(\"training loss (final epoch)\", train_losses[-1])\n    if val_losses:\n        print_metric(\"validation loss (best epoch)\", min(val_losses))\n\n    # Shape-weighted accuracies\n    train_swa = rec.get(\"metrics\", {}).get(\"train_swa\", [])\n    val_swa = rec.get(\"metrics\", {}).get(\"val_swa\", [])\n\n    if train_swa:\n        print_metric(\"training shape-weighted accuracy (final epoch)\", train_swa[-1])\n    if val_swa:\n        print_metric(\"validation shape-weighted accuracy (best epoch)\", max(val_swa))\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper to choose best/final ----------\ndef pick_value(name, values, want_best=True):\n    \"\"\"\n    Return either the best (max for scores, min for losses) or final value.\n    If want_best=False, always return the last value in the list.\n    \"\"\"\n    if not values:  # empty list\n        return None\n    if not want_best:  # just give final\n        return values[-1]\n    # decide direction automatically: losses -> lower is better\n    if \"loss\" in name.lower():\n        return min(values)\n    # otherwise higher is better\n    return max(values)\n\n\n# ---------- reporting ----------\nfor dataset_name, rec in experiment_data.items():\n    print(f\"\\n{dataset_name}\")  # dataset heading\n\n    # metrics (scores)\n    metrics = rec.get(\"metrics\", {})\n    if \"train_swa\" in metrics:\n        val = pick_value(\"train_swa\", metrics[\"train_swa\"], want_best=False)\n        if val is not None:\n            print(f\"training shape-weighted accuracy: {val:.4f}\")\n\n    if \"val_swa\" in metrics:\n        val = pick_value(\"val_swa\", metrics[\"val_swa\"], want_best=True)\n        if val is not None:\n            print(f\"validation shape-weighted accuracy (best): {val:.4f}\")\n\n    # losses\n    losses = rec.get(\"losses\", {})\n    if \"train\" in losses:\n        val = pick_value(\"train_loss\", losses[\"train\"], want_best=False)\n        if val is not None:\n            print(f\"training loss (final): {val:.4f}\")\n\n    if \"val\" in losses:\n        val = pick_value(\"validation_loss\", losses[\"val\"], want_best=True)\n        if val is not None:\n            print(f\"validation loss (best): {val:.4f}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------------------------------\n# locate and load the experiment data\n# -------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_path):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_path}\")\n\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------------------------------\n# small helpers\n# -------------------------------------------------------------------------\ndef _beautify_metric_name(raw_key: str) -> str:\n    \"\"\"\n    Convert keys such as 'train_swa' or 'val' (inside the losses dict)\n    into readable labels like 'training shape-weighted accuracy' or\n    'validation loss'.\n    \"\"\"\n    # Handle the special case where losses dict uses plain 'train'/'val'\n    if raw_key in {\"train\", \"val\", \"test\"}:\n        prefix_map = {\"train\": \"training\", \"val\": \"validation\", \"test\": \"test\"}\n        return f\"{prefix_map[raw_key]} loss\"\n\n    # For keys such as train_swa, val_f1 etc.\n    parts = raw_key.split(\"_\", 1)\n    if len(parts) == 2:\n        split, metric = parts\n        split_map = {\"train\": \"training\", \"val\": \"validation\", \"test\": \"test\"}\n        metric = metric.replace(\"_\", \" \")\n        return f\"{split_map.get(split, split)} {metric}\"\n    return raw_key.replace(\"_\", \" \")\n\n\ndef _select_best(label: str, values):\n    \"\"\"\n    Choose the 'best' value:\n    - for losses  : the minimum\n    - for others  : the maximum\n    \"\"\"\n    if not values:\n        return None\n    if \"loss\" in label.lower():\n        return float(min(values))\n    return float(max(values))\n\n\n# -------------------------------------------------------------------------\n# iterate and print\n# -------------------------------------------------------------------------\nfor ds_name, ds_blob in experiment_data.items():\n    print(ds_name)  # dataset title first\n\n    # losses\n    for key, values in ds_blob.get(\"losses\", {}).items():\n        metric_label = _beautify_metric_name(key)\n        best_val = _select_best(metric_label, values)\n        if best_val is not None:\n            print(f\"{metric_label}: {best_val:.4f}\")\n\n    # other metrics (accuracies, F1, etc.)\n    for key, values in ds_blob.get(\"metrics\", {}).items():\n        metric_label = _beautify_metric_name(key)\n        best_val = _select_best(metric_label, values)\n        if best_val is not None:\n            print(f\"{metric_label}: {best_val:.4f}\")\n\n    # add a blank line between datasets for readability\n    print()\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate and load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# helper to compute plain accuracy\ndef accuracy(y_true, y_pred):\n    if len(y_true) == 0:\n        return float(\"nan\")\n    y_true = np.asarray(y_true)\n    y_pred = np.asarray(y_pred)\n    return (y_true == y_pred).mean()\n\n\n# ------------------------------------------------------------------\n# iterate over datasets and print metrics\nfor dataset_name, rec in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # losses\n    train_losses = rec.get(\"losses\", {}).get(\"train\", [])\n    val_losses = rec.get(\"losses\", {}).get(\"val\", [])\n    if train_losses:\n        print(f\"training loss: {train_losses[-1]:.6f}\")\n    if val_losses:\n        print(f\"validation loss: {val_losses[-1]:.6f}\")\n\n    # SWA metrics\n    train_swa = rec.get(\"metrics\", {}).get(\"train_swa\", [])\n    val_swa = rec.get(\"metrics\", {}).get(\"val_swa\", [])\n    if train_swa:\n        print(f\"training shape-weighted accuracy: {train_swa[-1]:.6f}\")\n    if val_swa:\n        print(f\"validation shape-weighted accuracy: {val_swa[-1]:.6f}\")\n\n    # test accuracy (plain)\n    preds = rec.get(\"predictions\", [])\n    gts = rec.get(\"ground_truth\", [])\n    if len(preds) and len(gts):\n        test_acc = accuracy(gts, preds)\n        print(f\"test accuracy: {test_acc:.6f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- helper to map metric keys to nice names ----------\nNAME_MAP = {\n    \"train\": \"train loss\",\n    \"val\": \"validation loss\",\n    \"train_swa\": \"train shape-weighted accuracy\",\n    \"val_swa\": \"validation shape-weighted accuracy\",\n}\n\n\ndef is_loss(metric_key: str) -> bool:\n    \"\"\"Heuristic: any key containing 'loss' or exactly 'train'/'val' in the\n    losses dict is considered a loss metric (lower is better).\"\"\"\n    return \"loss\" in metric_key or metric_key in {\"train\", \"val\"}\n\n\n# ---------- print best/final metrics ----------\nfor dataset_name, rec in experiment_data.items():\n    print(f\"Dataset: {dataset_name}\")\n\n    # losses\n    for key, values in rec.get(\"losses\", {}).items():\n        if not values:\n            continue\n        values = np.asarray(values, dtype=float)\n        best_val = values.min() if is_loss(key) else values.max()\n        metric_name = NAME_MAP.get(key, key)\n        print(f\"  {metric_name}: {best_val:.4f}\")\n\n    # other metrics\n    for key, values in rec.get(\"metrics\", {}).items():\n        if not values:\n            continue\n        values = np.asarray(values, dtype=float)\n        best_val = values.min() if is_loss(key) else values.max()\n        metric_name = NAME_MAP.get(key, key)\n        print(f\"  {metric_name}: {best_val:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------- working directory ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# ---------------- load experiment data ------------\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nif not os.path.isfile(exp_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy at {exp_path}\")\n\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------------- helper: safe extraction ----------\ndef _last(seq):\n    return seq[-1] if seq else None\n\n\ndef _fmt(val, precision=4):\n    if val is None:\n        return \"N/A\"\n    if isinstance(val, float):\n        return f\"{val:.{precision}f}\"\n    return str(val)\n\n\n# ---------------- iterate over datasets ------------\nfor ds_name, ds_rec in experiment_data.items():\n    print(f\"\\nDataset: {ds_name}\")\n\n    # Losses\n    train_loss_final = _last(ds_rec.get(\"losses\", {}).get(\"train\", []))\n    val_loss_final = _last(ds_rec.get(\"losses\", {}).get(\"val\", []))\n\n    # Shape-weighted accuracy (SWA)\n    train_swa_final = _last(ds_rec.get(\"metrics\", {}).get(\"train_swa\", []))\n    val_swa_list = ds_rec.get(\"metrics\", {}).get(\"val_swa\", [])\n    val_swa_final = _last(val_swa_list)\n    val_swa_best = max(val_swa_list) if val_swa_list else None\n\n    # Test accuracy (if predictions available)\n    preds = np.asarray(ds_rec.get(\"predictions\", []))\n    gts = np.asarray(ds_rec.get(\"ground_truth\", []))\n    test_acc = float((preds == gts).mean()) if preds.size and gts.size else None\n\n    # --------- print metrics -------------\n    print(f\"training loss: { _fmt(train_loss_final) }\")\n    print(f\"validation loss: { _fmt(val_loss_final) }\")\n\n    print(f\"training shape-weighted accuracy: { _fmt(train_swa_final) }\")\n    print(f\"validation shape-weighted accuracy (final): { _fmt(val_swa_final) }\")\n    print(f\"validation shape-weighted accuracy (best):  { _fmt(val_swa_best) }\")\n\n    print(f\"test classification accuracy: { _fmt(test_acc) }\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load experiment file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_file}\")\n\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n\n# ---------- helper for selecting best value ----------\ndef pick_best(values, bigger_is_better=True):\n    \"\"\"Return the best (max or min) from a list/array of numeric values.\"\"\"\n    if not values:\n        return None\n    return max(values) if bigger_is_better else min(values)\n\n\n# readable names for printing\nlabel_map = {\n    \"train_swa\": \"train shape-weighted accuracy\",\n    \"val_swa\": \"validation shape-weighted accuracy\",\n    \"train\": \"train loss\",\n    \"val\": \"validation loss\",\n}\n\n# ---------- iterate through stored datasets ----------\nfor dataset_name, record in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n    # process metrics that are in 'metrics' or 'losses'\n    for group_key, bigger_is_better in ((\"metrics\", True), (\"losses\", False)):\n        if group_key not in record:\n            continue\n        for metric_key, values in record[group_key].items():\n            pretty_name = label_map.get(metric_key, metric_key)\n            best_val = pick_best(values, bigger_is_better=bigger_is_better)\n            # skip None or empty lists\n            if best_val is None:\n                continue\n            if isinstance(best_val, (float, np.floating)):\n                print(f\"{pretty_name}: {best_val:.4f}\")\n            else:\n                print(f\"{pretty_name}: {best_val}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load experiment file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_file}\")\n\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n\n# ---------- helper for selecting best value ----------\ndef pick_best(values, bigger_is_better=True):\n    \"\"\"Return the best (max or min) from a list/array of numeric values.\"\"\"\n    if not values:\n        return None\n    return max(values) if bigger_is_better else min(values)\n\n\n# readable names for printing\nlabel_map = {\n    \"train_swa\": \"train shape-weighted accuracy\",\n    \"val_swa\": \"validation shape-weighted accuracy\",\n    \"train\": \"train loss\",\n    \"val\": \"validation loss\",\n}\n\n# ---------- iterate through stored datasets ----------\nfor dataset_name, record in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n    # process metrics that are in 'metrics' or 'losses'\n    for group_key, bigger_is_better in ((\"metrics\", True), (\"losses\", False)):\n        if group_key not in record:\n            continue\n        for metric_key, values in record[group_key].items():\n            pretty_name = label_map.get(metric_key, metric_key)\n            best_val = pick_best(values, bigger_is_better=bigger_is_better)\n            # skip None or empty lists\n            if best_val is None:\n                continue\n            if isinstance(best_val, (float, np.floating)):\n                print(f\"{pretty_name}: {best_val:.4f}\")\n            else:\n                print(f\"{pretty_name}: {best_val}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load experiment file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_file}\")\n\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n\n# ---------- helper for selecting best value ----------\ndef pick_best(values, bigger_is_better=True):\n    \"\"\"Return the best (max or min) from a list/array of numeric values.\"\"\"\n    if not values:\n        return None\n    return max(values) if bigger_is_better else min(values)\n\n\n# readable names for printing\nlabel_map = {\n    \"train_swa\": \"train shape-weighted accuracy\",\n    \"val_swa\": \"validation shape-weighted accuracy\",\n    \"train\": \"train loss\",\n    \"val\": \"validation loss\",\n}\n\n# ---------- iterate through stored datasets ----------\nfor dataset_name, record in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n    # process metrics that are in 'metrics' or 'losses'\n    for group_key, bigger_is_better in ((\"metrics\", True), (\"losses\", False)):\n        if group_key not in record:\n            continue\n        for metric_key, values in record[group_key].items():\n            pretty_name = label_map.get(metric_key, metric_key)\n            best_val = pick_best(values, bigger_is_better=bigger_is_better)\n            # skip None or empty lists\n            if best_val is None:\n                continue\n            if isinstance(best_val, (float, np.floating)):\n                print(f\"{pretty_name}: {best_val:.4f}\")\n            else:\n                print(f\"{pretty_name}: {best_val}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load experiment file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_file}\")\n\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n\n# ---------- helper for selecting best value ----------\ndef pick_best(values, bigger_is_better=True):\n    \"\"\"Return the best (max or min) from a list/array of numeric values.\"\"\"\n    if not values:\n        return None\n    return max(values) if bigger_is_better else min(values)\n\n\n# readable names for printing\nlabel_map = {\n    \"train_swa\": \"train shape-weighted accuracy\",\n    \"val_swa\": \"validation shape-weighted accuracy\",\n    \"train\": \"train loss\",\n    \"val\": \"validation loss\",\n}\n\n# ---------- iterate through stored datasets ----------\nfor dataset_name, record in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n    # process metrics that are in 'metrics' or 'losses'\n    for group_key, bigger_is_better in ((\"metrics\", True), (\"losses\", False)):\n        if group_key not in record:\n            continue\n        for metric_key, values in record[group_key].items():\n            pretty_name = label_map.get(metric_key, metric_key)\n            best_val = pick_best(values, bigger_is_better=bigger_is_better)\n            # skip None or empty lists\n            if best_val is None:\n                continue\n            if isinstance(best_val, (float, np.floating)):\n                print(f\"{pretty_name}: {best_val:.4f}\")\n            else:\n                print(f\"{pretty_name}: {best_val}\")\n", ""], "parse_term_out": ["['Dataset: SPR_BENCH', '\\n', 'Training loss (final): 0.5198', '\\n', 'Validation\nloss (best): 0.5210', '\\n', 'Training RCWA (final): 0.7518', '\\n', 'Validation\nRCWA (best): 0.7648', '\\n', 'Test accuracy: 0.6204', '\\n', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'final training loss:', ' ', '0.1716961413383484', '\\n',\n'final training SWA:', ' ', '0.9443855855332859', '\\n', 'final validation\nloss:', ' ', '0.17271616201996803', '\\n', 'best validation SWA:', ' ',\n'0.9446575979537263', '\\n', 'test accuracy:', ' ', '0.6951', '\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', '    training loss (final epoch): 0.166078',\n'\\n', '    validation loss (best epoch): 0.168127', '\\n', '    training shape-\nweighted accuracy (final epoch): 0.944487', '\\n', '    validation shape-weighted\naccuracy (best epoch): 0.944658', '\\n', 'Execution time: a moment seconds (time\nlimit is 30 minutes).']", "['\\nSPR_BENCH', '\\n', 'training shape-weighted accuracy: 0.9446', '\\n',\n'validation shape-weighted accuracy (best): 0.9447', '\\n', 'training loss\n(final): 0.1642', '\\n', 'validation loss (best): 0.1660', '\\n', 'Execution time:\na moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'training loss: 0.1738', '\\n', 'validation loss: 0.1706',\n'\\n', 'training swa: 0.9446', '\\n', 'validation swa: 0.9447', '\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'training loss: 0.017313', '\\n', 'validation\nloss: 0.016038', '\\n', 'training shape-weighted accuracy: 0.997213', '\\n',\n'validation shape-weighted accuracy: 0.996047', '\\n', 'test accuracy: 0.701500',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', '  train loss: 0.0691', '\\n', '  validation loss:\n0.0138', '\\n', '  train shape-weighted accuracy: 0.9971', '\\n', '  validation\nshape-weighted accuracy: 0.9960', '\\n', 'Execution time: a moment seconds (time\nlimit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'training loss: 0.0023', '\\n', 'validation loss:\n0.0065', '\\n', 'training shape-weighted accuracy: 0.9988', '\\n', 'validation\nshape-weighted accuracy (final): 0.9986', '\\n', 'validation shape-weighted\naccuracy (best):  0.9998', '\\n', 'test classification accuracy: 0.6995', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'train shape-weighted accuracy: 1.0000', '\\n',\n'validation shape-weighted accuracy: 1.0000', '\\n', 'train loss: 0.0026', '\\n',\n'validation loss: 0.0003', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'train shape-weighted accuracy: 1.0000', '\\n',\n'validation shape-weighted accuracy: 0.9993', '\\n', 'train loss: 0.0027', '\\n',\n'validation loss: 0.0018', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'train shape-weighted accuracy: 0.9994', '\\n',\n'validation shape-weighted accuracy: 0.9995', '\\n', 'train loss: 0.0044', '\\n',\n'validation loss: 0.0031', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'train shape-weighted accuracy: 0.9999', '\\n',\n'validation shape-weighted accuracy: 0.9994', '\\n', 'train loss: 0.0021', '\\n',\n'validation loss: 0.0016', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3"]}