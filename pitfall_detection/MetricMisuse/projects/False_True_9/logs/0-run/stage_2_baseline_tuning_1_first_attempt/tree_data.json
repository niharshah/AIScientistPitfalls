{"edges": [[0, 2], [0, 1], [0, 3], [0, 4]], "layout": [[0.5, 0.0], [0.0, 1.0], [0.3333333333333333, 1.0], [0.6666666666666666, 1.0], [1.0, 1.0]], "plan": ["The previous script crashed because it used a hard-coded absolute path for the\nSPR_BENCH folder, which inevitably fails on machines with a different directory\nlayout.   We make the path resolution robust by: (1) accepting an optional\nenvironment variable SPR_DATA_PATH; (2) searching a list of sensible fallback\nlocations relative to the current script; and (3) raising a clear error if the\ndataset is still not found.   No other logic changes are required, so the rest\nof the pipeline (tokenisation, model, training loop, metric logging, saving)\nremains the same but now runs successfully on any machine that actually has the\ndataset.", "Hyperparam tuning name: EPOCHS. We will tune the single hyper-parameter \u201cnumber\nof training epochs\u201d.   For each candidate epoch budget (e.g. 6, 12, 18) we: (1)\nre-initialise the BiLSTM, (2) train for that many epochs while logging per-epoch\ntrain/validation losses and weighted accuracies, and (3) store everything in\n`experiment_data['epochs_tuning']['SPR_BENCH']['runs']`.   After all runs finish\nwe save the collected data as `experiment_data.npy`.", "Hyperparam tuning name: Learning Rate. The solution trains an independent BiLSTM\nfrom scratch for each learning-rate in a small logarithmic sweep (3e-4, 1e-3,\n3e-3).   The script reuses all dataset, dataloader and metric utilities, but\nwraps the training/validation loop in a function that is invoked per lr value;\nresults are stored under\nexperiment_data['learning_rate']['SPR_BENCH'][lr_as_str].   Everything (loss\ncurves, metrics, predictions, ground-truth) is collected epoch-by-epoch and\nsaved to experiment_data.npy at the end.", "Hyperparam tuning name: Batch Size. We will explore batch sizes [32, 64, 128,\n256].   For every batch size we rebuild the DataLoader, initialize a fresh Bi-\nLSTM model, train for 6 epochs, evaluate on the dev set, and log losses plus\n(SWA, CWA, HWA).   Results are stored under experiment_data['batch_size'][<bs>]\nand finally persisted to \u2018experiment_data.npy\u2019.   Nothing else in the training\nprocedure is changed, ensuring a pure batch-size study.", "Hyperparam tuning name: hidden_dim (LSTM hidden size). The script below extends\nthe baseline by sweeping over several LSTM hidden sizes (64, 128, 256, 512).\nFor every hidden_dim the model is (re)-initialised, trained for a few epochs,\nevaluated on the dev split each epoch, and all losses / metrics are stored in an\n`experiment_data` structure keyed by the hyper-parameter value.   Everything is\nself-contained, uses the same data-loading / model code as the baseline, and\nfinally saves `experiment_data.npy`."], "code": ["import os, pathlib, numpy as np, torch, torch.nn as nn, random, math, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working directory & device -----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- locate SPR_BENCH ---------------------\ndef find_spr_bench() -> pathlib.Path:\n    \"\"\"Try several candidate locations; honour env-var if provided.\"\"\"\n    candidates = []\n    env_path = os.environ.get(\"SPR_DATA_PATH\")\n    if env_path:\n        candidates.append(env_path)\n    # common relative fallbacks\n    candidates += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in candidates:\n        if p and pathlib.Path(p).expanduser().joinpath(\"train.csv\").exists():\n            return pathlib.Path(p).expanduser().resolve()\n    raise FileNotFoundError(\n        \"Could not find SPR_BENCH dataset. \"\n        \"Set environment variable SPR_DATA_PATH or place the folder next to this script.\"\n    )\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ---------- helper: load SPR_BENCH --------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\n# ---------- load dataset ------------------------\nspr = load_spr_bench(DATA_PATH)\n\n# ---------- build vocabulary -------------------\nall_tokens = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq: str):\n    return [token2id[tok] for tok in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size = {vocab_size},  num_classes = {num_classes}\")\n\n\n# ---------- PyTorch Dataset --------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.encoded = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.encoded[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(item[\"input_ids\"]) for item in batch)\n    input_ids, labels, raw = [], [], []\n    for item in batch:\n        seq = item[\"input_ids\"]\n        pad_len = maxlen - len(seq)\n        if pad_len:\n            seq = torch.cat([seq, torch.full((pad_len,), PAD_ID, dtype=torch.long)])\n        input_ids.append(seq)\n        labels.append(item[\"label\"])\n        raw.append(item[\"raw_seq\"])\n    return {\n        \"input_ids\": torch.stack(input_ids),\n        \"label\": torch.stack(labels),\n        \"raw_seq\": raw,\n    }\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ---------- model ------------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)  # [B,L,E]\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], dim=1)  # [B,2H]\n        return self.fc(out)\n\n\nmodel = BiLSTMClassifier(vocab_size, num_cls=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------- experiment data container ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ---------- training loop ----------------------\nEPOCHS = 6\nfor epoch in range(1, EPOCHS + 1):\n    # -- training --\n    model.train()\n    total_loss, n_batch = 0.0, 0\n    for batch in train_loader:\n        # move tensors to device\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        n_batch += 1\n    train_loss = total_loss / n_batch\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append((epoch, train_loss))\n\n    # -- validation --\n    model.eval()\n    val_loss_tot, nb = 0.0, 0\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            val_loss_tot += loss.item()\n            nb += 1\n            preds = logits.argmax(-1).cpu().tolist()\n            labels = batch[\"label\"].cpu().tolist()\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n            all_seqs.extend(batch[\"raw_seq\"])\n    val_loss = val_loss_tot / nb\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append((epoch, val_loss))\n\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    hwa = harmonic_weighted_accuracy(swa, cwa)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = all_preds\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_labels\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n        f\"SWA={swa:.4f}  CWA={cwa:.4f}  HWA={hwa:.4f}\"\n    )\n\n# ---------- save experiment data ---------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved experiment data to {os.path.join(working_dir, 'experiment_data.npy')}\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, random, math, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working directory & device -----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- locate SPR_BENCH ---------------------\ndef find_spr_bench() -> pathlib.Path:\n    candidates = []\n    env_path = os.environ.get(\"SPR_DATA_PATH\")\n    if env_path:\n        candidates.append(env_path)\n    candidates += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in candidates:\n        if p and pathlib.Path(p).expanduser().joinpath(\"train.csv\").exists():\n            return pathlib.Path(p).expanduser().resolve()\n    raise FileNotFoundError(\n        \"Could not find SPR_BENCH dataset. \"\n        \"Set environment variable SPR_DATA_PATH or place the folder next to this script.\"\n    )\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ---------- helper: load SPR_BENCH --------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\n# ---------- load dataset ------------------------\nspr = load_spr_bench(DATA_PATH)\n\n# ---------- build vocabulary -------------------\nall_tokens = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq: str):\n    return [token2id[tok] for tok in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size = {vocab_size},  num_classes = {num_classes}\")\n\n\n# ---------- PyTorch Dataset --------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.encoded = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.encoded[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(item[\"input_ids\"]) for item in batch)\n    input_ids, labels, raw = [], [], []\n    for item in batch:\n        seq = item[\"input_ids\"]\n        pad_len = maxlen - len(seq)\n        if pad_len:\n            seq = torch.cat([seq, torch.full((pad_len,), PAD_ID, dtype=torch.long)])\n        input_ids.append(seq)\n        labels.append(item[\"label\"])\n        raw.append(item[\"raw_seq\"])\n    return {\n        \"input_ids\": torch.stack(input_ids),\n        \"label\": torch.stack(labels),\n        \"raw_seq\": raw,\n    }\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ---------- model ------------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], dim=1)\n        return self.fc(out)\n\n\n# ---------- experiment data container ----------\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"SPR_BENCH\": {\"runs\": []}  # list of dicts, one per epoch-budget run\n    }\n}\n\n# ---------- hyper-parameter values -------------\nEPOCH_BUDGETS = [6, 12, 18]  # try three settings\n\nfor budget in EPOCH_BUDGETS:\n    print(f\"\\n=== Training for {budget} epochs ===\")\n    model = BiLSTMClassifier(vocab_size, num_cls=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    run_record = {\n        \"epochs\": budget,\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, budget + 1):\n        # -- training --\n        model.train()\n        total_loss, n_batch = 0.0, 0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            n_batch += 1\n        train_loss = total_loss / n_batch\n        run_record[\"losses\"][\"train\"].append((epoch, train_loss))\n\n        # -- validation --\n        model.eval()\n        val_loss_tot, nb = 0.0, 0\n        all_preds, all_labels, all_seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss_tot += loss.item()\n                nb += 1\n                preds = logits.argmax(-1).cpu().tolist()\n                labels = batch[\"label\"].cpu().tolist()\n                all_preds.extend(preds)\n                all_labels.extend(labels)\n                all_seqs.extend(batch[\"raw_seq\"])\n        val_loss = val_loss_tot / nb\n        run_record[\"losses\"][\"val\"].append((epoch, val_loss))\n\n        swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n        cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        run_record[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n        print(\n            f\"Epoch {epoch}/{budget}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n            f\"SWA={swa:.4f}  CWA={cwa:.4f}  HWA={hwa:.4f}\"\n        )\n\n    # store last validation predictions/labels for this run\n    run_record[\"predictions\"] = all_preds\n    run_record[\"ground_truth\"] = all_labels\n    experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"runs\"].append(run_record)\n\n# ---------- save experiment data ---------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment data to {os.path.join(working_dir, 'experiment_data.npy')}\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, random, math, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# --------- reproducibility ----------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic, torch.backends.cudnn.benchmark = True, False\n\n# ---------- working directory -------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- locate SPR_BENCH --------\ndef find_spr_bench() -> pathlib.Path:\n    env = os.environ.get(\"SPR_DATA_PATH\")\n    cand = [env] if env else []\n    cand += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in cand:\n        if p and pathlib.Path(p).expanduser().joinpath(\"train.csv\").exists():\n            return pathlib.Path(p).expanduser().resolve()\n    raise FileNotFoundError(\"SPR_BENCH not found.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(\"Found SPR_BENCH at\", DATA_PATH)\n\n\n# ---------- helpers & metrics -------\ndef load_spr_bench(root):\n    def _load(name):\n        return load_dataset(\n            \"csv\", data_files=str(root / name), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"] = _load(\"train.csv\")\n    d[\"dev\"] = _load(\"dev.csv\")\n    d[\"test\"] = _load(\"test.csv\")\n    return d\n\n\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.split()))\n\n\ndef count_color_variety(seq):\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\n# ---------- dataset -----------------\nspr = load_spr_bench(DATA_PATH)\nall_tokens = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq):\n    return [token2id[t] for t in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.encoded = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.encoded[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(it[\"input_ids\"]) for it in batch)\n    inp, lab, raw = [], [], []\n    for it in batch:\n        seq = it[\"input_ids\"]\n        if maxlen - len(seq):\n            seq = torch.cat(\n                [seq, torch.full((maxlen - len(seq),), PAD_ID, dtype=torch.long)]\n            )\n        inp.append(seq)\n        lab.append(it[\"label\"])\n        raw.append(it[\"raw_seq\"])\n    return {\"input_ids\": torch.stack(inp), \"label\": torch.stack(lab), \"raw_seq\": raw}\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ---------- model -------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], 1)\n        return self.fc(out)\n\n\n# --------- experiment container -----\nexperiment_data = {\"learning_rate\": {\"SPR_BENCH\": {}}}\n\n\n# --------- training routine ---------\ndef train_and_eval(lr, epochs=6):\n    model = BiLSTMClassifier(vocab_size, num_cls=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    rec = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for ep in range(1, epochs + 1):\n        # train\n        model.train()\n        tot_loss = 0\n        nb = 0\n        for batch in train_loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item()\n            nb += 1\n        tr_loss = tot_loss / nb\n        rec[\"losses\"][\"train\"].append((ep, tr_loss))\n        # val\n        model.eval()\n        tot, nb = 0, 0\n        preds, labels, seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                tot += loss.item()\n                nb += 1\n                p = logits.argmax(-1).cpu().tolist()\n                l = batch[\"label\"].cpu().tolist()\n                preds.extend(p)\n                labels.extend(l)\n                seqs.extend(batch[\"raw_seq\"])\n        v_loss = tot / nb\n        rec[\"losses\"][\"val\"].append((ep, v_loss))\n        swa = shape_weighted_accuracy(seqs, labels, preds)\n        cwa = color_weighted_accuracy(seqs, labels, preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        rec[\"metrics\"][\"val\"].append((ep, swa, cwa, hwa))\n        rec[\"predictions\"], rec[\"ground_truth\"] = preds, labels\n        print(\n            f\"[lr={lr}] Epoch {ep}: train_loss={tr_loss:.4f} val_loss={v_loss:.4f} \"\n            f\"SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n    return rec\n\n\n# --------- hyperparameter sweep -----\nfor lr in [3e-4, 1e-3, 3e-3]:\n    torch.cuda.empty_cache()\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][str(lr)] = train_and_eval(lr)\n    del lr\n\n# --------- save ---------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, random, math, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- reproducibility ----------\ntorch.manual_seed(0)\nnp.random.seed(0)\nrandom.seed(0)\n\n# ---------- experiment container -----\nexperiment_data = {\"batch_size\": {}}\n\n# ---------- working directory ---------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- locate SPR_BENCH ----------\ndef find_spr_bench() -> pathlib.Path:\n    candidates = []\n    env_path = os.environ.get(\"SPR_DATA_PATH\")\n    if env_path:\n        candidates.append(env_path)\n    candidates += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in candidates:\n        if p and pathlib.Path(p).expanduser().joinpath(\"train.csv\").exists():\n            return pathlib.Path(p).expanduser().resolve()\n    raise FileNotFoundError(\"Could not find SPR_BENCH dataset.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ---------- helpers -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_shape_variety(sequence: str):\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str):\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0\n\n\n# ---------- load dataset & vocab ------\nspr = load_spr_bench(DATA_PATH)\nall_tokens = set()\n[all_tokens.update(ex[\"sequence\"].split()) for ex in spr[\"train\"]]\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq: str):\n    return [token2id[t] for t in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size={vocab_size}, classes={num_classes}\")\n\n\n# ---------- Dataset wrappers ----------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.enc = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.enc[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(item[\"input_ids\"]) for item in batch)\n    inp, lab, raw = [], [], []\n    for item in batch:\n        seq = item[\"input_ids\"]\n        pad = maxlen - len(seq)\n        if pad:\n            seq = torch.cat([seq, torch.full((pad,), PAD_ID, dtype=torch.long)])\n        inp.append(seq)\n        lab.append(item[\"label\"])\n        raw.append(item[\"raw_seq\"])\n    return {\"input_ids\": torch.stack(inp), \"label\": torch.stack(lab), \"raw_seq\": raw}\n\n\n# ---------- model ---------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], dim=1)\n        return self.fc(out)\n\n\n# ---------- hyperparameter tuning -----\nBATCH_SIZES = [32, 64, 128, 256]\nEPOCHS = 6\nfor bs in BATCH_SIZES:\n    print(f\"\\n======== Training with batch size {bs} ========\")\n    train_loader = DataLoader(\n        SPRTorchSet(spr[\"train\"]), batch_size=bs, shuffle=True, collate_fn=collate_fn\n    )\n    dev_loader = DataLoader(\n        SPRTorchSet(spr[\"dev\"]), batch_size=512, shuffle=False, collate_fn=collate_fn\n    )\n    model = BiLSTMClassifier(vocab_size, num_cls=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    exp_rec = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for epoch in range(1, EPOCHS + 1):\n        # training\n        model.train()\n        tot_loss = 0\n        n = 0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item()\n            n += 1\n        tr_loss = tot_loss / n\n        exp_rec[\"losses\"][\"train\"].append((epoch, tr_loss))\n\n        # validation\n        model.eval()\n        val_loss = 0\n        nb = 0\n        all_preds, all_labels, all_seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss += loss.item()\n                nb += 1\n                preds = logits.argmax(-1).cpu().tolist()\n                labs = batch[\"label\"].cpu().tolist()\n                all_preds.extend(preds)\n                all_labels.extend(labs)\n                all_seqs.extend(batch[\"raw_seq\"])\n        val_loss /= nb\n        exp_rec[\"losses\"][\"val\"].append((epoch, val_loss))\n        swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n        cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        exp_rec[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n        exp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = all_preds, all_labels\n        print(\n            f\"Epoch {epoch}: train_loss={tr_loss:.4f} val_loss={val_loss:.4f} SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n\n    experiment_data[\"batch_size\"][str(bs)] = exp_rec\n\n# ---------- save results --------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment data to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, random, math, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working directory & device -----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- locate SPR_BENCH ---------------------\ndef find_spr_bench() -> pathlib.Path:\n    cand = []\n    env_path = os.environ.get(\"SPR_DATA_PATH\")\n    if env_path:\n        cand.append(env_path)\n    cand += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in cand:\n        pth = pathlib.Path(p).expanduser()\n        if p and pth.joinpath(\"train.csv\").exists():\n            return pth.resolve()\n    raise FileNotFoundError(\n        \"SPR_BENCH not found; set SPR_DATA_PATH or place folder nearby.\"\n    )\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ---------- helper: load SPR_BENCH --------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\n# ---------- load dataset ------------------------\nspr = load_spr_bench(DATA_PATH)\n\n# ---------- build vocabulary -------------------\nall_tokens = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size = {vocab_size},  num_classes = {num_classes}\")\n\n\ndef encode(seq: str):\n    return [token2id[tok] for tok in seq.split()]\n\n\n# ---------- PyTorch Dataset --------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.encoded = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.encoded[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(item[\"input_ids\"]) for item in batch)\n    input_ids, labels, raw = [], [], []\n    for item in batch:\n        seq = item[\"input_ids\"]\n        pad_len = maxlen - len(seq)\n        if pad_len:\n            seq = torch.cat([seq, torch.full((pad_len,), PAD_ID, dtype=torch.long)])\n        input_ids.append(seq)\n        labels.append(item[\"label\"])\n        raw.append(item[\"raw_seq\"])\n    return {\n        \"input_ids\": torch.stack(input_ids),\n        \"label\": torch.stack(labels),\n        \"raw_seq\": raw,\n    }\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ---------- model ------------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], dim=1)\n        return self.fc(out)\n\n\n# ---------- experiment data container ----------\nexperiment_data = {\n    \"hidden_dim\": {\n        \"SPR_BENCH\": {\n            # each hidden size key will be filled later\n        }\n    }\n}\n\n# ---------- hyper-parameter grid ---------------\nhidden_grid = [64, 128, 256, 512]\nEPOCHS = 6\n\nfor hidden_size in hidden_grid:\n    print(f\"\\n=== Training with hidden_dim = {hidden_size} ===\")\n    model = BiLSTMClassifier(vocab_size, hidden=hidden_size, num_cls=num_classes).to(\n        device\n    )\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    # storage for this run\n    run_store = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        # ---- training ----\n        model.train()\n        tot_loss, nb = 0.0, 0\n        for batch in train_loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item()\n            nb += 1\n        train_loss = tot_loss / nb\n        run_store[\"losses\"][\"train\"].append((epoch, train_loss))\n\n        # ---- validation ----\n        model.eval()\n        val_loss_tot, nbv = 0.0, 0\n        all_preds, all_labels, all_seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss_tot += loss.item()\n                nbv += 1\n                preds = logits.argmax(-1).cpu().tolist()\n                labels = batch[\"label\"].cpu().tolist()\n                all_preds.extend(preds)\n                all_labels.extend(labels)\n                all_seqs.extend(batch[\"raw_seq\"])\n        val_loss = val_loss_tot / nbv\n        run_store[\"losses\"][\"val\"].append((epoch, val_loss))\n\n        swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n        cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        run_store[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n            f\"SWA={swa:.4f}  CWA={cwa:.4f}  HWA={hwa:.4f}\"\n        )\n\n    # store final predictions / labels from last epoch\n    run_store[\"predictions\"] = all_preds\n    run_store[\"ground_truth\"] = all_labels\n    experiment_data[\"hidden_dim\"][\"SPR_BENCH\"][str(hidden_size)] = run_store\n\n# ---------- save experiment data ---------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment data to {os.path.join(working_dir, 'experiment_data.npy')}\")\n"], "term_out": ["['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 517757.78\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 734219.79\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 875728.99\nexamples/s]', '\\n', 'Vocab size = 17,  num_classes = 2', '\\n', 'Epoch 1:\ntrain_loss=0.2051  val_loss=0.0845  SWA=0.9779  CWA=0.9774  HWA=0.9776', '\\n',\n'Epoch 2: train_loss=0.0490  val_loss=0.0258  SWA=0.9913  CWA=0.9910\nHWA=0.9912', '\\n', 'Epoch 3: train_loss=0.0148  val_loss=0.0066  SWA=0.9993\nCWA=0.9993  HWA=0.9993', '\\n', 'Epoch 4: train_loss=0.0047  val_loss=0.0027\nSWA=0.9993  CWA=0.9994  HWA=0.9993', '\\n', 'Epoch 5: train_loss=0.0017\nval_loss=0.0019  SWA=0.9998  CWA=0.9998  HWA=0.9998', '\\n', 'Epoch 6:\ntrain_loss=0.0007  val_loss=0.0015  SWA=0.9998  CWA=0.9998  HWA=0.9998', '\\n',\n'Saved experiment data to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-\n16_02-30-16_context_aware_contrastive_learning_attempt_0/0-\nrun/process_ForkProcess-2/working/experiment_data.npy', '\\n', 'Execution time: 6\nseconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 269269.55\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 374017.23\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 489314.26\nexamples/s]', '\\n', 'Vocab size = 17,  num_classes = 2', '\\n', '\\n=== Training\nfor 6 epochs ===', '\\n', 'Epoch 1/6: train_loss=0.2051  val_loss=0.0845\nSWA=0.9779  CWA=0.9774  HWA=0.9776', '\\n', 'Epoch 2/6: train_loss=0.0490\nval_loss=0.0258  SWA=0.9913  CWA=0.9910  HWA=0.9912', '\\n', 'Epoch 3/6:\ntrain_loss=0.0148  val_loss=0.0066  SWA=0.9993  CWA=0.9993  HWA=0.9993', '\\n',\n'Epoch 4/6: train_loss=0.0047  val_loss=0.0027  SWA=0.9993  CWA=0.9994\nHWA=0.9993', '\\n', 'Epoch 5/6: train_loss=0.0017  val_loss=0.0019  SWA=0.9998\nCWA=0.9998  HWA=0.9998', '\\n', 'Epoch 6/6: train_loss=0.0007  val_loss=0.0015\nSWA=0.9998  CWA=0.9998  HWA=0.9998', '\\n', '\\n=== Training for 12 epochs ===',\n'\\n', 'Epoch 1/12: train_loss=0.1885  val_loss=0.0736  SWA=0.9753  CWA=0.9749\nHWA=0.9751', '\\n', 'Epoch 2/12: train_loss=0.0481  val_loss=0.0325  SWA=0.9899\nCWA=0.9904  HWA=0.9902', '\\n', 'Epoch 3/12: train_loss=0.0181  val_loss=0.0114\nSWA=0.9960  CWA=0.9963  HWA=0.9962', '\\n', 'Epoch 4/12: train_loss=0.0051\nval_loss=0.0038  SWA=0.9995  CWA=0.9996  HWA=0.9996', '\\n', 'Epoch 5/12:\ntrain_loss=0.0016  val_loss=0.0022  SWA=0.9992  CWA=0.9992  HWA=0.9992', '\\n',\n'Epoch 6/12: train_loss=0.0008  val_loss=0.0014  SWA=0.9999  CWA=0.9998\nHWA=0.9999', '\\n', 'Epoch 7/12: train_loss=0.0005  val_loss=0.0010  SWA=1.0000\nCWA=1.0000  HWA=1.0000', '\\n', 'Epoch 8/12: train_loss=0.0003  val_loss=0.0010\nSWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n', 'Epoch 9/12: train_loss=0.0002\nval_loss=0.0009  SWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n', 'Epoch 10/12:\ntrain_loss=0.0002  val_loss=0.0008  SWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n',\n'Epoch 11/12: train_loss=0.0001  val_loss=0.0007  SWA=1.0000  CWA=1.0000\nHWA=1.0000', '\\n', 'Epoch 12/12: train_loss=0.0001  val_loss=0.0007  SWA=1.0000\nCWA=1.0000  HWA=1.0000', '\\n', '\\n=== Training for 18 epochs ===', '\\n', 'Epoch\n1/18: train_loss=0.1901  val_loss=0.0691  SWA=0.9781  CWA=0.9771  HWA=0.9776',\n'\\n', 'Epoch 2/18: train_loss=0.0438  val_loss=0.0247  SWA=0.9931  CWA=0.9932\nHWA=0.9932', '\\n', 'Epoch 3/18: train_loss=0.0148  val_loss=0.0077  SWA=0.9980\nCWA=0.9983  HWA=0.9981', '\\n', 'Epoch 4/18: train_loss=0.0044  val_loss=0.0037\nSWA=0.9981  CWA=0.9986  HWA=0.9984', '\\n', 'Epoch 5/18: train_loss=0.0020\nval_loss=0.0034  SWA=0.9988  CWA=0.9991  HWA=0.9990', '\\n', 'Epoch 6/18:\ntrain_loss=0.0011  val_loss=0.0012  SWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n',\n'Epoch 7/18: train_loss=0.0004  val_loss=0.0009  SWA=0.9998  CWA=0.9998\nHWA=0.9998', '\\n', 'Epoch 8/18: train_loss=0.0003  val_loss=0.0009  SWA=1.0000\nCWA=1.0000  HWA=1.0000', '\\n', 'Epoch 9/18: train_loss=0.0002  val_loss=0.0007\nSWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n', 'Epoch 10/18: train_loss=0.0001\nval_loss=0.0007  SWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n', 'Epoch 11/18:\ntrain_loss=0.0001  val_loss=0.0006  SWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n',\n'Epoch 12/18: train_loss=0.0001  val_loss=0.0006  SWA=1.0000  CWA=1.0000\nHWA=1.0000', '\\n', 'Epoch 13/18: train_loss=0.0001  val_loss=0.0005  SWA=1.0000\nCWA=1.0000  HWA=1.0000', '\\n', 'Epoch 14/18: train_loss=0.0001  val_loss=0.0005\nSWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n', 'Epoch 15/18: train_loss=0.0001\nval_loss=0.0005  SWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n', 'Epoch 16/18:\ntrain_loss=0.0000  val_loss=0.0005  SWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n',\n'Epoch 17/18: train_loss=0.0000  val_loss=0.0004  SWA=1.0000  CWA=1.0000\nHWA=1.0000', '\\n', 'Epoch 18/18: train_loss=0.0000  val_loss=0.0004  SWA=1.0000\nCWA=1.0000  HWA=1.0000', '\\n', '\\nSaved experiment data to /home/zxl240011/AI-Sc\nientist-v2/experiments/2025-08-16_02-30-\n16_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n6/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at', ' ', '/home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 306554.11\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 405889.91\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 505252.61\nexamples/s]', '\\n', '[lr=0.0003] Epoch 1: train_loss=0.3279 val_loss=0.1586\nSWA=0.9537 CWA=0.9515 HWA=0.9526', '\\n', '[lr=0.0003] Epoch 2: train_loss=0.1362\nval_loss=0.1158 SWA=0.9644 CWA=0.9624 HWA=0.9634', '\\n', '[lr=0.0003] Epoch 3:\ntrain_loss=0.0873 val_loss=0.0596 SWA=0.9821 CWA=0.9820 HWA=0.9820', '\\n',\n'[lr=0.0003] Epoch 4: train_loss=0.0465 val_loss=0.0360 SWA=0.9888 CWA=0.9895\nHWA=0.9891', '\\n', '[lr=0.0003] Epoch 5: train_loss=0.0302 val_loss=0.0258\nSWA=0.9944 CWA=0.9949 HWA=0.9947', '\\n', '[lr=0.0003] Epoch 6: train_loss=0.0200\nval_loss=0.0192 SWA=0.9938 CWA=0.9942 HWA=0.9940', '\\n', '[lr=0.001] Epoch 1:\ntrain_loss=0.1913 val_loss=0.0762 SWA=0.9809 CWA=0.9803 HWA=0.9806', '\\n',\n'[lr=0.001] Epoch 2: train_loss=0.0430 val_loss=0.0264 SWA=0.9919 CWA=0.9926\nHWA=0.9922', '\\n', '[lr=0.001] Epoch 3: train_loss=0.0148 val_loss=0.0103\nSWA=0.9971 CWA=0.9974 HWA=0.9973', '\\n', '[lr=0.001] Epoch 4: train_loss=0.0071\nval_loss=0.0074 SWA=0.9981 CWA=0.9984 HWA=0.9983', '\\n', '[lr=0.001] Epoch 5:\ntrain_loss=0.0029 val_loss=0.0037 SWA=0.9993 CWA=0.9993 HWA=0.9993', '\\n',\n'[lr=0.001] Epoch 6: train_loss=0.0009 val_loss=0.0025 SWA=0.9993 CWA=0.9993\nHWA=0.9993', '\\n', '[lr=0.003] Epoch 1: train_loss=0.1218 val_loss=0.0257\nSWA=0.9929 CWA=0.9936 HWA=0.9933', '\\n', '[lr=0.003] Epoch 2: train_loss=0.0136\nval_loss=0.0137 SWA=0.9974 CWA=0.9974 HWA=0.9974', '\\n', '[lr=0.003] Epoch 3:\ntrain_loss=0.0035 val_loss=0.0040 SWA=0.9988 CWA=0.9991 HWA=0.9990', '\\n',\n'[lr=0.003] Epoch 4: train_loss=0.0005 val_loss=0.0014 SWA=0.9998 CWA=0.9998\nHWA=0.9998', '\\n', '[lr=0.003] Epoch 5: train_loss=0.0002 val_loss=0.0013\nSWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', '[lr=0.003] Epoch 6: train_loss=0.0001\nval_loss=0.0011 SWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', 'Saved experiment data\nto', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_02-30-\n16_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n7/working/experiment_data.npy', '\\n', 'Execution time: 13 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 430794.77\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 457623.67\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 453732.58\nexamples/s]', '\\n', 'Vocab size=17, classes=2', '\\n', '\\n======== Training with\nbatch size 32 ========', '\\n', 'Epoch 1: train_loss=0.1025 val_loss=0.0253\nSWA=0.9920 CWA=0.9927 HWA=0.9923', '\\n', 'Epoch 2: train_loss=0.0174\nval_loss=0.0045 SWA=0.9987 CWA=0.9985 HWA=0.9986', '\\n', 'Epoch 3:\ntrain_loss=0.0027 val_loss=0.0010 SWA=1.0000 CWA=1.0000 HWA=1.0000', '\\n',\n'Epoch 4: train_loss=0.0005 val_loss=0.0007 SWA=0.9998 CWA=0.9998 HWA=0.9998',\n'\\n', 'Epoch 5: train_loss=0.0002 val_loss=0.0005 SWA=0.9998 CWA=0.9998\nHWA=0.9998', '\\n', 'Epoch 6: train_loss=0.0001 val_loss=0.0005 SWA=0.9998\nCWA=0.9998 HWA=0.9998', '\\n', '\\n======== Training with batch size 64 ========',\n'\\n', 'Epoch 1: train_loss=0.1253 val_loss=0.0288 SWA=0.9910 CWA=0.9919\nHWA=0.9915', '\\n', 'Epoch 2: train_loss=0.0170 val_loss=0.0062 SWA=0.9991\nCWA=0.9992 HWA=0.9991', '\\n', 'Epoch 3: train_loss=0.0027 val_loss=0.0026\nSWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n', 'Epoch 4: train_loss=0.0007\nval_loss=0.0011 SWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n', 'Epoch 5:\ntrain_loss=0.0003 val_loss=0.0011 SWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n',\n'Epoch 6: train_loss=0.0002 val_loss=0.0009 SWA=0.9998 CWA=0.9998 HWA=0.9998',\n'\\n', '\\n======== Training with batch size 128 ========', '\\n', 'Epoch 1:\ntrain_loss=0.1859 val_loss=0.0612 SWA=0.9799 CWA=0.9799 HWA=0.9799', '\\n',\n'Epoch 2: train_loss=0.0384 val_loss=0.0211 SWA=0.9939 CWA=0.9946 HWA=0.9942',\n'\\n', 'Epoch 3: train_loss=0.0147 val_loss=0.0098 SWA=0.9974 CWA=0.9978\nHWA=0.9976', '\\n', 'Epoch 4: train_loss=0.0055 val_loss=0.0044 SWA=0.9995\nCWA=0.9995 HWA=0.9995', '\\n', 'Epoch 5: train_loss=0.0017 val_loss=0.0023\nSWA=0.9993 CWA=0.9993 HWA=0.9993', '\\n', 'Epoch 6: train_loss=0.0007\nval_loss=0.0015 SWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n', '\\n======== Training\nwith batch size 256 ========', '\\n', 'Epoch 1: train_loss=0.2585 val_loss=0.1448\nSWA=0.9590 CWA=0.9570 HWA=0.9580', '\\n', 'Epoch 2: train_loss=0.0984\nval_loss=0.0531 SWA=0.9848 CWA=0.9849 HWA=0.9849', '\\n', 'Epoch 3:\ntrain_loss=0.0401 val_loss=0.0260 SWA=0.9937 CWA=0.9942 HWA=0.9939', '\\n',\n'Epoch 4: train_loss=0.0215 val_loss=0.0144 SWA=0.9964 CWA=0.9968 HWA=0.9966',\n'\\n', 'Epoch 5: train_loss=0.0109 val_loss=0.0080 SWA=0.9980 CWA=0.9982\nHWA=0.9981', '\\n', 'Epoch 6: train_loss=0.0049 val_loss=0.0050 SWA=0.9981\nCWA=0.9985 HWA=0.9983', '\\n', '\\nSaved experiment data to /home/zxl240011/AI-Sci\nentist-v2/experiments/2025-08-16_02-30-\n16_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n8/working/experiment_data.npy', '\\n', 'Execution time: 24 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 286094.59\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 540099.41\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 672940.57\nexamples/s]', '\\n', 'Vocab size = 17,  num_classes = 2', '\\n', '\\n=== Training\nwith hidden_dim = 64 ===', '\\n', 'Epoch 1: train_loss=0.2374  val_loss=0.1257\nSWA=0.9624  CWA=0.9599  HWA=0.9611', '\\n', 'Epoch 2: train_loss=0.0776\nval_loss=0.0375  SWA=0.9908  CWA=0.9914  HWA=0.9911', '\\n', 'Epoch 3:\ntrain_loss=0.0270  val_loss=0.0161  SWA=0.9953  CWA=0.9960  HWA=0.9957', '\\n',\n'Epoch 4: train_loss=0.0128  val_loss=0.0089  SWA=0.9979  CWA=0.9982\nHWA=0.9980', '\\n', 'Epoch 5: train_loss=0.0055  val_loss=0.0053  SWA=0.9986\nCWA=0.9988  HWA=0.9987', '\\n', 'Epoch 6: train_loss=0.0029  val_loss=0.0047\nSWA=0.9981  CWA=0.9984  HWA=0.9983', '\\n', '\\n=== Training with hidden_dim = 128\n===', '\\n', 'Epoch 1: train_loss=0.1849  val_loss=0.0552  SWA=0.9853  CWA=0.9849\nHWA=0.9851', '\\n', 'Epoch 2: train_loss=0.0424  val_loss=0.0237  SWA=0.9931\nCWA=0.9932  HWA=0.9932', '\\n', 'Epoch 3: train_loss=0.0176  val_loss=0.0127\nSWA=0.9970  CWA=0.9974  HWA=0.9972', '\\n', 'Epoch 4: train_loss=0.0084\nval_loss=0.0055  SWA=0.9992  CWA=0.9993  HWA=0.9992', '\\n', 'Epoch 5:\ntrain_loss=0.0025  val_loss=0.0028  SWA=0.9992  CWA=0.9993  HWA=0.9992', '\\n',\n'Epoch 6: train_loss=0.0008  val_loss=0.0027  SWA=0.9987  CWA=0.9989\nHWA=0.9988', '\\n', '\\n=== Training with hidden_dim = 256 ===', '\\n', 'Epoch 1:\ntrain_loss=0.1771  val_loss=0.0667  SWA=0.9814  CWA=0.9817  HWA=0.9815', '\\n',\n'Epoch 2: train_loss=0.0463  val_loss=0.0318  SWA=0.9902  CWA=0.9905\nHWA=0.9903', '\\n', 'Epoch 3: train_loss=0.0189  val_loss=0.0138  SWA=0.9946\nCWA=0.9952  HWA=0.9949', '\\n', 'Epoch 4: train_loss=0.0090  val_loss=0.0053\nSWA=0.9983  CWA=0.9984  HWA=0.9984', '\\n', 'Epoch 5: train_loss=0.0016\nval_loss=0.0018  SWA=0.9994  CWA=0.9993  HWA=0.9993', '\\n', 'Epoch 6:\ntrain_loss=0.0004  val_loss=0.0007  SWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n',\n'\\n=== Training with hidden_dim = 512 ===', '\\n', 'Epoch 1: train_loss=0.1639\nval_loss=0.0602  SWA=0.9832  CWA=0.9832  HWA=0.9832', '\\n', 'Epoch 2:\ntrain_loss=0.0461  val_loss=0.0312  SWA=0.9924  CWA=0.9930  HWA=0.9927', '\\n',\n'Epoch 3: train_loss=0.0223  val_loss=0.0166  SWA=0.9937  CWA=0.9944\nHWA=0.9941', '\\n', 'Epoch 4: train_loss=0.0085  val_loss=0.0105  SWA=0.9959\nCWA=0.9963  HWA=0.9961', '\\n', 'Epoch 5: train_loss=0.0018  val_loss=0.0031\nSWA=0.9984  CWA=0.9986  HWA=0.9985', '\\n', 'Epoch 6: train_loss=0.0002\nval_loss=0.0021  SWA=0.9991  CWA=0.9992  HWA=0.9991', '\\n', '\\nSaved experiment\ndata to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_02-30-\n16_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n9/working/experiment_data.npy', '\\n', 'Execution time: 59 seconds seconds (time\nlimit is 30 minutes).']"], "analysis": ["", "", "", "", ""], "exc_type": [null, null, null, null, null], "exc_info": [null, null, null, null, null], "exc_stack": [null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The final loss during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.000666, "best_value": 0.000666}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The final loss during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.001513, "best_value": 0.001513}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The final shape-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.999767, "best_value": 0.999767}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The final color-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.999756, "best_value": 0.999756}]}, {"metric_name": "validation harmonic-weighted accuracy", "lower_is_better": false, "description": "The final harmonic-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.999762, "best_value": 0.999762}]}]}, {"metric_names": [{"metric_name": "Training Loss", "lower_is_better": true, "description": "Measures the error in the model's predictions during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0007, "best_value": 0.0}]}, {"metric_name": "Validation Loss", "lower_is_better": true, "description": "Measures the error in the model's predictions on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0004, "best_value": 0.0004}]}, {"metric_name": "Validation Shape Weighted Accuracy", "lower_is_better": false, "description": "Accuracy metric for shape classification weighted by class frequency.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Validation Color Weighted Accuracy", "lower_is_better": false, "description": "Accuracy metric for color classification weighted by class frequency.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Validation Harmonic Weighted Accuracy", "lower_is_better": false, "description": "Harmonic mean of shape and color weighted accuracies.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value calculated on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0001, "best_value": 0.0001}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0011, "best_value": 0.0011}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9995, "best_value": 0.9995}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9996, "best_value": 0.9996}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic-weighted accuracy calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9996, "best_value": 0.9996}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value calculated on the training dataset, indicating the model's performance during training.", "data": [{"dataset_name": "Batch size 32", "final_value": 0.0001, "best_value": 0.0001}, {"dataset_name": "Batch size 64", "final_value": 0.0002, "best_value": 0.0002}, {"dataset_name": "Batch size 128", "final_value": 0.0007, "best_value": 0.0007}, {"dataset_name": "Batch size 256", "final_value": 0.0049, "best_value": 0.0049}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value calculated on the validation dataset, used to evaluate the model's generalization ability.", "data": [{"dataset_name": "Batch size 32", "final_value": 0.0005, "best_value": 0.0005}, {"dataset_name": "Batch size 64", "final_value": 0.0009, "best_value": 0.0009}, {"dataset_name": "Batch size 128", "final_value": 0.0015, "best_value": 0.0015}, {"dataset_name": "Batch size 256", "final_value": 0.005, "best_value": 0.005}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on the shape-related tasks in the validation dataset, weighted by the importance of each class.", "data": [{"dataset_name": "Batch size 32", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "Batch size 64", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "Batch size 128", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "Batch size 256", "final_value": 0.9981, "best_value": 0.9981}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on the color-related tasks in the validation dataset, weighted by the importance of each class.", "data": [{"dataset_name": "Batch size 32", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "Batch size 64", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "Batch size 128", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "Batch size 256", "final_value": 0.9985, "best_value": 0.9985}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic mean of accuracies across different tasks in the validation dataset, weighted by the importance of each class.", "data": [{"dataset_name": "Batch size 32", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "Batch size 64", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "Batch size 128", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "Batch size 256", "final_value": 0.9983, "best_value": 0.9983}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating the model's performance on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0002, "best_value": 0.0002}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, indicating the model's performance on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0021, "best_value": 0.0007}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy weighted by shapes during validation, indicating the model's performance in recognizing shapes.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9991, "best_value": 1.0}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The accuracy weighted by colors during validation, indicating the model's performance in recognizing colors.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9992, "best_value": 1.0}]}, {"metric_name": "validation harmonic-weighted accuracy", "lower_is_better": false, "description": "The harmonic mean of accuracies during validation, providing an overall performance metric.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9991, "best_value": 1.0}]}]}], "is_best_node": [false, true, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_val_metrics.png", "../../logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_confusion_matrix.png", "../../logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_class_distribution.png"], ["../../logs/0-run/experiment_results/experiment_a15ef597b64f4e76b2d3cbc4e0ad7fc8_proc_3098457/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_a15ef597b64f4e76b2d3cbc4e0ad7fc8_proc_3098457/SPR_BENCH_metric_curves.png", "../../logs/0-run/experiment_results/experiment_a15ef597b64f4e76b2d3cbc4e0ad7fc8_proc_3098457/SPR_BENCH_final_metrics.png"], ["../../logs/0-run/experiment_results/experiment_74e3f50a315c401c8e04cb1d1b7016c5_proc_3098458/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_74e3f50a315c401c8e04cb1d1b7016c5_proc_3098458/SPR_BENCH_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_74e3f50a315c401c8e04cb1d1b7016c5_proc_3098458/SPR_BENCH_final_hwa_bar.png"], ["../../logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_training_loss.png", "../../logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_validation_loss.png", "../../logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_validation_hwa.png", "../../logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_final_hwa_bar.png"], ["../../logs/0-run/experiment_results/experiment_aba4e445a7074dc28f875c0836664f7d_proc_3098460/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_aba4e445a7074dc28f875c0836664f7d_proc_3098460/SPR_BENCH_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_aba4e445a7074dc28f875c0836664f7d_proc_3098460/SPR_BENCH_final_hwa_bar.png"]], "plot_paths": [["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_val_metrics.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_confusion_matrix.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_class_distribution.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a15ef597b64f4e76b2d3cbc4e0ad7fc8_proc_3098457/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a15ef597b64f4e76b2d3cbc4e0ad7fc8_proc_3098457/SPR_BENCH_metric_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a15ef597b64f4e76b2d3cbc4e0ad7fc8_proc_3098457/SPR_BENCH_final_metrics.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_74e3f50a315c401c8e04cb1d1b7016c5_proc_3098458/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_74e3f50a315c401c8e04cb1d1b7016c5_proc_3098458/SPR_BENCH_hwa_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_74e3f50a315c401c8e04cb1d1b7016c5_proc_3098458/SPR_BENCH_final_hwa_bar.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_training_loss.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_validation_loss.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_validation_hwa.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_final_hwa_bar.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_aba4e445a7074dc28f875c0836664f7d_proc_3098460/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_aba4e445a7074dc28f875c0836664f7d_proc_3098460/SPR_BENCH_hwa_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_aba4e445a7074dc28f875c0836664f7d_proc_3098460/SPR_BENCH_final_hwa_bar.png"]], "plot_analyses": [[{"analysis": "The training and validation loss curves show a consistent decrease over the epochs, with both converging to near-zero values by the sixth epoch. This indicates that the model is effectively learning the patterns in the data without overfitting, as the validation loss closely tracks the training loss.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_loss_curves.png"}, {"analysis": "The validation metrics for SWA, CWA, and HWA demonstrate a rapid increase and convergence to nearly perfect accuracy (close to 1.0) within the first few epochs. This suggests that the model is performing exceptionally well on the validation set, achieving high accuracy across all weighted metrics.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_val_metrics.png"}, {"analysis": "The confusion matrix shows a strong diagonal dominance, indicating that the model is correctly predicting the majority of the samples. Misclassifications appear minimal, as evidenced by the low values in the off-diagonal cells.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_confusion_matrix.png"}, {"analysis": "The class distribution plot reveals that the predicted class distribution closely matches the ground truth distribution, suggesting that the model is not biased toward any particular class and is performing well in classifying all classes equally.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a052badb1bcf4992953766f78bc21dd5_proc_3095884/SPR_BENCH_class_distribution.png"}], [{"analysis": "This plot shows the training and validation loss across different learning rates (6e, 12e, and 18e). All configurations converge quickly within the first few epochs, with both training and validation losses approaching zero, indicating that the model successfully minimizes error. The consistent overlap between training and validation loss curves suggests minimal overfitting. However, further analysis may be needed to ensure that the model's generalization is robust.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a15ef597b64f4e76b2d3cbc4e0ad7fc8_proc_3098457/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the Harmonic Weighted Accuracy (HWA) on the validation set across epochs for different epoch budgets. The HWA metric rapidly increases and stabilizes near 1.0 within the first few epochs for all configurations, indicating excellent performance. The convergence trend is consistent across different epoch budgets, suggesting that extending the number of epochs beyond a certain point does not significantly improve the HWA. This stability points to the model's efficiency in learning the task.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a15ef597b64f4e76b2d3cbc4e0ad7fc8_proc_3098457/SPR_BENCH_metric_curves.png"}, {"analysis": "This plot compares the final validation metrics (SWA, CWA, and HWA) for different epoch budgets. All metrics reach a perfect score of 1.0 regardless of the epoch budget, indicating that the model achieves optimal performance across all configurations. The results suggest that the model's performance is not constrained by the number of training epochs and that the proposed approach is highly effective in addressing the SPR task.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a15ef597b64f4e76b2d3cbc4e0ad7fc8_proc_3098457/SPR_BENCH_final_metrics.png"}], [{"analysis": "This plot shows the cross-entropy loss for training and validation datasets across different learning rates. The learning rate of 0.003 achieves the fastest convergence, with both training and validation losses decreasing sharply and stabilizing by epoch 3. The learning rate of 0.001 also performs well, converging slightly slower but achieving a similar final loss. The learning rate of 0.0003 converges the slowest and exhibits a larger gap between training and validation losses, indicating potential underfitting. Overall, higher learning rates (0.001 and 0.003) demonstrate better performance in terms of convergence speed and final loss values.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_74e3f50a315c401c8e04cb1d1b7016c5_proc_3098458/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the Harmonic Weighted Accuracy (HWA) on the validation set over epochs for different learning rates. The learning rate of 0.003 achieves the highest HWA consistently, reaching close to 1.0 by epoch 3 and maintaining this performance. The learning rate of 0.001 performs similarly, with a slightly slower climb to the maximum HWA. The learning rate of 0.0003 shows a slower improvement, with its HWA lagging behind the other two learning rates throughout the epochs. This suggests that higher learning rates enable faster optimization and better generalization in this task.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_74e3f50a315c401c8e04cb1d1b7016c5_proc_3098458/SPR_BENCH_hwa_curves.png"}, {"analysis": "This plot compares the final epoch Harmonic Weighted Accuracy (HWA) for different learning rates. All learning rates achieve nearly identical final HWA values, close to 1.0, indicating that the model's ultimate performance is robust to the choice of learning rate. However, considering the faster convergence observed in earlier plots, higher learning rates (0.001 and 0.003) are preferable for achieving optimal performance more efficiently.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_74e3f50a315c401c8e04cb1d1b7016c5_proc_3098458/SPR_BENCH_final_hwa_bar.png"}], [{"analysis": "This plot shows the training loss across epochs for different batch sizes. Smaller batch sizes (e.g., bs=32 and bs=64) result in faster convergence to lower training loss compared to larger batch sizes (e.g., bs=256). The model with bs=256 has a slower drop in loss, which is consistent with the general observation that smaller batch sizes often allow for sharper minima in the loss landscape. However, all batch sizes eventually converge to near-zero training loss by epoch 6.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_training_loss.png"}, {"analysis": "This plot depicts the validation loss over epochs for different batch sizes. Similar to the training loss, smaller batch sizes (bs=32 and bs=64) demonstrate faster reduction in validation loss, indicating better generalization initially. Larger batch sizes (bs=256) lag behind in reducing validation loss, but all batch sizes converge to near-zero validation loss by epoch 6. This suggests that the model is capable of fitting the validation set well regardless of batch size, though smaller batch sizes may offer a slight advantage early on.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_validation_loss.png"}, {"analysis": "This plot illustrates the validation harmonic weighted accuracy (HWA) over epochs for different batch sizes. Smaller batch sizes (bs=32 and bs=64) achieve higher accuracy earlier in the training process, reflecting better generalization during initial epochs. Larger batch sizes (bs=256) require more epochs to catch up. By epoch 6, all batch sizes achieve nearly identical HWA, indicating that the batch size has minimal impact on the final performance when sufficient epochs are used.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_validation_hwa.png"}, {"analysis": "This bar chart summarizes the final harmonic weighted accuracy (HWA) at the last epoch for different batch sizes. The HWA is nearly identical across all batch sizes, with only marginal differences. This indicates that while batch size affects the training dynamics and early-stage performance, the final performance is robust to batch size variations when the model is trained for enough epochs.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e8e85bd46e3c4a308420d7df3322d6ef_proc_3098459/SPR_BENCH_final_hwa_bar.png"}], [{"analysis": "The training and validation loss curves for different hidden dimensions (64, 128, 256, 512) show consistent convergence within six epochs. Notably, smaller hidden dimensions (e.g., 64) have higher initial loss values but converge to nearly the same final loss as larger hidden dimensions. This indicates that the model is capable of achieving similar performance regardless of hidden dimension size, though larger dimensions may provide slightly smoother convergence.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_aba4e445a7074dc28f875c0836664f7d_proc_3098460/SPR_BENCH_loss_curves.png"}, {"analysis": "The harmonic-weighted accuracy (HWA) for validation data improves steadily across epochs for all hidden dimensions, with larger dimensions (128, 256, 512) showing slightly faster convergence compared to smaller ones (64). By the final epoch, all configurations achieve near-perfect HWA, indicating that the model is highly effective at capturing the patterns in the SPR task.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_aba4e445a7074dc28f875c0836664f7d_proc_3098460/SPR_BENCH_hwa_curves.png"}, {"analysis": "The bar chart shows that the final epoch HWA is nearly identical across all tested hidden dimensions, with all values approaching or reaching 1.0. This reinforces the observation that the choice of hidden dimension has minimal impact on the ultimate performance of the model, suggesting that the model's architecture and training process are robust to this hyperparameter.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_aba4e445a7074dc28f875c0836664f7d_proc_3098460/SPR_BENCH_final_hwa_bar.png"}]], "vlm_feedback_summary": ["The plots collectively indicate that the model is performing exceptionally well,\nachieving near-perfect training and validation performance. The loss curves\ndemonstrate effective learning without overfitting, while the validation metrics\nand class distribution confirm the robustness and fairness of the predictions.\nThe confusion matrix further supports the model's high accuracy with minimal\nmisclassifications.", "The experimental results demonstrate that the proposed context-aware contrastive\nlearning framework performs exceptionally well on the SPR task. The loss curves\nindicate effective learning with minimal overfitting, and the validation metrics\nconfirm that the model achieves optimal performance across all configurations.\nThese findings support the hypothesis that the context-aware approach enhances\nsymbolic pattern recognition.", "The plots indicate that higher learning rates (0.001 and 0.003) lead to faster\nconvergence and better optimization during training, as evidenced by lower\ncross-entropy loss and quicker attainment of high Harmonic Weighted Accuracy\n(HWA). However, all learning rates ultimately achieve similar final HWA values,\nsuggesting robustness in the model's performance across learning rates.", "The received plots provide insights into the impact of batch size on training\ndynamics and final performance. Smaller batch sizes demonstrate faster\nconvergence and better early-stage generalization, but all batch sizes achieve\nsimilar final performance. These results suggest that batch size selection can\nbe guided by computational efficiency and training time considerations without\ncompromising final accuracy.", "The plots indicate that the model performs robustly across different hidden\ndimensions, with all configurations achieving near-perfect accuracy. The\ntraining and validation losses converge effectively, and the harmonic-weighted\naccuracy steadily improves, suggesting that the proposed approach is well-suited\nfor the SPR task."], "exec_time": [6.479233741760254, 100.6684262752533, 13.095924139022827, 24.12612295150757, 59.38293719291687], "exec_time_feedback": ["", "", "", "", ""], "datasets_successfully_tested": [["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"]], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    data = experiment_data.get(\"SPR_BENCH\", {})\n    losses_tr = (\n        np.array(data[\"losses\"][\"train\"])\n        if data[\"losses\"][\"train\"]\n        else np.empty((0, 2))\n    )\n    losses_val = (\n        np.array(data[\"losses\"][\"val\"]) if data[\"losses\"][\"val\"] else np.empty((0, 2))\n    )\n    metrics_val = (\n        np.array(data[\"metrics\"][\"val\"]) if data[\"metrics\"][\"val\"] else np.empty((0, 4))\n    )\n    preds = np.array(data.get(\"predictions\", []))\n    gts = np.array(data.get(\"ground_truth\", []))\n\n    # -------- Plot 1: loss curves --------\n    try:\n        plt.figure()\n        if losses_tr.size:\n            plt.plot(losses_tr[:, 0], losses_tr[:, 1], label=\"Train Loss\")\n        if losses_val.size:\n            plt.plot(losses_val[:, 0], losses_val[:, 1], label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH Training vs. Validation Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # -------- Plot 2: validation metrics --------\n    try:\n        plt.figure()\n        if metrics_val.size:\n            plt.plot(metrics_val[:, 0], metrics_val[:, 1], label=\"SWA\")\n            plt.plot(metrics_val[:, 0], metrics_val[:, 2], label=\"CWA\")\n            plt.plot(metrics_val[:, 0], metrics_val[:, 3], label=\"HWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.title(\"SPR_BENCH Validation Metrics (SWA, CWA, HWA)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_metrics.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metrics plot: {e}\")\n        plt.close()\n\n    # -------- Plot 3: confusion matrix --------\n    try:\n        if preds.size and gts.size:\n            num_classes = int(max(preds.max(), gts.max()) + 1)\n            cm = np.zeros((num_classes, num_classes), dtype=int)\n            for t, p in zip(gts, preds):\n                cm[t, p] += 1\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(\"SPR_BENCH Confusion Matrix\")\n            plt.savefig(os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\n    # -------- Plot 4: class distribution bar chart --------\n    try:\n        if preds.size and gts.size:\n            classes = np.arange(int(max(preds.max(), gts.max()) + 1))\n            pred_counts = np.array([np.sum(preds == c) for c in classes])\n            gt_counts = np.array([np.sum(gts == c) for c in classes])\n            width = 0.35\n            plt.figure()\n            plt.bar(classes - width / 2, gt_counts, width=width, label=\"Ground Truth\")\n            plt.bar(classes + width / 2, pred_counts, width=width, label=\"Predictions\")\n            plt.xlabel(\"Class\")\n            plt.ylabel(\"Count\")\n            plt.title(\"SPR_BENCH Class Distribution\")\n            plt.legend()\n            plt.savefig(os.path.join(working_dir, \"SPR_BENCH_class_distribution.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating distribution plot: {e}\")\n        plt.close()\n\n    # -------- Print final evaluation number --------\n    if metrics_val.size:\n        final_hwa = metrics_val[-1, 3]\n        print(f\"Final Harmonic Weighted Accuracy (HWA): {final_hwa:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- setup ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    exp_path = os.path.join(working_dir, \"experiment_data.npy\")\n    experiment_data = np.load(exp_path, allow_pickle=True).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    runs = experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"runs\"]\n    colors = [\"tab:blue\", \"tab:orange\", \"tab:green\"]  # one per budget\n    budgets = [r[\"epochs\"] for r in runs]\n\n    # ---------- figure 1: loss curves ----------\n    try:\n        plt.figure(figsize=(8, 5))\n        for i, run in enumerate(runs):\n            ep, tr_loss = zip(*run[\"losses\"][\"train\"])\n            _, val_loss = zip(*run[\"losses\"][\"val\"])\n            plt.plot(\n                ep,\n                tr_loss,\n                linestyle=\"-\",\n                color=colors[i],\n                label=f\"{budgets[i]}e Train\",\n            )\n            plt.plot(\n                ep,\n                val_loss,\n                linestyle=\"--\",\n                color=colors[i],\n                label=f\"{budgets[i]}e Val\",\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH \u2013 Training vs Validation Loss (All Runs)\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # ---------- figure 2: HWA curves ----------\n    try:\n        plt.figure(figsize=(8, 5))\n        for i, run in enumerate(runs):\n            ep, _, _, hwa = zip(*run[\"metrics\"][\"val\"])\n            plt.plot(ep, hwa, color=colors[i], label=f\"{budgets[i]} epochs\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Harmonic Weighted Accuracy\")\n        plt.title(\"SPR_BENCH \u2013 Validation HWA Across Epochs\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_metric_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric plot: {e}\")\n        plt.close()\n\n    # ---------- figure 3: final metrics bar chart ----------\n    try:\n        final_swa, final_cwa, final_hwa = [], [], []\n        for run in runs:\n            _, swa, cwa, hwa = run[\"metrics\"][\"val\"][-1]\n            final_swa.append(swa)\n            final_cwa.append(cwa)\n            final_hwa.append(hwa)\n\n        x = np.arange(len(budgets))\n        width = 0.25\n        plt.figure(figsize=(9, 5))\n        plt.bar(x - width, final_swa, width, label=\"SWA\")\n        plt.bar(x, final_cwa, width, label=\"CWA\")\n        plt.bar(x + width, final_hwa, width, label=\"HWA\")\n        plt.xticks(x, [f\"{b}e\" for b in budgets])\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH \u2013 Final Validation Metrics per Epoch Budget\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_metrics.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating final metrics plot: {e}\")\n        plt.close()\n\n    # ---------- print final numbers ----------\n    print(\"Final Validation Metrics\")\n    print(\"Budget\\tSWA\\tCWA\\tHWA\")\n    for b, s, c, h in zip(budgets, final_swa, final_cwa, final_hwa):\n        print(f\"{b}\\t{s:.4f}\\t{c:.4f}\\t{h:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nlr_dict = experiment_data.get(\"learning_rate\", {}).get(\"SPR_BENCH\", {})\nif not lr_dict:\n    print(\"No data found, aborting plots.\")\n    exit()\n\n\n# helper to extract arrays -----------------------------------------------------\ndef tup2arr(tup_list, idx=1):\n    \"\"\"get x(epochs) and y(values[idx]) arrays from list[(ep,val,...)]\"\"\"\n    if not tup_list:\n        return [], []\n    ep = [t[0] for t in tup_list]\n    val = [t[idx] for t in tup_list]\n    return ep, val\n\n\n# ---------------------- Figure 1: loss curves ---------------------------------\ntry:\n    plt.figure()\n    for lr, rec in lr_dict.items():\n        ep_tr, tr = tup2arr(rec[\"losses\"][\"train\"])\n        ep_val, val = tup2arr(rec[\"losses\"][\"val\"])\n        plt.plot(ep_tr, tr, \"--\", label=f\"lr={lr} train\")\n        plt.plot(ep_val, val, \"-\", label=f\"lr={lr} val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-entropy loss\")\n    plt.title(\"SPR_BENCH Loss Curves (Train vs. Validation)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# ---------------------- Figure 2: HWA curves ----------------------------------\ntry:\n    plt.figure()\n    for lr, rec in lr_dict.items():\n        ep, hwa = tup2arr(rec[\"metrics\"][\"val\"], idx=3)\n        plt.plot(ep, hwa, label=f\"lr={lr}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Accuracy\")\n    plt.title(\"SPR_BENCH Validation HWA Across Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curves plot: {e}\")\n    plt.close()\n\n# ---------------------- Figure 3: Final HWA bar -------------------------------\ntry:\n    plt.figure()\n    lrs, final_hwa = [], []\n    for lr, rec in lr_dict.items():\n        if rec[\"metrics\"][\"val\"]:\n            final_hwa.append(rec[\"metrics\"][\"val\"][-1][3])\n            lrs.append(lr)\n    plt.bar(range(len(lrs)), final_hwa, tick_label=lrs)\n    plt.ylabel(\"Final HWA\")\n    plt.title(\"SPR_BENCH Final Epoch HWA by Learning Rate\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_hwa_bar.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar plot: {e}\")\n    plt.close()\n\n# -------------- print final metrics to stdout ---------------------------------\nfor lr, hwa in zip(lrs, final_hwa):\n    print(f\"Learning rate {lr}: final HWA = {hwa:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nbs_section = experiment_data.get(\"batch_size\", {})\nbs_keys = sorted(bs_section.keys(), key=int)\n\n# containers for summary printout\nsummary = []\n\n# ---------- figure 1: training loss ----------\ntry:\n    plt.figure()\n    for bs in bs_keys:\n        epochs, tr_loss = zip(*bs_section[bs][\"losses\"][\"train\"])\n        plt.plot(epochs, tr_loss, marker=\"o\", label=f\"bs={bs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Training Loss\")\n    plt.title(\"SPR_BENCH: Training Loss over Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_training_loss.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating training loss plot: {e}\")\n    plt.close()\n\n# ---------- figure 2: validation loss ----------\ntry:\n    plt.figure()\n    for bs in bs_keys:\n        epochs, val_loss = zip(*bs_section[bs][\"losses\"][\"val\"])\n        plt.plot(epochs, val_loss, marker=\"o\", label=f\"bs={bs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Validation Loss\")\n    plt.title(\"SPR_BENCH: Validation Loss over Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_validation_loss.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating validation loss plot: {e}\")\n    plt.close()\n\n# ---------- figure 3: validation HWA ----------\ntry:\n    plt.figure()\n    for bs in bs_keys:\n        epochs, swa, cwa, hwa = zip(*bs_section[bs][\"metrics\"][\"val\"])\n        plt.plot(epochs, hwa, marker=\"o\", label=f\"bs={bs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"HWA\")\n    plt.title(\"SPR_BENCH: Validation Harmonic Weighted Accuracy over Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_validation_hwa.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA plot: {e}\")\n    plt.close()\n\n# ---------- figure 4: final HWA bar ----------\ntry:\n    plt.figure()\n    final_hwa = []\n    for bs in bs_keys:\n        *_, last = bs_section[bs][\"metrics\"][\"val\"]\n        final_hwa.append(last[3])  # last element is hwa\n        summary.append((bs, last[1], last[2], last[3]))  # swa, cwa, hwa\n    x = np.arange(len(bs_keys))\n    plt.bar(x, final_hwa, tick_label=bs_keys)\n    plt.xlabel(\"Batch Size\")\n    plt.ylabel(\"Final Epoch HWA\")\n    plt.title(\"SPR_BENCH: Final Harmonic Weighted Accuracy by Batch Size\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_hwa_bar.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar plot: {e}\")\n    plt.close()\n\n# ---------- print summary ----------\nprint(\"Final Validation Metrics per Batch Size\")\nprint(f\"{'Batch':>6} | {'SWA':>6} | {'CWA':>6} | {'HWA':>6}\")\nprint(\"-\" * 30)\nfor bs, swa, cwa, hwa in sorted(summary, key=lambda x: int(x[0])):\n    print(f\"{bs:>6} | {swa:6.3f} | {cwa:6.3f} | {hwa:6.3f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# --- paths & load ---\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    runs = experiment_data[\"hidden_dim\"][\"SPR_BENCH\"]\n    hidden_sizes = sorted(int(h) for h in runs.keys())\n\n    # --------- PLOT 1: loss curves -----------\n    try:\n        plt.figure(figsize=(6, 4))\n        for h in hidden_sizes:\n            run = runs[str(h)]\n            epochs, tr_loss = zip(*run[\"losses\"][\"train\"])\n            _, val_loss = zip(*run[\"losses\"][\"val\"])\n            plt.plot(epochs, tr_loss, label=f\"{h}-train\", linestyle=\"--\")\n            plt.plot(epochs, val_loss, label=f\"{h}-val\")\n        plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend(fontsize=8)\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname, dpi=150)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # --------- PLOT 2: HWA curves ------------\n    try:\n        plt.figure(figsize=(6, 4))\n        for h in hidden_sizes:\n            run = runs[str(h)]\n            epochs, swa, cwa, hwa = zip(*run[\"metrics\"][\"val\"])\n            plt.plot(epochs, hwa, label=f\"{h}-HWA\")\n        plt.title(\"SPR_BENCH: Harmonic-Weighted Accuracy (Validation)\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HWA\")\n        plt.legend(fontsize=8)\n        fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves.png\")\n        plt.savefig(fname, dpi=150)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating HWA curve plot: {e}\")\n        plt.close()\n\n    # --------- PLOT 3: final HWA vs hidden ----\n    try:\n        final_hwa = []\n        for h in hidden_sizes:\n            hwa_last = runs[str(h)][\"metrics\"][\"val\"][-1][3]\n            final_hwa.append(hwa_last)\n        plt.figure(figsize=(5, 3))\n        plt.bar([str(h) for h in hidden_sizes], final_hwa, color=\"skyblue\")\n        plt.title(\"SPR_BENCH: Final Epoch HWA vs Hidden Size\")\n        plt.xlabel(\"Hidden Dimension\")\n        plt.ylabel(\"Final Harmonic-Weighted Accuracy\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_final_hwa_bar.png\")\n        plt.savefig(fname, dpi=150)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating final HWA bar plot: {e}\")\n        plt.close()\n\n    # --------- Print summary -----------------\n    print(\"\\nFinal epoch validation HWA by hidden size:\")\n    for h, hwa in zip(hidden_sizes, final_hwa):\n        print(f\"  hidden={h:3d} -> HWA = {hwa:.4f}\")\n"], "plot_plan": ["We will load experiment_data.npy, which contains nested dictionaries for the single dataset \u201cSPR_BENCH\u201d.  From this we extract the epoch-indexed training/validation losses and the three validation metrics (SWA, CWA, HWA).  Four concise visualisations are generated: (1) a line chart of training vs. validation loss, (2) a line chart of the three validation metrics, (3) a confusion-matrix heat-map built from the latest ground-truth vs. prediction arrays, and (4) a bar chart that compares class-frequency distributions of predictions and ground truth.  Each figure is wrapped in its own try-except block, saved into working_dir with descriptive filenames, and the figure is closed regardless of success.  We also compute and print the final-epoch HWA as the headline evaluation number.  All plotting uses vanilla matplotlib; no extra styling is introduced.  No synthetic data are created\u2014every value comes directly from experiment_data.npy.  At most four figures are produced, keeping within the five-plot limit.  The resulting script can be run after training to give a quick visual audit of the experiment.", "We first load experiment_data.npy, grab the three runs stored for the SPR_BENCH dataset, and extract the epoch-wise training/validation losses along with SWA, CWA and HWA.  For visual inspection we generate three figures: (1) combined training and validation loss curves for all runs, (2) combined HWA curves for all runs, and (3) a grouped-bar chart comparing final SWA, CWA and HWA achieved after the last epoch of every run.  Each figure is built inside its own try-except block, saved to working_dir with descriptive names and then closed.  We restrict ourselves to just these three figures to stay within the \u201c\u22645 similar plots\u201d rule.  After plotting, the script prints a small table showing the final SWA, CWA and HWA for each epoch budget so the user can quickly read the numerical results from stdout as well.  The code follows the mandated import order, creates working_dir if missing, and never attempts to fabricate data\u2014everything comes directly from experiment_data.npy.  Finally, figures contain clear titles such as \u201cSPR_BENCH \u2013 Training vs Validation Loss (All Runs)\u201d and use legends to distinguish the epoch-budget settings.", "We will load the saved experiment_data.npy, iterate over the three learning-rate runs, and extract (epoch, loss) tuples for train/validation as well as (epoch, swa, cwa, hwa) for validation.  \nFigure 1 plots train vs. validation loss curves for all learning rates in a single canvas, so users can see convergence behavior.  \nFigure 2 shows the harmonic weighted accuracy (HWA) per epoch for each learning rate, highlighting generalization quality.  \nFigure 3 is a bar chart of the final\u2010epoch HWA attained by every learning rate, offering an at-a-glance comparison.  \nEach figure is wrapped in its own try-except; on failure we print the error and still close the figure.  \nAll plots are saved into working_dir with descriptive names containing \u201cSPR_BENCH\u201d and the plot type.  \nWe cap visualization to these three figures (<5 as required) and close figures after saving to avoid memory leaks.  \nFinally, the script prints out the final HWA values so they are visible in logs even without opening the plots.", "The script first loads the stored experiment_data.npy, extracts per-batch-size arrays for epochs, training/validation loss, and validation SWA, CWA, and HWA. It then creates up to five standard figures: (1) training loss curves, (2) validation loss curves, (3) validation HWA curves, and (4) a bar chart of the final-epoch HWA for each batch size (the fifth slot is left unused to stay within the limit). Each figure is wrapped in its own try-except block, is titled with the dataset name (SPR_BENCH) and a clear description of the content, saved to working_dir with descriptive filenames, and explicitly closed. After plotting, the script prints a neat summary table of the final SWA, CWA and HWA achieved by each batch size so users can see the numeric results alongside the visualizations. All plotting uses only data present in experiment_data.npy and basic matplotlib commands, adhering to the provided guidelines.", "We first load the saved experiment_data.npy, then iterate through the four hidden-size runs.  For each run we extract per-epoch training/validation losses and the validation shape-, color- and harmonic-weighted accuracies.  We create at most three figures: (1) loss curves, (2) harmonic-weighted accuracy curves, and (3) a bar chart of final epoch HWAs versus hidden size, keeping every figure in its own try-except block and closing it afterwards.  All figures are saved in the working directory with descriptive filenames that include \u201cSPR_BENCH\u201d and the plot type.  After plotting we compute the best (highest) final HWA and print a concise summary table to stdout so the user can immediately see model quality.  The plotting strictly uses data stored inside experiment_data.npy; no synthetic values are introduced.  Basic matplotlib is used with clear titles and axis labels, complying with all provided style and safety guidelines.  The whole visualization script is self-contained and can be executed directly."], "ablation_name": [null, null, null, null, null], "hyperparam_name": [null, "EPOCHS", "Learning Rate", "Batch Size", "hidden_dim (LSTM hidden size)"], "is_seed_node": [false, false, false, false, false], "is_seed_agg_node": [false, false, false, false, false], "parse_metrics_plan": ["The script will locate the file path of experiment_data.npy inside the working\ndirectory, load it with NumPy, and convert the array back to a Python\ndictionary.   For every dataset key (e.g., \u201cSPR_BENCH\u201d) it will pull out the\nstored lists for losses and metrics, pick the final entry in each list\n(representing the last training epoch), and print these values with fully-\nqualified names such as \u201cfinal training loss\u201d or \u201cfinal validation harmonic-\nweighted accuracy.\u201d   Because the original code only logs validation metrics\n(SWA, CWA, HWA) and not training accuracies, the script reports those three\ntogether with the final training and validation losses.   All code lives at\nglobal scope so the file runs immediately when executed.", "The solution loads the serialized experiment dictionary from the working\ndirectory, drills down to the \u201cruns\u201d list for the SPR_BENCH dataset, and \u2013 for\neach run \u2013 fetches the last-epoch entry for every stored statistic.  It then\nprints the dataset name followed by clearly labeled final values: training loss,\nvalidation loss, validation shape-weighted accuracy, validation color-weighted\naccuracy and validation harmonic-weighted accuracy.  All logic is placed at the\nglobal scope so the script executes immediately when run.  No figures are\ngenerated, strictly adhering to the stated constraints.", "The script will load the NumPy file from the working directory, unpack the\nnested dictionary, and iterate over each learning-rate run stored under the\nsingle dataset key \u201cSPR_BENCH.\u201d   For every run it will grab the last (i.e.,\nfinal-epoch) entry from the stored loss and metric lists, then print them with\nexplicit, human-readable metric names.   The printout will always begin with the\ndataset name, followed by clearly labeled lines for \u201cfinal training loss,\u201d\n\u201cfinal validation loss,\u201d \u201cfinal validation shape-weighted accuracy,\u201d \u201cfinal\nvalidation color-weighted accuracy,\u201d and \u201cfinal validation harmonic-weighted\naccuracy.\u201d   All code is placed at global scope so it executes immediately when\nthe file is run, and absolutely no plotting commands or `if __name__ ==\n\"__main__\":` guards are used.", "The script will locate the saved NumPy file in the working directory, load it as\na Python dictionary, iterate over each batch-size experiment, and compute the\nbest (minimum) training/validation losses and the best (maximum) validation\nShape-, Color-, and Harmonic-weighted accuracies. It then prints the dataset\nname (\u201cBatch size \u2026\u201d) followed by clearly labeled metric values. No plotting is\ndone, and everything runs immediately at the top level.", "We will load the NumPy file from the working directory, iterate through the\nstored results, and for each dataset (here \u201cSPR_BENCH\u201d) examine every hidden-\ndimension run.   For every run we look at the recorded per-epoch tuples, choose\nthe \u201cbest\u201d value (minimum for losses, maximum for accuracies), and print them\nwith clear labels such as \u201ctraining loss\u201d or \u201cvalidation harmonic-weighted\naccuracy\u201d.   The script executes immediately, contains no `if __name__ ==\n\"__main__\":` guard, and produces only textual output\u2014no plots."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 1. Locate and load the experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment data at: {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# 2. Iterate through each dataset and print the final metrics\n# ------------------------------------------------------------------\nfor dataset_name, data in experiment_data.items():\n    print(f\"\\n{dataset_name}\")  # dataset header\n\n    # ---- losses ----\n    train_losses = data.get(\"losses\", {}).get(\"train\", [])\n    val_losses = data.get(\"losses\", {}).get(\"val\", [])\n\n    if train_losses:\n        _, final_train_loss = train_losses[-1]\n        print(f\"final training loss: {final_train_loss:.6f}\")\n\n    if val_losses:\n        _, final_val_loss = val_losses[-1]\n        print(f\"final validation loss: {final_val_loss:.6f}\")\n\n    # ---- validation metrics ----\n    val_metrics = data.get(\"metrics\", {}).get(\"val\", [])\n    if val_metrics:\n        _, final_swa, final_cwa, final_hwa = val_metrics[-1]\n        print(f\"final validation shape-weighted accuracy: {final_swa:.6f}\")\n        print(f\"final validation color-weighted accuracy: {final_cwa:.6f}\")\n        print(f\"final validation harmonic-weighted accuracy: {final_hwa:.6f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- iterate over datasets and runs ------------\nfor dataset_name, dataset_dict in experiment_data.get(\"epochs_tuning\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n    runs = dataset_dict.get(\"runs\", [])\n    for run_idx, run in enumerate(runs, 1):\n        epochs = run.get(\"epochs\", \"unknown\")\n        # fetch final values\n        final_train_loss = (\n            run[\"losses\"][\"train\"][-1][1] if run[\"losses\"][\"train\"] else None\n        )\n        final_val_loss = run[\"losses\"][\"val\"][-1][1]\n        _, swa, cwa, hwa = run[\"metrics\"][\"val\"][-1]\n\n        print(f\"  Run {run_idx} (epoch budget = {epochs})\")\n        if final_train_loss is not None:\n            print(f\"    Training loss (final epoch): {final_train_loss:.4f}\")\n        print(f\"    Validation loss (final epoch): {final_val_loss:.4f}\")\n        print(f\"    Validation shape weighted accuracy (final epoch): {swa:.4f}\")\n        print(f\"    Validation color weighted accuracy (final epoch): {cwa:.4f}\")\n        print(f\"    Validation harmonic weighted accuracy (final epoch): {hwa:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load the experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- helper to format a float to 4 decimal places ----------\nfmt = lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else str(x)\n\n# ---------- iterate through datasets and print final metrics ----------\nfor dataset_name, lr_dict in experiment_data.get(\"learning_rate\", {}).items():\n    # dataset_name is \"SPR_BENCH\"\n    print(dataset_name)\n    for lr, record in lr_dict.items():\n        # fetch final (last epoch) values\n        final_train_loss = record[\"losses\"][\"train\"][-1][1]  # (epoch, value)\n        final_val_loss = record[\"losses\"][\"val\"][-1][1]\n\n        _, final_swa, final_cwa, final_hwa = record[\"metrics\"][\"val\"][-1]\n\n        # print metrics\n        print(f\"  learning rate: {lr}\")\n        print(f\"    final training loss: {fmt(final_train_loss)}\")\n        print(f\"    final validation loss: {fmt(final_val_loss)}\")\n        print(f\"    final validation shape weighted accuracy: {fmt(final_swa)}\")\n        print(f\"    final validation color weighted accuracy: {fmt(final_cwa)}\")\n        print(f\"    final validation harmonic weighted accuracy: {fmt(final_hwa)}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\nbatch_size_dict = experiment_data.get(\"batch_size\", {})\n\n\n# ---------- helper to find best values ----------\ndef best_loss(loss_list):\n    \"\"\"Return the minimum loss across epochs.\"\"\"\n    if not loss_list:\n        return None\n    return min(loss for _, loss in loss_list)\n\n\ndef best_metric(metric_list):\n    \"\"\"Return the maximum metric across epochs.\"\"\"\n    if not metric_list:\n        return None\n    return max(val for _, *vals in metric_list for val in vals)  # flatten and max\n\n\n# ---------- iterate and print ----------\nfor bs_str in sorted(batch_size_dict.keys(), key=lambda x: int(x)):\n    record = batch_size_dict[bs_str]\n    train_losses = record[\"losses\"][\"train\"]\n    val_losses = record[\"losses\"][\"val\"]\n    val_metrics = record[\"metrics\"][\"val\"]  # list of (epoch, swa, cwa, hwa)\n\n    # Best losses\n    best_train_loss = best_loss(train_losses)\n    best_val_loss = best_loss(val_losses)\n\n    # Best accuracies\n    if val_metrics:\n        best_swa = max(metric[1] for metric in val_metrics)\n        best_cwa = max(metric[2] for metric in val_metrics)\n        best_hwa = max(metric[3] for metric in val_metrics)\n    else:\n        best_swa = best_cwa = best_hwa = None\n\n    # ---------- printing ----------\n    print(f\"Dataset: Batch size {bs_str}\")\n    if best_train_loss is not None:\n        print(f\"best training loss: {best_train_loss:.4f}\")\n    if best_val_loss is not None:\n        print(f\"best validation loss: {best_val_loss:.4f}\")\n    if best_swa is not None:\n        print(f\"best validation shape weighted accuracy: {best_swa:.4f}\")\n    if best_cwa is not None:\n        print(f\"best validation color weighted accuracy: {best_cwa:.4f}\")\n    if best_hwa is not None:\n        print(f\"best validation harmonic weighted accuracy: {best_hwa:.4f}\")\n    print()  # blank line for readability\n", "import os\nimport numpy as np\n\n# ---------- locate the saved numpy file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nnpy_path = os.path.join(working_dir, \"experiment_data.npy\")\nif not os.path.isfile(npy_path):\n    raise FileNotFoundError(f\"Cannot find experiment_data.npy in {working_dir}\")\n\nexperiment_data = np.load(npy_path, allow_pickle=True).item()\n\n\n# ---------- helper functions ---------------------\ndef best_value(pairs, higher_is_better=True):\n    \"\"\"\n    pairs: list of (epoch, value)\n    higher_is_better: bool, whether larger numbers are preferred\n    \"\"\"\n    if not pairs:\n        return None\n    key_fn = (lambda x: x[1]) if higher_is_better else (lambda x: -x[1])\n    best_epoch, best_val = max(pairs, key=key_fn)\n    return best_val\n\n\n# ---------- iterate and print metrics ------------\nfor dataset_name, dataset_runs in experiment_data.get(\"hidden_dim\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n    for hidden_size, run_store in dataset_runs.items():\n        train_losses = run_store[\"losses\"].get(\"train\", [])\n        val_losses = run_store[\"losses\"].get(\"val\", [])\n        val_metrics = run_store[\"metrics\"].get(\"val\", [])  # (epoch, swa, cwa, hwa)\n\n        best_train_loss = best_value(train_losses, higher_is_better=False)\n        best_val_loss = best_value(val_losses, higher_is_better=False)\n\n        if val_metrics:\n            # separate the tuples\n            swa_vals = [(ep, swa) for ep, swa, _, _ in val_metrics]\n            cwa_vals = [(ep, cwa) for ep, _, cwa, _ in val_metrics]\n            hwa_vals = [(ep, hwa) for ep, _, _, hwa in val_metrics]\n\n            best_swa = best_value(swa_vals)\n            best_cwa = best_value(cwa_vals)\n            best_hwa = best_value(hwa_vals)\n        else:\n            best_swa = best_cwa = best_hwa = None\n\n        print(f\"  hidden_dim = {hidden_size}\")\n        if best_train_loss is not None:\n            print(f\"    best training loss: {best_train_loss:.4f}\")\n        if best_val_loss is not None:\n            print(f\"    best validation loss: {best_val_loss:.4f}\")\n        if best_swa is not None:\n            print(f\"    best validation shape-weighted accuracy: {best_swa:.4f}\")\n        if best_cwa is not None:\n            print(f\"    best validation color-weighted accuracy: {best_cwa:.4f}\")\n        if best_hwa is not None:\n            print(f\"    best validation harmonic-weighted accuracy: {best_hwa:.4f}\")\n"], "parse_term_out": ["['\\nSPR_BENCH', '\\n', 'final training loss: 0.000666', '\\n', 'final validation\nloss: 0.001513', '\\n', 'final validation shape-weighted accuracy: 0.999767',\n'\\n', 'final validation color-weighted accuracy: 0.999756', '\\n', 'final\nvalidation harmonic-weighted accuracy: 0.999762', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', '  Run 1 (epoch budget = 6)', '\\n', '    Training\nloss (final epoch): 0.0007', '\\n', '    Validation loss (final epoch): 0.0015',\n'\\n', '    Validation shape weighted accuracy (final epoch): 0.9998', '\\n', '\nValidation color weighted accuracy (final epoch): 0.9998', '\\n', '    Validation\nharmonic weighted accuracy (final epoch): 0.9998', '\\n', '  Run 2 (epoch budget\n= 12)', '\\n', '    Training loss (final epoch): 0.0001', '\\n', '    Validation\nloss (final epoch): 0.0007', '\\n', '    Validation shape weighted accuracy\n(final epoch): 1.0000', '\\n', '    Validation color weighted accuracy (final\nepoch): 1.0000', '\\n', '    Validation harmonic weighted accuracy (final epoch):\n1.0000', '\\n', '  Run 3 (epoch budget = 18)', '\\n', '    Training loss (final\nepoch): 0.0000', '\\n', '    Validation loss (final epoch): 0.0004', '\\n', '\nValidation shape weighted accuracy (final epoch): 1.0000', '\\n', '    Validation\ncolor weighted accuracy (final epoch): 1.0000', '\\n', '    Validation harmonic\nweighted accuracy (final epoch): 1.0000', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', '  learning rate: 0.0003', '\\n', '    final training loss:\n0.0200', '\\n', '    final validation loss: 0.0192', '\\n', '    final validation\nshape weighted accuracy: 0.9938', '\\n', '    final validation color weighted\naccuracy: 0.9942', '\\n', '    final validation harmonic weighted accuracy:\n0.9940', '\\n', '  learning rate: 0.001', '\\n', '    final training loss:\n0.0009', '\\n', '    final validation loss: 0.0025', '\\n', '    final validation\nshape weighted accuracy: 0.9993', '\\n', '    final validation color weighted\naccuracy: 0.9993', '\\n', '    final validation harmonic weighted accuracy:\n0.9993', '\\n', '  learning rate: 0.003', '\\n', '    final training loss:\n0.0001', '\\n', '    final validation loss: 0.0011', '\\n', '    final validation\nshape weighted accuracy: 0.9995', '\\n', '    final validation color weighted\naccuracy: 0.9996', '\\n', '    final validation harmonic weighted accuracy:\n0.9996', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: Batch size 32', '\\n', 'best training loss: 0.0001', '\\n', 'best\nvalidation loss: 0.0005', '\\n', 'best validation shape weighted accuracy:\n1.0000', '\\n', 'best validation color weighted accuracy: 1.0000', '\\n', 'best\nvalidation harmonic weighted accuracy: 1.0000', '\\n', '\\n', 'Dataset: Batch size\n64', '\\n', 'best training loss: 0.0002', '\\n', 'best validation loss: 0.0009',\n'\\n', 'best validation shape weighted accuracy: 0.9998', '\\n', 'best validation\ncolor weighted accuracy: 0.9998', '\\n', 'best validation harmonic weighted\naccuracy: 0.9998', '\\n', '\\n', 'Dataset: Batch size 128', '\\n', 'best training\nloss: 0.0007', '\\n', 'best validation loss: 0.0015', '\\n', 'best validation\nshape weighted accuracy: 0.9998', '\\n', 'best validation color weighted\naccuracy: 0.9998', '\\n', 'best validation harmonic weighted accuracy: 0.9998',\n'\\n', '\\n', 'Dataset: Batch size 256', '\\n', 'best training loss: 0.0049', '\\n',\n'best validation loss: 0.0050', '\\n', 'best validation shape weighted accuracy:\n0.9981', '\\n', 'best validation color weighted accuracy: 0.9985', '\\n', 'best\nvalidation harmonic weighted accuracy: 0.9983', '\\n', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', '  hidden_dim = 64', '\\n', '    best training loss:\n0.0029', '\\n', '    best validation loss: 0.0047', '\\n', '    best validation\nshape-weighted accuracy: 0.9986', '\\n', '    best validation color-weighted\naccuracy: 0.9988', '\\n', '    best validation harmonic-weighted accuracy:\n0.9987', '\\n', '  hidden_dim = 128', '\\n', '    best training loss: 0.0008',\n'\\n', '    best validation loss: 0.0027', '\\n', '    best validation shape-\nweighted accuracy: 0.9992', '\\n', '    best validation color-weighted accuracy:\n0.9993', '\\n', '    best validation harmonic-weighted accuracy: 0.9992', '\\n', '\nhidden_dim = 256', '\\n', '    best training loss: 0.0004', '\\n', '    best\nvalidation loss: 0.0007', '\\n', '    best validation shape-weighted accuracy:\n1.0000', '\\n', '    best validation color-weighted accuracy: 1.0000', '\\n', '\nbest validation harmonic-weighted accuracy: 1.0000', '\\n', '  hidden_dim = 512',\n'\\n', '    best training loss: 0.0002', '\\n', '    best validation loss:\n0.0021', '\\n', '    best validation shape-weighted accuracy: 0.9991', '\\n', '\nbest validation color-weighted accuracy: 0.9992', '\\n', '    best validation\nharmonic-weighted accuracy: 0.9991', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']"], "parse_exc_type": [null, null, null, null, null], "parse_exc_info": [null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]}