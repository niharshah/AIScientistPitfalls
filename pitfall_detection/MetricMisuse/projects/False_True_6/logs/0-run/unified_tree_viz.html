<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[2, 10], [2, 11], [2, 9], [2, 12]], "layout": [[0.0, 0.0], [0.125, 0.0], [0.25, 0.0], [0.375, 0.0], [0.5, 0.0], [0.625, 0.0], [0.75, 0.0], [0.875, 0.0], [1.0, 0.0], [0.0625, 1.0], [0.1875, 1.0], [0.3125, 1.0], [0.4375, 1.0]], "plan": ["Hyperparam tuning name: EPOCHS. We extend the baseline by treating\n\u201cEPOCH_TUNING\u201d as the hyper-parameter experiment, train for up to 20 epochs and\napply early stopping (patience = 3) on the validation loss. The loop records\nlosses/metrics each epoch, keeps the best model weights, and halts when no\nfurther improvement is observed. After training, the best checkpoint is\nevaluated on the test set, metrics are stored in the experiment_data structure,\nand everything (including a bar-plot) is saved exactly as required.", "Ablation name: Multi-Dataset Generalisation (3\u00d7 Synthetic SPR Variants). The\nsolution generates three biased variants of the original SPR\u2010BENCH training\nsplit (different shape/length biases and random seeds), builds loaders for the\nunion of those variants, retrains the original HybridTransformer on the mixed\ndata and finally evaluates on the untouched SPR-BENCH dev/test splits. All\nlosses, metrics and predictions are logged in the required experiment_data\nstructure and saved to \u201cexperiment_data.npy\u201d, together with a validation\u2013SWA\ncurve.", "Ablation name: No-SymFeat Transformer. We drop the handcrafted symbolic features\nby removing the feature-norm layer and feeding only the pooled Transformer\nrepresentation to the classifier. The rest of the training / evaluation pipeline\nremains identical, allowing a direct comparison with the original\nHybridTransformer. All logs, metrics and artefacts are stored under the ablation\nkey \u201cNoSymFeatTransformer\u201d and saved to experiment_data.npy.", "Ablation name: CLS-Token Pooling. This ablation keeps the architecture identical\nto the baseline except for the sequence-level summarisation: a learnable [CLS]\ntoken is prepended at every step, a suitable padding mask is built, and after\nthe Transformer encoder only the hidden state of this first position is used\n(concatenated with the normalised symbolic features) for classification.  All\ndata loading, training, logging and plotting routines stay unchanged, ensuring\nthe study isolates the pooling strategy alone.", "Ablation name: No-Positional-Embedding. We remove explicit position embeddings\nfrom HybridTransformer by omitting the pos_emb layer and its addition, leaving\ntoken encodings as the sum of shape + color embeddings only. Everything else\n(training loop, metrics, plotting, saving) remains identical, enabling a direct\ncomparison with the baseline to assess how much SPR performance relies on\npositional information.", "Ablation name: Fixed-Sinusoidal-Position-Embedding. The solution keeps the full\ntraining / evaluation pipeline unchanged while swapping the learnable\npositional\u2010embedding table for a deterministic, non-trainable sinusoidal\nencoding that is stored as a buffer (`register_buffer`) inside the model. This\nisolates the effect of learned positional parameters. All logs, metrics and\nartefacts are still saved following the required naming convention.", "Ablation name: Concatenative Shape-Color Fusion. We incorporate a fusion\nargument into HybridTransformer:   \u2022 add (the original summation),   \u2022\nconcat_doubled (concatenate then use 2\u00b7d_model encoder), and   \u2022 concat_proj\n(concatenate then project back to d_model).   The script trains both the\nbaseline \u201cAdditive\u201d and the proposed \u201cConcatProj\u201d models on SPR-BENCH, logs\nidentical metrics, saves everything to experiment_data.npy, and produces\nseparate validation-SWA curves. All code is in one executable file.", "Ablation name: Color-Blind Transformer. We replicate the original training\npipeline but replace the encoder with a Color-Blind Transformer that completely\nignores colour: the colour-embedding matrix is replaced by a frozen all-zero\ntensor and is not added to the token representation, so the encoder sees only\nshape, position and global symmetry features. All logging, early-stopping,\nplotting and artefact saving remain unchanged, and results are stored under the\nkey \u201cColorBlindTransformer/SPR_BENCH\u201d.", "Ablation name: No-Transformer (Bag-of-Embeddings). The ablation replaces the\nTransformer encoder with a simple \u201cbag-of-embeddings\u201d reader that discards\npositional information. Shape and color token embeddings are summed, padded\npositions are ignored, and the mean vector across the sequence is concatenated\nwith layer-normalised symbolic features before the final classifier. Training,\nevaluation, logging, early stopping and artefact saving all mirror the baseline\nso results are directly comparable.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\"\"\"\nSingle-file script: GRU on SPR-BENCH with epoch-number tuning + early stopping.\n\"\"\"\nimport os, pathlib, time, math, json, random, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# --------------------------- house-keeping ---------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# --------------------------- experiment log scaffold -----------------\nexperiment_data = {\n    \"EPOCH_TUNING\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"EPOCH_TUNING\"][\"SPR_BENCH\"]  # shorthand\n\n\n# --------------------------- metric helpers --------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_t, y_p)) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_t, y_p)) / max(sum(w), 1)\n\n\ndef rule_signature(sequence: str) -> str:\n    return \" \".join(tok[0] for tok in sequence.strip().split() if tok)\n\n\n# --------------------------- data loading ----------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# --------------------------- vocab & encoding ------------------------\nPAD_TOKEN, UNK_TOKEN = \"<PAD>\", \"<UNK>\"\n\n\ndef build_vocab(dataset):\n    vocab = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n    tokens = set(itertools.chain.from_iterable(seq.strip().split() for seq in dataset))\n    for tok in sorted(tokens):\n        vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"][\"sequence\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\ndef encode_sequence(seq: str, vocab=vocab):\n    return [vocab.get(tok, vocab[UNK_TOKEN]) for tok in seq.strip().split()]\n\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\nprint(f\"Labels: {label_set}\")\n\n\n# --------------------------- torch datasets --------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"seq_enc\": torch.tensor(encode_sequence(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    seqs = [b[\"seq_enc\"] for b in batch]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    padded = nn.utils.rnn.pad_sequence(\n        seqs, batch_first=True, padding_value=vocab[PAD_TOKEN]\n    )\n    return {\"input_ids\": padded, \"labels\": labels, \"raw_seq\": raw}\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\n\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate_fn)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate_fn)\n\n\n# --------------------------- model -----------------------------------\nclass GRUClassifier(nn.Module):\n    def __init__(self, vocab_size, emb=32, hidden=64, num_labels=2):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, emb, padding_idx=0)\n        self.gru = nn.GRU(emb, hidden, batch_first=True)\n        self.fc = nn.Linear(hidden, num_labels)\n\n    def forward(self, input_ids):\n        x = self.embedding(input_ids)\n        _, h = self.gru(x)\n        return self.fc(h.squeeze(0))\n\n\nmodel = GRUClassifier(len(vocab), 32, 64, len(label_set)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# Precompute signatures for NRGS\ntrain_signatures = set(rule_signature(s) for s in spr[\"train\"][\"sequence\"])\n\n\n# --------------------------- evaluation ------------------------------\ndef evaluate(loader):\n    model.eval()\n    total, corr, loss_sum = 0, 0, 0.0\n    all_seq, all_true, all_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            inp = batch[\"input_ids\"].to(device)\n            lab = batch[\"labels\"].to(device)\n            logits = model(inp)\n            loss = criterion(logits, lab)\n            loss_sum += loss.item() * len(lab)\n            pred = logits.argmax(dim=-1)\n            corr += (pred == lab).sum().item()\n            total += len(lab)\n            all_seq.extend(batch[\"raw_seq\"])\n            all_true.extend(lab.cpu().tolist())\n            all_pred.extend(pred.cpu().tolist())\n    acc = corr / total\n    swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n    cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n    novel_mask = [rule_signature(s) not in train_signatures for s in all_seq]\n    novel_tot = sum(novel_mask)\n    novel_corr = sum(\n        int(p == t) for p, t, m in zip(all_pred, all_true, novel_mask) if m\n    )\n    nrgs = novel_corr / novel_tot if novel_tot else 0.0\n    return loss_sum / total, acc, swa, cwa, nrgs, all_pred, all_true, all_seq\n\n\n# --------------------------- training loop ---------------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, best_state, epochs_no_improve = math.inf, None, 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"])\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = running_loss / len(train_ds)\n\n    val_loss, val_acc, val_swa, val_cwa, val_nrgs, *_ = evaluate(dev_loader)\n\n    print(\n        f\"Epoch {epoch:02d}/{MAX_EPOCHS}: \"\n        f\"train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n        f\"acc={val_acc:.3f}  SWA={val_swa:.3f}  CWA={val_cwa:.3f}  NRGS={val_nrgs:.3f}\"\n    )\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"metrics\"][\"train\"].append({\"epoch\": epoch})\n    exp_rec[\"metrics\"][\"val\"].append(\n        {\n            \"epoch\": epoch,\n            \"acc\": val_acc,\n            \"swa\": val_swa,\n            \"cwa\": val_cwa,\n            \"nrgs\": val_nrgs,\n        }\n    )\n    exp_rec[\"timestamps\"].append(time.time())\n\n    # --- early stopping bookkeeping ---\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss, best_state = val_loss, model.state_dict()\n        epochs_no_improve = 0\n    else:\n        epochs_no_improve += 1\n        if epochs_no_improve >= PATIENCE:\n            print(f\"No improvement for {PATIENCE} epochs, stopping early.\")\n            break\n\n# restore best model\nif best_state is not None:\n    model.load_state_dict(best_state)\n\n# --------------------------- final test eval -------------------------\ntest_loss, test_acc, test_swa, test_cwa, test_nrgs, preds, trues, seqs = evaluate(\n    test_loader\n)\nprint(\n    \"\\nTEST RESULTS  \"\n    f\"loss={test_loss:.4f}  acc={test_acc:.3f}  \"\n    f\"SWA={test_swa:.3f}  CWA={test_cwa:.3f}  NRGS={test_nrgs:.3f}\"\n)\n\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\nexp_rec[\"metrics\"][\"test\"] = {\n    \"loss\": test_loss,\n    \"acc\": test_acc,\n    \"swa\": test_swa,\n    \"cwa\": test_cwa,\n    \"nrgs\": test_nrgs,\n}\n\n# --------------------------- save artefacts --------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Experiment data saved to {os.path.join(working_dir,'experiment_data.npy')}\")\n\n# quick visualisation\nfig, ax = plt.subplots(figsize=(6, 4))\nax.bar(\n    [\"Acc\", \"SWA\", \"CWA\", \"NRGS\"],\n    [test_acc, test_swa, test_cwa, test_nrgs],\n    color=\"skyblue\",\n)\nax.set_ylim(0, 1)\nax.set_title(\"SPR_BENCH Test Metrics\")\nplt.tight_layout()\nplot_path = os.path.join(working_dir, \"spr_metrics_bar.png\")\nplt.savefig(plot_path)\nprint(f\"Plot saved to {plot_path}\")\n", "# ----------------------------------------------------\n# Multi-Dataset Generalisation Ablation\n# ----------------------------------------------------\nimport os, pathlib, math, time, itertools, numpy as np, torch, random\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ---------------- housekeeping -----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Running on\", device)\n\n# --------------- experiment log ---------------------\nexperiment_data = {\n    \"MultiDataset\": {\n        \"SPR_BENCH_HELDOUT\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"MultiDataset\"][\"SPR_BENCH_HELDOUT\"]\n\n# --------------- load original SPR_BENCH ------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\nspr = load_spr_bench(DATA_PATH)\nprint(\"Original sizes:\", {k: len(v) for k, v in spr.items()})\n\n# --------------- utilities --------------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(chars_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(chars_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab, color_vocab = build_char_vocab(shape_chars), build_char_vocab(color_chars)\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# --------------- torch dataset ----------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, sequences, labels):\n        self.seqs, self.labels = sequences, labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids),\n            \"color_ids\": torch.tensor(cids),\n            \"sym_feats\": feats,\n            \"label\": torch.tensor(label2idx[self.labels[idx]]),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\n# --------------- variant creation -------------------\ndef create_variant(seed: int, bias: str):\n    random.seed(seed)\n    np.random.seed(seed)\n    seqs, labels = spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"]\n    if bias == \"shape_A\":\n        fav = [i for i, s in enumerate(seqs) if s.split()[0][0] == \"A\"]\n    elif bias == \"short\":\n        fav = [i for i, s in enumerate(seqs) if len(s.split()) <= 6]\n    elif bias == \"long\":\n        fav = [i for i, s in enumerate(seqs) if len(s.split()) >= 10]\n    else:\n        fav = list(range(len(seqs)))\n    prob = np.ones(len(seqs))\n    prob[fav] *= 5.0  # up-weight favourites\n    prob /= prob.sum()\n    idxs = np.random.choice(len(seqs), size=len(seqs), replace=True, p=prob)\n    return [seqs[i] for i in idxs], [labels[i] for i in idxs]\n\n\nvariant_specs = [(111, \"shape_A\"), (222, \"short\"), (333, \"long\")]\nvariant_datasets = []\nfor seed, bias in variant_specs:\n    v_seqs, v_labels = create_variant(seed, bias)\n    variant_datasets.append(SPRTorchDataset(v_seqs, v_labels))\nprint(\"Built {} variants.\".format(len(variant_datasets)))\n\n# --------------- loaders ----------------------------\ntrain_dataset = ConcatDataset(variant_datasets)\ntrain_loader = DataLoader(train_dataset, 128, shuffle=True, collate_fn=collate)\n\ndev_ds = SPRTorchDataset(spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"])\ntest_ds = SPRTorchDataset(spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"])\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# --------------- model ------------------------------\nclass HybridTransformer(nn.Module):\n    def __init__(self, s_vocab, c_vocab, num_labels, d_model=64, nhead=4, nlayers=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(512, d_model)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, 128, 0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n        self.feat_norm = nn.LayerNorm(3)\n        self.fc = nn.Linear(d_model + 3, num_labels)\n\n    def forward(self, shape_ids, color_ids, sym_feats):\n        seq_len = shape_ids.size(1)\n        pos = (\n            torch.arange(seq_len, device=shape_ids.device)\n            .unsqueeze(0)\n            .expand(shape_ids.size(0), -1)\n        )\n        x = self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        mask = shape_ids.eq(0)\n        h = self.encoder(x, src_key_padding_mask=mask)\n        pooled = h.masked_fill(mask.unsqueeze(-1), 0).sum(1) / (~mask).sum(\n            1, keepdim=True\n        ).clamp(min=1)\n        logits = self.fc(torch.cat([pooled, self.feat_norm(sym_feats)], dim=-1))\n        return logits\n\n\nmodel = HybridTransformer(len(shape_vocab), len(color_vocab), len(label_set)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# --------------- evaluation -------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            bt = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(bt[\"shape_ids\"], bt[\"color_ids\"], bt[\"sym_feats\"])\n            loss = criterion(logits, bt[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = bt[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(bt[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (tot_loss / total, shape_weighted_accuracy(all_seq, y_true, y_pred))\n\n\n# --------------- training loop ----------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = float(\"inf\"), 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        bt = {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()}\n        optimizer.zero_grad()\n        logits = model(bt[\"shape_ids\"], bt[\"color_ids\"], bt[\"sym_feats\"])\n        loss = criterion(logits, bt[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * bt[\"labels\"].size(0)\n    train_loss = running / len(train_dataset)\n    val_loss, val_swa = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d} | train {train_loss:.4f} | val {val_loss:.4f} | SWA {val_swa:.3f}\"\n    )\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# --------------- final test -------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa = evaluate(test_loader)\nprint(f\"\\nTEST \u2011 loss {test_loss:.4f} | SWA {test_swa:.3f}\")\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"SWA\"][\"test\"] = test_swa\n\n# --------------- predictions for saving -------------\nmodel.eval()\npreds, trues, seqs = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        bt = {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()}\n        out = model(bt[\"shape_ids\"], bt[\"color_ids\"], bt[\"sym_feats\"]).argmax(-1)\n        preds.extend(out.cpu().tolist())\n        trues.extend(bt[\"labels\"].cpu().tolist())\n        seqs.extend(batch[\"raw_seq\"])\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# --------------- save artefacts ---------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Plot saved.\")\n", "import os, pathlib, math, time, itertools, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------- housekeeping & GPU ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------- experiment log --------------------\nexperiment_data = {\n    \"NoSymFeatTransformer\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"NoSymFeatTransformer\"][\"SPR_BENCH\"]\n\n\n# ---------------- dataset helpers -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# ---------------- load data -------------------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# ---------------- vocabularies ----------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab = build_char_vocab(shape_chars)\ncolor_vocab = build_char_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# ---------------- encoding utilities ----------------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# ---------------- torch dataset ---------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,  # still produced but ignored in ablation\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# ---------------- model (No-SymFeat Transformer) ----\nclass NoSymFeatTransformer(nn.Module):\n    def __init__(self, s_vocab, c_vocab, num_labels, d_model=64, nhead=4, nlayers=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(512, d_model)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n        self.fc = nn.Linear(d_model, num_labels)\n\n    def forward(self, shape_ids, color_ids, _sym_feats=None):  # feat ignored\n        seq_len = shape_ids.size(1)\n        pos = (\n            torch.arange(seq_len, device=shape_ids.device)\n            .unsqueeze(0)\n            .expand(shape_ids.size(0), -1)\n        )\n        x = self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        mask = shape_ids.eq(0)\n        h = self.encoder(x, src_key_padding_mask=mask)\n        pooled = h.masked_fill(mask.unsqueeze(-1), 0).sum(1) / (~mask).sum(\n            1, keepdim=True\n        ).clamp(min=1)\n        return self.fc(pooled)\n\n\nmodel = NoSymFeatTransformer(len(shape_vocab), len(color_vocab), len(label_set)).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------------- evaluation ------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# ---------------- training loop ---------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = math.inf, 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# load best\nmodel.load_state_dict(best_state)\n\n# ---------------- final test ------------------------\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# ---------------- save artefacts --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA (No-SymFeat)\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n", "# CLS-TOKEN POOLING ABLATION \u2013 self-contained script\nimport os, pathlib, math, time, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ------- bookkeeping & GPU ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------- experiment dict scaffold ----\nexperiment_data = {\n    \"CLS_Pooling\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"CLS_Pooling\"][\"SPR_BENCH\"]\n\n\n# ---------- dataset helpers ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# ---------- load data ----------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# ---------- vocabularies ------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab, color_vocab = build_char_vocab(shape_chars), build_char_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# ---------- encoding utilities -------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# ---------- torch datasets -----------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# ---------- model with CLS pooling ---\nclass HybridTransformerCLS(nn.Module):\n    def __init__(\n        self, s_vocab, c_vocab, num_labels, d_model=64, nhead=4, nlayers=2, max_len=512\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(max_len + 1, d_model)  # +1 for CLS position\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))  # learnable CLS\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n        self.feat_norm = nn.LayerNorm(3)\n        self.fc = nn.Linear(d_model + 3, num_labels)\n        nn.init.normal_(self.cls_token, std=0.02)\n\n    def forward(self, shape_ids, color_ids, sym_feats):\n        B, L = shape_ids.size()\n        device = shape_ids.device\n        tok_emb = self.shape_emb(shape_ids) + self.color_emb(color_ids)\n        pos_ids = torch.arange(1, L + 1, device=device).unsqueeze(0).expand(B, -1)\n        tok_emb = tok_emb + self.pos_emb(pos_ids)\n        cls_emb = self.cls_token.expand(B, -1, -1) + self.pos_emb(\n            torch.zeros(B, 1, dtype=torch.long, device=device)\n        )\n        x = torch.cat([cls_emb, tok_emb], dim=1)  # [B, L+1, d]\n        pad_mask = shape_ids.eq(0)  # [B, L]\n        src_mask = torch.cat(\n            [torch.zeros(B, 1, dtype=torch.bool, device=device), pad_mask], dim=1\n        )\n        h = self.encoder(x, src_key_padding_mask=src_mask)\n        pooled = h[:, 0]  # CLS state\n        logits = self.fc(torch.cat([pooled, self.feat_norm(sym_feats)], dim=-1))\n        return logits\n\n\nmodel = HybridTransformerCLS(len(shape_vocab), len(color_vocab), len(label_set)).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------- evaluation ---------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss = total = 0.0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# ---------- training loop ------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val, no_imp, best_state = math.inf, 0, None\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n    if val_loss < best_val - 1e-4:\n        best_val = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n    if no_imp >= PATIENCE:\n        print(\"Early stopping.\")\n        break\n\n# ---------- load best & test ----------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# ---------- save artefacts -----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n", "import os, pathlib, math, time, itertools, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------- housekeeping & GPU ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# --------------- experiment log scaffold ------------\nexperiment_data = {\n    \"NoPositionalEmbedding\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"NoPositionalEmbedding\"][\"SPR_BENCH\"]\n\n\n# --------------- dataset helpers --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# --------------- load data --------------------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# --------------- vocabularies -----------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab = build_vocab(shape_chars)\ncolor_vocab = build_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# --------------- encoding utilities -----------------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# --------------- torch dataset ----------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# --------------- model ------------------------------\nclass HybridTransformerNoPos(nn.Module):\n    def __init__(self, s_vocab, c_vocab, num_labels, d_model=64, nhead=4, nlayers=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n        self.feat_norm = nn.LayerNorm(3)\n        self.fc = nn.Linear(d_model + 3, num_labels)\n\n    def forward(self, shape_ids, color_ids, sym_feats):\n        x = self.shape_emb(shape_ids) + self.color_emb(\n            color_ids\n        )  # NO positional embedding\n        mask = shape_ids.eq(0)\n        h = self.encoder(x, src_key_padding_mask=mask)\n        pooled = h.masked_fill(mask.unsqueeze(-1), 0).sum(1) / (~mask).sum(\n            1, keepdim=True\n        ).clamp(min=1)\n        logits = self.fc(torch.cat([pooled, self.feat_norm(sym_feats)], dim=-1))\n        return logits\n\n\nmodel = HybridTransformerNoPos(len(shape_vocab), len(color_vocab), len(label_set)).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# --------------- evaluation -------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# --------------- training loop ----------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = math.inf, 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# --------------- final test -------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# --------------- save artefacts ---------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA (No Pos Emb)\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n", "# ---------------- Fixed-Sinusoidal-Positional-Embedding ablation ---------------\n# Entire runnable script (single file)\n\nimport os, pathlib, math, time, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# --------------- experiment bookkeeping ---------------------------------------\nexperiment_data = {\n    \"FixedSinusoidalPosEmb\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"FixedSinusoidalPosEmb\"][\"SPR_BENCH\"]\n\n# ---------------- housekeeping & GPU ------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# --------------- dataset helpers ---------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# ---------------- load data ---------------------------------------------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# ---------------- vocabularies ------------------------------------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        vocab.setdefault(ch, len(vocab))\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab = build_char_vocab(shape_chars)\ncolor_vocab = build_char_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# ---------------- encoding utilities ------------------------------------------\ndef encode_seq(seq: str):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# ---------------- torch dataset ----------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# --------------- model with fixed sinusoidal PE --------------------------------\nclass HybridTransformer(nn.Module):\n    def __init__(\n        self, s_vocab, c_vocab, num_labels, d_model=64, nhead=4, nlayers=2, max_len=512\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n\n        # precompute sinusoidal positional encoding and store as buffer\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n        div_term = torch.exp(\n            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n        )\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        self.register_buffer(\"pos_enc\", pe)  # non-trainable\n\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n        self.feat_norm = nn.LayerNorm(3)\n        self.fc = nn.Linear(d_model + 3, num_labels)\n\n    def forward(self, shape_ids, color_ids, sym_feats):\n        seq_len = shape_ids.size(1)\n        pos = self.pos_enc[:seq_len].unsqueeze(0)  # (1, seq, dim)\n        x = self.shape_emb(shape_ids) + self.color_emb(color_ids) + pos\n        mask = shape_ids.eq(0)  # PAD mask\n        h = self.encoder(x, src_key_padding_mask=mask)\n        pooled = h.masked_fill(mask.unsqueeze(-1), 0).sum(1) / (~mask).sum(\n            1, keepdim=True\n        ).clamp(min=1)\n        logits = self.fc(torch.cat([pooled, self.feat_norm(sym_feats)], dim=-1))\n        return logits\n\n\nmodel = HybridTransformer(len(shape_vocab), len(color_vocab), len(label_set)).to(device)\ncriterion, optimizer = nn.CrossEntropyLoss(), torch.optim.Adam(\n    model.parameters(), lr=1e-3\n)\n\n\n# ---------------- evaluation ---------------------------------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: v.to(device) if torch.is_tensor(v) else v for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# ---------------- training loop ------------------------------------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = math.inf, 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: v.to(device) if torch.is_tensor(v) else v for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# ---------------- final evaluation --------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# ---------------- save artefacts ----------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n", "#!/usr/bin/env python3\nimport os, pathlib, math, time, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ---------------- housekeeping & GPU ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------- experiment dict -------------------\ndef blank_rec():\n    return {\n        \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"SWA\": {\"val\": [], \"test\": None},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n\n\nexperiment_data = {\n    \"Additive\": {\"SPR_BENCH\": blank_rec()},\n    \"ConcatProj\": {\"SPR_BENCH\": blank_rec()},\n}\n\n\n# ---------------- dataset helpers -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\", data_files=str(root / split_csv), split=\"train\", cache_dir=\".cache\"\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# ---------------- load data -------------------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# ---------------- vocabularies ----------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab = build_char_vocab(shape_chars)\ncolor_vocab = build_char_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, l in enumerate(label_set)}\n\n\n# ---------------- encoding utilities ----------------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# ---------------- torch dataset ---------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# ---------------- model -----------------------------\nclass HybridTransformer(nn.Module):\n    def __init__(\n        self,\n        s_vocab,\n        c_vocab,\n        num_labels,\n        d_model=64,\n        nhead=4,\n        nlayers=2,\n        fusion=\"add\",  # 'add' | 'concat-doubled' | 'concat-proj'\n    ):\n        super().__init__()\n        assert fusion in {\"add\", \"concat-doubled\", \"concat-proj\"}\n        self.fusion = fusion\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n\n        if fusion == \"add\":\n            enc_dim = d_model\n            self.pos_emb = nn.Embedding(512, enc_dim)\n            encoder_layer = nn.TransformerEncoderLayer(\n                enc_dim, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n            )\n            self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n            self.fc = nn.Linear(enc_dim + 3, num_labels)\n\n        elif fusion == \"concat-doubled\":\n            enc_dim = d_model * 2\n            self.pos_emb = nn.Embedding(512, enc_dim)\n            encoder_layer = nn.TransformerEncoderLayer(\n                enc_dim,\n                nhead * 2,  # keep head dim same\n                dim_feedforward=256,\n                dropout=0.1,\n                batch_first=True,\n            )\n            self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n            self.fc = nn.Linear(enc_dim + 3, num_labels)\n\n        else:  # concat-proj\n            self.concat_proj = nn.Linear(d_model * 2, d_model)\n            enc_dim = d_model\n            self.pos_emb = nn.Embedding(512, enc_dim)\n            encoder_layer = nn.TransformerEncoderLayer(\n                enc_dim, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n            )\n            self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n            self.fc = nn.Linear(enc_dim + 3, num_labels)\n\n        self.feat_norm = nn.LayerNorm(3)\n\n    def forward(self, shape_ids, color_ids, sym_feats):\n        B, L = shape_ids.size()\n        pos = torch.arange(L, device=shape_ids.device).unsqueeze(0).expand(B, -1)\n        se = self.shape_emb(shape_ids)\n        ce = self.color_emb(color_ids)\n\n        if self.fusion == \"add\":\n            x = se + ce + self.pos_emb(pos)\n        elif self.fusion == \"concat-doubled\":\n            x = torch.cat([se, ce], dim=-1) + self.pos_emb(pos)\n        else:  # concat-proj\n            x = self.concat_proj(torch.cat([se, ce], dim=-1)) + self.pos_emb(pos)\n\n        mask = shape_ids.eq(0)\n        h = self.encoder(x, src_key_padding_mask=mask)\n        pooled = h.masked_fill(mask.unsqueeze(-1), 0).sum(1) / (~mask).sum(\n            1, keepdim=True\n        ).clamp(min=1)\n        logits = self.fc(torch.cat([pooled, self.feat_norm(sym_feats)], dim=-1))\n        return logits\n\n\n# ---------------- train / eval helpers --------------\ndef evaluate(model, loader, criterion):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            pred = logits.argmax(-1)\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\ndef train_model(tag, fusion):\n    print(f\"\\n===== Training {tag} ({fusion}) =====\")\n    rec = experiment_data[tag][\"SPR_BENCH\"]\n    model = HybridTransformer(\n        len(shape_vocab), len(color_vocab), len(label_set), fusion=fusion\n    ).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    MAX_EPOCHS, PATIENCE = 20, 3\n    best_val_loss, no_imp = math.inf, 0\n\n    for epoch in range(1, MAX_EPOCHS + 1):\n        model.train()\n        running = 0.0\n        for batch in train_loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            running += loss.item() * batch_t[\"labels\"].size(0)\n\n        train_loss = running / len(train_ds)\n        val_loss, val_swa, *_ = evaluate(model, dev_loader, criterion)\n        print(\n            f\"{tag} Epoch {epoch:02d}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} SWA={val_swa:.3f}\"\n        )\n\n        rec[\"losses\"][\"train\"].append(train_loss)\n        rec[\"losses\"][\"val\"].append(val_loss)\n        rec[\"SWA\"][\"val\"].append(val_swa)\n        rec[\"timestamps\"].append(time.time())\n\n        if val_loss < best_val_loss - 1e-4:\n            best_val_loss = val_loss\n            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n            no_imp = 0\n        else:\n            no_imp += 1\n            if no_imp >= PATIENCE:\n                print(\"Early stopping.\")\n                break\n\n    model.load_state_dict(best_state)\n    test_loss, test_swa, preds, trues, seqs = evaluate(model, test_loader, criterion)\n    rec[\"SWA\"][\"test\"] = test_swa\n    rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\n    rec[\"predictions\"], rec[\"ground_truth\"] = preds, trues\n    print(f\"{tag} TEST: loss={test_loss:.4f} SWA={test_swa:.3f}\")\n    return rec\n\n\n# ---------------- run experiments -------------------\nadd_rec = train_model(\"Additive\", \"add\")\nconcat_rec = train_model(\"ConcatProj\", \"concat-proj\")\n\n# ---------------- save artefacts --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(add_rec[\"SWA\"][\"val\"], label=\"Additive\")\nplt.plot(concat_rec[\"SWA\"][\"val\"], label=\"ConcatProj\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation SWA\")\nplt.title(\"Validation SWA Comparison\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n", "import os, pathlib, math, time, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# -------------- housekeeping & GPU -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# -------------- experiment log scaffold ------------\nexperiment_data = {\n    \"ColorBlindTransformer\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"ColorBlindTransformer\"][\"SPR_BENCH\"]\n\n\n# -------------- dataset helpers --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# -------------- load data --------------------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# -------------- vocabularies -----------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab, color_vocab = build_char_vocab(shape_chars), build_char_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# -------------- encoding utilities -----------------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# -------------- torch dataset ----------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# -------------- Color-Blind Transformer ------------\nclass ColorBlindTransformer(nn.Module):\n    def __init__(self, s_vocab, num_labels, d_model=64, nhead=4, nlayers=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        # colour embedding is an all-zero, non-trainable parameter kept for interface completeness\n        self.register_buffer(\"color_zero\", torch.zeros(1))\n        self.pos_emb = nn.Embedding(512, d_model)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n        self.feat_norm = nn.LayerNorm(3)\n        self.fc = nn.Linear(d_model + 3, num_labels)\n\n    def forward(self, shape_ids, color_ids, sym_feats):\n        seq_len = shape_ids.size(1)\n        pos = (\n            torch.arange(seq_len, device=shape_ids.device)\n            .unsqueeze(0)\n            .expand(shape_ids.size(0), -1)\n        )\n        x = self.shape_emb(shape_ids) + self.pos_emb(pos)  # colour information omitted\n        mask = shape_ids.eq(0)\n        h = self.encoder(x, src_key_padding_mask=mask)\n        pooled = h.masked_fill(mask.unsqueeze(-1), 0).sum(1) / (~mask).sum(\n            1, keepdim=True\n        ).clamp(min=1)\n        sym_norm = self.feat_norm(sym_feats)\n        logits = self.fc(torch.cat([pooled, sym_norm], dim=-1))\n        return logits\n\n\nmodel = ColorBlindTransformer(len(shape_vocab), len(label_set)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(\n    filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3\n)\n\n\n# -------------- evaluation -------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# -------------- training loop ----------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = math.inf, 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# -------------- final test -------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# -------------- save artefacts ---------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\"), plt.ylabel(\"SWA\")\nplt.title(\"Validation SWA\"), plt.legend(), plt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n", "import os, pathlib, math, time, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ---------------- housekeeping & GPU ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# --------------- experiment log scaffold ------------\nexperiment_data = {\n    \"BagOfEmbeddings\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"BagOfEmbeddings\"][\"SPR_BENCH\"]\n\n\n# --------------- dataset helpers --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# --------------- load data --------------------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# --------------- vocabularies -----------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab = build_char_vocab(shape_chars)\ncolor_vocab = build_char_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# --------------- encoding utilities -----------------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# --------------- torch dataset ----------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# --------------- Bag-of-Embeddings model ------------\nclass BagOfEmbeddings(nn.Module):\n    def __init__(self, s_vocab, c_vocab, num_labels, d_model=64):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        self.feat_norm = nn.LayerNorm(3)\n        self.fc = nn.Sequential(nn.Linear(d_model + 3, num_labels))\n\n    def forward(self, shape_ids, color_ids, sym_feats):\n        emb = self.shape_emb(shape_ids) + self.color_emb(color_ids)\n        mask = shape_ids.eq(0)\n        emb = emb.masked_fill(mask.unsqueeze(-1), 0)\n        denom = (~mask).sum(dim=1, keepdim=True).clamp(min=1)\n        pooled = emb.sum(dim=1) / denom\n        sym_norm = self.feat_norm(sym_feats)\n        logits = self.fc(torch.cat([pooled, sym_norm], dim=-1))\n        return logits\n\n\nmodel = BagOfEmbeddings(len(shape_vocab), len(color_vocab), len(label_set)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# --------------- evaluation -------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# --------------- training loop ----------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = math.inf, 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# load best\nmodel.load_state_dict(best_state)\n\n# --------------- final test -------------------------\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# --------------- save artefacts ---------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA (Bag-of-Embeddings)\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, math, time, itertools, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------- housekeeping & GPU ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------- experiment log --------------------\nexperiment_data = {\n    \"NoSymFeatTransformer\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"NoSymFeatTransformer\"][\"SPR_BENCH\"]\n\n\n# ---------------- dataset helpers -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# ---------------- load data -------------------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# ---------------- vocabularies ----------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab = build_char_vocab(shape_chars)\ncolor_vocab = build_char_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# ---------------- encoding utilities ----------------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# ---------------- torch dataset ---------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,  # still produced but ignored in ablation\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# ---------------- model (No-SymFeat Transformer) ----\nclass NoSymFeatTransformer(nn.Module):\n    def __init__(self, s_vocab, c_vocab, num_labels, d_model=64, nhead=4, nlayers=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(512, d_model)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n        self.fc = nn.Linear(d_model, num_labels)\n\n    def forward(self, shape_ids, color_ids, _sym_feats=None):  # feat ignored\n        seq_len = shape_ids.size(1)\n        pos = (\n            torch.arange(seq_len, device=shape_ids.device)\n            .unsqueeze(0)\n            .expand(shape_ids.size(0), -1)\n        )\n        x = self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        mask = shape_ids.eq(0)\n        h = self.encoder(x, src_key_padding_mask=mask)\n        pooled = h.masked_fill(mask.unsqueeze(-1), 0).sum(1) / (~mask).sum(\n            1, keepdim=True\n        ).clamp(min=1)\n        return self.fc(pooled)\n\n\nmodel = NoSymFeatTransformer(len(shape_vocab), len(color_vocab), len(label_set)).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------------- evaluation ------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# ---------------- training loop ---------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = math.inf, 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# load best\nmodel.load_state_dict(best_state)\n\n# ---------------- final test ------------------------\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# ---------------- save artefacts --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA (No-SymFeat)\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, math, time, itertools, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------- housekeeping & GPU ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------- experiment log --------------------\nexperiment_data = {\n    \"NoSymFeatTransformer\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"NoSymFeatTransformer\"][\"SPR_BENCH\"]\n\n\n# ---------------- dataset helpers -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# ---------------- load data -------------------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# ---------------- vocabularies ----------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab = build_char_vocab(shape_chars)\ncolor_vocab = build_char_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# ---------------- encoding utilities ----------------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# ---------------- torch dataset ---------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,  # still produced but ignored in ablation\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# ---------------- model (No-SymFeat Transformer) ----\nclass NoSymFeatTransformer(nn.Module):\n    def __init__(self, s_vocab, c_vocab, num_labels, d_model=64, nhead=4, nlayers=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(512, d_model)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n        self.fc = nn.Linear(d_model, num_labels)\n\n    def forward(self, shape_ids, color_ids, _sym_feats=None):  # feat ignored\n        seq_len = shape_ids.size(1)\n        pos = (\n            torch.arange(seq_len, device=shape_ids.device)\n            .unsqueeze(0)\n            .expand(shape_ids.size(0), -1)\n        )\n        x = self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        mask = shape_ids.eq(0)\n        h = self.encoder(x, src_key_padding_mask=mask)\n        pooled = h.masked_fill(mask.unsqueeze(-1), 0).sum(1) / (~mask).sum(\n            1, keepdim=True\n        ).clamp(min=1)\n        return self.fc(pooled)\n\n\nmodel = NoSymFeatTransformer(len(shape_vocab), len(color_vocab), len(label_set)).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------------- evaluation ------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# ---------------- training loop ---------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = math.inf, 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# load best\nmodel.load_state_dict(best_state)\n\n# ---------------- final test ------------------------\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# ---------------- save artefacts --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA (No-SymFeat)\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, math, time, itertools, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------- housekeeping & GPU ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------- experiment log --------------------\nexperiment_data = {\n    \"NoSymFeatTransformer\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"NoSymFeatTransformer\"][\"SPR_BENCH\"]\n\n\n# ---------------- dataset helpers -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# ---------------- load data -------------------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# ---------------- vocabularies ----------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab = build_char_vocab(shape_chars)\ncolor_vocab = build_char_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# ---------------- encoding utilities ----------------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# ---------------- torch dataset ---------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,  # still produced but ignored in ablation\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# ---------------- model (No-SymFeat Transformer) ----\nclass NoSymFeatTransformer(nn.Module):\n    def __init__(self, s_vocab, c_vocab, num_labels, d_model=64, nhead=4, nlayers=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(512, d_model)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n        self.fc = nn.Linear(d_model, num_labels)\n\n    def forward(self, shape_ids, color_ids, _sym_feats=None):  # feat ignored\n        seq_len = shape_ids.size(1)\n        pos = (\n            torch.arange(seq_len, device=shape_ids.device)\n            .unsqueeze(0)\n            .expand(shape_ids.size(0), -1)\n        )\n        x = self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        mask = shape_ids.eq(0)\n        h = self.encoder(x, src_key_padding_mask=mask)\n        pooled = h.masked_fill(mask.unsqueeze(-1), 0).sum(1) / (~mask).sum(\n            1, keepdim=True\n        ).clamp(min=1)\n        return self.fc(pooled)\n\n\nmodel = NoSymFeatTransformer(len(shape_vocab), len(color_vocab), len(label_set)).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------------- evaluation ------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# ---------------- training loop ---------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = math.inf, 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# load best\nmodel.load_state_dict(best_state)\n\n# ---------------- final test ------------------------\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# ---------------- save artefacts --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA (No-SymFeat)\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 465847.44\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 620753.02\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 389736.38\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize: 18', '\\n', 'Labels: [0, 1]', '\\n', 'Epoch 01/20: train_loss=0.3444\nval_loss=0.1715  acc=0.941  SWA=0.943  CWA=0.942  NRGS=0.907', '\\n', 'Epoch\n02/20: train_loss=0.1467  val_loss=0.1293  acc=0.958  SWA=0.961  CWA=0.959\nNRGS=0.933', '\\n', 'Epoch 03/20: train_loss=0.1117  val_loss=0.0969  acc=0.974\nSWA=0.974  CWA=0.974  NRGS=0.959', '\\n', 'Epoch 04/20: train_loss=0.0768\nval_loss=0.0596  acc=0.982  SWA=0.982  CWA=0.982  NRGS=0.959', '\\n', 'Epoch\n05/20: train_loss=0.0524  val_loss=0.0426  acc=0.990  SWA=0.990  CWA=0.990\nNRGS=0.979', '\\n', 'Epoch 06/20: train_loss=0.0379  val_loss=0.0342  acc=0.990\nSWA=0.990  CWA=0.990  NRGS=0.984', '\\n', 'Epoch 07/20: train_loss=0.0281\nval_loss=0.0240  acc=0.992  SWA=0.992  CWA=0.993  NRGS=0.984', '\\n', 'Epoch\n08/20: train_loss=0.0214  val_loss=0.0243  acc=0.992  SWA=0.991  CWA=0.992\nNRGS=0.984', '\\n', 'Epoch 09/20: train_loss=0.0157  val_loss=0.0150  acc=0.995\nSWA=0.995  CWA=0.995  NRGS=0.995', '\\n', 'Epoch 10/20: train_loss=0.0120\nval_loss=0.0126  acc=0.997  SWA=0.996  CWA=0.997  NRGS=0.990', '\\n', 'Epoch\n11/20: train_loss=0.0088  val_loss=0.0112  acc=0.996  SWA=0.996  CWA=0.996\nNRGS=1.000', '\\n', 'Epoch 12/20: train_loss=0.0060  val_loss=0.0116  acc=0.997\nSWA=0.997  CWA=0.997  NRGS=1.000', '\\n', 'Epoch 13/20: train_loss=0.0046\nval_loss=0.0060  acc=0.999  SWA=0.999  CWA=0.999  NRGS=1.000', '\\n', 'Epoch\n14/20: train_loss=0.0029  val_loss=0.0054  acc=0.999  SWA=0.998  CWA=0.998\nNRGS=1.000', '\\n', 'Epoch 15/20: train_loss=0.0020  val_loss=0.0043  acc=0.999\nSWA=0.999  CWA=0.999  NRGS=1.000', '\\n', 'Epoch 16/20: train_loss=0.0014\nval_loss=0.0045  acc=0.998  SWA=0.998  CWA=0.998  NRGS=1.000', '\\n', 'Epoch\n17/20: train_loss=0.0010  val_loss=0.0041  acc=0.999  SWA=0.999  CWA=0.999\nNRGS=1.000', '\\n', 'Epoch 18/20: train_loss=0.0008  val_loss=0.0039  acc=0.998\nSWA=0.998  CWA=0.998  NRGS=1.000', '\\n', 'Epoch 19/20: train_loss=0.0006\nval_loss=0.0038  acc=0.999  SWA=0.998  CWA=0.998  NRGS=1.000', '\\n', 'Epoch\n20/20: train_loss=0.0005  val_loss=0.0034  acc=0.998  SWA=0.998  CWA=0.998\nNRGS=1.000', '\\n', '\\nTEST RESULTS  loss=3.7237  acc=0.701  SWA=0.653  CWA=0.701\nNRGS=0.758', '\\n', 'Experiment data saved to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/0-\nrun/process_ForkProcess-6/working/experiment_data.npy', '\\n', 'Plot saved to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-14_17-37-\n20_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-\n6/working/spr_metrics_bar.png', '\\n', 'Execution time: 34 seconds seconds (time\nlimit is 30 minutes).']", "['Running on', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples [00:00,\n? examples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 438111.47\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 498953.63\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 625614.01\nexamples/s]', '\\n', 'Original sizes:', ' ', \"{'train': 20000, 'dev': 5000,\n'test': 10000}\", '\\n', 'Built 3 variants.', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01 | train 0.0935 | val\n0.0211 | SWA 0.994', '\\n', 'Epoch 02 | train 0.0162 | val 0.0111 | SWA 0.997',\n'\\n', 'Epoch 03 | train 0.0081 | val 0.0111 | SWA 0.996', '\\n', 'Epoch 04 |\ntrain 0.0088 | val 0.0076 | SWA 0.999', '\\n', 'Epoch 05 | train 0.0073 | val\n0.0042 | SWA 0.999', '\\n', 'Epoch 06 | train 0.0073 | val 0.0226 | SWA 0.995',\n'\\n', 'Epoch 07 | train 0.0047 | val 0.0017 | SWA 1.000', '\\n', 'Epoch 08 |\ntrain 0.0028 | val 0.0035 | SWA 0.999', '\\n', 'Epoch 09 | train 0.0032 | val\n0.0012 | SWA 1.000', '\\n', 'Epoch 10 | train 0.0050 | val 0.0036 | SWA 0.999',\n'\\n', 'Epoch 11 | train 0.0035 | val 0.0016 | SWA 0.999', '\\n', 'Epoch 12 |\ntrain 0.0005 | val 0.0016 | SWA 0.999', '\\n', 'Early stopping.', '\\n', '\\nTEST \u2011\nloss 4.0157 | SWA 0.652', '\\n', 'Saved experiment_data.npy', '\\n', 'Plot\nsaved.', '\\n', 'Execution time: a minute seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 290608.16\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 514297.77\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 527048.42\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Shape\nvocab 6, Color vocab 6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: train_loss=0.1756\nval_loss=0.0795  SWA=0.978', '\\n', 'Epoch 02: train_loss=0.0637  val_loss=0.0544\nSWA=0.984', '\\n', 'Epoch 03: train_loss=0.0377  val_loss=0.0276  SWA=0.992',\n'\\n', 'Epoch 04: train_loss=0.0276  val_loss=0.0170  SWA=0.996', '\\n', 'Epoch\n05: train_loss=0.0218  val_loss=0.0323  SWA=0.991', '\\n', 'Epoch 06:\ntrain_loss=0.0167  val_loss=0.0095  SWA=0.997', '\\n', 'Epoch 07:\ntrain_loss=0.0142  val_loss=0.0129  SWA=0.996', '\\n', 'Epoch 08:\ntrain_loss=0.0149  val_loss=0.0050  SWA=0.998', '\\n', 'Epoch 09:\ntrain_loss=0.0100  val_loss=0.0139  SWA=0.995', '\\n', 'Epoch 10:\ntrain_loss=0.0111  val_loss=0.0078  SWA=0.997', '\\n', 'Epoch 11:\ntrain_loss=0.0086  val_loss=0.0040  SWA=0.998', '\\n', 'Epoch 12:\ntrain_loss=0.0073  val_loss=0.0036  SWA=0.999', '\\n', 'Epoch 13:\ntrain_loss=0.0104  val_loss=0.0023  SWA=0.999', '\\n', 'Epoch 14:\ntrain_loss=0.0051  val_loss=0.0021  SWA=1.000', '\\n', 'Epoch 15:\ntrain_loss=0.0074  val_loss=0.0010  SWA=1.000', '\\n', 'Epoch 16:\ntrain_loss=0.0067  val_loss=0.0027  SWA=0.999', '\\n', 'Epoch 17:\ntrain_loss=0.0050  val_loss=0.0013  SWA=1.000', '\\n', 'Epoch 18:\ntrain_loss=0.0056  val_loss=0.0012  SWA=1.000', '\\n', 'Early stopping.', '\\n',\n'\\nTEST: loss=3.2691  SWA=0.652', '\\n', 'Saved experiment data.', '\\n', 'Saved\nplot to working/swa_curve.png', '\\n', 'Execution time: 28 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 361811.86\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 630097.05\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 377654.28\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Shape\nvocab 6, Color vocab 6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: train_loss=0.1766\nval_loss=0.0920  SWA=0.973', '\\n', 'Epoch 02: train_loss=0.0631  val_loss=0.0542\nSWA=0.987', '\\n', 'Epoch 03: train_loss=0.0489  val_loss=0.0299  SWA=0.991',\n'\\n', 'Epoch 04: train_loss=0.0319  val_loss=0.0272  SWA=0.991', '\\n', 'Epoch\n05: train_loss=0.0283  val_loss=0.0185  SWA=0.995', '\\n', 'Epoch 06:\ntrain_loss=0.0245  val_loss=0.0151  SWA=0.996', '\\n', 'Epoch 07:\ntrain_loss=0.0218  val_loss=0.0136  SWA=0.996', '\\n', 'Epoch 08:\ntrain_loss=0.0236  val_loss=0.0134  SWA=0.997', '\\n', 'Epoch 09:\ntrain_loss=0.0215  val_loss=0.0163  SWA=0.994', '\\n', 'Epoch 10:\ntrain_loss=0.0174  val_loss=0.0095  SWA=0.998', '\\n', 'Epoch 11:\ntrain_loss=0.0167  val_loss=0.0136  SWA=0.996', '\\n', 'Epoch 12:\ntrain_loss=0.0161  val_loss=0.0081  SWA=0.998', '\\n', 'Epoch 13:\ntrain_loss=0.0147  val_loss=0.0248  SWA=0.993', '\\n', 'Epoch 14:\ntrain_loss=0.0223  val_loss=0.0098  SWA=0.998', '\\n', 'Epoch 15:\ntrain_loss=0.0180  val_loss=0.0113  SWA=0.997', '\\n', 'Early stopping.', '\\n',\n'\\nTEST: loss=2.3917  SWA=0.653', '\\n', 'Saved experiment data.', '\\n', 'Saved\nplot to working/swa_curve.png', '\\n', 'Execution time: 23 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 499672.87\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 703647.83\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 704356.82\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Shape\nvocab 6, Color vocab 6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: train_loss=0.3379\nval_loss=0.2313  SWA=0.926', '\\n', 'Epoch 02: train_loss=0.1992  val_loss=0.1793\nSWA=0.945', '\\n', 'Epoch 03: train_loss=0.1785  val_loss=0.1740  SWA=0.942',\n'\\n', 'Epoch 04: train_loss=0.1743  val_loss=0.1657  SWA=0.944', '\\n', 'Epoch\n05: train_loss=0.1712  val_loss=0.1653  SWA=0.945', '\\n', 'Epoch 06:\ntrain_loss=0.1715  val_loss=0.1659  SWA=0.944', '\\n', 'Epoch 07:\ntrain_loss=0.1692  val_loss=0.1716  SWA=0.945', '\\n', 'Epoch 08:\ntrain_loss=0.1701  val_loss=0.1662  SWA=0.945', '\\n', 'Early stopping.', '\\n',\n'\\nTEST: loss=1.2630  SWA=0.650', '\\n', 'Saved experiment data.', '\\n', 'Saved\nplot to working/swa_curve.png', '\\n', 'Execution time: 13 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Shape vocab 6, Color vocab 6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: train_loss=0.2138\nval_loss=0.1468  SWA=0.955', '\\n', 'Epoch 02: train_loss=0.0732  val_loss=0.0370\nSWA=0.990', '\\n', 'Epoch 03: train_loss=0.0337  val_loss=0.0353  SWA=0.991',\n'\\n', 'Epoch 04: train_loss=0.0240  val_loss=0.0258  SWA=0.993', '\\n', 'Epoch\n05: train_loss=0.0197  val_loss=0.0134  SWA=0.996', '\\n', 'Epoch 06:\ntrain_loss=0.0145  val_loss=0.0025  SWA=1.000', '\\n', 'Epoch 07:\ntrain_loss=0.0127  val_loss=0.0027  SWA=1.000', '\\n', 'Epoch 08:\ntrain_loss=0.0116  val_loss=0.0146  SWA=0.996', '\\n', 'Epoch 09:\ntrain_loss=0.0094  val_loss=0.0009  SWA=1.000', '\\n', 'Epoch 10:\ntrain_loss=0.0164  val_loss=0.0016  SWA=1.000', '\\n', 'Epoch 11:\ntrain_loss=0.0072  val_loss=0.0017  SWA=1.000', '\\n', 'Epoch 12:\ntrain_loss=0.0084  val_loss=0.0079  SWA=0.996', '\\n', 'Early stopping.', '\\n',\n'\\nTEST: loss=3.1481  SWA=0.652', '\\n', 'Saved experiment data.', '\\n', 'Saved\nplot to working/swa_curve.png', '\\n', 'Execution time: 20 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 394066.32\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 592248.52\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 687827.61\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Shape\nvocab 6, Color vocab 6', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 96, in <module>\\n    idx2label = {i: l for l, l in\nenumerate(label_set)}\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\nFile \"runfile.py\", line 96, in <dictcomp>\\n    idx2label = {i: l for l, l in\nenumerate(label_set)}\\n                 ^\\nNameError: name \\'i\\' is not\ndefined\\n', 'Execution time: a second seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Shape vocab 6, Color vocab 6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: train_loss=0.2739\nval_loss=0.1214  SWA=0.969', '\\n', 'Epoch 02: train_loss=0.1202  val_loss=0.1074\nSWA=0.972', '\\n', 'Epoch 03: train_loss=0.1125  val_loss=0.1089  SWA=0.972',\n'\\n', 'Epoch 04: train_loss=0.1085  val_loss=0.1078  SWA=0.973', '\\n', 'Epoch\n05: train_loss=0.1117  val_loss=0.1041  SWA=0.972', '\\n', 'Epoch 06:\ntrain_loss=0.1094  val_loss=0.1076  SWA=0.972', '\\n', 'Epoch 07:\ntrain_loss=0.1075  val_loss=0.1078  SWA=0.973', '\\n', 'Epoch 08:\ntrain_loss=0.1074  val_loss=0.1067  SWA=0.973', '\\n', 'Early stopping.', '\\n',\n'\\nTEST: loss=1.5904  SWA=0.645', '\\n', 'Saved experiment data.', '\\n', 'Saved\nplot to working/swa_curve.png', '\\n', 'Execution time: 17 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Shape vocab 6, Color vocab 6', '\\n', 'Epoch 01: train_loss=0.5835\nval_loss=0.5531  SWA=0.701', '\\n', 'Epoch 02: train_loss=0.5481  val_loss=0.5493\nSWA=0.734', '\\n', 'Epoch 03: train_loss=0.5431  val_loss=0.5453  SWA=0.715',\n'\\n', 'Epoch 04: train_loss=0.5411  val_loss=0.5471  SWA=0.696', '\\n', 'Epoch\n05: train_loss=0.5408  val_loss=0.5458  SWA=0.719', '\\n', 'Epoch 06:\ntrain_loss=0.5399  val_loss=0.5439  SWA=0.723', '\\n', 'Epoch 07:\ntrain_loss=0.5397  val_loss=0.5445  SWA=0.721', '\\n', 'Epoch 08:\ntrain_loss=0.5401  val_loss=0.5459  SWA=0.717', '\\n', 'Epoch 09:\ntrain_loss=0.5398  val_loss=0.5453  SWA=0.736', '\\n', 'Early stopping.', '\\n',\n'\\nTEST: loss=0.6852  SWA=0.587', '\\n', 'Saved experiment data.', '\\n', 'Saved\nplot to working/swa_curve.png', '\\n', 'Execution time: 9 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Shape vocab 6, Color vocab 6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: train_loss=0.1935\nval_loss=0.0811  SWA=0.979', '\\n', 'Epoch 02: train_loss=0.0646  val_loss=0.0408\nSWA=0.989', '\\n', 'Epoch 03: train_loss=0.0375  val_loss=0.0384  SWA=0.991',\n'\\n', 'Epoch 04: train_loss=0.0264  val_loss=0.0181  SWA=0.996', '\\n', 'Epoch\n05: train_loss=0.0210  val_loss=0.0144  SWA=0.996', '\\n', 'Epoch 06:\ntrain_loss=0.0172  val_loss=0.0164  SWA=0.995', '\\n', 'Epoch 07:\ntrain_loss=0.0171  val_loss=0.0129  SWA=0.996', '\\n', 'Epoch 08:\ntrain_loss=0.0113  val_loss=0.0051  SWA=0.998', '\\n', 'Epoch 09:\ntrain_loss=0.0131  val_loss=0.0210  SWA=0.994', '\\n', 'Epoch 10:\ntrain_loss=0.0105  val_loss=0.0107  SWA=0.997', '\\n', 'Epoch 11:\ntrain_loss=0.0088  val_loss=0.0068  SWA=0.998', '\\n', 'Early stopping.', '\\n',\n'\\nTEST: loss=2.8128  SWA=0.653', '\\n', 'Saved experiment data.', '\\n', 'Saved\nplot to working/swa_curve.png', '\\n', 'Execution time: 19 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Shape vocab 6, Color vocab 6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: train_loss=0.2012\nval_loss=0.0882  SWA=0.978', '\\n', 'Epoch 02: train_loss=0.0757  val_loss=0.0617\nSWA=0.983', '\\n', 'Epoch 03: train_loss=0.0374  val_loss=0.0223  SWA=0.994',\n'\\n', 'Epoch 04: train_loss=0.0260  val_loss=0.0301  SWA=0.991', '\\n', 'Epoch\n05: train_loss=0.0208  val_loss=0.0129  SWA=0.996', '\\n', 'Epoch 06:\ntrain_loss=0.0166  val_loss=0.0139  SWA=0.995', '\\n', 'Epoch 07:\ntrain_loss=0.0137  val_loss=0.0114  SWA=0.997', '\\n', 'Epoch 08:\ntrain_loss=0.0149  val_loss=0.0117  SWA=0.996', '\\n', 'Epoch 09:\ntrain_loss=0.0136  val_loss=0.0110  SWA=0.996', '\\n', 'Epoch 10:\ntrain_loss=0.0124  val_loss=0.0068  SWA=0.997', '\\n', 'Epoch 11:\ntrain_loss=0.0103  val_loss=0.0079  SWA=0.997', '\\n', 'Epoch 12:\ntrain_loss=0.0090  val_loss=0.0096  SWA=0.997', '\\n', 'Epoch 13:\ntrain_loss=0.0162  val_loss=0.0086  SWA=0.996', '\\n', 'Early stopping.', '\\n',\n'\\nTEST: loss=3.0942  SWA=0.654', '\\n', 'Saved experiment data.', '\\n', 'Saved\nplot to working/swa_curve.png', '\\n', 'Execution time: 21 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Shape vocab 6, Color vocab 6', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: train_loss=0.1843\nval_loss=0.0681  SWA=0.980', '\\n', 'Epoch 02: train_loss=0.0487  val_loss=0.0377\nSWA=0.990', '\\n', 'Epoch 03: train_loss=0.0276  val_loss=0.0406  SWA=0.988',\n'\\n', 'Epoch 04: train_loss=0.0210  val_loss=0.0174  SWA=0.996', '\\n', 'Epoch\n05: train_loss=0.0167  val_loss=0.0137  SWA=0.995', '\\n', 'Epoch 06:\ntrain_loss=0.0154  val_loss=0.0091  SWA=0.997', '\\n', 'Epoch 07:\ntrain_loss=0.0114  val_loss=0.0293  SWA=0.992', '\\n', 'Epoch 08:\ntrain_loss=0.0131  val_loss=0.0071  SWA=0.997', '\\n', 'Epoch 09:\ntrain_loss=0.0096  val_loss=0.0137  SWA=0.996', '\\n', 'Epoch 10:\ntrain_loss=0.0086  val_loss=0.0058  SWA=0.998', '\\n', 'Epoch 11:\ntrain_loss=0.0129  val_loss=0.0112  SWA=0.996', '\\n', 'Epoch 12:\ntrain_loss=0.0087  val_loss=0.0051  SWA=0.998', '\\n', 'Epoch 13:\ntrain_loss=0.0064  val_loss=0.0040  SWA=0.998', '\\n', 'Epoch 14:\ntrain_loss=0.0088  val_loss=0.0010  SWA=1.000', '\\n', 'Epoch 15:\ntrain_loss=0.0050  val_loss=0.0058  SWA=0.998', '\\n', 'Epoch 16:\ntrain_loss=0.0073  val_loss=0.0081  SWA=0.997', '\\n', 'Epoch 17:\ntrain_loss=0.0055  val_loss=0.0103  SWA=0.997', '\\n', 'Early stopping.', '\\n',\n'\\nTEST: loss=3.1133  SWA=0.652', '\\n', 'Saved experiment data.', '\\n', 'Saved\nplot to working/swa_curve.png', '\\n', 'Execution time: 31 seconds seconds (time\nlimit is 30 minutes).']", ""], "analysis": ["", "", "", "", "", "The training process showed promising results during the validation phase,\nachieving a Shape-Weighted Accuracy (SWA) of 1.000 on the validation set.\nHowever, when tested on the test set, the SWA dropped significantly to 0.652,\nindicating a potential overfitting issue. This discrepancy suggests that the\nmodel may not generalize well to unseen data. To address this, consider\nimplementing techniques such as dropout regularization, early stopping based on\ntest set performance, or augmenting the training dataset to improve\ngeneralization.", "The script encountered a bug in the dictionary comprehension used to create\n`idx2label`. Specifically, the variable `i` was not defined in the dictionary\ncomprehension `idx2label = {i: l for l, l in enumerate(label_set)}`. This error\noccurs because the same variable name `l` was used for both the key and value,\nwhich is not allowed.   To fix this issue, modify the dictionary comprehension\nto use distinct variable names for the key and value. For example: `idx2label =\n{i: l for i, l in enumerate(label_set)}`.", "The final test results show a significant drop in Shape-Weighted Accuracy (SWA)\non the test set compared to the validation set (from ~0.973 to 0.645). This\nindicates potential overfitting to the training/validation data. To address\nthis, consider implementing regularization techniques such as dropout, weight\ndecay, or early stopping with stricter criteria. Additionally, increasing the\ndiversity of the training data or employing data augmentation techniques could\nhelp improve generalization to the test set.", "", "The training script encountered an issue where the test loss is significantly\nhigher (2.8128) compared to the validation loss (0.0068), and the Shape-Weighted\nAccuracy (SWA) on the test set is only 0.653, much lower than the validation SWA\n(around 0.998). This suggests potential overfitting during training. To address\nthis, consider implementing techniques to reduce overfitting, such as increasing\ndropout rates in the transformer encoder, using regularization methods like\nweight decay, or employing data augmentation strategies. Additionally, reviewing\nthe training and validation data splits for potential data leakage might be\nnecessary.", "The training script has a significant issue where the test Shape-Weighted\nAccuracy (SWA) is drastically lower than expected at 0.654, compared to the\nvalidation SWA of 0.997. This discrepancy suggests overfitting to the validation\ndata and poor generalization to unseen test data. To address this, consider\nimplementing regularization techniques such as dropout or weight decay,\nincreasing the size of the training dataset, or employing data augmentation to\nimprove the model's generalization capability.", "", ""], "exc_type": [null, null, null, null, null, null, "NameError", null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, {"args": ["name 'i' is not defined"], "name": "i"}, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 96, "<module>", "idx2label = {i: l for l, l in enumerate(label_set)}"], ["runfile.py", 96, "<dictcomp>", "idx2label = {i: l for l, l in enumerate(label_set)}"]], null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating model error.", "data": [{"dataset_name": "training set", "final_value": 0.000515, "best_value": 0.000515}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation set, indicating model error.", "data": [{"dataset_name": "validation set", "final_value": 0.003376, "best_value": 0.003376}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation set.", "data": [{"dataset_name": "validation set", "final_value": 0.9984, "best_value": 0.9984}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy of the model on the validation set.", "data": [{"dataset_name": "validation set", "final_value": 0.998256, "best_value": 0.998256}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy of the model on the validation set.", "data": [{"dataset_name": "validation set", "final_value": 0.998231, "best_value": 0.998231}]}, {"metric_name": "validation NRGS", "lower_is_better": false, "description": "The NRGS metric on the validation set.", "data": [{"dataset_name": "validation set", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value on the test set, indicating model error.", "data": [{"dataset_name": "test set", "final_value": 3.723709, "best_value": 3.723709}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "The accuracy of the model on the test set.", "data": [{"dataset_name": "test set", "final_value": 0.7005, "best_value": 0.7005}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy of the model on the test set.", "data": [{"dataset_name": "test set", "final_value": 0.652862, "best_value": 0.652862}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy of the model on the test set.", "data": [{"dataset_name": "test set", "final_value": 0.700969, "best_value": 0.700969}]}, {"metric_name": "test NRGS", "lower_is_better": false, "description": "The NRGS metric on the test set.", "data": [{"dataset_name": "test set", "final_value": 0.757812, "best_value": 0.757812}]}]}, {"metric_names": [{"metric_name": "Training Loss", "lower_is_better": true, "description": "Loss during training phase", "data": [{"dataset_name": "SPR_BENCH_HELDOUT", "final_value": 0.0005, "best_value": 0.0005}]}, {"metric_name": "Validation Loss", "lower_is_better": true, "description": "Loss during validation phase", "data": [{"dataset_name": "SPR_BENCH_HELDOUT", "final_value": 0.0012, "best_value": 0.0012}]}, {"metric_name": "Validation Shape-Weighted Accuracy", "lower_is_better": false, "description": "Shape-weighted accuracy during validation phase", "data": [{"dataset_name": "SPR_BENCH_HELDOUT", "final_value": 0.9995, "best_value": 0.9995}]}, {"metric_name": "Test Loss", "lower_is_better": true, "description": "Loss during testing phase", "data": [{"dataset_name": "SPR_BENCH_HELDOUT", "final_value": 4.0157, "best_value": 4.0157}]}, {"metric_name": "Test Shape-Weighted Accuracy", "lower_is_better": false, "description": "Shape-weighted accuracy during testing phase", "data": [{"dataset_name": "SPR_BENCH_HELDOUT", "final_value": 0.6522, "best_value": 0.6522}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0056, "best_value": 0.0056}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.001, "best_value": 0.001}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy during validation with a shape-weighted metric.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Measures the error during testing.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 3.2691, "best_value": 3.2691}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy during testing with a shape-weighted metric.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.652, "best_value": 0.652}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the error of the model's predictions; lower values indicate better performance.", "data": [{"dataset_name": "Training", "final_value": 0.018, "best_value": 0.018}, {"dataset_name": "Validation", "final_value": 0.0113, "best_value": 0.0113}, {"dataset_name": "Test", "final_value": 2.3917, "best_value": 2.3917}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions, weighted by the shape of the data; higher values indicate better performance.", "data": [{"dataset_name": "Validation", "final_value": 0.9972, "best_value": 0.9972}, {"dataset_name": "Test", "final_value": 0.6529, "best_value": 0.6529}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated on the training dataset during the final epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1701, "best_value": 0.1701}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The lowest loss calculated on the validation dataset during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1653, "best_value": 0.1653}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The highest shape-weighted accuracy achieved on the validation dataset during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9447, "best_value": 0.9447}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss calculated on the test dataset after training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.263, "best_value": 1.263}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy calculated on the test dataset after training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.65, "best_value": 0.65}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating the error rate of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0072, "best_value": 0.0072}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, indicating the error rate of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0009, "best_value": 0.0009}]}, {"metric_name": "validation shape-weighted accuracy (SWA)", "lower_is_better": false, "description": "The shape-weighted accuracy metric during validation, reflecting the model's performance in recognizing shapes.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value during testing, indicating the error rate of the model on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 3.1481, "best_value": 3.1481}]}, {"metric_name": "test shape-weighted accuracy (SWA)", "lower_is_better": false, "description": "The shape-weighted accuracy metric during testing, reflecting the model's performance in recognizing shapes.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.652, "best_value": 0.652}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1073619705915451, "best_value": 0.1073619705915451}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.10407546188831329, "best_value": 0.10407546188831329}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9729101267294501, "best_value": 0.9729101267294501}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss of the model on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.5903858589172364, "best_value": 1.5903858589172364}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy of the model on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6450369511664976, "best_value": 0.6450369511664976}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.539729, "best_value": 0.539729}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error during validation. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.543899, "best_value": 0.543899}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "Measures the Stochastic Weight Averaging performance on the validation set. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.735903, "best_value": 0.735903}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Measures the error during testing. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.685242, "best_value": 0.685242}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "Measures the Stochastic Weight Averaging performance on the test set. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.58719, "best_value": 0.58719}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0088, "best_value": 0.0088}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error on the validation dataset. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0051, "best_value": 0.0051}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Measures the shape-weighted accuracy on the validation dataset. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.998, "best_value": 0.998}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Measures the error on the test dataset. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 2.8128, "best_value": 2.8128}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "Measures the shape-weighted accuracy on the test dataset. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.653, "best_value": 0.653}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the loss during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0162, "best_value": 0.0162}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the loss during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0068, "best_value": 0.0068}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of the model during validation, weighted by shape.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.997, "best_value": 0.997}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Measures the loss during testing phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 3.0942, "best_value": 3.0942}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of the model during testing, weighted by shape.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.654, "best_value": 0.654}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0055, "best_value": 0.0055}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.001, "best_value": 0.001}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value during testing phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 3.1133, "best_value": 3.1133}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during testing phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.652, "best_value": 0.652}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [true, false, false, false, false, false, false, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/spr_metrics_bar.png", "../../logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_val_accuracy.png", "../../logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_test_metrics.png", "../../logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/swa_curve.png", "../../logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_loss_curves.png", "../../logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_val_SWA.png", "../../logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/swa_curve.png", "../../logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/SPR_BENCH_swa_curve.png", "../../logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/swa_curve.png", "../../logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_validation_SWA.png", "../../logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/swa_curve.png", "../../logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_swa_curve.png", "../../logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_confusion_matrix.png"], [], [], [], ["../../logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/swa_curve.png", "../../logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_swa_curve.png", "../../logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_confusion_matrix.png"], [], [], ["../../logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/swa_curve.png", "../../logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/SPR_BENCH_swa_curve.png", "../../logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/seed_aggregation_f659fcaf47d74791a28ec278f7c5b632/SPR_BENCH_loss_curves_agg.png", "../../logs/0-run/experiment_results/seed_aggregation_f659fcaf47d74791a28ec278f7c5b632/SPR_BENCH_swa_curve_agg.png"]], "plot_paths": [["experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/spr_metrics_bar.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_loss_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_val_accuracy.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_test_metrics.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/swa_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_loss_curves.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_val_SWA.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_confusion_matrix.png"], ["experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/swa_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/SPR_BENCH_swa_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/swa_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_validation_SWA.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/swa_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_loss_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_swa_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_confusion_matrix.png"], [], [], [], ["experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/swa_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_swa_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_confusion_matrix.png"], [], [], ["experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/swa_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/SPR_BENCH_loss_curves.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/SPR_BENCH_swa_curve.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_f659fcaf47d74791a28ec278f7c5b632/SPR_BENCH_loss_curves_agg.png", "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_f659fcaf47d74791a28ec278f7c5b632/SPR_BENCH_swa_curve_agg.png"]], "plot_analyses": [[{"analysis": "The bar chart displays the test metrics for the SPR_BENCH dataset. Accuracy (Acc), Shape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA), and Neural Rule Generalization Score (NRGS) are all above 0.6, indicating strong performance. NRGS is the highest, suggesting effective generalization capabilities of the model, while SWA is slightly lower compared to the others, indicating room for improvement in shape-related reasoning.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/spr_metrics_bar.png"}, {"analysis": "The loss curves for train and validation datasets show a steady decrease in cross-entropy loss over 20 epochs. The validation loss closely follows the training loss, indicating minimal overfitting and good generalization. The convergence of both curves suggests that the model is well-trained.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_loss_curve.png"}, {"analysis": "The validation accuracy plot shows consistent improvement over epochs, stabilizing near 1.0. This indicates that the model achieves high accuracy on the validation set, demonstrating strong learning and generalization capabilities.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_val_accuracy.png"}, {"analysis": "The bar chart reiterates the test metrics: Acc, SWA, CWA, and NRGS. The relative performance remains consistent, with NRGS being the highest and SWA slightly lower. This visualization confirms the robustness of the model across multiple metrics.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_test_metrics.png"}, {"analysis": "The confusion matrix highlights the classification performance. The true positive and true negative rates are high, but there is a noticeable number of false positives and false negatives. The imbalance between correct and incorrect classifications suggests areas for further optimization, such as improving the handling of ambiguous cases.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5032b21fc69c4c59b341004095b32966_proc_2700561/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "This plot shows the Validation Shape-Weighted Accuracy (SWA) over training epochs. The SWA starts at a relatively high value (~0.994) and shows a general upward trend, indicating improved performance as the training progresses. There is a noticeable dip at epoch 5, which could suggest instability or a temporary failure to generalize. Afterward, the SWA stabilizes and reaches a plateau near 0.999, suggesting that the model achieves near-perfect generalization on the validation set.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/swa_curve.png"}, {"analysis": "The loss curves for both training and validation sets are depicted here. The training loss starts high and decreases rapidly, indicating effective learning. The validation loss also decreases but exhibits some fluctuations, particularly around epoch 6, which might correspond to overfitting or challenges in generalization. By the final epochs, both losses are close to zero, suggesting that the model fits the data well.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_loss_curves.png"}, {"analysis": "This plot again shows Validation Shape-Weighted Accuracy (SWA) but emphasizes the individual points more clearly. The trend mirrors the earlier SWA plot, where the accuracy improves with epochs, stabilizes, and reaches a high value near 0.999. The dip at epoch 6 is also visible here, reinforcing the need to investigate potential model instability or hyperparameter adjustments to smooth the training process.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_val_SWA.png"}, {"analysis": "The confusion matrix shows the performance of the model on a binary classification task. The true negatives and true positives are represented in the darker blue regions, indicating that the model correctly classifies the majority of examples. The lighter blue regions for false positives and false negatives are relatively smaller, suggesting that the model achieves high accuracy. However, the exact numerical values should be analyzed to assess class imbalance or specific areas for improvement.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_confusion_matrix.png"}], [{"analysis": "This plot shows the validation Shape-Weighted Accuracy (SWA) over epochs for the model without symbolic features (No-SymFeat). The SWA increases rapidly in the initial epochs and gradually plateaus, nearing a perfect score of 1.0. This indicates that the model effectively learns to generalize in terms of shape-based reasoning, even without symbolic features. However, the lack of noticeable fluctuations after epoch 10 suggests that further training may not yield significant gains in SWA.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/swa_curve.png"}, {"analysis": "This plot compares the training and validation losses over epochs. Both losses decrease sharply in the early epochs and converge to near-zero values by epoch 10. The close alignment of training and validation loss curves indicates minimal overfitting and good generalization. The rapid loss reduction in the initial epochs highlights efficient learning dynamics, while the eventual convergence suggests that the model has captured the underlying patterns in the data effectively.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot tracks the validation Shape-Weighted Accuracy (SWA) per epoch. The SWA improves steadily, with minor fluctuations, and approaches a value close to 1.0 by epoch 15. The consistent improvement in SWA demonstrates the model's ability to generalize shape-based reasoning over the validation set. The minor fluctuations in the middle epochs could indicate sensitivity to specific training instances but do not significantly impact the overall trend.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/SPR_BENCH_swa_curve.png"}, {"analysis": "This confusion matrix for the test set provides a breakdown of true positive, true negative, false positive, and false negative predictions. The darker diagonal elements indicate a high number of correct predictions for both classes. The relatively lighter off-diagonal elements suggest that misclassification rates are low. This confirms the model's strong performance in distinguishing between the two classes, aligning with the high SWA observed in the previous plots.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e1a31c634a9a4d388d3b7df55f4f8741_proc_2705535/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The Validation SWA curve demonstrates a steady improvement in Shape-Weighted Accuracy over the epochs, reaching a plateau at around epoch 7. This indicates the model's ability to generalize well on the validation set and suggests that the integration of neural and symbolic reasoning is effective in achieving high accuracy.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/swa_curve.png"}, {"analysis": "The Training vs. Validation Loss plot shows a consistent decrease in both training and validation loss over the epochs, with the training loss being slightly lower than the validation loss. This indicates that the model is learning effectively without significant overfitting, as the gap between the two losses remains small.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_loss_curves.png"}, {"analysis": "The Validation SWA Curve corroborates the findings from the Validation SWA plot, showing a steady improvement in Shape-Weighted Accuracy over time. The curve stabilizes after epoch 7, suggesting that the model has reached its optimal performance.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_validation_SWA.png"}, {"analysis": "The confusion matrix reveals that the model performs well overall but struggles slightly with false positives and false negatives. The misclassification rates suggest potential room for improvement in handling edge cases or ambiguous sequences.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "This plot shows the validation Shape-Weighted Accuracy (SWA) over 7 epochs without the use of positional embeddings. The SWA improves significantly from epoch 0 to epoch 1, indicating that the model quickly learns to generalize to shape-related rules. After epoch 1, the SWA stabilizes with minor fluctuations, suggesting that the model has reached its performance plateau early in training.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/swa_curve.png"}, {"analysis": "The training and validation loss curves for the SPR_BENCH dataset decrease steeply in the first few epochs, showing that the model is learning effectively. The gap between training and validation loss is minimal, indicating that the model generalizes well and is not overfitting. The convergence of both curves towards the end of training further supports this observation.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_loss_curve.png"}, {"analysis": "This plot depicts the validation Shape-Weighted Accuracy (SWA) for the SPR_BENCH dataset across 7 epochs. The SWA increases rapidly between epochs 0 and 1, followed by a gradual improvement and stabilization. This trend indicates that the model quickly learns to generalize to shape-related rules and maintains consistent performance after initial training.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_swa_curve.png"}, {"analysis": "The confusion matrix visualizes the model's performance on the test dataset. The high concentration of values along the diagonal indicates strong agreement between the predicted and true labels. However, there is some misclassification, as evidenced by the off-diagonal values. Further analysis could focus on the specific cases where the model struggles to differentiate between classes.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_confusion_matrix.png"}], [], [], [], [{"analysis": "This plot shows the validation Shape-Weighted Accuracy (SWA) across epochs for a Bag-of-Embeddings model. The SWA starts at around 0.7, peaks at 0.735 in the second epoch, and then drops significantly in the third epoch. It fluctuates moderately in subsequent epochs, with a final sharp increase to 0.735. These fluctuations suggest potential overfitting or instability in the model's learning process, indicating a need for further regularization or hyperparameter tuning.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/swa_curve.png"}, {"analysis": "The loss curves depict the training and validation cross-entropy loss over epochs. Both losses decrease steadily in the first few epochs, with the training loss reducing more sharply. Afterward, the training loss continues to decline, while the validation loss plateaus around epoch 6. This divergence between training and validation loss suggests slight overfitting of the model to the training data, indicating that early stopping or stronger regularization might be beneficial.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot again illustrates the validation Shape-Weighted Accuracy (SWA) over epochs for the Bag-of-Embeddings model. The trends are consistent with the earlier SWA plot, showing an initial increase, a sharp drop, and subsequent fluctuations. The final sharp increase to 0.735 suggests that the model retains some generalization ability, but the irregular trend highlights instability, possibly due to hyperparameter settings or insufficient training data.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_swa_curve.png"}, {"analysis": "The confusion matrix for the SPR_BENCH test set shows the distribution of true versus predicted labels. The darker diagonal regions indicate correct predictions, while off-diagonal regions represent errors. The matrix suggests that the model achieves reasonable accuracy but struggles with certain classes, as evidenced by the lighter off-diagonal regions. This imbalance may be due to class distribution or model bias, warranting further investigation into class-specific performance.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_confusion_matrix.png"}], [], [], [{"analysis": "This plot shows the validation Shape-Weighted Accuracy (SWA) over epochs for the No-SymFeat model. The SWA starts at around 0.98 and steadily improves, reaching close to 1.0 by epoch 15. The consistent improvement indicates that the model is effectively learning to handle shape variations in the data, even without symbolic features. However, the slight fluctuations in the middle epochs suggest some sensitivity to the training dynamics.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/swa_curve.png"}, {"analysis": "This plot compares the training and validation cross-entropy loss over epochs. Both losses decrease rapidly in the initial epochs and stabilize close to zero, indicating that the model is learning effectively and generalizing well to the validation data. The close alignment of training and validation losses suggests minimal overfitting.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot provides a detailed view of the validation Shape-Weighted Accuracy (SWA) over epochs. The SWA improves consistently, with minor fluctuations, and approaches 1.0 by epoch 15. This confirms the model's ability to generalize to shape-weighted tasks on the validation set, demonstrating robustness in performance.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/SPR_BENCH_swa_curve.png"}, {"analysis": "This confusion matrix represents the performance of the model on the test set. The diagonal elements, particularly the high values for both classes, indicate strong predictive accuracy. However, the presence of some off-diagonal values suggests occasional misclassifications, which could be analyzed further to identify challenging cases or potential biases in the model.", "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/SPR_BENCH_confusion_matrix.png"}], []], "vlm_feedback_summary": ["The plots collectively indicate that the model demonstrates strong performance\nacross various metrics, with particularly high generalization scores. The loss\ncurves and validation accuracy plot confirm effective training and minimal\noverfitting. However, the confusion matrix reveals some misclassifications,\nsuggesting potential for further refinement in ambiguous cases.", "The plots collectively indicate that the model performs well with high Shape-\nWeighted Accuracy (SWA) and low loss values, particularly in later epochs. There\nis a slight instability around epoch 6 that warrants further investigation. The\nconfusion matrix confirms high classification accuracy, but potential class\nimbalance should be examined.", "The plots collectively indicate that the model achieves strong performance in\nSynthetic PolyRule Reasoning (SPR), with high Shape-Weighted Accuracy (SWA) and\nminimal loss. The confusion matrix further corroborates the model's ability to\ngeneralize effectively to unseen data, demonstrating low misclassification\nrates. These results suggest that the neural-symbolic integration approach is\nhighly effective for zero-shot reasoning tasks.", "The plots provide a comprehensive view of the model's performance. The\nValidation SWA and loss curves indicate effective learning and generalization,\nwhile the confusion matrix highlights areas for further refinement in\nclassification accuracy.", "The plots indicate that the model achieves rapid learning and generalization in\nterms of Shape-Weighted Accuracy (SWA). The training and validation loss curves\nconfirm effective learning with minimal overfitting. The confusion matrix shows\nstrong overall performance but highlights areas for improvement in\nmisclassification handling.", "[]", "[]", "[]", "The plots reveal that the Bag-of-Embeddings model exhibits instability in SWA\ntrends, with fluctuations and potential overfitting. The loss curves show a\ndivergence between training and validation loss, indicating overfitting. The\nconfusion matrix highlights reasonable accuracy but also reveals class-specific\nperformance issues. These findings suggest a need for regularization,\nhyperparameter tuning, and a closer examination of class distributions to\nimprove model performance.", "[]", "[]", "The plots demonstrate that the model achieves high Shape-Weighted Accuracy (SWA)\nand generalizes well, as indicated by the validation metrics and confusion\nmatrix. The training and validation losses are well-aligned, showing effective\nlearning without overfitting. The confusion matrix highlights strong test set\nperformance with some room for improvement in reducing misclassifications.", "[]"], "exec_time": [34.40768051147461, 63.46847915649414, 28.40204381942749, 23.407490253448486, 13.432891368865967, 20.640799522399902, 1.2621500492095947, 17.106008768081665, 9.009757995605469, 19.372615814208984, 21.636297702789307, 31.64590072631836, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["['SPR_BENCH']"], ["[\"SPR_BENCH_HELDOUT\"]"], ["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], [], [], [], ["[]"], [], [], ["[\"SPR_BENCH\"]"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment results ----------\ntry:\n    exp_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp_data = None\n\nif exp_data:\n    # drill down to record\n    exp_rec = exp_data[\"EPOCH_TUNING\"][\"SPR_BENCH\"]\n    ds_name = \"SPR_BENCH\"\n    epochs = np.arange(1, len(exp_rec[\"losses\"][\"train\"]) + 1)\n\n    # ---------- figure 1: loss curves ----------\n    try:\n        plt.figure()\n        plt.plot(epochs, exp_rec[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(epochs, exp_rec[\"losses\"][\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{ds_name} Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, f\"{ds_name}_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # ---------- figure 2: validation accuracy ----------\n    try:\n        val_acc = [m[\"acc\"] for m in exp_rec[\"metrics\"][\"val\"]]\n        plt.figure()\n        plt.plot(epochs, val_acc, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.ylim(0, 1)\n        plt.title(f\"{ds_name} Validation Accuracy over Epochs\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, f\"{ds_name}_val_accuracy.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot: {e}\")\n        plt.close()\n\n    # ---------- figure 3: test metric bar chart ----------\n    try:\n        test_metrics = exp_rec[\"metrics\"][\"test\"]\n        labels = [\"acc\", \"swa\", \"cwa\", \"nrgs\"]\n        values = [test_metrics[k] for k in labels]\n        plt.figure()\n        plt.bar(labels, values, color=\"skyblue\")\n        plt.ylim(0, 1)\n        plt.title(f\"{ds_name} Test Metrics\\nLeft\u2192Right: Acc, SWA, CWA, NRGS\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, f\"{ds_name}_test_metrics.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar chart: {e}\")\n        plt.close()\n\n    # ---------- figure 4: confusion matrix ----------\n    try:\n        y_true = np.array(exp_rec[\"ground_truth\"])\n        y_pred = np.array(exp_rec[\"predictions\"])\n        num_classes = len(set(y_true) | set(y_pred))\n        cm = np.zeros((num_classes, num_classes), dtype=int)\n        for t, p in zip(y_true, y_pred):\n            cm[t, p] += 1\n        plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(f\"{ds_name} Confusion Matrix\")\n        for i in range(num_classes):\n            for j in range(num_classes):\n                plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, f\"{ds_name}_confusion_matrix.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\n    # ---------- print test metrics ----------\n    print(\"Test metrics:\")\n    for k, v in test_metrics.items():\n        print(f\"  {k}: {v:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------- load experiment data ----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    rec = experiment_data[\"MultiDataset\"][\"SPR_BENCH_HELDOUT\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    rec = None\n\nif rec:\n    epochs = np.arange(1, len(rec[\"losses\"][\"train\"]) + 1)\n\n    # ------------- plot 1: loss curves -----------------\n    try:\n        plt.figure(figsize=(6, 4))\n        plt.plot(epochs, rec[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(epochs, rec[\"losses\"][\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH_HELDOUT Loss Curves\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_HELDOUT_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ------------- plot 2: validation SWA --------------\n    try:\n        plt.figure(figsize=(6, 4))\n        plt.plot(epochs, rec[\"SWA\"][\"val\"], marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(\"SPR_BENCH_HELDOUT Validation SWA\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_HELDOUT_val_SWA.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot: {e}\")\n        plt.close()\n\n    # ------------- plot 3: confusion matrix ------------\n    try:\n        y_true = np.array(rec[\"ground_truth\"])\n        y_pred = np.array(rec[\"predictions\"])\n        labels = np.unique(np.concatenate([y_true, y_pred]))\n        if len(labels) <= 20:  # keep plot readable\n            cm = np.zeros((len(labels), len(labels)), dtype=int)\n            for t, p in zip(y_true, y_pred):\n                cm[t, p] += 1\n            plt.figure(figsize=(6, 5))\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im, shrink=0.8)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(\"SPR_BENCH_HELDOUT Confusion Matrix\")\n            plt.xticks(labels)\n            plt.yticks(labels)\n            plt.tight_layout()\n            fname = os.path.join(working_dir, \"SPR_BENCH_HELDOUT_confusion_matrix.png\")\n            plt.savefig(fname)\n            plt.close()\n        else:\n            print(\"Too many labels for readable confusion matrix; skipping plot.\")\n    except Exception as e:\n        print(f\"Error creating confusion matrix plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------- paths & load ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exit()\n\n# ----- pick the single exp entry ----------\ntry:\n    rec = experiment_data[\"NoSymFeatTransformer\"][\"SPR_BENCH\"]\nexcept KeyError:\n    print(\"Expected keys not found in experiment_data.\")\n    exit()\n\nloss_train = rec[\"losses\"][\"train\"]\nloss_val = rec[\"losses\"][\"val\"]\nswa_val = rec[\"SWA\"][\"val\"]\ntest_metrics = rec[\"metrics\"][\"test\"]\npreds = np.array(rec.get(\"predictions\", []))\ntrues = np.array(rec.get(\"ground_truth\", []))\n\n# ---------------- PLOT 1: loss curves ---------------\ntry:\n    plt.figure(figsize=(6, 4))\n    epochs = np.arange(1, len(loss_train) + 1)\n    plt.plot(epochs, loss_train, label=\"Train Loss\")\n    plt.plot(epochs, loss_val, label=\"Val Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ---------------- PLOT 2: SWA curve -----------------\ntry:\n    plt.figure(figsize=(6, 4))\n    plt.plot(epochs, swa_val, marker=\"o\", label=\"Val SWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Shape-Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: Validation SWA per Epoch\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_swa_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA plot: {e}\")\n    plt.close()\n\n# ---------------- PLOT 3: confusion matrix ----------\ntry:\n    if preds.size and trues.size and preds.shape == trues.shape:\n        n_labels = len(set(trues.tolist() + preds.tolist()))\n        cm = np.zeros((n_labels, n_labels), dtype=int)\n        for t, p in zip(trues, preds):\n            cm[t, p] += 1\n        plt.figure(figsize=(5, 5))\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\"SPR_BENCH: Confusion Matrix (Test Set)\")\n        plt.xticks(range(n_labels))\n        plt.yticks(range(n_labels))\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n        plt.savefig(fname)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ---------------- print final metrics ---------------\nprint(\n    f\"Test metrics -> Loss: {test_metrics.get('loss', 'NA'):.4f}, \"\n    f\"SWA: {test_metrics.get('SWA', 'NA'):.3f}\"\n)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- load data -----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    rec = experiment_data[\"CLS_Pooling\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    rec = None\n\n# ----------------- plot 1: loss curves -----------------\ntry:\n    if rec is None:\n        raise ValueError(\"Experiment record missing\")\n    train_loss = rec[\"losses\"][\"train\"]\n    val_loss = rec[\"losses\"][\"val\"]\n    epochs = np.arange(1, len(train_loss) + 1)\n\n    plt.figure()\n    plt.plot(epochs, train_loss, label=\"Train Loss\")\n    plt.plot(epochs, val_loss, label=\"Val Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH \u2013 Training vs Validation Loss\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ----------------- plot 2: validation SWA -----------------\ntry:\n    if rec is None:\n        raise ValueError(\"Experiment record missing\")\n    val_swa = rec[\"SWA\"][\"val\"]\n    epochs = np.arange(1, len(val_swa) + 1)\n\n    plt.figure()\n    plt.plot(epochs, val_swa, marker=\"o\", label=\"Val SWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Shape-Weighted Accuracy\")\n    plt.title(\"SPR_BENCH \u2013 Validation SWA Curve\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_validation_SWA.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA plot: {e}\")\n    plt.close()\n\n# ----------------- plot 3: confusion matrix -----------------\ntry:\n    if rec is None:\n        raise ValueError(\"Experiment record missing\")\n    y_pred = np.array(rec[\"predictions\"])\n    y_true = np.array(rec[\"ground_truth\"])\n    num_labels = int(max(y_true.max(), y_pred.max()) + 1)\n    cm = np.zeros((num_labels, num_labels), dtype=int)\n    for t, p in zip(y_true, y_pred):\n        cm[t, p] += 1\n\n    plt.figure(figsize=(6, 5))\n    plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n    plt.colorbar()\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(\n        \"SPR_BENCH \u2013 Confusion Matrix\\nLeft: Ground Truth, Right: Generated Predictions\"\n    )\n    # annotate cells\n    for i in range(num_labels):\n        for j in range(num_labels):\n            plt.text(\n                j,\n                i,\n                cm[i, j],\n                ha=\"center\",\n                va=\"center\",\n                color=\"white\" if cm[i, j] > cm.max() * 0.5 else \"black\",\n                fontsize=8,\n            )\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nexp_key = \"NoPositionalEmbedding\"\ndset_key = \"SPR_BENCH\"\nrec = experiment_data.get(exp_key, {}).get(dset_key, {})\n\n\n# ---------- helper to close safely ----------\ndef safe_close():\n    if plt.get_fignums():\n        plt.close()\n\n\n# ---------- 1. Loss curve ----------\ntry:\n    train_loss = rec.get(\"losses\", {}).get(\"train\", [])\n    val_loss = rec.get(\"losses\", {}).get(\"val\", [])\n    if train_loss and val_loss:\n        plt.figure(figsize=(6, 4))\n        plt.plot(train_loss, label=\"Train Loss\")\n        plt.plot(val_loss, label=\"Val Loss\")\n        plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curve.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    safe_close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    safe_close()\n\n# ---------- 2. Validation SWA curve ----------\ntry:\n    val_swa = rec.get(\"SWA\", {}).get(\"val\", [])\n    if val_swa:\n        plt.figure(figsize=(6, 4))\n        plt.plot(val_swa, marker=\"o\")\n        plt.title(\"SPR_BENCH: Validation Shape-Weighted Accuracy\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SWA\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_swa_curve.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    safe_close()\nexcept Exception as e:\n    print(f\"Error creating SWA curve: {e}\")\n    safe_close()\n\n# ---------- 3. Confusion matrix ----------\ntry:\n    preds = rec.get(\"predictions\", [])\n    truths = rec.get(\"ground_truth\", [])\n    if preds and truths:\n        labels = sorted(set(truths + preds))\n        n_cls = len(labels)\n        conf = np.zeros((n_cls, n_cls), dtype=int)\n        idx = {l: i for i, l in enumerate(labels)}\n        for t, p in zip(truths, preds):\n            conf[idx[t], idx[p]] += 1\n        plt.figure(figsize=(6, 5))\n        im = plt.imshow(conf, cmap=\"Blues\")\n        plt.colorbar(im, fraction=0.046, pad=0.04)\n        plt.title(\"SPR_BENCH: Confusion Matrix\\nLeft: Ground Truth, Right: Predicted\")\n        plt.xlabel(\"Predicted Label\")\n        plt.ylabel(\"True Label\")\n        plt.xticks(range(n_cls), labels, rotation=90)\n        plt.yticks(range(n_cls), labels)\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    safe_close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    safe_close()\n", null, null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------- setup --------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- load data ------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    rec = experiment_data[\"BagOfEmbeddings\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    rec = None\n\nif rec:\n    epochs = np.arange(1, len(rec[\"losses\"][\"train\"]) + 1)\n\n    # --------------- loss curves --------------------\n    try:\n        plt.figure(figsize=(6, 4))\n        plt.plot(epochs, rec[\"losses\"][\"train\"], label=\"Train Loss\")\n        plt.plot(epochs, rec[\"losses\"][\"val\"], label=\"Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"Loss Curves \u2014 SPR_BENCH (Bag-of-Embeddings)\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # --------------- SWA curve ----------------------\n    try:\n        plt.figure(figsize=(6, 4))\n        plt.plot(epochs, rec[\"SWA\"][\"val\"], label=\"Validation SWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(\"Validation SWA \u2014 SPR_BENCH (Bag-of-Embeddings)\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_swa_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA curve: {e}\")\n        plt.close()\n\n    # --------------- confusion matrix ---------------\n    try:\n        preds, trues = np.array(rec[\"predictions\"]), np.array(rec[\"ground_truth\"])\n        if preds.size and trues.size:\n            num_labels = int(max(preds.max(), trues.max()) + 1)\n            cm = np.zeros((num_labels, num_labels), dtype=int)\n            for t, p in zip(trues, preds):\n                cm[t, p] += 1\n            plt.figure(figsize=(6, 5))\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im, fraction=0.046, pad=0.04)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(\"Confusion Matrix \u2014 SPR_BENCH Test Set\")\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\n    # --------------- print metrics ------------------\n    print(\"Test metrics:\", rec.get(\"metrics\", {}).get(\"test\", {}))\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------- paths & load ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exit()\n\n# ----- pick the single exp entry ----------\ntry:\n    rec = experiment_data[\"NoSymFeatTransformer\"][\"SPR_BENCH\"]\nexcept KeyError:\n    print(\"Expected keys not found in experiment_data.\")\n    exit()\n\nloss_train = rec[\"losses\"][\"train\"]\nloss_val = rec[\"losses\"][\"val\"]\nswa_val = rec[\"SWA\"][\"val\"]\ntest_metrics = rec[\"metrics\"][\"test\"]\npreds = np.array(rec.get(\"predictions\", []))\ntrues = np.array(rec.get(\"ground_truth\", []))\n\n# ---------------- PLOT 1: loss curves ---------------\ntry:\n    plt.figure(figsize=(6, 4))\n    epochs = np.arange(1, len(loss_train) + 1)\n    plt.plot(epochs, loss_train, label=\"Train Loss\")\n    plt.plot(epochs, loss_val, label=\"Val Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ---------------- PLOT 2: SWA curve -----------------\ntry:\n    plt.figure(figsize=(6, 4))\n    plt.plot(epochs, swa_val, marker=\"o\", label=\"Val SWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Shape-Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: Validation SWA per Epoch\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_swa_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA plot: {e}\")\n    plt.close()\n\n# ---------------- PLOT 3: confusion matrix ----------\ntry:\n    if preds.size and trues.size and preds.shape == trues.shape:\n        n_labels = len(set(trues.tolist() + preds.tolist()))\n        cm = np.zeros((n_labels, n_labels), dtype=int)\n        for t, p in zip(trues, preds):\n            cm[t, p] += 1\n        plt.figure(figsize=(5, 5))\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\"SPR_BENCH: Confusion Matrix (Test Set)\")\n        plt.xticks(range(n_labels))\n        plt.yticks(range(n_labels))\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n        plt.savefig(fname)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ---------------- print final metrics ---------------\nprint(\n    f\"Test metrics -> Loss: {test_metrics.get('loss', 'NA'):.4f}, \"\n    f\"SWA: {test_metrics.get('SWA', 'NA'):.3f}\"\n)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------- paths & load ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exit()\n\n# ----- pick the single exp entry ----------\ntry:\n    rec = experiment_data[\"NoSymFeatTransformer\"][\"SPR_BENCH\"]\nexcept KeyError:\n    print(\"Expected keys not found in experiment_data.\")\n    exit()\n\nloss_train = rec[\"losses\"][\"train\"]\nloss_val = rec[\"losses\"][\"val\"]\nswa_val = rec[\"SWA\"][\"val\"]\ntest_metrics = rec[\"metrics\"][\"test\"]\npreds = np.array(rec.get(\"predictions\", []))\ntrues = np.array(rec.get(\"ground_truth\", []))\n\n# ---------------- PLOT 1: loss curves ---------------\ntry:\n    plt.figure(figsize=(6, 4))\n    epochs = np.arange(1, len(loss_train) + 1)\n    plt.plot(epochs, loss_train, label=\"Train Loss\")\n    plt.plot(epochs, loss_val, label=\"Val Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ---------------- PLOT 2: SWA curve -----------------\ntry:\n    plt.figure(figsize=(6, 4))\n    plt.plot(epochs, swa_val, marker=\"o\", label=\"Val SWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Shape-Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: Validation SWA per Epoch\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_swa_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA plot: {e}\")\n    plt.close()\n\n# ---------------- PLOT 3: confusion matrix ----------\ntry:\n    if preds.size and trues.size and preds.shape == trues.shape:\n        n_labels = len(set(trues.tolist() + preds.tolist()))\n        cm = np.zeros((n_labels, n_labels), dtype=int)\n        for t, p in zip(trues, preds):\n            cm[t, p] += 1\n        plt.figure(figsize=(5, 5))\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\"SPR_BENCH: Confusion Matrix (Test Set)\")\n        plt.xticks(range(n_labels))\n        plt.yticks(range(n_labels))\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n        plt.savefig(fname)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ---------------- print final metrics ---------------\nprint(\n    f\"Test metrics -> Loss: {test_metrics.get('loss', 'NA'):.4f}, \"\n    f\"SWA: {test_metrics.get('SWA', 'NA'):.3f}\"\n)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------- paths & load ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exit()\n\n# ----- pick the single exp entry ----------\ntry:\n    rec = experiment_data[\"NoSymFeatTransformer\"][\"SPR_BENCH\"]\nexcept KeyError:\n    print(\"Expected keys not found in experiment_data.\")\n    exit()\n\nloss_train = rec[\"losses\"][\"train\"]\nloss_val = rec[\"losses\"][\"val\"]\nswa_val = rec[\"SWA\"][\"val\"]\ntest_metrics = rec[\"metrics\"][\"test\"]\npreds = np.array(rec.get(\"predictions\", []))\ntrues = np.array(rec.get(\"ground_truth\", []))\n\n# ---------------- PLOT 1: loss curves ---------------\ntry:\n    plt.figure(figsize=(6, 4))\n    epochs = np.arange(1, len(loss_train) + 1)\n    plt.plot(epochs, loss_train, label=\"Train Loss\")\n    plt.plot(epochs, loss_val, label=\"Val Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ---------------- PLOT 2: SWA curve -----------------\ntry:\n    plt.figure(figsize=(6, 4))\n    plt.plot(epochs, swa_val, marker=\"o\", label=\"Val SWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Shape-Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: Validation SWA per Epoch\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_swa_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA plot: {e}\")\n    plt.close()\n\n# ---------------- PLOT 3: confusion matrix ----------\ntry:\n    if preds.size and trues.size and preds.shape == trues.shape:\n        n_labels = len(set(trues.tolist() + preds.tolist()))\n        cm = np.zeros((n_labels, n_labels), dtype=int)\n        for t, p in zip(trues, preds):\n            cm[t, p] += 1\n        plt.figure(figsize=(5, 5))\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\"SPR_BENCH: Confusion Matrix (Test Set)\")\n        plt.xticks(range(n_labels))\n        plt.yticks(range(n_labels))\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n        plt.savefig(fname)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ---------------- print final metrics ---------------\nprint(\n    f\"Test metrics -> Loss: {test_metrics.get('loss', 'NA'):.4f}, \"\n    f\"SWA: {test_metrics.get('SWA', 'NA'):.3f}\"\n)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up output dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- candidate paths ----------\nexperiment_data_path_list = [\n    \"None/experiment_data.npy\",\n    \"None/experiment_data.npy\",\n    \"experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_094d5cbff8bb4eaeaa7c21d973b5acf2_proc_2705536/experiment_data.npy\",\n]\n\nall_experiment_data = []\nfor p in experiment_data_path_list:\n    # if an environment root is provided, try that first\n    full_path = (\n        os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p)\n        if not os.path.isabs(p)\n        else p\n    )\n    try:\n        exp_dict = np.load(full_path, allow_pickle=True).item()\n        all_experiment_data.append(exp_dict)\n        print(f\"Loaded experiment data from {full_path}\")\n    except Exception as e:\n        print(f\"Skipping {p}: {e}\")\n\nif not all_experiment_data:\n    print(\"No experiment data could be loaded, exiting.\")\n    exit()\n\n# ------------- aggregate -------------\nmodel_name = \"NoSymFeatTransformer\"\ndataset_name = \"SPR_BENCH\"\n\ntrain_losses, val_losses, val_swa, test_loss, test_swa = [], [], [], [], []\n\nfor exp in all_experiment_data:\n    try:\n        rec = exp[model_name][dataset_name]\n        train_losses.append(np.asarray(rec[\"losses\"][\"train\"]))\n        val_losses.append(np.asarray(rec[\"losses\"][\"val\"]))\n        val_swa.append(np.asarray(rec[\"SWA\"][\"val\"]))\n        test_loss.append(rec[\"metrics\"][\"test\"].get(\"loss\", np.nan))\n        test_swa.append(rec[\"metrics\"][\"test\"].get(\"SWA\", np.nan))\n    except Exception as e:\n        print(f\"Missing keys in one run, skipping it: {e}\")\n\nn_runs = len(train_losses)\nif n_runs == 0:\n    print(\"No valid runs for requested model/dataset.\")\n    exit()\n\n# make all arrays equal length (truncate to shortest run)\nmin_len = min(map(len, train_losses))\ntrain_losses = np.stack([tl[:min_len] for tl in train_losses])\nval_losses = np.stack([vl[:min_len] for vl in val_losses])\nval_swa = np.stack([vs[:min_len] for vs in val_swa])\nepochs = np.arange(1, min_len + 1)\n\n\ndef compute_mean_sem(arr):\n    mean = arr.mean(axis=0)\n    sem = (\n        arr.std(axis=0, ddof=1) / np.sqrt(arr.shape[0])\n        if arr.shape[0] > 1\n        else np.zeros_like(mean)\n    )\n    return mean, sem\n\n\ntrain_mean, train_sem = compute_mean_sem(train_losses)\nval_mean, val_sem = compute_mean_sem(val_losses)\nswa_mean, swa_sem = compute_mean_sem(val_swa)\n\n# --------- PLOT 1: aggregated loss curves -----------\ntry:\n    plt.figure(figsize=(6, 4))\n    plt.plot(epochs, train_mean, label=\"Train Loss (mean)\")\n    plt.fill_between(\n        epochs,\n        train_mean - train_sem,\n        train_mean + train_sem,\n        alpha=0.3,\n        label=\"Train SEM\",\n    )\n    plt.plot(epochs, val_mean, label=\"Val Loss (mean)\")\n    plt.fill_between(\n        epochs, val_mean - val_sem, val_mean + val_sem, alpha=0.3, label=\"Val SEM\"\n    )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\n        f\"{dataset_name}: Training vs Validation Loss\\n(Aggregated over {n_runs} run{'s' if n_runs>1 else ''})\"\n    )\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, f\"{dataset_name}_loss_curves_agg.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated loss plot: {e}\")\n    plt.close()\n\n# --------- PLOT 2: aggregated SWA -----------\ntry:\n    plt.figure(figsize=(6, 4))\n    plt.plot(epochs, swa_mean, marker=\"o\", label=\"Val SWA (mean)\")\n    plt.fill_between(\n        epochs, swa_mean - swa_sem, swa_mean + swa_sem, alpha=0.3, label=\"SWA SEM\"\n    )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Shape-Weighted Accuracy\")\n    plt.title(\n        f\"{dataset_name}: Validation SWA per Epoch\\n(Aggregated over {n_runs} run{'s' if n_runs>1 else ''})\"\n    )\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, f\"{dataset_name}_swa_curve_agg.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated SWA plot: {e}\")\n    plt.close()\n\n# ------------- print final aggregated metrics -------------\ntest_loss = np.asarray(test_loss, dtype=float)\ntest_swa = np.asarray(test_swa, dtype=float)\n\n\ndef agg_str(arr):\n    if len(arr) > 1:\n        return f\"{np.nanmean(arr):.4f} \u00b1 {np.nanstd(arr, ddof=1)/np.sqrt(len(arr)):.4f}\"\n    else:\n        return f\"{arr[0]:.4f}\"\n\n\nprint(\n    f\"Aggregated Test Metrics ({n_runs} run{'s' if n_runs>1 else ''}) -> \"\n    f\"Loss: {agg_str(test_loss)}, SWA: {agg_str(test_swa)}\"\n)\n"], "plot_plan": ["We will load the saved numpy dictionary, locate the single experiment record under EPOCH_TUNING \u2192 SPR_BENCH and pull out train/val losses, per-epoch validation metrics, and final test metrics plus predictions/labels.  Using these arrays we will plot (1) a train-vs-validation loss curve, (2) a validation accuracy curve, (3) a bar chart of the four reported test metrics, and (4) a 2\u00d72 confusion-matrix heat-map derived from the stored predictions and ground-truth.  Each figure is wrapped in its own try/except so that one failure does not stop the others, and figures are always closed.  All plots are saved into the existing working directory with descriptive names that include the dataset and plot type.  Titles explicitly mention the dataset and give a subtitle explaining what is shown.  We stay under the five-figure limit and rely solely on data present in experiment_data.npy.  After plotting, we also print the numeric test metrics so they appear in stdout for quick reference.", "We first load the saved experiment_data.npy and extract the record for the \u2018SPR_BENCH_HELDOUT\u2019 split. From it we pull the epoch-wise training and validation losses as well as the validation SWA scores. These sequences are plotted against epoch indices (starting from 1). Next we compute a confusion matrix using the stored ground-truth and prediction indices; if the number of labels is reasonable (\u226420) we visualise it with imshow, otherwise we skip the plot. Each figure is wrapped in its own try-except block, stored in working_dir with descriptive filenames, given a clear title that includes the dataset name, and closed afterwards. We cap the total number of figures to three, satisfying the \u201c\u22645 figures\u201d rule. Only data present in experiment_data.npy are used; nothing is fabricated. Finally, no custom matplotlib styles are employed and all figures are saved in PNG format.", "We will first load experiment_data.npy from the working directory and extract the single run stored under NoSymFeatTransformer / SPR_BENCH. If the file is missing we simply print an error and exit. Three plots will be produced (all wrapped in individual try-except blocks): (1) training vs. validation loss over epochs; (2) validation Shape-Weighted Accuracy (SWA) over epochs; (3) a confusion-matrix style heat-map comparing final test predictions and ground-truth labels. Each figure will be titled clearly, saved to working_dir with descriptive filenames, then closed. We cap ourselves at these three figures to respect the \u201c\u22645 plots\u201d rule. The script also prints the final test loss and SWA that were saved by the training code so users can see numerical metrics. All plotting uses vanilla matplotlib and only draws information present in experiment_data.npy.", "We first load experiment_data.npy and grab the single experiment record (CLS_Pooling\u2006/\u2006SPR_BENCH).  From it we extract the per-epoch training and validation losses, the per-epoch validation SWA scores, and the final test predictions/ground-truth arrays.  Three plots are generated, each wrapped in its own try-except block: (1) a line plot showing training vs. validation loss over epochs; (2) a line plot of the validation shape-weighted accuracy (SWA) curve; (3) a confusion-matrix heat-map comparing ground-truth labels to model predictions on the test set.  All figures are saved into working_dir with descriptive filenames that include the dataset name and plot type.  Each figure is titled clearly and closed after saving to free memory.  Only data present in experiment_data.npy are used\u2014no synthetic values are created.  The code follows the required imports/order and prints a confirmation for each saved plot as well as any caught errors.", "We first load experiment_data.npy from the working directory and probe its nested dictionaries to obtain arrays for training loss, validation loss, and validation SWA recorded across epochs, as well as the test-set predictions and ground-truth labels. Three independent plots are produced (each guarded by its own try/except): (1) a loss curve comparing train and validation losses per epoch; (2) a validation Shape-Weighted Accuracy (SWA) curve; (3) a confusion-matrix heat-map between ground-truth and predicted labels on the test set. Each figure has a clear title and axis labels, is saved to working_dir with descriptive names including the dataset (SPR_BENCH) and plot type, and the figure is always closed afterwards. The code opens at most these three plots, satisfying the five-figure limit. We limit data use strictly to what exists inside experiment_data.npy; no extra values are generated. Basic matplotlib is employed without custom style sheets, and every plot is wrapped in try/except to ensure robust execution even if some keys are missing. Finally, the script prints a short confirmation once all plots are saved.", null, null, null, "The script loads the stored experiment_data.npy, extracts the BagOfEmbeddings results for the SPR_BENCH dataset, and then produces up to three standard visualisations. It first plots the training and validation loss curves across epochs, then the validation shape-weighted accuracy curve, and finally a confusion-matrix heat-map computed from the saved test predictions versus ground-truth labels. Each figure is created in its own try-except block, saved with a descriptive name to working_dir, and explicitly closed to avoid resource leaks. The code also prints the recorded test metrics (loss and SWA) so they appear in the execution log. Only data present in the numpy file are used\u2014no synthetic values are introduced. The whole routine respects the figure limit and uses only basic matplotlib functionalities.", null, null, null, null], "ablation_name": [null, "Multi-Dataset Generalisation (3\u00d7 Synthetic SPR Variants)", "No-SymFeat Transformer", "CLS-Token Pooling", "No-Positional-Embedding", "Fixed-Sinusoidal-Position-Embedding", "Concatenative Shape-Color Fusion", "Color-Blind Transformer", "No-Transformer (Bag-of-Embeddings)", null, null, null, null], "hyperparam_name": ["EPOCHS", null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["The script will load the saved NumPy dictionary, navigate to the only experiment\nrun (EPOCH_TUNING \u2192 SPR_BENCH), and gather the last-epoch training loss, the\nbest (i.e., lowest) validation loss together with the corresponding highest\nvalidation accuracy/SWA/CWA/NRGS, and finally the test metrics that were stored\nafter evaluation. It then prints each dataset\u2019s name followed by clearly-labeled\nmetric values. No plots are produced, and all code executes directly at import\ntime in global scope.", "The script will load the NumPy file from the working directory, walk through\nevery dataset/sub-dataset entry, and gather the stored lists/dictionaries of\nlosses and shape-weighted accuracies. For each metric we will choose a sensible\n\u201cbest\u201d representative value (minimum for losses, maximum for accuracies) and\nthen print these with explicit, descriptive names. All code is placed at the\nglobal scope so that it runs immediately when the file is executed.", "The script needs to load experiment_data.npy from the working directory, iterate\nover every recorded dataset, and print clear, descriptive metric names together\nwith the single best (or final) value required. We will consider the last\ntraining loss as the final training loss, the minimum validation loss as the\nbest validation loss, the maximum validation SWA as the best validation shape-\nweighted accuracy, and the stored test metrics as final test results. No plots\nare generated and everything runs immediately at the top level.", "We will load the saved NumPy file from the working directory, navigate the\nnested dictionary to reach the section that stores losses and SWA scores, and\nthen print the most recent (i.e. final/best) values for each split.   For the\ntraining split we output the last recorded training loss; for the validation\nsplit we output both the last validation loss and validation shape-weighted\naccuracy (SWA); for the test split we output the stored test loss and test SWA.\nAll printing is done with explicit, descriptive metric names preceded by the\ncorresponding split name.", "The script will load the stored NumPy dictionary from the working directory,\niterate through every experiment and dataset inside it, extract the relevant\nlists/dictionaries that hold the logged values, determine the \u201cbest\u201d (min loss /\nmax accuracy) or final value as appropriate, and print them in a clear,\ndescriptive format. It avoids any plotting or special entry-point guards so that\nthe code executes immediately when run.", "The script will (1) locate the working directory, (2) load experiment_data.npy\ninto a Python dict, (3) iterate through every model and dataset stored, (4)\ncompute \u201cbest\u201d values (minimum for losses, maximum for accuracies/SWA) or, when\nonly a single value exists, use that value, and (5) print each dataset name\nfollowed by clearly-labelled metric/value pairs. This runs immediately at import\ntime and needs no special entry point.", "", "The script will load the saved numpy file from the working directory, traverse\nthe nested dictionary, and neatly report the best (minimum or maximum, as\nappropriate) or final values of each tracked metric. It prints the dataset name\nfirst, followed by clearly-labelled metrics such as \u201ctraining loss,\u201d \u201cvalidation\nloss,\u201d and \u201ctest shape-weighted accuracy.\u201d The code executes immediately\u2014no\nspecial entry point or plotting is used.", "The script will load the NumPy file from the working directory, walk through\nevery model and dataset inside the saved dictionary, and pull out the stored\ntraining/validation loss curves, validation SWA curve, and the final test\nmetrics. It then computes the best (minimum) training loss, the best validation\nloss, and the best validation SWA, and directly reads the recorded final test\nloss and test SWA. Each dataset\u2019s name is printed first, followed by clearly-\nlabelled metric/value lines. The code runs immediately on execution and contains\nno plotting or `if __name__ == \"__main__\":` guard.", "The script needs to load experiment_data.npy from the working directory, iterate\nover every recorded dataset, and print clear, descriptive metric names together\nwith the single best (or final) value required. We will consider the last\ntraining loss as the final training loss, the minimum validation loss as the\nbest validation loss, the maximum validation SWA as the best validation shape-\nweighted accuracy, and the stored test metrics as final test results. No plots\nare generated and everything runs immediately at the top level.", "The script needs to load experiment_data.npy from the working directory, iterate\nover every recorded dataset, and print clear, descriptive metric names together\nwith the single best (or final) value required. We will consider the last\ntraining loss as the final training loss, the minimum validation loss as the\nbest validation loss, the maximum validation SWA as the best validation shape-\nweighted accuracy, and the stored test metrics as final test results. No plots\nare generated and everything runs immediately at the top level.", "The script needs to load experiment_data.npy from the working directory, iterate\nover every recorded dataset, and print clear, descriptive metric names together\nwith the single best (or final) value required. We will consider the last\ntraining loss as the final training loss, the minimum validation loss as the\nbest validation loss, the maximum validation SWA as the best validation shape-\nweighted accuracy, and the stored test metrics as final test results. No plots\nare generated and everything runs immediately at the top level.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# 0. Locate and load the experiment data\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Navigate to the only run contained in the file\nrun_dict = experiment_data[\"EPOCH_TUNING\"][\"SPR_BENCH\"]\n\ntrain_losses = run_dict[\"losses\"][\"train\"]  # list of floats per epoch\nval_losses = run_dict[\"losses\"][\"val\"]  # list of floats per epoch\nval_metrics = run_dict[\"metrics\"][\"val\"]  # list of dicts per epoch\ntest_metrics = run_dict[\"metrics\"][\"test\"]  # single dict\n\n# ---------------------------------------------------------------------\n# 1. Extract final / best values\n# ---------------------------------------------------------------------\n# Training set \u2013 we only have loss logged epoch-wise\nfinal_train_loss = train_losses[-1] if train_losses else None\n\n# Validation set \u2013 pick epoch with lowest loss\nif val_losses:\n    best_epoch_idx = int(np.argmin(val_losses))\n    best_val = val_metrics[best_epoch_idx]\n    best_val_loss = val_losses[best_epoch_idx]\nelse:  # Fallback if no validation info\n    best_val = {}\n    best_val_loss = None\n\n# ---------------------------------------------------------------------\n# 2. Print results\n# ---------------------------------------------------------------------\n# Training\nprint(\"TRAINING SET\")\nif final_train_loss is not None:\n    print(f\"  training loss: {final_train_loss:.6f}\")\n\n# Validation\nprint(\"VALIDATION SET\")\nif best_val_loss is not None:\n    print(f\"  validation loss (best): {best_val_loss:.6f}\")\nfor k in (\"acc\", \"swa\", \"cwa\", \"nrgs\"):\n    if k in best_val:\n        metric_name = {\n            \"acc\": \"validation accuracy\",\n            \"swa\": \"validation shape-weighted accuracy\",\n            \"cwa\": \"validation color-weighted accuracy\",\n            \"nrgs\": \"validation NRGS\",\n        }[k]\n        print(f\"  {metric_name}: {best_val[k]:.6f}\")\n\n# Test\nprint(\"TEST SET\")\nfor k, v in test_metrics.items():\n    metric_name = {\n        \"loss\": \"test loss\",\n        \"acc\": \"test accuracy\",\n        \"swa\": \"test shape-weighted accuracy\",\n        \"cwa\": \"test color-weighted accuracy\",\n        \"nrgs\": \"test NRGS\",\n    }.get(k, k)\n    print(f\"  {metric_name}: {v:.6f}\")\n", "import os\nimport numpy as np\n\n# --------------------------------------------------\n# Locate and load the saved experiment artefacts\n# --------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# --------------------------------------------------\n# Utility to print a metric only if it exists\n# --------------------------------------------------\ndef safe_print(label: str, value):\n    if value is not None:\n        print(f\"    {label}: {value:.4f}\")\n\n\n# --------------------------------------------------\n# Traverse every dataset & summarise the metrics\n# --------------------------------------------------\nfor dataset_name, dataset_content in experiment_data.items():\n    for sub_name, rec in dataset_content.items():\n        print(f\"{dataset_name} - {sub_name}\")\n\n        # Training / validation losses\n        train_losses = rec.get(\"losses\", {}).get(\"train\", [])\n        val_losses = rec.get(\"losses\", {}).get(\"val\", [])\n\n        best_train_loss = min(train_losses) if train_losses else None\n        best_val_loss = min(val_losses) if val_losses else None\n\n        safe_print(\"Best Training Loss\", best_train_loss)\n        safe_print(\"Best Validation Loss\", best_val_loss)\n\n        # Validation accuracy (Shape-Weighted Accuracy)\n        val_swa = rec.get(\"SWA\", {}).get(\"val\", [])\n        best_val_swa = max(val_swa) if val_swa else None\n        safe_print(\"Best Validation Shape-Weighted Accuracy\", best_val_swa)\n\n        # Final test metrics\n        test_metrics = rec.get(\"metrics\", {}).get(\"test\", {})\n        safe_print(\"Test Loss\", test_metrics.get(\"loss\"))\n        safe_print(\"Test Shape-Weighted Accuracy\", test_metrics.get(\"SWA\"))\n", "import os\nimport numpy as np\n\n# -------- locate and load experiment data ---------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# -------- iterate and report metrics --------------\nfor model_name, datasets in experiment_data.items():\n    for dataset_name, rec in datasets.items():\n        print(dataset_name)  # dataset header\n\n        # Training loss (final value)\n        train_losses = rec.get(\"losses\", {}).get(\"train\", [])\n        if train_losses:\n            print(f\"final training loss: {train_losses[-1]:.4f}\")\n\n        # Validation loss (best value)\n        val_losses = rec.get(\"losses\", {}).get(\"val\", [])\n        if val_losses:\n            best_val_loss = min(val_losses)\n            print(f\"best validation loss: {best_val_loss:.4f}\")\n\n        # Validation SWA (best value)\n        val_swa_scores = rec.get(\"SWA\", {}).get(\"val\", [])\n        if val_swa_scores:\n            best_val_swa = max(val_swa_scores)\n            print(f\"best validation shape-weighted accuracy: {best_val_swa:.3f}\")\n\n        # Test metrics (single recorded values)\n        test_metrics = rec.get(\"metrics\", {}).get(\"test\", {})\n        if \"loss\" in test_metrics:\n            print(f\"test loss: {test_metrics['loss']:.4f}\")\n        if \"SWA\" in test_metrics:\n            print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.3f}\")\n", "import os\nimport numpy as np\n\n# ---------- load saved experiment dictionary ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper to print a metric safely ------------\ndef _print_metric(name: str, value):\n    if isinstance(value, float):\n        print(f\"{name}: {value:.4f}\")\n    else:  # fallback for non-float values\n        print(f\"{name}: {value}\")\n\n\n# ---------- iterate through stored experiments ----------\nfor model_name, datasets in experiment_data.items():  # e.g. \"CLS_Pooling\"\n    for bench_name, rec in datasets.items():  # e.g. \"SPR_BENCH\"\n        losses = rec.get(\"losses\", {})\n        swa_scores = rec.get(\"SWA\", {})\n        test_metrics = rec.get(\"metrics\", {}).get(\"test\", {})\n\n        # -------- Training split --------\n        if losses.get(\"train\"):\n            print(\"\\nDataset: Training\")\n            _print_metric(\"Training loss\", losses[\"train\"][-1])\n\n        # -------- Validation split --------\n        if losses.get(\"val\") or swa_scores.get(\"val\"):\n            print(\"\\nDataset: Validation\")\n            if losses.get(\"val\"):\n                _print_metric(\"Validation loss\", losses[\"val\"][-1])\n            if swa_scores.get(\"val\"):\n                _print_metric(\n                    \"Validation shape-weighted accuracy\", swa_scores[\"val\"][-1]\n                )\n\n        # -------- Test split --------\n        if test_metrics:\n            print(\"\\nDataset: Test\")\n            if \"loss\" in test_metrics:\n                _print_metric(\"Test loss\", test_metrics[\"loss\"])\n            if \"SWA\" in test_metrics:\n                _print_metric(\"Test shape-weighted accuracy\", test_metrics[\"SWA\"])\n", "import os\nimport numpy as np\n\n# ---------- load experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"Could not find {exp_file}\")\n\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n\n# ---------- helper functions ----------\ndef safe_best(values, mode=\"min\"):\n    \"\"\"Return best value from list; if empty return None.\"\"\"\n    if not values:\n        return None\n    return min(values) if mode == \"min\" else max(values)\n\n\ndef fmt(name, value):\n    \"\"\"Format printing only when value is not None.\"\"\"\n    if value is not None:\n        print(f\"{name}: {value:.4f}\")\n\n\n# ---------- iterate & report ----------\nfor exp_name, datasets in experiment_data.items():\n    # exp_name would be 'NoPositionalEmbedding'; we may ignore it or include it\n    for dset_name, rec in datasets.items():\n        print(dset_name)  # dataset header\n\n        # training loss  (use final epoch value)\n        train_losses = rec.get(\"losses\", {}).get(\"train\", [])\n        if train_losses:\n            fmt(\"training loss (final)\", train_losses[-1])\n\n        # best validation loss (minimum)\n        val_losses = rec.get(\"losses\", {}).get(\"val\", [])\n        fmt(\"validation loss (best)\", safe_best(val_losses, mode=\"min\"))\n\n        # best validation shape-weighted accuracy (maximum SWA)\n        val_swa_list = rec.get(\"SWA\", {}).get(\"val\", [])\n        fmt(\n            \"validation shape-weighted accuracy (best)\",\n            safe_best(val_swa_list, mode=\"max\"),\n        )\n\n        # test metrics\n        test_metrics = rec.get(\"metrics\", {}).get(\"test\", {})\n        if test_metrics:\n            fmt(\"test loss\", test_metrics.get(\"loss\"))\n            fmt(\"test shape-weighted accuracy\", test_metrics.get(\"SWA\"))\n\n        # blank line between datasets for readability\n        print()\n", "import os\nimport numpy as np\n\n# ---------------- locate & load ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n\n# ---------------- helper to pick best -----------------------------------------\ndef best_value(list_or_scalar, smaller_is_better=True):\n    \"\"\"\n    Return the best (min or max) from a list; if the input is not iterable,\n    simply return it.\n    \"\"\"\n    if isinstance(list_or_scalar, (list, tuple)) and list_or_scalar:\n        return min(list_or_scalar) if smaller_is_better else max(list_or_scalar)\n    return list_or_scalar\n\n\n# ---------------- iterate & print ---------------------------------------------\nfor model_name, ds_dict in experiment_data.items():\n    for dataset_name, rec in ds_dict.items():\n        print(f\"\\nDataset: {dataset_name}\")\n\n        # training / validation losses\n        train_loss_best = best_value(rec[\"losses\"][\"train\"], smaller_is_better=True)\n        val_loss_best = best_value(rec[\"losses\"][\"val\"], smaller_is_better=True)\n        print(f\"best training loss: {train_loss_best:.4f}\")\n        print(f\"best validation loss: {val_loss_best:.4f}\")\n\n        # validation SWA (Shape-Weighted Accuracy)\n        val_swa_best = best_value(rec[\"SWA\"][\"val\"], smaller_is_better=False)\n        print(f\"best validation shape-weighted accuracy (SWA): {val_swa_best:.3f}\")\n\n        # test metrics\n        test_metrics = rec.get(\"metrics\", {}).get(\"test\", {})\n        if \"loss\" in test_metrics:\n            print(f\"test loss: {test_metrics['loss']:.4f}\")\n        if \"SWA\" in test_metrics:\n            print(f\"test shape-weighted accuracy (SWA): {test_metrics['SWA']:.3f}\")\n", "", "import os\nimport numpy as np\n\n# ---------------- locate and load data ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------------- helper to print one dataset ----------\ndef report_dataset(name, rec):\n    # training / validation losses\n    train_losses = rec[\"losses\"][\"train\"]\n    val_losses = rec[\"losses\"][\"val\"]\n    val_swa = rec[\"SWA\"][\"val\"]\n\n    # best (or final) values\n    if train_losses:\n        best_train_loss = min(train_losses)\n        print(\"  training loss:\", best_train_loss)\n    if val_losses:\n        best_val_loss = min(val_losses)\n        print(\"  validation loss:\", best_val_loss)\n    if val_swa:\n        best_val_swa = max(val_swa)\n        print(\"  validation shape-weighted accuracy:\", best_val_swa)\n\n    # test metrics (only one entry stored)\n    test_metrics = rec[\"metrics\"][\"test\"]\n    if test_metrics:\n        print(\"  test loss:\", test_metrics.get(\"loss\"))\n        print(\"  test shape-weighted accuracy:\", test_metrics.get(\"SWA\"))\n\n\n# ---------------- iterate through models/datasets -----\nfor model_name, model_rec in experiment_data.items():\n    for dataset_name, ds_rec in model_rec.items():\n        print(dataset_name)\n        report_dataset(dataset_name, ds_rec)\n", "import os\nimport numpy as np\n\n# -------- locate & load the saved experiment data --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# -------- helper to get best or final metric values -------\ndef best_or_none(values, mode=\"min\"):\n    \"\"\"Return best value (min or max) from list or None if list is empty.\"\"\"\n    if not values:\n        return None\n    return min(values) if mode == \"min\" else max(values)\n\n\n# -------- iterate through structure and print -------------\nfor model_name, datasets in experiment_data.items():\n    for dataset_name, rec in datasets.items():\n        print(dataset_name)  # dataset header\n\n        # training loss (best / lowest)\n        train_losses = rec.get(\"losses\", {}).get(\"train\", [])\n        best_train_loss = best_or_none(train_losses, mode=\"min\")\n        if best_train_loss is not None:\n            print(f\"training loss: {best_train_loss:.6f}\")\n\n        # validation loss (best / lowest)\n        val_losses = rec.get(\"losses\", {}).get(\"val\", [])\n        best_val_loss = best_or_none(val_losses, mode=\"min\")\n        if best_val_loss is not None:\n            print(f\"validation loss: {best_val_loss:.6f}\")\n\n        # validation SWA (best / highest)\n        val_swa = rec.get(\"SWA\", {}).get(\"val\", [])\n        best_val_swa = best_or_none(val_swa, mode=\"max\")\n        if best_val_swa is not None:\n            print(f\"validation SWA: {best_val_swa:.6f}\")\n\n        # test metrics (final)\n        test_metrics = rec.get(\"metrics\", {}).get(\"test\", {})\n        test_loss = test_metrics.get(\"loss\")\n        if test_loss is not None:\n            print(f\"test loss: {test_loss:.6f}\")\n\n        test_swa = test_metrics.get(\"SWA\", rec.get(\"SWA\", {}).get(\"test\"))\n        if test_swa is not None:\n            print(f\"test SWA: {test_swa:.6f}\")\n\n        print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# -------- locate and load experiment data ---------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# -------- iterate and report metrics --------------\nfor model_name, datasets in experiment_data.items():\n    for dataset_name, rec in datasets.items():\n        print(dataset_name)  # dataset header\n\n        # Training loss (final value)\n        train_losses = rec.get(\"losses\", {}).get(\"train\", [])\n        if train_losses:\n            print(f\"final training loss: {train_losses[-1]:.4f}\")\n\n        # Validation loss (best value)\n        val_losses = rec.get(\"losses\", {}).get(\"val\", [])\n        if val_losses:\n            best_val_loss = min(val_losses)\n            print(f\"best validation loss: {best_val_loss:.4f}\")\n\n        # Validation SWA (best value)\n        val_swa_scores = rec.get(\"SWA\", {}).get(\"val\", [])\n        if val_swa_scores:\n            best_val_swa = max(val_swa_scores)\n            print(f\"best validation shape-weighted accuracy: {best_val_swa:.3f}\")\n\n        # Test metrics (single recorded values)\n        test_metrics = rec.get(\"metrics\", {}).get(\"test\", {})\n        if \"loss\" in test_metrics:\n            print(f\"test loss: {test_metrics['loss']:.4f}\")\n        if \"SWA\" in test_metrics:\n            print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.3f}\")\n", "import os\nimport numpy as np\n\n# -------- locate and load experiment data ---------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# -------- iterate and report metrics --------------\nfor model_name, datasets in experiment_data.items():\n    for dataset_name, rec in datasets.items():\n        print(dataset_name)  # dataset header\n\n        # Training loss (final value)\n        train_losses = rec.get(\"losses\", {}).get(\"train\", [])\n        if train_losses:\n            print(f\"final training loss: {train_losses[-1]:.4f}\")\n\n        # Validation loss (best value)\n        val_losses = rec.get(\"losses\", {}).get(\"val\", [])\n        if val_losses:\n            best_val_loss = min(val_losses)\n            print(f\"best validation loss: {best_val_loss:.4f}\")\n\n        # Validation SWA (best value)\n        val_swa_scores = rec.get(\"SWA\", {}).get(\"val\", [])\n        if val_swa_scores:\n            best_val_swa = max(val_swa_scores)\n            print(f\"best validation shape-weighted accuracy: {best_val_swa:.3f}\")\n\n        # Test metrics (single recorded values)\n        test_metrics = rec.get(\"metrics\", {}).get(\"test\", {})\n        if \"loss\" in test_metrics:\n            print(f\"test loss: {test_metrics['loss']:.4f}\")\n        if \"SWA\" in test_metrics:\n            print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.3f}\")\n", "import os\nimport numpy as np\n\n# -------- locate and load experiment data ---------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# -------- iterate and report metrics --------------\nfor model_name, datasets in experiment_data.items():\n    for dataset_name, rec in datasets.items():\n        print(dataset_name)  # dataset header\n\n        # Training loss (final value)\n        train_losses = rec.get(\"losses\", {}).get(\"train\", [])\n        if train_losses:\n            print(f\"final training loss: {train_losses[-1]:.4f}\")\n\n        # Validation loss (best value)\n        val_losses = rec.get(\"losses\", {}).get(\"val\", [])\n        if val_losses:\n            best_val_loss = min(val_losses)\n            print(f\"best validation loss: {best_val_loss:.4f}\")\n\n        # Validation SWA (best value)\n        val_swa_scores = rec.get(\"SWA\", {}).get(\"val\", [])\n        if val_swa_scores:\n            best_val_swa = max(val_swa_scores)\n            print(f\"best validation shape-weighted accuracy: {best_val_swa:.3f}\")\n\n        # Test metrics (single recorded values)\n        test_metrics = rec.get(\"metrics\", {}).get(\"test\", {})\n        if \"loss\" in test_metrics:\n            print(f\"test loss: {test_metrics['loss']:.4f}\")\n        if \"SWA\" in test_metrics:\n            print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.3f}\")\n", ""], "parse_term_out": ["['TRAINING SET', '\\n', '  training loss: 0.000515', '\\n', 'VALIDATION SET',\n'\\n', '  validation loss (best): 0.003376', '\\n', '  validation accuracy:\n0.998400', '\\n', '  validation shape-weighted accuracy: 0.998256', '\\n', '\nvalidation color-weighted accuracy: 0.998231', '\\n', '  validation NRGS:\n1.000000', '\\n', 'TEST SET', '\\n', '  test loss: 3.723709', '\\n', '  test\naccuracy: 0.700500', '\\n', '  test shape-weighted accuracy: 0.652862', '\\n', '\ntest color-weighted accuracy: 0.700969', '\\n', '  test NRGS: 0.757812', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['MultiDataset - SPR_BENCH_HELDOUT', '\\n', '    Best Training Loss: 0.0005',\n'\\n', '    Best Validation Loss: 0.0012', '\\n', '    Best Validation Shape-\nWeighted Accuracy: 0.9995', '\\n', '    Test Loss: 4.0157', '\\n', '    Test\nShape-Weighted Accuracy: 0.6522', '\\n', 'Execution time: a moment seconds (time\nlimit is 30 minutes).']", "['SPR_BENCH', '\\n', 'final training loss: 0.0056', '\\n', 'best validation loss:\n0.0010', '\\n', 'best validation shape-weighted accuracy: 1.000', '\\n', 'test\nloss: 3.2691', '\\n', 'test shape-weighted accuracy: 0.652', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: Training', '\\n', 'Training loss: 0.0180', '\\n', '\\nDataset:\nValidation', '\\n', 'Validation loss: 0.0113', '\\n', 'Validation shape-weighted\naccuracy: 0.9972', '\\n', '\\nDataset: Test', '\\n', 'Test loss: 2.3917', '\\n',\n'Test shape-weighted accuracy: 0.6529', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'training loss (final): 0.1701', '\\n', 'validation loss\n(best): 0.1653', '\\n', 'validation shape-weighted accuracy (best): 0.9447',\n'\\n', 'test loss: 1.2630', '\\n', 'test shape-weighted accuracy: 0.6500', '\\n',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'best training loss: 0.0072', '\\n', 'best\nvalidation loss: 0.0009', '\\n', 'best validation shape-weighted accuracy (SWA):\n1.000', '\\n', 'test loss: 3.1481', '\\n', 'test shape-weighted accuracy (SWA):\n0.652', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "", "['SPR_BENCH', '\\n', '  training loss:', ' ', '0.1073619705915451', '\\n', '\nvalidation loss:', ' ', '0.10407546188831329', '\\n', '  validation shape-\nweighted accuracy:', ' ', '0.9729101267294501', '\\n', '  test loss:', ' ',\n'1.5903858589172364', '\\n', '  test shape-weighted accuracy:', ' ',\n'0.6450369511664976', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['SPR_BENCH', '\\n', 'training loss: 0.539729', '\\n', 'validation loss:\n0.543899', '\\n', 'validation SWA: 0.735903', '\\n', 'test loss: 0.685242', '\\n',\n'test SWA: 0.587190', '\\n', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['SPR_BENCH', '\\n', 'final training loss: 0.0088', '\\n', 'best validation loss:\n0.0051', '\\n', 'best validation shape-weighted accuracy: 0.998', '\\n', 'test\nloss: 2.8128', '\\n', 'test shape-weighted accuracy: 0.653', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'final training loss: 0.0162', '\\n', 'best validation loss:\n0.0068', '\\n', 'best validation shape-weighted accuracy: 0.997', '\\n', 'test\nloss: 3.0942', '\\n', 'test shape-weighted accuracy: 0.654', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'final training loss: 0.0055', '\\n', 'best validation loss:\n0.0010', '\\n', 'best validation shape-weighted accuracy: 1.000', '\\n', 'test\nloss: 3.1133', '\\n', 'test shape-weighted accuracy: 0.652', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"], "current_stage": "Stage_4"};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
