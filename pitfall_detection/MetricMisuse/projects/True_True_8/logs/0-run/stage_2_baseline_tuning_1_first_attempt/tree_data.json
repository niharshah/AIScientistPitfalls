{"edges": [[0, 4], [0, 2], [0, 1], [0, 3], [0, 5], [3, 6], [3, 7], [7, 9], [7, 10], [7, 11], [7, 8]], "layout": [[0.5, 0.0], [0.0, 0.33333333333333337], [0.25, 0.33333333333333337], [0.5, 0.33333333333333337], [0.75, 0.33333333333333337], [1.0, 0.33333333333333337], [0.375, 0.6666666666666667], [0.625, 0.6666666666666667], [0.25, 1.0], [0.5, 1.0], [0.75, 1.0], [1.0, 1.0]], "plan": ["We first load the SPR_BENCH splits (or fall back to a tiny synthetic set if the\nfolder is missing), build a token-level vocabulary, and pad/encode every\nsequence to a fixed length. A light mean-pooled embedding model (embedding +\naverage pooling + linear classifier) serves as the initial baseline; it is\ntrained with standard cross-entropy on the training split for a few epochs. A\nsimple rule-preserving augmentation (\u201cshape-renaming\u201d: consistent random\nremapping of the first character of every token) is implemented and injected on-\nthe-fly during training to expose the model to context variations. After every\nepoch we evaluate on the dev split, print the validation loss, and compute the\nAugmentation Consistency Score (ACS) by checking how often the predicted label\nremains correct across five independent augmented variants of each sequence. All\nmetrics, losses, predictions and ground-truth targets are stored in a structured\nexperiment_data dictionary and saved to disk. Basic GPU/CPU handling, data-\nloader device transfer, and metric persistence are included to satisfy the\nmandatory requirements. Although simple, this pipeline establishes a\nreproducible end-to-end baseline on which more sophisticated contrastive\nobjectives can be plugged in later.", "Hyperparam tuning name: learning_rate. We sweep Adam\u2019s learning-rate over {1e-4,\n5e-4, 1e-3, 2e-3}.   For every rate we re-initialise the mean-embedding model,\ntrain for five epochs with the same on-the-fly augmentation, and record train\nloss, validation loss and validation ACS each epoch plus final dev\npredictions/labels.   Results are stored in a single dict named experiment_data\nunder the top-level key 'lr_sweep', then saved to experiment_data.npy.", "Hyperparam tuning name: batch_size. The script below loops over the candidate\nbatch sizes (32, 64, 128, 256, 512), trains a fresh model for each setting,\nevaluates on the validation split every epoch, and stores per-epoch losses plus\nthe ACS metric.  All results are collected under\nexperiment_data['batch_size']['SPR_BENCH'] and saved to experiment_data.npy, so\nthey can later be plotted to see which batch size works best.", "Hyperparam tuning name: embed_dim. Below is a compact extension of the baseline\nthat performs a sweep over three embedding sizes (64 / 128 / 256).  For every\ndimension we (re-)initialise the model, train for five epochs with the same\noptimiser, and log loss as well as ACS on the dev set.  All results \u2013 together\nwith predictions and ground-truth labels \u2013 are stored in the required\nexperiment_data structure and saved to working/experiment_data.npy.", "Hyperparam tuning name: weight_decay. We introduce a simple grid\u2013search over\nAdam\u2019s weight_decay (0, 1e-5, 1e-4, 5e-4, 1e-3).   For every value a fresh Mean-\nEmbedding classifier is trained for a few epochs, metrics are collected, and the\nwhole structure is stored in the experiment_data dictionary before being saved\nto experiment_data.npy.   Apart from inserting weight decay into the optimizer,\nno other changes are made to the model or data pipeline.", "Hyperparam tuning name: aug_probability. The script below sweeps the\naugmentation probability `aug_probability` over {0.0, 0.25, 0.5, 0.75, 1.0}.\nFor each value a fresh model is trained, validation loss and ACS are tracked\nper-epoch, and all results are stored in the `experiment_data` dictionary under\nthe key `\"aug_probability\" \u2192 \"SPR_BENCH\" \u2192 <probability> \u2026`.   Finally the full\nstructure is saved to `experiment_data.npy`, enabling later analysis and\nplotting.", "The crash occurred because the name Dataset was imported twice: first from\ntorch.utils.data (which should be the superclass for our PyTorch dataset\nwrapper) and then from datasets (the Hugging-Face object).   After the second\nimport, Dataset referred to the Hugging-Face class; subclassing it in\nSPRTorchDataset and later assigning to self.data (a read-only property)\ntriggered AttributeError.   Solution: keep the two concepts separate by aliasing\n\u2013 e.g. TorchDataset for torch.utils.data.Dataset and HFDataset for\ndatasets.Dataset \u2013 then subclass TorchDataset and store the HF dataset in a\ndifferent attribute (e.g. self.hf_ds).   The rest of the script is updated to\ncompute SWA, CWA and their composite CoWA each epoch, respect device placement,\nand save all results.", "We fix the crash by avoiding the name-collision between the two different\n\u201cDataset\u201d classes.   Torch\u2019s `torch.utils.data.Dataset` is now imported as\n`TorchDataset`, while Hugging-Face\u2019s is kept as `HFDataset`.   `SPRTorchDataset`\ncorrectly subclasses `TorchDataset`, so assigning to the attribute `self.ds`\n(instead of the reserved name `data`) is safe.   We additionally compute the\nrequired Shape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA) and their\nmean Composite Weighted Accuracy (CoWA) at each epoch, record everything inside\n`experiment_data`, and save the results.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, random, string, pathlib, time, math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import DatasetDict\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- helper : load dataset (provided util) ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    from datasets import load_dataset, DatasetDict\n\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\n# ---------- synthetic fallback ----------\ndef build_synthetic_dataset(n_train=2000, n_dev=500, n_test=500, max_len=12):\n    def _gen_row():\n        length = random.randint(4, max_len)\n        seq = []\n        label = 0\n        for _ in range(length):\n            shape = random.choice(string.ascii_uppercase[:5])  # 5 shapes\n            color = random.choice(\"01234\")  # 5 colors\n            seq.append(shape + color)\n            label ^= (ord(shape) + int(color)) & 1  # synthetic rule: parity\n        return {\n            \"id\": str(random.randint(0, 1e9)),\n            \"sequence\": \" \".join(seq),\n            \"label\": int(label),\n        }\n\n    def _many(n):\n        return [_gen_row() for _ in range(n)]\n\n    from datasets import Dataset, DatasetDict\n\n    return DatasetDict(\n        {\n            \"train\": Dataset.from_list(_many(n_train)),\n            \"dev\": Dataset.from_list(_many(n_dev)),\n            \"test\": Dataset.from_list(_many(n_test)),\n        }\n    )\n\n\n# ---------- dataset loading ----------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif DATA_PATH.exists():\n    spr = load_spr_bench(DATA_PATH)\n    print(\"Loaded SPR_BENCH from disk.\")\nelse:\n    spr = build_synthetic_dataset()\n    print(\"SPR_BENCH folder not found, using synthetic data.\")\n\n# ---------- vocabulary ----------\nPAD, UNK = \"<pad>\", \"<unk>\"\nvocab = {PAD: 0, UNK: 1}\nfor split in [\"train\", \"dev\", \"test\"]:\n    for seq in spr[split][\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\npad_idx = vocab[PAD]\n\n\n# ---------- encode function ----------\ndef encode_sequence(seq, max_len=40):\n    toks = seq.strip().split()[:max_len]\n    ids = [vocab.get(t, vocab[UNK]) for t in toks]\n    if len(ids) < max_len:\n        ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\n\nMAX_LEN = 40\n\n\n# ---------- PyTorch dataset ----------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_dataset):\n        self.data = hf_dataset\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        ids = torch.tensor(encode_sequence(row[\"sequence\"], MAX_LEN), dtype=torch.long)\n        label = torch.tensor(row[\"label\"], dtype=torch.long)\n        return {\"input_ids\": ids, \"labels\": label, \"sequence\": row[\"sequence\"]}\n\n\ndef collate_fn(batch):\n    input_ids = torch.stack([b[\"input_ids\"] for b in batch])\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    seqs = [b[\"sequence\"] for b in batch]\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequence\": seqs}\n\n\ntrain_loader = DataLoader(\n    SPRTorchDataset(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ---------- model ----------\nclass MeanEmbedClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n        self.fc = nn.Linear(embed_dim, num_classes)\n\n    def forward(self, x):\n        emb = self.embed(x)  # B,L,D\n        mask = (x != pad_idx).unsqueeze(-1).float()\n        summed = (emb * mask).sum(1)\n        denom = mask.sum(1).clamp(min=1e-6)\n        pooled = summed / denom\n        return self.fc(pooled)\n\n\nnum_labels = len(set(spr[\"train\"][\"label\"]))\nmodel = MeanEmbedClassifier(len(vocab), 128, num_labels).to(device)\n\n# ---------- optimizer & loss ----------\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n\n\n# ---------- augmentation (shape renaming) ----------\ndef shape_rename(seq):\n    toks = seq.strip().split()\n    shapes = list({t[0] for t in toks})\n    mapping = {s: random.choice(string.ascii_uppercase) for s in shapes}\n    new_toks = [mapping[t[0]] + t[1:] if len(t) > 1 else mapping[t[0]] for t in toks]\n    return \" \".join(new_toks)\n\n\n# ---------- metrics storage ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_loss\": [], \"val_loss\": [], \"val_ACS\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ---------- training loop ----------\nEPOCHS = 5\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    total_loss = 0.0\n    for batch in train_loader:\n        # optional on-the-fly augmentation 50% probability\n        seqs_aug = []\n        for s in batch[\"sequence\"]:\n            if random.random() < 0.5:\n                s = shape_rename(s)\n            seqs_aug.append(s)\n        input_ids = torch.stack(\n            [\n                torch.tensor(encode_sequence(s, MAX_LEN), dtype=torch.long)\n                for s in seqs_aug\n            ]\n        )\n        batch[\"input_ids\"] = input_ids\n\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"])\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    train_loss = total_loss / len(train_loader)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train_loss\"].append((epoch, train_loss))\n\n    # ----- validation -----\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch_t = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch_t[\"input_ids\"])\n            loss = criterion(logits, batch_t[\"labels\"])\n            val_loss += loss.item()\n            preds = logits.argmax(-1).cpu().tolist()\n            experiment_data[\"SPR_BENCH\"][\"predictions\"].extend(preds)\n            experiment_data[\"SPR_BENCH\"][\"ground_truth\"].extend(\n                batch[\"labels\"].cpu().tolist()\n            )\n    val_loss /= len(dev_loader)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_loss\"].append((epoch, val_loss))\n\n    # ----- ACS computation (subset for speed) -----\n    def compute_ACS(model, dataset, max_samples=1000, n_aug=5):\n        model.eval()\n        total = 0\n        consist_sum = 0.0\n        with torch.no_grad():\n            for i in range(min(len(dataset), max_samples)):\n                row = dataset[i]\n                base_seq = row[\"sequence\"]\n                label = row[\"label\"]\n                seq_variants = [base_seq] + [\n                    shape_rename(base_seq) for _ in range(n_aug)\n                ]\n                correct = 0\n                for sv in seq_variants:\n                    ids = (\n                        torch.tensor(encode_sequence(sv, MAX_LEN), dtype=torch.long)\n                        .unsqueeze(0)\n                        .to(device)\n                    )\n                    pred = model(ids).argmax(-1).item()\n                    if pred == label:\n                        correct += 1\n                consist_sum += correct / len(seq_variants)\n                total += 1\n        return consist_sum / total if total > 0 else 0.0\n\n    val_ACS = compute_ACS(model, spr[\"dev\"])\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_ACS\"].append((epoch, val_ACS))\n\n    print(\n        f\"Epoch {epoch}: train_loss = {train_loss:.4f} | validation_loss = {val_loss:.4f} | val_ACS = {val_ACS:.4f}\"\n    )\n\n# ---------- save experiment data ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, random, string, pathlib, time, math, json, copy, warnings\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import DatasetDict, load_dataset\n\n# ------------- reproducibility -------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# ------------- saving dict -------------\nexperiment_data = {\n    \"lr_sweep\": {}  # a sub-dict will be created for every learning-rate tried\n}\n\n# ------------- working dir -------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------- device -------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------- dataset utils -------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef build_synthetic_dataset(n_train=2000, n_dev=500, n_test=500, max_len=12):\n    def _gen_row():\n        length = random.randint(4, max_len)\n        seq, label = [], 0\n        for _ in range(length):\n            shape = random.choice(string.ascii_uppercase[:5])\n            color = random.choice(\"01234\")\n            seq.append(shape + color)\n            label ^= (ord(shape) + int(color)) & 1\n        return {\n            \"id\": str(random.randint(0, 1e9)),\n            \"sequence\": \" \".join(seq),\n            \"label\": int(label),\n        }\n\n    def _many(n):\n        return [_gen_row() for _ in range(n)]\n\n    from datasets import Dataset\n\n    return DatasetDict(\n        {\n            \"train\": Dataset.from_list(_many(n_train)),\n            \"dev\": Dataset.from_list(_many(n_dev)),\n            \"test\": Dataset.from_list(_many(n_test)),\n        }\n    )\n\n\n# ------------- obtain data -------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif DATA_PATH.exists():\n    spr = load_spr_bench(DATA_PATH)\n    print(\"Loaded SPR_BENCH from disk.\")\nelse:\n    spr = build_synthetic_dataset()\n    print(\"SPR_BENCH folder not found, using synthetic data.\")\n\n# ------------- vocab -------------\nPAD, UNK = \"<pad>\", \"<unk>\"\nvocab = {PAD: 0, UNK: 1}\nfor split in [\"train\", \"dev\", \"test\"]:\n    for seq in spr[split][\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\npad_idx = vocab[PAD]\n\nMAX_LEN = 40\n\n\ndef encode_sequence(seq, max_len=MAX_LEN):\n    toks = seq.strip().split()[:max_len]\n    ids = [vocab.get(t, vocab[UNK]) for t in toks]\n    ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\n\n# ------------- torch dataset -------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_dataset):\n        self.data = hf_dataset\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        ids = torch.tensor(encode_sequence(row[\"sequence\"]), dtype=torch.long)\n        label = torch.tensor(row[\"label\"], dtype=torch.long)\n        return {\"input_ids\": ids, \"labels\": label, \"sequence\": row[\"sequence\"]}\n\n\ndef collate_fn(batch):\n    return {\n        \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n        \"labels\": torch.stack([b[\"labels\"] for b in batch]),\n        \"sequence\": [b[\"sequence\"] for b in batch],\n    }\n\n\ntrain_loader_base = DataLoader(\n    SPRTorchDataset(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader_base = DataLoader(\n    SPRTorchDataset(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ------------- model -------------\nclass MeanEmbedClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n        self.fc = nn.Linear(embed_dim, num_classes)\n\n    def forward(self, x):\n        emb = self.embed(x)  # B,L,D\n        mask = (x != pad_idx).unsqueeze(-1).float()  # B,L,1\n        pooled = (emb * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n        return self.fc(pooled)\n\n\n# ------------- augmentation -------------\ndef shape_rename(seq):\n    toks = seq.strip().split()\n    shapes = list({t[0] for t in toks})\n    mapping = {s: random.choice(string.ascii_uppercase) for s in shapes}\n    new_toks = [mapping[t[0]] + t[1:] if len(t) > 1 else mapping[t[0]] for t in toks]\n    return \" \".join(new_toks)\n\n\ndef compute_ACS(model, dataset, max_samples=1000, n_aug=5):\n    model.eval()\n    consist_sum = 0.0\n    with torch.no_grad():\n        for i in range(min(len(dataset), max_samples)):\n            row = dataset[i]\n            base_seq, label = row[\"sequence\"], row[\"label\"]\n            seq_variants = [base_seq] + [shape_rename(base_seq) for _ in range(n_aug)]\n            correct = 0\n            for sv in seq_variants:\n                ids = (\n                    torch.tensor(encode_sequence(sv), dtype=torch.long)\n                    .unsqueeze(0)\n                    .to(device)\n                )\n                pred = model(ids).argmax(-1).item()\n                if pred == label:\n                    correct += 1\n            consist_sum += correct / len(seq_variants)\n    return consist_sum / min(len(dataset), max_samples)\n\n\n# ------------- hyperparam sweep -------------\nlearning_rates = [1e-4, 5e-4, 1e-3, 2e-3]\nEPOCHS = 5\nnum_labels = len(set(spr[\"train\"][\"label\"]))\n\nfor lr in learning_rates:\n    print(f\"\\n==== Training with learning_rate = {lr} ====\")\n    # copy data loaders to reset iterator each run\n    train_loader = train_loader_base\n    dev_loader = dev_loader_base\n\n    model = MeanEmbedClassifier(len(vocab), 128, num_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    lr_key = f\"lr_{lr:.0e}\" if lr < 1e-3 else f\"lr_{lr}\"\n    experiment_data[\"lr_sweep\"][lr_key] = {\n        \"metrics\": {\"train_loss\": [], \"val_loss\": [], \"val_ACS\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        # ---- train ----\n        model.train()\n        tot_loss = 0.0\n        for batch in train_loader:\n            # on-the-fly augmentation (50%)\n            seqs_aug = [\n                shape_rename(s) if random.random() < 0.5 else s\n                for s in batch[\"sequence\"]\n            ]\n            batch[\"input_ids\"] = torch.stack(\n                [torch.tensor(encode_sequence(s), dtype=torch.long) for s in seqs_aug]\n            )\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item()\n        train_loss = tot_loss / len(train_loader)\n        experiment_data[\"lr_sweep\"][lr_key][\"metrics\"][\"train_loss\"].append(\n            (epoch, train_loss)\n        )\n\n        # ---- validation ----\n        model.eval()\n        vloss, preds_all, gts_all = 0.0, [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                bt = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(bt[\"input_ids\"])\n                vloss += criterion(logits, bt[\"labels\"]).item()\n                preds_all.extend(logits.argmax(-1).cpu().tolist())\n                gts_all.extend(batch[\"labels\"].cpu().tolist())\n        vloss /= len(dev_loader)\n        experiment_data[\"lr_sweep\"][lr_key][\"metrics\"][\"val_loss\"].append(\n            (epoch, vloss)\n        )\n        experiment_data[\"lr_sweep\"][lr_key][\"predictions\"] = preds_all\n        experiment_data[\"lr_sweep\"][lr_key][\"ground_truth\"] = gts_all\n\n        # ---- ACS ----\n        val_ACS = compute_ACS(model, spr[\"dev\"])\n        experiment_data[\"lr_sweep\"][lr_key][\"metrics\"][\"val_ACS\"].append(\n            (epoch, val_ACS)\n        )\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={vloss:.4f} | val_ACS={val_ACS:.4f}\"\n        )\n\n# ------------- save -------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, random, string, pathlib, time, math, gc\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import DatasetDict\n\n# ---------- experiment dict ----------\nexperiment_data = {\n    \"batch_size\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},  # ACS etc.\n            \"losses\": {\"train\": [], \"val\": []},  # CE losses\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- helper : load dataset (provided util) ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    from datasets import load_dataset\n\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\n# ---------- synthetic fallback ----------\ndef build_synthetic_dataset(n_train=2000, n_dev=500, n_test=500, max_len=12):\n    def _gen_row():\n        length = random.randint(4, max_len)\n        seq, label = [], 0\n        for _ in range(length):\n            shape = random.choice(string.ascii_uppercase[:5])  # 5 shapes\n            color = random.choice(\"01234\")  # 5 colors\n            seq.append(shape + color)\n            label ^= (ord(shape) + int(color)) & 1  # parity rule\n        return {\n            \"id\": str(random.randint(0, 1e9)),\n            \"sequence\": \" \".join(seq),\n            \"label\": int(label),\n        }\n\n    def _many(n):\n        return [_gen_row() for _ in range(n)]\n\n    from datasets import Dataset\n\n    return DatasetDict(\n        {\n            \"train\": Dataset.from_list(_many(n_train)),\n            \"dev\": Dataset.from_list(_many(n_dev)),\n            \"test\": Dataset.from_list(_many(n_test)),\n        }\n    )\n\n\n# ---------- dataset loading ----------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif DATA_PATH.exists():\n    spr = load_spr_bench(DATA_PATH)\n    print(\"Loaded SPR_BENCH from disk.\")\nelse:\n    spr = build_synthetic_dataset()\n    print(\"SPR_BENCH folder not found, using synthetic data.\")\n\n# ---------- vocabulary ----------\nPAD, UNK = \"<pad>\", \"<unk>\"\nvocab = {PAD: 0, UNK: 1}\nfor split in [\"train\", \"dev\", \"test\"]:\n    for seq in spr[split][\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\npad_idx = vocab[PAD]\n\n\n# ---------- encode function ----------\ndef encode_sequence(seq, max_len=40):\n    toks = seq.strip().split()[:max_len]\n    ids = [vocab.get(t, vocab[UNK]) for t in toks]\n    if len(ids) < max_len:\n        ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\n\nMAX_LEN = 40\n\n\n# ---------- PyTorch dataset ----------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_dataset):\n        self.data = hf_dataset\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        ids = torch.tensor(encode_sequence(row[\"sequence\"], MAX_LEN), dtype=torch.long)\n        label = torch.tensor(row[\"label\"], dtype=torch.long)\n        return {\"input_ids\": ids, \"labels\": label, \"sequence\": row[\"sequence\"]}\n\n\ndef collate_fn(batch):\n    input_ids = torch.stack([b[\"input_ids\"] for b in batch])\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    seqs = [b[\"sequence\"] for b in batch]\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequence\": seqs}\n\n\n# ---------- model ----------\nclass MeanEmbedClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n        self.fc = nn.Linear(embed_dim, num_classes)\n\n    def forward(self, x):\n        emb = self.embed(x)  # B,L,D\n        mask = (x != pad_idx).unsqueeze(-1).float()\n        pooled = (emb * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n        return self.fc(pooled)\n\n\n# ---------- augmentation ----------\ndef shape_rename(seq):\n    toks = seq.strip().split()\n    shapes = list({t[0] for t in toks})\n    mapping = {s: random.choice(string.ascii_uppercase) for s in shapes}\n    return \" \".join(\n        [mapping[t[0]] + t[1:] if len(t) > 1 else mapping[t[0]] for t in toks]\n    )\n\n\n# ---------- ACS ----------\ndef compute_ACS(model, dataset, max_samples=1000, n_aug=5):\n    model.eval()\n    total, consist_sum = 0, 0.0\n    with torch.no_grad():\n        for i in range(min(len(dataset), max_samples)):\n            base_seq = dataset[i][\"sequence\"]\n            label = dataset[i][\"label\"]\n            seq_variants = [base_seq] + [shape_rename(base_seq) for _ in range(n_aug)]\n            correct = 0\n            for sv in seq_variants:\n                ids = (\n                    torch.tensor(encode_sequence(sv, MAX_LEN), dtype=torch.long)\n                    .unsqueeze(0)\n                    .to(device)\n                )\n                pred = model(ids).argmax(-1).item()\n                if pred == label:\n                    correct += 1\n            consist_sum += correct / len(seq_variants)\n            total += 1\n    return consist_sum / total if total else 0.0\n\n\n# ---------- hyperparameter search ----------\nbatch_sizes = [32, 64, 128, 256, 512]\nEPOCHS = 5\nnum_labels = len(set(spr[\"train\"][\"label\"]))\n\nfor bs in batch_sizes:\n    print(f\"\\n=== Training with batch_size={bs} ===\")\n    # loaders\n    train_loader = DataLoader(\n        SPRTorchDataset(spr[\"train\"]),\n        batch_size=bs,\n        shuffle=True,\n        collate_fn=collate_fn,\n    )\n    dev_loader = DataLoader(\n        SPRTorchDataset(spr[\"dev\"]),\n        batch_size=256,\n        shuffle=False,\n        collate_fn=collate_fn,\n    )\n    # model, opt\n    model = MeanEmbedClassifier(len(vocab), 128, num_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n\n    for epoch in range(1, EPOCHS + 1):\n        # ---- training ----\n        model.train()\n        total_loss = 0.0\n        for batch in train_loader:\n            # optional augmentation\n            seqs_aug = [\n                shape_rename(s) if random.random() < 0.5 else s\n                for s in batch[\"sequence\"]\n            ]\n            batch[\"input_ids\"] = torch.stack(\n                [\n                    torch.tensor(encode_sequence(s, MAX_LEN), dtype=torch.long)\n                    for s in seqs_aug\n                ]\n            )\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        train_loss = total_loss / len(train_loader)\n        experiment_data[\"batch_size\"][\"SPR_BENCH\"][\"losses\"][\"train\"].append(\n            (bs, epoch, train_loss)\n        )\n\n        # ---- validation ----\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch_t = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(batch_t[\"input_ids\"])\n                loss = criterion(logits, batch_t[\"labels\"])\n                val_loss += loss.item()\n                preds = logits.argmax(-1).cpu().tolist()\n                experiment_data[\"batch_size\"][\"SPR_BENCH\"][\"predictions\"].extend(\n                    [(bs, p) for p in preds]\n                )\n                experiment_data[\"batch_size\"][\"SPR_BENCH\"][\"ground_truth\"].extend(\n                    batch[\"labels\"].cpu().tolist()\n                )\n        val_loss /= len(dev_loader)\n        experiment_data[\"batch_size\"][\"SPR_BENCH\"][\"losses\"][\"val\"].append(\n            (bs, epoch, val_loss)\n        )\n\n        # ---- ACS ----\n        val_ACS = compute_ACS(model, spr[\"dev\"])\n        experiment_data[\"batch_size\"][\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n            (bs, epoch, val_ACS)\n        )\n\n        print(\n            f\"[bs={bs}] Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | val_ACS={val_ACS:.4f}\"\n        )\n\n    # clean up GPU memory for next run\n    del model, optimizer, train_loader, dev_loader\n    torch.cuda.empty_cache()\n    gc.collect()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "# hyperparam-tuning : embed_dim\nimport os, random, string, pathlib, math, time\nimport numpy as np, torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import DatasetDict, Dataset, load_dataset\n\n# ---------- misc ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n\n# ---------- load or build dataset ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef build_synthetic_dataset(n_train=2000, n_dev=500, n_test=500, max_len=12):\n    def _gen_row():\n        l = random.randint(4, max_len)\n        seq = []\n        label = 0\n        for _ in range(l):\n            sh = random.choice(string.ascii_uppercase[:5])\n            co = random.choice(\"01234\")\n            seq.append(sh + co)\n            label ^= (ord(sh) + int(co)) & 1\n        return {\n            \"id\": str(random.randint(0, 1e9)),\n            \"sequence\": \" \".join(seq),\n            \"label\": label,\n        }\n\n    def _many(n):\n        return [_gen_row() for _ in range(n)]\n\n    return DatasetDict(\n        train=Dataset.from_list(_many(n_train)),\n        dev=Dataset.from_list(_many(n_dev)),\n        test=Dataset.from_list(_many(n_test)),\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH) if DATA_PATH.exists() else build_synthetic_dataset()\nprint(\"Dataset size:\", {k: len(v) for k, v in spr.items()})\n\n# ---------- vocabulary ----------\nPAD, UNK = \"<pad>\", \"<unk>\"\nvocab = {PAD: 0, UNK: 1}\nfor split in [\"train\", \"dev\", \"test\"]:\n    for seq in spr[split][\"sequence\"]:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\npad_idx = len(vocab) if PAD not in vocab else vocab[PAD]  # ensure pad in vocab\npad_idx = vocab[PAD]\n\n# ---------- helpers ----------\nMAX_LEN = 40\n\n\ndef encode_sequence(seq, max_len=MAX_LEN):\n    ids = [vocab.get(t, vocab[UNK]) for t in seq.strip().split()[:max_len]]\n    ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\n\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_dataset):\n        self.data = hf_dataset\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        return {\n            \"input_ids\": torch.tensor(\n                encode_sequence(row[\"sequence\"]), dtype=torch.long\n            ),\n            \"labels\": torch.tensor(row[\"label\"], dtype=torch.long),\n            \"sequence\": row[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    return {\n        \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n        \"labels\": torch.stack([b[\"labels\"] for b in batch]),\n        \"sequence\": [b[\"sequence\"] for b in batch],\n    }\n\n\ndef shape_rename(seq):\n    toks = seq.split()\n    shapes = list({t[0] for t in toks})\n    mapping = {s: random.choice(string.ascii_uppercase) for s in shapes}\n    return \" \".join([mapping[t[0]] + t[1:] for t in toks])\n\n\n# ---------- model ----------\nclass MeanEmbedClassifier(nn.Module):\n    def __init__(self, vocab_sz, embed_dim, num_cls):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, embed_dim, padding_idx=pad_idx)\n        self.fc = nn.Linear(embed_dim, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)  # B,L,D\n        mask = (x != pad_idx).unsqueeze(-1).float()  # B,L,1\n        pooled = (emb * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n        return self.fc(pooled)\n\n\n# ---------- experiment store ----------\nexperiment_data = {\"embed_dim_tuning\": {}}\n\n# ---------- sweep ----------\nembed_dims = [64, 128, 256]\nEPOCHS = 5\nfor dim in embed_dims:\n    print(f\"\\n=== Training embed_dim={dim} ===\")\n    train_loader = DataLoader(\n        SPRTorchDataset(spr[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_fn,\n    )\n    dev_loader = DataLoader(\n        SPRTorchDataset(spr[\"dev\"]),\n        batch_size=256,\n        shuffle=False,\n        collate_fn=collate_fn,\n    )\n\n    model = MeanEmbedClassifier(len(vocab), dim, len(set(spr[\"train\"][\"label\"]))).to(\n        device\n    )\n    opt = torch.optim.Adam(model.parameters(), lr=3e-3)\n    crit = nn.CrossEntropyLoss()\n\n    run_store = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for epoch in range(1, EPOCHS + 1):\n        # ----- train -----\n        model.train()\n        total_loss = 0.0\n        for batch in train_loader:\n            # augment 50%\n            seq_aug = [\n                shape_rename(s) if random.random() < 0.5 else s\n                for s in batch[\"sequence\"]\n            ]\n            input_ids = torch.stack(\n                [torch.tensor(encode_sequence(s), dtype=torch.long) for s in seq_aug]\n            )\n            batch[\"input_ids\"] = input_ids\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            opt.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = crit(logits, batch[\"labels\"])\n            loss.backward()\n            opt.step()\n            total_loss += loss.item()\n        train_loss = total_loss / len(train_loader)\n\n        # ----- validation -----\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for batch in dev_loader:\n                b = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(b[\"input_ids\"])\n                val_loss += crit(logits, b[\"labels\"]).item()\n                preds = logits.argmax(-1).cpu().tolist()\n                run_store[\"predictions\"].extend(preds)\n                run_store[\"ground_truth\"].extend(batch[\"labels\"].tolist())\n        val_loss /= len(dev_loader)\n\n        # ----- ACS -----\n        def compute_ACS(model, dataset, max_samples=1000, n_aug=5):\n            model.eval()\n            tot = cons = 0.0\n            with torch.no_grad():\n                for i in range(min(len(dataset), max_samples)):\n                    row = dataset[i]\n                    base = row[\"sequence\"]\n                    label = row[\"label\"]\n                    variants = [base] + [shape_rename(base) for _ in range(n_aug)]\n                    corr = sum(\n                        model(\n                            torch.tensor(encode_sequence(v), dtype=torch.long)\n                            .unsqueeze(0)\n                            .to(device)\n                        )\n                        .argmax(-1)\n                        .item()\n                        == label\n                        for v in variants\n                    )\n                    cons += corr / len(variants)\n                    tot += 1\n            return cons / tot if tot else 0.0\n\n        val_ACS = compute_ACS(model, spr[\"dev\"])\n\n        run_store[\"losses\"][\"train\"].append((epoch, train_loss))\n        run_store[\"losses\"][\"val\"].append((epoch, val_loss))\n        run_store[\"metrics\"][\"train\"].append((epoch, float(\"nan\")))  # no train metric\n        run_store[\"metrics\"][\"val\"].append((epoch, val_ACS))\n        print(\n            f\"epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"val_ACS={val_ACS:.4f}\"\n        )\n\n    experiment_data[\"embed_dim_tuning\"][f\"embed_{dim}\"] = run_store\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, random, string, pathlib, math, time\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import DatasetDict\n\n# --------------------------- experiment data dict ---------------------------\nexperiment_data = {\n    \"weight_decay\": {  # <- hyperparam tuning type\n        # each key added later: str(weight_decay)\n    }\n}\n\n# --------------------------- working dir & device ---------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# --------------------------- load or build dataset --------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    from datasets import load_dataset\n\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef build_synthetic_dataset(n_train=2000, n_dev=500, n_test=500, max_len=12):\n    def _row():\n        length = random.randint(4, max_len)\n        label, seq = 0, []\n        for _ in range(length):\n            shape, color = random.choice(string.ascii_uppercase[:5]), random.choice(\n                \"01234\"\n            )\n            seq.append(shape + color)\n            label ^= (ord(shape) + int(color)) & 1\n        return {\n            \"id\": str(random.randint(0, 1e9)),\n            \"sequence\": \" \".join(seq),\n            \"label\": int(label),\n        }\n\n    from datasets import Dataset\n\n    return DatasetDict(\n        {\n            \"train\": Dataset.from_list([_row() for _ in range(n_train)]),\n            \"dev\": Dataset.from_list([_row() for _ in range(n_dev)]),\n            \"test\": Dataset.from_list([_row() for _ in range(n_test)]),\n        }\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH) if DATA_PATH.exists() else build_synthetic_dataset()\nprint(\"Dataset sizes:\", {k: len(v) for k, v in spr.items()})\n\n# --------------------------- vocabulary & encoding --------------------------\nPAD, UNK = \"<pad>\", \"<unk>\"\nvocab = {PAD: 0, UNK: 1}\nfor split in [\"train\", \"dev\", \"test\"]:\n    for seq in spr[split][\"sequence\"]:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\npad_idx, MAX_LEN = vocab[PAD], 40\n\n\ndef encode_sequence(seq, max_len=MAX_LEN):\n    ids = [vocab.get(t, vocab[UNK]) for t in seq.strip().split()[:max_len]]\n    ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\n\n# --------------------------- torch dataset ----------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.ds = hf_ds\n\n    def __len__(self):\n        return len(self.ds)\n\n    def __getitem__(self, i):\n        row = self.ds[i]\n        return {\n            \"input_ids\": torch.tensor(\n                encode_sequence(row[\"sequence\"]), dtype=torch.long\n            ),\n            \"labels\": torch.tensor(row[\"label\"], dtype=torch.long),\n            \"sequence\": row[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    return {\n        \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n        \"labels\": torch.stack([b[\"labels\"] for b in batch]),\n        \"sequence\": [b[\"sequence\"] for b in batch],\n    }\n\n\n# --------------------------- model ------------------------------------------\nclass MeanEmbedClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n        self.fc = nn.Linear(embed_dim, num_classes)\n\n    def forward(self, x):\n        emb = self.embed(x)  # B,L,D\n        mask = (x != pad_idx).unsqueeze(-1).float()  # B,L,1\n        pooled = (emb * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n        return self.fc(pooled)\n\n\n# --------------------------- augmentation helper ----------------------------\ndef shape_rename(seq):\n    toks = seq.split()\n    shapes = list({t[0] for t in toks})\n    mapping = {s: random.choice(string.ascii_uppercase) for s in shapes}\n    new_toks = [mapping[t[0]] + t[1:] for t in toks]\n    return \" \".join(new_toks)\n\n\n# --------------------------- ACS metric -------------------------------------\n@torch.no_grad()\ndef compute_ACS(model, dataset, max_samples=500, n_aug=5):\n    model.eval()\n    total, consist = 0, 0.0\n    for i in range(min(len(dataset), max_samples)):\n        base = dataset[i][\"sequence\"]\n        label = dataset[i][\"label\"]\n        variants = [base] + [shape_rename(base) for _ in range(n_aug)]\n        correct = sum(\n            model(\n                torch.tensor(\n                    encode_sequence(v), dtype=torch.long, device=device\n                ).unsqueeze(0)\n            )\n            .argmax(-1)\n            .item()\n            == label\n            for v in variants\n        )\n        consist += correct / len(variants)\n        total += 1\n    return consist / total if total else 0.0\n\n\n# --------------------------- training loop with grid search -----------------\nweight_decays = [0.0, 1e-5, 1e-4, 5e-4, 1e-3]\nEPOCHS = 5\nbatch_size_tr, batch_size_val = 128, 256\ncriterion = nn.CrossEntropyLoss()\n\nfor wd in weight_decays:\n    print(f\"\\n=== Training with weight_decay = {wd} ===\")\n    key = str(wd)\n    experiment_data[\"weight_decay\"][key] = {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_loss\": [], \"val_loss\": [], \"val_ACS\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n    # data loaders re-constructed each run (for shuffling independence)\n    train_loader = DataLoader(\n        SPRTorchDataset(spr[\"train\"]),\n        batch_size=batch_size_tr,\n        shuffle=True,\n        collate_fn=collate_fn,\n    )\n    dev_loader = DataLoader(\n        SPRTorchDataset(spr[\"dev\"]),\n        batch_size=batch_size_val,\n        shuffle=False,\n        collate_fn=collate_fn,\n    )\n\n    model = MeanEmbedClassifier(len(vocab), 128, len(set(spr[\"train\"][\"label\"]))).to(\n        device\n    )\n    optimizer = torch.optim.Adam(model.parameters(), lr=3e-3, weight_decay=wd)\n\n    for epoch in range(1, EPOCHS + 1):\n        # ---- train ----\n        model.train()\n        total_loss = 0.0\n        for batch in train_loader:\n            # on-the-fly 50% augmentation\n            seq_aug = [\n                shape_rename(s) if random.random() < 0.5 else s\n                for s in batch[\"sequence\"]\n            ]\n            batch[\"input_ids\"] = torch.stack(\n                [torch.tensor(encode_sequence(s), dtype=torch.long) for s in seq_aug]\n            )\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        train_loss = total_loss / len(train_loader)\n        experiment_data[\"weight_decay\"][key][\"SPR_BENCH\"][\"metrics\"][\n            \"train_loss\"\n        ].append((epoch, train_loss))\n\n        # ---- validation ----\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for batch in dev_loader:\n                bt = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(bt[\"input_ids\"])\n                loss = criterion(logits, bt[\"labels\"])\n                val_loss += loss.item()\n                experiment_data[\"weight_decay\"][key][\"SPR_BENCH\"][\"predictions\"].extend(\n                    logits.argmax(-1).cpu().tolist()\n                )\n                experiment_data[\"weight_decay\"][key][\"SPR_BENCH\"][\n                    \"ground_truth\"\n                ].extend(batch[\"labels\"].cpu().tolist())\n        val_loss /= len(dev_loader)\n        experiment_data[\"weight_decay\"][key][\"SPR_BENCH\"][\"metrics\"][\"val_loss\"].append(\n            (epoch, val_loss)\n        )\n\n        val_ACS = compute_ACS(model, spr[\"dev\"])\n        experiment_data[\"weight_decay\"][key][\"SPR_BENCH\"][\"metrics\"][\"val_ACS\"].append(\n            (epoch, val_ACS)\n        )\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | val_ACS={val_ACS:.4f}\"\n        )\n\n# --------------------------- save everything --------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved metrics to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# --------------------------------------------------\n# Hyper-parameter sweep : aug_probability\n# --------------------------------------------------\nimport os, random, string, pathlib, math, time\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import DatasetDict, load_dataset\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- helper : load SPR-BENCH (or synthetic) ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef build_synthetic_dataset(n_train=2000, n_dev=500, n_test=500, max_len=12):\n    def _gen_row():\n        length = random.randint(4, max_len)\n        seq, label = [], 0\n        for _ in range(length):\n            shape = random.choice(string.ascii_uppercase[:5])  # 5 shapes\n            color = random.choice(\"01234\")  # 5 colors\n            seq.append(shape + color)\n            label ^= (ord(shape) + int(color)) & 1  # parity rule\n        return {\n            \"id\": str(random.randint(0, 1e9)),\n            \"sequence\": \" \".join(seq),\n            \"label\": int(label),\n        }\n\n    def _many(n):\n        return [_gen_row() for _ in range(n)]\n\n    from datasets import Dataset\n\n    return DatasetDict(\n        {\n            \"train\": Dataset.from_list(_many(n_train)),\n            \"dev\": Dataset.from_list(_many(n_dev)),\n            \"test\": Dataset.from_list(_many(n_test)),\n        }\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nif DATA_PATH.exists():\n    spr = load_spr_bench(DATA_PATH)\n    print(\"Loaded SPR_BENCH from disk.\")\nelse:\n    spr = build_synthetic_dataset()\n    print(\"SPR_BENCH folder not found, using synthetic data.\")\n\n# ---------- vocabulary ----------\nPAD, UNK = \"<pad>\", \"<unk>\"\nvocab = {PAD: 0, UNK: 1}\nfor split in [\"train\", \"dev\", \"test\"]:\n    for seq in spr[split][\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\npad_idx = vocab[PAD]\n\n# ---------- encode ----------\nMAX_LEN = 40\n\n\ndef encode_sequence(seq, max_len=MAX_LEN):\n    ids = [vocab.get(t, vocab[UNK]) for t in seq.strip().split()[:max_len]]\n    ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\n\n# ---------- torch dataset ----------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_dataset):\n        self.data = hf_dataset\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        return {\n            \"input_ids\": torch.tensor(\n                encode_sequence(row[\"sequence\"]), dtype=torch.long\n            ),\n            \"labels\": torch.tensor(row[\"label\"], dtype=torch.long),\n            \"sequence\": row[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    return {\n        \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n        \"labels\": torch.stack([b[\"labels\"] for b in batch]),\n        \"sequence\": [b[\"sequence\"] for b in batch],\n    }\n\n\ntrain_loader_base = DataLoader(\n    SPRTorchDataset(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ---------- model ----------\nclass MeanEmbedClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n        self.fc = nn.Linear(embed_dim, num_classes)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        mask = (x != pad_idx).unsqueeze(-1).float()\n        pooled = (emb * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n        return self.fc(pooled)\n\n\n# ---------- augmentation ----------\ndef shape_rename(seq):\n    toks = seq.strip().split()\n    shapes = list({t[0] for t in toks})\n    mapping = {s: random.choice(string.ascii_uppercase) for s in shapes}\n    new_toks = [mapping[t[0]] + t[1:] if len(t) > 1 else mapping[t[0]] for t in toks]\n    return \" \".join(new_toks)\n\n\n# ---------- ACS metric ----------\n@torch.no_grad()\ndef compute_ACS(model, dataset, max_samples=500, n_aug=5):\n    model.eval()\n    total, consist = 0, 0.0\n    for i in range(min(len(dataset), max_samples)):\n        row = dataset[i]\n        variants = [row[\"sequence\"]] + [\n            shape_rename(row[\"sequence\"]) for _ in range(n_aug)\n        ]\n        correct = 0\n        for sv in variants:\n            ids = (\n                torch.tensor(encode_sequence(sv), dtype=torch.long)\n                .unsqueeze(0)\n                .to(device)\n            )\n            if model(ids).argmax(-1).item() == row[\"label\"]:\n                correct += 1\n        consist += correct / len(variants)\n        total += 1\n    return consist / total if total else 0.0\n\n\n# ---------- experiment data ----------\nexperiment_data = {\"aug_probability\": {\"SPR_BENCH\": {}}}\n\n# ---------- training & sweep ----------\nprob_list = [0.0, 0.25, 0.5, 0.75, 1.0]\nEPOCHS = 5\nnum_labels = len(set(spr[\"train\"][\"label\"]))\n\nfor prob in prob_list:\n    print(f\"\\n=== Training with aug_probability = {prob} ===\")\n    model = MeanEmbedClassifier(len(vocab), 128, num_labels).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n    criterion = nn.CrossEntropyLoss()\n\n    # record containers\n    run_dict = {\n        \"train_loss\": [],\n        \"val_loss\": [],\n        \"val_ACS\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    # (need independent train loader each run because shuffle state)\n    train_loader = DataLoader(\n        SPRTorchDataset(spr[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_fn,\n    )\n\n    for epoch in range(1, EPOCHS + 1):\n        model.train()\n        tot_loss = 0.0\n        for batch in train_loader:\n            # apply augmentation with given probability\n            seqs_aug = [\n                shape_rename(s) if random.random() < prob else s\n                for s in batch[\"sequence\"]\n            ]\n            batch[\"input_ids\"] = torch.stack(\n                [torch.tensor(encode_sequence(s), dtype=torch.long) for s in seqs_aug]\n            )\n            # move to device\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch_t[\"input_ids\"])\n            loss = criterion(logits, batch_t[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item()\n        train_loss = tot_loss / len(train_loader)\n\n        # validation\n        model.eval()\n        val_loss, preds, gts = 0.0, [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch_t = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(batch_t[\"input_ids\"])\n                val_loss += criterion(logits, batch_t[\"labels\"]).item()\n                preds.extend(logits.argmax(-1).cpu().tolist())\n                gts.extend(batch[\"labels\"].cpu().tolist())\n        val_loss /= len(dev_loader)\n        val_ACS = compute_ACS(model, spr[\"dev\"])\n\n        run_dict[\"train_loss\"].append((epoch, train_loss))\n        run_dict[\"val_loss\"].append((epoch, val_loss))\n        run_dict[\"val_ACS\"].append((epoch, val_ACS))\n\n        print(\n            f\"Epoch {epoch} | train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | ACS {val_ACS:.4f}\"\n        )\n\n    run_dict[\"predictions\"] = preds\n    run_dict[\"ground_truth\"] = gts\n    experiment_data[\"aug_probability\"][\"SPR_BENCH\"][prob] = run_dict\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy with all sweep results.\")\n", "import os, random, string, pathlib, time\nimport numpy as np, torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset as TorchDataset\nfrom datasets import load_dataset, DatasetDict, Dataset as HFDataset\n\n# -------------------------------------------------------\n# basic setup & reproducibility\n# -------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n\n# -------------------------------------------------------\n# data loading helpers\n# -------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef build_synthetic_dataset(n_train=2000, n_dev=500, n_test=500, max_len=12):\n    def _gen_row():\n        l = random.randint(4, max_len)\n        seq, label = [], 0\n        for _ in range(l):\n            sh = random.choice(string.ascii_uppercase[:5])\n            co = random.choice(\"01234\")\n            seq.append(sh + co)\n            label ^= (ord(sh) + int(co)) & 1\n        return {\n            \"id\": str(random.randint(0, 1e9)),\n            \"sequence\": \" \".join(seq),\n            \"label\": label,\n        }\n\n    def _many(n):\n        return [_gen_row() for _ in range(n)]\n\n    return DatasetDict(\n        train=HFDataset.from_list(_many(n_train)),\n        dev=HFDataset.from_list(_many(n_dev)),\n        test=HFDataset.from_list(_many(n_test)),\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH) if DATA_PATH.exists() else build_synthetic_dataset()\nprint(\"Loaded dataset sizes ->\", {k: len(v) for k, v in spr.items()})\n\n# -------------------------------------------------------\n# vocabulary\n# -------------------------------------------------------\nPAD, UNK = \"<pad>\", \"<unk>\"\nvocab = {PAD: 0, UNK: 1}\nfor split in [\"train\", \"dev\", \"test\"]:\n    for seq in spr[split][\"sequence\"]:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\npad_idx = vocab[PAD]\nMAX_LEN = 40\n\n\ndef encode_sequence(seq: str, max_len: int = MAX_LEN):\n    ids = [vocab.get(t, vocab[UNK]) for t in seq.strip().split()[:max_len]]\n    ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\n\n# -------------------------------------------------------\n# metrics\n# -------------------------------------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(token[0] for token in sequence.strip().split() if token))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(token[1] for token in sequence.strip().split() if len(token) > 1))\n\n\ndef shape_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(1, sum(weights))\n\n\ndef color_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_color_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(1, sum(weights))\n\n\ndef composite_weighted_accuracy(sequences, y_true, y_pred):\n    return 0.5 * (\n        shape_weighted_accuracy(sequences, y_true, y_pred)\n        + color_weighted_accuracy(sequences, y_true, y_pred)\n    )\n\n\n# -------------------------------------------------------\n# torch dataset wrapper\n# -------------------------------------------------------\nclass SPRTorchDataset(TorchDataset):\n    def __init__(self, hf_ds: HFDataset):\n        self.hf_ds = hf_ds\n\n    def __len__(self):\n        return len(self.hf_ds)\n\n    def __getitem__(self, idx):\n        row = self.hf_ds[idx]\n        return {\n            \"input_ids\": torch.tensor(\n                encode_sequence(row[\"sequence\"]), dtype=torch.long\n            ),\n            \"labels\": torch.tensor(row[\"label\"], dtype=torch.long),\n            \"sequence\": row[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    return {\n        \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n        \"labels\": torch.stack([b[\"labels\"] for b in batch]),\n        \"sequence\": [b[\"sequence\"] for b in batch],\n    }\n\n\ndef shape_rename(seq: str):\n    toks = seq.split()\n    shapes = list({t[0] for t in toks})\n    mapping = {s: random.choice(string.ascii_uppercase) for s in shapes}\n    return \" \".join([mapping[t[0]] + t[1:] for t in toks])\n\n\n# -------------------------------------------------------\n# model\n# -------------------------------------------------------\nclass MeanEmbedClassifier(nn.Module):\n    def __init__(self, vocab_sz: int, embed_dim: int, num_cls: int):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, embed_dim, padding_idx=pad_idx)\n        self.fc = nn.Linear(embed_dim, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)  # B,L,D\n        mask = (x != pad_idx).unsqueeze(-1).float()\n        pooled = (emb * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n        return self.fc(pooled)\n\n\n# -------------------------------------------------------\n# experiment store\n# -------------------------------------------------------\nexperiment_data = {\"embed_dim_sweep\": {}}\n\n# -------------------------------------------------------\n# training loop\n# -------------------------------------------------------\nembed_dims = [64, 128, 256]\nEPOCHS = 5\nBATCH_SZ = 128\n\nfor dim in embed_dims:\n    print(f\"\\n===== Training embed_dim={dim} =====\")\n    train_loader = DataLoader(\n        SPRTorchDataset(spr[\"train\"]),\n        batch_size=BATCH_SZ,\n        shuffle=True,\n        collate_fn=collate_fn,\n    )\n    dev_loader = DataLoader(\n        SPRTorchDataset(spr[\"dev\"]),\n        batch_size=256,\n        shuffle=False,\n        collate_fn=collate_fn,\n    )\n\n    model = MeanEmbedClassifier(len(vocab), dim, len(set(spr[\"train\"][\"label\"]))).to(\n        device\n    )\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n\n    run_store = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"CoWA_train\": [], \"CoWA_val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        # ---------- training ----------\n        model.train()\n        t0 = time.time()\n        train_loss_total = 0.0\n        for batch in train_loader:\n            # on-the-fly augmentation (50% chance per sequence)\n            aug_sequences = [\n                shape_rename(s) if random.random() < 0.5 else s\n                for s in batch[\"sequence\"]\n            ]\n            batch[\"input_ids\"] = torch.stack(\n                [\n                    torch.tensor(encode_sequence(s), dtype=torch.long)\n                    for s in aug_sequences\n                ]\n            )\n            # move tensors to device\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            train_loss_total += loss.item()\n\n        train_loss = train_loss_total / len(train_loader)\n\n        # ---------- evaluation ----------\n        model.eval()\n        val_loss_total = 0.0\n        val_sequences, val_true, val_pred = [], [], []\n        train_sequences, train_true, train_pred = [], [], []\n\n        # compute train metrics on one random mini-batch (cheap)\n        with torch.no_grad():\n            sample_batch = next(iter(train_loader))\n            sample_batch_t = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in sample_batch.items()\n            }\n            logits = model(sample_batch_t[\"input_ids\"])\n            preds = logits.argmax(-1).cpu().tolist()\n            train_sequences.extend(sample_batch[\"sequence\"])\n            train_true.extend(sample_batch[\"labels\"].tolist())\n            train_pred.extend(preds)\n\n        # full dev set\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch_t = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch_t[\"input_ids\"])\n                val_loss_total += criterion(logits, batch_t[\"labels\"]).item()\n                preds = logits.argmax(-1).cpu().tolist()\n\n                val_sequences.extend(batch[\"sequence\"])\n                val_true.extend(batch[\"labels\"].tolist())\n                val_pred.extend(preds)\n\n        val_loss = val_loss_total / len(dev_loader)\n\n        # metrics\n        CoWA_train = composite_weighted_accuracy(\n            train_sequences, train_true, train_pred\n        )\n        CoWA_val = composite_weighted_accuracy(val_sequences, val_true, val_pred)\n\n        run_store[\"losses\"][\"train\"].append((epoch, train_loss))\n        run_store[\"losses\"][\"val\"].append((epoch, val_loss))\n        run_store[\"metrics\"][\"CoWA_train\"].append((epoch, CoWA_train))\n        run_store[\"metrics\"][\"CoWA_val\"].append((epoch, CoWA_val))\n        run_store[\"predictions\"].append((epoch, val_pred))\n        run_store[\"ground_truth\"].append((epoch, val_true))\n\n        print(\n            f\"Epoch {epoch:02d} | \"\n            f\"train_loss={train_loss:.4f}  val_loss={val_loss:.4f} | \"\n            f\"CoWA_train={CoWA_train:.4f}  CoWA_val={CoWA_val:.4f} | \"\n            f\"time={(time.time()-t0):.1f}s\"\n        )\n\n    experiment_data[\"embed_dim_sweep\"][f\"emb_{dim}\"] = run_store\n\n# -------------------------------------------------------\n# save experiment data\n# -------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, random, string, pathlib, math, time, json\nimport numpy as np, torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset as TorchDataset\nfrom datasets import Dataset as HFDataset, DatasetDict, load_dataset\n\n# ------------------------------ house-keeping ------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n\n# ------------------------------ data utils ---------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"),\n        dev=_load(\"dev.csv\"),\n        test=_load(\"test.csv\"),\n    )\n\n\ndef build_synthetic_dataset(n_train=2000, n_dev=500, n_test=500, max_len=12):\n    def _gen_row():\n        l = random.randint(4, max_len)\n        seq, label = [], 0\n        for _ in range(l):\n            sh, co = random.choice(string.ascii_uppercase[:5]), random.choice(\"01234\")\n            seq.append(sh + co)\n            label ^= (ord(sh) + int(co)) & 1\n        return {\n            \"id\": str(random.randint(0, 1e9)),\n            \"sequence\": \" \".join(seq),\n            \"label\": label,\n        }\n\n    def _many(n):\n        return [_gen_row() for _ in range(n)]\n\n    return DatasetDict(\n        train=HFDataset.from_list(_many(n_train)),\n        dev=HFDataset.from_list(_many(n_dev)),\n        test=HFDataset.from_list(_many(n_test)),\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH) if DATA_PATH.exists() else build_synthetic_dataset()\nprint(\"Dataset size:\", {k: len(v) for k, v in spr.items()})\n\n# ------------------------------ vocabulary ---------------------------------\nPAD, UNK = \"<pad>\", \"<unk>\"\nvocab = {PAD: 0, UNK: 1}\nfor split in [\"train\", \"dev\", \"test\"]:\n    for seq in spr[split][\"sequence\"]:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\npad_idx = vocab[PAD]\n\nMAX_LEN = 40\n\n\ndef encode_sequence(seq, max_len=MAX_LEN):\n    ids = [vocab.get(t, vocab[UNK]) for t in seq.strip().split()[:max_len]]\n    ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\n\n# ------------------------------ metrics ------------------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(token[0] for token in sequence.strip().split() if token))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(token[1] for token in sequence.strip().split() if len(token) > 1))\n\n\ndef shape_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\ndef color_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_color_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ------------------------------ dataset wrappers ---------------------------\nclass SPRTorchDataset(TorchDataset):\n    def __init__(self, hf_dataset: HFDataset):\n        self.ds = hf_dataset\n\n    def __len__(self):\n        return len(self.ds)\n\n    def __getitem__(self, idx):\n        row = self.ds[idx]\n        return {\n            \"sequence\": row[\"sequence\"],\n            \"input_ids\": torch.tensor(\n                encode_sequence(row[\"sequence\"]), dtype=torch.long\n            ),\n            \"labels\": torch.tensor(row[\"label\"], dtype=torch.long),\n        }\n\n\ndef collate_fn(batch):\n    return {\n        \"sequence\": [b[\"sequence\"] for b in batch],\n        \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n        \"labels\": torch.stack([b[\"labels\"] for b in batch]),\n    }\n\n\ndef shape_rename(seq):\n    toks = seq.split()\n    shapes = list({t[0] for t in toks})\n    mapping = {s: random.choice(string.ascii_uppercase) for s in shapes}\n    return \" \".join([mapping[t[0]] + t[1:] for t in toks])\n\n\n# ------------------------------ model --------------------------------------\nclass MeanEmbedClassifier(nn.Module):\n    def __init__(self, vocab_sz, embed_dim, num_cls):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, embed_dim, padding_idx=pad_idx)\n        self.fc = nn.Linear(embed_dim, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)  # B,L,D\n        mask = (x != pad_idx).unsqueeze(-1).float()  # B,L,1\n        pooled = (emb * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n        return self.fc(pooled)\n\n\n# ------------------------------ experiment store ---------------------------\nexperiment_data = {\"embed_dim_tuning\": {}}\n\n# ------------------------------ sweep --------------------------------------\nembed_dims = [64, 128, 256]\nEPOCHS = 5\n\nfor dim in embed_dims:\n    print(f\"\\n=== Training embed_dim={dim} ===\")\n    train_loader = DataLoader(\n        SPRTorchDataset(spr[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_fn,\n    )\n    dev_loader = DataLoader(\n        SPRTorchDataset(spr[\"dev\"]),\n        batch_size=256,\n        shuffle=False,\n        collate_fn=collate_fn,\n    )\n\n    model = MeanEmbedClassifier(len(vocab), dim, len(set(spr[\"train\"][\"label\"]))).to(\n        device\n    )\n    opt = torch.optim.Adam(model.parameters(), lr=3e-3)\n    crit = nn.CrossEntropyLoss()\n\n    run_store = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"CoWA\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        # -------------------- train --------------------\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            # 50 % augmentation\n            seq_aug = [\n                shape_rename(s) if random.random() < 0.5 else s\n                for s in batch[\"sequence\"]\n            ]\n            batch[\"input_ids\"] = torch.stack(\n                [torch.tensor(encode_sequence(s), dtype=torch.long) for s in seq_aug]\n            )\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            opt.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = crit(logits, batch[\"labels\"])\n            loss.backward()\n            opt.step()\n            running_loss += loss.item()\n        train_loss = running_loss / len(train_loader)\n        run_store[\"losses\"][\"train\"].append((epoch, train_loss))\n\n        # -------------------- validation ----------------\n        model.eval()\n        val_loss, seqs, gts, preds = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch_cuda = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch_cuda[\"input_ids\"])\n                val_loss += crit(logits, batch_cuda[\"labels\"]).item()\n                p = logits.argmax(-1).cpu().tolist()\n                preds.extend(p)\n                gts.extend(batch[\"labels\"].tolist())\n                seqs.extend(batch[\"sequence\"])\n        val_loss /= len(dev_loader)\n        SWA = shape_weighted_accuracy(seqs, gts, preds)\n        CWA = color_weighted_accuracy(seqs, gts, preds)\n        CoWA = (SWA + CWA) / 2\n\n        run_store[\"losses\"][\"val\"].append((epoch, val_loss))\n        run_store[\"metrics\"][\"SWA\"].append((epoch, SWA))\n        run_store[\"metrics\"][\"CWA\"].append((epoch, CWA))\n        run_store[\"metrics\"][\"CoWA\"].append((epoch, CoWA))\n        run_store[\"predictions\"].append((epoch, preds))\n        run_store[\"ground_truth\"].append((epoch, gts))\n\n        print(\n            f\"epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"SWA={SWA:.4f} CWA={CWA:.4f} CoWA={CoWA:.4f}\"\n        )\n\n    experiment_data[\"embed_dim_tuning\"][f\"embed_{dim}\"] = run_store\n\n# ------------------------------ save ---------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Experiment data saved to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, random, string, pathlib, math, time, json\nimport numpy as np, torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset as TorchDataset\nfrom datasets import Dataset as HFDataset, DatasetDict, load_dataset\n\n# ------------------------------ house-keeping ------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n\n# ------------------------------ data utils ---------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"),\n        dev=_load(\"dev.csv\"),\n        test=_load(\"test.csv\"),\n    )\n\n\ndef build_synthetic_dataset(n_train=2000, n_dev=500, n_test=500, max_len=12):\n    def _gen_row():\n        l = random.randint(4, max_len)\n        seq, label = [], 0\n        for _ in range(l):\n            sh, co = random.choice(string.ascii_uppercase[:5]), random.choice(\"01234\")\n            seq.append(sh + co)\n            label ^= (ord(sh) + int(co)) & 1\n        return {\n            \"id\": str(random.randint(0, 1e9)),\n            \"sequence\": \" \".join(seq),\n            \"label\": label,\n        }\n\n    def _many(n):\n        return [_gen_row() for _ in range(n)]\n\n    return DatasetDict(\n        train=HFDataset.from_list(_many(n_train)),\n        dev=HFDataset.from_list(_many(n_dev)),\n        test=HFDataset.from_list(_many(n_test)),\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH) if DATA_PATH.exists() else build_synthetic_dataset()\nprint(\"Dataset size:\", {k: len(v) for k, v in spr.items()})\n\n# ------------------------------ vocabulary ---------------------------------\nPAD, UNK = \"<pad>\", \"<unk>\"\nvocab = {PAD: 0, UNK: 1}\nfor split in [\"train\", \"dev\", \"test\"]:\n    for seq in spr[split][\"sequence\"]:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\npad_idx = vocab[PAD]\n\nMAX_LEN = 40\n\n\ndef encode_sequence(seq, max_len=MAX_LEN):\n    ids = [vocab.get(t, vocab[UNK]) for t in seq.strip().split()[:max_len]]\n    ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\n\n# ------------------------------ metrics ------------------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(token[0] for token in sequence.strip().split() if token))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(token[1] for token in sequence.strip().split() if len(token) > 1))\n\n\ndef shape_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\ndef color_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_color_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ------------------------------ dataset wrappers ---------------------------\nclass SPRTorchDataset(TorchDataset):\n    def __init__(self, hf_dataset: HFDataset):\n        self.ds = hf_dataset\n\n    def __len__(self):\n        return len(self.ds)\n\n    def __getitem__(self, idx):\n        row = self.ds[idx]\n        return {\n            \"sequence\": row[\"sequence\"],\n            \"input_ids\": torch.tensor(\n                encode_sequence(row[\"sequence\"]), dtype=torch.long\n            ),\n            \"labels\": torch.tensor(row[\"label\"], dtype=torch.long),\n        }\n\n\ndef collate_fn(batch):\n    return {\n        \"sequence\": [b[\"sequence\"] for b in batch],\n        \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n        \"labels\": torch.stack([b[\"labels\"] for b in batch]),\n    }\n\n\ndef shape_rename(seq):\n    toks = seq.split()\n    shapes = list({t[0] for t in toks})\n    mapping = {s: random.choice(string.ascii_uppercase) for s in shapes}\n    return \" \".join([mapping[t[0]] + t[1:] for t in toks])\n\n\n# ------------------------------ model --------------------------------------\nclass MeanEmbedClassifier(nn.Module):\n    def __init__(self, vocab_sz, embed_dim, num_cls):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, embed_dim, padding_idx=pad_idx)\n        self.fc = nn.Linear(embed_dim, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)  # B,L,D\n        mask = (x != pad_idx).unsqueeze(-1).float()  # B,L,1\n        pooled = (emb * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n        return self.fc(pooled)\n\n\n# ------------------------------ experiment store ---------------------------\nexperiment_data = {\"embed_dim_tuning\": {}}\n\n# ------------------------------ sweep --------------------------------------\nembed_dims = [64, 128, 256]\nEPOCHS = 5\n\nfor dim in embed_dims:\n    print(f\"\\n=== Training embed_dim={dim} ===\")\n    train_loader = DataLoader(\n        SPRTorchDataset(spr[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_fn,\n    )\n    dev_loader = DataLoader(\n        SPRTorchDataset(spr[\"dev\"]),\n        batch_size=256,\n        shuffle=False,\n        collate_fn=collate_fn,\n    )\n\n    model = MeanEmbedClassifier(len(vocab), dim, len(set(spr[\"train\"][\"label\"]))).to(\n        device\n    )\n    opt = torch.optim.Adam(model.parameters(), lr=3e-3)\n    crit = nn.CrossEntropyLoss()\n\n    run_store = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"CoWA\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        # -------------------- train --------------------\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            # 50 % augmentation\n            seq_aug = [\n                shape_rename(s) if random.random() < 0.5 else s\n                for s in batch[\"sequence\"]\n            ]\n            batch[\"input_ids\"] = torch.stack(\n                [torch.tensor(encode_sequence(s), dtype=torch.long) for s in seq_aug]\n            )\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            opt.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = crit(logits, batch[\"labels\"])\n            loss.backward()\n            opt.step()\n            running_loss += loss.item()\n        train_loss = running_loss / len(train_loader)\n        run_store[\"losses\"][\"train\"].append((epoch, train_loss))\n\n        # -------------------- validation ----------------\n        model.eval()\n        val_loss, seqs, gts, preds = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch_cuda = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch_cuda[\"input_ids\"])\n                val_loss += crit(logits, batch_cuda[\"labels\"]).item()\n                p = logits.argmax(-1).cpu().tolist()\n                preds.extend(p)\n                gts.extend(batch[\"labels\"].tolist())\n                seqs.extend(batch[\"sequence\"])\n        val_loss /= len(dev_loader)\n        SWA = shape_weighted_accuracy(seqs, gts, preds)\n        CWA = color_weighted_accuracy(seqs, gts, preds)\n        CoWA = (SWA + CWA) / 2\n\n        run_store[\"losses\"][\"val\"].append((epoch, val_loss))\n        run_store[\"metrics\"][\"SWA\"].append((epoch, SWA))\n        run_store[\"metrics\"][\"CWA\"].append((epoch, CWA))\n        run_store[\"metrics\"][\"CoWA\"].append((epoch, CoWA))\n        run_store[\"predictions\"].append((epoch, preds))\n        run_store[\"ground_truth\"].append((epoch, gts))\n\n        print(\n            f\"epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"SWA={SWA:.4f} CWA={CWA:.4f} CoWA={CoWA:.4f}\"\n        )\n\n    experiment_data[\"embed_dim_tuning\"][f\"embed_{dim}\"] = run_store\n\n# ------------------------------ save ---------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Experiment data saved to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, random, string, pathlib, math, time, json\nimport numpy as np, torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset as TorchDataset\nfrom datasets import Dataset as HFDataset, DatasetDict, load_dataset\n\n# ------------------------------ house-keeping ------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n\n# ------------------------------ data utils ---------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"),\n        dev=_load(\"dev.csv\"),\n        test=_load(\"test.csv\"),\n    )\n\n\ndef build_synthetic_dataset(n_train=2000, n_dev=500, n_test=500, max_len=12):\n    def _gen_row():\n        l = random.randint(4, max_len)\n        seq, label = [], 0\n        for _ in range(l):\n            sh, co = random.choice(string.ascii_uppercase[:5]), random.choice(\"01234\")\n            seq.append(sh + co)\n            label ^= (ord(sh) + int(co)) & 1\n        return {\n            \"id\": str(random.randint(0, 1e9)),\n            \"sequence\": \" \".join(seq),\n            \"label\": label,\n        }\n\n    def _many(n):\n        return [_gen_row() for _ in range(n)]\n\n    return DatasetDict(\n        train=HFDataset.from_list(_many(n_train)),\n        dev=HFDataset.from_list(_many(n_dev)),\n        test=HFDataset.from_list(_many(n_test)),\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH) if DATA_PATH.exists() else build_synthetic_dataset()\nprint(\"Dataset size:\", {k: len(v) for k, v in spr.items()})\n\n# ------------------------------ vocabulary ---------------------------------\nPAD, UNK = \"<pad>\", \"<unk>\"\nvocab = {PAD: 0, UNK: 1}\nfor split in [\"train\", \"dev\", \"test\"]:\n    for seq in spr[split][\"sequence\"]:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\npad_idx = vocab[PAD]\n\nMAX_LEN = 40\n\n\ndef encode_sequence(seq, max_len=MAX_LEN):\n    ids = [vocab.get(t, vocab[UNK]) for t in seq.strip().split()[:max_len]]\n    ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\n\n# ------------------------------ metrics ------------------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(token[0] for token in sequence.strip().split() if token))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(token[1] for token in sequence.strip().split() if len(token) > 1))\n\n\ndef shape_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\ndef color_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_color_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ------------------------------ dataset wrappers ---------------------------\nclass SPRTorchDataset(TorchDataset):\n    def __init__(self, hf_dataset: HFDataset):\n        self.ds = hf_dataset\n\n    def __len__(self):\n        return len(self.ds)\n\n    def __getitem__(self, idx):\n        row = self.ds[idx]\n        return {\n            \"sequence\": row[\"sequence\"],\n            \"input_ids\": torch.tensor(\n                encode_sequence(row[\"sequence\"]), dtype=torch.long\n            ),\n            \"labels\": torch.tensor(row[\"label\"], dtype=torch.long),\n        }\n\n\ndef collate_fn(batch):\n    return {\n        \"sequence\": [b[\"sequence\"] for b in batch],\n        \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n        \"labels\": torch.stack([b[\"labels\"] for b in batch]),\n    }\n\n\ndef shape_rename(seq):\n    toks = seq.split()\n    shapes = list({t[0] for t in toks})\n    mapping = {s: random.choice(string.ascii_uppercase) for s in shapes}\n    return \" \".join([mapping[t[0]] + t[1:] for t in toks])\n\n\n# ------------------------------ model --------------------------------------\nclass MeanEmbedClassifier(nn.Module):\n    def __init__(self, vocab_sz, embed_dim, num_cls):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, embed_dim, padding_idx=pad_idx)\n        self.fc = nn.Linear(embed_dim, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)  # B,L,D\n        mask = (x != pad_idx).unsqueeze(-1).float()  # B,L,1\n        pooled = (emb * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n        return self.fc(pooled)\n\n\n# ------------------------------ experiment store ---------------------------\nexperiment_data = {\"embed_dim_tuning\": {}}\n\n# ------------------------------ sweep --------------------------------------\nembed_dims = [64, 128, 256]\nEPOCHS = 5\n\nfor dim in embed_dims:\n    print(f\"\\n=== Training embed_dim={dim} ===\")\n    train_loader = DataLoader(\n        SPRTorchDataset(spr[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_fn,\n    )\n    dev_loader = DataLoader(\n        SPRTorchDataset(spr[\"dev\"]),\n        batch_size=256,\n        shuffle=False,\n        collate_fn=collate_fn,\n    )\n\n    model = MeanEmbedClassifier(len(vocab), dim, len(set(spr[\"train\"][\"label\"]))).to(\n        device\n    )\n    opt = torch.optim.Adam(model.parameters(), lr=3e-3)\n    crit = nn.CrossEntropyLoss()\n\n    run_store = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"CoWA\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        # -------------------- train --------------------\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            # 50 % augmentation\n            seq_aug = [\n                shape_rename(s) if random.random() < 0.5 else s\n                for s in batch[\"sequence\"]\n            ]\n            batch[\"input_ids\"] = torch.stack(\n                [torch.tensor(encode_sequence(s), dtype=torch.long) for s in seq_aug]\n            )\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            opt.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = crit(logits, batch[\"labels\"])\n            loss.backward()\n            opt.step()\n            running_loss += loss.item()\n        train_loss = running_loss / len(train_loader)\n        run_store[\"losses\"][\"train\"].append((epoch, train_loss))\n\n        # -------------------- validation ----------------\n        model.eval()\n        val_loss, seqs, gts, preds = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch_cuda = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch_cuda[\"input_ids\"])\n                val_loss += crit(logits, batch_cuda[\"labels\"]).item()\n                p = logits.argmax(-1).cpu().tolist()\n                preds.extend(p)\n                gts.extend(batch[\"labels\"].tolist())\n                seqs.extend(batch[\"sequence\"])\n        val_loss /= len(dev_loader)\n        SWA = shape_weighted_accuracy(seqs, gts, preds)\n        CWA = color_weighted_accuracy(seqs, gts, preds)\n        CoWA = (SWA + CWA) / 2\n\n        run_store[\"losses\"][\"val\"].append((epoch, val_loss))\n        run_store[\"metrics\"][\"SWA\"].append((epoch, SWA))\n        run_store[\"metrics\"][\"CWA\"].append((epoch, CWA))\n        run_store[\"metrics\"][\"CoWA\"].append((epoch, CoWA))\n        run_store[\"predictions\"].append((epoch, preds))\n        run_store[\"ground_truth\"].append((epoch, gts))\n\n        print(\n            f\"epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"SWA={SWA:.4f} CWA={CWA:.4f} CoWA={CoWA:.4f}\"\n        )\n\n    experiment_data[\"embed_dim_tuning\"][f\"embed_{dim}\"] = run_store\n\n# ------------------------------ save ---------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Experiment data saved to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, random, string, pathlib, math, time, json\nimport numpy as np, torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset as TorchDataset\nfrom datasets import Dataset as HFDataset, DatasetDict, load_dataset\n\n# ------------------------------ house-keeping ------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n\n# ------------------------------ data utils ---------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"),\n        dev=_load(\"dev.csv\"),\n        test=_load(\"test.csv\"),\n    )\n\n\ndef build_synthetic_dataset(n_train=2000, n_dev=500, n_test=500, max_len=12):\n    def _gen_row():\n        l = random.randint(4, max_len)\n        seq, label = [], 0\n        for _ in range(l):\n            sh, co = random.choice(string.ascii_uppercase[:5]), random.choice(\"01234\")\n            seq.append(sh + co)\n            label ^= (ord(sh) + int(co)) & 1\n        return {\n            \"id\": str(random.randint(0, 1e9)),\n            \"sequence\": \" \".join(seq),\n            \"label\": label,\n        }\n\n    def _many(n):\n        return [_gen_row() for _ in range(n)]\n\n    return DatasetDict(\n        train=HFDataset.from_list(_many(n_train)),\n        dev=HFDataset.from_list(_many(n_dev)),\n        test=HFDataset.from_list(_many(n_test)),\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\nspr = load_spr_bench(DATA_PATH) if DATA_PATH.exists() else build_synthetic_dataset()\nprint(\"Dataset size:\", {k: len(v) for k, v in spr.items()})\n\n# ------------------------------ vocabulary ---------------------------------\nPAD, UNK = \"<pad>\", \"<unk>\"\nvocab = {PAD: 0, UNK: 1}\nfor split in [\"train\", \"dev\", \"test\"]:\n    for seq in spr[split][\"sequence\"]:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\npad_idx = vocab[PAD]\n\nMAX_LEN = 40\n\n\ndef encode_sequence(seq, max_len=MAX_LEN):\n    ids = [vocab.get(t, vocab[UNK]) for t in seq.strip().split()[:max_len]]\n    ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\n\n# ------------------------------ metrics ------------------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(token[0] for token in sequence.strip().split() if token))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(token[1] for token in sequence.strip().split() if len(token) > 1))\n\n\ndef shape_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\ndef color_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_color_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ------------------------------ dataset wrappers ---------------------------\nclass SPRTorchDataset(TorchDataset):\n    def __init__(self, hf_dataset: HFDataset):\n        self.ds = hf_dataset\n\n    def __len__(self):\n        return len(self.ds)\n\n    def __getitem__(self, idx):\n        row = self.ds[idx]\n        return {\n            \"sequence\": row[\"sequence\"],\n            \"input_ids\": torch.tensor(\n                encode_sequence(row[\"sequence\"]), dtype=torch.long\n            ),\n            \"labels\": torch.tensor(row[\"label\"], dtype=torch.long),\n        }\n\n\ndef collate_fn(batch):\n    return {\n        \"sequence\": [b[\"sequence\"] for b in batch],\n        \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n        \"labels\": torch.stack([b[\"labels\"] for b in batch]),\n    }\n\n\ndef shape_rename(seq):\n    toks = seq.split()\n    shapes = list({t[0] for t in toks})\n    mapping = {s: random.choice(string.ascii_uppercase) for s in shapes}\n    return \" \".join([mapping[t[0]] + t[1:] for t in toks])\n\n\n# ------------------------------ model --------------------------------------\nclass MeanEmbedClassifier(nn.Module):\n    def __init__(self, vocab_sz, embed_dim, num_cls):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, embed_dim, padding_idx=pad_idx)\n        self.fc = nn.Linear(embed_dim, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)  # B,L,D\n        mask = (x != pad_idx).unsqueeze(-1).float()  # B,L,1\n        pooled = (emb * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n        return self.fc(pooled)\n\n\n# ------------------------------ experiment store ---------------------------\nexperiment_data = {\"embed_dim_tuning\": {}}\n\n# ------------------------------ sweep --------------------------------------\nembed_dims = [64, 128, 256]\nEPOCHS = 5\n\nfor dim in embed_dims:\n    print(f\"\\n=== Training embed_dim={dim} ===\")\n    train_loader = DataLoader(\n        SPRTorchDataset(spr[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_fn,\n    )\n    dev_loader = DataLoader(\n        SPRTorchDataset(spr[\"dev\"]),\n        batch_size=256,\n        shuffle=False,\n        collate_fn=collate_fn,\n    )\n\n    model = MeanEmbedClassifier(len(vocab), dim, len(set(spr[\"train\"][\"label\"]))).to(\n        device\n    )\n    opt = torch.optim.Adam(model.parameters(), lr=3e-3)\n    crit = nn.CrossEntropyLoss()\n\n    run_store = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"CoWA\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        # -------------------- train --------------------\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            # 50 % augmentation\n            seq_aug = [\n                shape_rename(s) if random.random() < 0.5 else s\n                for s in batch[\"sequence\"]\n            ]\n            batch[\"input_ids\"] = torch.stack(\n                [torch.tensor(encode_sequence(s), dtype=torch.long) for s in seq_aug]\n            )\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            opt.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = crit(logits, batch[\"labels\"])\n            loss.backward()\n            opt.step()\n            running_loss += loss.item()\n        train_loss = running_loss / len(train_loader)\n        run_store[\"losses\"][\"train\"].append((epoch, train_loss))\n\n        # -------------------- validation ----------------\n        model.eval()\n        val_loss, seqs, gts, preds = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch_cuda = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch_cuda[\"input_ids\"])\n                val_loss += crit(logits, batch_cuda[\"labels\"]).item()\n                p = logits.argmax(-1).cpu().tolist()\n                preds.extend(p)\n                gts.extend(batch[\"labels\"].tolist())\n                seqs.extend(batch[\"sequence\"])\n        val_loss /= len(dev_loader)\n        SWA = shape_weighted_accuracy(seqs, gts, preds)\n        CWA = color_weighted_accuracy(seqs, gts, preds)\n        CoWA = (SWA + CWA) / 2\n\n        run_store[\"losses\"][\"val\"].append((epoch, val_loss))\n        run_store[\"metrics\"][\"SWA\"].append((epoch, SWA))\n        run_store[\"metrics\"][\"CWA\"].append((epoch, CWA))\n        run_store[\"metrics\"][\"CoWA\"].append((epoch, CoWA))\n        run_store[\"predictions\"].append((epoch, preds))\n        run_store[\"ground_truth\"].append((epoch, gts))\n\n        print(\n            f\"epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"SWA={SWA:.4f} CWA={CWA:.4f} CoWA={CoWA:.4f}\"\n        )\n\n    experiment_data[\"embed_dim_tuning\"][f\"embed_{dim}\"] = run_store\n\n# ------------------------------ save ---------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Experiment data saved to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 475148.71\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 469855.27\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 693491.18\nexamples/s]', '\\n', 'Loaded SPR_BENCH from disk.', '\\n', 'Epoch 1: train_loss =\n0.6209 | validation_loss = 0.5335 | val_ACS = 0.5293', '\\n', 'Epoch 2:\ntrain_loss = 0.6130 | validation_loss = 0.5241 | val_ACS = 0.5292', '\\n', 'Epoch\n3: train_loss = 0.6109 | validation_loss = 0.5245 | val_ACS = 0.5510', '\\n',\n'Epoch 4: train_loss = 0.6131 | validation_loss = 0.5219 | val_ACS = 0.5510',\n'\\n', 'Epoch 5: train_loss = 0.6069 | validation_loss = 0.5322 | val_ACS =\n0.5307', '\\n', 'Saved experiment_data.npy', '\\n', 'Execution time: 17 seconds\nseconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 492375.89\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 467571.57\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 527220.66\nexamples/s]', '\\n', 'Loaded SPR_BENCH from disk.', '\\n', '\\n==== Training with\nlearning_rate = 0.0001 ====', '\\n', 'Epoch 1: train_loss=0.6880 |\nval_loss=0.6589 | val_ACS=0.5358', '\\n', 'Epoch 2: train_loss=0.6667 |\nval_loss=0.6251 | val_ACS=0.5243', '\\n', 'Epoch 3: train_loss=0.6518 |\nval_loss=0.6004 | val_ACS=0.5272', '\\n', 'Epoch 4: train_loss=0.6421 |\nval_loss=0.5824 | val_ACS=0.5508', '\\n', 'Epoch 5: train_loss=0.6347 |\nval_loss=0.5691 | val_ACS=0.5267', '\\n', '\\n==== Training with learning_rate =\n0.0005 ====', '\\n', 'Epoch 1: train_loss=0.6567 | val_loss=0.5737 |\nval_ACS=0.5278', '\\n', 'Epoch 2: train_loss=0.6207 | val_loss=0.5385 |\nval_ACS=0.5282', '\\n', 'Epoch 3: train_loss=0.6134 | val_loss=0.5277 |\nval_ACS=0.5288', '\\n', 'Epoch 4: train_loss=0.6113 | val_loss=0.5234 |\nval_ACS=0.5283', '\\n', 'Epoch 5: train_loss=0.6070 | val_loss=0.5230 |\nval_ACS=0.5272', '\\n', '\\n==== Training with learning_rate = 0.001 ====', '\\n',\n'Epoch 1: train_loss=0.6436 | val_loss=0.5351 | val_ACS=0.5290', '\\n', 'Epoch 2:\ntrain_loss=0.6108 | val_loss=0.5231 | val_ACS=0.5268', '\\n', 'Epoch 3:\ntrain_loss=0.6072 | val_loss=0.5218 | val_ACS=0.5517', '\\n', 'Epoch 4:\ntrain_loss=0.6096 | val_loss=0.5226 | val_ACS=0.5497', '\\n', 'Epoch 5:\ntrain_loss=0.6073 | val_loss=0.5231 | val_ACS=0.5497', '\\n', '\\n==== Training\nwith learning_rate = 0.002 ====', '\\n', 'Epoch 1: train_loss=0.6284 |\nval_loss=0.5241 | val_ACS=0.5282', '\\n', 'Epoch 2: train_loss=0.6100 |\nval_loss=0.5219 | val_ACS=0.5275', '\\n', 'Epoch 3: train_loss=0.6053 |\nval_loss=0.5235 | val_ACS=0.5517', '\\n', 'Epoch 4: train_loss=0.6040 |\nval_loss=0.5245 | val_ACS=0.5260', '\\n', 'Epoch 5: train_loss=0.6112 |\nval_loss=0.5257 | val_ACS=0.5313', '\\n', 'Saved experiment_data.npy', '\\n',\n'Execution time: a minute seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 467331.92\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 573948.93\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 389663.97\nexamples/s]', '\\n', 'Loaded SPR_BENCH from disk.', '\\n', '\\n=== Training with\nbatch_size=32 ===', '\\n', '[bs=32] Epoch 1: train_loss=0.6204 | val_loss=0.5292\n| val_ACS=0.5290', '\\n', '[bs=32] Epoch 2: train_loss=0.6154 | val_loss=0.5298 |\nval_ACS=0.5547', '\\n', '[bs=32] Epoch 3: train_loss=0.6167 | val_loss=0.5268 |\nval_ACS=0.5537', '\\n', '[bs=32] Epoch 4: train_loss=0.6144 | val_loss=0.5250 |\nval_ACS=0.5493', '\\n', '[bs=32] Epoch 5: train_loss=0.6154 | val_loss=0.5252 |\nval_ACS=0.5507', '\\n', '\\n=== Training with batch_size=64 ===', '\\n', '[bs=64]\nEpoch 1: train_loss=0.6233 | val_loss=0.5268 | val_ACS=0.5290', '\\n', '[bs=64]\nEpoch 2: train_loss=0.6131 | val_loss=0.5248 | val_ACS=0.5508', '\\n', '[bs=64]\nEpoch 3: train_loss=0.6134 | val_loss=0.5231 | val_ACS=0.5530', '\\n', '[bs=64]\nEpoch 4: train_loss=0.6106 | val_loss=0.5234 | val_ACS=0.5520', '\\n', '[bs=64]\nEpoch 5: train_loss=0.6119 | val_loss=0.5241 | val_ACS=0.5277', '\\n', '\\n===\nTraining with batch_size=128 ===', '\\n', '[bs=128] Epoch 1: train_loss=0.6260 |\nval_loss=0.5257 | val_ACS=0.5282', '\\n', '[bs=128] Epoch 2: train_loss=0.6133 |\nval_loss=0.5244 | val_ACS=0.5268', '\\n', '[bs=128] Epoch 3: train_loss=0.6118 |\nval_loss=0.5241 | val_ACS=0.5285', '\\n', '[bs=128] Epoch 4: train_loss=0.6095 |\nval_loss=0.5255 | val_ACS=0.5318', '\\n', '[bs=128] Epoch 5: train_loss=0.6124 |\nval_loss=0.5255 | val_ACS=0.5313', '\\n', '\\n=== Training with batch_size=256\n===', '\\n', '[bs=256] Epoch 1: train_loss=0.6322 | val_loss=0.5248 |\nval_ACS=0.5267', '\\n', '[bs=256] Epoch 2: train_loss=0.6133 | val_loss=0.5214 |\nval_ACS=0.5510', '\\n', '[bs=256] Epoch 3: train_loss=0.6104 | val_loss=0.5229 |\nval_ACS=0.5502', '\\n', '[bs=256] Epoch 4: train_loss=0.6050 | val_loss=0.5224 |\nval_ACS=0.5508', '\\n', '[bs=256] Epoch 5: train_loss=0.6146 | val_loss=0.5228 |\nval_ACS=0.5327', '\\n', '\\n=== Training with batch_size=512 ===', '\\n', '[bs=512]\nEpoch 1: train_loss=0.6540 | val_loss=0.5359 | val_ACS=0.5517', '\\n', '[bs=512]\nEpoch 2: train_loss=0.6141 | val_loss=0.5242 | val_ACS=0.5498', '\\n', '[bs=512]\nEpoch 3: train_loss=0.6071 | val_loss=0.5226 | val_ACS=0.5488', '\\n', '[bs=512]\nEpoch 4: train_loss=0.6105 | val_loss=0.5213 | val_ACS=0.5507', '\\n', '[bs=512]\nEpoch 5: train_loss=0.6111 | val_loss=0.5235 | val_ACS=0.5265', '\\n', '\\nSaved\nexperiment_data.npy', '\\n', 'Execution time: a minute seconds (time limit is 30\nminutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 20000 examples [00:00,\n617731.47 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 457444.00\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 877139.15\nexamples/s]', '\\n', 'Dataset size:', ' ', \"{'train': 20000, 'dev': 5000, 'test':\n10000}\", '\\n', '\\n=== Training embed_dim=64 ===', '\\n', 'Traceback (most recent\ncall last):\\n  File \"runfile.py\", line 140, in <module>\\n\nSPRTorchDataset(spr[\"train\"]),\\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"runfile.py\", line 86, in __init__\\n    self.data = hf_dataset\\n\n^^^^^^^^^\\nAttributeError: property \\'data\\' of \\'SPRTorchDataset\\' object has\nno setter\\n', 'Execution time: a second seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Dataset sizes:', ' ', \"{'train': 20000,\n'dev': 5000, 'test': 10000}\", '\\n', '\\n=== Training with weight_decay = 0.0\n===', '\\n', 'Epoch 1: train_loss=0.6205 | val_loss=0.5234 | val_ACS=0.5367',\n'\\n', 'Epoch 2: train_loss=0.6151 | val_loss=0.5241 | val_ACS=0.5393', '\\n',\n'Epoch 3: train_loss=0.6112 | val_loss=0.5246 | val_ACS=0.5340', '\\n', 'Epoch 4:\ntrain_loss=0.6137 | val_loss=0.5239 | val_ACS=0.5363', '\\n', 'Epoch 5:\ntrain_loss=0.6088 | val_loss=0.5232 | val_ACS=0.5370', '\\n', '\\n=== Training\nwith weight_decay = 1e-05 ===', '\\n', 'Epoch 1: train_loss=0.6228 |\nval_loss=0.5235 | val_ACS=0.5373', '\\n', 'Epoch 2: train_loss=0.6125 |\nval_loss=0.5258 | val_ACS=0.5353', '\\n', 'Epoch 3: train_loss=0.6080 |\nval_loss=0.5239 | val_ACS=0.5337', '\\n', 'Epoch 4: train_loss=0.6100 |\nval_loss=0.5222 | val_ACS=0.5330', '\\n', 'Epoch 5: train_loss=0.6135 |\nval_loss=0.5241 | val_ACS=0.5377', '\\n', '\\n=== Training with weight_decay =\n0.0001 ===', '\\n', 'Epoch 1: train_loss=0.6242 | val_loss=0.5240 |\nval_ACS=0.5340', '\\n', 'Epoch 2: train_loss=0.6090 | val_loss=0.5240 |\nval_ACS=0.5337', '\\n', 'Epoch 3: train_loss=0.6117 | val_loss=0.5234 |\nval_ACS=0.5360', '\\n', 'Epoch 4: train_loss=0.6086 | val_loss=0.5228 |\nval_ACS=0.5393', '\\n', 'Epoch 5: train_loss=0.6115 | val_loss=0.5244 |\nval_ACS=0.5393', '\\n', '\\n=== Training with weight_decay = 0.0005 ===', '\\n',\n'Epoch 1: train_loss=0.6250 | val_loss=0.5250 | val_ACS=0.5330', '\\n', 'Epoch 2:\ntrain_loss=0.6113 | val_loss=0.5232 | val_ACS=0.5353', '\\n', 'Epoch 3:\ntrain_loss=0.6098 | val_loss=0.5241 | val_ACS=0.5357', '\\n', 'Epoch 4:\ntrain_loss=0.6097 | val_loss=0.5234 | val_ACS=0.5380', '\\n', 'Epoch 5:\ntrain_loss=0.6139 | val_loss=0.5246 | val_ACS=0.5347', '\\n', '\\n=== Training\nwith weight_decay = 0.001 ===', '\\n', 'Epoch 1: train_loss=0.6294 |\nval_loss=0.5264 | val_ACS=0.5383', '\\n', 'Epoch 2: train_loss=0.6094 |\nval_loss=0.5249 | val_ACS=0.5353', '\\n', 'Epoch 3: train_loss=0.6088 |\nval_loss=0.5253 | val_ACS=0.5347', '\\n', 'Epoch 4: train_loss=0.6107 |\nval_loss=0.5260 | val_ACS=0.5343', '\\n', 'Epoch 5: train_loss=0.6108 |\nval_loss=0.5260 | val_ACS=0.5353', '\\n', '\\nSaved metrics to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_00-47-\n34_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n9/working/experiment_data.npy', '\\n', 'Execution time: 8 minutes seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded SPR_BENCH from disk.', '\\n', '\\n===\nTraining with aug_probability = 0.0 ===', '\\n', 'Epoch 1 | train_loss 0.5349 |\nval_loss 0.5275 | ACS 0.5373', '\\n', 'Epoch 2 | train_loss 0.5220 | val_loss\n0.5242 | ACS 0.5377', '\\n', 'Epoch 3 | train_loss 0.5231 | val_loss 0.5233 | ACS\n0.5353', '\\n', 'Epoch 4 | train_loss 0.5225 | val_loss 0.5305 | ACS 0.5357',\n'\\n', 'Epoch 5 | train_loss 0.5239 | val_loss 0.5272 | ACS 0.5373', '\\n', '\\n===\nTraining with aug_probability = 0.25 ===', '\\n', 'Epoch 1 | train_loss 0.5786 |\nval_loss 0.5240 | ACS 0.5360', '\\n', 'Epoch 2 | train_loss 0.5661 | val_loss\n0.5233 | ACS 0.5350', '\\n', 'Epoch 3 | train_loss 0.5662 | val_loss 0.5234 | ACS\n0.5397', '\\n', 'Epoch 4 | train_loss 0.5702 | val_loss 0.5244 | ACS 0.5343',\n'\\n', 'Epoch 5 | train_loss 0.5681 | val_loss 0.5248 | ACS 0.5357', '\\n', '\\n===\nTraining with aug_probability = 0.5 ===', '\\n', 'Epoch 1 | train_loss 0.6286 |\nval_loss 0.5234 | ACS 0.5393', '\\n', 'Epoch 2 | train_loss 0.6133 | val_loss\n0.5244 | ACS 0.5357', '\\n', 'Epoch 3 | train_loss 0.6144 | val_loss 0.5227 | ACS\n0.5343', '\\n', 'Epoch 4 | train_loss 0.6109 | val_loss 0.5265 | ACS 0.5423',\n'\\n', 'Epoch 5 | train_loss 0.6124 | val_loss 0.5265 | ACS 0.5390', '\\n', '\\n===\nTraining with aug_probability = 0.75 ===', '\\n', 'Epoch 1 | train_loss 0.6663 |\nval_loss 0.5260 | ACS 0.5360', '\\n', 'Epoch 2 | train_loss 0.6546 | val_loss\n0.5265 | ACS 0.5397', '\\n', 'Epoch 3 | train_loss 0.6531 | val_loss 0.5255 | ACS\n0.5397', '\\n', 'Epoch 4 | train_loss 0.6552 | val_loss 0.5300 | ACS 0.5403',\n'\\n', 'Epoch 5 | train_loss 0.6532 | val_loss 0.5229 | ACS 0.5400', '\\n', '\\n===\nTraining with aug_probability = 1.0 ===', '\\n', 'Epoch 1 | train_loss 0.6970 |\nval_loss 0.7534 | ACS 0.4760', '\\n', 'Epoch 2 | train_loss 0.6976 | val_loss\n0.7511 | ACS 0.4780', '\\n', 'Epoch 3 | train_loss 0.6978 | val_loss 0.7482 | ACS\n0.4790', '\\n', 'Epoch 4 | train_loss 0.6997 | val_loss 0.7467 | ACS 0.4797',\n'\\n', 'Epoch 5 | train_loss 0.6991 | val_loss 0.7447 | ACS 0.4803', '\\n',\n'\\nSaved experiment_data.npy with all sweep results.', '\\n', 'Execution time: 56\nseconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded dataset sizes ->', ' ', \"{'train': 20000,\n'dev': 5000, 'test': 10000}\", '\\n', '\\n===== Training embed_dim=64 =====', '\\n',\n'Epoch 01 | train_loss=0.6382  val_loss=0.5275 | CoWA_train=0.8222\nCoWA_val=0.7471 | time=1.8s', '\\n', 'Epoch 02 | train_loss=0.6107\nval_loss=0.5231 | CoWA_train=0.7672  CoWA_val=0.7520 | time=1.5s', '\\n', 'Epoch\n03 | train_loss=0.6072  val_loss=0.5234 | CoWA_train=0.7680  CoWA_val=0.7754 |\ntime=1.5s', '\\n', 'Epoch 04 | train_loss=0.6094  val_loss=0.5231 |\nCoWA_train=0.7459  CoWA_val=0.7553 | time=1.5s', '\\n', 'Epoch 05 |\ntrain_loss=0.6088  val_loss=0.5228 | CoWA_train=0.7391  CoWA_val=0.7654 |\ntime=1.6s', '\\n', '\\n===== Training embed_dim=128 =====', '\\n', 'Epoch 01 |\ntrain_loss=0.6248  val_loss=0.5229 | CoWA_train=0.7486  CoWA_val=0.7512 |\ntime=1.5s', '\\n', 'Epoch 02 | train_loss=0.6084  val_loss=0.5239 |\nCoWA_train=0.7595  CoWA_val=0.7522 | time=1.5s', '\\n', 'Epoch 03 |\ntrain_loss=0.6109  val_loss=0.5271 | CoWA_train=0.7662  CoWA_val=0.7568 |\ntime=1.6s', '\\n', 'Epoch 04 | train_loss=0.6139  val_loss=0.5286 |\nCoWA_train=0.6589  CoWA_val=0.7207 | time=1.5s', '\\n', 'Epoch 05 |\ntrain_loss=0.6118  val_loss=0.5249 | CoWA_train=0.6861  CoWA_val=0.7383 |\ntime=1.5s', '\\n', '\\n===== Training embed_dim=256 =====', '\\n', 'Epoch 01 |\ntrain_loss=0.6254  val_loss=0.5243 | CoWA_train=0.7473  CoWA_val=0.7515 |\ntime=1.5s', '\\n', 'Epoch 02 | train_loss=0.6154  val_loss=0.5292 |\nCoWA_train=0.7325  CoWA_val=0.7318 | time=1.6s', '\\n', 'Epoch 03 |\ntrain_loss=0.6110  val_loss=0.5251 | CoWA_train=0.7183  CoWA_val=0.7436 |\ntime=1.6s', '\\n', 'Epoch 04 | train_loss=0.6119  val_loss=0.5258 |\nCoWA_train=0.7896  CoWA_val=0.7549 | time=1.6s', '\\n', 'Epoch 05 |\ntrain_loss=0.6116  val_loss=0.5258 | CoWA_train=0.7587  CoWA_val=0.7560 |\ntime=1.6s', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist\n-v2/experiments/2025-08-16_00-47-\n34_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n8/working/experiment_data.npy', '\\n', 'Execution time: 25 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Dataset size:', ' ', \"{'train': 20000, 'dev':\n5000, 'test': 10000}\", '\\n', '\\n=== Training embed_dim=64 ===', '\\n', 'epoch 1:\ntrain_loss=0.6382 val_loss=0.5275 SWA=0.7499 CWA=0.7442 CoWA=0.7471', '\\n',\n'epoch 2: train_loss=0.6085 val_loss=0.5245 SWA=0.7525 CWA=0.7478 CoWA=0.7501',\n'\\n', 'epoch 3: train_loss=0.6060 val_loss=0.5218 SWA=0.7709 CWA=0.7661\nCoWA=0.7685', '\\n', 'epoch 4: train_loss=0.6122 val_loss=0.5235 SWA=0.7467\nCWA=0.7407 CoWA=0.7437', '\\n', 'epoch 5: train_loss=0.6060 val_loss=0.5235\nSWA=0.7388 CWA=0.7347 CoWA=0.7367', '\\n', '\\n=== Training embed_dim=128 ===',\n'\\n', 'epoch 1: train_loss=0.6245 val_loss=0.5236 SWA=0.7387 CWA=0.7361\nCoWA=0.7374', '\\n', 'epoch 2: train_loss=0.6096 val_loss=0.5257 SWA=0.7668\nCWA=0.7645 CoWA=0.7657', '\\n', 'epoch 3: train_loss=0.6102 val_loss=0.5249\nSWA=0.7510 CWA=0.7456 CoWA=0.7483', '\\n', 'epoch 4: train_loss=0.6088\nval_loss=0.5245 SWA=0.7601 CWA=0.7541 CoWA=0.7571', '\\n', 'epoch 5:\ntrain_loss=0.6108 val_loss=0.5257 SWA=0.7825 CWA=0.7788 CoWA=0.7807', '\\n',\n'\\n=== Training embed_dim=256 ===', '\\n', 'epoch 1: train_loss=0.6283\nval_loss=0.5252 SWA=0.7510 CWA=0.7469 CoWA=0.7489', '\\n', 'epoch 2:\ntrain_loss=0.6115 val_loss=0.5262 SWA=0.7587 CWA=0.7588 CoWA=0.7588', '\\n',\n'epoch 3: train_loss=0.6167 val_loss=0.5294 SWA=0.7692 CWA=0.7666 CoWA=0.7679',\n'\\n', 'epoch 4: train_loss=0.6176 val_loss=0.5282 SWA=0.7603 CWA=0.7580\nCoWA=0.7591', '\\n', 'epoch 5: train_loss=0.6088 val_loss=0.5231 SWA=0.7609\nCWA=0.7574 CoWA=0.7592', '\\n', 'Experiment data saved to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_00-47-\n34_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n6/working/experiment_data.npy', '\\n', 'Execution time: 39 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Dataset size:', ' ', \"{'train': 20000, 'dev':\n5000, 'test': 10000}\", '\\n', '\\n=== Training embed_dim=64 ===', '\\n', 'epoch 1:\ntrain_loss=0.6382 val_loss=0.5275 SWA=0.7499 CWA=0.7442 CoWA=0.7471', '\\n',\n'epoch 2: train_loss=0.6085 val_loss=0.5245 SWA=0.7525 CWA=0.7478 CoWA=0.7501',\n'\\n', 'epoch 3: train_loss=0.6060 val_loss=0.5218 SWA=0.7709 CWA=0.7661\nCoWA=0.7685', '\\n', 'epoch 4: train_loss=0.6122 val_loss=0.5235 SWA=0.7467\nCWA=0.7407 CoWA=0.7437', '\\n', 'epoch 5: train_loss=0.6060 val_loss=0.5235\nSWA=0.7388 CWA=0.7347 CoWA=0.7367', '\\n', '\\n=== Training embed_dim=128 ===',\n'\\n', 'epoch 1: train_loss=0.6245 val_loss=0.5236 SWA=0.7387 CWA=0.7361\nCoWA=0.7374', '\\n', 'epoch 2: train_loss=0.6096 val_loss=0.5257 SWA=0.7668\nCWA=0.7645 CoWA=0.7657', '\\n', 'epoch 3: train_loss=0.6102 val_loss=0.5249\nSWA=0.7510 CWA=0.7456 CoWA=0.7483', '\\n', 'epoch 4: train_loss=0.6088\nval_loss=0.5245 SWA=0.7601 CWA=0.7541 CoWA=0.7571', '\\n', 'epoch 5:\ntrain_loss=0.6108 val_loss=0.5257 SWA=0.7825 CWA=0.7788 CoWA=0.7807', '\\n',\n'\\n=== Training embed_dim=256 ===', '\\n', 'epoch 1: train_loss=0.6283\nval_loss=0.5252 SWA=0.7510 CWA=0.7469 CoWA=0.7489', '\\n', 'epoch 2:\ntrain_loss=0.6115 val_loss=0.5262 SWA=0.7587 CWA=0.7588 CoWA=0.7588', '\\n',\n'epoch 3: train_loss=0.6167 val_loss=0.5294 SWA=0.7692 CWA=0.7666 CoWA=0.7679',\n'\\n', 'epoch 4: train_loss=0.6176 val_loss=0.5282 SWA=0.7603 CWA=0.7580\nCoWA=0.7591', '\\n', 'epoch 5: train_loss=0.6088 val_loss=0.5231 SWA=0.7609\nCWA=0.7574 CoWA=0.7592', '\\n', 'Experiment data saved to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_00-47-\n34_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n8/working/experiment_data.npy', '\\n', 'Execution time: 45 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Dataset size:', ' ', \"{'train': 20000, 'dev':\n5000, 'test': 10000}\", '\\n', '\\n=== Training embed_dim=64 ===', '\\n', 'epoch 1:\ntrain_loss=0.6382 val_loss=0.5275 SWA=0.7499 CWA=0.7442 CoWA=0.7471', '\\n',\n'epoch 2: train_loss=0.6085 val_loss=0.5245 SWA=0.7525 CWA=0.7478 CoWA=0.7501',\n'\\n', 'epoch 3: train_loss=0.6060 val_loss=0.5218 SWA=0.7709 CWA=0.7661\nCoWA=0.7685', '\\n', 'epoch 4: train_loss=0.6122 val_loss=0.5235 SWA=0.7467\nCWA=0.7407 CoWA=0.7437', '\\n', 'epoch 5: train_loss=0.6060 val_loss=0.5235\nSWA=0.7388 CWA=0.7347 CoWA=0.7367', '\\n', '\\n=== Training embed_dim=128 ===',\n'\\n', 'epoch 1: train_loss=0.6245 val_loss=0.5236 SWA=0.7387 CWA=0.7361\nCoWA=0.7374', '\\n', 'epoch 2: train_loss=0.6096 val_loss=0.5257 SWA=0.7668\nCWA=0.7645 CoWA=0.7657', '\\n', 'epoch 3: train_loss=0.6102 val_loss=0.5249\nSWA=0.7510 CWA=0.7456 CoWA=0.7483', '\\n', 'epoch 4: train_loss=0.6088\nval_loss=0.5245 SWA=0.7601 CWA=0.7541 CoWA=0.7571', '\\n', 'epoch 5:\ntrain_loss=0.6108 val_loss=0.5257 SWA=0.7825 CWA=0.7788 CoWA=0.7807', '\\n',\n'\\n=== Training embed_dim=256 ===', '\\n', 'epoch 1: train_loss=0.6283\nval_loss=0.5252 SWA=0.7510 CWA=0.7469 CoWA=0.7489', '\\n', 'epoch 2:\ntrain_loss=0.6115 val_loss=0.5262 SWA=0.7587 CWA=0.7588 CoWA=0.7588', '\\n',\n'epoch 3: train_loss=0.6167 val_loss=0.5294 SWA=0.7692 CWA=0.7666 CoWA=0.7679',\n'\\n', 'epoch 4: train_loss=0.6176 val_loss=0.5282 SWA=0.7603 CWA=0.7580\nCoWA=0.7591', '\\n', 'epoch 5: train_loss=0.6088 val_loss=0.5231 SWA=0.7609\nCWA=0.7574 CoWA=0.7592', '\\n', 'Experiment data saved to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_00-47-\n34_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n6/working/experiment_data.npy', '\\n', 'Execution time: 30 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Dataset size:', ' ', \"{'train': 20000, 'dev':\n5000, 'test': 10000}\", '\\n', '\\n=== Training embed_dim=64 ===', '\\n', 'epoch 1:\ntrain_loss=0.6382 val_loss=0.5275 SWA=0.7499 CWA=0.7442 CoWA=0.7471', '\\n',\n'epoch 2: train_loss=0.6085 val_loss=0.5245 SWA=0.7525 CWA=0.7478 CoWA=0.7501',\n'\\n', 'epoch 3: train_loss=0.6060 val_loss=0.5218 SWA=0.7709 CWA=0.7661\nCoWA=0.7685', '\\n', 'epoch 4: train_loss=0.6122 val_loss=0.5235 SWA=0.7467\nCWA=0.7407 CoWA=0.7437', '\\n', 'epoch 5: train_loss=0.6060 val_loss=0.5235\nSWA=0.7388 CWA=0.7347 CoWA=0.7367', '\\n', '\\n=== Training embed_dim=128 ===',\n'\\n', 'epoch 1: train_loss=0.6245 val_loss=0.5236 SWA=0.7387 CWA=0.7361\nCoWA=0.7374', '\\n', 'epoch 2: train_loss=0.6096 val_loss=0.5257 SWA=0.7668\nCWA=0.7645 CoWA=0.7657', '\\n', 'epoch 3: train_loss=0.6102 val_loss=0.5249\nSWA=0.7510 CWA=0.7456 CoWA=0.7483', '\\n', 'epoch 4: train_loss=0.6088\nval_loss=0.5245 SWA=0.7601 CWA=0.7541 CoWA=0.7571', '\\n', 'epoch 5:\ntrain_loss=0.6108 val_loss=0.5257 SWA=0.7825 CWA=0.7788 CoWA=0.7807', '\\n',\n'\\n=== Training embed_dim=256 ===', '\\n', 'epoch 1: train_loss=0.6283\nval_loss=0.5252 SWA=0.7510 CWA=0.7469 CoWA=0.7489', '\\n', 'epoch 2:\ntrain_loss=0.6115 val_loss=0.5262 SWA=0.7587 CWA=0.7588 CoWA=0.7588', '\\n',\n'epoch 3: train_loss=0.6167 val_loss=0.5294 SWA=0.7692 CWA=0.7666 CoWA=0.7679',\n'\\n', 'epoch 4: train_loss=0.6176 val_loss=0.5282 SWA=0.7603 CWA=0.7580\nCoWA=0.7591', '\\n', 'epoch 5: train_loss=0.6088 val_loss=0.5231 SWA=0.7609\nCWA=0.7574 CoWA=0.7592', '\\n', 'Experiment data saved to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_00-47-\n34_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n7/working/experiment_data.npy', '\\n', 'Execution time: 28 seconds seconds (time\nlimit is 30 minutes).']", ""], "analysis": ["", "The training script executed successfully without any errors or bugs. The\ntraining and validation losses decreased as expected, and the ACS metric\n(Average Consistency Score) was computed for each learning rate. However, the\nACS values remained relatively low (~0.53-0.55), indicating room for improvement\nin model performance or augmentation techniques. Overall, the script performed\nas intended, and the results were saved successfully.", "The training script executed successfully without any errors or bugs. The model\nwas trained using different batch sizes, and the results were logged. However,\nthe performance metrics (train_loss, val_loss, and val_ACS) did not show\nsignificant improvement across epochs or batch sizes. This indicates that the\ncurrent model and training configuration might not be optimal for the task.\nFurther experimentation with hyperparameters, model architecture, or data\npreprocessing might be needed to achieve better results.", "The code execution failed due to an AttributeError in the SPRTorchDataset class.\nSpecifically, the 'data' attribute is being assigned directly, but the class\ndefinition does not allow setting 'data' as it is likely defined as a property\nwithout a setter. To fix this issue, modify the SPRTorchDataset class to allow\nassignment to 'data', either by removing the property decorator or by defining a\nsetter method for 'data'. Alternatively, if 'data' should not be modified\ndirectly, consider using a different attribute name for storing the dataset.", "", "", "", "The code executed successfully without any bugs. The training process for three\ndifferent embedding dimensions (64, 128, 256) was conducted, and the metrics\nShape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA), and Combined\nWeighted Accuracy (CoWA) were calculated and logged for each epoch. The results\nshowed improvements in the metrics over epochs for certain configurations. The\nexperiment data was saved successfully, and the execution time was within the\nlimit.", "The execution of the script was successful. The training process for different\nembedding dimensions (64, 128, 256) was completed without any errors. The script\nlogged training and validation losses, as well as metrics (SWA, CWA, CoWA) for\neach epoch. The results show that the model achieved CoWA values above the SOTA\nbenchmarks of 65.0% SWA and 70.0% CWA, indicating significant improvement.\nExperiment data was saved properly, and the execution time was well within the\nlimit. No bugs were identified in the execution.", "The training script executed successfully without any errors or bugs. The\ndataset was loaded correctly, and the training process for three different\nembedding dimensions (64, 128, 256) completed as expected. Metrics such as\nShape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA), and their average\n(CoWA) were calculated and reported per epoch. The experiment data was saved\nsuccessfully for further analysis. No issues were detected in the output.", "The execution of the training script was successful. The script tested three\ndifferent embedding dimensions (64, 128, 256) and recorded Shape-Weighted\nAccuracy (SWA), Color-Weighted Accuracy (CWA), and Combined Weighted Accuracy\n(CoWA) as metrics for evaluation. The results showed that the model was able to\ntrain and validate correctly, with no errors or bugs encountered during\nexecution. The experiment data was successfully saved for further analysis. The\nexecution time was well within the limit, completing in 28 seconds.", ""], "exc_type": [null, null, null, "AttributeError", null, null, null, null, null, null, null, null], "exc_info": [null, null, null, {"args": ["property 'data' of 'SPRTorchDataset' object has no setter"], "name": "None", "obj": "None"}, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 140, "<module>", "SPRTorchDataset(spr[\"train\"]),"], ["runfile.py", 86, "__init__", "self.data = hf_dataset"]], null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Represents the error on the training dataset during model training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6069, "best_value": 0.6069}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Represents the error on the validation dataset during model training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5219, "best_value": 0.5219}]}, {"metric_name": "validation ACS", "lower_is_better": false, "description": "Represents the Average Classification Score (ACS) on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.551, "best_value": 0.551}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value computed on the training dataset.", "data": [{"dataset_name": "lr_1e-04", "final_value": 0.6347, "best_value": 0.6347}, {"dataset_name": "lr_5e-04", "final_value": 0.607, "best_value": 0.607}, {"dataset_name": "lr_0.001", "final_value": 0.6072, "best_value": 0.6072}, {"dataset_name": "lr_0.002", "final_value": 0.604, "best_value": 0.604}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value computed on the validation dataset.", "data": [{"dataset_name": "lr_1e-04", "final_value": 0.5691, "best_value": 0.5691}, {"dataset_name": "lr_5e-04", "final_value": 0.523, "best_value": 0.523}, {"dataset_name": "lr_0.001", "final_value": 0.5218, "best_value": 0.5218}, {"dataset_name": "lr_0.002", "final_value": 0.5219, "best_value": 0.5219}]}, {"metric_name": "validation ACS", "lower_is_better": false, "description": "The ACS (Accuracy) metric computed on the validation dataset.", "data": [{"dataset_name": "lr_1e-04", "final_value": 0.5508, "best_value": 0.5508}, {"dataset_name": "lr_5e-04", "final_value": 0.5288, "best_value": 0.5288}, {"dataset_name": "lr_0.001", "final_value": 0.5517, "best_value": 0.5517}, {"dataset_name": "lr_0.002", "final_value": 0.5517, "best_value": 0.5517}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated during the training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.605, "best_value": 0.605}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5213, "best_value": 0.5213}]}, {"metric_name": "validation ACS", "lower_is_better": false, "description": "The ACS (accuracy or equivalent metric) calculated during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5547, "best_value": 0.5547}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy calculated during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7535, "best_value": 0.7535}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value on the training dataset, indicating how well the model fits the training data.", "data": [{"dataset_name": "SPR_BENCH (weight_decay = 0.0)", "final_value": 0.6088, "best_value": 0.6088}, {"dataset_name": "SPR_BENCH (weight_decay = 1e-05)", "final_value": 0.608, "best_value": 0.608}, {"dataset_name": "SPR_BENCH (weight_decay = 0.0001)", "final_value": 0.6086, "best_value": 0.6086}, {"dataset_name": "SPR_BENCH (weight_decay = 0.0005)", "final_value": 0.6097, "best_value": 0.6097}, {"dataset_name": "SPR_BENCH (weight_decay = 0.001)", "final_value": 0.6088, "best_value": 0.6088}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset, indicating how well the model generalizes to unseen data.", "data": [{"dataset_name": "SPR_BENCH (weight_decay = 0.0)", "final_value": 0.5232, "best_value": 0.5232}, {"dataset_name": "SPR_BENCH (weight_decay = 1e-05)", "final_value": 0.5222, "best_value": 0.5222}, {"dataset_name": "SPR_BENCH (weight_decay = 0.0001)", "final_value": 0.5228, "best_value": 0.5228}, {"dataset_name": "SPR_BENCH (weight_decay = 0.0005)", "final_value": 0.5232, "best_value": 0.5232}, {"dataset_name": "SPR_BENCH (weight_decay = 0.001)", "final_value": 0.5249, "best_value": 0.5249}]}, {"metric_name": "validation ACS", "lower_is_better": false, "description": "The ACS value on the validation dataset, measuring the accuracy or correctness of predictions.", "data": [{"dataset_name": "SPR_BENCH (weight_decay = 0.0)", "final_value": 0.5393, "best_value": 0.5393}, {"dataset_name": "SPR_BENCH (weight_decay = 1e-05)", "final_value": 0.5377, "best_value": 0.5377}, {"dataset_name": "SPR_BENCH (weight_decay = 0.0001)", "final_value": 0.5393, "best_value": 0.5393}, {"dataset_name": "SPR_BENCH (weight_decay = 0.0005)", "final_value": 0.538, "best_value": 0.538}, {"dataset_name": "SPR_BENCH (weight_decay = 0.001)", "final_value": 0.5383, "best_value": 0.5383}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value calculated during the training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6991, "best_value": 0.5239}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value calculated during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7447, "best_value": 0.5229}]}, {"metric_name": "validation ACS", "lower_is_better": false, "description": "The Accuracy Score (ACS) calculated during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4803, "best_value": 0.54}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Training loss measures the error during the training phase. Lower values indicate better performance.", "data": [{"dataset_name": "emb_64", "final_value": 0.6088, "best_value": 0.6088}, {"dataset_name": "emb_128", "final_value": 0.6118, "best_value": 0.6118}, {"dataset_name": "emb_256", "final_value": 0.6116, "best_value": 0.6116}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss measures the error during the validation phase. Lower values indicate better performance.", "data": [{"dataset_name": "emb_64", "final_value": 0.5228, "best_value": 0.5228}, {"dataset_name": "emb_128", "final_value": 0.5249, "best_value": 0.5249}, {"dataset_name": "emb_256", "final_value": 0.5258, "best_value": 0.5258}]}, {"metric_name": "training composite weighted accuracy", "lower_is_better": false, "description": "Training composite weighted accuracy evaluates the weighted accuracy during training. Higher values indicate better performance.", "data": [{"dataset_name": "emb_64", "final_value": 0.7391, "best_value": 0.7391}, {"dataset_name": "emb_128", "final_value": 0.6861, "best_value": 0.6861}, {"dataset_name": "emb_256", "final_value": 0.7587, "best_value": 0.7587}]}, {"metric_name": "validation composite weighted accuracy", "lower_is_better": false, "description": "Validation composite weighted accuracy evaluates the weighted accuracy during validation. Higher values indicate better performance.", "data": [{"dataset_name": "emb_64", "final_value": 0.7654, "best_value": 0.7654}, {"dataset_name": "emb_128", "final_value": 0.7383, "best_value": 0.7383}, {"dataset_name": "emb_256", "final_value": 0.756, "best_value": 0.756}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, which indicates how well the model is learning from the training data.", "data": [{"dataset_name": "embed_64", "final_value": 0.606, "best_value": 0.606}, {"dataset_name": "embed_128", "final_value": 0.6088, "best_value": 0.6088}, {"dataset_name": "embed_256", "final_value": 0.6088, "best_value": 0.6088}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, which indicates how well the model is performing on unseen data.", "data": [{"dataset_name": "embed_64", "final_value": 0.5218, "best_value": 0.5218}, {"dataset_name": "embed_128", "final_value": 0.5236, "best_value": 0.5236}, {"dataset_name": "embed_256", "final_value": 0.5231, "best_value": 0.5231}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model weighted by shape-related metrics.", "data": [{"dataset_name": "embed_64", "final_value": 0.7709, "best_value": 0.7709}, {"dataset_name": "embed_128", "final_value": 0.7825, "best_value": 0.7825}, {"dataset_name": "embed_256", "final_value": 0.7692, "best_value": 0.7692}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model weighted by color-related metrics.", "data": [{"dataset_name": "embed_64", "final_value": 0.7661, "best_value": 0.7661}, {"dataset_name": "embed_128", "final_value": 0.7788, "best_value": 0.7788}, {"dataset_name": "embed_256", "final_value": 0.7666, "best_value": 0.7666}]}, {"metric_name": "combined weighted accuracy", "lower_is_better": false, "description": "The combined accuracy of the model weighted by both shape and color metrics.", "data": [{"dataset_name": "embed_64", "final_value": 0.7685, "best_value": 0.7685}, {"dataset_name": "embed_128", "final_value": 0.7807, "best_value": 0.7807}, {"dataset_name": "embed_256", "final_value": 0.7679, "best_value": 0.7679}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is fitting the training data.", "data": [{"dataset_name": "embed_64", "final_value": 0.606, "best_value": 0.606}, {"dataset_name": "embed_128", "final_value": 0.6088, "best_value": 0.6088}, {"dataset_name": "embed_256", "final_value": 0.6088, "best_value": 0.6088}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, indicating how well the model is generalizing to unseen data.", "data": [{"dataset_name": "embed_64", "final_value": 0.5218, "best_value": 0.5218}, {"dataset_name": "embed_128", "final_value": 0.5236, "best_value": 0.5236}, {"dataset_name": "embed_256", "final_value": 0.5231, "best_value": 0.5231}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by shape attributes, indicating how well the model predicts shape-related features.", "data": [{"dataset_name": "embed_64", "final_value": 0.7709, "best_value": 0.7709}, {"dataset_name": "embed_128", "final_value": 0.7825, "best_value": 0.7825}, {"dataset_name": "embed_256", "final_value": 0.7692, "best_value": 0.7692}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by color attributes, indicating how well the model predicts color-related features.", "data": [{"dataset_name": "embed_64", "final_value": 0.7661, "best_value": 0.7661}, {"dataset_name": "embed_128", "final_value": 0.7788, "best_value": 0.7788}, {"dataset_name": "embed_256", "final_value": 0.7666, "best_value": 0.7666}]}, {"metric_name": "combined weighted accuracy", "lower_is_better": false, "description": "Combined accuracy weighted by both shape and color attributes.", "data": [{"dataset_name": "embed_64", "final_value": 0.7685, "best_value": 0.7685}, {"dataset_name": "embed_128", "final_value": 0.7807, "best_value": 0.7807}, {"dataset_name": "embed_256", "final_value": 0.7679, "best_value": 0.7679}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value computed on the training dataset at the end of training.", "data": [{"dataset_name": "embed_64", "final_value": 0.606, "best_value": 0.606}, {"dataset_name": "embed_128", "final_value": 0.6088, "best_value": 0.6088}, {"dataset_name": "embed_256", "final_value": 0.6088, "best_value": 0.6088}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value computed on the validation dataset at the end of training.", "data": [{"dataset_name": "embed_64", "final_value": 0.5218, "best_value": 0.5218}, {"dataset_name": "embed_128", "final_value": 0.5236, "best_value": 0.5236}, {"dataset_name": "embed_256", "final_value": 0.5231, "best_value": 0.5231}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "The weighted accuracy for shape predictions.", "data": [{"dataset_name": "embed_64", "final_value": 0.7709, "best_value": 0.7709}, {"dataset_name": "embed_128", "final_value": 0.7825, "best_value": 0.7825}, {"dataset_name": "embed_256", "final_value": 0.7692, "best_value": 0.7692}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "The weighted accuracy for color predictions.", "data": [{"dataset_name": "embed_64", "final_value": 0.7661, "best_value": 0.7661}, {"dataset_name": "embed_128", "final_value": 0.7788, "best_value": 0.7788}, {"dataset_name": "embed_256", "final_value": 0.7666, "best_value": 0.7666}]}, {"metric_name": "combined weighted accuracy", "lower_is_better": false, "description": "The combined weighted accuracy for both shape and color predictions.", "data": [{"dataset_name": "embed_64", "final_value": 0.7685, "best_value": 0.7685}, {"dataset_name": "embed_128", "final_value": 0.7807, "best_value": 0.7807}, {"dataset_name": "embed_256", "final_value": 0.7679, "best_value": 0.7679}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss computed on the training dataset.", "data": [{"dataset_name": "embed_64", "final_value": 0.606, "best_value": 0.606}, {"dataset_name": "embed_128", "final_value": 0.6088, "best_value": 0.6088}, {"dataset_name": "embed_256", "final_value": 0.6088, "best_value": 0.6088}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss computed on the validation dataset.", "data": [{"dataset_name": "embed_64", "final_value": 0.5218, "best_value": 0.5218}, {"dataset_name": "embed_128", "final_value": 0.5236, "best_value": 0.5236}, {"dataset_name": "embed_256", "final_value": 0.5231, "best_value": 0.5231}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "The weighted accuracy for shape predictions.", "data": [{"dataset_name": "embed_64", "final_value": 0.7709, "best_value": 0.7709}, {"dataset_name": "embed_128", "final_value": 0.7825, "best_value": 0.7825}, {"dataset_name": "embed_256", "final_value": 0.7692, "best_value": 0.7692}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "The weighted accuracy for color predictions.", "data": [{"dataset_name": "embed_64", "final_value": 0.7661, "best_value": 0.7661}, {"dataset_name": "embed_128", "final_value": 0.7788, "best_value": 0.7788}, {"dataset_name": "embed_256", "final_value": 0.7666, "best_value": 0.7666}]}, {"metric_name": "combined weighted accuracy", "lower_is_better": false, "description": "The combined weighted accuracy for both shape and color predictions.", "data": [{"dataset_name": "embed_64", "final_value": 0.7685, "best_value": 0.7685}, {"dataset_name": "embed_128", "final_value": 0.7807, "best_value": 0.7807}, {"dataset_name": "embed_256", "final_value": 0.7679, "best_value": 0.7679}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, false, false, false, true, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_543524ad2efd4fb5ac09e39248e2f5ae_proc_3066822/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_543524ad2efd4fb5ac09e39248e2f5ae_proc_3066822/SPR_BENCH_ACS_curve.png", "../../logs/0-run/experiment_results/experiment_543524ad2efd4fb5ac09e39248e2f5ae_proc_3066822/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_38814c2557eb4f14a20d02938e4e5c62_proc_3071488/spr_loss_curves.png", "../../logs/0-run/experiment_results/experiment_38814c2557eb4f14a20d02938e4e5c62_proc_3071488/spr_val_ACS_curves.png", "../../logs/0-run/experiment_results/experiment_38814c2557eb4f14a20d02938e4e5c62_proc_3071488/spr_final_ACS_bar.png"], ["../../logs/0-run/experiment_results/experiment_c311401954be48cda04eb19659e5f496_proc_3071489/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_c311401954be48cda04eb19659e5f496_proc_3071489/SPR_BENCH_ACS_curves.png", "../../logs/0-run/experiment_results/experiment_c311401954be48cda04eb19659e5f496_proc_3071489/SPR_BENCH_val_accuracy_by_batch_size.png"], [], ["../../logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_train_loss_curve.png", "../../logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_val_loss_curve.png", "../../logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_val_ACS_curve.png", "../../logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_confusion_matrix_wd_0.0.png"], ["../../logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_ACS_curves.png", "../../logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_final_ACS.png", "../../logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_final_accuracy.png"], ["../../logs/0-run/experiment_results/experiment_0ba3ff0ff10646c6a7f63b666c7fa163_proc_3071489/embed_dim_sweep_loss_curves.png", "../../logs/0-run/experiment_results/experiment_0ba3ff0ff10646c6a7f63b666c7fa163_proc_3071489/embed_dim_sweep_cowa_curves.png", "../../logs/0-run/experiment_results/experiment_0ba3ff0ff10646c6a7f63b666c7fa163_proc_3071489/embed_dim_sweep_cowa_summary.png"], ["../../logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_loss_embed_128.png", "../../logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_loss_embed_256.png", "../../logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_loss_embed_64.png", "../../logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_CoWA_epochs.png", "../../logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_final_CoWA_bar.png"], ["../../logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_loss_embed_128.png", "../../logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_loss_embed_256.png", "../../logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_loss_embed_64.png", "../../logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_CoWA_epochs.png", "../../logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_final_CoWA_bar.png"], ["../../logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_loss_embed_128.png", "../../logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_loss_embed_256.png", "../../logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_loss_embed_64.png", "../../logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_CoWA_epochs.png", "../../logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_final_CoWA_bar.png"], ["../../logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_loss_embed_128.png", "../../logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_loss_embed_256.png", "../../logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_loss_embed_64.png", "../../logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_CoWA_epochs.png", "../../logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_final_CoWA_bar.png"], ["../../logs/0-run/experiment_results/seed_aggregation_591f42447db143d5b74bcf7c71da5c49/dataset_train_loss_aggregated.png", "../../logs/0-run/experiment_results/seed_aggregation_591f42447db143d5b74bcf7c71da5c49/dataset_val_loss_aggregated.png", "../../logs/0-run/experiment_results/seed_aggregation_591f42447db143d5b74bcf7c71da5c49/dataset_CoWA_epochs_aggregated.png", "../../logs/0-run/experiment_results/seed_aggregation_591f42447db143d5b74bcf7c71da5c49/dataset_final_CoWA_bar_aggregated.png"]], "plot_paths": [["experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_543524ad2efd4fb5ac09e39248e2f5ae_proc_3066822/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_543524ad2efd4fb5ac09e39248e2f5ae_proc_3066822/SPR_BENCH_ACS_curve.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_543524ad2efd4fb5ac09e39248e2f5ae_proc_3066822/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_38814c2557eb4f14a20d02938e4e5c62_proc_3071488/spr_loss_curves.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_38814c2557eb4f14a20d02938e4e5c62_proc_3071488/spr_val_ACS_curves.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_38814c2557eb4f14a20d02938e4e5c62_proc_3071488/spr_final_ACS_bar.png"], ["experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c311401954be48cda04eb19659e5f496_proc_3071489/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c311401954be48cda04eb19659e5f496_proc_3071489/SPR_BENCH_ACS_curves.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c311401954be48cda04eb19659e5f496_proc_3071489/SPR_BENCH_val_accuracy_by_batch_size.png"], [], ["experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_train_loss_curve.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_val_loss_curve.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_val_ACS_curve.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_confusion_matrix_wd_0.0.png"], ["experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_ACS_curves.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_final_ACS.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_final_accuracy.png"], ["experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_0ba3ff0ff10646c6a7f63b666c7fa163_proc_3071489/embed_dim_sweep_loss_curves.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_0ba3ff0ff10646c6a7f63b666c7fa163_proc_3071489/embed_dim_sweep_cowa_curves.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_0ba3ff0ff10646c6a7f63b666c7fa163_proc_3071489/embed_dim_sweep_cowa_summary.png"], ["experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_loss_embed_128.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_loss_embed_256.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_loss_embed_64.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_CoWA_epochs.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_final_CoWA_bar.png"], ["experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_loss_embed_128.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_loss_embed_256.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_loss_embed_64.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_CoWA_epochs.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_final_CoWA_bar.png"], ["experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_loss_embed_128.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_loss_embed_256.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_loss_embed_64.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_CoWA_epochs.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_final_CoWA_bar.png"], ["experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_loss_embed_128.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_loss_embed_256.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_loss_embed_64.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_CoWA_epochs.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_final_CoWA_bar.png"], ["experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_591f42447db143d5b74bcf7c71da5c49/dataset_train_loss_aggregated.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_591f42447db143d5b74bcf7c71da5c49/dataset_val_loss_aggregated.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_591f42447db143d5b74bcf7c71da5c49/dataset_CoWA_epochs_aggregated.png", "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_591f42447db143d5b74bcf7c71da5c49/dataset_final_CoWA_bar_aggregated.png"]], "plot_analyses": [[{"analysis": "This plot shows the training and validation loss over five epochs. The training loss starts at around 0.62 and gradually decreases to approximately 0.59, indicating that the model is learning from the training data. The validation loss, on the other hand, starts at about 0.54 and remains relatively stable, with a slight increase toward the end. The gap between training and validation loss suggests that while the model is improving on the training data, its generalization to unseen data is limited. This could indicate potential overfitting or insufficient learning of the task-specific features. Further investigation into hyperparameter tuning or regularization techniques might be necessary.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_543524ad2efd4fb5ac09e39248e2f5ae_proc_3066822/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot depicts the validation ACS (Accuracy with Contextual Sensitivity) over five epochs. The ACS metric starts at approximately 0.55 and shows minimal improvement, peaking at around 0.58 before slightly declining. The lack of significant improvement in ACS suggests that the model struggles to capture the contextual dependencies required for better performance on the SPR task. Enhancements in the contrastive learning framework or better data augmentation techniques might help improve this metric.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_543524ad2efd4fb5ac09e39248e2f5ae_proc_3066822/SPR_BENCH_ACS_curve.png"}, {"analysis": "The confusion matrix illustrates the model's classification performance. Out of all predictions, the model correctly classified 8849 instances as negative and 10082 as positive. However, there are 3651 false positives and 2418 false negatives. The relatively high number of false positives and false negatives indicates room for improvement in the model's ability to distinguish between classes. This could be addressed by refining the loss function or incorporating additional context-aware features into the model.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_543524ad2efd4fb5ac09e39248e2f5ae_proc_3066822/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The training loss plot shows that all learning rates lead to a decrease in loss over epochs, with faster convergence for higher learning rates (e.g., 0.002). However, the smallest learning rate (1e-04) converges much slower and remains higher compared to others, indicating suboptimal learning. The validation loss follows a similar trend, suggesting that the model generalizes well to unseen data across most learning rates, but the lowest learning rate struggles to keep up.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_38814c2557eb4f14a20d02938e4e5c62_proc_3071488/spr_loss_curves.png"}, {"analysis": "The validation ACS (Accuracy-Conditioned Score) plot reveals that the learning rate of 0.002 achieves the highest ACS at epoch 3, but its performance fluctuates significantly across epochs, indicating potential overfitting or instability. The learning rate of 0.001 shows more stable performance, with a gradual improvement over epochs. The smallest learning rates (1e-04 and 5e-04) exhibit consistently lower ACS, with limited improvement over epochs.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_38814c2557eb4f14a20d02938e4e5c62_proc_3071488/spr_val_ACS_curves.png"}, {"analysis": "The bar chart of final validation ACS per learning rate indicates that the learning rate of 0.001 achieves the best overall performance, followed closely by 0.002. The smaller learning rates (1e-04 and 5e-04) yield suboptimal results, likely due to insufficient weight updates during training. This suggests that 0.001 is the most balanced choice, offering both stability and effectiveness.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_38814c2557eb4f14a20d02938e4e5c62_proc_3071488/spr_final_ACS_bar.png"}], [{"analysis": "The first plot illustrates the training and validation loss curves for various batch sizes. Smaller batch sizes (e.g., 32 and 64) show higher initial losses but converge more quickly, while larger batch sizes (e.g., 256 and 512) start with lower initial losses but converge more slowly. This suggests that smaller batch sizes might be better for faster convergence but may result in noisier optimization. The validation loss is generally stable across epochs for all batch sizes, indicating no significant overfitting or underfitting issues.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c311401954be48cda04eb19659e5f496_proc_3071489/SPR_BENCH_loss_curves.png"}, {"analysis": "The second plot displays the Validation ACS (Accuracy per Class Score) across epochs for different batch sizes. Smaller batch sizes (32 and 64) achieve higher ACS values in the early epochs and maintain relatively consistent performance. In contrast, larger batch sizes (128, 256, and 512) show less consistent performance, with batch size 128 exhibiting a dip in ACS before recovering. This indicates that smaller batch sizes might be more effective for this task in terms of achieving higher ACS values.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c311401954be48cda04eb19659e5f496_proc_3071489/SPR_BENCH_ACS_curves.png"}, {"analysis": "The third plot shows the final validation accuracy for different batch sizes. However, the plot appears incomplete or incorrect, as it only shows values for a few batch sizes (e.g., 32, 64, and 128), and the accuracy values are not clearly distinguishable. This limits the ability to draw meaningful conclusions about the impact of batch size on final validation accuracy.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c311401954be48cda04eb19659e5f496_proc_3071489/SPR_BENCH_val_accuracy_by_batch_size.png"}], [], [{"analysis": "This plot illustrates the training loss across epochs for various weight decay (wd) values. The training loss decreases initially for all weight decay settings, indicating effective learning during the early epochs. However, after reaching a minimum, the training loss increases slightly for some configurations, such as wd=0.0 and wd=0.001, suggesting potential overfitting. The configuration with wd=0.0001 shows the most stable and lowest training loss, which might indicate that this weight decay value is optimal for generalization.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_train_loss_curve.png"}, {"analysis": "This plot shows the validation loss across epochs for different weight decay values. The validation loss remains relatively stable across epochs, with minor fluctuations. The configuration with wd=0.0001 achieves the lowest validation loss consistently, indicating better generalization to unseen data. In contrast, wd=0.001 and wd=1e-05 show higher validation losses, suggesting suboptimal generalization.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_val_loss_curve.png"}, {"analysis": "This plot depicts the validation ACS (Accuracy of Correct Sequences) across epochs for various weight decay values. The performance varies significantly across epochs, with wd=0.0001 consistently achieving the highest validation ACS. This indicates that this weight decay value enhances the model's ability to correctly classify sequences. Other configurations, such as wd=0.001, show lower and less stable performance, highlighting their inefficiency in optimizing this metric.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_val_ACS_curve.png"}, {"analysis": "The confusion matrix provides a detailed view of the classification results for the best-performing weight decay configuration (wd=0.0). The model correctly classifies 1790 instances of class 0 and 1975 instances of class 1, while misclassifying 710 and 525 instances, respectively. This suggests that the model performs better on class 1 (lower false negative rate) compared to class 0. However, there is still room for improvement in reducing misclassifications, particularly for class 0.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b06897d8cf714d7c9652a6297790e7db_proc_3071490/SPR_BENCH_confusion_matrix_wd_0.0.png"}], [{"analysis": "The training vs. validation loss plot shows that as the augmentation probability increases, the training loss remains relatively stable across epochs, while the validation loss exhibits more variability. This suggests that higher augmentation probabilities may be introducing noise that affects the model's ability to generalize. The stability of the training loss indicates that the model is learning effectively on the training data, but the validation performance might be hindered by the augmentation.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_loss_curves.png"}, {"analysis": "The ACS curves across epochs indicate that augmentation probabilities have varying impacts on ACS performance. Lower augmentation probabilities (p=0.0 to p=0.75) maintain relatively consistent ACS values, while the highest augmentation probability (p=1.0) shows a gradual increase in ACS across epochs but starts at a lower baseline. This suggests that high augmentation probabilities may initially disrupt the model's ability to extract meaningful features but allow for some recovery over time.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_ACS_curves.png"}, {"analysis": "The bar chart showing final ACS vs. augmentation probability reveals that ACS is relatively stable for augmentation probabilities from 0.0 to 0.75, with a slight decline at p=1.0. This indicates that moderate augmentation probabilities are effective in maintaining ACS, while excessive augmentation may degrade the model's ability to achieve high ACS.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_final_ACS.png"}, {"analysis": "The bar chart showing final accuracy vs. augmentation probability demonstrates that the final accuracy is highest for augmentation probabilities between 0.0 and 0.75, while p=1.0 leads to a significant drop in performance. This suggests that excessive augmentation may introduce too much noise or variability, negatively impacting the model's ability to generalize and perform well on the task.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9a0854679c17479e9e320e169b63e924_proc_3071488/SPR_BENCH_final_accuracy.png"}], [{"analysis": "The first plot shows the training and validation cross-entropy loss for different embedding dimensions (64, 128, 256) over five epochs. The training loss decreases consistently for all embedding dimensions, indicating that the model is learning. However, the validation loss remains relatively constant, suggesting potential overfitting or insufficient generalization. Among the embedding dimensions, emb_128 and emb_256 show slightly more stable validation loss compared to emb_64.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_0ba3ff0ff10646c6a7f63b666c7fa163_proc_3071489/embed_dim_sweep_loss_curves.png"}, {"analysis": "The second plot displays the Composite Weighted Accuracy (CoWA) for training and validation across epochs for different embedding dimensions. The training CoWA fluctuates for all embedding dimensions, especially for emb_128, which shows a significant dip at epoch 3. Validation CoWA for emb_64 and emb_256 remains relatively stable, with emb_64 achieving the highest validation CoWA at most epochs. This suggests that emb_64 may provide better generalization compared to emb_128 and emb_256.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_0ba3ff0ff10646c6a7f63b666c7fa163_proc_3071489/embed_dim_sweep_cowa_curves.png"}, {"analysis": "The third plot is a summary of the final validation CoWA for different embedding dimensions. Emb_64 achieves the highest validation CoWA (0.77), followed by emb_256 (0.76), and emb_128 (0.74). This reinforces the observation that emb_64 provides better performance in terms of generalization, while emb_128 performs the worst among the three embedding dimensions tested.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_0ba3ff0ff10646c6a7f63b666c7fa163_proc_3071489/embed_dim_sweep_cowa_summary.png"}], [{"analysis": "The cross-entropy loss for the embedding dimension of 128 shows a consistent decrease in the training loss, indicating that the model is learning. However, the validation loss remains relatively flat, which suggests that the model might not be generalizing well to unseen data. This could indicate a need for better regularization or data augmentation strategies.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_loss_embed_128.png"}, {"analysis": "For the embedding dimension of 256, the training loss decreases steadily, and the validation loss also shows a slight decrease. This indicates better generalization compared to the embedding dimension of 128. The model with this embedding size seems to be performing relatively well on both training and validation sets.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_loss_embed_256.png"}, {"analysis": "With an embedding dimension of 64, the training loss decreases, but the validation loss remains almost constant, similar to the behavior observed with the embedding dimension of 128. This suggests that the smaller embedding size might not be sufficient to capture the complexity of the data, leading to limited generalization.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_loss_embed_64.png"}, {"analysis": "The CoWA (Color-Weighted Accuracy) over epochs shows that the embedding dimension of 256 consistently performs better across epochs, maintaining a relatively stable and high CoWA. The embedding dimension of 128 shows improvement later in training, while the embedding dimension of 64 fluctuates significantly, indicating instability and poor performance.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_CoWA_epochs.png"}, {"analysis": "The bar plot for final CoWA by embedding size indicates that the embedding dimension of 128 achieves the highest CoWA, followed by 256 and then 64. This suggests that while 256 performed well during training, 128 might offer the best trade-off between performance and stability for this task.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_accc7227dc7845e69f15b6b88f30bd64_proc_3071487/synthetic_SPR_final_CoWA_bar.png"}], [{"analysis": "The loss curves for embedding dimension 128 show that the training loss decreases steadily, while the validation loss remains relatively flat with a slight upward trend. This indicates potential overfitting, as the model performs better on the training data but struggles to generalize to the validation set.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_loss_embed_128.png"}, {"analysis": "For embedding dimension 256, the training loss decreases more consistently compared to the validation loss, which shows a slight decrease followed by a plateau. This suggests that this embedding size might be better suited for the task, as the validation performance does not degrade significantly.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_loss_embed_256.png"}, {"analysis": "The loss curves for embedding dimension 64 show a consistent decrease in training loss, but the validation loss remains relatively flat, indicating limited generalization. This suggests that the smaller embedding size might not capture enough information for effective validation performance.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_loss_embed_64.png"}, {"analysis": "The CoWA over epochs plot highlights that the embedding dimension of 128 achieves the highest performance in later epochs, while 256 shows stable performance with less fluctuation. The embedding dimension of 64 has the lowest CoWA, suggesting it is less effective for this task.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_CoWA_epochs.png"}, {"analysis": "The final CoWA by embedding size bar chart confirms that embedding dimension 128 achieves the highest CoWA, followed by 256 and then 64. This reinforces the earlier observations that larger embedding dimensions tend to perform better for this task.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/synthetic_SPR_final_CoWA_bar.png"}], [{"analysis": "The loss curves for embedding dimension 128 show that the training loss decreases steadily over epochs, indicating the model is learning. However, the validation loss remains relatively constant after a slight increase, suggesting potential overfitting or an issue with generalization.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_loss_embed_128.png"}, {"analysis": "For embedding dimension 256, the training loss decreases smoothly, and the validation loss shows a slight downward trend after an initial increase. This suggests better generalization compared to embedding dimension 128, though the improvement is not substantial.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_loss_embed_256.png"}, {"analysis": "The loss curves for embedding dimension 64 indicate that training loss decreases, but the validation loss remains flat with a slight upward trend. This could imply underfitting or that the embedding size is too small to capture the necessary features effectively.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_loss_embed_64.png"}, {"analysis": "The CoWA performance over epochs reveals that embedding dimension 128 achieves the highest CoWA at the final epoch, while embedding dimension 64 performs the worst. This suggests that larger embedding dimensions (128 and 256) are more effective in capturing contextual information for the SPR task.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_CoWA_epochs.png"}, {"analysis": "The bar chart summarizing final CoWA by embedding size confirms that embedding dimension 128 yields the highest CoWA, followed closely by 256, with 64 trailing behind. This reinforces the observation that embedding dimension 128 is optimal among the tested configurations.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/synthetic_SPR_final_CoWA_bar.png"}], [{"analysis": "The loss curves for embedding dimension 128 show a consistent decline in training loss across epochs, indicating that the model is learning effectively. However, the validation loss remains relatively flat, suggesting potential overfitting or a lack of generalization to unseen data. The gap between training and validation loss is noticeable, which further supports this observation.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_loss_embed_128.png"}, {"analysis": "For embedding dimension 256, the training loss decreases steadily, and the validation loss shows a slight decline after an initial increase. This indicates marginal improvement in generalization compared to the embedding dimension 128. However, the gap between training and validation losses is still present, which could indicate suboptimal regularization or insufficient model capacity.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_loss_embed_256.png"}, {"analysis": "The loss curves for embedding dimension 64 show a relatively higher initial training loss, which decreases over epochs. The validation loss remains mostly flat with a slight increase towards the end. This suggests that the smaller embedding dimension might be insufficient to capture the complexity of the data, leading to underfitting.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_loss_embed_64.png"}, {"analysis": "The CoWA metric over epochs reveals that embedding dimension 128 achieves the highest final CoWA, with a steady improvement after epoch 3. Embedding dimension 256 shows a more stable CoWA trend but does not achieve the same peak as 128. Embedding dimension 64 has the lowest CoWA throughout, indicating that it is the least effective in this context.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_CoWA_epochs.png"}, {"analysis": "The bar plot comparing final CoWA across embedding dimensions confirms that embedding dimension 128 outperforms the others, followed by 256 and 64. This suggests that embedding dimension 128 provides the best balance between representation capacity and generalization for the SPR task.", "plot_path": "experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/synthetic_SPR_final_CoWA_bar.png"}], []], "vlm_feedback_summary": ["The plots reveal that while the model demonstrates some learning ability on the\ntraining data, its generalization to the validation set is limited. The\nvalidation ACS shows minimal improvement, and the confusion matrix highlights a\nsignificant number of misclassifications. These results suggest that further\noptimization of the contrastive learning framework and data augmentation\ntechniques is required to enhance the model's performance on the SPR task.", "The plots indicate that learning rate 0.001 provides the best trade-off between\nstability and performance, with consistent improvements in both loss and ACS\nmetrics. Higher learning rates such as 0.002 show potential but suffer from\ninstability, while lower learning rates are too slow to converge effectively.", "The plots provide insights into the effect of batch size on training and\nvalidation performance. Smaller batch sizes seem to favor faster convergence and\nhigher accuracy per class, while larger batch sizes exhibit slower convergence\nand inconsistent performance. The final validation accuracy plot is incomplete,\nwhich hampers a comprehensive evaluation of batch size impact.", "[]", "The plots suggest that a weight decay of 0.0001 performs best across training\nloss, validation loss, and validation ACS metrics. This configuration\ndemonstrates the most stable and generalizable performance. The confusion matrix\nfor the best-performing configuration (wd=0.0) reveals better performance on\nclass 1 compared to class 0, with some misclassifications remaining. Further\ntuning or architectural modifications may help address these misclassifications.", "The analysis of the provided plots indicates that moderate augmentation\nprobabilities (p=0.0 to p=0.75) are effective in maintaining both ACS and\naccuracy, while excessive augmentation (p=1.0) negatively impacts performance.\nThe stability of training loss across augmentation probabilities suggests\neffective learning on the training data, but the variability in validation loss\nand performance metrics highlights the trade-offs introduced by augmentation.", "The analysis highlights that emb_64 achieves the best validation performance in\nterms of both loss and accuracy metrics, suggesting it is the most effective\nembedding dimension for the current setup. Emb_128 shows instability and\nperforms the worst, while emb_256 provides slightly better results but still\nfalls short of emb_64.", "The results suggest that embedding dimensions of 128 and 256 perform better than\n64, with 128 achieving the highest final CoWA. The model with an embedding\ndimension of 256 shows the best generalization during training, while 64\nexhibits instability and poor performance. Further tuning or experimentation\nwith regularization techniques could help improve the generalization observed\nfor embedding dimension 128.", "The results suggest that embedding dimension 128 provides the best performance\noverall, achieving the highest CoWA and showing steady improvement over epochs.\nEmbedding dimension 256 also performs well but shows less improvement in later\nepochs. Embedding dimension 64 consistently underperforms, indicating that it\nmay not capture sufficient information for the task. Further tuning of\nhyperparameters and regularization techniques could help mitigate overfitting\nobserved in some cases.", "The analysis highlights that embedding dimension 128 provides the best\nperformance in terms of CoWA, with dimension 256 being slightly less effective.\nEmbedding dimension 64 underperforms, likely due to insufficient capacity to\ncapture complex patterns. The loss curves suggest that embedding dimension 256\ngeneralizes slightly better than 128, though both outperform 64. Further tuning\nor architectural adjustments may be needed to address generalization issues and\nvalidation loss trends.", "The plots indicate that embedding dimension 128 achieves the best performance,\nwith the highest CoWA and effective learning as shown by the loss curves.\nEmbedding dimension 256 performs slightly worse but is more stable, while\nembedding dimension 64 underperforms due to underfitting. The results suggest\nthat embedding dimension plays a critical role in optimizing model performance\nfor the SPR task.", "[]"], "exec_time": [17.073505401611328, 60.38750123977661, 76.46411776542664, 1.3335192203521729, 501.77070784568787, 56.05903363227844, 25.72123694419861, 39.044650077819824, 45.383474588394165, 30.920567989349365, 28.595328092575073, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[]"], ["[\"Synthetic SPR Dataset\"]"], ["[\"SPR_BENCH\"]"], [], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["['emb_64']"], ["['synthetic_SPR']"], ["['synthetic_SPR']"], ["[\"synthetic_SPR\"]"], ["['synthetic_SPR']"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    exp_path = os.path.join(working_dir, \"experiment_data.npy\")\n    experiment_data = np.load(exp_path, allow_pickle=True).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- iterate through datasets ----------\nfor dset_name, dset in experiment_data.items():\n    metrics = dset.get(\"metrics\", {})\n    preds = np.array(dset.get(\"predictions\", []))\n    gts = np.array(dset.get(\"ground_truth\", []))\n\n    # ---- 1) train/val loss ----\n    try:\n        train_loss = np.array(\n            metrics.get(\"train_loss\", [])\n        )  # shape (N,2) [epoch, value]\n        val_loss = np.array(metrics.get(\"val_loss\", []))\n        if train_loss.size and val_loss.size:\n            plt.figure()\n            plt.plot(train_loss[:, 0], train_loss[:, 1], label=\"Train Loss\")\n            plt.plot(val_loss[:, 0], val_loss[:, 1], label=\"Validation Loss\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.title(\n                f\"{dset_name}: Training vs Validation Loss\\n(Left: Ground Truth, Right: Generated Samples)\"\n            )\n            plt.legend()\n            fname = f\"{dset_name}_loss_curves.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {dset_name}: {e}\")\n        plt.close()\n\n    # ---- 2) validation ACS ----\n    try:\n        val_acs = np.array(metrics.get(\"val_ACS\", []))\n        if val_acs.size:\n            plt.figure()\n            plt.plot(val_acs[:, 0], val_acs[:, 1], marker=\"o\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"ACS\")\n            plt.ylim(0, 1)\n            plt.title(\n                f\"{dset_name}: Validation ACS over Epochs\\n(Left: Ground Truth, Right: Generated Samples)\"\n            )\n            fname = f\"{dset_name}_ACS_curve.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating ACS plot for {dset_name}: {e}\")\n        plt.close()\n\n    # ---- 3) confusion matrix ----\n    try:\n        if preds.size and gts.size:\n            num_classes = max(max(preds), max(gts)) + 1\n            cm = np.zeros((num_classes, num_classes), dtype=int)\n            for p, g in zip(preds, gts):\n                cm[g, p] += 1\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(\n                f\"{dset_name}: Confusion Matrix\\n(Left: Ground Truth, Right: Generated Samples)\"\n            )\n            for i in range(num_classes):\n                for j in range(num_classes):\n                    plt.text(\n                        j,\n                        i,\n                        cm[i, j],\n                        ha=\"center\",\n                        va=\"center\",\n                        color=\"black\",\n                        fontsize=8,\n                    )\n            fname = f\"{dset_name}_confusion_matrix.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dset_name}: {e}\")\n        plt.close()\n\nprint(\"Finished saving plots to\", working_dir)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---- working dir ----\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---- load data ----\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nlr_sweep = experiment_data.get(\"lr_sweep\", {})\nlrs = sorted(lr_sweep.keys())  # keep a consistent order\n\n\n# helper to extract metric list -> two arrays\ndef metric_xy(lr_key, metric_name):\n    vals = lr_sweep[lr_key][\"metrics\"][metric_name]\n    if not vals:\n        return [], []\n    x, y = zip(*vals)\n    return list(x), list(y)\n\n\nfinal_acs = {}\n\n# ---- Figure 1: train/val loss curves ----\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n    for lr_key in lrs[:]:  # all lrs but still <=4, so OK\n        x_tr, y_tr = metric_xy(lr_key, \"train_loss\")\n        x_v, y_v = metric_xy(lr_key, \"val_loss\")\n        axes[0].plot(x_tr, y_tr, label=lr_key)\n        axes[1].plot(x_v, y_v, label=lr_key)\n    axes[0].set_title(\"Train Loss\")\n    axes[1].set_title(\"Validation Loss\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[1].set_ylabel(\"Loss\")\n    axes[0].legend()\n    axes[1].legend()\n    fig.suptitle(\"Synthetic SPR Dataset \u2013 Left: Train, Right: Validation Loss\")\n    fig.tight_layout(rect=[0, 0, 1, 0.95])\n    out_path = os.path.join(working_dir, \"spr_loss_curves.png\")\n    plt.savefig(out_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---- Figure 2: validation ACS curves ----\ntry:\n    plt.figure(figsize=(6, 4))\n    for lr_key in lrs:\n        x_ac, y_ac = metric_xy(lr_key, \"val_ACS\")\n        plt.plot(x_ac, y_ac, marker=\"o\", label=lr_key)\n        if x_ac:\n            final_acs[lr_key] = y_ac[-1]\n    plt.title(\"Synthetic SPR Dataset \u2013 Validation ACS over Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"ACS\")\n    plt.legend()\n    plt.tight_layout()\n    out_path = os.path.join(working_dir, \"spr_val_ACS_curves.png\")\n    plt.savefig(out_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating ACS curves: {e}\")\n    plt.close()\n\n# ---- Figure 3: final ACS bar chart ----\ntry:\n    if final_acs:\n        plt.figure(figsize=(6, 4))\n        lr_names = list(final_acs.keys())\n        acs_vals = [final_acs[k] for k in lr_names]\n        plt.bar(range(len(lr_names)), acs_vals)\n        plt.xticks(range(len(lr_names)), lr_names, rotation=45)\n        plt.ylabel(\"Final Validation ACS\")\n        plt.title(\"Synthetic SPR Dataset \u2013 Final ACS per Learning-Rate\")\n        plt.tight_layout()\n        out_path = os.path.join(working_dir, \"spr_final_ACS_bar.png\")\n        plt.savefig(out_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final ACS bar: {e}\")\n    plt.close()\n\n# ---- print evaluation metrics ----\nif final_acs:\n    print(\"Final Validation ACS per learning rate:\")\n    for k, v in final_acs.items():\n        print(f\"  {k}: {v:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    losses_tr = experiment_data[\"batch_size\"][\"SPR_BENCH\"][\"losses\"][\"train\"]\n    losses_va = experiment_data[\"batch_size\"][\"SPR_BENCH\"][\"losses\"][\"val\"]\n    acs_va = experiment_data[\"batch_size\"][\"SPR_BENCH\"][\"metrics\"][\"val\"]\n    preds_all = experiment_data[\"batch_size\"][\"SPR_BENCH\"][\"predictions\"]\n    gts_all = experiment_data[\"batch_size\"][\"SPR_BENCH\"][\"ground_truth\"]\n\n    # collect unique batch sizes\n    bs_list = sorted({bs for bs, _, _ in losses_tr})\n\n    # -------- plot 1 : loss curves --------\n    try:\n        plt.figure(figsize=(6, 4))\n        for bs in bs_list:\n            x_tr = [ep for b, ep, _ in losses_tr if b == bs]\n            y_tr = [vl for b, _, vl in losses_tr if b == bs]\n            x_va = [ep for b, ep, _ in losses_va if b == bs]\n            y_va = [vl for b, _, vl in losses_va if b == bs]\n            plt.plot(x_tr, y_tr, label=f\"train bs={bs}\")\n            plt.plot(x_va, y_va, \"--\", label=f\"val bs={bs}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # -------- plot 2 : ACS curves --------\n    try:\n        plt.figure(figsize=(6, 4))\n        for bs in bs_list:\n            x_acs = [ep for b, ep, _ in acs_va if b == bs]\n            y_acs = [vl for b, _, vl in acs_va if b == bs]\n            plt.plot(x_acs, y_acs, marker=\"o\", label=f\"bs={bs}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"ACS\")\n        plt.title(\"SPR_BENCH: Validation ACS Across Epochs\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_ACS_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating ACS plot: {e}\")\n        plt.close()\n\n    # -------- plot 3 : accuracy per batch size --------\n    try:\n        # compute accuracy\n        acc_dict = {bs: [0, 0] for bs in bs_list}  # correct, total\n        for (bs, pred), gt in zip(preds_all, gts_all):\n            acc_dict[bs][1] += 1\n            if pred == gt:\n                acc_dict[bs][0] += 1\n        acc_pct = {bs: (c / t if t else 0.0) for bs, (c, t) in acc_dict.items()}\n\n        plt.figure(figsize=(6, 4))\n        plt.bar(list(acc_pct.keys()), list(acc_pct.values()), color=\"skyblue\")\n        plt.ylim(0, 1)\n        plt.xlabel(\"Batch Size\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH: Final Validation Accuracy by Batch Size\")\n        plt.tight_layout()\n        plt.savefig(\n            os.path.join(working_dir, \"SPR_BENCH_val_accuracy_by_batch_size.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot: {e}\")\n        plt.close()\n\n    # ---------- print evaluation metric ----------\n    print(\n        \"Validation accuracy per batch size:\",\n        {bs: round(acc_pct[bs], 4) for bs in bs_list},\n    )\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# helper: collect metric arrays for each wd\nmetric_names = [\"train_loss\", \"val_loss\", \"val_ACS\"]\nmetrics = {m: {} for m in metric_names}  # e.g. metrics['train_loss'][wd]=([ep],[vals])\n\nfor wd, runs in experiment_data.get(\"weight_decay\", {}).items():\n    mdict = runs[\"SPR_BENCH\"][\"metrics\"]\n    for m in metric_names:\n        ep, vals = zip(*mdict[m]) if mdict[m] else ([], [])\n        metrics[m][wd] = (np.array(ep), np.array(vals))\n\n# ------------- PLOT 1\u20133: curves -----------------\nplot_info = [\n    (\"train_loss\", \"Training Loss vs Epochs\"),\n    (\"val_loss\", \"Validation Loss vs Epochs\"),\n    (\"val_ACS\", \"Validation ACS vs Epochs\"),\n]\n\nfor m, title in plot_info:\n    try:\n        plt.figure()\n        for wd, (ep, vals) in metrics[m].items():\n            plt.plot(ep, vals, label=f\"wd={wd}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(m)\n        plt.title(f\"SPR_BENCH: {title}\")\n        plt.legend()\n        fname = f\"SPR_BENCH_{m}_curve.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating plot for {m}: {e}\")\n        plt.close()\n\n# ------------- PLOT 4: confusion matrix for best run -------------\ntry:\n    # pick wd with lowest final val_loss\n    best_wd = None\n    best_loss = float(\"inf\")\n    for wd, (ep, vals) in metrics[\"val_loss\"].items():\n        if len(vals) and vals[-1] < best_loss:\n            best_loss = vals[-1]\n            best_wd = wd\n    if best_wd is not None:\n        run = experiment_data[\"weight_decay\"][best_wd][\"SPR_BENCH\"]\n        preds = run[\"predictions\"]\n        gts = run[\"ground_truth\"]\n        epochs = len(run[\"metrics\"][\"val_loss\"])\n        dev_size = len(gts) // epochs if epochs else 0\n        preds = np.array(preds[-dev_size:])\n        gts = np.array(gts[-dev_size:])\n        num_cls = max(gts.max(), preds.max()) + 1\n        cm = np.zeros((num_cls, num_cls), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n\n        plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.title(f\"SPR_BENCH Confusion Matrix (best wd={best_wd})\")\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        for i in range(num_cls):\n            for j in range(num_cls):\n                plt.text(\n                    j,\n                    i,\n                    cm[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"white\" if cm[i, j] > cm.max() * 0.6 else \"black\",\n                )\n        fname = f\"SPR_BENCH_confusion_matrix_wd_{best_wd}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    sweep = experiment_data[\"aug_probability\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    sweep = {}\n\n# containers for summary\nfinal_ACS, final_acc = {}, {}\n\n# iterate once to collect summary stats\nfor prob, run in sweep.items():\n    # unpack tuples -> arrays\n    epochs, acs_vals = zip(*run[\"val_ACS\"])\n    preds, gts = np.array(run[\"predictions\"]), np.array(run[\"ground_truth\"])\n    final_ACS[prob] = acs_vals[-1]\n    final_acc[prob] = (preds == gts).mean()\n\n# ---------- 1) Loss curves ----------\ntry:\n    plt.figure(figsize=(6, 4))\n    for prob, run in sweep.items():\n        ep, tr = zip(*run[\"train_loss\"])\n        _, va = zip(*run[\"val_loss\"])\n        plt.plot(ep, tr, \"--\", label=f\"train p={prob}\")\n        plt.plot(ep, va, \"-\", label=f\"val p={prob}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ---------- 2) ACS curves ----------\ntry:\n    plt.figure(figsize=(6, 4))\n    for prob, run in sweep.items():\n        ep, acs = zip(*run[\"val_ACS\"])\n        plt.plot(ep, acs, label=f\"p={prob}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"ACS\")\n    plt.title(\"SPR_BENCH: ACS Curves Across Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_ACS_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating ACS curve plot: {e}\")\n    plt.close()\n\n# ---------- 3) Final ACS bar chart ----------\ntry:\n    plt.figure(figsize=(5, 4))\n    probs = list(final_ACS.keys())\n    vals = [final_ACS[p] for p in probs]\n    plt.bar([str(p) for p in probs], vals, color=\"skyblue\")\n    plt.xlabel(\"Augmentation Probability\")\n    plt.ylabel(\"Final ACS\")\n    plt.title(\"SPR_BENCH: Final ACS vs Augmentation Probability\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_ACS.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final ACS bar chart: {e}\")\n    plt.close()\n\n# ---------- 4) Final Accuracy bar chart ----------\ntry:\n    plt.figure(figsize=(5, 4))\n    vals = [final_acc[p] for p in probs]\n    plt.bar([str(p) for p in probs], vals, color=\"salmon\")\n    plt.xlabel(\"Augmentation Probability\")\n    plt.ylabel(\"Final Accuracy\")\n    plt.title(\"SPR_BENCH: Final Accuracy vs Augmentation Probability\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_accuracy.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final accuracy bar chart: {e}\")\n    plt.close()\n\n# ---------- print metrics ----------\nprint(\"\\n=== Final Metrics ===\")\nfor p in sorted(final_ACS):\n    print(f\"p={p:>4} | ACS={final_ACS[p]:.4f} | Acc={final_acc[p]:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------\n# paths / data load\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# helper to fetch lists of (epoch,value) as np arrays\ndef get_xy(run_store, key):\n    # run_store['losses']['train'] etc. -> list[(epoch,val)]\n    arr = np.array(run_store[key])\n    return arr[:, 0], arr[:, 1]\n\n\n# collect final val CoWA for summary printing / bar chart\nfinal_cowa = {}\n\n# ---------------------------------------------------------------\n# Plot 1: Train vs Val Loss curves per embedding dimension\n# ---------------------------------------------------------------\ntry:\n    plt.figure()\n    for emb_key, run in experiment_data.get(\"embed_dim_sweep\", {}).items():\n        x_tr, y_tr = get_xy(run[\"losses\"], \"train\")\n        x_va, y_va = get_xy(run[\"losses\"], \"val\")\n        plt.plot(x_tr, y_tr, marker=\"o\", label=f\"{emb_key}-train\")\n        plt.plot(x_va, y_va, marker=\"x\", linestyle=\"--\", label=f\"{emb_key}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"Embed Dim Sweep: Training vs Validation Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"embed_dim_sweep_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------\n# Plot 2: Train vs Val CoWA curves per embedding dimension\n# ---------------------------------------------------------------\ntry:\n    plt.figure()\n    for emb_key, run in experiment_data.get(\"embed_dim_sweep\", {}).items():\n        x_tr, y_tr = get_xy(run[\"metrics\"], \"CoWA_train\")\n        x_va, y_va = get_xy(run[\"metrics\"], \"CoWA_val\")\n        plt.plot(x_tr, y_tr, marker=\"o\", label=f\"{emb_key}-train\")\n        plt.plot(x_va, y_va, marker=\"x\", linestyle=\"--\", label=f\"{emb_key}-val\")\n        # save final val CoWA for summary\n        final_cowa[emb_key] = y_va[-1] if len(y_va) else np.nan\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Composite Weighted Accuracy\")\n    plt.title(\"Embed Dim Sweep: Training vs Validation CoWA\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"embed_dim_sweep_cowa_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CoWA curves: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------\n# Plot 3: Bar chart of final validation CoWA per embedding dim\n# ---------------------------------------------------------------\ntry:\n    if final_cowa:\n        plt.figure()\n        dims = list(final_cowa.keys())\n        values = [final_cowa[d] for d in dims]\n        plt.bar(dims, values, color=\"skyblue\")\n        plt.ylim(0, 1)\n        plt.ylabel(\"Final Validation CoWA\")\n        plt.title(\"Embed Dim Sweep: Final Validation CoWA Summary\")\n        for i, v in enumerate(values):\n            plt.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n        fname = os.path.join(working_dir, \"embed_dim_sweep_cowa_summary.png\")\n        plt.savefig(fname)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating CoWA summary bar chart: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------\n# Print final metrics\n# ---------------------------------------------------------------\nif final_cowa:\n    print(\"Final Validation CoWA by embedding dimension:\")\n    for k, v in final_cowa.items():\n        print(f\"  {k}: {v:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# --------------------- load data ---------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ntuning = experiment_data.get(\"embed_dim_tuning\", {})\nembed_keys = sorted(tuning.keys())  # e.g. ['embed_64', ...]\ndataset_name = \"synthetic_SPR\"  # underlying dataset\n\n\n# --------------------- helper ------------------------\ndef unpack(run_store, path):\n    \"\"\"path like ('losses','train') returns epoch list, value list\"\"\"\n    items = run_store\n    for p in path:\n        items = items[p]\n    epochs, vals = zip(*items)\n    return np.array(epochs), np.array(vals)\n\n\nplot_count = 0\nmax_plots = 5\n\n# ------------- 1-3: loss curves per embedding --------\nfor k in embed_keys:\n    if plot_count >= max_plots:\n        break\n    try:\n        run = tuning[k]\n        ep_tr, tr_loss = unpack(run, (\"losses\", \"train\"))\n        ep_va, va_loss = unpack(run, (\"losses\", \"val\"))\n        plt.figure()\n        plt.plot(ep_tr, tr_loss, label=\"Train\")\n        plt.plot(ep_va, va_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f'Loss Curves ({dataset_name})\\nEmbedding dim = {k.split(\"_\")[1]}')\n        plt.legend()\n        fname = f\"{dataset_name}_loss_{k}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {k}: {e}\")\n        plt.close()\n    plot_count += 1\n\n# ------------- 4: CoWA vs epoch across dims ----------\nif plot_count < max_plots:\n    try:\n        plt.figure()\n        for k in embed_keys:\n            ep, cowa = unpack(tuning[k], (\"metrics\", \"CoWA\"))\n            plt.plot(ep, cowa, label=k.split(\"_\")[1])\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CoWA\")\n        plt.title(\n            f\"CoWA over Epochs ({dataset_name})\\nLeft: Ground Truth, Right: Generated Samples\"\n        )\n        plt.legend(title=\"Embed dim\")\n        fname = f\"{dataset_name}_CoWA_epochs.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CoWA comparison plot: {e}\")\n        plt.close()\n    plot_count += 1\n\n# ------------- 5: final CoWA bar chart ---------------\nif plot_count < max_plots:\n    try:\n        dims, finals = [], []\n        for k in embed_keys:\n            dims.append(k.split(\"_\")[1])\n            finals.append(unpack(tuning[k], (\"metrics\", \"CoWA\"))[1][-1])\n        x = np.arange(len(dims))\n        plt.figure()\n        plt.bar(x, finals, color=\"skyblue\")\n        plt.xticks(x, dims)\n        plt.xlabel(\"Embedding Dimension\")\n        plt.ylabel(\"Final CoWA\")\n        plt.title(f\"Final CoWA by Embedding Size ({dataset_name})\")\n        fname = f\"{dataset_name}_final_CoWA_bar.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating final CoWA bar chart: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# --------------------- load data ---------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ntuning = experiment_data.get(\"embed_dim_tuning\", {})\nembed_keys = sorted(tuning.keys())  # e.g. ['embed_64', ...]\ndataset_name = \"synthetic_SPR\"  # underlying dataset\n\n\n# --------------------- helper ------------------------\ndef unpack(run_store, path):\n    \"\"\"path like ('losses','train') returns epoch list, value list\"\"\"\n    items = run_store\n    for p in path:\n        items = items[p]\n    epochs, vals = zip(*items)\n    return np.array(epochs), np.array(vals)\n\n\nplot_count = 0\nmax_plots = 5\n\n# ------------- 1-3: loss curves per embedding --------\nfor k in embed_keys:\n    if plot_count >= max_plots:\n        break\n    try:\n        run = tuning[k]\n        ep_tr, tr_loss = unpack(run, (\"losses\", \"train\"))\n        ep_va, va_loss = unpack(run, (\"losses\", \"val\"))\n        plt.figure()\n        plt.plot(ep_tr, tr_loss, label=\"Train\")\n        plt.plot(ep_va, va_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f'Loss Curves ({dataset_name})\\nEmbedding dim = {k.split(\"_\")[1]}')\n        plt.legend()\n        fname = f\"{dataset_name}_loss_{k}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {k}: {e}\")\n        plt.close()\n    plot_count += 1\n\n# ------------- 4: CoWA vs epoch across dims ----------\nif plot_count < max_plots:\n    try:\n        plt.figure()\n        for k in embed_keys:\n            ep, cowa = unpack(tuning[k], (\"metrics\", \"CoWA\"))\n            plt.plot(ep, cowa, label=k.split(\"_\")[1])\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CoWA\")\n        plt.title(\n            f\"CoWA over Epochs ({dataset_name})\\nLeft: Ground Truth, Right: Generated Samples\"\n        )\n        plt.legend(title=\"Embed dim\")\n        fname = f\"{dataset_name}_CoWA_epochs.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CoWA comparison plot: {e}\")\n        plt.close()\n    plot_count += 1\n\n# ------------- 5: final CoWA bar chart ---------------\nif plot_count < max_plots:\n    try:\n        dims, finals = [], []\n        for k in embed_keys:\n            dims.append(k.split(\"_\")[1])\n            finals.append(unpack(tuning[k], (\"metrics\", \"CoWA\"))[1][-1])\n        x = np.arange(len(dims))\n        plt.figure()\n        plt.bar(x, finals, color=\"skyblue\")\n        plt.xticks(x, dims)\n        plt.xlabel(\"Embedding Dimension\")\n        plt.ylabel(\"Final CoWA\")\n        plt.title(f\"Final CoWA by Embedding Size ({dataset_name})\")\n        fname = f\"{dataset_name}_final_CoWA_bar.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating final CoWA bar chart: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# --------------------- load data ---------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ntuning = experiment_data.get(\"embed_dim_tuning\", {})\nembed_keys = sorted(tuning.keys())  # e.g. ['embed_64', ...]\ndataset_name = \"synthetic_SPR\"  # underlying dataset\n\n\n# --------------------- helper ------------------------\ndef unpack(run_store, path):\n    \"\"\"path like ('losses','train') returns epoch list, value list\"\"\"\n    items = run_store\n    for p in path:\n        items = items[p]\n    epochs, vals = zip(*items)\n    return np.array(epochs), np.array(vals)\n\n\nplot_count = 0\nmax_plots = 5\n\n# ------------- 1-3: loss curves per embedding --------\nfor k in embed_keys:\n    if plot_count >= max_plots:\n        break\n    try:\n        run = tuning[k]\n        ep_tr, tr_loss = unpack(run, (\"losses\", \"train\"))\n        ep_va, va_loss = unpack(run, (\"losses\", \"val\"))\n        plt.figure()\n        plt.plot(ep_tr, tr_loss, label=\"Train\")\n        plt.plot(ep_va, va_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f'Loss Curves ({dataset_name})\\nEmbedding dim = {k.split(\"_\")[1]}')\n        plt.legend()\n        fname = f\"{dataset_name}_loss_{k}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {k}: {e}\")\n        plt.close()\n    plot_count += 1\n\n# ------------- 4: CoWA vs epoch across dims ----------\nif plot_count < max_plots:\n    try:\n        plt.figure()\n        for k in embed_keys:\n            ep, cowa = unpack(tuning[k], (\"metrics\", \"CoWA\"))\n            plt.plot(ep, cowa, label=k.split(\"_\")[1])\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CoWA\")\n        plt.title(\n            f\"CoWA over Epochs ({dataset_name})\\nLeft: Ground Truth, Right: Generated Samples\"\n        )\n        plt.legend(title=\"Embed dim\")\n        fname = f\"{dataset_name}_CoWA_epochs.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CoWA comparison plot: {e}\")\n        plt.close()\n    plot_count += 1\n\n# ------------- 5: final CoWA bar chart ---------------\nif plot_count < max_plots:\n    try:\n        dims, finals = [], []\n        for k in embed_keys:\n            dims.append(k.split(\"_\")[1])\n            finals.append(unpack(tuning[k], (\"metrics\", \"CoWA\"))[1][-1])\n        x = np.arange(len(dims))\n        plt.figure()\n        plt.bar(x, finals, color=\"skyblue\")\n        plt.xticks(x, dims)\n        plt.xlabel(\"Embedding Dimension\")\n        plt.ylabel(\"Final CoWA\")\n        plt.title(f\"Final CoWA by Embedding Size ({dataset_name})\")\n        fname = f\"{dataset_name}_final_CoWA_bar.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating final CoWA bar chart: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# --------------------- load data ---------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ntuning = experiment_data.get(\"embed_dim_tuning\", {})\nembed_keys = sorted(tuning.keys())  # e.g. ['embed_64', ...]\ndataset_name = \"synthetic_SPR\"  # underlying dataset\n\n\n# --------------------- helper ------------------------\ndef unpack(run_store, path):\n    \"\"\"path like ('losses','train') returns epoch list, value list\"\"\"\n    items = run_store\n    for p in path:\n        items = items[p]\n    epochs, vals = zip(*items)\n    return np.array(epochs), np.array(vals)\n\n\nplot_count = 0\nmax_plots = 5\n\n# ------------- 1-3: loss curves per embedding --------\nfor k in embed_keys:\n    if plot_count >= max_plots:\n        break\n    try:\n        run = tuning[k]\n        ep_tr, tr_loss = unpack(run, (\"losses\", \"train\"))\n        ep_va, va_loss = unpack(run, (\"losses\", \"val\"))\n        plt.figure()\n        plt.plot(ep_tr, tr_loss, label=\"Train\")\n        plt.plot(ep_va, va_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f'Loss Curves ({dataset_name})\\nEmbedding dim = {k.split(\"_\")[1]}')\n        plt.legend()\n        fname = f\"{dataset_name}_loss_{k}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {k}: {e}\")\n        plt.close()\n    plot_count += 1\n\n# ------------- 4: CoWA vs epoch across dims ----------\nif plot_count < max_plots:\n    try:\n        plt.figure()\n        for k in embed_keys:\n            ep, cowa = unpack(tuning[k], (\"metrics\", \"CoWA\"))\n            plt.plot(ep, cowa, label=k.split(\"_\")[1])\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CoWA\")\n        plt.title(\n            f\"CoWA over Epochs ({dataset_name})\\nLeft: Ground Truth, Right: Generated Samples\"\n        )\n        plt.legend(title=\"Embed dim\")\n        fname = f\"{dataset_name}_CoWA_epochs.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CoWA comparison plot: {e}\")\n        plt.close()\n    plot_count += 1\n\n# ------------- 5: final CoWA bar chart ---------------\nif plot_count < max_plots:\n    try:\n        dims, finals = [], []\n        for k in embed_keys:\n            dims.append(k.split(\"_\")[1])\n            finals.append(unpack(tuning[k], (\"metrics\", \"CoWA\"))[1][-1])\n        x = np.arange(len(dims))\n        plt.figure()\n        plt.bar(x, finals, color=\"skyblue\")\n        plt.xticks(x, dims)\n        plt.xlabel(\"Embedding Dimension\")\n        plt.ylabel(\"Final CoWA\")\n        plt.title(f\"Final CoWA by Embedding Size ({dataset_name})\")\n        fname = f\"{dataset_name}_final_CoWA_bar.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating final CoWA bar chart: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------- set up -------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --------- load all experiment_data.npy --------\nexperiment_data_path_list = [\n    \"experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f3a89b2e29f9428dbe2bd53139c15b3d_proc_3071489/experiment_data.npy\",\n    \"experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1015f05b31df4338b08e899490c83d7c_proc_3071487/experiment_data.npy\",\n    \"experiments/2025-08-16_00-47-34_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8df468bebbf549a79b2d3fd4f5dd4c29_proc_3071488/experiment_data.npy\",\n]\n\nall_experiment_data = []\nfor p in experiment_data_path_list:\n    try:\n        exp = np.load(\n            os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p), allow_pickle=True\n        ).item()\n        all_experiment_data.append(exp)\n    except Exception as e:\n        print(f\"Error loading {p}: {e}\")\n\nif len(all_experiment_data) == 0:\n    print(\"No experiment data could be loaded; aborting plots.\")\n    exit()\n\n# assume same dataset name across runs\ndataset_name = list(all_experiment_data[0].get(\"embed_dim_tuning\", {}).values())[0].get(\n    \"dataset_name\", \"dataset\"\n)\n\n\n# ---------------- helper ----------------------\ndef unpack(run_store, path):\n    \"\"\"path like ('losses','train') returns epoch list, value list\"\"\"\n    items = run_store\n    for p in path:\n        items = items[p]\n    epochs, vals = zip(*items)\n    return np.array(epochs), np.array(vals)\n\n\n# Collect union of all embedding keys\nembed_keys = sorted(\n    {k for exp in all_experiment_data for k in exp.get(\"embed_dim_tuning\", {})}\n)\n\n# -------------------------------------------------------\n# 1) Aggregated train / val loss with stderr\n# -------------------------------------------------------\ntry:\n    for loss_split, color in [(\"train\", \"tab:blue\"), (\"val\", \"tab:orange\")]:\n        plt.figure()\n        for k in embed_keys:\n            stacks = []\n            for exp in all_experiment_data:\n                tuning = exp.get(\"embed_dim_tuning\", {})\n                if k not in tuning:  # key missing in this run\n                    break\n            else:\n                # every run has this key\n                epochs = None\n                for exp in all_experiment_data:\n                    ep, vals = unpack(\n                        exp[\"embed_dim_tuning\"][k], (\"losses\", loss_split)\n                    )\n                    if epochs is None:\n                        epochs = ep\n                    stacks.append(vals)\n                mat = np.vstack(stacks)\n                mean = mat.mean(axis=0)\n                stderr = mat.std(axis=0, ddof=1) / np.sqrt(mat.shape[0])\n                plt.plot(epochs, mean, label=f\"{k.split('_')[1]}d mean\")\n                plt.fill_between(epochs, mean - stderr, mean + stderr, alpha=0.2)\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{loss_split.capitalize()} Loss (Aggregated) ({dataset_name})\")\n        plt.legend(title=\"Embedding dim\")\n        fname = f\"{dataset_name}_{loss_split}_loss_aggregated.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated loss plots: {e}\")\n    plt.close()\n\n# -------------------------------------------------------\n# 2) Aggregated CoWA vs. epoch\n# -------------------------------------------------------\ntry:\n    plt.figure()\n    for k in embed_keys:\n        stacks = []\n        for exp in all_experiment_data:\n            tuning = exp.get(\"embed_dim_tuning\", {})\n            if k not in tuning:\n                break\n        else:\n            epochs = None\n            for exp in all_experiment_data:\n                ep, vals = unpack(exp[\"embed_dim_tuning\"][k], (\"metrics\", \"CoWA\"))\n                if epochs is None:\n                    epochs = ep\n                stacks.append(vals)\n            mat = np.vstack(stacks)\n            mean = mat.mean(0)\n            stderr = mat.std(0, ddof=1) / np.sqrt(mat.shape[0])\n            plt.plot(epochs, mean, label=f\"{k.split('_')[1]}d mean\")\n            plt.fill_between(epochs, mean - stderr, mean + stderr, alpha=0.2)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CoWA\")\n    plt.title(\n        f\"CoWA over Epochs (Aggregated) ({dataset_name})\\nLeft: Ground Truth, Right: Generated Samples\"\n    )\n    plt.legend(title=\"Embed dim\")\n    fname = f\"{dataset_name}_CoWA_epochs_aggregated.png\"\n    plt.savefig(os.path.join(working_dir, fname))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated CoWA plot: {e}\")\n    plt.close()\n\n# -------------------------------------------------------\n# 3) Final-epoch CoWA bar chart with error bars\n# -------------------------------------------------------\nfinal_results = {}\ntry:\n    dims, means, errs = [], [], []\n    for k in embed_keys:\n        finals = []\n        for exp in all_experiment_data:\n            tuning = exp.get(\"embed_dim_tuning\", {})\n            if k not in tuning:\n                break\n        else:\n            for exp in all_experiment_data:\n                finals.append(\n                    unpack(exp[\"embed_dim_tuning\"][k], (\"metrics\", \"CoWA\"))[1][-1]\n                )\n            finals = np.array(finals)\n            dim = k.split(\"_\")[1]\n            dims.append(dim)\n            means.append(finals.mean())\n            errs.append(finals.std(ddof=1) / np.sqrt(len(finals)))\n            final_results[dim] = (means[-1], errs[-1])\n    x = np.arange(len(dims))\n    plt.figure()\n    plt.bar(x, means, yerr=errs, capsize=5, color=\"skyblue\", alpha=0.8)\n    plt.xticks(x, dims)\n    plt.xlabel(\"Embedding Dimension\")\n    plt.ylabel(\"Final CoWA\")\n    plt.title(f\"Final CoWA by Embedding Size (Aggregated) ({dataset_name})\")\n    fname = f\"{dataset_name}_final_CoWA_bar_aggregated.png\"\n    plt.savefig(os.path.join(working_dir, fname))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated final CoWA bar chart: {e}\")\n    plt.close()\n\n# ------------------- print summary --------------------\nprint(\"Final CoWA (mean \u00b1 stderr):\")\nfor dim, (m, s) in final_results.items():\n    print(f\"  {dim}d : {m:.4f} \u00b1 {s:.4f}\")\n"], "plot_plan": ["We first load experiment_data.npy from the working directory, safely handling any loading failures. For every dataset stored inside the file (here only \u201cSPR_BENCH\u201d), we extract the metric tuples into plain numpy arrays so they can be plotted. We then create at most three standard visualizations: (1) training-vs-validation loss across epochs, (2) validation ACS across epochs, and (3) a confusion-matrix style heat-map comparing final predictions with ground-truth labels. Each plot is wrapped in a separate try-except block, saved with a descriptive name that contains the dataset and plot type, given a clear title and subtitle, and the figure is always closed afterward. We respect the limit of at most five figures, use only data that actually exists in the file, and never attempt to fabricate values or styles. All plots are saved to the same \u201cworking\u201d directory that was used during training so that downstream systems can easily locate them. The code is concise, relies solely on matplotlib + numpy + os, and prints a short confirmation once all requested plots have been saved. Finally, everything is encapsulated in one script so it can be run directly in the evaluation environment.", "We load experiment_data.npy, iterate through the lr_sweep dictionary and collect (epoch,value) pairs for train_loss, val_loss and val_ACS.  \nFigure 1 has two sub-plots: left shows train loss vs. epoch for every LR, right shows validation loss; it is saved as \u201cspr_loss_curves.png\u201d.  \nFigure 2 plots validation ACS vs. epoch for every LR and is saved as \u201cspr_val_ACS_curves.png\u201d.  \nFigure 3 is a bar-chart comparing the final (last-epoch) validation ACS across learning rates, saved as \u201cspr_final_ACS_bar.png\u201d.  \nEach plot is wrapped in its own try-except block, saved to working_dir, and the figure is closed afterwards.  \nAfter plotting, we print a dictionary mapping each learning rate to its final validation ACS so the user can see the quantitative comparison.  \nThe code relies solely on the contents of experiment_data.npy and creates at most three figures, satisfying all plotting constraints.", "Load the saved experiment dictionary, then parse the lists of (batch size, epoch, value) tuples for train/validation losses and validation ACS.  Plot three standard figures: (1) training vs validation loss across epochs for every batch size, (2) ACS across epochs for every batch size, and (3) a bar-chart of final validation accuracy per batch size, computed from the stored predictions and ground-truth labels.  Each figure is wrapped in its own try-except so that one failure does not break the others, and every figure is saved with a descriptive name under working_dir and then closed.  When plotting many lines, solid lines represent training curves while dashed lines represent validation curves.  To keep the number of figures small we aggregate all batch sizes in the same axes instead of creating separate plots per batch size.  After plotting, the script prints a dictionary that maps each batch size to its overall validation accuracy so the user can immediately see the main evaluation metric.  Only data contained in experiment_data.npy are used; no synthetic values are introduced.  All requirements on imports, directory handling, titles, and figure closing are followed.", null, "We load the saved experiment_data.npy, parse the nested dict, and for each weight-decay value unpack the three tracked metrics (train_loss, val_loss, val_ACS).  Using these series we draw three multi-line plots\u2014one for each metric\u2014so that every curve represents a different weight-decay setting across epochs.  We then identify the weight-decay run that achieved the lowest final validation loss, slice out its last epoch\u2019s predictions/ground-truth pairs (length = total_pairs // EPOCHS), and build a 2-by-2 confusion matrix.  That matrix is displayed as a heat-map figure.  Each figure is wrapped in its own try/except block, saved into working_dir with a descriptive filename, includes titles, and is closed afterward.  We cap ourselves at four figures (\u22645 as required) and only use existing data\u2014no fabrication or resampling.  All plotting uses plain matplotlib defaults and numpy for light data wrangling.  The code conforms to the required header imports, working_dir handling, and error-safe plotting pattern.", "We will load the stored sweep results, gather per-probability time-series (train loss, validation loss, ACS) as well as the final ACS and accuracy, then create four concise figures: (1) training/validation loss curves, (2) ACS curves, (3) a bar chart of the final ACS versus augmentation probability, and (4) a bar chart of the final accuracy versus augmentation probability.  Each figure is wrapped in its own try-except block, saved to the working directory with descriptive names, and the figure is closed afterwards.  Only data present in experiment_data.npy are used\u2014no values are invented.  Finally, the script prints a small table of the final ACS and accuracy so users can see the metrics directly in the console.", "We will first load experiment_data.npy and extract the results stored under embed_dim_sweep. For each embedding dimension we gather epoch-wise training/validation loss and CoWA (composite weighted accuracy). We then build three visualizations: (1) Loss curves comparing train vs. validation across epochs for every embedding size, (2) CoWA curves with the same layout, and (3) a bar chart summarizing the final validation CoWA for each embedding size. Each plot is wrapped in an independent try-except block that gracefully handles missing keys or any other error, and every figure is saved to working_dir with descriptive filenames that include the dataset tag (embed_dim_sweep) and plot type. We keep the number of figures \u22645 by combining multiple runs into single multi-line plots and using a single bar chart for the summary. After plotting we print the final validation CoWA values so that quantitative performance is visible in plain text. All figures are closed after saving to avoid memory leaks. The code is concise, uses only matplotlib and numpy, and never fabricates data. Finally, we ensure working_dir exists before saving the figures.", "We will first load experiment_data.npy from the working directory, extract the training/validation losses and evaluation metrics logged for each embedding dimension, and collect the epoch-wise values.  For every embedding size (64, 128, 256) we create a dedicated figure that overlays the training and validation loss curves so the effect of model capacity on convergence is visible; each plot is enclosed in its own try-except block, saved with a descriptive name, and the figure is closed afterwards.  Next, we generate a single comparison figure that shows CoWA over epochs for all three models on the same axes, letting us judge which configuration dominates throughout training.  Finally we add a compact bar chart that summarizes the final-epoch CoWA for each embedding dimension, facilitating a quick hyper-parameter selection snapshot.  All figures include clear titles and axis labels, use plain matplotlib styling, and are stored in the working directory.  No synthetic or missing data are invented\u2014the code only touches content fetched from experiment_data.npy.  We cap the total number of plots at five, well within the guideline.  Every figure is closed whether the plotting succeeds or fails to avoid memory leakage.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": [null, "learning_rate", "batch_size", "embed_dim", "weight_decay", "aug_probability", null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["The script will locate the working directory, load the saved NumPy file, pull\nout the stored metrics, decide the \u201cbest\u201d value for each metric (minimum for\nlosses, maximum for accuracy-style metrics), and print the results with clear,\ndescriptive names. Everything runs immediately at import time, with no special\nentry point or plotting.", "We first load the numpy file from the \u201cworking\u201d sub-directory and recover it as\na normal Python dict.   Each learning-rate experiment (keys such as \u201clr_0.001\u201d)\nis treated as a separate \u201cdataset.\u201d   For every experiment we scan the recorded\n(epoch,value) tuples stored under metrics \u2192 train_loss, val_loss, and val_ACS.\nFor loss metrics we report the minimum (best) value; for ACS we report the\nmaximum value.   The script immediately prints the dataset name followed by\nclearly labelled metric/value lines.", "The script below immediately loads \u201cexperiment_data.npy\u201d from the working\ndirectory, navigates the nested dictionary structure produced by the original\ntraining code, and computes the best (i.e., minimum or maximum, as appropriate)\nvalue for every stored metric: training loss, validation loss, validation ACS,\nand overall validation accuracy derived from the saved predictions.   For every\ndataset (e.g., \u201cSPR_BENCH\u201d) it prints the dataset name followed by clearly-\nlabelled metric/value pairs.", "", "The script will read the saved NumPy file from the working directory, unpack the\nnested dictionary, and iterate through every hyper-parameter setting.   For each\ndataset encountered (here only \u201cSPR_BENCH\u201d) it will compute the best value for\nevery recorded metric (minimum for the two loss curves and maximum for ACS).\nAfter computing these values, it will print the dataset name followed by the\nmetric name and its best score in a clear, human-readable form.   All logic is\nkept at the top level so the script runs immediately when executed, with no\nreliance on an `if __name__ == \"__main__\":` guard.", "We will load the stored npy file from the working directory, walk through its\nnested dictionary structure (`hyper-parameter \u2192 dataset \u2192 probability \u2192\nmetrics`) and, for every dataset, print the final epoch\u2019s training loss,\nvalidation loss, and validation ACS for each augmentation-probability setting.\nFor each metric, the metric name is printed explicitly before its value; no\nplots are produced and there is no `if __name__ == \"__main__\":` guard.", "The script will load the stored numpy dictionary, iterate over the three\nexperimental runs (emb_64, emb_128, emb_256) and\u2014treating each run as its own\n\u201cdataset\u201d of results\u2014print the final\u2010epoch values for training loss, validation\nloss, training composite-weighted accuracy, and validation composite-weighted\naccuracy. Metric labels are printed clearly, and all code executes immediately\non import without any special entry point.", "The solution loads the saved NumPy file from the working directory, iterates\nover every experimental run (each embedding\u2010dimension \u201cdataset\u201d), and for each\nrun locates the best (minimum) training/validation loss and the best (maximum)\nvalue for each weighted-accuracy metric. Those values are then printed with\nexplicit metric names so the output is self-explanatory. No plotting code or\nspecial entry point is used; everything executes immediately.", "The solution loads the saved NumPy file from the working directory, iterates\nover every experimental run (each embedding\u2010dimension \u201cdataset\u201d), and for each\nrun locates the best (minimum) training/validation loss and the best (maximum)\nvalue for each weighted-accuracy metric. Those values are then printed with\nexplicit metric names so the output is self-explanatory. No plotting code or\nspecial entry point is used; everything executes immediately.", "The solution loads the saved NumPy file from the working directory, iterates\nover every experimental run (each embedding\u2010dimension \u201cdataset\u201d), and for each\nrun locates the best (minimum) training/validation loss and the best (maximum)\nvalue for each weighted-accuracy metric. Those values are then printed with\nexplicit metric names so the output is self-explanatory. No plotting code or\nspecial entry point is used; everything executes immediately.", "The solution loads the saved NumPy file from the working directory, iterates\nover every experimental run (each embedding\u2010dimension \u201cdataset\u201d), and for each\nrun locates the best (minimum) training/validation loss and the best (maximum)\nvalue for each weighted-accuracy metric. Those values are then printed with\nexplicit metric names so the output is self-explanatory. No plotting code or\nspecial entry point is used; everything executes immediately.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ---------- locate file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\n# ---------- load ----------\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- pretty names for printing ----------\npretty_name = {\n    \"train_loss\": \"training loss\",\n    \"val_loss\": \"validation loss\",\n    \"val_ACS\": \"validation ACS\",\n}\n\n\n# ---------- helper to pick best value ----------\ndef best_value(metric_key, epoch_value_pairs):\n    # epoch_value_pairs is list like [(epoch, value), ...]\n    values = [v for _, v in epoch_value_pairs]\n    if \"loss\" in metric_key.lower():\n        return min(values)  # lower is better for loss\n    return max(values)  # higher is better for accuracy/consistency\n\n\n# ---------- main printing ----------\nfor dataset_name, data in experiment_data.items():\n    print(f\"{dataset_name}:\")\n    metrics_dict = data.get(\"metrics\", {})\n    for metric_key, epoch_vals in metrics_dict.items():\n        if not epoch_vals:  # skip empty lists\n            continue\n        best = best_value(metric_key, epoch_vals)\n        metric_label = pretty_name.get(metric_key, metric_key.replace(\"_\", \" \"))\n        print(f\"  {metric_label}: {best:.4f}\")\n", "import os\nimport numpy as np\n\n# -------- locate and load --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------- helper to pick best --------\ndef best_value(pairs, maximize: bool):\n    \"\"\"Return best value from list of (epoch, val).\"\"\"\n    if not pairs:\n        return None\n    # unpack second element\n    values = [v for _, v in pairs]\n    return max(values) if maximize else min(values)\n\n\n# -------- iterate and print --------\nfor lr_name, lr_entry in experiment_data.get(\"lr_sweep\", {}).items():\n    print(f\"Dataset: {lr_name}\")\n    metrics = lr_entry.get(\"metrics\", {})\n\n    # best / final values\n    train_loss_best = best_value(metrics.get(\"train_loss\", []), maximize=False)\n    val_loss_best = best_value(metrics.get(\"val_loss\", []), maximize=False)\n    val_ACS_best = best_value(metrics.get(\"val_ACS\", []), maximize=True)\n\n    if train_loss_best is not None:\n        print(f\"  train loss: {train_loss_best:.4f}\")\n    if val_loss_best is not None:\n        print(f\"  validation loss: {val_loss_best:.4f}\")\n    if val_ACS_best is not None:\n        print(f\"  validation ACS: {val_ACS_best:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfilepath = os.path.join(working_dir, \"experiment_data.npy\")\nif not os.path.exists(filepath):\n    raise FileNotFoundError(f\"Could not find {filepath}\")\n\nexperiment_data = np.load(filepath, allow_pickle=True).item()\n\n\n# ---------- helper to compute accuracy ----------\ndef accuracy(preds, gold):\n    if len(preds) == 0:\n        return float(\"nan\")\n    correct = sum(int(p == g) for p, g in zip(preds, gold))\n    return correct / len(preds)\n\n\n# ---------- iterate over datasets ----------\nfor dataset_name, data in experiment_data.get(\"batch_size\", {}).items():\n    # extract losses\n    train_losses = data[\"losses\"][\"train\"]  # list of (bs, epoch, loss)\n    val_losses = data[\"losses\"][\"val\"]  # list of (bs, epoch, loss)\n    val_acs = data[\"metrics\"][\"val\"]  # list of (bs, epoch, acs)\n\n    best_train_loss = (\n        min(train_losses, key=lambda x: x[2])[2] if train_losses else float(\"nan\")\n    )\n    best_val_loss = (\n        min(val_losses, key=lambda x: x[2])[2] if val_losses else float(\"nan\")\n    )\n    best_val_acs = max(val_acs, key=lambda x: x[2])[2] if val_acs else float(\"nan\")\n\n    # compute overall validation accuracy from stored predictions\n    pred_tuples = data.get(\"predictions\", [])\n    preds = [p[1] for p in pred_tuples]\n    gold = data.get(\"ground_truth\", [])\n    val_accuracy = accuracy(preds, gold)\n\n    # ---------- print ----------\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Best training loss: {best_train_loss:.4f}\")\n    print(f\"Best validation loss: {best_val_loss:.4f}\")\n    print(f\"Best validation ACS: {best_val_acs:.4f}\")\n    print(f\"Validation accuracy: {val_accuracy:.4f}\")\n", "", "import os\nimport numpy as np\n\n# ----------------- load experiment data -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ----------------- helper to obtain best values ---------\ndef best_metric(metric_list, larger_is_better=False):\n    \"\"\"\n    metric_list: list of (epoch, value) tuples\n    larger_is_better: True for metrics to maximize, False to minimize\n    \"\"\"\n    values = [v for _, v in metric_list]\n    return max(values) if larger_is_better else min(values)\n\n\n# ----------------- iterate and print --------------------\nfor tuning_type, param_dict in experiment_data.items():  # e.g. \"weight_decay\"\n    for param_val, datasets in param_dict.items():  # e.g. \"0.0001\"\n        for dataset_name, ds_payload in datasets.items():  # e.g. \"SPR_BENCH\"\n            metrics = ds_payload.get(\"metrics\", {})\n            print(f\"{dataset_name} ({tuning_type} = {param_val})\")\n\n            # Best train loss (lower is better)\n            if \"train_loss\" in metrics and metrics[\"train_loss\"]:\n                value = best_metric(metrics[\"train_loss\"], larger_is_better=False)\n                print(f\"best train loss: {value:.4f}\")\n\n            # Best validation loss (lower is better)\n            if \"val_loss\" in metrics and metrics[\"val_loss\"]:\n                value = best_metric(metrics[\"val_loss\"], larger_is_better=False)\n                print(f\"best validation loss: {value:.4f}\")\n\n            # Best validation ACS (higher is better)\n            if \"val_ACS\" in metrics and metrics[\"val_ACS\"]:\n                value = best_metric(metrics[\"val_ACS\"], larger_is_better=True)\n                print(f\"best validation ACS: {value:.4f}\")\n\n            print()  # blank line for readability\n", "import os\nimport numpy as np\n\n\n# ---------- helper functions ----------\ndef get_final_metric(metric_list):\n    \"\"\"\n    metric_list is a list of (epoch, value) tuples.\n    The 'final' value is simply the value from the last tuple.\n    \"\"\"\n    if not metric_list:\n        return None\n    return metric_list[-1][1]\n\n\ndef print_metrics(dataset_name, prob, run_dict):\n    \"\"\"Pretty-print the final metrics for a single run_dict.\"\"\"\n    final_train_loss = get_final_metric(run_dict.get(\"train_loss\", []))\n    final_val_loss = get_final_metric(run_dict.get(\"val_loss\", []))\n    final_val_ACS = get_final_metric(run_dict.get(\"val_ACS\", []))\n\n    # header identifying the hyper-parameter setting\n    print(f\"  Augmentation probability: {prob}\")\n    if final_train_loss is not None:\n        print(f\"    training loss: {final_train_loss:.4f}\")\n    if final_val_loss is not None:\n        print(f\"    validation loss: {final_val_loss:.4f}\")\n    if final_val_ACS is not None:\n        print(f\"    validation ACS: {final_val_ACS:.4f}\")\n\n\n# ---------- main execution (runs immediately) ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Top-level key is the hyper-parameter sweep name (e.g., 'aug_probability')\nfor sweep_name, datasets in experiment_data.items():\n    for dataset_name, prob_dict in datasets.items():\n        print(f\"\\nDataset: {dataset_name}\")\n        for prob, run_dict in prob_dict.items():\n            print_metrics(dataset_name, prob, run_dict)\n", "import os\nimport numpy as np\n\n# -------------------------------------------------------\n# locate and load the experiment data\n# -------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\nruns = experiment_data.get(\"embed_dim_sweep\", {})\n\n\n# -------------------------------------------------------\n# helper to get final value from (epoch, value) list\n# -------------------------------------------------------\ndef final_value(epoch_value_list):\n    \"\"\"Return the value recorded at the last epoch.\"\"\"\n    if not epoch_value_list:\n        return None\n    return epoch_value_list[-1][1]\n\n\n# -------------------------------------------------------\n# iterate over runs and print metrics\n# -------------------------------------------------------\nfor run_name, run_store in runs.items():\n    print(f\"\\nDataset: {run_name}\")\n\n    # losses\n    train_loss_final = final_value(run_store[\"losses\"][\"train\"])\n    val_loss_final = final_value(run_store[\"losses\"][\"val\"])\n\n    # composite weighted accuracy (CoWA)\n    train_cowa_final = final_value(run_store[\"metrics\"][\"CoWA_train\"])\n    val_cowa_final = final_value(run_store[\"metrics\"][\"CoWA_val\"])\n\n    # print with clear labels\n    print(f\"training loss: {train_loss_final:.4f}\")\n    print(f\"validation loss: {val_loss_final:.4f}\")\n    print(f\"training composite weighted accuracy: {train_cowa_final:.4f}\")\n    print(f\"validation composite weighted accuracy: {val_cowa_final:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------------\n# locate and load the experiment data\n# ---------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------------\n# helper to extract the best value from a list of (epoch, value) tuples\n# ---------------------------------------------------------------------------\ndef best_value(pairs, maximize=True):\n    \"\"\"\n    Return the best value from (epoch, value) pairs.\n    If maximize=True, return the maximum value; otherwise the minimum.\n    \"\"\"\n    if not pairs:\n        return None\n    values = [v for _, v in pairs]\n    return max(values) if maximize else min(values)\n\n\n# ---------------------------------------------------------------------------\n# iterate over each embedding-dimension experiment and report metrics\n# ---------------------------------------------------------------------------\nfor dataset_name, run_store in experiment_data.get(\"embed_dim_tuning\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n\n    # losses\n    best_train_loss = best_value(run_store[\"losses\"][\"train\"], maximize=False)\n    best_val_loss = best_value(run_store[\"losses\"][\"val\"], maximize=False)\n\n    # weighted accuracies (maximize=True)\n    best_swa = best_value(run_store[\"metrics\"][\"SWA\"], maximize=True)\n    best_cwa = best_value(run_store[\"metrics\"][\"CWA\"], maximize=True)\n    best_cowa = best_value(run_store[\"metrics\"][\"CoWA\"], maximize=True)\n\n    # print results with explicit labels\n    print(f\"  training loss: {best_train_loss:.4f}\")\n    print(f\"  validation loss: {best_val_loss:.4f}\")\n    print(f\"  shape weighted accuracy: {best_swa:.4f}\")\n    print(f\"  color weighted accuracy: {best_cwa:.4f}\")\n    print(f\"  combined weighted accuracy: {best_cowa:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------------\n# locate and load the experiment data\n# ---------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------------\n# helper to extract the best value from a list of (epoch, value) tuples\n# ---------------------------------------------------------------------------\ndef best_value(pairs, maximize=True):\n    \"\"\"\n    Return the best value from (epoch, value) pairs.\n    If maximize=True, return the maximum value; otherwise the minimum.\n    \"\"\"\n    if not pairs:\n        return None\n    values = [v for _, v in pairs]\n    return max(values) if maximize else min(values)\n\n\n# ---------------------------------------------------------------------------\n# iterate over each embedding-dimension experiment and report metrics\n# ---------------------------------------------------------------------------\nfor dataset_name, run_store in experiment_data.get(\"embed_dim_tuning\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n\n    # losses\n    best_train_loss = best_value(run_store[\"losses\"][\"train\"], maximize=False)\n    best_val_loss = best_value(run_store[\"losses\"][\"val\"], maximize=False)\n\n    # weighted accuracies (maximize=True)\n    best_swa = best_value(run_store[\"metrics\"][\"SWA\"], maximize=True)\n    best_cwa = best_value(run_store[\"metrics\"][\"CWA\"], maximize=True)\n    best_cowa = best_value(run_store[\"metrics\"][\"CoWA\"], maximize=True)\n\n    # print results with explicit labels\n    print(f\"  training loss: {best_train_loss:.4f}\")\n    print(f\"  validation loss: {best_val_loss:.4f}\")\n    print(f\"  shape weighted accuracy: {best_swa:.4f}\")\n    print(f\"  color weighted accuracy: {best_cwa:.4f}\")\n    print(f\"  combined weighted accuracy: {best_cowa:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------------\n# locate and load the experiment data\n# ---------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------------\n# helper to extract the best value from a list of (epoch, value) tuples\n# ---------------------------------------------------------------------------\ndef best_value(pairs, maximize=True):\n    \"\"\"\n    Return the best value from (epoch, value) pairs.\n    If maximize=True, return the maximum value; otherwise the minimum.\n    \"\"\"\n    if not pairs:\n        return None\n    values = [v for _, v in pairs]\n    return max(values) if maximize else min(values)\n\n\n# ---------------------------------------------------------------------------\n# iterate over each embedding-dimension experiment and report metrics\n# ---------------------------------------------------------------------------\nfor dataset_name, run_store in experiment_data.get(\"embed_dim_tuning\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n\n    # losses\n    best_train_loss = best_value(run_store[\"losses\"][\"train\"], maximize=False)\n    best_val_loss = best_value(run_store[\"losses\"][\"val\"], maximize=False)\n\n    # weighted accuracies (maximize=True)\n    best_swa = best_value(run_store[\"metrics\"][\"SWA\"], maximize=True)\n    best_cwa = best_value(run_store[\"metrics\"][\"CWA\"], maximize=True)\n    best_cowa = best_value(run_store[\"metrics\"][\"CoWA\"], maximize=True)\n\n    # print results with explicit labels\n    print(f\"  training loss: {best_train_loss:.4f}\")\n    print(f\"  validation loss: {best_val_loss:.4f}\")\n    print(f\"  shape weighted accuracy: {best_swa:.4f}\")\n    print(f\"  color weighted accuracy: {best_cwa:.4f}\")\n    print(f\"  combined weighted accuracy: {best_cowa:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------------\n# locate and load the experiment data\n# ---------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------------\n# helper to extract the best value from a list of (epoch, value) tuples\n# ---------------------------------------------------------------------------\ndef best_value(pairs, maximize=True):\n    \"\"\"\n    Return the best value from (epoch, value) pairs.\n    If maximize=True, return the maximum value; otherwise the minimum.\n    \"\"\"\n    if not pairs:\n        return None\n    values = [v for _, v in pairs]\n    return max(values) if maximize else min(values)\n\n\n# ---------------------------------------------------------------------------\n# iterate over each embedding-dimension experiment and report metrics\n# ---------------------------------------------------------------------------\nfor dataset_name, run_store in experiment_data.get(\"embed_dim_tuning\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n\n    # losses\n    best_train_loss = best_value(run_store[\"losses\"][\"train\"], maximize=False)\n    best_val_loss = best_value(run_store[\"losses\"][\"val\"], maximize=False)\n\n    # weighted accuracies (maximize=True)\n    best_swa = best_value(run_store[\"metrics\"][\"SWA\"], maximize=True)\n    best_cwa = best_value(run_store[\"metrics\"][\"CWA\"], maximize=True)\n    best_cowa = best_value(run_store[\"metrics\"][\"CoWA\"], maximize=True)\n\n    # print results with explicit labels\n    print(f\"  training loss: {best_train_loss:.4f}\")\n    print(f\"  validation loss: {best_val_loss:.4f}\")\n    print(f\"  shape weighted accuracy: {best_swa:.4f}\")\n    print(f\"  color weighted accuracy: {best_cwa:.4f}\")\n    print(f\"  combined weighted accuracy: {best_cowa:.4f}\\n\")\n", ""], "parse_term_out": ["['SPR_BENCH:', '\\n', '  training loss: 0.6069', '\\n', '  validation loss:\n0.5219', '\\n', '  validation ACS: 0.5510', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['Dataset: lr_1e-04', '\\n', '  train loss: 0.6347', '\\n', '  validation loss:\n0.5691', '\\n', '  validation ACS: 0.5508', '\\n', 'Dataset: lr_5e-04', '\\n', '\ntrain loss: 0.6070', '\\n', '  validation loss: 0.5230', '\\n', '  validation ACS:\n0.5288', '\\n', 'Dataset: lr_0.001', '\\n', '  train loss: 0.6072', '\\n', '\nvalidation loss: 0.5218', '\\n', '  validation ACS: 0.5517', '\\n', 'Dataset:\nlr_0.002', '\\n', '  train loss: 0.6040', '\\n', '  validation loss: 0.5219',\n'\\n', '  validation ACS: 0.5517', '\\n', 'Execution time: a moment seconds (time\nlimit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', 'Best training loss: 0.6050', '\\n', 'Best\nvalidation loss: 0.5213', '\\n', 'Best validation ACS: 0.5547', '\\n', 'Validation\naccuracy: 0.7535', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "", "['SPR_BENCH (weight_decay = 0.0)', '\\n', 'best train loss: 0.6088', '\\n', 'best\nvalidation loss: 0.5232', '\\n', 'best validation ACS: 0.5393', '\\n', '\\n',\n'SPR_BENCH (weight_decay = 1e-05)', '\\n', 'best train loss: 0.6080', '\\n', 'best\nvalidation loss: 0.5222', '\\n', 'best validation ACS: 0.5377', '\\n', '\\n',\n'SPR_BENCH (weight_decay = 0.0001)', '\\n', 'best train loss: 0.6086', '\\n',\n'best validation loss: 0.5228', '\\n', 'best validation ACS: 0.5393', '\\n', '\\n',\n'SPR_BENCH (weight_decay = 0.0005)', '\\n', 'best train loss: 0.6097', '\\n',\n'best validation loss: 0.5232', '\\n', 'best validation ACS: 0.5380', '\\n', '\\n',\n'SPR_BENCH (weight_decay = 0.001)', '\\n', 'best train loss: 0.6088', '\\n', 'best\nvalidation loss: 0.5249', '\\n', 'best validation ACS: 0.5383', '\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Augmentation probability: 0.0', '\\n', '\ntraining loss: 0.5239', '\\n', '    validation loss: 0.5272', '\\n', '\nvalidation ACS: 0.5373', '\\n', '  Augmentation probability: 0.25', '\\n', '\ntraining loss: 0.5681', '\\n', '    validation loss: 0.5248', '\\n', '\nvalidation ACS: 0.5357', '\\n', '  Augmentation probability: 0.5', '\\n', '\ntraining loss: 0.6124', '\\n', '    validation loss: 0.5265', '\\n', '\nvalidation ACS: 0.5390', '\\n', '  Augmentation probability: 0.75', '\\n', '\ntraining loss: 0.6532', '\\n', '    validation loss: 0.5229', '\\n', '\nvalidation ACS: 0.5400', '\\n', '  Augmentation probability: 1.0', '\\n', '\ntraining loss: 0.6991', '\\n', '    validation loss: 0.7447', '\\n', '\nvalidation ACS: 0.4803', '\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']", "['\\nDataset: emb_64', '\\n', 'training loss: 0.6088', '\\n', 'validation loss:\n0.5228', '\\n', 'training composite weighted accuracy: 0.7391', '\\n', 'validation\ncomposite weighted accuracy: 0.7654', '\\n', '\\nDataset: emb_128', '\\n',\n'training loss: 0.6118', '\\n', 'validation loss: 0.5249', '\\n', 'training\ncomposite weighted accuracy: 0.6861', '\\n', 'validation composite weighted\naccuracy: 0.7383', '\\n', '\\nDataset: emb_256', '\\n', 'training loss: 0.6116',\n'\\n', 'validation loss: 0.5258', '\\n', 'training composite weighted accuracy:\n0.7587', '\\n', 'validation composite weighted accuracy: 0.7560', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: embed_64', '\\n', '  training loss: 0.6060', '\\n', '  validation loss:\n0.5218', '\\n', '  shape weighted accuracy: 0.7709', '\\n', '  color weighted\naccuracy: 0.7661', '\\n', '  combined weighted accuracy: 0.7685\\n', '\\n',\n'Dataset: embed_128', '\\n', '  training loss: 0.6088', '\\n', '  validation loss:\n0.5236', '\\n', '  shape weighted accuracy: 0.7825', '\\n', '  color weighted\naccuracy: 0.7788', '\\n', '  combined weighted accuracy: 0.7807\\n', '\\n',\n'Dataset: embed_256', '\\n', '  training loss: 0.6088', '\\n', '  validation loss:\n0.5231', '\\n', '  shape weighted accuracy: 0.7692', '\\n', '  color weighted\naccuracy: 0.7666', '\\n', '  combined weighted accuracy: 0.7679\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: embed_64', '\\n', '  training loss: 0.6060', '\\n', '  validation loss:\n0.5218', '\\n', '  shape weighted accuracy: 0.7709', '\\n', '  color weighted\naccuracy: 0.7661', '\\n', '  combined weighted accuracy: 0.7685\\n', '\\n',\n'Dataset: embed_128', '\\n', '  training loss: 0.6088', '\\n', '  validation loss:\n0.5236', '\\n', '  shape weighted accuracy: 0.7825', '\\n', '  color weighted\naccuracy: 0.7788', '\\n', '  combined weighted accuracy: 0.7807\\n', '\\n',\n'Dataset: embed_256', '\\n', '  training loss: 0.6088', '\\n', '  validation loss:\n0.5231', '\\n', '  shape weighted accuracy: 0.7692', '\\n', '  color weighted\naccuracy: 0.7666', '\\n', '  combined weighted accuracy: 0.7679\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: embed_64', '\\n', '  training loss: 0.6060', '\\n', '  validation loss:\n0.5218', '\\n', '  shape weighted accuracy: 0.7709', '\\n', '  color weighted\naccuracy: 0.7661', '\\n', '  combined weighted accuracy: 0.7685\\n', '\\n',\n'Dataset: embed_128', '\\n', '  training loss: 0.6088', '\\n', '  validation loss:\n0.5236', '\\n', '  shape weighted accuracy: 0.7825', '\\n', '  color weighted\naccuracy: 0.7788', '\\n', '  combined weighted accuracy: 0.7807\\n', '\\n',\n'Dataset: embed_256', '\\n', '  training loss: 0.6088', '\\n', '  validation loss:\n0.5231', '\\n', '  shape weighted accuracy: 0.7692', '\\n', '  color weighted\naccuracy: 0.7666', '\\n', '  combined weighted accuracy: 0.7679\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: embed_64', '\\n', '  training loss: 0.6060', '\\n', '  validation loss:\n0.5218', '\\n', '  shape weighted accuracy: 0.7709', '\\n', '  color weighted\naccuracy: 0.7661', '\\n', '  combined weighted accuracy: 0.7685\\n', '\\n',\n'Dataset: embed_128', '\\n', '  training loss: 0.6088', '\\n', '  validation loss:\n0.5236', '\\n', '  shape weighted accuracy: 0.7825', '\\n', '  color weighted\naccuracy: 0.7788', '\\n', '  combined weighted accuracy: 0.7807\\n', '\\n',\n'Dataset: embed_256', '\\n', '  training loss: 0.6088', '\\n', '  validation loss:\n0.5231', '\\n', '  shape weighted accuracy: 0.7692', '\\n', '  color weighted\naccuracy: 0.7666', '\\n', '  combined weighted accuracy: 0.7679\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]}