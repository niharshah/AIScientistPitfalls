{"edges": [[0, 6], [0, 1], [0, 2], [0, 4], [0, 7], [0, 8], [0, 5], [0, 3], [1, 11], [1, 12], [1, 10], [1, 9]], "layout": [[0.5882352941176471, 0.0], [0.17647058823529413, 0.5], [0.29411764705882354, 0.5], [0.4117647058823529, 0.5], [0.5294117647058824, 0.5], [0.6470588235294118, 0.5], [0.7647058823529411, 0.5], [0.8823529411764706, 0.5], [1.0, 0.5], [0.0, 1.0], [0.11764705882352941, 1.0], [0.23529411764705882, 1.0], [0.35294117647058826, 1.0]], "plan": ["We start with a light neural-symbolic baseline that converts each SPR sequence\ninto a bag-of-token representation: every shape\u2013color token is mapped to an\nembedding and the averaged embedding vector is concatenated with two symbolic\nfeatures (number of distinct shapes and colors). A simple linear classifier on\ntop predicts the label. We build the vocabulary and label mappings from the\ntraining split, pad sequences for mini-batching, and train the network for a few\nepochs with cross-entropy loss. After each epoch we evaluate on the dev split,\nprinting loss and the required Composite Rule-Weighted Accuracy (CRWA) while\nalso storing SWA and CWA for reference. All tensors and the model are moved to\nGPU if available, and metrics, losses, predictions, and ground truth are saved\ninto the prescribed experiment_data structure under ./working. If the true\nSPR_BENCH folder is missing we automatically fall back to a small synthetic\ndataset so the script is always runnable. The resulting code therefore provides\na fully-working, easily-extendable baseline that respects all execution, saving,\nand device guidelines.", "Hyperparam tuning name: num_epochs. We extend the baseline with a hyper-\nparameter sweep over the maximum number of training epochs (5, 10, 20, 30).\nFor every setting we (re)initialize the model, train up to the specified limit\nusing early-stopping on the dev loss (patience = 3), record per-epoch\nlosses/metrics, and finally evaluate on the test set.   Results of every run are\nstored under experiment_data['num_epochs']['epochs_<N>'] and saved to\nexperiment_data.npy so they can be plotted later.", "Hyperparam tuning name: learning_rate. We sweep five initial learning-rates, re-\ninitialising model and optimizer for each. For every lr we train for the same\nepochs, evaluate on dev/test, log losses/metrics, and store everything inside a\nnested experiment_data structure under the \u201clearning_rate\u201d key before finally\nsaving it to experiment_data.npy.", "Hyperparam tuning name: batch_size. Our solution runs a small grid-search over\nbatch sizes (32, 64, 128, 256).   For every batch size we rebuild dataloaders,\nre-initialise the model/optimizer, train for five epochs, evaluate on the\nvalidation set every epoch, then record final test metrics.   All per-epoch\nlosses/metrics together with predictions, ground-truth and timestamps are saved\ninside the required experiment_data structure and written to\n\u2018experiment_data.npy\u2019.   The rest of the pipeline (dataset loading, model,\nmetrics, etc.) is the same as in the baseline.", "Hyperparam tuning name: embed_dim. The solution trains separate\nAvgEmbedClassifier models while sweeping the token-embedding size over {32, 64,\n128, 256}.   For every embed_dim the script performs a full 5-epoch train / dev\nevaluation cycle, then tests the final model and logs all plottable data under\nthe key experiment_data['embed_dim_tuning']['SPR_BENCH_dim_{D}'].   All results\nare aggregated and finally saved to working/experiment_data.npy.", "Hyperparam tuning name: weight_decay (L2 regularization). We sweep four weight-\ndecay values (0, 1e-5, 1e-4, 1e-3).   For every value we rebuild the tiny\nAvgEmbedClassifier, train it for a few epochs, evaluate on dev each epoch and\nfinally on test, then log losses/metrics/predictions into a single\nexperiment_data dict under the \u201cweight_decay\u201d key.   The only architectural\nchange is passing weight_decay=wd to torch.optim.Adam; all other code is\nidentical to the baseline.   Results for every sweep are appended and finally\nsaved to working/experiment_data.npy.", "Hyperparam tuning name: dropout_rate. Below is a compact implementation that\nadds a Dropout layer to the classifier, performs a grid-search over dropout\nrates {0.0, 0.1, 0.2, 0.3, 0.5}, records training/validation statistics for\nevery setting, selects the best model by validation CRWA, and finally evaluates\nthat model on the test split. All plottable data are collected in the\nexperiment_data dictionary and saved to \u201cexperiment_data.npy\u201d.", "Hyperparam tuning name: label_smoothing. The solution sweeps over four label-\nsmoothing values (0, 0.05, 0.1, 0.2).   For every value a fresh model is trained\nfor five epochs with CrossEntropyLoss(label_smoothing=val), evaluated on dev\neach epoch and once on test, and all plottable data are collected in the\nexperiment_data dict and saved as experiment_data.npy.", "Hyperparam tuning name: gradient_clip_norm. The script below iterates over a set\nof gradient-clipping thresholds (no clipping, 0.1, 0.5, 1, 5).   For each\nthreshold it trains a fresh copy of the baseline classifier, performs gradient-\nnorm clipping with the chosen max-norm right after loss.backward(), and logs\ntrain/validation/test losses plus CRWA/SWA/CWA scores.   All results are stored\nin a nested experiment_data dictionary under the key \"gradient_clip_norm\" and\nfinally serialized to experiment_data.npy for later plotting or analysis.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ----------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef CRWA(seqs, y_true, y_pred):\n    weights = [count_shape(s) * count_color(s) for s in seqs]\n    corr = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(corr) / max(sum(weights), 1)\n\n\ndef SWA(seqs, y_true, y_pred):\n    weights = [count_shape(s) for s in seqs]\n    corr = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(corr) / max(sum(weights), 1)\n\n\ndef CWA(seqs, y_true, y_pred):\n    weights = [count_color(s) for s in seqs]\n    corr = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(corr) / max(sum(weights), 1)\n\n\n# ---------- dataset loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        dset = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Could not load real data, generating synthetic toy data.\", e)\n\n        # synthetic\n        def gen(n):\n            shapes = \"ABCD\"\n            colors = \"abcd\"\n            data = []\n            for i in range(n):\n                seq = \" \".join(\n                    random.choice(shapes) + random.choice(colors)\n                    for _ in range(random.randint(3, 10))\n                )\n                label = random.choice([\"yes\", \"no\"])\n                data.append({\"id\": i, \"sequence\": seq, \"label\": label})\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        dset = DatasetDict()\n        dset[\"train\"] = gen(1000)\n        dset[\"dev\"] = gen(200)\n        dset[\"test\"] = gen(200)\n    return dset\n\n\nspr = get_dataset()\n\n# ---------- vocab + label mapping ----------\nall_tokens = set()\nall_labels = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    all_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}  # 0 reserved for PAD\nlabel2id = {lab: i for i, lab in enumerate(sorted(all_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size = len(tok2id) + 1\nnum_classes = len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={num_classes}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, hf_split):\n        self.seq = hf_split[\"sequence\"]\n        self.lbl = [label2id[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        toks = self.seq[idx].split()\n        ids = [tok2id[t] for t in toks]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"length\": torch.tensor(len(ids), dtype=torch.long),\n            \"n_shape\": torch.tensor(count_shape(self.seq[idx]), dtype=torch.long),\n            \"n_color\": torch.tensor(count_color(self.seq[idx]), dtype=torch.long),\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": self.seq[idx],\n        }  # raw for metric later\n\n\ndef collate(batch):\n    max_len = max(x[\"length\"] for x in batch).item()\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        padded[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    out = {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n    return out\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)  # B,L,E\n        mask = mask.unsqueeze(-1)  # B,L,1\n        summed = (emb * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        avg = summed / lengths\n        x = torch.cat([avg, feat], dim=-1)\n        return self.fc(x)\n\n\nembed_dim = 64\nmodel = AvgEmbedClassifier(vocab_size, embed_dim, num_classes).to(device)\n\n# ---------- optimizer & loss ----------\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------- experiment data ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\ndef evaluate(loader):\n    model.eval()\n    all_seq, all_true, all_pred = [], [], []\n    loss_total, n = 0, 0\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            feat = torch.stack([batch_t[\"n_shape\"], batch_t[\"n_color\"]], dim=-1).float()\n            logits = model(batch_t[\"input_ids\"], batch_t[\"mask\"], feat)\n            loss = criterion(logits, batch_t[\"label\"])\n            loss_total += loss.item() * batch_t[\"label\"].size(0)\n            n += batch_t[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().numpy()\n            labels = batch_t[\"label\"].cpu().numpy()\n            all_pred.extend(preds)\n            all_true.extend(labels)\n            all_seq.extend(batch[\"raw_seq\"])\n    crwa = CRWA(all_seq, all_true, all_pred)\n    swa = SWA(all_seq, all_true, all_pred)\n    cwa = CWA(all_seq, all_true, all_pred)\n    return loss_total / n, crwa, swa, cwa, all_true, all_pred, all_seq\n\n\n# ---------- training loop ----------\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    model.train()\n    ep_loss, m = 0, 0\n    for batch in train_loader:\n        batch_t = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        feat = torch.stack([batch_t[\"n_shape\"], batch_t[\"n_color\"]], dim=-1).float()\n        optimizer.zero_grad()\n        logits = model(batch_t[\"input_ids\"], batch_t[\"mask\"], feat)\n        loss = criterion(logits, batch_t[\"label\"])\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * batch_t[\"label\"].size(0)\n        m += batch_t[\"label\"].size(0)\n    train_loss = ep_loss / m\n\n    val_loss, val_crwa, val_swa, val_cwa, y_true, y_pred, seqs = evaluate(dev_loader)\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CRWA={val_crwa:.4f} | SWA={val_swa:.4f} | CWA={val_cwa:.4f}\"\n    )\n\n    # store\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(None)  # placeholder\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"CRWA\": val_crwa, \"SWA\": val_swa, \"CWA\": val_cwa}\n    )\n    experiment_data[\"SPR_BENCH\"][\"predictions\"].append(y_pred)\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"].append(y_true)\n    experiment_data[\"SPR_BENCH\"][\"timestamps\"].append(time.time())\n\n# ---------- final test evaluation ----------\ntest_loss, test_crwa, test_swa, test_cwa, y_true, y_pred, seqs = evaluate(test_loader)\nprint(\n    f\"TEST: loss={test_loss:.4f} | CRWA={test_crwa:.4f} | SWA={test_swa:.4f} | CWA={test_cwa:.4f}\"\n)\n\nexperiment_data[\"SPR_BENCH\"][\"metrics\"][\"test\"] = {\n    \"CRWA\": test_crwa,\n    \"SWA\": test_swa,\n    \"CWA\": test_cwa,\n}\nexperiment_data[\"SPR_BENCH\"][\"losses\"][\"test\"] = test_loss\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, random, time, numpy as np, torch, copy, warnings\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\nwarnings.filterwarnings(\"ignore\")\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ----------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef CRWA(seqs, y_true, y_pred):\n    w = [count_shape(s) * count_color(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef SWA(seqs, y_true, y_pred):\n    w = [count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef CWA(seqs, y_true, y_pred):\n    w = [count_color(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------- dataset ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        dset = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Could not load real data, generating synthetic toy data.\", e)\n\n        def gen(n):\n            shapes, colors = \"ABCD\", \"abcd\"\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        dset = DatasetDict()\n        dset[\"train\"], dset[\"dev\"], dset[\"test\"] = gen(1000), gen(200), gen(200)\n    return dset\n\n\nspr = get_dataset()\n\n# ---------- vocab ----------\nall_tokens = set()\nall_labels = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    all_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nlabel2id = {l: i for i, l in enumerate(sorted(all_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size = len(tok2id) + 1\nnum_classes = len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={num_classes}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, hf_split):\n        self.seq = hf_split[\"sequence\"]\n        self.lbl = [label2id[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        ids = [tok2id[t] for t in self.seq[idx].split()]\n        return {\n            \"input_ids\": torch.tensor(ids),\n            \"length\": torch.tensor(len(ids)),\n            \"n_shape\": torch.tensor(count_shape(self.seq[idx])),\n            \"n_color\": torch.tensor(count_color(self.seq[idx])),\n            \"label\": torch.tensor(self.lbl[idx]),\n            \"raw_seq\": self.seq[idx],\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        padded[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)\n        mask = mask.unsqueeze(-1)\n        avg = (emb * mask).sum(1) / mask.sum(1).clamp(min=1)\n        return self.fc(torch.cat([avg, feat], -1))\n\n\n# ---------- helpers ----------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    all_s, all_t, all_p = [], [], []\n    loss_total = n = 0\n    with torch.no_grad():\n        for batch in loader:\n            b = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([b[\"n_shape\"], b[\"n_color\"]], -1).float()\n            logits = model(b[\"input_ids\"], b[\"mask\"], feat)\n            loss = criterion(logits, b[\"label\"])\n            loss_total += loss.item() * b[\"label\"].size(0)\n            n += b[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().numpy()\n            labels = b[\"label\"].cpu().numpy()\n            all_p.extend(preds)\n            all_t.extend(labels)\n            all_s.extend(batch[\"raw_seq\"])\n    return (\n        loss_total / n,\n        CRWA(all_s, all_t, all_p),\n        SWA(all_s, all_t, all_p),\n        CWA(all_s, all_t, all_p),\n        all_t,\n        all_p,\n        all_s,\n    )\n\n\n# ---------- hyperparameter tuning ----------\nepoch_options = [5, 10, 20, 30]\nexperiment_data = {\"num_epochs\": {}}\n\nfor max_epochs in epoch_options:\n    print(f\"\\n=== Training for up to {max_epochs} epochs ===\")\n    model = AvgEmbedClassifier(vocab_size, 64, num_classes).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    run_data = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    best_val = float(\"inf\")\n    patience, pat_count = 3, 0\n    for epoch in range(1, max_epochs + 1):\n        model.train()\n        ep_loss = m = 0\n        for batch in train_loader:\n            b = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([b[\"n_shape\"], b[\"n_color\"]], -1).float()\n            optimizer.zero_grad()\n            logits = model(b[\"input_ids\"], b[\"mask\"], feat)\n            loss = criterion(logits, b[\"label\"])\n            loss.backward()\n            optimizer.step()\n            ep_loss += loss.item() * b[\"label\"].size(0)\n            m += b[\"label\"].size(0)\n        train_loss = ep_loss / m\n        val_loss, val_crwa, val_swa, val_cwa, y_true, y_pred, seqs = evaluate(\n            model, dev_loader\n        )\n        print(\n            f\"Epoch {epoch}: train={train_loss:.4f} val={val_loss:.4f} CRWA={val_crwa:.4f}\"\n        )\n        run_data[\"losses\"][\"train\"].append(train_loss)\n        run_data[\"losses\"][\"val\"].append(val_loss)\n        run_data[\"metrics\"][\"train\"].append(None)\n        run_data[\"metrics\"][\"val\"].append(\n            {\"CRWA\": val_crwa, \"SWA\": val_swa, \"CWA\": val_cwa}\n        )\n        run_data[\"predictions\"].append(y_pred)\n        run_data[\"ground_truth\"].append(y_true)\n        run_data[\"timestamps\"].append(time.time())\n        # early stopping\n        if val_loss < best_val - 1e-4:\n            best_val = val_loss\n            best_state = copy.deepcopy(model.state_dict())\n            pat_count = 0\n        else:\n            pat_count += 1\n        if pat_count >= patience:\n            print(\"Early stopping.\")\n            break\n    model.load_state_dict(best_state)\n    test_loss, test_crwa, test_swa, test_cwa, yt, yp, seq = evaluate(model, test_loader)\n    run_data[\"losses\"][\"test\"] = test_loss\n    run_data[\"metrics\"][\"test\"] = {\"CRWA\": test_crwa, \"SWA\": test_swa, \"CWA\": test_cwa}\n    print(\n        f\"TEST: loss={test_loss:.4f} CRWA={test_crwa:.4f} SWA={test_swa:.4f} CWA={test_cwa:.4f}\"\n    )\n    experiment_data[\"num_epochs\"][f\"epochs_{max_epochs}\"] = run_data\n\n# ---------- save ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- experiment data dict ----------\nexperiment_data = {\n    \"learning_rate\": {\"SPR_BENCH\": {}}  # lr-specific sub-dicts will be inserted here\n}\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ----------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef _weighted_acc(weights, y_true, y_pred):\n    corr = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(corr) / max(sum(weights), 1)\n\n\ndef CRWA(seqs, y_true, y_pred):\n    w = [count_shape(s) * count_color(s) for s in seqs]\n    return _weighted_acc(w, y_true, y_pred)\n\n\ndef SWA(seqs, y_true, y_pred):\n    w = [count_shape(s) for s in seqs]\n    return _weighted_acc(w, y_true, y_pred)\n\n\ndef CWA(seqs, y_true, y_pred):\n    w = [count_color(s) for s in seqs]\n    return _weighted_acc(w, y_true, y_pred)\n\n\n# ---------- dataset loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        dset = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Could not load real data, generating synthetic toy data.\", e)\n\n        def gen(n):\n            shapes, colors, data = \"ABCD\", \"abcd\", []\n            for i in range(n):\n                seq = \" \".join(\n                    random.choice(shapes) + random.choice(colors)\n                    for _ in range(random.randint(3, 10))\n                )\n                data.append(\n                    {\"id\": i, \"sequence\": seq, \"label\": random.choice([\"yes\", \"no\"])}\n                )\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        dset = DatasetDict()\n        dset[\"train\"], dset[\"dev\"], dset[\"test\"] = gen(1000), gen(200), gen(200)\n    return dset\n\n\nspr = get_dataset()\n\n# ---------- vocab + label mapping ----------\nall_tokens, all_labels = set(), set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    all_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}  # 0 = PAD\nlabel2id = {lab: i for i, lab in enumerate(sorted(all_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size, num_classes = len(tok2id) + 1, len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={num_classes}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, hf_split):\n        self.seq = hf_split[\"sequence\"]\n        self.lbl = [label2id[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        toks = self.seq[idx].split()\n        ids = [tok2id[t] for t in toks]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"length\": torch.tensor(len(ids), dtype=torch.long),\n            \"n_shape\": torch.tensor(count_shape(self.seq[idx]), dtype=torch.long),\n            \"n_color\": torch.tensor(count_color(self.seq[idx]), dtype=torch.long),\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": self.seq[idx],\n        }\n\n\ndef collate(batch):\n    max_len = max(x[\"length\"] for x in batch).item()\n    padded, mask = torch.zeros(len(batch), max_len, dtype=torch.long), torch.zeros(\n        len(batch), max_len, dtype=torch.bool\n    )\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        padded[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)\n        mask = mask.unsqueeze(-1)\n        avg = (emb * mask).sum(1) / mask.sum(1).clamp(min=1)\n        return self.fc(torch.cat([avg, feat], dim=-1))\n\n\n# ---------- evaluation fn ----------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    all_seq, all_true, all_pred = [], [], []\n    loss_total = 0\n    n = 0\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([batch_t[\"n_shape\"], batch_t[\"n_color\"]], dim=-1).float()\n            logits = model(batch_t[\"input_ids\"], batch_t[\"mask\"], feat)\n            loss = criterion(logits, batch_t[\"label\"])\n            loss_total += loss.item() * batch_t[\"label\"].size(0)\n            n += batch_t[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().numpy()\n            all_pred.extend(preds)\n            all_true.extend(batch_t[\"label\"].cpu().numpy())\n            all_seq.extend(batch[\"raw_seq\"])\n    return (\n        loss_total / n,\n        CRWA(all_seq, all_true, all_pred),\n        SWA(all_seq, all_true, all_pred),\n        CWA(all_seq, all_true, all_pred),\n        all_true,\n        all_pred,\n        all_seq,\n    )\n\n\n# ---------- hyper-parameter sweep ----------\nlrs = [1e-4, 3e-4, 5e-4, 1e-3, 3e-3]\nepochs, embed_dim = 5, 64\n\nfor lr in lrs:\n    print(f\"\\n===== TRAINING WITH learning_rate={lr} =====\")\n    lr_key = f\"{lr:.0e}\"\n    exp_slot = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    # init model/optim\n    model = AvgEmbedClassifier(vocab_size, embed_dim, num_classes).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    # training loop\n    for epoch in range(1, epochs + 1):\n        model.train()\n        ep_loss = 0\n        m = 0\n        for batch in train_loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([batch_t[\"n_shape\"], batch_t[\"n_color\"]], dim=-1).float()\n            optimizer.zero_grad()\n            logits = model(batch_t[\"input_ids\"], batch_t[\"mask\"], feat)\n            loss = criterion(logits, batch_t[\"label\"])\n            loss.backward()\n            optimizer.step()\n            ep_loss += loss.item() * batch_t[\"label\"].size(0)\n            m += batch_t[\"label\"].size(0)\n        train_loss = ep_loss / m\n\n        val_loss, val_crwa, val_swa, val_cwa, y_true, y_pred, _ = evaluate(\n            model, dev_loader\n        )\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CRWA={val_crwa:.4f} | SWA={val_swa:.4f} | CWA={val_cwa:.4f}\"\n        )\n\n        exp_slot[\"losses\"][\"train\"].append(train_loss)\n        exp_slot[\"losses\"][\"val\"].append(val_loss)\n        exp_slot[\"metrics\"][\"train\"].append(None)\n        exp_slot[\"metrics\"][\"val\"].append(\n            {\"CRWA\": val_crwa, \"SWA\": val_swa, \"CWA\": val_cwa}\n        )\n        exp_slot[\"predictions\"].append(y_pred)\n        exp_slot[\"ground_truth\"].append(y_true)\n        exp_slot[\"timestamps\"].append(time.time())\n\n    # test evaluation\n    test_loss, test_crwa, test_swa, test_cwa, y_true, y_pred, _ = evaluate(\n        model, test_loader\n    )\n    print(\n        f\"TEST: loss={test_loss:.4f} | CRWA={test_crwa:.4f} | SWA={test_swa:.4f} | CWA={test_cwa:.4f}\"\n    )\n    exp_slot[\"metrics\"][\"test\"] = {\"CRWA\": test_crwa, \"SWA\": test_swa, \"CWA\": test_cwa}\n    exp_slot[\"losses\"][\"test\"] = test_loss\n\n    # store under experiment_data\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][lr_key] = exp_slot\n\n    # free GPU mem for next run\n    del model, optimizer\n    torch.cuda.empty_cache()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "# -------------- imports --------------\nimport os, pathlib, random, time, numpy as np, torch, math\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# -------------- working dir --------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------- device --------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------- metrics --------------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef CRWA(seqs, y_true, y_pred):\n    w = [count_shape(s) * count_color(s) for s in seqs]\n    corr = [a if t == p else 0 for a, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(sum(w), 1)\n\n\ndef SWA(seqs, y_true, y_pred):\n    w = [count_shape(s) for s in seqs]\n    corr = [a if t == p else 0 for a, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(sum(w), 1)\n\n\ndef CWA(seqs, y_true, y_pred):\n    w = [count_color(s) for s in seqs]\n    corr = [a if t == p else 0 for a, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(sum(w), 1)\n\n\n# -------------- dataset loading --------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef get_dataset():\n    try:\n        dset = load_spr_bench(\n            pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        )\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Generating synthetic toy data due to:\", e)\n\n        def gen(n):\n            shapes = \"ABCD\"\n            colors = \"abcd\"\n            data = []\n            for i in range(n):\n                seq = \" \".join(\n                    random.choice(shapes) + random.choice(colors)\n                    for _ in range(random.randint(3, 10))\n                )\n                label = random.choice([\"yes\", \"no\"])\n                data.append({\"id\": i, \"sequence\": seq, \"label\": label})\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        dset = DatasetDict()\n        dset[\"train\"], dset[\"dev\"], dset[\"test\"] = gen(1000), gen(200), gen(200)\n    return dset\n\n\nspr = get_dataset()\n\n# -------------- vocab + labels --------------\nall_tokens = set()\nall_labels = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    all_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}  # 0 PAD\nlabel2id = {lab: i for i, lab in enumerate(sorted(all_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size = len(tok2id) + 1\nnum_classes = len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={num_classes}\")\n\n\n# -------------- torch dataset --------------\nclass SPRTorch(Dataset):\n    def __init__(self, hf_split):\n        self.seq = hf_split[\"sequence\"]\n        self.lbl = [label2id[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        s = self.seq[idx]\n        toks = s.split()\n        ids = [tok2id[t] for t in toks]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"length\": torch.tensor(len(ids), dtype=torch.long),\n            \"n_shape\": torch.tensor(count_shape(s), dtype=torch.long),\n            \"n_color\": torch.tensor(count_color(s), dtype=torch.long),\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": s,\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        padded[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\n# -------------- model --------------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)\n        mask = mask.unsqueeze(-1)\n        avg = (emb * mask).sum(1) / mask.sum(1).clamp(min=1)\n        return self.fc(torch.cat([avg, feat], dim=-1))\n\n\n# -------------- evaluation --------------\ndef evaluate(model, loader, criterion):\n    model.eval()\n    tot_loss, n = 0, 0\n    seqs = []\n    y_true = []\n    y_pred = []\n    with torch.no_grad():\n        for batch in loader:\n            bt = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([bt[\"n_shape\"], bt[\"n_color\"]], dim=-1).float()\n            logits = model(bt[\"input_ids\"], bt[\"mask\"], feat)\n            loss = criterion(logits, bt[\"label\"])\n            bs = bt[\"label\"].size(0)\n            tot_loss += loss.item() * bs\n            n += bs\n            preds = logits.argmax(-1).cpu().numpy()\n            y_pred.extend(preds)\n            y_true.extend(bt[\"label\"].cpu().numpy())\n            seqs.extend(batch[\"raw_seq\"])\n    return (\n        tot_loss / n,\n        CRWA(seqs, y_true, y_pred),\n        SWA(seqs, y_true, y_pred),\n        CWA(seqs, y_true, y_pred),\n        y_true,\n        y_pred,\n    )\n\n\n# -------------- experiment data skeleton --------------\nexperiment_data = {\n    \"batch_size_tuning\": {\n        \"SPR_BENCH\": {\n            \"batch_sizes\": [],\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": []},\n            \"losses\": {\"train\": [], \"val\": [], \"test\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n# -------------- hyperparameter sweep --------------\nembed_dim = 64\nepochs = 5\nbatch_sizes_to_try = [32, 64, 128, 256]\nfor bs in batch_sizes_to_try:\n    print(f\"\\n=== Training with batch size {bs} ===\")\n    # dataloaders\n    train_loader = DataLoader(\n        SPRTorch(spr[\"train\"]), batch_size=bs, shuffle=True, collate_fn=collate\n    )\n    dev_loader = DataLoader(\n        SPRTorch(spr[\"dev\"]), batch_size=bs, shuffle=False, collate_fn=collate\n    )\n    test_loader = DataLoader(\n        SPRTorch(spr[\"test\"]), batch_size=bs, shuffle=False, collate_fn=collate\n    )\n    # model, optimizer\n    model = AvgEmbedClassifier(vocab_size, embed_dim, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    train_losses_epoch = []\n    val_losses_epoch = []\n    val_metrics_epoch = []\n    for ep in range(1, epochs + 1):\n        model.train()\n        ep_loss, n = 0, 0\n        for batch in train_loader:\n            bt = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([bt[\"n_shape\"], bt[\"n_color\"]], dim=-1).float()\n            optimizer.zero_grad()\n            logits = model(bt[\"input_ids\"], bt[\"mask\"], feat)\n            loss = criterion(logits, bt[\"label\"])\n            loss.backward()\n            optimizer.step()\n            bs_cur = bt[\"label\"].size(0)\n            ep_loss += loss.item() * bs_cur\n            n += bs_cur\n        train_loss = ep_loss / n\n        val_loss, crwa, swa, cwa, _, _ = evaluate(model, dev_loader, criterion)\n        print(\n            f\"Epoch {ep}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CRWA={crwa:.4f} | SWA={swa:.4f} | CWA={cwa:.4f}\"\n        )\n        train_losses_epoch.append(train_loss)\n        val_losses_epoch.append(val_loss)\n        val_metrics_epoch.append({\"CRWA\": crwa, \"SWA\": swa, \"CWA\": cwa})\n    # final test\n    test_loss, crwa_t, swa_t, cwa_t, y_true, y_pred = evaluate(\n        model, test_loader, criterion\n    )\n    print(\n        f\"TEST (bs={bs}): loss={test_loss:.4f} | CRWA={crwa_t:.4f} | SWA={swa_t:.4f} | CWA={cwa_t:.4f}\"\n    )\n    # store experiment data\n    ed = experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"]\n    ed[\"batch_sizes\"].append(bs)\n    ed[\"losses\"][\"train\"].append(train_losses_epoch)\n    ed[\"losses\"][\"val\"].append(val_losses_epoch)\n    ed[\"losses\"][\"test\"].append(test_loss)\n    ed[\"metrics\"][\"val\"].append(val_metrics_epoch)\n    ed[\"metrics\"][\"test\"].append({\"CRWA\": crwa_t, \"SWA\": swa_t, \"CWA\": cwa_t})\n    ed[\"predictions\"].append(y_pred)\n    ed[\"ground_truth\"].append(y_true)\n    ed[\"timestamps\"].append(time.time())\n\n# -------------- save --------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nHyperparameter tuning complete. Results saved to 'experiment_data.npy'\")\n", "import os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- storage ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\"embed_dim_tuning\": {}}  # container required by instruction\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ----------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef CRWA(seqs, y_true, y_pred):\n    w = [count_shape(s) * count_color(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(sum(w), 1)\n\n\ndef SWA(seqs, y_true, y_pred):\n    w = [count_shape(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(sum(w), 1)\n\n\ndef CWA(seqs, y_true, y_pred):\n    w = [count_color(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(sum(w), 1)\n\n\n# ---------- dataset ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        d = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Could not load real data, generating synthetic toy data.\", e)\n\n        def gen(n):\n            shapes, colors = \"ABCD\", \"abcd\"\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        d = DatasetDict()\n        d[\"train\"], d[\"dev\"], d[\"test\"] = gen(1000), gen(200), gen(200)\n    return d\n\n\nspr = get_dataset()\n\n# ---------- vocab & labels ----------\nall_tokens = set()\nall_labels = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    all_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}  # 0 pad\nlabel2id = {lab: i for i, lab in enumerate(sorted(all_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size = len(tok2id) + 1\nnum_classes = len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={num_classes}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, hf_split):\n        self.seq = hf_split[\"sequence\"]\n        self.lbl = [label2id[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        toks = self.seq[idx].split()\n        ids = [tok2id[t] for t in toks]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"length\": torch.tensor(len(ids), dtype=torch.long),\n            \"n_shape\": torch.tensor(count_shape(self.seq[idx]), dtype=torch.long),\n            \"n_color\": torch.tensor(count_color(self.seq[idx]), dtype=torch.long),\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": self.seq[idx],\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        padded[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)\n        mask = mask.unsqueeze(-1)\n        summed = (emb * mask).sum(1)\n        avg = summed / mask.sum(1).clamp(min=1)\n        x = torch.cat([avg, feat], dim=-1)\n        return self.fc(x)\n\n\n# ---------- evaluation ----------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    all_seq, all_true, all_pred = [], [], []\n    total_loss, n = 0, 0\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([batch_t[\"n_shape\"], batch_t[\"n_color\"]], dim=-1).float()\n            logits = model(batch_t[\"input_ids\"], batch_t[\"mask\"], feat)\n            loss = criterion(logits, batch_t[\"label\"])\n            total_loss += loss.item() * batch_t[\"label\"].size(0)\n            n += batch_t[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().numpy()\n            labels = batch_t[\"label\"].cpu().numpy()\n            all_pred.extend(preds)\n            all_true.extend(labels)\n            all_seq.extend(batch[\"raw_seq\"])\n    return (\n        total_loss / n,\n        CRWA(all_seq, all_true, all_pred),\n        SWA(all_seq, all_true, all_pred),\n        CWA(all_seq, all_true, all_pred),\n        all_true,\n        all_pred,\n        all_seq,\n    )\n\n\n# ---------- training procedure ----------\ndef run_training(embed_dim, epochs=5):\n    print(f\"\\n--- Training with embed_dim={embed_dim} ---\")\n    model = AvgEmbedClassifier(vocab_size, embed_dim, num_classes).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    exp = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    for ep in range(1, epochs + 1):\n        model.train()\n        running_loss, n = 0, 0\n        for batch in train_loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([batch_t[\"n_shape\"], batch_t[\"n_color\"]], dim=-1).float()\n            optimizer.zero_grad()\n            logits = model(batch_t[\"input_ids\"], batch_t[\"mask\"], feat)\n            loss = criterion(logits, batch_t[\"label\"])\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * batch_t[\"label\"].size(0)\n            n += batch_t[\"label\"].size(0)\n        train_loss = running_loss / n\n        val_loss, crwa, swa, cwa, y_true, y_pred, seqs = evaluate(model, dev_loader)\n        print(\n            f\"Ep{ep}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CRWA={crwa:.4f} | SWA={swa:.4f} | CWA={cwa:.4f}\"\n        )\n        exp[\"losses\"][\"train\"].append(train_loss)\n        exp[\"losses\"][\"val\"].append(val_loss)\n        exp[\"metrics\"][\"train\"].append(None)\n        exp[\"metrics\"][\"val\"].append({\"CRWA\": crwa, \"SWA\": swa, \"CWA\": cwa})\n        exp[\"predictions\"].append(y_pred)\n        exp[\"ground_truth\"].append(y_true)\n        exp[\"timestamps\"].append(time.time())\n    # final test\n    test_loss, crwa, swa, cwa, y_true, y_pred, seqs = evaluate(model, test_loader)\n    print(\n        f\"TEST (dim={embed_dim}): loss={test_loss:.4f} | CRWA={crwa:.4f} | SWA={swa:.4f} | CWA={cwa:.4f}\"\n    )\n    exp[\"metrics\"][\"test\"] = {\"CRWA\": crwa, \"SWA\": swa, \"CWA\": cwa}\n    exp[\"losses\"][\"test\"] = test_loss\n    exp[\"predictions_test\"] = y_pred\n    exp[\"ground_truth_test\"] = y_true\n    return exp, model\n\n\n# ---------- hyperparameter sweep ----------\nfor dim in [32, 64, 128, 256]:\n    exp_data, model = run_training(dim, epochs=5)\n    experiment_data[\"embed_dim_tuning\"][f\"SPR_BENCH_dim_{dim}\"] = exp_data\n    # free memory\n    del model\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ----------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef CRWA(seqs, y_true, y_pred):\n    w = [count_shape(s) * count_color(s) for s in seqs]\n    c = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef SWA(seqs, y_true, y_pred):\n    w = [count_shape(s) for s in seqs]\n    c = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef CWA(seqs, y_true, y_pred):\n    w = [count_color(s) for s in seqs]\n    c = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\n# ---------- dataset loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        dset = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Could not load real data, generating synthetic toy data.\", e)\n\n        def gen(n):\n            shapes, colors = \"ABCD\", \"abcd\"\n            data = []\n            for i in range(n):\n                seq = \" \".join(\n                    random.choice(shapes) + random.choice(colors)\n                    for _ in range(random.randint(3, 10))\n                )\n                label = random.choice([\"yes\", \"no\"])\n                data.append({\"id\": i, \"sequence\": seq, \"label\": label})\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        dset = DatasetDict()\n        dset[\"train\"], dset[\"dev\"], dset[\"test\"] = gen(1000), gen(200), gen(200)\n    return dset\n\n\nspr = get_dataset()\n\n# ---------- vocab + label mapping ----------\nall_tokens, set_labels = set(), set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    set_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}  # 0 for PAD\nlabel2id = {lab: i for i, lab in enumerate(sorted(set_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size = len(tok2id) + 1\nnum_classes = len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={num_classes}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, hf_split):\n        self.seq = hf_split[\"sequence\"]\n        self.lbl = [label2id[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        toks = self.seq[idx].split()\n        ids = [tok2id[t] for t in toks]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"length\": torch.tensor(len(ids), dtype=torch.long),\n            \"n_shape\": torch.tensor(count_shape(self.seq[idx]), dtype=torch.long),\n            \"n_color\": torch.tensor(count_color(self.seq[idx]), dtype=torch.long),\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": self.seq[idx],\n        }\n\n\ndef collate(batch):\n    max_len = max(x[\"length\"] for x in batch).item()\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        padded[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)\n        mask = mask.unsqueeze(-1)\n        summed = (emb * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        avg = summed / lengths\n        x = torch.cat([avg, feat], dim=-1)\n        return self.fc(x)\n\n\n# ---------- evaluation helper ----------\ndef evaluate(model, loader, criterion):\n    model.eval()\n    all_seq, all_true, all_pred = [], [], []\n    loss_total, n = 0, 0\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([batch_t[\"n_shape\"], batch_t[\"n_color\"]], dim=-1).float()\n            logits = model(batch_t[\"input_ids\"], batch_t[\"mask\"], feat)\n            loss = criterion(logits, batch_t[\"label\"])\n            bs = batch_t[\"label\"].size(0)\n            loss_total += loss.item() * bs\n            n += bs\n            preds = logits.argmax(-1).cpu().numpy()\n            labels = batch_t[\"label\"].cpu().numpy()\n            all_pred.extend(preds)\n            all_true.extend(labels)\n            all_seq.extend(batch[\"raw_seq\"])\n    crwa, swa, cwa = (\n        CRWA(all_seq, all_true, all_pred),\n        SWA(all_seq, all_true, all_pred),\n        CWA(all_seq, all_true, all_pred),\n    )\n    return loss_total / n, crwa, swa, cwa, all_true, all_pred\n\n\n# ---------- experiment data ----------\nexperiment_data = {\n    \"weight_decay\": {\n        \"SPR_BENCH\": {\n            \"decay_values\": [],\n            \"metrics\": {\"val\": [], \"test\": []},\n            \"losses\": {\"train\": [], \"val\": [], \"test\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\nweight_decays = [0.0, 1e-5, 1e-4, 1e-3]\nepochs = 5\nembed_dim = 64\n\nfor wd in weight_decays:\n    print(f\"\\n=== Training with weight_decay={wd} ===\")\n    model = AvgEmbedClassifier(vocab_size, embed_dim, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=wd)\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        ep_loss, m = 0, 0\n        for batch in train_loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([batch_t[\"n_shape\"], batch_t[\"n_color\"]], dim=-1).float()\n            optimizer.zero_grad()\n            logits = model(batch_t[\"input_ids\"], batch_t[\"mask\"], feat)\n            loss = criterion(logits, batch_t[\"label\"])\n            loss.backward()\n            optimizer.step()\n            bs = batch_t[\"label\"].size(0)\n            ep_loss += loss.item() * bs\n            m += bs\n        train_loss = ep_loss / m\n\n        val_loss, val_crwa, val_swa, val_cwa, _, _ = evaluate(\n            model, dev_loader, criterion\n        )\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CRWA={val_crwa:.4f} | SWA={val_swa:.4f} | CWA={val_cwa:.4f}\"\n        )\n\n    # final test\n    test_loss, test_crwa, test_swa, test_cwa, y_true, y_pred = evaluate(\n        model, test_loader, criterion\n    )\n    print(\n        f\"TEST: loss={test_loss:.4f} | CRWA={test_crwa:.4f} | SWA={test_swa:.4f} | CWA={test_cwa:.4f}\"\n    )\n\n    # store\n    ed = experiment_data[\"weight_decay\"][\"SPR_BENCH\"]\n    ed[\"decay_values\"].append(wd)\n    ed[\"metrics\"][\"val\"].append({\"CRWA\": val_crwa, \"SWA\": val_swa, \"CWA\": val_cwa})\n    ed[\"metrics\"][\"test\"].append({\"CRWA\": test_crwa, \"SWA\": test_swa, \"CWA\": test_cwa})\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"losses\"][\"test\"].append(test_loss)\n    ed[\"predictions\"].append(y_pred)\n    ed[\"ground_truth\"].append(y_true)\n    ed[\"timestamps\"].append(time.time())\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# dropout_rate hyperparameter-tuning baseline\nimport os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# -------------- reproducibility --------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# -------------- work dir --------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ----------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef _weighted_acc(seqs, y_true, y_pred, weight_fn):\n    w = [weight_fn(s) for s in seqs]\n    corr = [w0 if t == p else 0 for w0, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(sum(w), 1)\n\n\ndef CRWA(seqs, y_true, y_pred):\n    return _weighted_acc(\n        seqs, y_true, y_pred, lambda s: count_shape(s) * count_color(s)\n    )\n\n\ndef SWA(seqs, y_true, y_pred):\n    return _weighted_acc(seqs, y_true, y_pred, count_shape)\n\n\ndef CWA(seqs, y_true, y_pred):\n    return _weighted_acc(seqs, y_true, y_pred, count_color)\n\n\n# ---------- dataset ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        d = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Could not load real data, generating synthetic toy data.\", e)\n\n        def gen(n):\n            shapes, colors = \"ABCD\", \"abcd\"\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        d = DatasetDict()\n        d[\"train\"], d[\"dev\"], d[\"test\"] = gen(1000), gen(200), gen(200)\n    return d\n\n\nspr = get_dataset()\n\n# ---------- vocab & labels ----------\nall_tokens = set()\nall_labels = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    all_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nlabel2id = {lab: i for i, lab in enumerate(sorted(all_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size, len_classes = len(tok2id) + 1, len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={len_classes}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seq = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        toks = self.seq[idx].split()\n        ids = [tok2id[t] for t in toks]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"length\": torch.tensor(len(ids)),\n            \"n_shape\": torch.tensor(count_shape(self.seq[idx])),\n            \"n_color\": torch.tensor(count_color(self.seq[idx])),\n            \"label\": torch.tensor(self.lbl[idx]),\n            \"raw_seq\": self.seq[idx],\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    pad = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        pad[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    return {\n        \"input_ids\": pad,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls, dropout_rate):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.drop = nn.Dropout(dropout_rate)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)\n        mask = mask.unsqueeze(-1)\n        avg = (emb * mask).sum(1) / mask.sum(1).clamp(min=1)\n        x = torch.cat([avg, feat], -1)\n        x = self.drop(x)\n        return self.fc(x)\n\n\n# ---------- train / eval helpers ----------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    all_seq, all_t, all_p = [], [], []\n    loss_tot = n = 0\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            feat = torch.stack([batch[\"n_shape\"], batch[\"n_color\"]], -1).float()\n            logits = model(batch[\"input_ids\"], batch[\"mask\"], feat)\n            loss = criterion(logits, batch[\"label\"])\n            loss_tot += loss.item() * batch[\"label\"].size(0)\n            n += batch[\"label\"].size(0)\n            pred = logits.argmax(-1).cpu().numpy()\n            lbl = batch[\"label\"].cpu().numpy()\n            all_p.extend(pred)\n            all_t.extend(lbl)\n            all_seq.extend(batch[\"raw_seq\"])\n    return (\n        loss_tot / n,\n        CRWA(all_seq, all_t, all_p),\n        SWA(all_seq, all_t, all_p),\n        CWA(all_seq, all_t, all_p),\n        all_t,\n        all_p,\n        all_seq,\n    )\n\n\n# ---------- experiment data dict ----------\nexperiment_data = {\"dropout_rate\": {}}\n\n# ---------- hyperparameter grid ----------\nembed_dim, epochs = 64, 5\ndrop_grid = [0.0, 0.1, 0.2, 0.3, 0.5]\nbest_val_crwa, best_state, best_rate = -1, None, None\n\nfor dp in drop_grid:\n    print(f\"\\n=== Training with dropout={dp} ===\")\n    model = AvgEmbedClassifier(vocab_size, embed_dim, len_classes, dp).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    hist = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    for epoch in range(1, epochs + 1):\n        model.train()\n        ep_loss = m = 0\n        for batch in train_loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            feat = torch.stack([batch[\"n_shape\"], batch[\"n_color\"]], -1).float()\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"], batch[\"mask\"], feat)\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer.step()\n            ep_loss += loss.item() * batch[\"label\"].size(0)\n            m += batch[\"label\"].size(0)\n        train_loss = ep_loss / m\n        val_loss, val_crwa, val_swa, val_cwa, y_t, y_p, _ = evaluate(model, dev_loader)\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CRWA={val_crwa:.4f}\"\n        )\n        hist[\"losses\"][\"train\"].append(train_loss)\n        hist[\"losses\"][\"val\"].append(val_loss)\n        hist[\"metrics\"][\"train\"].append(None)\n        hist[\"metrics\"][\"val\"].append(\n            {\"CRWA\": val_crwa, \"SWA\": val_swa, \"CWA\": val_cwa}\n        )\n        hist[\"predictions\"].append(y_p)\n        hist[\"ground_truth\"].append(y_t)\n        hist[\"timestamps\"].append(time.time())\n    experiment_data[\"dropout_rate\"][dp] = {\"SPR_BENCH\": hist}\n    if val_crwa > best_val_crwa:\n        best_val_crwa, best_state, best_rate = val_crwa, model.state_dict(), dp\n\n# ---------- test with best rate ----------\nprint(f\"\\nBest dropout rate by dev CRWA = {best_rate}\")\nbest_model = AvgEmbedClassifier(vocab_size, embed_dim, len_classes, best_rate).to(\n    device\n)\nbest_model.load_state_dict(best_state)\ntest_loss, test_crwa, test_swa, test_cwa, y_t, y_p, _ = evaluate(\n    best_model, test_loader\n)\nprint(\n    f\"TEST: loss={test_loss:.4f} | CRWA={test_crwa:.4f} | SWA={test_swa:.4f} | CWA={test_cwa:.4f}\"\n)\nexperiment_data[\"dropout_rate\"][\"best_rate\"] = best_rate\nexperiment_data[\"dropout_rate\"][\"test_metrics\"] = {\n    \"loss\": test_loss,\n    \"CRWA\": test_crwa,\n    \"SWA\": test_swa,\n    \"CWA\": test_cwa,\n}\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ----------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef _weighted_acc(seqs, y_true, y_pred, w_fn):\n    w = [w_fn(s) for s in seqs]\n    corr = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(sum(w), 1)\n\n\ndef CRWA(seqs, y_true, y_pred):\n    return _weighted_acc(\n        seqs, y_true, y_pred, lambda s: count_shape(s) * count_color(s)\n    )\n\n\ndef SWA(seqs, y_true, y_pred):\n    return _weighted_acc(seqs, y_true, y_pred, count_shape)\n\n\ndef CWA(seqs, y_true, y_pred):\n    return _weighted_acc(seqs, y_true, y_pred, count_color)\n\n\n# ---------- dataset loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {split: _load(f\"{split}.csv\") for split in [\"train\", \"dev\", \"test\"]}\n    )\n\n\ndef get_dataset():\n    try:\n        dset = load_spr_bench(\n            pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        )\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Could not load real data, generating synthetic toy data.\", e)\n\n        def gen(n):\n            shapes, colors = \"ABCD\", \"abcd\"\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        dset = DatasetDict(train=gen(1000), dev=gen(200), test=gen(200))\n    return dset\n\n\nspr = get_dataset()\n\n# ---------- vocab + label mapping ----------\nall_tokens, all_labels = set(), set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    all_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}  # 0 pad\nlabel2id = {lab: i for i, lab in enumerate(sorted(all_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size, num_classes = len(tok2id) + 1, len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={num_classes}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, hf_split):\n        self.seq = hf_split[\"sequence\"]\n        self.lbl = [label2id[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        toks = self.seq[idx].split()\n        ids = [tok2id[t] for t in toks]\n        return {\n            \"input_ids\": torch.tensor(ids),\n            \"length\": torch.tensor(len(ids)),\n            \"n_shape\": torch.tensor(count_shape(self.seq[idx])),\n            \"n_color\": torch.tensor(count_color(self.seq[idx])),\n            \"label\": torch.tensor(self.lbl[idx]),\n            \"raw_seq\": self.seq[idx],\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        padded[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)\n        mask = mask.unsqueeze(-1)\n        avg = (emb * mask).sum(1) / mask.sum(1).clamp(min=1)\n        return self.fc(torch.cat([avg, feat], -1))\n\n\n# ---------- evaluation ----------\n@torch.no_grad()\ndef evaluate(model, loader, criterion):\n    model.eval()\n    all_seq, all_true, all_pred = [], [], []\n    loss_tot, n = 0, 0\n    for batch in loader:\n        b = {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()}\n        feat = torch.stack([b[\"n_shape\"], b[\"n_color\"]], -1).float()\n        logits = model(b[\"input_ids\"], b[\"mask\"], feat)\n        loss = criterion(logits, b[\"label\"])\n        loss_tot += loss.item() * b[\"label\"].size(0)\n        n += b[\"label\"].size(0)\n        preds = logits.argmax(-1).cpu().numpy()\n        labels = b[\"label\"].cpu().numpy()\n        all_pred.extend(preds)\n        all_true.extend(labels)\n        all_seq.extend(batch[\"raw_seq\"])\n    return (\n        loss_tot / n if n else 0,\n        CRWA(all_seq, all_true, all_pred),\n        SWA(all_seq, all_true, all_pred),\n        CWA(all_seq, all_true, all_pred),\n        all_true,\n        all_pred,\n    )\n\n\n# ---------- hyperparameter sweep ----------\nsmoothing_vals = [0.0, 0.05, 0.1, 0.2]\nepochs = 5\nembed_dim = 64\nlr = 1e-3\nexperiment_data = {\"label_smoothing\": {}}\n\nfor sm in smoothing_vals:\n    print(f\"\\n=== Training with label_smoothing={sm} ===\")\n    torch.manual_seed(0)\n    random.seed(0)\n    np.random.seed(0)\n    model = AvgEmbedClassifier(vocab_size, embed_dim, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss(label_smoothing=sm)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    rec = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    for epoch in range(1, epochs + 1):\n        model.train()\n        ep_loss = 0\n        m = 0\n        for batch in train_loader:\n            b = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            feat = torch.stack([b[\"n_shape\"], b[\"n_color\"]], -1).float()\n            optimizer.zero_grad()\n            logits = model(b[\"input_ids\"], b[\"mask\"], feat)\n            loss = criterion(logits, b[\"label\"])\n            loss.backward()\n            optimizer.step()\n            ep_loss += loss.item() * b[\"label\"].size(0)\n            m += b[\"label\"].size(0)\n        train_loss = ep_loss / m\n        val_loss, crwa, swa, cwa, y_true, y_pred = evaluate(\n            model, dev_loader, criterion\n        )\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CRWA={crwa:.4f} | SWA={swa:.4f} | CWA={cwa:.4f}\"\n        )\n\n        rec[\"losses\"][\"train\"].append(train_loss)\n        rec[\"losses\"][\"val\"].append(val_loss)\n        rec[\"metrics\"][\"train\"].append(None)\n        rec[\"metrics\"][\"val\"].append({\"CRWA\": crwa, \"SWA\": swa, \"CWA\": cwa})\n        rec[\"predictions\"].append(y_pred)\n        rec[\"ground_truth\"].append(y_true)\n        rec[\"timestamps\"].append(time.time())\n\n    test_loss, crwa, swa, cwa, y_true, y_pred = evaluate(model, test_loader, criterion)\n    print(\n        f\"TEST: loss={test_loss:.4f} | CRWA={crwa:.4f} | SWA={swa:.4f} | CWA={cwa:.4f}\"\n    )\n    rec[\"metrics\"][\"test\"] = {\"CRWA\": crwa, \"SWA\": swa, \"CWA\": cwa}\n    rec[\"losses\"][\"test\"] = test_loss\n    rec[\"predictions\"].append(y_pred)\n    rec[\"ground_truth\"].append(y_true)\n    experiment_data[\"label_smoothing\"][f\"{sm}\"] = rec\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved results to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- reproducibility ----------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\n# ---------- dirs ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ----------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef CRWA(seqs, y_true, y_pred):\n    w = [count_shape(s) * count_color(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef SWA(seqs, y_true, y_pred):\n    w = [count_shape(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef CWA(seqs, y_true, y_pred):\n    w = [count_color(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# ---------- dataset ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {split: _load(f\"{split}.csv\") for split in [\"train\", \"dev\", \"test\"]}\n    )\n\n\ndef get_dataset():\n    try:\n        dset = load_spr_bench(\n            pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        )\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Could not load real data, generating synthetic toy data.\", e)\n\n        def gen(n):\n            shapes, colors = \"ABCD\", \"abcd\"\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        dset = DatasetDict()\n        dset[\"train\"], dset[\"dev\"], dset[\"test\"] = gen(1000), gen(200), gen(200)\n    return dset\n\n\nspr = get_dataset()\n\n# ---------- vocab & labels ----------\nall_tokens, all_labels = set(), set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    all_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}  # 0 = PAD\nlabel2id = {lab: i for i, lab in enumerate(sorted(all_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size, num_classes = len(tok2id) + 1, len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={num_classes}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, hf_split):\n        self.seq = hf_split[\"sequence\"]\n        self.lbl = [label2id[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        ids = [tok2id[t] for t in self.seq[idx].split()]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"length\": torch.tensor(len(ids)),\n            \"n_shape\": torch.tensor(count_shape(self.seq[idx])),\n            \"n_color\": torch.tensor(count_color(self.seq[idx])),\n            \"label\": torch.tensor(self.lbl[idx]),\n            \"raw_seq\": self.seq[idx],\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        padded[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)  # B,L,E\n        summed = (emb * mask.unsqueeze(-1)).sum(1)\n        avg = summed / mask.sum(1).clamp(min=1).unsqueeze(-1)\n        x = torch.cat([avg, feat], -1)\n        return self.fc(x)\n\n\n# ---------- evaluation helper ----------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    all_seq, all_true, all_pred = [], [], []\n    loss_total, n = 0, 0\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([batch_t[\"n_shape\"], batch_t[\"n_color\"]], -1).float()\n            logits = model(batch_t[\"input_ids\"], batch_t[\"mask\"], feat)\n            loss = criterion(logits, batch_t[\"label\"])\n            loss_total += loss.item() * batch_t[\"label\"].size(0)\n            n += batch_t[\"label\"].size(0)\n            all_pred.extend(logits.argmax(-1).cpu().numpy())\n            all_true.extend(batch_t[\"label\"].cpu().numpy())\n            all_seq.extend(batch[\"raw_seq\"])\n    return (\n        loss_total / n,\n        CRWA(all_seq, all_true, all_pred),\n        SWA(all_seq, all_true, all_pred),\n        CWA(all_seq, all_true, all_pred),\n        all_true,\n        all_pred,\n        all_seq,\n    )\n\n\n# ---------- experiment data ----------\nexperiment_data = {\"gradient_clip_norm\": {\"SPR_BENCH\": {}}}\n\n# ---------- hyperparameter search ----------\nclip_vals = [None, 0.1, 0.5, 1.0, 5.0]\nembed_dim, epochs, lr = 64, 5, 1e-3\n\nfor clip in clip_vals:\n    clip_key = \"none\" if clip is None else str(clip)\n    print(f\"\\n=== Training with gradient_clip_norm={clip_key} ===\")\n    model = AvgEmbedClassifier(vocab_size, embed_dim, num_classes).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    run_data = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        ep_loss, m = 0, 0\n        for batch in train_loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([batch_t[\"n_shape\"], batch_t[\"n_color\"]], -1).float()\n            optimizer.zero_grad()\n            logits = model(batch_t[\"input_ids\"], batch_t[\"mask\"], feat)\n            loss = criterion(logits, batch_t[\"label\"])\n            loss.backward()\n            if clip is not None:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n            optimizer.step()\n            ep_loss += loss.item() * batch_t[\"label\"].size(0)\n            m += batch_t[\"label\"].size(0)\n        train_loss = ep_loss / m\n\n        val_loss, val_crwa, val_swa, val_cwa, y_true, y_pred, _ = evaluate(\n            model, dev_loader\n        )\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} \"\n            f\"| CRWA={val_crwa:.4f} | SWA={val_swa:.4f} | CWA={val_cwa:.4f}\"\n        )\n\n        run_data[\"losses\"][\"train\"].append(train_loss)\n        run_data[\"losses\"][\"val\"].append(val_loss)\n        run_data[\"metrics\"][\"train\"].append(None)\n        run_data[\"metrics\"][\"val\"].append(\n            {\"CRWA\": val_crwa, \"SWA\": val_swa, \"CWA\": val_cwa}\n        )\n        run_data[\"predictions\"].append(y_pred)\n        run_data[\"ground_truth\"].append(y_true)\n        run_data[\"timestamps\"].append(time.time())\n\n    test_loss, test_crwa, test_swa, test_cwa, y_true, y_pred, _ = evaluate(\n        model, test_loader\n    )\n    print(\n        f\"TEST: loss={test_loss:.4f} | CRWA={test_crwa:.4f} | SWA={test_swa:.4f} | CWA={test_cwa:.4f}\"\n    )\n\n    run_data[\"metrics\"][\"test\"] = {\"CRWA\": test_crwa, \"SWA\": test_swa, \"CWA\": test_cwa}\n    run_data[\"losses\"][\"test\"] = test_loss\n    experiment_data[\"gradient_clip_norm\"][\"SPR_BENCH\"][clip_key] = run_data\n\n    del model\n    torch.cuda.empty_cache()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, numpy as np, torch, copy, warnings\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\nwarnings.filterwarnings(\"ignore\")\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ----------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef CRWA(seqs, y_true, y_pred):\n    w = [count_shape(s) * count_color(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef SWA(seqs, y_true, y_pred):\n    w = [count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef CWA(seqs, y_true, y_pred):\n    w = [count_color(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------- dataset ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        dset = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Could not load real data, generating synthetic toy data.\", e)\n\n        def gen(n):\n            shapes, colors = \"ABCD\", \"abcd\"\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        dset = DatasetDict()\n        dset[\"train\"], dset[\"dev\"], dset[\"test\"] = gen(1000), gen(200), gen(200)\n    return dset\n\n\nspr = get_dataset()\n\n# ---------- vocab ----------\nall_tokens = set()\nall_labels = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    all_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nlabel2id = {l: i for i, l in enumerate(sorted(all_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size = len(tok2id) + 1\nnum_classes = len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={num_classes}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, hf_split):\n        self.seq = hf_split[\"sequence\"]\n        self.lbl = [label2id[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        ids = [tok2id[t] for t in self.seq[idx].split()]\n        return {\n            \"input_ids\": torch.tensor(ids),\n            \"length\": torch.tensor(len(ids)),\n            \"n_shape\": torch.tensor(count_shape(self.seq[idx])),\n            \"n_color\": torch.tensor(count_color(self.seq[idx])),\n            \"label\": torch.tensor(self.lbl[idx]),\n            \"raw_seq\": self.seq[idx],\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        padded[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)\n        mask = mask.unsqueeze(-1)\n        avg = (emb * mask).sum(1) / mask.sum(1).clamp(min=1)\n        return self.fc(torch.cat([avg, feat], -1))\n\n\n# ---------- helpers ----------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    all_s, all_t, all_p = [], [], []\n    loss_total = n = 0\n    with torch.no_grad():\n        for batch in loader:\n            b = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([b[\"n_shape\"], b[\"n_color\"]], -1).float()\n            logits = model(b[\"input_ids\"], b[\"mask\"], feat)\n            loss = criterion(logits, b[\"label\"])\n            loss_total += loss.item() * b[\"label\"].size(0)\n            n += b[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().numpy()\n            labels = b[\"label\"].cpu().numpy()\n            all_p.extend(preds)\n            all_t.extend(labels)\n            all_s.extend(batch[\"raw_seq\"])\n    return (\n        loss_total / n,\n        CRWA(all_s, all_t, all_p),\n        SWA(all_s, all_t, all_p),\n        CWA(all_s, all_t, all_p),\n        all_t,\n        all_p,\n        all_s,\n    )\n\n\n# ---------- hyperparameter tuning ----------\nepoch_options = [5, 10, 20, 30]\nexperiment_data = {\"num_epochs\": {}}\n\nfor max_epochs in epoch_options:\n    print(f\"\\n=== Training for up to {max_epochs} epochs ===\")\n    model = AvgEmbedClassifier(vocab_size, 64, num_classes).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    run_data = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    best_val = float(\"inf\")\n    patience, pat_count = 3, 0\n    for epoch in range(1, max_epochs + 1):\n        model.train()\n        ep_loss = m = 0\n        for batch in train_loader:\n            b = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([b[\"n_shape\"], b[\"n_color\"]], -1).float()\n            optimizer.zero_grad()\n            logits = model(b[\"input_ids\"], b[\"mask\"], feat)\n            loss = criterion(logits, b[\"label\"])\n            loss.backward()\n            optimizer.step()\n            ep_loss += loss.item() * b[\"label\"].size(0)\n            m += b[\"label\"].size(0)\n        train_loss = ep_loss / m\n        val_loss, val_crwa, val_swa, val_cwa, y_true, y_pred, seqs = evaluate(\n            model, dev_loader\n        )\n        print(\n            f\"Epoch {epoch}: train={train_loss:.4f} val={val_loss:.4f} CRWA={val_crwa:.4f}\"\n        )\n        run_data[\"losses\"][\"train\"].append(train_loss)\n        run_data[\"losses\"][\"val\"].append(val_loss)\n        run_data[\"metrics\"][\"train\"].append(None)\n        run_data[\"metrics\"][\"val\"].append(\n            {\"CRWA\": val_crwa, \"SWA\": val_swa, \"CWA\": val_cwa}\n        )\n        run_data[\"predictions\"].append(y_pred)\n        run_data[\"ground_truth\"].append(y_true)\n        run_data[\"timestamps\"].append(time.time())\n        # early stopping\n        if val_loss < best_val - 1e-4:\n            best_val = val_loss\n            best_state = copy.deepcopy(model.state_dict())\n            pat_count = 0\n        else:\n            pat_count += 1\n        if pat_count >= patience:\n            print(\"Early stopping.\")\n            break\n    model.load_state_dict(best_state)\n    test_loss, test_crwa, test_swa, test_cwa, yt, yp, seq = evaluate(model, test_loader)\n    run_data[\"losses\"][\"test\"] = test_loss\n    run_data[\"metrics\"][\"test\"] = {\"CRWA\": test_crwa, \"SWA\": test_swa, \"CWA\": test_cwa}\n    print(\n        f\"TEST: loss={test_loss:.4f} CRWA={test_crwa:.4f} SWA={test_swa:.4f} CWA={test_cwa:.4f}\"\n    )\n    experiment_data[\"num_epochs\"][f\"epochs_{max_epochs}\"] = run_data\n\n# ---------- save ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, numpy as np, torch, copy, warnings\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\nwarnings.filterwarnings(\"ignore\")\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ----------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef CRWA(seqs, y_true, y_pred):\n    w = [count_shape(s) * count_color(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef SWA(seqs, y_true, y_pred):\n    w = [count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef CWA(seqs, y_true, y_pred):\n    w = [count_color(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------- dataset ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        dset = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Could not load real data, generating synthetic toy data.\", e)\n\n        def gen(n):\n            shapes, colors = \"ABCD\", \"abcd\"\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        dset = DatasetDict()\n        dset[\"train\"], dset[\"dev\"], dset[\"test\"] = gen(1000), gen(200), gen(200)\n    return dset\n\n\nspr = get_dataset()\n\n# ---------- vocab ----------\nall_tokens = set()\nall_labels = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    all_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nlabel2id = {l: i for i, l in enumerate(sorted(all_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size = len(tok2id) + 1\nnum_classes = len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={num_classes}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, hf_split):\n        self.seq = hf_split[\"sequence\"]\n        self.lbl = [label2id[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        ids = [tok2id[t] for t in self.seq[idx].split()]\n        return {\n            \"input_ids\": torch.tensor(ids),\n            \"length\": torch.tensor(len(ids)),\n            \"n_shape\": torch.tensor(count_shape(self.seq[idx])),\n            \"n_color\": torch.tensor(count_color(self.seq[idx])),\n            \"label\": torch.tensor(self.lbl[idx]),\n            \"raw_seq\": self.seq[idx],\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        padded[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)\n        mask = mask.unsqueeze(-1)\n        avg = (emb * mask).sum(1) / mask.sum(1).clamp(min=1)\n        return self.fc(torch.cat([avg, feat], -1))\n\n\n# ---------- helpers ----------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    all_s, all_t, all_p = [], [], []\n    loss_total = n = 0\n    with torch.no_grad():\n        for batch in loader:\n            b = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([b[\"n_shape\"], b[\"n_color\"]], -1).float()\n            logits = model(b[\"input_ids\"], b[\"mask\"], feat)\n            loss = criterion(logits, b[\"label\"])\n            loss_total += loss.item() * b[\"label\"].size(0)\n            n += b[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().numpy()\n            labels = b[\"label\"].cpu().numpy()\n            all_p.extend(preds)\n            all_t.extend(labels)\n            all_s.extend(batch[\"raw_seq\"])\n    return (\n        loss_total / n,\n        CRWA(all_s, all_t, all_p),\n        SWA(all_s, all_t, all_p),\n        CWA(all_s, all_t, all_p),\n        all_t,\n        all_p,\n        all_s,\n    )\n\n\n# ---------- hyperparameter tuning ----------\nepoch_options = [5, 10, 20, 30]\nexperiment_data = {\"num_epochs\": {}}\n\nfor max_epochs in epoch_options:\n    print(f\"\\n=== Training for up to {max_epochs} epochs ===\")\n    model = AvgEmbedClassifier(vocab_size, 64, num_classes).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    run_data = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    best_val = float(\"inf\")\n    patience, pat_count = 3, 0\n    for epoch in range(1, max_epochs + 1):\n        model.train()\n        ep_loss = m = 0\n        for batch in train_loader:\n            b = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([b[\"n_shape\"], b[\"n_color\"]], -1).float()\n            optimizer.zero_grad()\n            logits = model(b[\"input_ids\"], b[\"mask\"], feat)\n            loss = criterion(logits, b[\"label\"])\n            loss.backward()\n            optimizer.step()\n            ep_loss += loss.item() * b[\"label\"].size(0)\n            m += b[\"label\"].size(0)\n        train_loss = ep_loss / m\n        val_loss, val_crwa, val_swa, val_cwa, y_true, y_pred, seqs = evaluate(\n            model, dev_loader\n        )\n        print(\n            f\"Epoch {epoch}: train={train_loss:.4f} val={val_loss:.4f} CRWA={val_crwa:.4f}\"\n        )\n        run_data[\"losses\"][\"train\"].append(train_loss)\n        run_data[\"losses\"][\"val\"].append(val_loss)\n        run_data[\"metrics\"][\"train\"].append(None)\n        run_data[\"metrics\"][\"val\"].append(\n            {\"CRWA\": val_crwa, \"SWA\": val_swa, \"CWA\": val_cwa}\n        )\n        run_data[\"predictions\"].append(y_pred)\n        run_data[\"ground_truth\"].append(y_true)\n        run_data[\"timestamps\"].append(time.time())\n        # early stopping\n        if val_loss < best_val - 1e-4:\n            best_val = val_loss\n            best_state = copy.deepcopy(model.state_dict())\n            pat_count = 0\n        else:\n            pat_count += 1\n        if pat_count >= patience:\n            print(\"Early stopping.\")\n            break\n    model.load_state_dict(best_state)\n    test_loss, test_crwa, test_swa, test_cwa, yt, yp, seq = evaluate(model, test_loader)\n    run_data[\"losses\"][\"test\"] = test_loss\n    run_data[\"metrics\"][\"test\"] = {\"CRWA\": test_crwa, \"SWA\": test_swa, \"CWA\": test_cwa}\n    print(\n        f\"TEST: loss={test_loss:.4f} CRWA={test_crwa:.4f} SWA={test_swa:.4f} CWA={test_cwa:.4f}\"\n    )\n    experiment_data[\"num_epochs\"][f\"epochs_{max_epochs}\"] = run_data\n\n# ---------- save ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, numpy as np, torch, copy, warnings\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\nwarnings.filterwarnings(\"ignore\")\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ----------\ndef count_shape(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef CRWA(seqs, y_true, y_pred):\n    w = [count_shape(s) * count_color(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef SWA(seqs, y_true, y_pred):\n    w = [count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef CWA(seqs, y_true, y_pred):\n    w = [count_color(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------- dataset ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        dset = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH dataset.\")\n    except Exception as e:\n        print(\"Could not load real data, generating synthetic toy data.\", e)\n\n        def gen(n):\n            shapes, colors = \"ABCD\", \"abcd\"\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        dset = DatasetDict()\n        dset[\"train\"], dset[\"dev\"], dset[\"test\"] = gen(1000), gen(200), gen(200)\n    return dset\n\n\nspr = get_dataset()\n\n# ---------- vocab ----------\nall_tokens = set()\nall_labels = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\n    all_labels.add(ex[\"label\"])\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nlabel2id = {l: i for i, l in enumerate(sorted(all_labels))}\nid2label = {v: k for k, v in label2id.items()}\nvocab_size = len(tok2id) + 1\nnum_classes = len(label2id)\nprint(f\"Vocab size={vocab_size-1}, classes={num_classes}\")\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, hf_split):\n        self.seq = hf_split[\"sequence\"]\n        self.lbl = [label2id[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        ids = [tok2id[t] for t in self.seq[idx].split()]\n        return {\n            \"input_ids\": torch.tensor(ids),\n            \"length\": torch.tensor(len(ids)),\n            \"n_shape\": torch.tensor(count_shape(self.seq[idx])),\n            \"n_color\": torch.tensor(count_color(self.seq[idx])),\n            \"label\": torch.tensor(self.lbl[idx]),\n            \"raw_seq\": self.seq[idx],\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        l = b[\"length\"]\n        padded[i, :l] = b[\"input_ids\"]\n        mask[i, :l] = 1\n    return {\n        \"input_ids\": padded,\n        \"mask\": mask,\n        \"n_shape\": torch.stack([b[\"n_shape\"] for b in batch]),\n        \"n_color\": torch.stack([b[\"n_color\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbedClassifier(nn.Module):\n    def __init__(self, vocab, embed_dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.fc = nn.Linear(embed_dim + 2, num_cls)\n\n    def forward(self, ids, mask, feat):\n        emb = self.emb(ids)\n        mask = mask.unsqueeze(-1)\n        avg = (emb * mask).sum(1) / mask.sum(1).clamp(min=1)\n        return self.fc(torch.cat([avg, feat], -1))\n\n\n# ---------- helpers ----------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    all_s, all_t, all_p = [], [], []\n    loss_total = n = 0\n    with torch.no_grad():\n        for batch in loader:\n            b = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([b[\"n_shape\"], b[\"n_color\"]], -1).float()\n            logits = model(b[\"input_ids\"], b[\"mask\"], feat)\n            loss = criterion(logits, b[\"label\"])\n            loss_total += loss.item() * b[\"label\"].size(0)\n            n += b[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().numpy()\n            labels = b[\"label\"].cpu().numpy()\n            all_p.extend(preds)\n            all_t.extend(labels)\n            all_s.extend(batch[\"raw_seq\"])\n    return (\n        loss_total / n,\n        CRWA(all_s, all_t, all_p),\n        SWA(all_s, all_t, all_p),\n        CWA(all_s, all_t, all_p),\n        all_t,\n        all_p,\n        all_s,\n    )\n\n\n# ---------- hyperparameter tuning ----------\nepoch_options = [5, 10, 20, 30]\nexperiment_data = {\"num_epochs\": {}}\n\nfor max_epochs in epoch_options:\n    print(f\"\\n=== Training for up to {max_epochs} epochs ===\")\n    model = AvgEmbedClassifier(vocab_size, 64, num_classes).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    run_data = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    best_val = float(\"inf\")\n    patience, pat_count = 3, 0\n    for epoch in range(1, max_epochs + 1):\n        model.train()\n        ep_loss = m = 0\n        for batch in train_loader:\n            b = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            feat = torch.stack([b[\"n_shape\"], b[\"n_color\"]], -1).float()\n            optimizer.zero_grad()\n            logits = model(b[\"input_ids\"], b[\"mask\"], feat)\n            loss = criterion(logits, b[\"label\"])\n            loss.backward()\n            optimizer.step()\n            ep_loss += loss.item() * b[\"label\"].size(0)\n            m += b[\"label\"].size(0)\n        train_loss = ep_loss / m\n        val_loss, val_crwa, val_swa, val_cwa, y_true, y_pred, seqs = evaluate(\n            model, dev_loader\n        )\n        print(\n            f\"Epoch {epoch}: train={train_loss:.4f} val={val_loss:.4f} CRWA={val_crwa:.4f}\"\n        )\n        run_data[\"losses\"][\"train\"].append(train_loss)\n        run_data[\"losses\"][\"val\"].append(val_loss)\n        run_data[\"metrics\"][\"train\"].append(None)\n        run_data[\"metrics\"][\"val\"].append(\n            {\"CRWA\": val_crwa, \"SWA\": val_swa, \"CWA\": val_cwa}\n        )\n        run_data[\"predictions\"].append(y_pred)\n        run_data[\"ground_truth\"].append(y_true)\n        run_data[\"timestamps\"].append(time.time())\n        # early stopping\n        if val_loss < best_val - 1e-4:\n            best_val = val_loss\n            best_state = copy.deepcopy(model.state_dict())\n            pat_count = 0\n        else:\n            pat_count += 1\n        if pat_count >= patience:\n            print(\"Early stopping.\")\n            break\n    model.load_state_dict(best_state)\n    test_loss, test_crwa, test_swa, test_cwa, yt, yp, seq = evaluate(model, test_loader)\n    run_data[\"losses\"][\"test\"] = test_loss\n    run_data[\"metrics\"][\"test\"] = {\"CRWA\": test_crwa, \"SWA\": test_swa, \"CWA\": test_cwa}\n    print(\n        f\"TEST: loss={test_loss:.4f} CRWA={test_crwa:.4f} SWA={test_swa:.4f} CWA={test_cwa:.4f}\"\n    )\n    experiment_data[\"num_epochs\"][f\"epochs_{max_epochs}\"] = run_data\n\n# ---------- save ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 414084.57\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 121322.94\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 290591.05\nexamples/s]', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab size=16,\nclasses=2', '\\n', 'Epoch 1: train_loss=0.6096 | val_loss=0.5414 | CRWA=0.7315 |\nSWA=0.7400 | CWA=0.7351', '\\n', 'Epoch 2: train_loss=0.5262 | val_loss=0.5190 |\nCRWA=0.7652 | SWA=0.7707 | CWA=0.7663', '\\n', 'Epoch 3: train_loss=0.5126 |\nval_loss=0.5109 | CRWA=0.7653 | SWA=0.7715 | CWA=0.7668', '\\n', 'Epoch 4:\ntrain_loss=0.5047 | val_loss=0.5049 | CRWA=0.7755 | SWA=0.7806 | CWA=0.7785',\n'\\n', 'Epoch 5: train_loss=0.4983 | val_loss=0.4981 | CRWA=0.7653 | SWA=0.7718 |\nCWA=0.7673', '\\n', 'TEST: loss=0.7049 | CRWA=0.5945 | SWA=0.5931 | CWA=0.6213',\n'\\n', 'Execution time: 7 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '\\rGenerating train split: 20000 examples [00:00, 181513.06\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 180349.75\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 182378.49\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 436188.77\nexamples/s]', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab size=16,\nclasses=2', '\\n', '\\n=== Training for up to 5 epochs ===', '\\n', 'Epoch 1:\ntrain=0.6054 val=0.5391 CRWA=0.7262', '\\n', 'Epoch 2: train=0.5214 val=0.5115\nCRWA=0.7531', '\\n', 'Epoch 3: train=0.5056 val=0.5035 CRWA=0.7585', '\\n', 'Epoch\n4: train=0.4979 val=0.4980 CRWA=0.7555', '\\n', 'Epoch 5: train=0.4919 val=0.4930\nCRWA=0.7669', '\\n', 'TEST: loss=0.7067 CRWA=0.5961 SWA=0.5944 CWA=0.6230', '\\n',\n'\\n=== Training for up to 10 epochs ===', '\\n', 'Epoch 1: train=0.5858\nval=0.5405 CRWA=0.7218', '\\n', 'Epoch 2: train=0.5268 val=0.5194 CRWA=0.7394',\n'\\n', 'Epoch 3: train=0.5130 val=0.5111 CRWA=0.7500', '\\n', 'Epoch 4:\ntrain=0.5048 val=0.5047 CRWA=0.7740', '\\n', 'Epoch 5: train=0.4983 val=0.4982\nCRWA=0.7652', '\\n', 'Epoch 6: train=0.4924 val=0.4925 CRWA=0.7695', '\\n', 'Epoch\n7: train=0.4869 val=0.4877 CRWA=0.7681', '\\n', 'Epoch 8: train=0.4825 val=0.4840\nCRWA=0.7683', '\\n', 'Epoch 9: train=0.4789 val=0.4809 CRWA=0.7701', '\\n', 'Epoch\n10: train=0.4750 val=0.4773 CRWA=0.7664', '\\n', 'TEST: loss=0.6873 CRWA=0.6015\nSWA=0.6003 CWA=0.6302', '\\n', '\\n=== Training for up to 20 epochs ===', '\\n',\n'Epoch 1: train=0.6093 val=0.5483 CRWA=0.7253', '\\n', 'Epoch 2: train=0.5284\nval=0.5186 CRWA=0.7534', '\\n', 'Epoch 3: train=0.5117 val=0.5104 CRWA=0.7422',\n'\\n', 'Epoch 4: train=0.5043 val=0.5044 CRWA=0.7622', '\\n', 'Epoch 5:\ntrain=0.4983 val=0.4983 CRWA=0.7638', '\\n', 'Epoch 6: train=0.4927 val=0.4931\nCRWA=0.7645', '\\n', 'Epoch 7: train=0.4878 val=0.4889 CRWA=0.7675', '\\n', 'Epoch\n8: train=0.4835 val=0.4860 CRWA=0.7683', '\\n', 'Epoch 9: train=0.4793 val=0.4813\nCRWA=0.7660', '\\n', 'Epoch 10: train=0.4759 val=0.4792 CRWA=0.7647', '\\n',\n'Epoch 11: train=0.4725 val=0.4766 CRWA=0.7658', '\\n', 'Epoch 12: train=0.4701\nval=0.4726 CRWA=0.7660', '\\n', 'Epoch 13: train=0.4669 val=0.4712 CRWA=0.7615',\n'\\n', 'Epoch 14: train=0.4648 val=0.4687 CRWA=0.7559', '\\n', 'Epoch 15:\ntrain=0.4626 val=0.4683 CRWA=0.7622', '\\n', 'Epoch 16: train=0.4610 val=0.4660\nCRWA=0.7618', '\\n', 'Epoch 17: train=0.4591 val=0.4646 CRWA=0.7680', '\\n',\n'Epoch 18: train=0.4578 val=0.4628 CRWA=0.7683', '\\n', 'Epoch 19: train=0.4568\nval=0.4623 CRWA=0.7661', '\\n', 'Epoch 20: train=0.4555 val=0.4618 CRWA=0.7725',\n'\\n', 'TEST: loss=0.6891 CRWA=0.6134 SWA=0.6124 CWA=0.6443', '\\n', '\\n===\nTraining for up to 30 epochs ===', '\\n', 'Epoch 1: train=0.5924 val=0.5352\nCRWA=0.7438', '\\n', 'Epoch 2: train=0.5186 val=0.5107 CRWA=0.7592', '\\n', 'Epoch\n3: train=0.5045 val=0.5033 CRWA=0.7571', '\\n', 'Epoch 4: train=0.4979 val=0.4976\nCRWA=0.7637', '\\n', 'Epoch 5: train=0.4921 val=0.4927 CRWA=0.7693', '\\n', 'Epoch\n6: train=0.4870 val=0.4878 CRWA=0.7680', '\\n', 'Epoch 7: train=0.4825 val=0.4845\nCRWA=0.7648', '\\n', 'Epoch 8: train=0.4783 val=0.4806 CRWA=0.7735', '\\n', 'Epoch\n9: train=0.4749 val=0.4777 CRWA=0.7649', '\\n', 'Epoch 10: train=0.4714\nval=0.4758 CRWA=0.7660', '\\n', 'Epoch 11: train=0.4687 val=0.4738 CRWA=0.7667',\n'\\n', 'Epoch 12: train=0.4663 val=0.4723 CRWA=0.7631', '\\n', 'Epoch 13:\ntrain=0.4640 val=0.4685 CRWA=0.7724', '\\n', 'Epoch 14: train=0.4619 val=0.4665\nCRWA=0.7640', '\\n', 'Epoch 15: train=0.4602 val=0.4650 CRWA=0.7708', '\\n',\n'Epoch 16: train=0.4585 val=0.4636 CRWA=0.7642', '\\n', 'Epoch 17: train=0.4571\nval=0.4622 CRWA=0.7648', '\\n', 'Epoch 18: train=0.4558 val=0.4626 CRWA=0.7672',\n'\\n', 'Epoch 19: train=0.4554 val=0.4623 CRWA=0.7723', '\\n', 'Epoch 20:\ntrain=0.4538 val=0.4609 CRWA=0.7684', '\\n', 'Epoch 21: train=0.4532 val=0.4590\nCRWA=0.7649', '\\n', 'Epoch 22: train=0.4523 val=0.4586 CRWA=0.7678', '\\n',\n'Epoch 23: train=0.4517 val=0.4582 CRWA=0.7656', '\\n', 'Epoch 24: train=0.4510\nval=0.4575 CRWA=0.7652', '\\n', 'Epoch 25: train=0.4502 val=0.4584 CRWA=0.7666',\n'\\n', 'Epoch 26: train=0.4499 val=0.4558 CRWA=0.7643', '\\n', 'Epoch 27:\ntrain=0.4493 val=0.4570 CRWA=0.7675', '\\n', 'Epoch 28: train=0.4488 val=0.4555\nCRWA=0.7678', '\\n', 'Epoch 29: train=0.4487 val=0.4552 CRWA=0.7684', '\\n',\n'Epoch 30: train=0.4480 val=0.4553 CRWA=0.7647', '\\n', 'TEST: loss=0.6885\nCRWA=0.6172 SWA=0.6168 CWA=0.6494', '\\n', 'Saved experiment_data.npy', '\\n',\n'Execution time: 2 minutes seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '\\rGenerating train split: 10000 examples [00:00, 81688.66\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 92268.69\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 93014.53\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 202938.08\nexamples/s]', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab size=16,\nclasses=2', '\\n', '\\n===== TRAINING WITH learning_rate=0.0001 =====', '\\n',\n'Epoch 1: train_loss=0.7394 | val_loss=0.6936 | CRWA=0.5283 | SWA=0.5301 |\nCWA=0.5354', '\\n', 'Epoch 2: train_loss=0.6742 | val_loss=0.6556 | CRWA=0.6182 |\nSWA=0.6238 | CWA=0.6159', '\\n', 'Epoch 3: train_loss=0.6447 | val_loss=0.6310 |\nCRWA=0.6635 | SWA=0.6706 | CWA=0.6609', '\\n', 'Epoch 4: train_loss=0.6224 |\nval_loss=0.6105 | CRWA=0.6931 | SWA=0.7002 | CWA=0.6926', '\\n', 'Epoch 5:\ntrain_loss=0.6036 | val_loss=0.5933 | CRWA=0.7029 | SWA=0.7105 | CWA=0.7036',\n'\\n', 'TEST: loss=0.6771 | CRWA=0.5733 | SWA=0.5724 | CWA=0.5930', '\\n',\n'\\n===== TRAINING WITH learning_rate=0.0003 =====', '\\n', 'Epoch 1:\ntrain_loss=0.6612 | val_loss=0.6184 | CRWA=0.6935 | SWA=0.7022 | CWA=0.6966',\n'\\n', 'Epoch 2: train_loss=0.5935 | val_loss=0.5698 | CRWA=0.7317 | SWA=0.7403 |\nCWA=0.7358', '\\n', 'Epoch 3: train_loss=0.5561 | val_loss=0.5428 | CRWA=0.7353 |\nSWA=0.7445 | CWA=0.7392', '\\n', 'Epoch 4: train_loss=0.5349 | val_loss=0.5280 |\nCRWA=0.7429 | SWA=0.7514 | CWA=0.7459', '\\n', 'Epoch 5: train_loss=0.5230 |\nval_loss=0.5199 | CRWA=0.7415 | SWA=0.7497 | CWA=0.7450', '\\n', 'TEST:\nloss=0.6874 | CRWA=0.5969 | SWA=0.5954 | CWA=0.6218', '\\n', '\\n===== TRAINING\nWITH learning_rate=0.0005 =====', '\\n', 'Epoch 1: train_loss=0.6542 |\nval_loss=0.5799 | CRWA=0.7304 | SWA=0.7383 | CWA=0.7345', '\\n', 'Epoch 2:\ntrain_loss=0.5553 | val_loss=0.5355 | CRWA=0.7497 | SWA=0.7569 | CWA=0.7553',\n'\\n', 'Epoch 3: train_loss=0.5266 | val_loss=0.5188 | CRWA=0.7490 | SWA=0.7568 |\nCWA=0.7535', '\\n', 'Epoch 4: train_loss=0.5147 | val_loss=0.5120 | CRWA=0.7519 |\nSWA=0.7591 | CWA=0.7557', '\\n', 'Epoch 5: train_loss=0.5086 | val_loss=0.5081 |\nCRWA=0.7600 | SWA=0.7663 | CWA=0.7626', '\\n', 'TEST: loss=0.7035 | CRWA=0.5965 |\nSWA=0.5950 | CWA=0.6224', '\\n', '\\n===== TRAINING WITH learning_rate=0.001\n=====', '\\n', 'Epoch 1: train_loss=0.6039 | val_loss=0.5431 | CRWA=0.7375 |\nSWA=0.7456 | CWA=0.7430', '\\n', 'Epoch 2: train_loss=0.5256 | val_loss=0.5165 |\nCRWA=0.7414 | SWA=0.7496 | CWA=0.7454', '\\n', 'Epoch 3: train_loss=0.5103 |\nval_loss=0.5085 | CRWA=0.7541 | SWA=0.7619 | CWA=0.7566', '\\n', 'Epoch 4:\ntrain_loss=0.5029 | val_loss=0.5029 | CRWA=0.7690 | SWA=0.7746 | CWA=0.7712',\n'\\n', 'Epoch 5: train_loss=0.4970 | val_loss=0.4969 | CRWA=0.7690 | SWA=0.7746 |\nCWA=0.7715', '\\n', 'TEST: loss=0.7091 | CRWA=0.5960 | SWA=0.5941 | CWA=0.6228',\n'\\n', '\\n===== TRAINING WITH learning_rate=0.003 =====', '\\n', 'Epoch 1:\ntrain_loss=0.5327 | val_loss=0.5061 | CRWA=0.7453 | SWA=0.7547 | CWA=0.7499',\n'\\n', 'Epoch 2: train_loss=0.4948 | val_loss=0.4887 | CRWA=0.7698 | SWA=0.7766 |\nCWA=0.7722', '\\n', 'Epoch 3: train_loss=0.4812 | val_loss=0.4811 | CRWA=0.7631 |\nSWA=0.7705 | CWA=0.7678', '\\n', 'Epoch 4: train_loss=0.4719 | val_loss=0.4732 |\nCRWA=0.7769 | SWA=0.7840 | CWA=0.7826', '\\n', 'Epoch 5: train_loss=0.4656 |\nval_loss=0.4696 | CRWA=0.7635 | SWA=0.7710 | CWA=0.7715', '\\n', 'TEST:\nloss=0.6912 | CRWA=0.6074 | SWA=0.6063 | CWA=0.6368', '\\n', 'Saved\nexperiment_data.npy', '\\n', 'Execution time: 44 seconds seconds (time limit is\n30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 214221.35\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 56931.36\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 183657.83\nexamples/s]', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab size=16,\nclasses=2', '\\n', '\\n=== Training with batch size 32 ===', '\\n', 'Epoch 1:\ntrain_loss=0.5506 | val_loss=0.5141 | CRWA=0.7421 | SWA=0.7508 | CWA=0.7467',\n'\\n', 'Epoch 2: train_loss=0.5044 | val_loss=0.5001 | CRWA=0.7621 | SWA=0.7689 |\nCWA=0.7641', '\\n', 'Epoch 3: train_loss=0.4910 | val_loss=0.4890 | CRWA=0.7676 |\nSWA=0.7741 | CWA=0.7704', '\\n', 'Epoch 4: train_loss=0.4811 | val_loss=0.4823 |\nCRWA=0.7680 | SWA=0.7742 | CWA=0.7737', '\\n', 'Epoch 5: train_loss=0.4737 |\nval_loss=0.4744 | CRWA=0.7692 | SWA=0.7770 | CWA=0.7744', '\\n', 'TEST (bs=32):\nloss=0.6905 | CRWA=0.6056 | SWA=0.6045 | CWA=0.6350', '\\n', '\\n=== Training with\nbatch size 64 ===', '\\n', 'Epoch 1: train_loss=0.5662 | val_loss=0.5171 |\nCRWA=0.7477 | SWA=0.7558 | CWA=0.7505', '\\n', 'Epoch 2: train_loss=0.5089 |\nval_loss=0.5047 | CRWA=0.7624 | SWA=0.7685 | CWA=0.7640', '\\n', 'Epoch 3:\ntrain_loss=0.4980 | val_loss=0.4958 | CRWA=0.7678 | SWA=0.7744 | CWA=0.7701',\n'\\n', 'Epoch 4: train_loss=0.4898 | val_loss=0.4889 | CRWA=0.7679 | SWA=0.7749 |\nCWA=0.7704', '\\n', 'Epoch 5: train_loss=0.4823 | val_loss=0.4838 | CRWA=0.7719 |\nSWA=0.7786 | CWA=0.7763', '\\n', 'TEST (bs=64): loss=0.6966 | CRWA=0.6032 |\nSWA=0.6016 | CWA=0.6315', '\\n', '\\n=== Training with batch size 128 ===', '\\n',\n'Epoch 1: train_loss=0.6048 | val_loss=0.5349 | CRWA=0.7465 | SWA=0.7535 |\nCWA=0.7519', '\\n', 'Epoch 2: train_loss=0.5210 | val_loss=0.5123 | CRWA=0.7594 |\nSWA=0.7656 | CWA=0.7633', '\\n', 'Epoch 3: train_loss=0.5074 | val_loss=0.5052 |\nCRWA=0.7618 | SWA=0.7679 | CWA=0.7641', '\\n', 'Epoch 4: train_loss=0.5011 |\nval_loss=0.5008 | CRWA=0.7693 | SWA=0.7750 | CWA=0.7717', '\\n', 'Epoch 5:\ntrain_loss=0.4953 | val_loss=0.4956 | CRWA=0.7687 | SWA=0.7749 | CWA=0.7715',\n'\\n', 'TEST (bs=128): loss=0.7039 | CRWA=0.5958 | SWA=0.5944 | CWA=0.6227',\n'\\n', '\\n=== Training with batch size 256 ===', '\\n', 'Epoch 1:\ntrain_loss=0.6396 | val_loss=0.5826 | CRWA=0.7165 | SWA=0.7245 | CWA=0.7217',\n'\\n', 'Epoch 2: train_loss=0.5557 | val_loss=0.5362 | CRWA=0.7398 | SWA=0.7476 |\nCWA=0.7450', '\\n', 'Epoch 3: train_loss=0.5257 | val_loss=0.5199 | CRWA=0.7432 |\nSWA=0.7510 | CWA=0.7474', '\\n', 'Epoch 4: train_loss=0.5144 | val_loss=0.5128 |\nCRWA=0.7516 | SWA=0.7593 | CWA=0.7543', '\\n', 'Epoch 5: train_loss=0.5085 |\nval_loss=0.5082 | CRWA=0.7631 | SWA=0.7695 | CWA=0.7647', '\\n', 'TEST (bs=256):\nloss=0.7099 | CRWA=0.5943 | SWA=0.5926 | CWA=0.6203', '\\n', \"\\nHyperparameter\ntuning complete. Results saved to 'experiment_data.npy'\", '\\n', 'Execution time:\n44 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '\\rGenerating train split: 20000 examples [00:00, 177729.64\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 173682.22\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 123127.94\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 111425.28\nexamples/s]', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab size=16,\nclasses=2', '\\n', '\\n--- Training with embed_dim=32 ---', '\\n', 'Ep1:\ntrain_loss=0.6300 | val_loss=0.5732 | CRWA=0.7055 | SWA=0.7132 | CWA=0.7095',\n'\\n', 'Ep2: train_loss=0.5428 | val_loss=0.5223 | CRWA=0.7385 | SWA=0.7467 |\nCWA=0.7439', '\\n', 'Ep3: train_loss=0.5115 | val_loss=0.5064 | CRWA=0.7424 |\nSWA=0.7507 | CWA=0.7483', '\\n', 'Ep4: train_loss=0.5000 | val_loss=0.4989 |\nCRWA=0.7635 | SWA=0.7701 | CWA=0.7657', '\\n', 'Ep5: train_loss=0.4936 |\nval_loss=0.4940 | CRWA=0.7646 | SWA=0.7713 | CWA=0.7669', '\\n', 'TEST (dim=32):\nloss=0.6969 | CRWA=0.5943 | SWA=0.5930 | CWA=0.6212', '\\n', '\\n--- Training with\nembed_dim=64 ---', '\\n', 'Ep1: train_loss=0.5862 | val_loss=0.5312 | CRWA=0.7416\n| SWA=0.7491 | CWA=0.7445', '\\n', 'Ep2: train_loss=0.5203 | val_loss=0.5158 |\nCRWA=0.7496 | SWA=0.7573 | CWA=0.7523', '\\n', 'Ep3: train_loss=0.5102 |\nval_loss=0.5095 | CRWA=0.7717 | SWA=0.7767 | CWA=0.7741', '\\n', 'Ep4:\ntrain_loss=0.5028 | val_loss=0.5023 | CRWA=0.7660 | SWA=0.7722 | CWA=0.7677',\n'\\n', 'Ep5: train_loss=0.4964 | val_loss=0.4967 | CRWA=0.7660 | SWA=0.7724 |\nCWA=0.7682', '\\n', 'TEST (dim=64): loss=0.7087 | CRWA=0.5939 | SWA=0.5922 |\nCWA=0.6204', '\\n', '\\n--- Training with embed_dim=128 ---', '\\n', 'Ep1:\ntrain_loss=0.5536 | val_loss=0.5144 | CRWA=0.7448 | SWA=0.7531 | CWA=0.7480',\n'\\n', 'Ep2: train_loss=0.5074 | val_loss=0.5048 | CRWA=0.7565 | SWA=0.7639 |\nCWA=0.7593', '\\n', 'Ep3: train_loss=0.4996 | val_loss=0.5000 | CRWA=0.7714 |\nSWA=0.7770 | CWA=0.7742', '\\n', 'Ep4: train_loss=0.4929 | val_loss=0.4979 |\nCRWA=0.7687 | SWA=0.7742 | CWA=0.7741', '\\n', 'Ep5: train_loss=0.4877 |\nval_loss=0.4887 | CRWA=0.7667 | SWA=0.7739 | CWA=0.7701', '\\n', 'TEST (dim=128):\nloss=0.6947 | CRWA=0.6005 | SWA=0.5990 | CWA=0.6282', '\\n', '\\n--- Training with\nembed_dim=256 ---', '\\n', 'Ep1: train_loss=0.5372 | val_loss=0.5170 |\nCRWA=0.7617 | SWA=0.7666 | CWA=0.7634', '\\n', 'Ep2: train_loss=0.5122 |\nval_loss=0.5122 | CRWA=0.7742 | SWA=0.7784 | CWA=0.7773', '\\n', 'Ep3:\ntrain_loss=0.5034 | val_loss=0.5012 | CRWA=0.7696 | SWA=0.7750 | CWA=0.7718',\n'\\n', 'Ep4: train_loss=0.4960 | val_loss=0.4950 | CRWA=0.7621 | SWA=0.7690 |\nCWA=0.7654', '\\n', 'Ep5: train_loss=0.4900 | val_loss=0.4910 | CRWA=0.7695 |\nSWA=0.7757 | CWA=0.7731', '\\n', 'TEST (dim=256): loss=0.7061 | CRWA=0.5994 |\nSWA=0.5977 | CWA=0.6268', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_16-42-\n50_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-\n9/working/experiment_data.npy', '\\n', 'Execution time: 42 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab\nsize=16, classes=2', '\\n', '\\n=== Training with weight_decay=0.0 ===', '\\n',\n'Epoch 1: train_loss=0.6096 | val_loss=0.5414 | CRWA=0.7315 | SWA=0.7400 |\nCWA=0.7351', '\\n', 'Epoch 2: train_loss=0.5262 | val_loss=0.5190 | CRWA=0.7652 |\nSWA=0.7707 | CWA=0.7663', '\\n', 'Epoch 3: train_loss=0.5126 | val_loss=0.5109 |\nCRWA=0.7653 | SWA=0.7715 | CWA=0.7668', '\\n', 'Epoch 4: train_loss=0.5047 |\nval_loss=0.5049 | CRWA=0.7755 | SWA=0.7806 | CWA=0.7785', '\\n', 'Epoch 5:\ntrain_loss=0.4983 | val_loss=0.4981 | CRWA=0.7653 | SWA=0.7718 | CWA=0.7673',\n'\\n', 'TEST: loss=0.7049 | CRWA=0.5945 | SWA=0.5931 | CWA=0.6213', '\\n', '\\n===\nTraining with weight_decay=1e-05 ===', '\\n', 'Epoch 1: train_loss=0.5967 |\nval_loss=0.5358 | CRWA=0.7364 | SWA=0.7454 | CWA=0.7400', '\\n', 'Epoch 2:\ntrain_loss=0.5212 | val_loss=0.5125 | CRWA=0.7512 | SWA=0.7591 | CWA=0.7536',\n'\\n', 'Epoch 3: train_loss=0.5071 | val_loss=0.5050 | CRWA=0.7617 | SWA=0.7687 |\nCWA=0.7635', '\\n', 'Epoch 4: train_loss=0.4999 | val_loss=0.4992 | CRWA=0.7656 |\nSWA=0.7722 | CWA=0.7676', '\\n', 'Epoch 5: train_loss=0.4936 | val_loss=0.4946 |\nCRWA=0.7672 | SWA=0.7735 | CWA=0.7701', '\\n', 'TEST: loss=0.7034 | CRWA=0.5955 |\nSWA=0.5938 | CWA=0.6224', '\\n', '\\n=== Training with weight_decay=0.0001 ===',\n'\\n', 'Epoch 1: train_loss=0.6052 | val_loss=0.5354 | CRWA=0.7458 | SWA=0.7528 |\nCWA=0.7515', '\\n', 'Epoch 2: train_loss=0.5215 | val_loss=0.5127 | CRWA=0.7591 |\nSWA=0.7653 | CWA=0.7633', '\\n', 'Epoch 3: train_loss=0.5077 | val_loss=0.5056 |\nCRWA=0.7605 | SWA=0.7669 | CWA=0.7626', '\\n', 'Epoch 4: train_loss=0.5015 |\nval_loss=0.5012 | CRWA=0.7692 | SWA=0.7749 | CWA=0.7716', '\\n', 'Epoch 5:\ntrain_loss=0.4958 | val_loss=0.4963 | CRWA=0.7670 | SWA=0.7732 | CWA=0.7697',\n'\\n', 'TEST: loss=0.7035 | CRWA=0.5959 | SWA=0.5943 | CWA=0.6228', '\\n', '\\n===\nTraining with weight_decay=0.001 ===', '\\n', 'Epoch 1: train_loss=0.6091 |\nval_loss=0.5523 | CRWA=0.7364 | SWA=0.7440 | CWA=0.7420', '\\n', 'Epoch 2:\ntrain_loss=0.5342 | val_loss=0.5227 | CRWA=0.7433 | SWA=0.7516 | CWA=0.7476',\n'\\n', 'Epoch 3: train_loss=0.5158 | val_loss=0.5128 | CRWA=0.7465 | SWA=0.7546 |\nCWA=0.7502', '\\n', 'Epoch 4: train_loss=0.5076 | val_loss=0.5071 | CRWA=0.7659 |\nSWA=0.7722 | CWA=0.7677', '\\n', 'Epoch 5: train_loss=0.5019 | val_loss=0.5020 |\nCRWA=0.7642 | SWA=0.7707 | CWA=0.7666', '\\n', 'TEST: loss=0.6965 | CRWA=0.5951 |\nSWA=0.5935 | CWA=0.6217', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_16-42-\n50_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-\n7/working/experiment_data.npy', '\\n', 'Execution time: 39 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab\nsize=16, classes=2', '\\n', '\\n=== Training with dropout=0.0 ===', '\\n', 'Epoch\n1: train_loss=0.6054 | val_loss=0.5391 | CRWA=0.7262', '\\n', 'Epoch 2:\ntrain_loss=0.5214 | val_loss=0.5115 | CRWA=0.7531', '\\n', 'Epoch 3:\ntrain_loss=0.5056 | val_loss=0.5035 | CRWA=0.7585', '\\n', 'Epoch 4:\ntrain_loss=0.4979 | val_loss=0.4980 | CRWA=0.7555', '\\n', 'Epoch 5:\ntrain_loss=0.4919 | val_loss=0.4930 | CRWA=0.7669', '\\n', '\\n=== Training with\ndropout=0.1 ===', '\\n', 'Epoch 1: train_loss=0.6019 | val_loss=0.5462 |\nCRWA=0.7277', '\\n', 'Epoch 2: train_loss=0.5338 | val_loss=0.5208 |\nCRWA=0.7226', '\\n', 'Epoch 3: train_loss=0.5217 | val_loss=0.5134 |\nCRWA=0.7594', '\\n', 'Epoch 4: train_loss=0.5193 | val_loss=0.5104 |\nCRWA=0.7590', '\\n', 'Epoch 5: train_loss=0.5164 | val_loss=0.5092 |\nCRWA=0.7381', '\\n', '\\n=== Training with dropout=0.2 ===', '\\n', 'Epoch 1:\ntrain_loss=0.6350 | val_loss=0.5487 | CRWA=0.7342', '\\n', 'Epoch 2:\ntrain_loss=0.5393 | val_loss=0.5184 | CRWA=0.7491', '\\n', 'Epoch 3:\ntrain_loss=0.5284 | val_loss=0.5140 | CRWA=0.7420', '\\n', 'Epoch 4:\ntrain_loss=0.5241 | val_loss=0.5129 | CRWA=0.7513', '\\n', 'Epoch 5:\ntrain_loss=0.5236 | val_loss=0.5131 | CRWA=0.7484', '\\n', '\\n=== Training with\ndropout=0.3 ===', '\\n', 'Epoch 1: train_loss=0.6235 | val_loss=0.5501 |\nCRWA=0.7291', '\\n', 'Epoch 2: train_loss=0.5451 | val_loss=0.5215 |\nCRWA=0.7413', '\\n', 'Epoch 3: train_loss=0.5359 | val_loss=0.5177 |\nCRWA=0.7423', '\\n', 'Epoch 4: train_loss=0.5330 | val_loss=0.5180 |\nCRWA=0.7633', '\\n', 'Epoch 5: train_loss=0.5312 | val_loss=0.5163 |\nCRWA=0.7529', '\\n', '\\n=== Training with dropout=0.5 ===', '\\n', 'Epoch 1:\ntrain_loss=0.6299 | val_loss=0.5528 | CRWA=0.7351', '\\n', 'Epoch 2:\ntrain_loss=0.5613 | val_loss=0.5286 | CRWA=0.7442', '\\n', 'Epoch 3:\ntrain_loss=0.5512 | val_loss=0.5237 | CRWA=0.7249', '\\n', 'Epoch 4:\ntrain_loss=0.5485 | val_loss=0.5220 | CRWA=0.7459', '\\n', 'Epoch 5:\ntrain_loss=0.5411 | val_loss=0.5214 | CRWA=0.7551', '\\n', '\\nBest dropout rate\nby dev CRWA = 0.0', '\\n', 'TEST: loss=0.7067 | CRWA=0.5961 | SWA=0.5944 |\nCWA=0.6230', '\\n', 'Execution time: 40 seconds seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab\nsize=16, classes=2', '\\n', '\\n=== Training with label_smoothing=0.0 ===', '\\n',\n'Epoch 1: train_loss=0.5958 | val_loss=0.5353 | CRWA=0.7306 | SWA=0.7396 |\nCWA=0.7350', '\\n', 'Epoch 2: train_loss=0.5190 | val_loss=0.5136 | CRWA=0.7554 |\nSWA=0.7627 | CWA=0.7573', '\\n', 'Epoch 3: train_loss=0.5066 | val_loss=0.5055 |\nCRWA=0.7631 | SWA=0.7698 | CWA=0.7644', '\\n', 'Epoch 4: train_loss=0.4994 |\nval_loss=0.4989 | CRWA=0.7639 | SWA=0.7705 | CWA=0.7661', '\\n', 'Epoch 5:\ntrain_loss=0.4941 | val_loss=0.4953 | CRWA=0.7674 | SWA=0.7730 | CWA=0.7704',\n'\\n', 'TEST: loss=0.7107 | CRWA=0.5957 | SWA=0.5938 | CWA=0.6226', '\\n', '\\n===\nTraining with label_smoothing=0.05 ===', '\\n', 'Epoch 1: train_loss=0.6038 |\nval_loss=0.5504 | CRWA=0.7318 | SWA=0.7407 | CWA=0.7363', '\\n', 'Epoch 2:\ntrain_loss=0.5373 | val_loss=0.5332 | CRWA=0.7581 | SWA=0.7650 | CWA=0.7599',\n'\\n', 'Epoch 3: train_loss=0.5272 | val_loss=0.5262 | CRWA=0.7627 | SWA=0.7694 |\nCWA=0.7639', '\\n', 'Epoch 4: train_loss=0.5210 | val_loss=0.5205 | CRWA=0.7649 |\nSWA=0.7717 | CWA=0.7673', '\\n', 'Epoch 5: train_loss=0.5163 | val_loss=0.5175 |\nCRWA=0.7653 | SWA=0.7712 | CWA=0.7687', '\\n', 'TEST: loss=0.7046 | CRWA=0.5964 |\nSWA=0.5947 | CWA=0.6236', '\\n', '\\n=== Training with label_smoothing=0.1 ===',\n'\\n', 'Epoch 1: train_loss=0.6117 | val_loss=0.5649 | CRWA=0.7323 | SWA=0.7410 |\nCWA=0.7369', '\\n', 'Epoch 2: train_loss=0.5544 | val_loss=0.5512 | CRWA=0.7589 |\nSWA=0.7657 | CWA=0.7605', '\\n', 'Epoch 3: train_loss=0.5462 | val_loss=0.5453 |\nCRWA=0.7626 | SWA=0.7693 | CWA=0.7638', '\\n', 'Epoch 4: train_loss=0.5407 |\nval_loss=0.5403 | CRWA=0.7653 | SWA=0.7720 | CWA=0.7677', '\\n', 'Epoch 5:\ntrain_loss=0.5366 | val_loss=0.5378 | CRWA=0.7633 | SWA=0.7696 | CWA=0.7671',\n'\\n', 'TEST: loss=0.6999 | CRWA=0.5975 | SWA=0.5958 | CWA=0.6246', '\\n', '\\n===\nTraining with label_smoothing=0.2 ===', '\\n', 'Epoch 1: train_loss=0.6268 |\nval_loss=0.5917 | CRWA=0.7346 | SWA=0.7433 | CWA=0.7393', '\\n', 'Epoch 2:\ntrain_loss=0.5852 | val_loss=0.5832 | CRWA=0.7610 | SWA=0.7676 | CWA=0.7629',\n'\\n', 'Epoch 3: train_loss=0.5795 | val_loss=0.5787 | CRWA=0.7633 | SWA=0.7699 |\nCWA=0.7652', '\\n', 'Epoch 4: train_loss=0.5753 | val_loss=0.5751 | CRWA=0.7660 |\nSWA=0.7728 | CWA=0.7685', '\\n', 'Epoch 5: train_loss=0.5723 | val_loss=0.5733 |\nCRWA=0.7596 | SWA=0.7662 | CWA=0.7640', '\\n', 'TEST: loss=0.6939 | CRWA=0.5980 |\nSWA=0.5963 | CWA=0.6253', '\\n', 'Saved results to', ' ', '/home/zxl240011/AI-Sci\nentist-v2/experiments/2025-08-15_16-42-\n50_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-\n8/working/experiment_data.npy', '\\n', 'Execution time: 29 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab\nsize=16, classes=2', '\\n', '\\n=== Training with gradient_clip_norm=none ===',\n'\\n', 'Epoch 1: train_loss=0.6054 | val_loss=0.5391 | CRWA=0.7262 | SWA=0.7356 |\nCWA=0.7328', '\\n', 'Epoch 2: train_loss=0.5214 | val_loss=0.5115 | CRWA=0.7531 |\nSWA=0.7614 | CWA=0.7563', '\\n', 'Epoch 3: train_loss=0.5056 | val_loss=0.5035 |\nCRWA=0.7585 | SWA=0.7661 | CWA=0.7613', '\\n', 'Epoch 4: train_loss=0.4979 |\nval_loss=0.4980 | CRWA=0.7555 | SWA=0.7637 | CWA=0.7594', '\\n', 'Epoch 5:\ntrain_loss=0.4919 | val_loss=0.4930 | CRWA=0.7669 | SWA=0.7733 | CWA=0.7697',\n'\\n', 'TEST: loss=0.7067 | CRWA=0.5961 | SWA=0.5944 | CWA=0.6230', '\\n', '\\n===\nTraining with gradient_clip_norm=0.1 ===', '\\n', 'Epoch 1: train_loss=0.5805 |\nval_loss=0.5349 | CRWA=0.7239 | SWA=0.7328 | CWA=0.7294', '\\n', 'Epoch 2:\ntrain_loss=0.5191 | val_loss=0.5122 | CRWA=0.7513 | SWA=0.7586 | CWA=0.7533',\n'\\n', 'Epoch 3: train_loss=0.5047 | val_loss=0.5029 | CRWA=0.7538 | SWA=0.7614 |\nCWA=0.7574', '\\n', 'Epoch 4: train_loss=0.4950 | val_loss=0.4938 | CRWA=0.7689 |\nSWA=0.7749 | CWA=0.7720', '\\n', 'Epoch 5: train_loss=0.4872 | val_loss=0.4877 |\nCRWA=0.7673 | SWA=0.7744 | CWA=0.7701', '\\n', 'TEST: loss=0.6955 | CRWA=0.5982 |\nSWA=0.5968 | CWA=0.6256', '\\n', '\\n=== Training with gradient_clip_norm=0.5\n===', '\\n', 'Epoch 1: train_loss=0.6029 | val_loss=0.5385 | CRWA=0.7419 |\nSWA=0.7492 | CWA=0.7464', '\\n', 'Epoch 2: train_loss=0.5206 | val_loss=0.5131 |\nCRWA=0.7483 | SWA=0.7556 | CWA=0.7514', '\\n', 'Epoch 3: train_loss=0.5069 |\nval_loss=0.5046 | CRWA=0.7661 | SWA=0.7718 | CWA=0.7684', '\\n', 'Epoch 4:\ntrain_loss=0.4995 | val_loss=0.4987 | CRWA=0.7656 | SWA=0.7716 | CWA=0.7680',\n'\\n', 'Epoch 5: train_loss=0.4931 | val_loss=0.4945 | CRWA=0.7704 | SWA=0.7760 |\nCWA=0.7740', '\\n', 'TEST: loss=0.7136 | CRWA=0.5979 | SWA=0.5958 | CWA=0.6252',\n'\\n', '\\n=== Training with gradient_clip_norm=1.0 ===', '\\n', 'Epoch 1:\ntrain_loss=0.5976 | val_loss=0.5374 | CRWA=0.7261 | SWA=0.7339 | CWA=0.7313',\n'\\n', 'Epoch 2: train_loss=0.5234 | val_loss=0.5144 | CRWA=0.7500 | SWA=0.7562 |\nCWA=0.7533', '\\n', 'Epoch 3: train_loss=0.5090 | val_loss=0.5074 | CRWA=0.7670 |\nSWA=0.7725 | CWA=0.7697', '\\n', 'Epoch 4: train_loss=0.5011 | val_loss=0.5001 |\nCRWA=0.7736 | SWA=0.7785 | CWA=0.7766', '\\n', 'Epoch 5: train_loss=0.4951 |\nval_loss=0.4944 | CRWA=0.7689 | SWA=0.7751 | CWA=0.7715', '\\n', 'TEST:\nloss=0.7031 | CRWA=0.5954 | SWA=0.5939 | CWA=0.6222', '\\n', '\\n=== Training with\ngradient_clip_norm=5.0 ===', '\\n', 'Epoch 1: train_loss=0.6162 | val_loss=0.5537\n| CRWA=0.7302 | SWA=0.7369 | CWA=0.7349', '\\n', 'Epoch 2: train_loss=0.5285 |\nval_loss=0.5181 | CRWA=0.7396 | SWA=0.7483 | CWA=0.7441', '\\n', 'Epoch 3:\ntrain_loss=0.5104 | val_loss=0.5083 | CRWA=0.7579 | SWA=0.7653 | CWA=0.7604',\n'\\n', 'Epoch 4: train_loss=0.5028 | val_loss=0.5023 | CRWA=0.7636 | SWA=0.7704 |\nCWA=0.7653', '\\n', 'Epoch 5: train_loss=0.4966 | val_loss=0.4971 | CRWA=0.7645 |\nSWA=0.7712 | CWA=0.7668', '\\n', 'TEST: loss=0.7015 | CRWA=0.5942 | SWA=0.5928 |\nCWA=0.6211', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientis\nt-v2/experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/0-\nrun/process_ForkProcess-6/working/experiment_data.npy', '\\n', 'Execution time:\n30 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab\nsize=16, classes=2', '\\n', '\\n=== Training for up to 5 epochs ===', '\\n', 'Epoch\n1: train=0.6054 val=0.5391 CRWA=0.7262', '\\n', 'Epoch 2: train=0.5214 val=0.5115\nCRWA=0.7531', '\\n', 'Epoch 3: train=0.5056 val=0.5035 CRWA=0.7585', '\\n', 'Epoch\n4: train=0.4979 val=0.4980 CRWA=0.7555', '\\n', 'Epoch 5: train=0.4919 val=0.4930\nCRWA=0.7669', '\\n', 'TEST: loss=0.7067 CRWA=0.5961 SWA=0.5944 CWA=0.6230', '\\n',\n'\\n=== Training for up to 10 epochs ===', '\\n', 'Epoch 1: train=0.5858\nval=0.5405 CRWA=0.7218', '\\n', 'Epoch 2: train=0.5268 val=0.5194 CRWA=0.7394',\n'\\n', 'Epoch 3: train=0.5130 val=0.5111 CRWA=0.7500', '\\n', 'Epoch 4:\ntrain=0.5048 val=0.5047 CRWA=0.7740', '\\n', 'Epoch 5: train=0.4983 val=0.4982\nCRWA=0.7652', '\\n', 'Epoch 6: train=0.4924 val=0.4925 CRWA=0.7695', '\\n', 'Epoch\n7: train=0.4869 val=0.4877 CRWA=0.7681', '\\n', 'Epoch 8: train=0.4825 val=0.4840\nCRWA=0.7683', '\\n', 'Epoch 9: train=0.4789 val=0.4809 CRWA=0.7701', '\\n', 'Epoch\n10: train=0.4750 val=0.4773 CRWA=0.7664', '\\n', 'TEST: loss=0.6873 CRWA=0.6015\nSWA=0.6003 CWA=0.6302', '\\n', '\\n=== Training for up to 20 epochs ===', '\\n',\n'Epoch 1: train=0.6093 val=0.5483 CRWA=0.7253', '\\n', 'Epoch 2: train=0.5284\nval=0.5186 CRWA=0.7534', '\\n', 'Epoch 3: train=0.5117 val=0.5104 CRWA=0.7422',\n'\\n', 'Epoch 4: train=0.5043 val=0.5044 CRWA=0.7622', '\\n', 'Epoch 5:\ntrain=0.4983 val=0.4983 CRWA=0.7638', '\\n', 'Epoch 6: train=0.4927 val=0.4931\nCRWA=0.7645', '\\n', 'Epoch 7: train=0.4878 val=0.4889 CRWA=0.7675', '\\n', 'Epoch\n8: train=0.4835 val=0.4860 CRWA=0.7683', '\\n', 'Epoch 9: train=0.4793 val=0.4813\nCRWA=0.7660', '\\n', 'Epoch 10: train=0.4759 val=0.4792 CRWA=0.7647', '\\n',\n'Epoch 11: train=0.4725 val=0.4766 CRWA=0.7658', '\\n', 'Epoch 12: train=0.4701\nval=0.4726 CRWA=0.7660', '\\n', 'Epoch 13: train=0.4669 val=0.4712 CRWA=0.7615',\n'\\n', 'Epoch 14: train=0.4648 val=0.4687 CRWA=0.7559', '\\n', 'Epoch 15:\ntrain=0.4626 val=0.4683 CRWA=0.7622', '\\n', 'Epoch 16: train=0.4610 val=0.4660\nCRWA=0.7618', '\\n', 'Epoch 17: train=0.4591 val=0.4646 CRWA=0.7680', '\\n',\n'Epoch 18: train=0.4578 val=0.4628 CRWA=0.7683', '\\n', 'Epoch 19: train=0.4568\nval=0.4623 CRWA=0.7661', '\\n', 'Epoch 20: train=0.4555 val=0.4618 CRWA=0.7725',\n'\\n', 'TEST: loss=0.6891 CRWA=0.6134 SWA=0.6124 CWA=0.6443', '\\n', '\\n===\nTraining for up to 30 epochs ===', '\\n', 'Epoch 1: train=0.5924 val=0.5352\nCRWA=0.7438', '\\n', 'Epoch 2: train=0.5186 val=0.5107 CRWA=0.7592', '\\n', 'Epoch\n3: train=0.5045 val=0.5033 CRWA=0.7571', '\\n', 'Epoch 4: train=0.4979 val=0.4976\nCRWA=0.7637', '\\n', 'Epoch 5: train=0.4921 val=0.4927 CRWA=0.7693', '\\n', 'Epoch\n6: train=0.4870 val=0.4878 CRWA=0.7680', '\\n', 'Epoch 7: train=0.4825 val=0.4845\nCRWA=0.7648', '\\n', 'Epoch 8: train=0.4783 val=0.4806 CRWA=0.7735', '\\n', 'Epoch\n9: train=0.4749 val=0.4777 CRWA=0.7649', '\\n', 'Epoch 10: train=0.4714\nval=0.4758 CRWA=0.7660', '\\n', 'Epoch 11: train=0.4687 val=0.4738 CRWA=0.7667',\n'\\n', 'Epoch 12: train=0.4663 val=0.4723 CRWA=0.7631', '\\n', 'Epoch 13:\ntrain=0.4640 val=0.4685 CRWA=0.7724', '\\n', 'Epoch 14: train=0.4619 val=0.4665\nCRWA=0.7640', '\\n', 'Epoch 15: train=0.4602 val=0.4650 CRWA=0.7708', '\\n',\n'Epoch 16: train=0.4585 val=0.4636 CRWA=0.7642', '\\n', 'Epoch 17: train=0.4571\nval=0.4622 CRWA=0.7648', '\\n', 'Epoch 18: train=0.4558 val=0.4626 CRWA=0.7672',\n'\\n', 'Epoch 19: train=0.4554 val=0.4623 CRWA=0.7723', '\\n', 'Epoch 20:\ntrain=0.4538 val=0.4609 CRWA=0.7684', '\\n', 'Epoch 21: train=0.4532 val=0.4590\nCRWA=0.7649', '\\n', 'Epoch 22: train=0.4523 val=0.4586 CRWA=0.7678', '\\n',\n'Epoch 23: train=0.4517 val=0.4582 CRWA=0.7656', '\\n', 'Epoch 24: train=0.4510\nval=0.4575 CRWA=0.7652', '\\n', 'Epoch 25: train=0.4502 val=0.4584 CRWA=0.7666',\n'\\n', 'Epoch 26: train=0.4499 val=0.4558 CRWA=0.7643', '\\n', 'Epoch 27:\ntrain=0.4493 val=0.4570 CRWA=0.7675', '\\n', 'Epoch 28: train=0.4488 val=0.4555\nCRWA=0.7678', '\\n', 'Epoch 29: train=0.4487 val=0.4552 CRWA=0.7684', '\\n',\n'Epoch 30: train=0.4480 val=0.4553 CRWA=0.7647', '\\n', 'TEST: loss=0.6885\nCRWA=0.6172 SWA=0.6168 CWA=0.6494', '\\n', 'Saved experiment_data.npy', '\\n',\n'Execution time: a minute seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab\nsize=16, classes=2', '\\n', '\\n=== Training for up to 5 epochs ===', '\\n', 'Epoch\n1: train=0.6054 val=0.5391 CRWA=0.7262', '\\n', 'Epoch 2: train=0.5214 val=0.5115\nCRWA=0.7531', '\\n', 'Epoch 3: train=0.5056 val=0.5035 CRWA=0.7585', '\\n', 'Epoch\n4: train=0.4979 val=0.4980 CRWA=0.7555', '\\n', 'Epoch 5: train=0.4919 val=0.4930\nCRWA=0.7669', '\\n', 'TEST: loss=0.7067 CRWA=0.5961 SWA=0.5944 CWA=0.6230', '\\n',\n'\\n=== Training for up to 10 epochs ===', '\\n', 'Epoch 1: train=0.5858\nval=0.5405 CRWA=0.7218', '\\n', 'Epoch 2: train=0.5268 val=0.5194 CRWA=0.7394',\n'\\n', 'Epoch 3: train=0.5130 val=0.5111 CRWA=0.7500', '\\n', 'Epoch 4:\ntrain=0.5048 val=0.5047 CRWA=0.7740', '\\n', 'Epoch 5: train=0.4983 val=0.4982\nCRWA=0.7652', '\\n', 'Epoch 6: train=0.4924 val=0.4925 CRWA=0.7695', '\\n', 'Epoch\n7: train=0.4869 val=0.4877 CRWA=0.7681', '\\n', 'Epoch 8: train=0.4825 val=0.4840\nCRWA=0.7683', '\\n', 'Epoch 9: train=0.4789 val=0.4809 CRWA=0.7701', '\\n', 'Epoch\n10: train=0.4750 val=0.4773 CRWA=0.7664', '\\n', 'TEST: loss=0.6873 CRWA=0.6015\nSWA=0.6003 CWA=0.6302', '\\n', '\\n=== Training for up to 20 epochs ===', '\\n',\n'Epoch 1: train=0.6093 val=0.5483 CRWA=0.7253', '\\n', 'Epoch 2: train=0.5284\nval=0.5186 CRWA=0.7534', '\\n', 'Epoch 3: train=0.5117 val=0.5104 CRWA=0.7422',\n'\\n', 'Epoch 4: train=0.5043 val=0.5044 CRWA=0.7622', '\\n', 'Epoch 5:\ntrain=0.4983 val=0.4983 CRWA=0.7638', '\\n', 'Epoch 6: train=0.4927 val=0.4931\nCRWA=0.7645', '\\n', 'Epoch 7: train=0.4878 val=0.4889 CRWA=0.7675', '\\n', 'Epoch\n8: train=0.4835 val=0.4860 CRWA=0.7683', '\\n', 'Epoch 9: train=0.4793 val=0.4813\nCRWA=0.7660', '\\n', 'Epoch 10: train=0.4759 val=0.4792 CRWA=0.7647', '\\n',\n'Epoch 11: train=0.4725 val=0.4766 CRWA=0.7658', '\\n', 'Epoch 12: train=0.4701\nval=0.4726 CRWA=0.7660', '\\n', 'Epoch 13: train=0.4669 val=0.4712 CRWA=0.7615',\n'\\n', 'Epoch 14: train=0.4648 val=0.4687 CRWA=0.7559', '\\n', 'Epoch 15:\ntrain=0.4626 val=0.4683 CRWA=0.7622', '\\n', 'Epoch 16: train=0.4610 val=0.4660\nCRWA=0.7618', '\\n', 'Epoch 17: train=0.4591 val=0.4646 CRWA=0.7680', '\\n',\n'Epoch 18: train=0.4578 val=0.4628 CRWA=0.7683', '\\n', 'Epoch 19: train=0.4568\nval=0.4623 CRWA=0.7661', '\\n', 'Epoch 20: train=0.4555 val=0.4618 CRWA=0.7725',\n'\\n', 'TEST: loss=0.6891 CRWA=0.6134 SWA=0.6124 CWA=0.6443', '\\n', '\\n===\nTraining for up to 30 epochs ===', '\\n', 'Epoch 1: train=0.5924 val=0.5352\nCRWA=0.7438', '\\n', 'Epoch 2: train=0.5186 val=0.5107 CRWA=0.7592', '\\n', 'Epoch\n3: train=0.5045 val=0.5033 CRWA=0.7571', '\\n', 'Epoch 4: train=0.4979 val=0.4976\nCRWA=0.7637', '\\n', 'Epoch 5: train=0.4921 val=0.4927 CRWA=0.7693', '\\n', 'Epoch\n6: train=0.4870 val=0.4878 CRWA=0.7680', '\\n', 'Epoch 7: train=0.4825 val=0.4845\nCRWA=0.7648', '\\n', 'Epoch 8: train=0.4783 val=0.4806 CRWA=0.7735', '\\n', 'Epoch\n9: train=0.4749 val=0.4777 CRWA=0.7649', '\\n', 'Epoch 10: train=0.4714\nval=0.4758 CRWA=0.7660', '\\n', 'Epoch 11: train=0.4687 val=0.4738 CRWA=0.7667',\n'\\n', 'Epoch 12: train=0.4663 val=0.4723 CRWA=0.7631', '\\n', 'Epoch 13:\ntrain=0.4640 val=0.4685 CRWA=0.7724', '\\n', 'Epoch 14: train=0.4619 val=0.4665\nCRWA=0.7640', '\\n', 'Epoch 15: train=0.4602 val=0.4650 CRWA=0.7708', '\\n',\n'Epoch 16: train=0.4585 val=0.4636 CRWA=0.7642', '\\n', 'Epoch 17: train=0.4571\nval=0.4622 CRWA=0.7648', '\\n', 'Epoch 18: train=0.4558 val=0.4626 CRWA=0.7672',\n'\\n', 'Epoch 19: train=0.4554 val=0.4623 CRWA=0.7723', '\\n', 'Epoch 20:\ntrain=0.4538 val=0.4609 CRWA=0.7684', '\\n', 'Epoch 21: train=0.4532 val=0.4590\nCRWA=0.7649', '\\n', 'Epoch 22: train=0.4523 val=0.4586 CRWA=0.7678', '\\n',\n'Epoch 23: train=0.4517 val=0.4582 CRWA=0.7656', '\\n', 'Epoch 24: train=0.4510\nval=0.4575 CRWA=0.7652', '\\n', 'Epoch 25: train=0.4502 val=0.4584 CRWA=0.7666',\n'\\n', 'Epoch 26: train=0.4499 val=0.4558 CRWA=0.7643', '\\n', 'Epoch 27:\ntrain=0.4493 val=0.4570 CRWA=0.7675', '\\n', 'Epoch 28: train=0.4488 val=0.4555\nCRWA=0.7678', '\\n', 'Epoch 29: train=0.4487 val=0.4552 CRWA=0.7684', '\\n',\n'Epoch 30: train=0.4480 val=0.4553 CRWA=0.7647', '\\n', 'TEST: loss=0.6885\nCRWA=0.6172 SWA=0.6168 CWA=0.6494', '\\n', 'Saved experiment_data.npy', '\\n',\n'Execution time: a minute seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Vocab\nsize=16, classes=2', '\\n', '\\n=== Training for up to 5 epochs ===', '\\n', 'Epoch\n1: train=0.6054 val=0.5391 CRWA=0.7262', '\\n', 'Epoch 2: train=0.5214 val=0.5115\nCRWA=0.7531', '\\n', 'Epoch 3: train=0.5056 val=0.5035 CRWA=0.7585', '\\n', 'Epoch\n4: train=0.4979 val=0.4980 CRWA=0.7555', '\\n', 'Epoch 5: train=0.4919 val=0.4930\nCRWA=0.7669', '\\n', 'TEST: loss=0.7067 CRWA=0.5961 SWA=0.5944 CWA=0.6230', '\\n',\n'\\n=== Training for up to 10 epochs ===', '\\n', 'Epoch 1: train=0.5858\nval=0.5405 CRWA=0.7218', '\\n', 'Epoch 2: train=0.5268 val=0.5194 CRWA=0.7394',\n'\\n', 'Epoch 3: train=0.5130 val=0.5111 CRWA=0.7500', '\\n', 'Epoch 4:\ntrain=0.5048 val=0.5047 CRWA=0.7740', '\\n', 'Epoch 5: train=0.4983 val=0.4982\nCRWA=0.7652', '\\n', 'Epoch 6: train=0.4924 val=0.4925 CRWA=0.7695', '\\n', 'Epoch\n7: train=0.4869 val=0.4877 CRWA=0.7681', '\\n', 'Epoch 8: train=0.4825 val=0.4840\nCRWA=0.7683', '\\n', 'Epoch 9: train=0.4789 val=0.4809 CRWA=0.7701', '\\n', 'Epoch\n10: train=0.4750 val=0.4773 CRWA=0.7664', '\\n', 'TEST: loss=0.6873 CRWA=0.6015\nSWA=0.6003 CWA=0.6302', '\\n', '\\n=== Training for up to 20 epochs ===', '\\n',\n'Epoch 1: train=0.6093 val=0.5483 CRWA=0.7253', '\\n', 'Epoch 2: train=0.5284\nval=0.5186 CRWA=0.7534', '\\n', 'Epoch 3: train=0.5117 val=0.5104 CRWA=0.7422',\n'\\n', 'Epoch 4: train=0.5043 val=0.5044 CRWA=0.7622', '\\n', 'Epoch 5:\ntrain=0.4983 val=0.4983 CRWA=0.7638', '\\n', 'Epoch 6: train=0.4927 val=0.4931\nCRWA=0.7645', '\\n', 'Epoch 7: train=0.4878 val=0.4889 CRWA=0.7675', '\\n', 'Epoch\n8: train=0.4835 val=0.4860 CRWA=0.7683', '\\n', 'Epoch 9: train=0.4793 val=0.4813\nCRWA=0.7660', '\\n', 'Epoch 10: train=0.4759 val=0.4792 CRWA=0.7647', '\\n',\n'Epoch 11: train=0.4725 val=0.4766 CRWA=0.7658', '\\n', 'Epoch 12: train=0.4701\nval=0.4726 CRWA=0.7660', '\\n', 'Epoch 13: train=0.4669 val=0.4712 CRWA=0.7615',\n'\\n', 'Epoch 14: train=0.4648 val=0.4687 CRWA=0.7559', '\\n', 'Epoch 15:\ntrain=0.4626 val=0.4683 CRWA=0.7622', '\\n', 'Epoch 16: train=0.4610 val=0.4660\nCRWA=0.7618', '\\n', 'Epoch 17: train=0.4591 val=0.4646 CRWA=0.7680', '\\n',\n'Epoch 18: train=0.4578 val=0.4628 CRWA=0.7683', '\\n', 'Epoch 19: train=0.4568\nval=0.4623 CRWA=0.7661', '\\n', 'Epoch 20: train=0.4555 val=0.4618 CRWA=0.7725',\n'\\n', 'TEST: loss=0.6891 CRWA=0.6134 SWA=0.6124 CWA=0.6443', '\\n', '\\n===\nTraining for up to 30 epochs ===', '\\n', 'Epoch 1: train=0.5924 val=0.5352\nCRWA=0.7438', '\\n', 'Epoch 2: train=0.5186 val=0.5107 CRWA=0.7592', '\\n', 'Epoch\n3: train=0.5045 val=0.5033 CRWA=0.7571', '\\n', 'Epoch 4: train=0.4979 val=0.4976\nCRWA=0.7637', '\\n', 'Epoch 5: train=0.4921 val=0.4927 CRWA=0.7693', '\\n', 'Epoch\n6: train=0.4870 val=0.4878 CRWA=0.7680', '\\n', 'Epoch 7: train=0.4825 val=0.4845\nCRWA=0.7648', '\\n', 'Epoch 8: train=0.4783 val=0.4806 CRWA=0.7735', '\\n', 'Epoch\n9: train=0.4749 val=0.4777 CRWA=0.7649', '\\n', 'Epoch 10: train=0.4714\nval=0.4758 CRWA=0.7660', '\\n', 'Epoch 11: train=0.4687 val=0.4738 CRWA=0.7667',\n'\\n', 'Epoch 12: train=0.4663 val=0.4723 CRWA=0.7631', '\\n', 'Epoch 13:\ntrain=0.4640 val=0.4685 CRWA=0.7724', '\\n', 'Epoch 14: train=0.4619 val=0.4665\nCRWA=0.7640', '\\n', 'Epoch 15: train=0.4602 val=0.4650 CRWA=0.7708', '\\n',\n'Epoch 16: train=0.4585 val=0.4636 CRWA=0.7642', '\\n', 'Epoch 17: train=0.4571\nval=0.4622 CRWA=0.7648', '\\n', 'Epoch 18: train=0.4558 val=0.4626 CRWA=0.7672',\n'\\n', 'Epoch 19: train=0.4554 val=0.4623 CRWA=0.7723', '\\n', 'Epoch 20:\ntrain=0.4538 val=0.4609 CRWA=0.7684', '\\n', 'Epoch 21: train=0.4532 val=0.4590\nCRWA=0.7649', '\\n', 'Epoch 22: train=0.4523 val=0.4586 CRWA=0.7678', '\\n',\n'Epoch 23: train=0.4517 val=0.4582 CRWA=0.7656', '\\n', 'Epoch 24: train=0.4510\nval=0.4575 CRWA=0.7652', '\\n', 'Epoch 25: train=0.4502 val=0.4584 CRWA=0.7666',\n'\\n', 'Epoch 26: train=0.4499 val=0.4558 CRWA=0.7643', '\\n', 'Epoch 27:\ntrain=0.4493 val=0.4570 CRWA=0.7675', '\\n', 'Epoch 28: train=0.4488 val=0.4555\nCRWA=0.7678', '\\n', 'Epoch 29: train=0.4487 val=0.4552 CRWA=0.7684', '\\n',\n'Epoch 30: train=0.4480 val=0.4553 CRWA=0.7647', '\\n', 'TEST: loss=0.6885\nCRWA=0.6172 SWA=0.6168 CWA=0.6494', '\\n', 'Saved experiment_data.npy', '\\n',\n'Execution time: a minute seconds (time limit is 30 minutes).']", ""], "analysis": ["", "", "The execution of the training script was successful, with no bugs identified.\nThe script performed hyperparameter tuning over different learning rates and\nevaluated the model using CRWA, SWA, and CWA metrics. The results were logged\ncorrectly, and the experiment data was saved as expected. The model showed\nimprovements in metrics over epochs during training, and the execution completed\nwithin the time limit.", "", "", "", "The script executed successfully without any bugs. It loaded the dataset,\ntrained the model for different dropout rates, and evaluated performance using\nthe CRWA, SWA, and CWA metrics. The best dropout rate was identified as 0.0, and\nthe test results were provided. No issues were detected in the execution.", "", "", "", "", "", ""], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Loss during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4983, "best_value": 0.4983}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4981, "best_value": 0.4981}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Loss during testing phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7049, "best_value": 0.7049}]}, {"metric_name": "validation CRWA", "lower_is_better": false, "description": "CRWA metric during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7653, "best_value": 0.7653}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "SWA metric during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7718, "best_value": 0.7718}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "CWA metric during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7673, "best_value": 0.7673}]}, {"metric_name": "test CRWA", "lower_is_better": false, "description": "CRWA metric during testing phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5945, "best_value": 0.5945}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "SWA metric during testing phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5931, "best_value": 0.5931}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "CWA metric during testing phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6213, "best_value": 0.6213}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the loss during training. Lower values indicate better performance.", "data": [{"dataset_name": "Training Dataset", "final_value": 0.448, "best_value": 0.448}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the loss on the validation dataset. Lower values indicate better performance.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.4552, "best_value": 0.4552}]}, {"metric_name": "validation CRWA", "lower_is_better": false, "description": "CRWA metric on the validation dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7684, "best_value": 0.7725}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "SWA metric on the validation dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7772, "best_value": 0.7808}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "CWA metric on the validation dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7787, "best_value": 0.7804}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Measures the loss on the test dataset. Lower values indicate better performance.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6885, "best_value": 0.6873}]}, {"metric_name": "test CRWA", "lower_is_better": false, "description": "CRWA metric on the test dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6172, "best_value": 0.6172}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "SWA metric on the test dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6168, "best_value": 0.6168}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "CWA metric on the test dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6494, "best_value": 0.6494}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value on the training dataset.", "data": [{"dataset_name": "training", "final_value": 0.4656, "best_value": 0.4656}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset.", "data": [{"dataset_name": "validation", "final_value": 0.4696, "best_value": 0.4696}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value on the test dataset.", "data": [{"dataset_name": "test", "final_value": 0.6912, "best_value": 0.6912}]}, {"metric_name": "validation CRWA", "lower_is_better": false, "description": "CRWA metric on the validation dataset.", "data": [{"dataset_name": "validation", "final_value": 0.7635, "best_value": 0.769}]}, {"metric_name": "test CRWA", "lower_is_better": false, "description": "CRWA metric on the test dataset.", "data": [{"dataset_name": "test", "final_value": 0.6074, "best_value": 0.6074}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "SWA metric on the validation dataset.", "data": [{"dataset_name": "validation", "final_value": 0.771, "best_value": 0.7746}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "SWA metric on the test dataset.", "data": [{"dataset_name": "test", "final_value": 0.6063, "best_value": 0.6063}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "CWA metric on the validation dataset.", "data": [{"dataset_name": "validation", "final_value": 0.7715, "best_value": 0.7715}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "CWA metric on the test dataset.", "data": [{"dataset_name": "test", "final_value": 0.6368, "best_value": 0.6368}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value on the training dataset during the final epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4823, "best_value": 0.4823}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset during the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4838, "best_value": 0.4838}]}, {"metric_name": "validation CRWA", "lower_is_better": false, "description": "The CRWA metric on the validation dataset during the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7719, "best_value": 0.7719}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "The SWA metric on the validation dataset during the same epoch as the best validation CRWA.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7786, "best_value": 0.7786}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "The CWA metric on the validation dataset during the same epoch as the best validation CRWA.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7763, "best_value": 0.7763}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6966, "best_value": 0.6966}]}, {"metric_name": "test CRWA", "lower_is_better": false, "description": "The CRWA metric on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6032, "best_value": 0.6032}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "The SWA metric on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6016, "best_value": 0.6016}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "The CWA metric on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6315, "best_value": 0.6315}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value calculated on the training dataset at the end of training.", "data": [{"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.493645, "best_value": 0.493645}, {"dataset_name": "SPR_BENCH_dim_64", "final_value": 0.496428, "best_value": 0.496428}, {"dataset_name": "SPR_BENCH_dim_128", "final_value": 0.487696, "best_value": 0.487696}, {"dataset_name": "SPR_BENCH_dim_256", "final_value": 0.489999, "best_value": 0.489999}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value calculated on the validation dataset at the end of training.", "data": [{"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.493965, "best_value": 0.493965}, {"dataset_name": "SPR_BENCH_dim_64", "final_value": 0.496683, "best_value": 0.496683}, {"dataset_name": "SPR_BENCH_dim_128", "final_value": 0.48871, "best_value": 0.48871}, {"dataset_name": "SPR_BENCH_dim_256", "final_value": 0.49098, "best_value": 0.49098}]}, {"metric_name": "validation CRWA", "lower_is_better": false, "description": "The CRWA metric value calculated on the validation dataset at the end of training.", "data": [{"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.764614, "best_value": 0.764614}, {"dataset_name": "SPR_BENCH_dim_64", "final_value": 0.766033, "best_value": 0.766033}, {"dataset_name": "SPR_BENCH_dim_128", "final_value": 0.766706, "best_value": 0.766706}, {"dataset_name": "SPR_BENCH_dim_256", "final_value": 0.769454, "best_value": 0.769454}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "The SWA metric value calculated on the validation dataset at the end of training.", "data": [{"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.771306, "best_value": 0.771306}, {"dataset_name": "SPR_BENCH_dim_64", "final_value": 0.772352, "best_value": 0.772352}, {"dataset_name": "SPR_BENCH_dim_128", "final_value": 0.773864, "best_value": 0.773864}, {"dataset_name": "SPR_BENCH_dim_256", "final_value": 0.775666, "best_value": 0.775666}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "The CWA metric value calculated on the validation dataset at the end of training.", "data": [{"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.766945, "best_value": 0.766945}, {"dataset_name": "SPR_BENCH_dim_64", "final_value": 0.768165, "best_value": 0.768165}, {"dataset_name": "SPR_BENCH_dim_128", "final_value": 0.770057, "best_value": 0.770057}, {"dataset_name": "SPR_BENCH_dim_256", "final_value": 0.773107, "best_value": 0.773107}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value calculated on the test dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.696931, "best_value": 0.696931}, {"dataset_name": "SPR_BENCH_dim_64", "final_value": 0.708749, "best_value": 0.708749}, {"dataset_name": "SPR_BENCH_dim_128", "final_value": 0.694666, "best_value": 0.694666}, {"dataset_name": "SPR_BENCH_dim_256", "final_value": 0.706085, "best_value": 0.706085}]}, {"metric_name": "test CRWA", "lower_is_better": false, "description": "The CRWA metric value calculated on the test dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.594295, "best_value": 0.594295}, {"dataset_name": "SPR_BENCH_dim_64", "final_value": 0.593872, "best_value": 0.593872}, {"dataset_name": "SPR_BENCH_dim_128", "final_value": 0.600546, "best_value": 0.600546}, {"dataset_name": "SPR_BENCH_dim_256", "final_value": 0.599375, "best_value": 0.599375}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "The SWA metric value calculated on the test dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.592958, "best_value": 0.592958}, {"dataset_name": "SPR_BENCH_dim_64", "final_value": 0.592204, "best_value": 0.592204}, {"dataset_name": "SPR_BENCH_dim_128", "final_value": 0.599044, "best_value": 0.599044}, {"dataset_name": "SPR_BENCH_dim_256", "final_value": 0.597653, "best_value": 0.597653}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "The CWA metric value calculated on the test dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.621153, "best_value": 0.621153}, {"dataset_name": "SPR_BENCH_dim_64", "final_value": 0.620424, "best_value": 0.620424}, {"dataset_name": "SPR_BENCH_dim_128", "final_value": 0.628202, "best_value": 0.628202}, {"dataset_name": "SPR_BENCH_dim_256", "final_value": 0.626774, "best_value": 0.626774}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4936, "best_value": 0.4936}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4946, "best_value": 0.4946}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss calculated on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7034, "best_value": 0.7034}]}, {"metric_name": "validation CRWA", "lower_is_better": false, "description": "The CRWA score calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7672, "best_value": 0.7672}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "The SWA score calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7735, "best_value": 0.7735}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "The CWA score calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7701, "best_value": 0.7701}]}, {"metric_name": "test CRWA", "lower_is_better": false, "description": "The CRWA score calculated on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5955, "best_value": 0.5955}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "The SWA score calculated on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5938, "best_value": 0.5938}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "The CWA score calculated on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6224, "best_value": 0.6224}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the difference between predicted and true values. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH - Train", "final_value": 0.4919, "best_value": 0.4919}, {"dataset_name": "SPR_BENCH - Validation", "final_value": 0.493, "best_value": 0.493}, {"dataset_name": "SPR_BENCH - Test", "final_value": 0.7067, "best_value": 0.7067}]}, {"metric_name": "CRWA", "lower_is_better": false, "description": "A performance metric where higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH - Validation", "final_value": 0.7669, "best_value": 0.7669}, {"dataset_name": "SPR_BENCH - Test", "final_value": 0.5961, "best_value": 0.5961}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "A performance metric where higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH - Validation", "final_value": 0.7733, "best_value": 0.7733}, {"dataset_name": "SPR_BENCH - Test", "final_value": 0.5944, "best_value": 0.5944}]}, {"metric_name": "CWA", "lower_is_better": false, "description": "A performance metric where higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH - Validation", "final_value": 0.7697, "best_value": 0.7697}, {"dataset_name": "SPR_BENCH - Test", "final_value": 0.623, "best_value": 0.623}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The average loss value over the training dataset.", "data": [{"dataset_name": "label_smoothing = 0.0", "final_value": 0.4941, "best_value": 0.4941}, {"dataset_name": "label_smoothing = 0.05", "final_value": 0.5163, "best_value": 0.5163}, {"dataset_name": "label_smoothing = 0.1", "final_value": 0.5366, "best_value": 0.5366}, {"dataset_name": "label_smoothing = 0.2", "final_value": 0.5723, "best_value": 0.5723}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The average loss value over the validation dataset.", "data": [{"dataset_name": "label_smoothing = 0.0", "final_value": 0.4953, "best_value": 0.4953}, {"dataset_name": "label_smoothing = 0.05", "final_value": 0.5175, "best_value": 0.5175}, {"dataset_name": "label_smoothing = 0.1", "final_value": 0.5378, "best_value": 0.5378}, {"dataset_name": "label_smoothing = 0.2", "final_value": 0.5733, "best_value": 0.5733}]}, {"metric_name": "validation CRWA", "lower_is_better": false, "description": "The CRWA metric for the validation dataset.", "data": [{"dataset_name": "label_smoothing = 0.0", "final_value": 0.7674, "best_value": 0.7674}, {"dataset_name": "label_smoothing = 0.05", "final_value": 0.7653, "best_value": 0.7653}, {"dataset_name": "label_smoothing = 0.1", "final_value": 0.7633, "best_value": 0.7633}, {"dataset_name": "label_smoothing = 0.2", "final_value": 0.7596, "best_value": 0.7596}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "The SWA metric for the validation dataset.", "data": [{"dataset_name": "label_smoothing = 0.0", "final_value": 0.773, "best_value": 0.773}, {"dataset_name": "label_smoothing = 0.05", "final_value": 0.7712, "best_value": 0.7712}, {"dataset_name": "label_smoothing = 0.1", "final_value": 0.7696, "best_value": 0.7696}, {"dataset_name": "label_smoothing = 0.2", "final_value": 0.7662, "best_value": 0.7662}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "The CWA metric for the validation dataset.", "data": [{"dataset_name": "label_smoothing = 0.0", "final_value": 0.7704, "best_value": 0.7704}, {"dataset_name": "label_smoothing = 0.05", "final_value": 0.7687, "best_value": 0.7687}, {"dataset_name": "label_smoothing = 0.1", "final_value": 0.7671, "best_value": 0.7671}, {"dataset_name": "label_smoothing = 0.2", "final_value": 0.764, "best_value": 0.764}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The average loss value over the test dataset.", "data": [{"dataset_name": "label_smoothing = 0.0", "final_value": 0.7107, "best_value": 0.7107}, {"dataset_name": "label_smoothing = 0.05", "final_value": 0.7046, "best_value": 0.7046}, {"dataset_name": "label_smoothing = 0.1", "final_value": 0.6999, "best_value": 0.6999}, {"dataset_name": "label_smoothing = 0.2", "final_value": 0.6939, "best_value": 0.6939}]}, {"metric_name": "test CRWA", "lower_is_better": false, "description": "The CRWA metric for the test dataset.", "data": [{"dataset_name": "label_smoothing = 0.0", "final_value": 0.5957, "best_value": 0.5957}, {"dataset_name": "label_smoothing = 0.05", "final_value": 0.5964, "best_value": 0.5964}, {"dataset_name": "label_smoothing = 0.1", "final_value": 0.5975, "best_value": 0.5975}, {"dataset_name": "label_smoothing = 0.2", "final_value": 0.598, "best_value": 0.598}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "The SWA metric for the test dataset.", "data": [{"dataset_name": "label_smoothing = 0.0", "final_value": 0.5938, "best_value": 0.5938}, {"dataset_name": "label_smoothing = 0.05", "final_value": 0.5947, "best_value": 0.5947}, {"dataset_name": "label_smoothing = 0.1", "final_value": 0.5958, "best_value": 0.5958}, {"dataset_name": "label_smoothing = 0.2", "final_value": 0.5963, "best_value": 0.5963}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "The CWA metric for the test dataset.", "data": [{"dataset_name": "label_smoothing = 0.0", "final_value": 0.6226, "best_value": 0.6226}, {"dataset_name": "label_smoothing = 0.05", "final_value": 0.6236, "best_value": 0.6236}, {"dataset_name": "label_smoothing = 0.1", "final_value": 0.6246, "best_value": 0.6246}, {"dataset_name": "label_smoothing = 0.2", "final_value": 0.6253, "best_value": 0.6253}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Training loss measures the error during the training process.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.487228, "best_value": 0.487228}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss measures the error on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.487735, "best_value": 0.487735}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Test loss measures the error on the test set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.695507, "best_value": 0.695507}]}, {"metric_name": "test CRWA", "lower_is_better": false, "description": "Test CRWA is a performance metric specific to the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.59816, "best_value": 0.59816}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "Test SWA is another performance metric specific to the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.596841, "best_value": 0.596841}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "Test CWA is yet another performance metric specific to the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.625619, "best_value": 0.625619}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training; lower values are better.", "data": [{"dataset_name": "Training Dataset", "final_value": 0.448, "best_value": 0.448}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error during validation; lower values are better.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.4552, "best_value": 0.4552}]}, {"metric_name": "validation CRWA", "lower_is_better": false, "description": "Validation metric CRWA.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7684, "best_value": 0.7725}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "Validation metric SWA.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7772, "best_value": 0.7808}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "Validation metric CWA.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7787, "best_value": 0.7804}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Measures the error during testing; lower values are better.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6885, "best_value": 0.6873}]}, {"metric_name": "test CRWA", "lower_is_better": false, "description": "Test metric CRWA.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6172, "best_value": 0.6172}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "Test metric SWA.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6168, "best_value": 0.6168}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "Test metric CWA.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6494, "best_value": 0.6494}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value for the training dataset.", "data": [{"dataset_name": "Training Dataset", "final_value": 0.448, "best_value": 0.448}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value for the validation dataset.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.4552, "best_value": 0.4552}]}, {"metric_name": "validation CRWA", "lower_is_better": false, "description": "The CRWA metric for the validation dataset.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7684, "best_value": 0.7725}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "The SWA metric for the validation dataset.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7772, "best_value": 0.7808}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "The CWA metric for the validation dataset.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7787, "best_value": 0.7804}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value for the test dataset.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6885, "best_value": 0.6873}]}, {"metric_name": "test CRWA", "lower_is_better": false, "description": "The CRWA metric for the test dataset.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6172, "best_value": 0.6172}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "The SWA metric for the test dataset.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6168, "best_value": 0.6168}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "The CWA metric for the test dataset.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6494, "best_value": 0.6494}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training. Lower values indicate better performance.", "data": [{"dataset_name": "Training Dataset", "final_value": 0.448, "best_value": 0.448}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error on the validation dataset. Lower values indicate better performance.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.4552, "best_value": 0.4552}]}, {"metric_name": "validation CRWA", "lower_is_better": false, "description": "CRWA metric on the validation dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7684, "best_value": 0.7725}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "SWA metric on the validation dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7772, "best_value": 0.7808}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "CWA metric on the validation dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.7787, "best_value": 0.7804}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Measures the error on the test dataset. Lower values indicate better performance.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6885, "best_value": 0.6873}]}, {"metric_name": "test CRWA", "lower_is_better": false, "description": "CRWA metric on the test dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6172, "best_value": 0.6172}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "SWA metric on the test dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6168, "best_value": 0.6168}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "CWA metric on the test dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6494, "best_value": 0.6494}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, true, false, false, false, false, false, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_f74a22b4a2d54aa18ebd47df4ad6e88e_proc_2942477/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f74a22b4a2d54aa18ebd47df4ad6e88e_proc_2942477/SPR_BENCH_val_metric_curves.png", "../../logs/0-run/experiment_results/experiment_f74a22b4a2d54aa18ebd47df4ad6e88e_proc_2942477/SPR_BENCH_test_metrics_bar.png"], ["../../logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_5_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_10_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_20_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_30_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/test_metrics_comparison_SPR_BENCH.png"], ["../../logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_CRWA_vs_lr.png", "../../logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_SWA_vs_lr.png", "../../logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_CWA_vs_lr.png"], ["../../logs/0-run/experiment_results/experiment_2de8945897614fd2a28b0390701b0aa2_proc_2945036/SPR_BENCH_loss_curves_batch_size_tuning.png", "../../logs/0-run/experiment_results/experiment_2de8945897614fd2a28b0390701b0aa2_proc_2945036/SPR_BENCH_val_CRWA_curves_batch_size_tuning.png", "../../logs/0-run/experiment_results/experiment_2de8945897614fd2a28b0390701b0aa2_proc_2945036/SPR_BENCH_test_metrics_batch_size_tuning.png"], ["../../logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_32_loss_crwa.png", "../../logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_64_loss_crwa.png", "../../logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_128_loss_crwa.png", "../../logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_256_loss_crwa.png", "../../logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_test_CRWA_vs_dim.png"], ["../../logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_loss_vs_weight_decay.png", "../../logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_CRWA_vs_weight_decay.png", "../../logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_SWA_vs_weight_decay.png", "../../logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_CWA_vs_weight_decay.png"], ["../../logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.0.png", "../../logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.1.png", "../../logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.2.png", "../../logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.3.png", "../../logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.5.png"], ["../../logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.0_loss_metric.png", "../../logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.05_loss_metric.png", "../../logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.1_loss_metric.png", "../../logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.2_loss_metric.png", "../../logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_summary_metrics.png"], ["../../logs/0-run/experiment_results/experiment_1511daa747b74d76aed547736a56cee1_proc_2945034/SPR_BENCH_loss_curves_gradient_clip.png", "../../logs/0-run/experiment_results/experiment_1511daa747b74d76aed547736a56cee1_proc_2945034/SPR_BENCH_val_CRWA_gradient_clip.png", "../../logs/0-run/experiment_results/experiment_1511daa747b74d76aed547736a56cee1_proc_2945034/SPR_BENCH_test_CRWA_bar_gradient_clip.png"], ["../../logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_5_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_10_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_20_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_30_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/test_metrics_comparison_SPR_BENCH.png"], ["../../logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_5_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_10_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_20_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_30_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/test_metrics_comparison_SPR_BENCH.png"], ["../../logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_5_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_10_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_20_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_30_loss_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/test_metrics_comparison_SPR_BENCH.png"], ["../../logs/0-run/experiment_results/seed_aggregation_c38236ac46c2468d83d36797ac06b0b0/epochs_10_loss_mean_se_SPR_BENCH.png", "../../logs/0-run/experiment_results/seed_aggregation_c38236ac46c2468d83d36797ac06b0b0/epochs_20_loss_mean_se_SPR_BENCH.png", "../../logs/0-run/experiment_results/seed_aggregation_c38236ac46c2468d83d36797ac06b0b0/epochs_30_loss_mean_se_SPR_BENCH.png", "../../logs/0-run/experiment_results/seed_aggregation_c38236ac46c2468d83d36797ac06b0b0/epochs_5_loss_mean_se_SPR_BENCH.png", "../../logs/0-run/experiment_results/seed_aggregation_c38236ac46c2468d83d36797ac06b0b0/aggregated_test_metrics_SPR_BENCH.png"]], "plot_paths": [["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f74a22b4a2d54aa18ebd47df4ad6e88e_proc_2942477/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f74a22b4a2d54aa18ebd47df4ad6e88e_proc_2942477/SPR_BENCH_val_metric_curves.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f74a22b4a2d54aa18ebd47df4ad6e88e_proc_2942477/SPR_BENCH_test_metrics_bar.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_5_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_10_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_20_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_30_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/test_metrics_comparison_SPR_BENCH.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_CRWA_vs_lr.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_SWA_vs_lr.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_CWA_vs_lr.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2de8945897614fd2a28b0390701b0aa2_proc_2945036/SPR_BENCH_loss_curves_batch_size_tuning.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2de8945897614fd2a28b0390701b0aa2_proc_2945036/SPR_BENCH_val_CRWA_curves_batch_size_tuning.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2de8945897614fd2a28b0390701b0aa2_proc_2945036/SPR_BENCH_test_metrics_batch_size_tuning.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_32_loss_crwa.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_64_loss_crwa.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_128_loss_crwa.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_256_loss_crwa.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_test_CRWA_vs_dim.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_loss_vs_weight_decay.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_CRWA_vs_weight_decay.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_SWA_vs_weight_decay.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_CWA_vs_weight_decay.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.0.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.1.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.2.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.3.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.5.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.0_loss_metric.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.05_loss_metric.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.1_loss_metric.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.2_loss_metric.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_summary_metrics.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1511daa747b74d76aed547736a56cee1_proc_2945034/SPR_BENCH_loss_curves_gradient_clip.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1511daa747b74d76aed547736a56cee1_proc_2945034/SPR_BENCH_val_CRWA_gradient_clip.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1511daa747b74d76aed547736a56cee1_proc_2945034/SPR_BENCH_test_CRWA_bar_gradient_clip.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_5_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_10_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_20_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_30_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/test_metrics_comparison_SPR_BENCH.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_5_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_10_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_20_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_30_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/test_metrics_comparison_SPR_BENCH.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_5_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_10_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_20_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_30_loss_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/test_metrics_comparison_SPR_BENCH.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_c38236ac46c2468d83d36797ac06b0b0/epochs_10_loss_mean_se_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_c38236ac46c2468d83d36797ac06b0b0/epochs_20_loss_mean_se_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_c38236ac46c2468d83d36797ac06b0b0/epochs_30_loss_mean_se_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_c38236ac46c2468d83d36797ac06b0b0/epochs_5_loss_mean_se_SPR_BENCH.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_c38236ac46c2468d83d36797ac06b0b0/aggregated_test_metrics_SPR_BENCH.png"]], "plot_analyses": [[{"analysis": "This plot shows the training and validation loss over epochs. The training loss decreases steadily, indicating that the model is learning from the data. The validation loss also decreases, though at a slightly slower rate, which suggests that the model is generalizing well to unseen data without overfitting. The convergence of training and validation loss towards the end of the epochs is a positive sign of a well-trained model.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f74a22b4a2d54aa18ebd47df4ad6e88e_proc_2942477/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the progression of validation metrics (CRWA, SWA, and CWA) over epochs. All metrics improve over time, with SWA showing the highest performance, followed by CWA and CRWA. The metrics peak around epoch 3 and slightly decline after that, which could indicate the beginning of overfitting. This suggests that early stopping at epoch 3 might yield optimal results.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f74a22b4a2d54aa18ebd47df4ad6e88e_proc_2942477/SPR_BENCH_val_metric_curves.png"}, {"analysis": "This plot presents the final test metrics for CRWA, SWA, and CWA. The scores are relatively close, with all metrics achieving similar performance levels around 0.6. This consistency across metrics indicates that the model performs similarly across different evaluation criteria, demonstrating balanced performance on shape and color reasoning tasks.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f74a22b4a2d54aa18ebd47df4ad6e88e_proc_2942477/SPR_BENCH_test_metrics_bar.png"}], [{"analysis": "The plot shows the training and validation loss over 5 epochs. Both losses decrease steadily, indicating that the model is learning effectively during this period. The gap between training and validation loss is minimal, suggesting no overfitting at this stage.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_5_loss_SPR_BENCH.png"}, {"analysis": "The plot shows the training and validation loss over 10 epochs. Both losses continue to decrease, and the gap between them remains minimal. This indicates that the model maintains good generalization ability while improving its performance.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_10_loss_SPR_BENCH.png"}, {"analysis": "The plot shows the training and validation loss over 20 epochs. Both losses decrease further, with the validation loss slightly higher than the training loss, which is expected. The trend suggests the model is still learning and has not overfit to the training data.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_20_loss_SPR_BENCH.png"}, {"analysis": "The plot shows the training and validation loss over 30 epochs. Both losses decrease further and stabilize. The minimal gap between the two losses indicates that the model generalizes well to unseen data even after prolonged training.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/epochs_30_loss_SPR_BENCH.png"}, {"analysis": "The bar chart compares CRWA, SWA, and CWA test metrics across different epoch settings. All metrics improve slightly as the number of epochs increases, with CWA consistently achieving the highest score. This suggests that the model's performance in color-weighted tasks is slightly better than in shape-weighted and combined reasoning tasks.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21f62ea497054eed8c774237c58ed2da_proc_2945034/test_metrics_comparison_SPR_BENCH.png"}], [{"analysis": "The first plot shows the training and validation loss curves for various learning rates (lr). It is evident that lower learning rates (e.g., lr=1e-04) result in slower convergence, as indicated by the higher loss values across epochs. Higher learning rates (e.g., lr=3e-03) achieve faster convergence and lower loss values. However, the validation loss for lr=3e-03 shows some signs of instability, which might indicate overfitting or suboptimal generalization. Learning rates like 3e-04 and 5e-04 appear to strike a balance between convergence speed and stability, as their validation losses decrease steadily and remain closer to the training losses.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_loss_curves.png"}, {"analysis": "The second plot illustrates the Color-Rule Weighted Accuracy (CRWA) on the test set for different learning rates. The CRWA is relatively consistent across learning rates, with lr=3e-03 achieving the highest accuracy. This suggests that the model's ability to handle color-based rule reasoning is not highly sensitive to learning rate adjustments, though higher learning rates may offer marginal improvements.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_CRWA_vs_lr.png"}, {"analysis": "The third plot depicts the Shape-Weighted Accuracy (SWA) on the test set as a function of learning rate. Similar to CRWA, SWA is also consistent across learning rates, with lr=3e-03 delivering the best performance. This indicates that the model's capacity to reason about shape-based rules is robust to changes in learning rate, with slight gains observed at higher rates.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_SWA_vs_lr.png"}, {"analysis": "The fourth plot shows the Color-Weighted Accuracy (CWA) on the test set for various learning rates. The trends are similar to those observed in CRWA and SWA, where the performance is stable across learning rates, with lr=3e-03 yielding the highest accuracy. This consistency across metrics suggests that the model's general reasoning ability is not heavily affected by learning rate, although higher rates might offer slight advantages.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2e28f8b1d66d45bbb83eb538cc7a1e31_proc_2945035/SPR_BENCH_CWA_vs_lr.png"}], [{"analysis": "This plot compares training and validation loss over epochs for different batch sizes. Smaller batch sizes (32, 64) show a faster initial decrease in both training and validation loss, but larger batch sizes (128, 256) achieve lower overall loss values by the end of training. The validation loss curves closely follow the training loss curves, indicating no significant overfitting. However, batch size 256 demonstrates a slightly slower convergence, which might be due to the noisier gradients associated with larger batch sizes.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2de8945897614fd2a28b0390701b0aa2_proc_2945036/SPR_BENCH_loss_curves_batch_size_tuning.png"}, {"analysis": "This plot tracks the validation CRWA (Combined Rule-Weighted Accuracy) over epochs for different batch sizes. Smaller batch sizes (32, 64) achieve higher CRWA earlier in training, but larger batch sizes (128, 256) catch up and even surpass smaller batch sizes by the final epoch. Batch size 256 shows a steady improvement in CRWA, indicating that while convergence is slower, the final performance is superior. This suggests that larger batch sizes might be better for overall generalization in this task.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2de8945897614fd2a28b0390701b0aa2_proc_2945036/SPR_BENCH_val_CRWA_curves_batch_size_tuning.png"}, {"analysis": "This bar chart compares the final test metrics (CRWA, SWA, CWA) across different batch sizes. SWA and CWA remain relatively stable across all batch sizes, with batch size 256 showing a slight edge in CRWA. This indicates that batch size has minimal impact on SWA and CWA but a more noticeable effect on CRWA, favoring larger batch sizes for this metric.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2de8945897614fd2a28b0390701b0aa2_proc_2945036/SPR_BENCH_test_metrics_batch_size_tuning.png"}], [{"analysis": "The loss curves indicate a steady decrease in both training and validation loss over epochs, demonstrating that the model is learning effectively without overfitting. The CRWA curve shows a consistent improvement in validation performance, suggesting that the model generalizes well to unseen data. The embedding dimension of 32 appears to be effective for this setup.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_32_loss_crwa.png"}, {"analysis": "The loss curves show a similar trend of decreasing loss for both training and validation sets, indicating effective learning. The CRWA curve shows a sharp increase followed by stabilization, suggesting that the model achieves its peak performance early in training. The embedding dimension of 64 slightly improves the CRWA compared to 32.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_64_loss_crwa.png"}, {"analysis": "The loss curves continue to show effective learning with a steady decline in both training and validation loss. The CRWA curve shows an initial improvement but plateaus, indicating diminishing returns on performance improvement with this embedding dimension. The embedding dimension of 128 does not appear to offer significant advantages over 64.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_128_loss_crwa.png"}, {"analysis": "The loss curves remain consistent with the trend of effective learning, with a steady decrease in loss. The CRWA curve exhibits fluctuations, indicating potential instability in performance with this embedding dimension. The embedding dimension of 256 does not seem to provide a clear advantage and might introduce instability.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_dim_256_loss_crwa.png"}, {"analysis": "The bar chart shows that the test CRWA values are similar across embedding dimensions, with minimal variance. This suggests that increasing the embedding dimension beyond 32 does not significantly impact the model's performance on the CRWA metric.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b222c24464354c96852d1e8f507e4a1e_proc_2945037/SPR_BENCH_test_CRWA_vs_dim.png"}], [{"analysis": "The plot indicates that the cross-entropy loss remains consistent across different weight decay values for all datasets (train, validation, and test). This suggests that weight decay does not significantly impact the model's ability to minimize loss. The train and validation losses are closely aligned, indicating no overfitting or underfitting. However, the test loss is notably higher, which may point to a generalization gap.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_loss_vs_weight_decay.png"}, {"analysis": "The CRWA metric for validation remains stable across all weight decay values, suggesting that the model's ability to capture color-related reasoning is unaffected by the regularization parameter. However, the test CRWA is consistently lower, highlighting a potential issue with generalization to unseen data. This discrepancy warrants further investigation.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_CRWA_vs_weight_decay.png"}, {"analysis": "The SWA metric for validation also remains stable across weight decay values, indicating that the model's shape-related reasoning performance is unaffected by this parameter. Similar to the CRWA metric, the test SWA is consistently lower, which again suggests a generalization issue that needs to be addressed.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_SWA_vs_weight_decay.png"}, {"analysis": "The CWA metric for validation is stable and unaffected by weight decay, similar to the trends observed in CRWA and SWA. The test CWA is consistently lower, reinforcing the observation that the model struggles to generalize its reasoning capabilities to unseen data.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2890596d567f4e4ba7ee770d69f58ffe_proc_2945035/SPR_BENCH_CWA_vs_weight_decay.png"}], [{"analysis": "The training and validation loss decrease steadily over the epochs, indicating that the model is learning effectively. The validation loss closely follows the training loss, suggesting that the model is generalizing well without overfitting. The dropout rate of 0.0 implies no regularization, and yet the model is performing well, which could indicate a relatively simple problem space or a robust model.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.0.png"}, {"analysis": "With a dropout rate of 0.1, the training and validation loss continue to decrease steadily. The validation loss remains closely aligned with the training loss, suggesting that the model maintains good generalization. The slight increase in dropout appears to have introduced some regularization, but it has not negatively impacted the performance, which is promising.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.1.png"}, {"analysis": "At a dropout rate of 0.2, the training loss decreases steadily, while the validation loss plateaus slightly towards the end. This could indicate the beginning of a trade-off between model capacity and regularization. The model still generalizes well, but further increases in dropout might lead to underfitting.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.2.png"}, {"analysis": "With a dropout rate of 0.3, the validation loss shows a more pronounced plateau compared to the training loss. This suggests that the regularization effect of dropout is becoming more significant, possibly limiting the model's capacity to fit the training data. The model still generalizes reasonably well, but the reduced convergence of validation loss warrants careful consideration.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.3.png"}, {"analysis": "At a dropout rate of 0.5, the validation loss remains relatively flat after the initial epochs, while the training loss continues to decrease. This indicates that the model is starting to underfit due to the high dropout rate, which is reducing its capacity to learn effectively from the training data. The generalization is still acceptable but may not be optimal for more complex tasks.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_df25da5bec184d6292cd830886081b65_proc_2945037/loss_curve_SPR_BENCH_dropout_0.5.png"}], [{"analysis": "The left sub-plot shows a consistent reduction in cross-entropy loss for both training and validation sets over epochs, indicating good convergence without overfitting. The validation loss closely follows the training loss, which signifies that the model generalizes well. The right sub-plot shows the CRWA (Color-Weighted Accuracy) metric improving steadily over epochs, plateauing after epoch 4, suggesting that the model's performance on the validation set stabilizes after this point.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.0_loss_metric.png"}, {"analysis": "The left sub-plot again shows decreasing cross-entropy loss for both training and validation sets, similar to the previous plot. The gap between training and validation loss remains small, indicating no overfitting. The right sub-plot for CRWA shows a similar trend of improvement over epochs, with a slight plateau after epoch 4. The use of label smoothing (0.05) does not seem to significantly affect the CRWA performance compared to the previous setting.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.05_loss_metric.png"}, {"analysis": "The left sub-plot continues to show a reduction in cross-entropy loss for both training and validation sets, with a small gap between them. This indicates that the model maintains good generalization. The right sub-plot shows a consistent increase in CRWA, but the improvement after epoch 3 becomes marginal. Label smoothing at 0.1 does not appear to have a substantial impact on the overall trends of loss reduction and CRWA improvement.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.1_loss_metric.png"}, {"analysis": "The left sub-plot displays a reduction in cross-entropy loss for both training and validation sets, but the gap between them slightly increases compared to lower label smoothing values, potentially indicating minor overfitting. The right sub-plot shows that CRWA improves until epoch 3 but slightly decreases after epoch 4, indicating that higher label smoothing (0.2) might negatively affect the performance.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_ls0.2_loss_metric.png"}, {"analysis": "The bar plot compares the CRWA, SWA, and CWA metrics across different label smoothing values. The metrics are relatively stable across all label smoothing values, but there is a slight dip in CRWA and SWA at label smoothing 0.2. This suggests that higher label smoothing might slightly degrade the model's ability to generalize and perform well on these weighted accuracy metrics.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_62c81cd13f8e4319b87ab16c7b1366cf_proc_2945036/SPR_BENCH_summary_metrics.png"}], [{"analysis": "The plot shows the train and validation loss curves for different gradient clipping norms over five epochs. As the epochs progress, both training and validation losses decrease, indicating effective learning across all configurations. The gradient clipping norm of 0.5 appears to result in the most consistent reduction in validation loss, suggesting it may provide a good trade-off between stability and generalization. Higher clipping norms (e.g., 5.0) show slightly higher validation losses, possibly indicating overfitting or instability.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1511daa747b74d76aed547736a56cee1_proc_2945034/SPR_BENCH_loss_curves_gradient_clip.png"}, {"analysis": "This plot presents the validation CRWA (Color-Weighted Accuracy) across epochs for various gradient clipping norms. Lower clipping norms (e.g., 0.1 and 0.5) demonstrate a more stable and consistent improvement in CRWA as epochs increase, with clipping norm 0.5 achieving the highest CRWA at epoch 3. Higher clipping norms (e.g., 5.0) show less consistent gains, suggesting that smaller clipping values may better balance learning stability and accuracy.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1511daa747b74d76aed547736a56cee1_proc_2945034/SPR_BENCH_val_CRWA_gradient_clip.png"}, {"analysis": "The bar chart depicts the test CRWA across different gradient clipping norms. The CRWA values are nearly identical across all configurations, indicating that gradient clipping norms have minimal impact on the final test performance. This suggests that the model's generalization ability is robust to variations in this hyperparameter.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1511daa747b74d76aed547736a56cee1_proc_2945034/SPR_BENCH_test_CRWA_bar_gradient_clip.png"}], [{"analysis": "The plot shows the training and validation loss over 5 epochs. Both losses decrease consistently, indicating that the model is learning effectively during this period. The training loss decreases more rapidly than the validation loss, which is expected in the early stages of training. Importantly, there is no indication of overfitting at this stage, as the validation loss follows a similar downward trend.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_5_loss_SPR_BENCH.png"}, {"analysis": "This plot extends the observation to 10 epochs. Both training and validation losses continue to decrease steadily. The gap between the two losses is minimal, which suggests that the model is generalizing well to the validation set. The consistent downward trend in validation loss indicates that the model has not yet reached a saturation point, and further training may improve performance.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_10_loss_SPR_BENCH.png"}, {"analysis": "The training and validation losses are plotted over 20 epochs. The losses continue to decrease, but the rate of decrease slows down compared to earlier epochs. This is typical as the model approaches convergence. The close alignment between training and validation losses indicates that the model maintains good generalization without overfitting.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_20_loss_SPR_BENCH.png"}, {"analysis": "This plot shows the training and validation losses over 30 epochs. The losses decrease further, but the rate of improvement is marginal at this stage. The training and validation losses remain closely aligned, suggesting that the model is still generalizing well. However, the diminishing returns in loss reduction suggest that the model may be nearing its optimal performance.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/epochs_30_loss_SPR_BENCH.png"}, {"analysis": "This bar chart compares test metrics (CRWA, SWA, and CWA) across different epoch settings (5, 10, 20, 30). The metrics are relatively stable across these settings, with slight improvements as the number of epochs increases. This stability indicates that the model's performance on the test set is robust and does not degrade with additional training. The CWA metric consistently outperforms the others, suggesting that the model is particularly adept at capturing color-weighted accuracy.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/test_metrics_comparison_SPR_BENCH.png"}], [{"analysis": "This plot shows the training and validation loss over 5 epochs. The training loss decreases significantly, indicating that the model is learning from the training data. The validation loss also decreases, which suggests that the model is generalizing well to unseen data within this short training period. The gap between the training and validation loss is minimal, indicating no significant overfitting at this stage.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_5_loss_SPR_BENCH.png"}, {"analysis": "This plot extends the training to 10 epochs. Both training and validation losses continue to decrease, and the gap between them remains small. This suggests that the model is still learning effectively, and its generalization capability is maintained over a longer training period. The decreasing trend in validation loss shows that the model is not overfitting yet.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_10_loss_SPR_BENCH.png"}, {"analysis": "With 20 epochs of training, the training and validation losses continue to decrease, though the rate of decrease has slowed. The small gap between the losses indicates that the model is still generalizing well. This plateauing trend suggests that the model might be approaching its optimal performance, and further training may yield diminishing returns.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_20_loss_SPR_BENCH.png"}, {"analysis": "At 30 epochs, the training loss decreases further, but the validation loss shows signs of plateauing. The minimal gap between the two losses indicates that overfitting is not a concern. However, the slower decrease in validation loss suggests that the model has nearly converged and additional epochs may not lead to substantial improvements.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/epochs_30_loss_SPR_BENCH.png"}, {"analysis": "This bar chart compares the test metrics CRWA, SWA, and CWA across different epoch settings. The metrics show consistent improvement as the number of epochs increases, with the highest scores achieved at 30 epochs. This indicates that prolonged training enhances the model's performance on the test set. However, the incremental gains diminish with more epochs, suggesting a point of diminishing returns.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/test_metrics_comparison_SPR_BENCH.png"}], [{"analysis": "The plot shows the training and validation loss over 5 epochs. Both losses decrease steadily, indicating that the model is learning effectively. The validation loss closely follows the training loss, suggesting no immediate overfitting. However, the limited number of epochs might not allow the model to reach its optimal performance.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_5_loss_SPR_BENCH.png"}, {"analysis": "The plot displays training and validation loss over 10 epochs. The losses continue to decline, with the validation loss slightly trailing the training loss. The trend indicates consistent learning without signs of overfitting. Extending the training further might reveal more insights into the model's capacity.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_10_loss_SPR_BENCH.png"}, {"analysis": "The training and validation loss curves over 20 epochs show a consistent downward trend. The validation loss remains close to the training loss, suggesting that the model generalizes well to the validation data. The steady decline indicates that the model has not yet fully converged, and additional training could further improve performance.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_20_loss_SPR_BENCH.png"}, {"analysis": "The training and validation loss curves over 30 epochs demonstrate continued reduction in loss. The validation loss remains close to the training loss, which is a positive indicator of generalization. The rate of decline slows down, suggesting that the model is approaching convergence. Further training might yield diminishing returns.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/epochs_30_loss_SPR_BENCH.png"}, {"analysis": "The bar chart compares CRWA, SWA, and CWA scores across different epoch settings. The metrics remain relatively stable across epochs, with slight improvements as the number of epochs increases. This stability indicates that the model performs consistently across different evaluation criteria and suggests that the training is effective in capturing relevant patterns.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/test_metrics_comparison_SPR_BENCH.png"}], []], "vlm_feedback_summary": ["The plots indicate successful model training and evaluation. The training and\nvalidation loss curves show good convergence, suggesting effective learning\nwithout overfitting. Validation metrics improve over epochs, peaking before a\nslight decline, indicating optimal performance around epoch 3. The final test\nmetrics reveal balanced performance across CRWA, SWA, and CWA, with scores\naround 0.6, reflecting consistent model performance across different reasoning\ntasks.", "The plots indicate that the model learns effectively over increasing epochs,\nwith both training and validation losses decreasing and stabilizing. The test\nmetrics show a slight improvement across epochs, with the color-weighted\naccuracy consistently outperforming other metrics.", "The plots reveal that learning rate adjustments influence the convergence\nbehavior of the model, with higher rates achieving faster convergence but\nrisking instability. Metrics such as CRWA, SWA, and CWA are relatively stable\nacross learning rates, with slight improvements observed at higher rates like\nlr=3e-03. This suggests that the model is robust to learning rate changes, but\ncareful tuning can yield marginal gains in performance.", "The analysis highlights that smaller batch sizes lead to faster initial\nconvergence, but larger batch sizes achieve better generalization and final\nperformance, particularly in CRWA. SWA and CWA are less sensitive to batch size\nvariations.", "The plots indicate effective learning across all embedding dimensions, as\nevidenced by the consistent decrease in loss. While CRWA improves with training,\nincreasing the embedding dimension beyond 32 yields diminishing returns and, in\nsome cases, introduces instability. The test CRWA values confirm that embedding\ndimension has minimal impact on performance.", "The plots show consistent trends across metrics, with validation performance\nremaining stable and test performance consistently lower, indicating a\ngeneralization issue. Weight decay does not significantly impact performance.", "The plots demonstrate the impact of varying dropout rates on the model's\ntraining and validation loss. Lower dropout rates (0.0 and 0.1) show effective\nlearning and generalization, while higher dropout rates (0.3 and 0.5) lead to\nreduced model capacity and potential underfitting.", "The experimental results demonstrate consistent convergence and good\ngeneralization of the model across all settings. Label smoothing generally does\nnot significantly affect performance, although higher values (e.g., 0.2) may\nslightly degrade CRWA and SWA metrics. The CRWA metric improves steadily over\nepochs, stabilizing after epoch 4 in most cases, indicating that the model\nreaches its peak performance by this point.", "The plots collectively show that gradient clipping norms influence training\nstability and validation performance, with smaller norms (e.g., 0.5) yielding\nbetter validation outcomes. However, test performance remains unaffected by\nthese variations, indicating robust generalization.", "The plots demonstrate a consistent decrease in training and validation losses\nover increasing epochs, with no signs of overfitting. The test metrics indicate\nstable and slightly improving performance across epoch settings, with CWA being\nthe strongest metric. Further tuning may yield marginal gains, but the model\nappears to be well-optimized for the task.", "The training and validation loss plots indicate that the model is learning\neffectively and generalizing well across all epoch settings, with minimal\noverfitting. The bar chart of test metrics shows consistent improvements in\nCRWA, SWA, and CWA as the number of epochs increases, though the gains diminish\nafter 20 epochs. Further optimization may focus on reducing training time\nwithout sacrificing performance.", "The plots show consistent learning progress as the number of epochs increases.\nTraining and validation loss decrease steadily, with no signs of overfitting.\nThe test metrics (CRWA, SWA, CWA) remain stable and slightly improve with more\nepochs, indicating effective training and generalization. Further\nexperimentation could focus on optimizing hyperparameters or extending training\nto confirm convergence.", "[]"], "exec_time": [7.6810853481292725, 123.69487404823303, 44.8143584728241, 44.846752882003784, 42.30722618103027, 39.10350322723389, 40.2850022315979, 29.933602333068848, 30.99005103111267, 92.25541806221008, 95.36825704574585, 93.21121954917908, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[]"], ["[\"SPR_BENCH (toy)\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["['embed_dim_32'", "'embed_dim_64'", "'embed_dim_128'", "'embed_dim_256']"], ["\"\""], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH (toy)\"]"], ["[\"SPR_BENCH (toy)\"]"], ["['SPR_BENCH']"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nfor dname, record in experiment_data.items():\n    losses = record.get(\"losses\", {})\n    metrics = record.get(\"metrics\", {})\n    # -------- Plot 1: loss curves --------\n    try:\n        plt.figure()\n        if \"train\" in losses and losses[\"train\"]:\n            plt.plot(losses[\"train\"], label=\"Train Loss\")\n        if \"val\" in losses and losses[\"val\"]:\n            plt.plot(losses[\"val\"], label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dname} Training vs Validation Loss\")\n        plt.legend()\n        save_path = os.path.join(working_dir, f\"{dname}_loss_curves.png\")\n        plt.savefig(save_path)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {dname}: {e}\")\n        plt.close()\n\n    # -------- Plot 2: validation metrics --------\n    try:\n        plt.figure()\n        val_metrics = metrics.get(\"val\", [])\n        if val_metrics:\n            epochs = range(len(val_metrics))\n            crwa = [m[\"CRWA\"] for m in val_metrics]\n            swa = [m[\"SWA\"] for m in val_metrics]\n            cwa = [m[\"CWA\"] for m in val_metrics]\n            plt.plot(epochs, crwa, label=\"CRWA\")\n            plt.plot(epochs, swa, label=\"SWA\")\n            plt.plot(epochs, cwa, label=\"CWA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Score\")\n            plt.title(f\"{dname} Validation Metrics over Epochs\")\n            plt.legend()\n            save_path = os.path.join(working_dir, f\"{dname}_val_metric_curves.png\")\n            plt.savefig(save_path)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric plot for {dname}: {e}\")\n        plt.close()\n\n    # -------- Plot 3: test metrics bar --------\n    try:\n        test_m = metrics.get(\"test\", {})\n        if test_m:\n            plt.figure()\n            names = list(test_m.keys())\n            vals = [test_m[k] for k in names]\n            plt.bar(names, vals)\n            plt.ylim(0, 1)\n            plt.ylabel(\"Score\")\n            plt.title(f\"{dname} Final Test Metrics\")\n            save_path = os.path.join(working_dir, f\"{dname}_test_metrics_bar.png\")\n            plt.savefig(save_path)\n            print(f\"{dname} test metrics:\", test_m)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar for {dname}: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nruns = experiment_data.get(\"num_epochs\", {})\n# -------------------- 1-4: loss curves per run --------------------\nfor run_idx, (run_name, run_data) in enumerate(runs.items()):\n    if run_idx >= 4:  # safety: plot at most 4 loss figures\n        break\n    try:\n        train_losses = run_data[\"losses\"][\"train\"]\n        val_losses = run_data[\"losses\"][\"val\"]\n        epochs = np.arange(1, len(train_losses) + 1)\n\n        plt.figure()\n        plt.plot(epochs, train_losses, label=\"Train\")\n        plt.plot(epochs, val_losses, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{run_name}: Training vs Validation Loss\\nDataset: SPR_BENCH (toy)\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{run_name}_loss_SPR_BENCH.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {run_name}: {e}\")\n        plt.close()\n\n# -------------------- 5: aggregated test metrics --------------------\ntry:\n    labels, crwa_vals, swa_vals, cwa_vals = [], [], [], []\n    for run_name, run_data in runs.items():\n        labels.append(run_name)\n        test_metrics = run_data.get(\"metrics\", {}).get(\"test\", {})\n        crwa_vals.append(test_metrics.get(\"CRWA\", 0))\n        swa_vals.append(test_metrics.get(\"SWA\", 0))\n        cwa_vals.append(test_metrics.get(\"CWA\", 0))\n\n    x = np.arange(len(labels))\n    w = 0.25\n    plt.figure(figsize=(8, 4))\n    plt.bar(x - w, crwa_vals, width=w, label=\"CRWA\")\n    plt.bar(x, swa_vals, width=w, label=\"SWA\")\n    plt.bar(x + w, cwa_vals, width=w, label=\"CWA\")\n    plt.xticks(x, labels, rotation=15)\n    plt.ylim(0, 1.05)\n    plt.ylabel(\"Score\")\n    plt.title(\"Test Metrics Across Epoch Settings\\nDataset: SPR_BENCH (toy)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"test_metrics_comparison_SPR_BENCH.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated metrics plot: {e}\")\n    plt.close()\n\n# -------------------- print evaluation metrics --------------------\nprint(\"Final Test Metrics:\")\nfor run_name, run_data in runs.items():\n    m = run_data.get(\"metrics\", {}).get(\"test\", {})\n    print(\n        f\"{run_name}: CRWA={m.get('CRWA',0):.4f}, SWA={m.get('SWA',0):.4f}, CWA={m.get('CWA',0):.4f}\"\n    )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    data_dict = experiment_data[\"learning_rate\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data_dict = {}\n\n\n# helper\ndef _sorted_lrs(d):\n    return sorted(d.keys(), key=lambda x: float(x.replace(\"e\", \"E\")))\n\n\nlrs = _sorted_lrs(data_dict)\n\n# ---------- fig 1: loss curves ----------\ntry:\n    plt.figure()\n    for lr in lrs:\n        tr = data_dict[lr][\"losses\"][\"train\"]\n        val = data_dict[lr][\"losses\"][\"val\"]\n        epochs = range(1, len(tr) + 1)\n        plt.plot(epochs, tr, label=f\"train lr={lr}\")\n        plt.plot(epochs, val, \"--\", label=f\"val lr={lr}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss Curves\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# collect test metrics once for the three bar plots\ntest_crwa, test_swa, test_cwa = [], [], []\nfor lr in lrs:\n    metr = data_dict[lr][\"metrics\"][\"test\"]\n    test_crwa.append(metr[\"CRWA\"])\n    test_swa.append(metr[\"SWA\"])\n    test_cwa.append(metr[\"CWA\"])\n\n\ndef bar_plot(values, metric_name, fname_suffix):\n    try:\n        plt.figure()\n        plt.bar(range(len(lrs)), values, tick_label=lrs)\n        plt.ylabel(metric_name)\n        plt.xlabel(\"Learning Rate\")\n        plt.title(f\"SPR_BENCH: Test {metric_name} vs Learning Rate\")\n        fname = os.path.join(working_dir, f\"SPR_BENCH_{fname_suffix}.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating {metric_name} plot: {e}\")\n        plt.close()\n\n\n# ---------- figs 2-4 ----------\nbar_plot(test_crwa, \"CRWA\", \"CRWA_vs_lr\")\nbar_plot(test_swa, \"SWA\", \"SWA_vs_lr\")\nbar_plot(test_cwa, \"CWA\", \"CWA_vs_lr\")\n\n# ---------- print summary ----------\nprint(\"\\n=== Test Metrics Summary ===\")\nfor lr, c1, s1, c2 in zip(lrs, test_crwa, test_swa, test_cwa):\n    print(f\"lr={lr:>5}: CRWA={c1:.4f} | SWA={s1:.4f} | CWA={c2:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    ed = experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"]\n    bs_list = ed[\"batch_sizes\"]\n    train_losses = ed[\"losses\"][\"train\"]  # list of lists [bs][epoch]\n    val_losses = ed[\"losses\"][\"val\"]  # list of lists [bs][epoch]\n    val_metrics = ed[\"metrics\"][\"val\"]  # list [bs] of list[epoch]{}\n    test_metrics = ed[\"metrics\"][\"test\"]  # list [bs] of {}\n    epochs = np.arange(1, len(train_losses[0]) + 1)\n\n    # 1) Loss curves ----------------------------------------------------------\n    try:\n        plt.figure()\n        for bs, tr, vl in zip(bs_list, train_losses, val_losses):\n            plt.plot(epochs, tr, \"--\", label=f\"train bs={bs}\")\n            plt.plot(epochs, vl, \"-\", label=f\"val   bs={bs}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, \"SPR_BENCH_loss_curves_batch_size_tuning.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # 2) Validation CRWA curves ----------------------------------------------\n    try:\n        plt.figure()\n        for bs, m in zip(bs_list, val_metrics):\n            crwa = [ep[\"CRWA\"] for ep in m]\n            plt.plot(epochs, crwa, label=f\"bs={bs}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CRWA\")\n        plt.title(\"SPR_BENCH: Validation CRWA over Epochs\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, \"SPR_BENCH_val_CRWA_curves_batch_size_tuning.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CRWA curve plot: {e}\")\n        plt.close()\n\n    # 3) Test metric comparison ----------------------------------------------\n    try:\n        idx = np.arange(len(bs_list))\n        width = 0.25\n        crwa = [m[\"CRWA\"] for m in test_metrics]\n        swa = [m[\"SWA\"] for m in test_metrics]\n        cwa = [m[\"CWA\"] for m in test_metrics]\n\n        plt.figure(figsize=(8, 4))\n        plt.bar(idx - width, crwa, width, label=\"CRWA\")\n        plt.bar(idx, swa, width, label=\"SWA\")\n        plt.bar(idx + width, cwa, width, label=\"CWA\")\n        plt.xticks(idx, bs_list)\n        plt.xlabel(\"Batch Size\")\n        plt.ylabel(\"Score\")\n        plt.title(\"SPR_BENCH: Test Metrics vs Batch Size\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(\n            os.path.join(working_dir, \"SPR_BENCH_test_metrics_batch_size_tuning.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar plot: {e}\")\n        plt.close()\n\n    # -------- Console summary ------------------------------------------------\n    print(\"\\n=== Test Metrics ===\")\n    for bs, m in zip(bs_list, test_metrics):\n        print(\n            f\"bs={bs:3}: CRWA={m['CRWA']:.4f} | SWA={m['SWA']:.4f} | CWA={m['CWA']:.4f}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------- load data -------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nruns = experiment_data.get(\"embed_dim_tuning\", {})\ndims_sorted = sorted(runs.keys(), key=lambda x: int(x.split(\"_\")[-1]))[:5]  # keep order\n\n# ------------------- per-run plots -------------------\nfor run_key in dims_sorted:\n    try:\n        data = runs[run_key]\n        epochs = range(1, len(data[\"losses\"][\"train\"]) + 1)\n        train_loss = data[\"losses\"][\"train\"]\n        val_loss = data[\"losses\"][\"val\"]\n        val_crwa = [m[\"CRWA\"] for m in data[\"metrics\"][\"val\"]]\n\n        plt.figure(figsize=(10, 4))\n        # left panel: loss curves\n        plt.subplot(1, 2, 1)\n        plt.plot(epochs, train_loss, label=\"Train Loss\")\n        plt.plot(epochs, val_loss, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.title(\"Loss Curves\")\n\n        # right panel: CRWA\n        plt.subplot(1, 2, 2)\n        plt.plot(epochs, val_crwa, marker=\"o\", label=\"Val CRWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CRWA\")\n        plt.legend()\n        plt.title(\"CRWA Over Epochs\")\n\n        dim = run_key.split(\"_\")[-1]\n        plt.suptitle(\n            f\"SPR_BENCH | Embed Dim {dim}\\nLeft: Loss | Right: CRWA\", fontsize=12\n        )\n        fname = os.path.join(working_dir, f\"SPR_BENCH_dim_{dim}_loss_crwa.png\")\n        plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating plot for {run_key}: {e}\")\n        plt.close()\n\n# ------------------- summary bar chart -------------------\ntry:\n    dims, crwas = [], []\n    for run_key in dims_sorted:\n        dims.append(int(run_key.split(\"_\")[-1]))\n        crwas.append(runs[run_key][\"metrics\"][\"test\"][\"CRWA\"])\n    plt.figure()\n    plt.bar([str(d) for d in dims], crwas, color=\"skyblue\")\n    plt.xlabel(\"Embedding Dimension\")\n    plt.ylabel(\"Test CRWA\")\n    plt.title(\"SPR_BENCH | Test CRWA vs Embedding Dimension\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_test_CRWA_vs_dim.png\")\n    plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n    plt.close()\n    print(f\"Saved {fname}\")\nexcept Exception as e:\n    print(f\"Error creating summary plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------- load data ----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    ed = experiment_data[\"weight_decay\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exit()\n\ndecays = np.array(ed[\"decay_values\"])\ntrain_loss = np.array(ed[\"losses\"][\"train\"])\nval_loss = np.array(ed[\"losses\"][\"val\"])\ntest_loss = np.array(ed[\"losses\"][\"test\"])\nval_crwa = np.array([m[\"CRWA\"] for m in ed[\"metrics\"][\"val\"]])\ntest_crwa = np.array([m[\"CRWA\"] for m in ed[\"metrics\"][\"test\"]])\nval_swa = np.array([m[\"SWA\"] for m in ed[\"metrics\"][\"val\"]])\ntest_swa = np.array([m[\"SWA\"] for m in ed[\"metrics\"][\"test\"]])\nval_cwa = np.array([m[\"CWA\"] for m in ed[\"metrics\"][\"val\"]])\ntest_cwa = np.array([m[\"CWA\"] for m in ed[\"metrics\"][\"test\"]])\n\n\n# ---------------- plotting helpers ----------------\ndef save_fig(name):\n    plt.savefig(os.path.join(working_dir, name), dpi=150)\n    plt.close()\n\n\n# 1) Loss curves\ntry:\n    plt.figure()\n    plt.plot(decays, train_loss, \"o-\", label=\"Train\")\n    plt.plot(decays, val_loss, \"s--\", label=\"Validation\")\n    plt.plot(decays, test_loss, \"d:\", label=\"Test\")\n    plt.xlabel(\"Weight Decay\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH Loss vs Weight Decay\")\n    plt.legend()\n    plt.xscale(\"log\")\n    save_fig(\"SPR_BENCH_loss_vs_weight_decay.png\")\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# 2) CRWA\ntry:\n    plt.figure()\n    plt.plot(decays, val_crwa, \"s--\", label=\"Validation\")\n    plt.plot(decays, test_crwa, \"d:\", label=\"Test\")\n    plt.xlabel(\"Weight Decay\")\n    plt.ylabel(\"CRWA\")\n    plt.title(\"SPR_BENCH CRWA vs Weight Decay\")\n    plt.xscale(\"log\")\n    plt.legend()\n    save_fig(\"SPR_BENCH_CRWA_vs_weight_decay.png\")\nexcept Exception as e:\n    print(f\"Error creating CRWA plot: {e}\")\n    plt.close()\n\n# 3) SWA\ntry:\n    plt.figure()\n    plt.plot(decays, val_swa, \"s--\", label=\"Validation\")\n    plt.plot(decays, test_swa, \"d:\", label=\"Test\")\n    plt.xlabel(\"Weight Decay\")\n    plt.ylabel(\"SWA\")\n    plt.title(\"SPR_BENCH SWA vs Weight Decay\")\n    plt.xscale(\"log\")\n    plt.legend()\n    save_fig(\"SPR_BENCH_SWA_vs_weight_decay.png\")\nexcept Exception as e:\n    print(f\"Error creating SWA plot: {e}\")\n    plt.close()\n\n# 4) CWA\ntry:\n    plt.figure()\n    plt.plot(decays, val_cwa, \"s--\", label=\"Validation\")\n    plt.plot(decays, test_cwa, \"d:\", label=\"Test\")\n    plt.xlabel(\"Weight Decay\")\n    plt.ylabel(\"CWA\")\n    plt.title(\"SPR_BENCH CWA vs Weight Decay\")\n    plt.xscale(\"log\")\n    plt.legend()\n    save_fig(\"SPR_BENCH_CWA_vs_weight_decay.png\")\nexcept Exception as e:\n    print(f\"Error creating CWA plot: {e}\")\n    plt.close()\n\n# ---------------- best configuration summary ----------------\nbest_idx = int(np.argmax(val_crwa))\nprint(f\"Best validation CRWA achieved at weight_decay={decays[best_idx]:.1e}\")\nprint(\n    f\"   Val  CRWA/SWA/CWA: {val_crwa[best_idx]:.4f}/{val_swa[best_idx]:.4f}/{val_cwa[best_idx]:.4f}\"\n)\nprint(\n    f\"   Test CRWA/SWA/CWA: {test_crwa[best_idx]:.4f}/{test_swa[best_idx]:.4f}/{test_cwa[best_idx]:.4f}\"\n)\n\n# Optional: full metric table\nprint(\n    \"\\nFull metric table (decay, val_CRWA, test_CRWA, val_SWA, test_SWA, val_CWA, test_CWA):\"\n)\nfor d, vc, tc, vs, ts, vca, tca in zip(\n    decays, val_crwa, test_crwa, val_swa, test_swa, val_cwa, test_cwa\n):\n    print(f\"{d:.1e}\\t{vc:.4f}\\t{tc:.4f}\\t{vs:.4f}\\t{ts:.4f}\\t{vca:.4f}\\t{tca:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- load experiment data --------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ndrop_dict = experiment_data.get(\"dropout_rate\", {})\n\n# -------- plot loss curves for each dropout --------\nfor dp in sorted([k for k in drop_dict.keys() if isinstance(k, float)]):\n    try:\n        hist = drop_dict[dp][\"SPR_BENCH\"]\n        train_losses = hist[\"losses\"][\"train\"]\n        val_losses = hist[\"losses\"][\"val\"]\n        epochs = np.arange(1, len(train_losses) + 1)\n\n        plt.figure()\n        plt.plot(epochs, train_losses, label=\"Train Loss\")\n        plt.plot(epochs, val_losses, label=\"Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"SPR_BENCH Train vs Validation Loss\\nDropout = {dp}\")\n        plt.legend()\n        fname = f\"loss_curve_SPR_BENCH_dropout_{dp}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for dropout {dp}: {e}\")\n        plt.close()\n\n# -------- print best model results --------\nbest_rate = drop_dict.get(\"best_rate\", None)\ntest_metrics = drop_dict.get(\"test_metrics\", {})\nprint(f\"Best dropout rate: {best_rate}\")\nprint(\"Test metrics:\", test_metrics)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    ls_dict = experiment_data.get(\"label_smoothing\", {})\n    # store test metrics for summary\n    test_metrics = {\"ls\": [], \"CRWA\": [], \"SWA\": [], \"CWA\": []}\n\n    for ls_str, rec in ls_dict.items():\n        try:\n            ls = float(ls_str)\n            train_losses = rec[\"losses\"][\"train\"]\n            val_losses = rec[\"losses\"][\"val\"]\n            # extract CRWA across epochs\n            val_crwa = [m[\"CRWA\"] for m in rec[\"metrics\"][\"val\"]]\n            epochs = np.arange(1, len(train_losses) + 1)\n\n            plt.figure(figsize=(10, 4))\n            # Left subplot: losses\n            plt.subplot(1, 2, 1)\n            plt.plot(epochs, train_losses, label=\"Train\")\n            plt.plot(epochs, val_losses, label=\"Val\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.legend()\n            plt.title(\"Loss\")\n\n            # Right subplot: CRWA\n            plt.subplot(1, 2, 2)\n            plt.plot(epochs, val_crwa, marker=\"o\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"CRWA\")\n            plt.title(\"CRWA\")\n\n            plt.suptitle(\n                f\"SPR_BENCH | label_smoothing={ls}  \\nLeft: Loss (Train/Val), Right: CRWA (Val)\"\n            )\n            fname = os.path.join(working_dir, f\"SPR_BENCH_ls{ls}_loss_metric.png\")\n            plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating plot for ls={ls_str}: {e}\")\n            plt.close()\n\n        # collect test metrics\n        try:\n            tm = rec[\"metrics\"][\"test\"]\n            test_metrics[\"ls\"].append(float(ls_str))\n            test_metrics[\"CRWA\"].append(tm[\"CRWA\"])\n            test_metrics[\"SWA\"].append(tm[\"SWA\"])\n            test_metrics[\"CWA\"].append(tm[\"CWA\"])\n        except Exception as e:\n            print(f\"Error extracting test metrics for ls={ls_str}: {e}\")\n\n    # ---------- summary figure ----------\n    try:\n        x = np.arange(len(test_metrics[\"ls\"]))\n        width = 0.25\n        plt.figure(figsize=(8, 4))\n        plt.bar(x - width, test_metrics[\"CRWA\"], width, label=\"CRWA\")\n        plt.bar(x, test_metrics[\"SWA\"], width, label=\"SWA\")\n        plt.bar(x + width, test_metrics[\"CWA\"], width, label=\"CWA\")\n        plt.xticks(x, [str(ls) for ls in test_metrics[\"ls\"]])\n        plt.xlabel(\"Label Smoothing\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH Test Metrics vs. Label Smoothing\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_summary_metrics.png\")\n        plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating summary figure: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------- load data ----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    runs = experiment_data[\"gradient_clip_norm\"][\"SPR_BENCH\"]\n    clip_keys = list(runs.keys())  # e.g. ['none','0.1',...]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    runs, clip_keys = {}, []\n\n\n# ---------------- helper ----------------\ndef get_epoch_counts(r):\n    return range(1, len(r[\"losses\"][\"train\"]) + 1)\n\n\n# ---------------- Figure 1: loss curves ----------------\ntry:\n    plt.figure()\n    for ck in clip_keys:\n        r = runs[ck]\n        epochs = get_epoch_counts(r)\n        plt.plot(epochs, r[\"losses\"][\"train\"], \"--\", label=f\"{ck}-train\")\n        plt.plot(epochs, r[\"losses\"][\"val\"], \"-\", label=f\"{ck}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Train vs Validation Loss for Different Gradient Clip Norms\")\n    plt.legend(fontsize=8)\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves_gradient_clip.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ---------------- Figure 2: validation CRWA ----------------\ntry:\n    plt.figure()\n    for ck in clip_keys:\n        r = runs[ck]\n        epochs = get_epoch_counts(r)\n        crwa_vals = [m[\"CRWA\"] for m in r[\"metrics\"][\"val\"]]\n        plt.plot(epochs, crwa_vals, marker=\"o\", label=ck)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CRWA\")\n    plt.title(\n        \"SPR_BENCH: Validation CRWA over Epochs\\nLeft: Lower Clip, Right: Higher Clip\"\n    )\n    plt.legend(title=\"clip_norm\", fontsize=8)\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_val_CRWA_gradient_clip.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CRWA plot: {e}\")\n    plt.close()\n\n# ---------------- Figure 3: test CRWA bar chart ----------------\ntry:\n    plt.figure()\n    crwa_test = [runs[ck][\"metrics\"][\"test\"][\"CRWA\"] for ck in clip_keys]\n    plt.bar(range(len(clip_keys)), crwa_test, tick_label=clip_keys)\n    plt.ylabel(\"CRWA\")\n    plt.title(\"SPR_BENCH: Test CRWA by Gradient Clip Norm\")\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_test_CRWA_bar_gradient_clip.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test CRWA bar plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nruns = experiment_data.get(\"num_epochs\", {})\n# -------------------- 1-4: loss curves per run --------------------\nfor run_idx, (run_name, run_data) in enumerate(runs.items()):\n    if run_idx >= 4:  # safety: plot at most 4 loss figures\n        break\n    try:\n        train_losses = run_data[\"losses\"][\"train\"]\n        val_losses = run_data[\"losses\"][\"val\"]\n        epochs = np.arange(1, len(train_losses) + 1)\n\n        plt.figure()\n        plt.plot(epochs, train_losses, label=\"Train\")\n        plt.plot(epochs, val_losses, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{run_name}: Training vs Validation Loss\\nDataset: SPR_BENCH (toy)\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{run_name}_loss_SPR_BENCH.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {run_name}: {e}\")\n        plt.close()\n\n# -------------------- 5: aggregated test metrics --------------------\ntry:\n    labels, crwa_vals, swa_vals, cwa_vals = [], [], [], []\n    for run_name, run_data in runs.items():\n        labels.append(run_name)\n        test_metrics = run_data.get(\"metrics\", {}).get(\"test\", {})\n        crwa_vals.append(test_metrics.get(\"CRWA\", 0))\n        swa_vals.append(test_metrics.get(\"SWA\", 0))\n        cwa_vals.append(test_metrics.get(\"CWA\", 0))\n\n    x = np.arange(len(labels))\n    w = 0.25\n    plt.figure(figsize=(8, 4))\n    plt.bar(x - w, crwa_vals, width=w, label=\"CRWA\")\n    plt.bar(x, swa_vals, width=w, label=\"SWA\")\n    plt.bar(x + w, cwa_vals, width=w, label=\"CWA\")\n    plt.xticks(x, labels, rotation=15)\n    plt.ylim(0, 1.05)\n    plt.ylabel(\"Score\")\n    plt.title(\"Test Metrics Across Epoch Settings\\nDataset: SPR_BENCH (toy)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"test_metrics_comparison_SPR_BENCH.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated metrics plot: {e}\")\n    plt.close()\n\n# -------------------- print evaluation metrics --------------------\nprint(\"Final Test Metrics:\")\nfor run_name, run_data in runs.items():\n    m = run_data.get(\"metrics\", {}).get(\"test\", {})\n    print(\n        f\"{run_name}: CRWA={m.get('CRWA',0):.4f}, SWA={m.get('SWA',0):.4f}, CWA={m.get('CWA',0):.4f}\"\n    )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nruns = experiment_data.get(\"num_epochs\", {})\n# -------------------- 1-4: loss curves per run --------------------\nfor run_idx, (run_name, run_data) in enumerate(runs.items()):\n    if run_idx >= 4:  # safety: plot at most 4 loss figures\n        break\n    try:\n        train_losses = run_data[\"losses\"][\"train\"]\n        val_losses = run_data[\"losses\"][\"val\"]\n        epochs = np.arange(1, len(train_losses) + 1)\n\n        plt.figure()\n        plt.plot(epochs, train_losses, label=\"Train\")\n        plt.plot(epochs, val_losses, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{run_name}: Training vs Validation Loss\\nDataset: SPR_BENCH (toy)\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{run_name}_loss_SPR_BENCH.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {run_name}: {e}\")\n        plt.close()\n\n# -------------------- 5: aggregated test metrics --------------------\ntry:\n    labels, crwa_vals, swa_vals, cwa_vals = [], [], [], []\n    for run_name, run_data in runs.items():\n        labels.append(run_name)\n        test_metrics = run_data.get(\"metrics\", {}).get(\"test\", {})\n        crwa_vals.append(test_metrics.get(\"CRWA\", 0))\n        swa_vals.append(test_metrics.get(\"SWA\", 0))\n        cwa_vals.append(test_metrics.get(\"CWA\", 0))\n\n    x = np.arange(len(labels))\n    w = 0.25\n    plt.figure(figsize=(8, 4))\n    plt.bar(x - w, crwa_vals, width=w, label=\"CRWA\")\n    plt.bar(x, swa_vals, width=w, label=\"SWA\")\n    plt.bar(x + w, cwa_vals, width=w, label=\"CWA\")\n    plt.xticks(x, labels, rotation=15)\n    plt.ylim(0, 1.05)\n    plt.ylabel(\"Score\")\n    plt.title(\"Test Metrics Across Epoch Settings\\nDataset: SPR_BENCH (toy)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"test_metrics_comparison_SPR_BENCH.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated metrics plot: {e}\")\n    plt.close()\n\n# -------------------- print evaluation metrics --------------------\nprint(\"Final Test Metrics:\")\nfor run_name, run_data in runs.items():\n    m = run_data.get(\"metrics\", {}).get(\"test\", {})\n    print(\n        f\"{run_name}: CRWA={m.get('CRWA',0):.4f}, SWA={m.get('SWA',0):.4f}, CWA={m.get('CWA',0):.4f}\"\n    )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nruns = experiment_data.get(\"num_epochs\", {})\n# -------------------- 1-4: loss curves per run --------------------\nfor run_idx, (run_name, run_data) in enumerate(runs.items()):\n    if run_idx >= 4:  # safety: plot at most 4 loss figures\n        break\n    try:\n        train_losses = run_data[\"losses\"][\"train\"]\n        val_losses = run_data[\"losses\"][\"val\"]\n        epochs = np.arange(1, len(train_losses) + 1)\n\n        plt.figure()\n        plt.plot(epochs, train_losses, label=\"Train\")\n        plt.plot(epochs, val_losses, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{run_name}: Training vs Validation Loss\\nDataset: SPR_BENCH (toy)\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{run_name}_loss_SPR_BENCH.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {run_name}: {e}\")\n        plt.close()\n\n# -------------------- 5: aggregated test metrics --------------------\ntry:\n    labels, crwa_vals, swa_vals, cwa_vals = [], [], [], []\n    for run_name, run_data in runs.items():\n        labels.append(run_name)\n        test_metrics = run_data.get(\"metrics\", {}).get(\"test\", {})\n        crwa_vals.append(test_metrics.get(\"CRWA\", 0))\n        swa_vals.append(test_metrics.get(\"SWA\", 0))\n        cwa_vals.append(test_metrics.get(\"CWA\", 0))\n\n    x = np.arange(len(labels))\n    w = 0.25\n    plt.figure(figsize=(8, 4))\n    plt.bar(x - w, crwa_vals, width=w, label=\"CRWA\")\n    plt.bar(x, swa_vals, width=w, label=\"SWA\")\n    plt.bar(x + w, cwa_vals, width=w, label=\"CWA\")\n    plt.xticks(x, labels, rotation=15)\n    plt.ylim(0, 1.05)\n    plt.ylabel(\"Score\")\n    plt.title(\"Test Metrics Across Epoch Settings\\nDataset: SPR_BENCH (toy)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"test_metrics_comparison_SPR_BENCH.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated metrics plot: {e}\")\n    plt.close()\n\n# -------------------- print evaluation metrics --------------------\nprint(\"Final Test Metrics:\")\nfor run_name, run_data in runs.items():\n    m = run_data.get(\"metrics\", {}).get(\"test\", {})\n    print(\n        f\"{run_name}: CRWA={m.get('CRWA',0):.4f}, SWA={m.get('SWA',0):.4f}, CWA={m.get('CWA',0):.4f}\"\n    )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom math import sqrt\n\n# ------------------------------------------------------------------\n# directory handling\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\n# list of experiment .npy files (relative to AI_SCIENTIST_ROOT)\nexperiment_data_path_list = [\n    \"experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b6263bb6965a4ed18fb902ebc2cd7d38_proc_2945037/experiment_data.npy\",\n    \"experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33fce08015854601941111947f50624d_proc_2945035/experiment_data.npy\",\n    \"experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab688ba1e96b476594dee8a6f576cf3a_proc_2945036/experiment_data.npy\",\n]\n\n# ------------------------------------------------------------------\n# load data\nall_experiment_data = []\ntry:\n    ai_root = os.getenv(\"AI_SCIENTIST_ROOT\", \".\")\n    for p in experiment_data_path_list:\n        full_path = os.path.join(ai_root, p)\n        exp_data = np.load(full_path, allow_pickle=True).item()\n        all_experiment_data.append(exp_data)\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\n# ------------------------------------------------------------------\n# collect runs shared across experiments (assume same naming scheme)\nrun_dicts = [d.get(\"num_epochs\", {}) for d in all_experiment_data if \"num_epochs\" in d]\nif not run_dicts:\n    print(\"No run information found in any experiment file.\")\n\nshared_run_names = set(run_dicts[0].keys())\nfor rd in run_dicts[1:]:\n    shared_run_names &= set(rd.keys())\nshared_run_names = sorted(list(shared_run_names))\n\n# ------------------------------------------------------------------\n# aggregate losses and plot mean \u00b1 SE\nfor idx, run_name in enumerate(shared_run_names):\n    if idx >= 5:  # plot at most 5 loss figures\n        break\n    try:\n        # collect losses across experiments\n        train_mat = []\n        val_mat = []\n        min_len = np.inf\n        for rd in run_dicts:\n            tr = np.asarray(rd[run_name][\"losses\"][\"train\"])\n            va = np.asarray(rd[run_name][\"losses\"][\"val\"])\n            min_len = min(min_len, len(tr), len(va))\n            train_mat.append(tr)\n            val_mat.append(va)\n        # truncate to shortest\n        train_mat = np.vstack([t[: int(min_len)] for t in train_mat])\n        val_mat = np.vstack([v[: int(min_len)] for v in val_mat])\n\n        train_mean = train_mat.mean(axis=0)\n        val_mean = val_mat.mean(axis=0)\n        train_se = train_mat.std(axis=0, ddof=1) / sqrt(train_mat.shape[0])\n        val_se = val_mat.std(axis=0, ddof=1) / sqrt(val_mat.shape[0])\n        epochs = np.arange(1, len(train_mean) + 1)\n\n        plt.figure()\n        plt.plot(epochs, train_mean, label=\"Train Mean\", color=\"C0\")\n        plt.fill_between(\n            epochs,\n            train_mean - train_se,\n            train_mean + train_se,\n            color=\"C0\",\n            alpha=0.3,\n            label=\"Train \u00b1SE\",\n        )\n        plt.plot(epochs, val_mean, label=\"Val Mean\", color=\"C1\")\n        plt.fill_between(\n            epochs,\n            val_mean - val_se,\n            val_mean + val_se,\n            color=\"C1\",\n            alpha=0.3,\n            label=\"Val \u00b1SE\",\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\n            f\"{run_name}: Mean Training & Validation Loss \u00b1SE\\nDataset: SPR_BENCH (toy)\"\n        )\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{run_name}_loss_mean_se_SPR_BENCH.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated loss plot for {run_name}: {e}\")\n        plt.close()\n\n# ------------------------------------------------------------------\n# aggregate final test metrics (bar plot with SE)\ntry:\n    metrics = [\"CRWA\", \"SWA\", \"CWA\"]\n    bar_w = 0.2\n    x_positions = np.arange(len(shared_run_names))\n    fig, ax = plt.subplots(figsize=(10, 4))\n\n    # store numeric values for printing later\n    aggregated_numbers = {run: {} for run in shared_run_names}\n\n    for m_idx, m in enumerate(metrics):\n        means = []\n        ses = []\n        for run_name in shared_run_names:\n            vals = []\n            for rd in run_dicts:\n                test_m = rd[run_name].get(\"metrics\", {}).get(\"test\", {})\n                if m in test_m:\n                    vals.append(test_m[m])\n            if not vals:\n                vals = [0.0]\n            means.append(np.mean(vals))\n            ses.append(np.std(vals, ddof=1) / sqrt(len(vals)) if len(vals) > 1 else 0.0)\n            aggregated_numbers[run_name][m] = (means[-1], ses[-1])\n\n        bar_x = x_positions + (m_idx - 1) * bar_w\n        ax.bar(bar_x, means, width=bar_w, label=m)\n        ax.errorbar(bar_x, means, yerr=ses, fmt=\"none\", ecolor=\"black\", capsize=3, lw=1)\n\n    ax.set_xticks(x_positions)\n    ax.set_xticklabels(shared_run_names, rotation=15)\n    ax.set_ylim(0, 1.05)\n    ax.set_ylabel(\"Score\")\n    ax.set_title(\"Aggregated Test Metrics (Mean \u00b1SE)\\nDataset: SPR_BENCH (toy)\")\n    ax.legend()\n    fname = os.path.join(working_dir, \"aggregated_test_metrics_SPR_BENCH.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated metrics plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------\n# print numeric summary\nprint(\"Aggregated Test Metrics (mean \u00b1 SE):\")\nfor run_name in shared_run_names:\n    vals = aggregated_numbers.get(run_name, {})\n    crwa = vals.get(\"CRWA\", (0, 0))\n    swa = vals.get(\"SWA\", (0, 0))\n    cwa = vals.get(\"CWA\", (0, 0))\n    print(\n        f\"{run_name}: CRWA={crwa[0]:.4f}\u00b1{crwa[1]:.4f}, \"\n        f\"SWA={swa[0]:.4f}\u00b1{swa[1]:.4f}, \"\n        f\"CWA={cwa[0]:.4f}\u00b1{cwa[1]:.4f}\"\n    )\n"], "plot_plan": ["We will load experiment_data.npy, loop over each dataset (only SPR_BENCH), and extract (i) training/validation losses, (ii) validation CRWA/SWA/CWA across epochs, and (iii) final-test CRWA/SWA/CWA. Three concise plots are sufficient, stay within the 5-figure limit, each guarded by a try-except: 1) line plot of loss curves; 2) line plot of three validation metrics; 3) bar plot showing the three test metrics. Every figure is titled, saved to working_dir with descriptive names, and closed afterward. Finally, we print the test metrics so users can see numerical values alongside the saved plots.", "We will first load experiment_data.npy, then iterate through the four \u201cepochs_*\u201d runs saved under num_epochs. For each run we extract the per-epoch train/val losses and validation CRWA scores. We create up to five figures: one figure per run showing loss curves (4 figures) and a fifth figure aggregating the final test CRWA/SWA/CWA metrics across all runs in a grouped-bar chart. Each plotting section is wrapped in its own try-except so an error in one plot does not affect the others, and every figure is closed after saving. Filenames include the run name and plot type, e.g. \u201cepochs_10_loss_SPR_BENCH.png\u201d, and titles always mention the dataset (SPR_BENCH synthetic or real) plus a clear subtitle. We only plot data that actually exists in experiment_data.npy and skip any missing keys safely. Finally, after plotting, we print a compact table of the test metrics so they are visible in the notebook / logs. This satisfies the visualization guidelines while staying under the five-figure limit.", "We first load experiment_data.npy, focus on the \u201cSPR_BENCH\u201d entries under the learning-rate sweep, and sort the five lr keys.  For each learning rate we extract the per-epoch training and validation losses, as well as the final test CRWA, SWA and CWA numbers.  We then build four plots: (1) a multi-line figure showing training and validation loss curves for every lr, (2-4) three bar charts where the x-axis is lr and the y-axis is respectively CRWA, SWA and CWA.  All figures are produced inside independent try-except blocks, saved to working_dir with descriptive filenames, and closed immediately after saving.  We cap ourselves at these four figures, meeting the \u201c\u22645 plots\u201d rule.  Finally, we print a tiny table so the user can see the numerical test metrics that were plotted.  Everything relies solely on the contents of experiment_data.npy and uses plain matplotlib defaults.  The code is concise and follows the required import/working_dir boilerplate.", "The script loads the saved experiment_data.npy, extracts the results of the batch-size sweep on the SPR_BENCH dataset, and then generates three standard diagnostic plots: (1) training vs. validation loss across epochs for every tried batch size, (2) validation CRWA metric across epochs for each batch size, and (3) a final bar chart comparing CRWA, SWA, and CWA on the test split for every batch size. Each plot is wrapped in its own try-except block, saved into the working directory with descriptive filenames, and the corresponding figure is closed afterwards. The code also prints a concise table of the test metrics to the console. All plotting is strictly based on the contents of experiment_data.npy, with no fabricated values. Only basic matplotlib is used, and at most three figures are produced to satisfy the \u201c\u22645 similar figures\u201d guideline.", "We'll load experiment_data.npy, iterate through the four hyper-parameter runs and extract per-epoch training/validation losses and validation CRWA.  \nFor each embedding dimension we create one figure with two subplots: left panel shows the loss curves, right panel shows CRWA across epochs.  \nA loop with try-except ensures each figure is produced safely; we close every figure afterward.  \nTo compare hyper-parameters we then assemble a bar chart of the final test CRWA versus embedding size.  \nAll figures are saved into working_dir with descriptive names that include the dataset (\u201cSPR_BENCH\u201d), the embedding dimension, and the plot type.  \nAt most five plots are generated (four per-dim figures + one summary).  \nBasic matplotlib calls are used, and we only read data from the provided .npy file.  \nThe code follows the required import order and path setup, and prints a short confirmation for each saved plot.", "We will first load the saved experiment_data.npy, retrieve the sub-dictionary corresponding to the weight-decay sweep on the SPR_BENCH dataset, and unpack the arrays for decay values, losses (train/val/test) and metrics (CRWA/SWA/CWA for val & test). Four separate figures will be generated: (1) line plot of train/val/test loss versus weight-decay, (2) CRWA versus weight-decay, (3) SWA versus weight-decay, and (4) CWA versus weight-decay. Each plot is wrapped in its own try-except block, is titled clearly, saved to working_dir with descriptive filenames, and the figure is always closed afterward. We then identify and print the weight-decay that achieves the best validation CRWA, along with its corresponding test CRWA/SWA/CWA for quick inspection. Only data available in experiment_data.npy are used\u2014no synthetic values are fabricated\u2014and no more than these four figures are created, satisfying the \u201c\u22645 figures\u201d rule. Finally, the script prints the full metric table so users can verify the numbers match the plots.", "We first load experiment_data.npy from the working directory, which stores per-epoch histories for each tested dropout rate plus the best model statistics. For every dropout value (0.0\u20130.5) we pull the train and validation loss arrays (length = 5 epochs) and plot them against epoch index, resulting in at most five loss\u2013curve figures. Each figure is wrapped in its own try-except so that a failure in one plotting block does not stop the rest. Titles explicitly mention the dataset (SPR_BENCH), the dropout rate and the content (\u201cTrain vs Validation Loss\u201d). Files are saved to working_dir using descriptive names such as loss_curve_SPR_BENCH_dropout_0.1.png, and every figure is closed after saving to avoid memory leaks. Finally, after the plotting section we print the best dropout rate chosen on the dev set together with its held-out test metrics (loss, CRWA, SWA, CWA) so that the user can see the quantitative outcome of the tuning experiment. No data are synthesized; everything is read directly from experiment_data.npy. The code is concise, uses only matplotlib and numpy, follows the required directory handling, and stays within the five-figure limit.", "We first load experiment_data.npy, safely handling missing files. For every label-smoothing setting we retrieve the per-epoch training/validation losses and the validation CRWA metric already stored. Each figure contains two side-by-side subplots: left shows the loss curves (train vs. val) and right shows the CRWA curve, with a clear subtitle \u201cLeft: Loss (Train/Val), Right: CRWA (Val)\u201d and dataset name \u201cSPR_BENCH\u201d. We loop through at most the four smoothing values, placing each figure in its own try-except so one failure does not stop the rest, always closing the figure. A final summary figure (fifth plot) shows the test CRWA, SWA and CWA for every smoothing value in a grouped bar chart, letting us directly compare generalization. All plots are saved into working_dir with descriptive filenames such as \u201cSPR_BENCH_ls0.1_loss_metric.png\u201d or \u201cSPR_BENCH_summary_metrics.png\u201d. We never fabricate data, plotting only what exists inside experiment_data. The script begins with the requested imports and working_dir definition and closes every figure regardless of success.", "We will load experiment_data.npy, isolate the \u201cgradient_clip_norm->SPR_BENCH\u201d dictionary, and iterate over the five clip settings (none, 0.1, 0.5, 1.0, 5.0). For each setting we\u2019ll collect the per-epoch train and validation losses and the validation CRWA to build common x-axes (epochs). Three figures will be produced: (1) a line plot showing train vs validation loss for all clip norms, (2) a line plot of validation CRWA over epochs for the same clip norms, and (3) a bar chart of final test CRWA scores per clip norm. Each figure creation is wrapped in its own try-except block, the title explicitly states the dataset and what is shown, and descriptive filenames are used. Figures are saved to working_dir and immediately closed to free memory. The code adheres strictly to basic matplotlib, uses only available data, and limits output to the required three plots.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": [null, "num_epochs", "learning_rate", "batch_size", "embed_dim", "weight_decay (L2 regularization)", "dropout_rate", "label_smoothing", "gradient_clip_norm", null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["Below is a concise plan followed by executable code. The script (1) locates the\nworking directory, (2) loads the saved numpy dictionary, (3) walks through every\ndataset inside it, and (4) prints the final-epoch training/validation metrics as\nwell as all test metrics with explicit names.", "The script will first locate and load the saved NumPy file, then iterate through\nevery training-run entry (e.g., epochs_5, epochs_10 \u2026).   For every run it will:\n1. Report the last recorded training loss.   2. Identify the epoch that achieved\nthe minimum validation loss and print that \u201cbest\u201d validation loss together with\nits corresponding CRWA, SWA and CWA scores.   3. Print the final test-set loss\nand its CRWA, SWA and CWA scores.   All information is printed\nimmediately\u2014dataset name first, followed by clearly named metrics.", "The script will load the saved NumPy dictionary, iterate over every learning-\nrate experiment, and for each of the three data splits (training, validation,\ntest) print the final (or only) value of every metric that was logged. For\ntraining we report the final loss; for validation we report the final loss plus\nthe last recorded CRWA, SWA, and CWA; for test we report the single stored loss\ntogether with CRWA, SWA, and CWA. Dataset names and metric names are printed\nexplicitly so that nothing is ambiguous.", "We will load the saved NumPy file, pull out the single dataset that was produced\nduring the batch-size sweep, identify the batch size that achieved the highest\nvalidation CRWA score, and then report the corresponding final-epoch train loss,\nbest validation loss, best validation CRWA/SWA/CWA, and the test-set loss and\nmetrics. All information is printed with explicit metric names, preceded by the\ndataset name, and the script runs immediately upon execution.", "The code will load the serialized NumPy dictionary from the working directory,\nloop over every experiment stored under the key embed_dim_tuning, and for each\nembedding-dimension run (e.g., SPR_BENCH_dim_32) it will fetch the final values\nstored in the training/validation loss lists, the last validation metric\ndictionary, and the dedicated test loss/metric entries. It then prints the\ndataset name followed by clearly labelled metrics such as \u201cfinal training loss,\u201d\n\u201cfinal validation CRWA,\u201d or \u201ctest SWA,\u201d thereby satisfying the requirement for\nexplicit metric naming. All logic sits at the global scope so the script runs\nimmediately when executed.", "The script will first locate and load the saved NumPy file that contains the\nexperimental results.   It then walks through the nested dictionary (hyper-\nparameter \u2192 dataset) to extract the metric lists.   For every dataset it selects\nthe setting that achieved the highest validation CRWA and prints the\ncorresponding training, validation and test losses together with CRWA, SWA and\nCWA, always using explicit metric names.   Everything is executed at the top\nlevel so the file runs immediately when executed.", "The script loads the saved numpy file from the working directory, retrieves the\ndropout rate that achieved the best validation CRWA, and then extracts the\nfinal-epoch training and validation losses, the final-epoch validation metrics,\nand the stored test-set metrics for that best model. It prints each metric with\nan explicit, descriptive label and precedes every group of metrics with the\ndataset name.", "The script will locate the saved NumPy file in the working directory, load it\ninto a Python dictionary, and iterate over each label-smoothing configuration.\nFor every configuration it will print the final (i.e., last-epoch) training\nloss, the final validation loss and weighted accuracies (CRWA, SWA, CWA), and\nthe single set of test metrics.   Each block is clearly prefixed with the\ndataset name (\u201cTraining\u201d, \u201cValidation\u201d, \u201cTest\u201d) and every metric is labeled\nexplicitly.", "We will load the numpy file from the \u201cworking\u201d directory, inspect its nested\ndictionary, and then pick the run (distinguished by the gradient-clip value)\nthat achieves the lowest final validation loss for each dataset. From that best\nrun we extract the final train loss, final validation loss, test loss, and the\nthree evaluation metrics (CRWA, SWA, CWA). Finally, we print the dataset name\nfollowed by each metric name and its value, clearly labelling everything. The\nscript executes immediately, contains no special entry-point guard, and respects\nall structural constraints.", "The script will first locate and load the saved NumPy file, then iterate through\nevery training-run entry (e.g., epochs_5, epochs_10 \u2026).   For every run it will:\n1. Report the last recorded training loss.   2. Identify the epoch that achieved\nthe minimum validation loss and print that \u201cbest\u201d validation loss together with\nits corresponding CRWA, SWA and CWA scores.   3. Print the final test-set loss\nand its CRWA, SWA and CWA scores.   All information is printed\nimmediately\u2014dataset name first, followed by clearly named metrics.", "The script will first locate and load the saved NumPy file, then iterate through\nevery training-run entry (e.g., epochs_5, epochs_10 \u2026).   For every run it will:\n1. Report the last recorded training loss.   2. Identify the epoch that achieved\nthe minimum validation loss and print that \u201cbest\u201d validation loss together with\nits corresponding CRWA, SWA and CWA scores.   3. Print the final test-set loss\nand its CRWA, SWA and CWA scores.   All information is printed\nimmediately\u2014dataset name first, followed by clearly named metrics.", "The script will first locate and load the saved NumPy file, then iterate through\nevery training-run entry (e.g., epochs_5, epochs_10 \u2026).   For every run it will:\n1. Report the last recorded training loss.   2. Identify the epoch that achieved\nthe minimum validation loss and print that \u201cbest\u201d validation loss together with\nits corresponding CRWA, SWA and CWA scores.   3. Print the final test-set loss\nand its CRWA, SWA and CWA scores.   All information is printed\nimmediately\u2014dataset name first, followed by clearly named metrics.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper ----------\ndef safe_last(lst):\n    \"\"\"Return the last element of a list if the list is non-empty; else None.\"\"\"\n    return lst[-1] if lst else None\n\n\n# ---------- iterate and report ----------\nfor dataset_name, content in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # losses\n    final_train_loss = safe_last(content[\"losses\"].get(\"train\", []))\n    final_val_loss = safe_last(content[\"losses\"].get(\"val\", []))\n    test_loss = content[\"losses\"].get(\"test\")\n\n    if final_train_loss is not None:\n        print(f\"Final training loss: {final_train_loss:.4f}\")\n    if final_val_loss is not None:\n        print(f\"Final validation loss: {final_val_loss:.4f}\")\n    if test_loss is not None:\n        print(f\"Test loss: {test_loss:.4f}\")\n\n    # validation metrics (take final epoch)\n    final_val_metrics = safe_last(content[\"metrics\"].get(\"val\", [])) or {}\n    for metric_name, metric_value in final_val_metrics.items():\n        print(f\"Final validation {metric_name}: {metric_value:.4f}\")\n\n    # test metrics (single dict)\n    test_metrics = content[\"metrics\"].get(\"test\", {}) or {}\n    for metric_name, metric_value in test_metrics.items():\n        print(f\"Test {metric_name}: {metric_value:.4f}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# 0-1. Load the stored experiment data dictionary\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\nruns = experiment_data.get(\"num_epochs\", {})\n\n# -------------------------------------------------\n# 2-5. Extract and print the required metrics\n# -------------------------------------------------\nfor run_name, run_data in runs.items():\n    print(f\"\\n===== {run_name} =====\")\n\n    # ---------- TRAIN ----------\n    # Last epoch\u2019s training loss\n    if run_data[\"losses\"][\"train\"]:\n        train_loss_final = run_data[\"losses\"][\"train\"][-1]\n        print(\"Training Dataset\")\n        print(f\"training loss: {train_loss_final:.4f}\")\n\n    # ---------- VALIDATION ----------\n    # Find epoch index with the minimum validation loss\n    val_losses = run_data[\"losses\"][\"val\"]\n    if val_losses:\n        best_idx = int(np.argmin(val_losses))\n        best_val_loss = val_losses[best_idx]\n        best_val_metrics = run_data[\"metrics\"][\"val\"][best_idx]\n\n        print(\"Validation Dataset\")\n        print(f\"validation loss: {best_val_loss:.4f}\")\n        if best_val_metrics:\n            print(f\"validation CRWA: {best_val_metrics['CRWA']:.4f}\")\n            print(f\"validation SWA: {best_val_metrics['SWA']:.4f}\")\n            print(f\"validation CWA: {best_val_metrics['CWA']:.4f}\")\n\n    # ---------- TEST ----------\n    test_loss = run_data[\"losses\"].get(\"test\", None)\n    test_metrics = run_data[\"metrics\"].get(\"test\", {})\n    if test_loss is not None:\n        print(\"Test Dataset\")\n        print(f\"test loss: {test_loss:.4f}\")\n        if test_metrics:\n            print(f\"test CRWA: {test_metrics['CRWA']:.4f}\")\n            print(f\"test SWA: {test_metrics['SWA']:.4f}\")\n            print(f\"test CWA: {test_metrics['CWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\nlr_dict = experiment_data.get(\"learning_rate\", {}).get(\"SPR_BENCH\", {})\n\n\ndef fmt(x):\n    \"Format floats uniformly\"\n    return f\"{x:.4f}\" if isinstance(x, (int, float, np.floating)) else str(x)\n\n\nfor lr_key, exp in lr_dict.items():\n    print(f\"\\n===== RESULTS FOR learning_rate = {lr_key} =====\")\n\n    # ---- TRAIN ----\n    print(\"Dataset: training\")\n    if exp[\"losses\"][\"train\"]:\n        train_loss_final = exp[\"losses\"][\"train\"][-1]\n        print(f\"training loss: {fmt(train_loss_final)}\")\n    else:\n        print(\"training loss: N/A\")\n\n    # ---- VALIDATION ----\n    print(\"Dataset: validation\")\n    if exp[\"losses\"][\"val\"]:\n        val_loss_final = exp[\"losses\"][\"val\"][-1]\n        print(f\"validation loss: {fmt(val_loss_final)}\")\n    if exp[\"metrics\"][\"val\"]:\n        last_val_metrics = exp[\"metrics\"][\"val\"][-1] or {}\n        for metric_name, val in last_val_metrics.items():\n            print(f\"validation {metric_name}: {fmt(val)}\")\n\n    # ---- TEST ----\n    print(\"Dataset: test\")\n    test_loss = exp[\"losses\"].get(\"test\")\n    if test_loss is not None:\n        print(f\"test loss: {fmt(test_loss)}\")\n    test_metrics = exp[\"metrics\"].get(\"test\", {})\n    for metric_name, val in test_metrics.items():\n        print(f\"test {metric_name}: {fmt(val)}\")\n", "import os\nimport numpy as np\n\n# ----------------- locate and load experiment data -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ----------------- helper to gather best validation epoch -----------------\ndef get_best_val_epoch(val_metrics_epoch):\n    \"\"\"Returns (best_epoch_index, best_CRWA) where best_CRWA is maximum.\"\"\"\n    crwa_values = [m[\"CRWA\"] for m in val_metrics_epoch]\n    best_idx = int(np.argmax(crwa_values))\n    return best_idx, crwa_values[best_idx]\n\n\n# ----------------- iterate through experiments/datasets -----------------\nfor exp_name, exp_content in experiment_data.items():\n    for dataset_name, data in exp_content.items():\n        # determine best batch size based on highest validation CRWA\n        best_overall = {\"batch_idx\": None, \"best_crwa\": -np.inf}\n        for idx, val_metrics_epoch in enumerate(data[\"metrics\"][\"val\"]):\n            _, best_crwa = get_best_val_epoch(val_metrics_epoch)\n            if best_crwa > best_overall[\"best_crwa\"]:\n                best_overall.update({\"batch_idx\": idx, \"best_crwa\": best_crwa})\n\n        i = best_overall[\"batch_idx\"]  # chosen batch-size index\n        bs_value = data[\"batch_sizes\"][i]  # actual batch size\n\n        # losses\n        train_loss_final = data[\"losses\"][\"train\"][i][-1]  # final epoch train loss\n        val_loss_best = min(data[\"losses\"][\"val\"][i])  # best (lowest) val loss\n        test_loss = data[\"losses\"][\"test\"][i]  # test loss\n\n        # best validation metrics (epoch with best CRWA)\n        best_ep_idx, _ = get_best_val_epoch(data[\"metrics\"][\"val\"][i])\n        best_val_metrics = data[\"metrics\"][\"val\"][i][best_ep_idx]\n\n        # test metrics\n        test_metrics = data[\"metrics\"][\"test\"][i]\n\n        # ----------------- print results -----------------\n        print(f\"\\nDataset: {dataset_name}\")\n        print(f\"chosen batch size: {bs_value}\")\n        print(f\"train loss (final epoch): {train_loss_final:.4f}\")\n        print(f\"validation loss (best epoch): {val_loss_best:.4f}\")\n        print(f\"validation CRWA (best epoch): {best_val_metrics['CRWA']:.4f}\")\n        print(f\"validation SWA  (same epoch): {best_val_metrics['SWA']:.4f}\")\n        print(f\"validation CWA  (same epoch): {best_val_metrics['CWA']:.4f}\")\n        print(f\"test loss: {test_loss:.4f}\")\n        print(f\"test CRWA: {test_metrics['CRWA']:.4f}\")\n        print(f\"test SWA:  {test_metrics['SWA']:.4f}\")\n        print(f\"test CWA:  {test_metrics['CWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\n# ---------- load ----------\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- iterate and display ----------\nfor run_name, run_data in experiment_data.get(\"embed_dim_tuning\", {}).items():\n    print(run_name)  # dataset name first\n\n    # -------- final training loss --------\n    train_losses = run_data.get(\"losses\", {}).get(\"train\", [])\n    if train_losses:\n        print(f\"  final training loss: {train_losses[-1]:.6f}\")\n\n    # -------- final validation loss --------\n    val_losses = run_data.get(\"losses\", {}).get(\"val\", [])\n    if val_losses:\n        print(f\"  final validation loss: {val_losses[-1]:.6f}\")\n\n    # -------- final validation metrics --------\n    val_metrics_list = run_data.get(\"metrics\", {}).get(\"val\", [])\n    if val_metrics_list and val_metrics_list[-1] is not None:\n        final_val_metrics = val_metrics_list[-1]\n        for metric_name, metric_value in final_val_metrics.items():\n            print(f\"  final validation {metric_name}: {metric_value:.6f}\")\n\n    # -------- test loss --------\n    test_loss = run_data.get(\"losses\", {}).get(\"test\")\n    if test_loss is not None:\n        print(f\"  test loss: {test_loss:.6f}\")\n\n    # -------- test metrics --------\n    test_metrics = run_data.get(\"metrics\", {}).get(\"test\", {})\n    for metric_name, metric_value in test_metrics.items():\n        print(f\"  test {metric_name}: {metric_value:.6f}\")\n\n    # blank line between runs\n    print()\n", "import os\nimport numpy as np\n\n# --------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# --------- iterate over stored results ----------\nfor hp_name, hp_block in experiment_data.items():  # e.g. \"weight_decay\"\n    for dataset_name, dset_block in hp_block.items():  # e.g. \"SPR_BENCH\"\n\n        decay_values = np.asarray(dset_block[\"decay_values\"])\n        val_metrics = dset_block[\"metrics\"][\"val\"]  # list of dicts\n        test_metrics = dset_block[\"metrics\"][\"test\"]  # list of dicts\n        train_losses = np.asarray(dset_block[\"losses\"][\"train\"])\n        val_losses = np.asarray(dset_block[\"losses\"][\"val\"])\n        test_losses = np.asarray(dset_block[\"losses\"][\"test\"])\n\n        # --------- choose the best configuration (highest validation CRWA) ----------\n        val_crwa_scores = np.array([m[\"CRWA\"] for m in val_metrics])\n        best_idx = int(val_crwa_scores.argmax())\n\n        # --------- fetch corresponding numbers ----------\n        best_decay = decay_values[best_idx]\n        best_train_loss = train_losses[best_idx]\n        best_val_loss = val_losses[best_idx]\n        best_test_loss = test_losses[best_idx]\n\n        best_val_crwa, best_val_swa, best_val_cwa = (\n            val_metrics[best_idx][\"CRWA\"],\n            val_metrics[best_idx][\"SWA\"],\n            val_metrics[best_idx][\"CWA\"],\n        )\n        best_test_crwa, best_test_swa, best_test_cwa = (\n            test_metrics[best_idx][\"CRWA\"],\n            test_metrics[best_idx][\"SWA\"],\n            test_metrics[best_idx][\"CWA\"],\n        )\n\n        # --------- print in the required format ----------\n        print(f\"\\nDataset: {dataset_name}\")\n        print(f\"Chosen weight decay: {best_decay}\")\n\n        # losses\n        print(f\"training loss: {best_train_loss:.4f}\")\n        print(f\"validation loss: {best_val_loss:.4f}\")\n        print(f\"test loss: {best_test_loss:.4f}\")\n\n        # validation metrics\n        print(f\"validation CRWA: {best_val_crwa:.4f}\")\n        print(f\"validation SWA: {best_val_swa:.4f}\")\n        print(f\"validation CWA: {best_val_cwa:.4f}\")\n\n        # test metrics\n        print(f\"test CRWA: {best_test_crwa:.4f}\")\n        print(f\"test SWA: {best_test_swa:.4f}\")\n        print(f\"test CWA: {best_test_cwa:.4f}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# locate and load the saved experiment dictionary\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# -------------------------------------------------\n# locate best model information\n# -------------------------------------------------\ndrop_section = experiment_data[\"dropout_rate\"]\nbest_rate = drop_section[\"best_rate\"]\nbest_hist = drop_section[best_rate][\"SPR_BENCH\"]  # history dict of best model\ntest_metrics = drop_section[\"test_metrics\"]  # test-set metrics dict\n\n# -------------------------------------------------\n# grab final-epoch values from the training history\n# -------------------------------------------------\ntrain_loss_final = best_hist[\"losses\"][\"train\"][-1]\nval_loss_final = best_hist[\"losses\"][\"val\"][-1]\nval_metrics_final = best_hist[\"metrics\"][\"val\"][-1]  # dict with CRWA / SWA / CWA\n\n# -------------------------------------------------\n# print metrics with clear, explicit labels\n# -------------------------------------------------\nprint(\"SPR_BENCH - Train\")\nprint(f\"train loss: {train_loss_final:.4f}\")\n\nprint(\"\\nSPR_BENCH - Validation\")\nprint(f\"validation loss: {val_loss_final:.4f}\")\nprint(f\"validation CRWA: {val_metrics_final['CRWA']:.4f}\")\nprint(f\"validation SWA: {val_metrics_final['SWA']:.4f}\")\nprint(f\"validation CWA: {val_metrics_final['CWA']:.4f}\")\n\nprint(\"\\nSPR_BENCH - Test\")\nprint(f\"test loss: {test_metrics['loss']:.4f}\")\nprint(f\"test CRWA: {test_metrics['CRWA']:.4f}\")\nprint(f\"test SWA: {test_metrics['SWA']:.4f}\")\nprint(f\"test CWA: {test_metrics['CWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- pretty printer ----------\ndef print_metrics(title: str, metrics: dict):\n    \"\"\"\n    Print metrics in 'name: value' form under a dataset title.\n    \"\"\"\n    print(title)\n    for key, value in metrics.items():\n        print(f\"  {title.lower()} {key}: {value:.4f}\")\n\n\n# ---------- iterate over label-smoothing runs ----------\nfor sm_val, record in experiment_data.get(\"label_smoothing\", {}).items():\n    print(f\"\\n=== Results for label_smoothing = {sm_val} ===\")\n\n    # ----- Training -----\n    train_loss_list = record[\"losses\"][\"train\"]\n    if train_loss_list:  # safeguard\n        final_train_loss = train_loss_list[-1]\n        print_metrics(\"Training\", {\"loss\": final_train_loss})\n\n    # ----- Validation -----\n    val_loss_list = record[\"losses\"][\"val\"]\n    val_metrics_list = record[\"metrics\"][\"val\"]\n    if val_loss_list and val_metrics_list:\n        final_val_loss = val_loss_list[-1]\n        final_val_metrics = val_metrics_list[-1] or {}\n        val_dict = {\"loss\": final_val_loss, **final_val_metrics}\n        print_metrics(\"Validation\", val_dict)\n\n    # ----- Test -----\n    test_loss = record[\"losses\"][\"test\"]\n    test_metrics = record[\"metrics\"][\"test\"]\n    test_dict = {\"loss\": test_loss, **test_metrics}\n    print_metrics(\"Test\", test_dict)\n", "import os\nimport numpy as np\n\n# 0. Path to the saved numpy file\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\n# 1. Load the data\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# 2. Traverse data \u2013 top level key is 'gradient_clip_norm'\nhp_key = \"gradient_clip_norm\"\ntop = experiment_data.get(hp_key, {})\n\nfor dataset_name, runs in top.items():  # e.g. 'SPR_BENCH' \u2192 {clip_val : run_data}\n    # Select the run with the lowest final validation loss\n    best_run_key = None\n    best_val_loss = float(\"inf\")\n    best_run_data = None\n\n    for clip_val, run_data in runs.items():\n        val_losses = run_data[\"losses\"][\"val\"]\n        if not val_losses:  # safety\n            continue\n        final_val_loss = val_losses[-1]\n        if final_val_loss < best_val_loss:\n            best_val_loss = final_val_loss\n            best_run_key = clip_val\n            best_run_data = run_data\n\n    if best_run_data is None:\n        continue  # nothing to show\n\n    # 3. Extract the desired final / test metrics\n    train_loss_final = best_run_data[\"losses\"][\"train\"][-1]\n    val_loss_final = best_run_data[\"losses\"][\"val\"][-1]\n    test_loss = best_run_data[\"losses\"][\"test\"]\n\n    test_metrics = best_run_data[\"metrics\"][\"test\"]\n    test_crwa = test_metrics[\"CRWA\"]\n    test_swa = test_metrics[\"SWA\"]\n    test_cwa = test_metrics[\"CWA\"]\n\n    # 3 & 4. Print results with clear labels\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Chosen gradient_clip_norm: {best_run_key}\")\n    print(f\"train loss: {train_loss_final:.6f}\")\n    print(f\"validation loss: {val_loss_final:.6f}\")\n    print(f\"test loss: {test_loss:.6f}\")\n    print(f\"test CRWA: {test_crwa:.6f}\")\n    print(f\"test SWA: {test_swa:.6f}\")\n    print(f\"test CWA: {test_cwa:.6f}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# 0-1. Load the stored experiment data dictionary\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\nruns = experiment_data.get(\"num_epochs\", {})\n\n# -------------------------------------------------\n# 2-5. Extract and print the required metrics\n# -------------------------------------------------\nfor run_name, run_data in runs.items():\n    print(f\"\\n===== {run_name} =====\")\n\n    # ---------- TRAIN ----------\n    # Last epoch\u2019s training loss\n    if run_data[\"losses\"][\"train\"]:\n        train_loss_final = run_data[\"losses\"][\"train\"][-1]\n        print(\"Training Dataset\")\n        print(f\"training loss: {train_loss_final:.4f}\")\n\n    # ---------- VALIDATION ----------\n    # Find epoch index with the minimum validation loss\n    val_losses = run_data[\"losses\"][\"val\"]\n    if val_losses:\n        best_idx = int(np.argmin(val_losses))\n        best_val_loss = val_losses[best_idx]\n        best_val_metrics = run_data[\"metrics\"][\"val\"][best_idx]\n\n        print(\"Validation Dataset\")\n        print(f\"validation loss: {best_val_loss:.4f}\")\n        if best_val_metrics:\n            print(f\"validation CRWA: {best_val_metrics['CRWA']:.4f}\")\n            print(f\"validation SWA: {best_val_metrics['SWA']:.4f}\")\n            print(f\"validation CWA: {best_val_metrics['CWA']:.4f}\")\n\n    # ---------- TEST ----------\n    test_loss = run_data[\"losses\"].get(\"test\", None)\n    test_metrics = run_data[\"metrics\"].get(\"test\", {})\n    if test_loss is not None:\n        print(\"Test Dataset\")\n        print(f\"test loss: {test_loss:.4f}\")\n        if test_metrics:\n            print(f\"test CRWA: {test_metrics['CRWA']:.4f}\")\n            print(f\"test SWA: {test_metrics['SWA']:.4f}\")\n            print(f\"test CWA: {test_metrics['CWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# 0-1. Load the stored experiment data dictionary\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\nruns = experiment_data.get(\"num_epochs\", {})\n\n# -------------------------------------------------\n# 2-5. Extract and print the required metrics\n# -------------------------------------------------\nfor run_name, run_data in runs.items():\n    print(f\"\\n===== {run_name} =====\")\n\n    # ---------- TRAIN ----------\n    # Last epoch\u2019s training loss\n    if run_data[\"losses\"][\"train\"]:\n        train_loss_final = run_data[\"losses\"][\"train\"][-1]\n        print(\"Training Dataset\")\n        print(f\"training loss: {train_loss_final:.4f}\")\n\n    # ---------- VALIDATION ----------\n    # Find epoch index with the minimum validation loss\n    val_losses = run_data[\"losses\"][\"val\"]\n    if val_losses:\n        best_idx = int(np.argmin(val_losses))\n        best_val_loss = val_losses[best_idx]\n        best_val_metrics = run_data[\"metrics\"][\"val\"][best_idx]\n\n        print(\"Validation Dataset\")\n        print(f\"validation loss: {best_val_loss:.4f}\")\n        if best_val_metrics:\n            print(f\"validation CRWA: {best_val_metrics['CRWA']:.4f}\")\n            print(f\"validation SWA: {best_val_metrics['SWA']:.4f}\")\n            print(f\"validation CWA: {best_val_metrics['CWA']:.4f}\")\n\n    # ---------- TEST ----------\n    test_loss = run_data[\"losses\"].get(\"test\", None)\n    test_metrics = run_data[\"metrics\"].get(\"test\", {})\n    if test_loss is not None:\n        print(\"Test Dataset\")\n        print(f\"test loss: {test_loss:.4f}\")\n        if test_metrics:\n            print(f\"test CRWA: {test_metrics['CRWA']:.4f}\")\n            print(f\"test SWA: {test_metrics['SWA']:.4f}\")\n            print(f\"test CWA: {test_metrics['CWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# 0-1. Load the stored experiment data dictionary\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\nruns = experiment_data.get(\"num_epochs\", {})\n\n# -------------------------------------------------\n# 2-5. Extract and print the required metrics\n# -------------------------------------------------\nfor run_name, run_data in runs.items():\n    print(f\"\\n===== {run_name} =====\")\n\n    # ---------- TRAIN ----------\n    # Last epoch\u2019s training loss\n    if run_data[\"losses\"][\"train\"]:\n        train_loss_final = run_data[\"losses\"][\"train\"][-1]\n        print(\"Training Dataset\")\n        print(f\"training loss: {train_loss_final:.4f}\")\n\n    # ---------- VALIDATION ----------\n    # Find epoch index with the minimum validation loss\n    val_losses = run_data[\"losses\"][\"val\"]\n    if val_losses:\n        best_idx = int(np.argmin(val_losses))\n        best_val_loss = val_losses[best_idx]\n        best_val_metrics = run_data[\"metrics\"][\"val\"][best_idx]\n\n        print(\"Validation Dataset\")\n        print(f\"validation loss: {best_val_loss:.4f}\")\n        if best_val_metrics:\n            print(f\"validation CRWA: {best_val_metrics['CRWA']:.4f}\")\n            print(f\"validation SWA: {best_val_metrics['SWA']:.4f}\")\n            print(f\"validation CWA: {best_val_metrics['CWA']:.4f}\")\n\n    # ---------- TEST ----------\n    test_loss = run_data[\"losses\"].get(\"test\", None)\n    test_metrics = run_data[\"metrics\"].get(\"test\", {})\n    if test_loss is not None:\n        print(\"Test Dataset\")\n        print(f\"test loss: {test_loss:.4f}\")\n        if test_metrics:\n            print(f\"test CRWA: {test_metrics['CRWA']:.4f}\")\n            print(f\"test SWA: {test_metrics['SWA']:.4f}\")\n            print(f\"test CWA: {test_metrics['CWA']:.4f}\")\n", ""], "parse_term_out": ["['\\nDataset: SPR_BENCH', '\\n', 'Final training loss: 0.4983', '\\n', 'Final\nvalidation loss: 0.4981', '\\n', 'Test loss: 0.7049', '\\n', 'Final validation\nCRWA: 0.7653', '\\n', 'Final validation SWA: 0.7718', '\\n', 'Final validation\nCWA: 0.7673', '\\n', 'Test CRWA: 0.5945', '\\n', 'Test SWA: 0.5931', '\\n', 'Test\nCWA: 0.6213', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\n===== epochs_5 =====', '\\n', 'Training Dataset', '\\n', 'training loss:\n0.4919', '\\n', 'Validation Dataset', '\\n', 'validation loss: 0.4930', '\\n',\n'validation CRWA: 0.7669', '\\n', 'validation SWA: 0.7733', '\\n', 'validation\nCWA: 0.7697', '\\n', 'Test Dataset', '\\n', 'test loss: 0.7067', '\\n', 'test CRWA:\n0.5961', '\\n', 'test SWA: 0.5944', '\\n', 'test CWA: 0.6230', '\\n', '\\n=====\nepochs_10 =====', '\\n', 'Training Dataset', '\\n', 'training loss: 0.4750', '\\n',\n'Validation Dataset', '\\n', 'validation loss: 0.4773', '\\n', 'validation CRWA:\n0.7664', '\\n', 'validation SWA: 0.7743', '\\n', 'validation CWA: 0.7707', '\\n',\n'Test Dataset', '\\n', 'test loss: 0.6873', '\\n', 'test CRWA: 0.6015', '\\n',\n'test SWA: 0.6003', '\\n', 'test CWA: 0.6302', '\\n', '\\n===== epochs_20 =====',\n'\\n', 'Training Dataset', '\\n', 'training loss: 0.4555', '\\n', 'Validation\nDataset', '\\n', 'validation loss: 0.4618', '\\n', 'validation CRWA: 0.7725',\n'\\n', 'validation SWA: 0.7808', '\\n', 'validation CWA: 0.7804', '\\n', 'Test\nDataset', '\\n', 'test loss: 0.6891', '\\n', 'test CRWA: 0.6134', '\\n', 'test SWA:\n0.6124', '\\n', 'test CWA: 0.6443', '\\n', '\\n===== epochs_30 =====', '\\n',\n'Training Dataset', '\\n', 'training loss: 0.4480', '\\n', 'Validation Dataset',\n'\\n', 'validation loss: 0.4552', '\\n', 'validation CRWA: 0.7684', '\\n',\n'validation SWA: 0.7772', '\\n', 'validation CWA: 0.7787', '\\n', 'Test Dataset',\n'\\n', 'test loss: 0.6885', '\\n', 'test CRWA: 0.6172', '\\n', 'test SWA: 0.6168',\n'\\n', 'test CWA: 0.6494', '\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']", "['\\n===== RESULTS FOR learning_rate = 1e-04 =====', '\\n', 'Dataset: training',\n'\\n', 'training loss: 0.6036', '\\n', 'Dataset: validation', '\\n', 'validation\nloss: 0.5933', '\\n', 'validation CRWA: 0.7029', '\\n', 'validation SWA: 0.7105',\n'\\n', 'validation CWA: 0.7036', '\\n', 'Dataset: test', '\\n', 'test loss:\n0.6771', '\\n', 'test CRWA: 0.5733', '\\n', 'test SWA: 0.5724', '\\n', 'test CWA:\n0.5930', '\\n', '\\n===== RESULTS FOR learning_rate = 3e-04 =====', '\\n',\n'Dataset: training', '\\n', 'training loss: 0.5230', '\\n', 'Dataset: validation',\n'\\n', 'validation loss: 0.5199', '\\n', 'validation CRWA: 0.7415', '\\n',\n'validation SWA: 0.7497', '\\n', 'validation CWA: 0.7450', '\\n', 'Dataset: test',\n'\\n', 'test loss: 0.6874', '\\n', 'test CRWA: 0.5969', '\\n', 'test SWA: 0.5954',\n'\\n', 'test CWA: 0.6218', '\\n', '\\n===== RESULTS FOR learning_rate = 5e-04\n=====', '\\n', 'Dataset: training', '\\n', 'training loss: 0.5086', '\\n',\n'Dataset: validation', '\\n', 'validation loss: 0.5081', '\\n', 'validation CRWA:\n0.7600', '\\n', 'validation SWA: 0.7663', '\\n', 'validation CWA: 0.7626', '\\n',\n'Dataset: test', '\\n', 'test loss: 0.7035', '\\n', 'test CRWA: 0.5965', '\\n',\n'test SWA: 0.5950', '\\n', 'test CWA: 0.6224', '\\n', '\\n===== RESULTS FOR\nlearning_rate = 1e-03 =====', '\\n', 'Dataset: training', '\\n', 'training loss:\n0.4970', '\\n', 'Dataset: validation', '\\n', 'validation loss: 0.4969', '\\n',\n'validation CRWA: 0.7690', '\\n', 'validation SWA: 0.7746', '\\n', 'validation\nCWA: 0.7715', '\\n', 'Dataset: test', '\\n', 'test loss: 0.7091', '\\n', 'test\nCRWA: 0.5960', '\\n', 'test SWA: 0.5941', '\\n', 'test CWA: 0.6228', '\\n',\n'\\n===== RESULTS FOR learning_rate = 3e-03 =====', '\\n', 'Dataset: training',\n'\\n', 'training loss: 0.4656', '\\n', 'Dataset: validation', '\\n', 'validation\nloss: 0.4696', '\\n', 'validation CRWA: 0.7635', '\\n', 'validation SWA: 0.7710',\n'\\n', 'validation CWA: 0.7715', '\\n', 'Dataset: test', '\\n', 'test loss:\n0.6912', '\\n', 'test CRWA: 0.6074', '\\n', 'test SWA: 0.6063', '\\n', 'test CWA:\n0.6368', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'chosen batch size: 64', '\\n', 'train loss (final\nepoch): 0.4823', '\\n', 'validation loss (best epoch): 0.4838', '\\n', 'validation\nCRWA (best epoch): 0.7719', '\\n', 'validation SWA  (same epoch): 0.7786', '\\n',\n'validation CWA  (same epoch): 0.7763', '\\n', 'test loss: 0.6966', '\\n', 'test\nCRWA: 0.6032', '\\n', 'test SWA:  0.6016', '\\n', 'test CWA:  0.6315', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH_dim_32', '\\n', '  final training loss: 0.493645', '\\n', '  final\nvalidation loss: 0.493965', '\\n', '  final validation CRWA: 0.764614', '\\n', '\nfinal validation SWA: 0.771306', '\\n', '  final validation CWA: 0.766945', '\\n',\n'  test loss: 0.696931', '\\n', '  test CRWA: 0.594295', '\\n', '  test SWA:\n0.592958', '\\n', '  test CWA: 0.621153', '\\n', '\\n', 'SPR_BENCH_dim_64', '\\n', '\nfinal training loss: 0.496428', '\\n', '  final validation loss: 0.496683', '\\n',\n'  final validation CRWA: 0.766033', '\\n', '  final validation SWA: 0.772352',\n'\\n', '  final validation CWA: 0.768165', '\\n', '  test loss: 0.708749', '\\n', '\ntest CRWA: 0.593872', '\\n', '  test SWA: 0.592204', '\\n', '  test CWA:\n0.620424', '\\n', '\\n', 'SPR_BENCH_dim_128', '\\n', '  final training loss:\n0.487696', '\\n', '  final validation loss: 0.488710', '\\n', '  final validation\nCRWA: 0.766706', '\\n', '  final validation SWA: 0.773864', '\\n', '  final\nvalidation CWA: 0.770057', '\\n', '  test loss: 0.694666', '\\n', '  test CRWA:\n0.600546', '\\n', '  test SWA: 0.599044', '\\n', '  test CWA: 0.628202', '\\n',\n'\\n', 'SPR_BENCH_dim_256', '\\n', '  final training loss: 0.489999', '\\n', '\nfinal validation loss: 0.490980', '\\n', '  final validation CRWA: 0.769454',\n'\\n', '  final validation SWA: 0.775666', '\\n', '  final validation CWA:\n0.773107', '\\n', '  test loss: 0.706085', '\\n', '  test CRWA: 0.599375', '\\n', '\ntest SWA: 0.597653', '\\n', '  test CWA: 0.626774', '\\n', '\\n', 'Execution time:\na moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'Chosen weight decay: 1e-05', '\\n', 'training\nloss: 0.4936', '\\n', 'validation loss: 0.4946', '\\n', 'test loss: 0.7034', '\\n',\n'validation CRWA: 0.7672', '\\n', 'validation SWA: 0.7735', '\\n', 'validation\nCWA: 0.7701', '\\n', 'test CRWA: 0.5955', '\\n', 'test SWA: 0.5938', '\\n', 'test\nCWA: 0.6224', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['SPR_BENCH - Train', '\\n', 'train loss: 0.4919', '\\n', '\\nSPR_BENCH -\nValidation', '\\n', 'validation loss: 0.4930', '\\n', 'validation CRWA: 0.7669',\n'\\n', 'validation SWA: 0.7733', '\\n', 'validation CWA: 0.7697', '\\n',\n'\\nSPR_BENCH - Test', '\\n', 'test loss: 0.7067', '\\n', 'test CRWA: 0.5961',\n'\\n', 'test SWA: 0.5944', '\\n', 'test CWA: 0.6230', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['\\n=== Results for label_smoothing = 0.0 ===', '\\n', 'Training', '\\n', '\ntraining loss: 0.4941', '\\n', 'Validation', '\\n', '  validation loss: 0.4953',\n'\\n', '  validation CRWA: 0.7674', '\\n', '  validation SWA: 0.7730', '\\n', '\nvalidation CWA: 0.7704', '\\n', 'Test', '\\n', '  test loss: 0.7107', '\\n', '\ntest CRWA: 0.5957', '\\n', '  test SWA: 0.5938', '\\n', '  test CWA: 0.6226',\n'\\n', '\\n=== Results for label_smoothing = 0.05 ===', '\\n', 'Training', '\\n', '\ntraining loss: 0.5163', '\\n', 'Validation', '\\n', '  validation loss: 0.5175',\n'\\n', '  validation CRWA: 0.7653', '\\n', '  validation SWA: 0.7712', '\\n', '\nvalidation CWA: 0.7687', '\\n', 'Test', '\\n', '  test loss: 0.7046', '\\n', '\ntest CRWA: 0.5964', '\\n', '  test SWA: 0.5947', '\\n', '  test CWA: 0.6236',\n'\\n', '\\n=== Results for label_smoothing = 0.1 ===', '\\n', 'Training', '\\n', '\ntraining loss: 0.5366', '\\n', 'Validation', '\\n', '  validation loss: 0.5378',\n'\\n', '  validation CRWA: 0.7633', '\\n', '  validation SWA: 0.7696', '\\n', '\nvalidation CWA: 0.7671', '\\n', 'Test', '\\n', '  test loss: 0.6999', '\\n', '\ntest CRWA: 0.5975', '\\n', '  test SWA: 0.5958', '\\n', '  test CWA: 0.6246',\n'\\n', '\\n=== Results for label_smoothing = 0.2 ===', '\\n', 'Training', '\\n', '\ntraining loss: 0.5723', '\\n', 'Validation', '\\n', '  validation loss: 0.5733',\n'\\n', '  validation CRWA: 0.7596', '\\n', '  validation SWA: 0.7662', '\\n', '\nvalidation CWA: 0.7640', '\\n', 'Test', '\\n', '  test loss: 0.6939', '\\n', '\ntest CRWA: 0.5980', '\\n', '  test SWA: 0.5963', '\\n', '  test CWA: 0.6253',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', 'Chosen gradient_clip_norm: 0.1', '\\n', 'train\nloss: 0.487228', '\\n', 'validation loss: 0.487735', '\\n', 'test loss: 0.695507',\n'\\n', 'test CRWA: 0.598160', '\\n', 'test SWA: 0.596841', '\\n', 'test CWA:\n0.625619', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\n===== epochs_5 =====', '\\n', 'Training Dataset', '\\n', 'training loss:\n0.4919', '\\n', 'Validation Dataset', '\\n', 'validation loss: 0.4930', '\\n',\n'validation CRWA: 0.7669', '\\n', 'validation SWA: 0.7733', '\\n', 'validation\nCWA: 0.7697', '\\n', 'Test Dataset', '\\n', 'test loss: 0.7067', '\\n', 'test CRWA:\n0.5961', '\\n', 'test SWA: 0.5944', '\\n', 'test CWA: 0.6230', '\\n', '\\n=====\nepochs_10 =====', '\\n', 'Training Dataset', '\\n', 'training loss: 0.4750', '\\n',\n'Validation Dataset', '\\n', 'validation loss: 0.4773', '\\n', 'validation CRWA:\n0.7664', '\\n', 'validation SWA: 0.7743', '\\n', 'validation CWA: 0.7707', '\\n',\n'Test Dataset', '\\n', 'test loss: 0.6873', '\\n', 'test CRWA: 0.6015', '\\n',\n'test SWA: 0.6003', '\\n', 'test CWA: 0.6302', '\\n', '\\n===== epochs_20 =====',\n'\\n', 'Training Dataset', '\\n', 'training loss: 0.4555', '\\n', 'Validation\nDataset', '\\n', 'validation loss: 0.4618', '\\n', 'validation CRWA: 0.7725',\n'\\n', 'validation SWA: 0.7808', '\\n', 'validation CWA: 0.7804', '\\n', 'Test\nDataset', '\\n', 'test loss: 0.6891', '\\n', 'test CRWA: 0.6134', '\\n', 'test SWA:\n0.6124', '\\n', 'test CWA: 0.6443', '\\n', '\\n===== epochs_30 =====', '\\n',\n'Training Dataset', '\\n', 'training loss: 0.4480', '\\n', 'Validation Dataset',\n'\\n', 'validation loss: 0.4552', '\\n', 'validation CRWA: 0.7684', '\\n',\n'validation SWA: 0.7772', '\\n', 'validation CWA: 0.7787', '\\n', 'Test Dataset',\n'\\n', 'test loss: 0.6885', '\\n', 'test CRWA: 0.6172', '\\n', 'test SWA: 0.6168',\n'\\n', 'test CWA: 0.6494', '\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']", "['\\n===== epochs_5 =====', '\\n', 'Training Dataset', '\\n', 'training loss:\n0.4919', '\\n', 'Validation Dataset', '\\n', 'validation loss: 0.4930', '\\n',\n'validation CRWA: 0.7669', '\\n', 'validation SWA: 0.7733', '\\n', 'validation\nCWA: 0.7697', '\\n', 'Test Dataset', '\\n', 'test loss: 0.7067', '\\n', 'test CRWA:\n0.5961', '\\n', 'test SWA: 0.5944', '\\n', 'test CWA: 0.6230', '\\n', '\\n=====\nepochs_10 =====', '\\n', 'Training Dataset', '\\n', 'training loss: 0.4750', '\\n',\n'Validation Dataset', '\\n', 'validation loss: 0.4773', '\\n', 'validation CRWA:\n0.7664', '\\n', 'validation SWA: 0.7743', '\\n', 'validation CWA: 0.7707', '\\n',\n'Test Dataset', '\\n', 'test loss: 0.6873', '\\n', 'test CRWA: 0.6015', '\\n',\n'test SWA: 0.6003', '\\n', 'test CWA: 0.6302', '\\n', '\\n===== epochs_20 =====',\n'\\n', 'Training Dataset', '\\n', 'training loss: 0.4555', '\\n', 'Validation\nDataset', '\\n', 'validation loss: 0.4618', '\\n', 'validation CRWA: 0.7725',\n'\\n', 'validation SWA: 0.7808', '\\n', 'validation CWA: 0.7804', '\\n', 'Test\nDataset', '\\n', 'test loss: 0.6891', '\\n', 'test CRWA: 0.6134', '\\n', 'test SWA:\n0.6124', '\\n', 'test CWA: 0.6443', '\\n', '\\n===== epochs_30 =====', '\\n',\n'Training Dataset', '\\n', 'training loss: 0.4480', '\\n', 'Validation Dataset',\n'\\n', 'validation loss: 0.4552', '\\n', 'validation CRWA: 0.7684', '\\n',\n'validation SWA: 0.7772', '\\n', 'validation CWA: 0.7787', '\\n', 'Test Dataset',\n'\\n', 'test loss: 0.6885', '\\n', 'test CRWA: 0.6172', '\\n', 'test SWA: 0.6168',\n'\\n', 'test CWA: 0.6494', '\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']", "['\\n===== epochs_5 =====', '\\n', 'Training Dataset', '\\n', 'training loss:\n0.4919', '\\n', 'Validation Dataset', '\\n', 'validation loss: 0.4930', '\\n',\n'validation CRWA: 0.7669', '\\n', 'validation SWA: 0.7733', '\\n', 'validation\nCWA: 0.7697', '\\n', 'Test Dataset', '\\n', 'test loss: 0.7067', '\\n', 'test CRWA:\n0.5961', '\\n', 'test SWA: 0.5944', '\\n', 'test CWA: 0.6230', '\\n', '\\n=====\nepochs_10 =====', '\\n', 'Training Dataset', '\\n', 'training loss: 0.4750', '\\n',\n'Validation Dataset', '\\n', 'validation loss: 0.4773', '\\n', 'validation CRWA:\n0.7664', '\\n', 'validation SWA: 0.7743', '\\n', 'validation CWA: 0.7707', '\\n',\n'Test Dataset', '\\n', 'test loss: 0.6873', '\\n', 'test CRWA: 0.6015', '\\n',\n'test SWA: 0.6003', '\\n', 'test CWA: 0.6302', '\\n', '\\n===== epochs_20 =====',\n'\\n', 'Training Dataset', '\\n', 'training loss: 0.4555', '\\n', 'Validation\nDataset', '\\n', 'validation loss: 0.4618', '\\n', 'validation CRWA: 0.7725',\n'\\n', 'validation SWA: 0.7808', '\\n', 'validation CWA: 0.7804', '\\n', 'Test\nDataset', '\\n', 'test loss: 0.6891', '\\n', 'test CRWA: 0.6134', '\\n', 'test SWA:\n0.6124', '\\n', 'test CWA: 0.6443', '\\n', '\\n===== epochs_30 =====', '\\n',\n'Training Dataset', '\\n', 'training loss: 0.4480', '\\n', 'Validation Dataset',\n'\\n', 'validation loss: 0.4552', '\\n', 'validation CRWA: 0.7684', '\\n',\n'validation SWA: 0.7772', '\\n', 'validation CWA: 0.7787', '\\n', 'Test Dataset',\n'\\n', 'test loss: 0.6885', '\\n', 'test CRWA: 0.6172', '\\n', 'test SWA: 0.6168',\n'\\n', 'test CWA: 0.6494', '\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]}