<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 3], [0, 4], [0, 1], [0, 7], [0, 5], [0, 2], [2, 8], [2, 6], [7, 11], [7, 12], [7, 10], [7, 9]], "layout": [[0.38461538461538464, 0.0], [0.0, 0.5], [0.15384615384615385, 0.5], [0.3076923076923077, 0.5], [0.46153846153846156, 0.5], [0.6153846153846154, 0.5], [0.07692307692307693, 1.0], [0.7692307692307693, 0.5], [0.23076923076923078, 1.0], [0.5384615384615384, 1.0], [0.6923076923076923, 1.0], [0.8461538461538461, 1.0], [1.0, 1.0]], "plan": ["We replace the simple average-embedding baseline with a light Neuro-Symbolic\nTransformer.   Token embeddings are processed by a 2-layer Transformer encoder\n(64 dims, 4 heads) to model relational patterns, while three symbolic scalars \u2013\nnumber of distinct shapes, number of distinct colours, and their product \u2013 are\nconcatenated to the pooled Transformer output.   The network is trained with\nAdam and early stopping on dev loss, and we report Shape-Weighted Accuracy (SWA)\nat every epoch; this is the sole metric used for model selection and test\nreporting.   If the real SPR_BENCH folder is unavailable, a tiny synthetic\ndataset is generated so the script always runs.   All tensors and the model are\nmoved to GPU when available, and training/validation losses plus SWA are stored\nin a numpy dictionary that is saved to ./working/experiment_data.npy for later\nanalysis.   The code is self-contained, executes on launch (no guard block),\nrespects the specified directory structure, and finishes in <30 min.   This\nfirst attempt establishes a stronger neural baseline and a clean metrics/logging\npipeline that future symbolic-reasoning modules can plug into.", "Ablation name: No-Symbolic-Features (Pure Transformer Baseline). The ablation\nstudy is implemented by defining a PureTransformerBaseline that discards the\nhandcrafted symbolic feature vector and feeds only the mean-pooled Transformer\nrepresentation to the classifier. Training, validation, and logging stay\nunchanged except that the model no longer consumes the sym input. Results are\nstored under the ablation key 'no_symbolic_features' in experiment_data.npy.", "Ablation name: Symbolic-Only (Transformer Removed). We reuse the existing data\npipeline but replace the NeuroSymbolicTransformer with a tiny feed-forward\nnetwork that consumes only the three symbolic statistics. All token embeddings\nand transformer layers are removed, so the model\u2019s input is a 3-D vector per\nsequence. The training / evaluation loops are adjusted to call the new model\naccordingly, while the rest of the logic (early-stopping, metric logging,\nsaving) stays unchanged.", "Ablation name: No-Interaction\u2010Symbolic (Drop n_shape \u00d7 n_color Feature). The\nablation study simply omits the handcrafted cross-term n_shape \u00d7 n_color from\nthe symbolic vector. We rebuild the dataset so each example carries a 2-dim sym\nfeature [n_shape, n_color] and instantiate the transformer with sym_dim=2. All\nlogging, early stopping and saving follow the same pattern as the baseline, but\nresults are stored under the ablation key \u201cno_interaction_symbolic\u201d in\nexperiment_data.npy.", "Ablation name: Bag-of-Embeddings (Transformer-Encoder Removed). We keep the\ndata-loading, dataclass, collate-function and evaluation utilities unchanged,\nbut replace the deep Transformer with a very shallow Bag-of-Embeddings\nclassifier that simply averages the masked token embeddings and concatenates\nthis vector with the three handcrafted symbolic features before the final linear\nlayer.  Training, early-stopping, evaluation and saving logic mirror the\nbaseline so results can be compared directly.  All metrics, losses and\npredictions are stored under the key \"bag_of_embeddings\" and written to\nworking/experiment_data.npy for later plotting.", "Ablation name: Frozen-Random-Embeddings. The ablation keeps the entire pipeline\nunchanged except that the token\u2013embedding matrix is randomly initialised once\nand then frozen, preventing any gradient updates. All other parameters\n(transformer encoder, pooling, symbolic features and classifier) continue to\nlearn, so any performance change will isolate the value of learnt lexical\nembeddings.", "The earlier script mixed CPU and GPU tensors and lacked the new Novelty-Weighted\nAccuracy (NWA) metric that we must track for zero-shot generalisation.   The fix\nis therefore (1) ensure that every tensor \u2013 inputs, labels and model \u2013 is moved\nto the selected device before use; (2) pre-compute the set of shape-color tokens\nthat occur in the training split and use it to implement NWA; and (3) store /\nreport all metrics in the `experiment_data` dictionary while keeping the rest of\nthe training loop unchanged.   The code below applies these changes, adds light\nnormalisation to the symbolic feature vector, and follows the mandatory saving /\nlogging and directory rules.", "Ablation name: CLS-Token-Pooling (Mean Pooling Removed). We replace the mean-\npooling sentence representation with a learnable [CLS] vector.   A dedicated\nCLS_ID is appended to the vocabulary; at batch creation the id is prepended to\nevery sequence and its position is marked as non-padding in the mask.   After\nthe transformer encoder we take the hidden state at position 0 (the [CLS] token)\nand concatenate it with the symbolic features for classification.   All other\ndata processing, training, evaluation, logging and saving follow the baseline so\nthat performance differences isolate the pooling mechanism.", "The issue stemmed from the synthetic-data fallback: load_dataset(\"json\",\ndata_files=python_list, \u2026) is illegal, silently creating an empty dataset and\nfreezing learning (hence constant SWA).   I replace it with a proper in-memory\nconstruction via datasets.Dataset.from_dict, so the model always gets a valid\ndataset.   While touching the code I also (a) add Novelty-Weighted Accuracy\n(NWA) required by the protocol, (b) normalise symbolic features, and (c) ensure\nevery tensor/model is moved to the correct device.   Everything else (early\nstopping, metric logging, saving) remains unchanged.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, random, time, copy, math, warnings, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# ---- working dir & device ---------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---- reproducibility --------------------------------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# ---- metric: Shape-Weighted Accuracy ---------------------------------------\ndef _count_shape(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---- load / fallback dataset ------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        ds = load_spr_bench(DATA_PATH)\n        print(\"Loaded SPR_BENCH.\")\n    except Exception as e:\n        print(\"Dataset not found, generating synthetic data.\", e)\n        shapes, colors = \"ABCD\", \"abcd\"\n\n        def make(n):\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        ds = DatasetDict({\"train\": make(2000), \"dev\": make(400), \"test\": make(400)})\n    return ds\n\n\nspr = get_dataset()\n\n# ---- vocabulary & label maps ------------------------------------------------\ntokens = {tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split()}\ntok2id = {t: i + 1 for i, t in enumerate(sorted(tokens))}  # 0 reserved for PAD\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\nVOCAB_SIZE = len(tok2id) + 1\nNUM_CLS = len(label2id)\n\n\n# ---- torch dataset ----------------------------------------------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        token_ids = [tok2id[t] for t in seq.split()]\n        n_shape = _count_shape(seq)\n        n_color = len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n        return {\n            \"input_ids\": torch.tensor(token_ids, dtype=torch.long),\n            \"length\": torch.tensor(len(token_ids)),\n            \"sym\": torch.tensor(\n                [n_shape, n_color, n_shape * n_color], dtype=torch.float\n            ),\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": seq,\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    ids = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        ids[i, : b[\"length\"]] = b[\"input_ids\"]\n        mask[i, : b[\"length\"]] = 1\n    return {\n        \"input_ids\": ids,\n        \"mask\": mask,\n        \"sym\": torch.stack([b[\"sym\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---- model ------------------------------------------------------------------\nclass NeuroSymbolicTransformer(nn.Module):\n    def __init__(self, vocab, embed_dim=64, nhead=4, nlayers=2, sym_dim=3, n_cls=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        encoder_layer = nn.TransformerEncoderLayer(\n            embed_dim, nhead, dim_feedforward=128, batch_first=True\n        )\n        self.trans = nn.TransformerEncoder(encoder_layer, nlayers)\n        self.cls = nn.Linear(embed_dim + sym_dim, n_cls)\n\n    def forward(self, ids, mask, sym_feats):\n        x = self.emb(ids)\n        x = self.trans(x, src_key_padding_mask=~mask)\n        pooled = (x * mask.unsqueeze(-1)).sum(1) / mask.sum(1, keepdim=True).clamp(\n            min=1\n        )\n        return self.cls(torch.cat([pooled, sym_feats], -1))\n\n\n# ---- helpers ----------------------------------------------------------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    total_loss, n_items = 0, 0\n    all_true, all_pred, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n            loss = criterion(logits, batch[\"label\"])\n            total_loss += loss.item() * batch[\"label\"].size(0)\n            n_items += batch[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            all_true.extend(batch[\"label\"].cpu().tolist())\n            all_pred.extend(preds)\n            all_seqs.extend(batch[\"raw_seq\"])\n    swa = shape_weighted_accuracy(all_seqs, all_true, all_pred)\n    return total_loss / n_items, swa, all_true, all_pred, all_seqs\n\n\n# ---- training loop ----------------------------------------------------------\nmax_epochs = 20\npatience = 4\nmodel = NeuroSymbolicTransformer(VOCAB_SIZE).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\nbest_val, wait, best_state = math.inf, 0, None\nfor epoch in range(1, max_epochs + 1):\n    model.train()\n    ep_loss, m = 0, 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * batch[\"label\"].size(0)\n        m += batch[\"label\"].size(0)\n    train_loss = ep_loss / m\n    val_loss, val_swa, y_true, y_pred, _ = evaluate(model, dev_loader)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}, SWA = {val_swa:.4f}\")\n    # log\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(None)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(val_swa)\n    experiment_data[\"SPR_BENCH\"][\"predictions\"].append(y_pred)\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"].append(y_true)\n    experiment_data[\"SPR_BENCH\"][\"epochs\"].append(epoch)\n    # early stopping\n    if val_loss < best_val - 1e-4:\n        best_val, wait, best_state = val_loss, 0, copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping triggered.\")\n        break\n\n# ---- test evaluation --------------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, y_tst, y_pst, seqs = evaluate(model, test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}\")\n\n# ---- save results -----------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "import os, pathlib, random, math, copy, warnings, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# ---- dir / device -----------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n# ---- reproducibility --------------------------------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# ---- metric -----------------------------------------------------------------\ndef _count_shape(seq):\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---- dataset ----------------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path):\n    def _load(f):\n        return load_dataset(\n            \"csv\", data_files=str(root / f), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef get_dataset():\n    try:\n        ds = load_spr_bench(pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\"))\n        print(\"Loaded SPR_BENCH\")\n    except Exception as e:\n        print(\"Dataset not found, generating synthetic.\", e)\n        shapes, colors = \"ABCD\", \"abcd\"\n\n        def make(n):\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        ds = DatasetDict({\"train\": make(2000), \"dev\": make(400), \"test\": make(400)})\n    return ds\n\n\nspr = get_dataset()\n\n# ---- vocab & label maps -----------------------------------------------------\ntokens = {tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split()}\ntok2id = {t: i + 1 for i, t in enumerate(sorted(tokens))}  # 0 PAD\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\nVOCAB_SIZE = len(tok2id) + 1\nNUM_CLS = len(label2id)\n\n\n# ---- torch dataset ----------------------------------------------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        token_ids = [tok2id[t] for t in seq.split()]\n        n_shape = _count_shape(seq)\n        n_color = len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n        return {\n            \"input_ids\": torch.tensor(token_ids),\n            \"length\": torch.tensor(len(token_ids)),\n            \"sym\": torch.tensor(\n                [n_shape, n_color, n_shape * n_color], dtype=torch.float\n            ),  # unused\n            \"label\": torch.tensor(self.lbl[idx]),\n            \"raw_seq\": seq,\n        }\n\n\ndef collate(batch):\n    L = max(b[\"length\"] for b in batch).item()\n    ids = torch.zeros(len(batch), L, dtype=torch.long)\n    mask = torch.zeros(len(batch), L, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        ids[i, : b[\"length\"]] = b[\"input_ids\"]\n        mask[i, : b[\"length\"]] = 1\n    return {\n        \"input_ids\": ids,\n        \"mask\": mask,\n        \"sym\": torch.stack([b[\"sym\"] for b in batch]),  # kept for compatibility\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---- model (no symbolic features) -------------------------------------------\nclass PureTransformerBaseline(nn.Module):\n    def __init__(self, vocab, embed_dim=64, nhead=4, nlayers=2, n_cls=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(embed_dim, nhead, 128, batch_first=True)\n        self.trans = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls = nn.Linear(embed_dim, n_cls)\n\n    def forward(self, ids, mask):\n        x = self.emb(ids)\n        x = self.trans(x, src_key_padding_mask=~mask)\n        pooled = (x * mask.unsqueeze(-1)).sum(1) / mask.sum(1, keepdim=True).clamp(\n            min=1\n        )\n        return self.cls(pooled)\n\n\n# ---- helpers ----------------------------------------------------------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    tot_loss = n_items = 0\n    all_t, all_p, all_seq = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"], batch[\"mask\"])\n            loss = criterion(logits, batch[\"label\"])\n            tot_loss += loss.item() * batch[\"label\"].size(0)\n            n_items += batch[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            all_t.extend(batch[\"label\"].cpu().tolist())\n            all_p.extend(preds)\n            all_seq.extend(batch[\"raw_seq\"])\n    return (\n        tot_loss / n_items,\n        shape_weighted_accuracy(all_seq, all_t, all_p),\n        all_t,\n        all_p,\n        all_seq,\n    )\n\n\n# ---- experiment data dict ---------------------------------------------------\nexperiment_data = {\n    \"no_symbolic_features\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---- training ---------------------------------------------------------------\nmax_epochs, patience = 20, 4\nmodel = PureTransformerBaseline(VOCAB_SIZE, n_cls=NUM_CLS).to(device)\noptim = torch.optim.Adam(model.parameters(), lr=1e-3)\nbest_val, best_state, wait = math.inf, None, 0\nfor ep in range(1, max_epochs + 1):\n    model.train()\n    ep_loss = m = 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optim.zero_grad()\n        logits = model(batch[\"input_ids\"], batch[\"mask\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optim.step()\n        ep_loss += loss.item() * batch[\"label\"].size(0)\n        m += batch[\"label\"].size(0)\n    train_loss = ep_loss / m\n    val_loss, val_swa, y_true, y_pred, _ = evaluate(model, dev_loader)\n    print(f\"Epoch {ep}: val_loss={val_loss:.4f}  SWA={val_swa:.4f}\")\n    d = experiment_data[\"no_symbolic_features\"][\"SPR_BENCH\"]\n    d[\"losses\"][\"train\"].append(train_loss)\n    d[\"losses\"][\"val\"].append(val_loss)\n    d[\"metrics\"][\"train\"].append(None)\n    d[\"metrics\"][\"val\"].append(val_swa)\n    d[\"predictions\"].append(y_pred)\n    d[\"ground_truth\"].append(y_true)\n    d[\"epochs\"].append(ep)\n    if val_loss < best_val - 1e-4:\n        best_val, val_wait = val_loss, 0\n        best_state = copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping.\")\n        break\n\n# ---- test -------------------------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, y_tst, y_pst, seqs = evaluate(model, test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}\")\n\n# ---- save -------------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved to working/experiment_data.npy\")\n", "# Symbolic-Only Ablation: transformer removed\nimport os, pathlib, random, math, copy, warnings, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------- working dir & device ---------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------- reproducibility --------------------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# ---------------- metric -----------------------------------------------------\ndef _count_shape(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------------- dataset helpers -------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        print(\"Trying to load SPR_BENCH ...\")\n        return load_spr_bench(DATA_PATH)\n    except Exception as e:\n        print(\"Dataset not found, generating synthetic data.\", e)\n        shapes, colors = \"ABCD\", \"abcd\"\n\n        def make(n):\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        return DatasetDict({\"train\": make(2000), \"dev\": make(400), \"test\": make(400)})\n\n\nspr = get_dataset()\n\n# ---------------- label map --------------------------------------------------\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\n\n\n# ---------------- torch dataset ---------------------------------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        n_shape = _count_shape(seq)\n        n_color = len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n        return {\n            \"sym\": torch.tensor(\n                [n_shape, n_color, n_shape * n_color], dtype=torch.float\n            ),\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": seq,\n        }\n\n\ndef collate(batch):\n    return {\n        \"sym\": torch.stack([b[\"sym\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------------- symbolic-only model ---------------------------------------\nclass SymbolicOnlyClassifier(nn.Module):\n    def __init__(self, sym_dim=3, n_cls=2):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(sym_dim, 16), nn.ReLU(), nn.Linear(16, n_cls)\n        )\n\n    def forward(self, sym_feats):\n        return self.net(sym_feats)\n\n\n# ---------------- helpers ----------------------------------------------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    total_loss = n_items = 0\n    all_true, all_pred, all_seq = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            sym = batch[\"sym\"].to(device)\n            logits = model(sym)\n            loss = criterion(logits, batch[\"label\"].to(device))\n            bs = sym.size(0)\n            total_loss += loss.item() * bs\n            n_items += bs\n            preds = logits.argmax(-1).cpu().tolist()\n            all_true.extend(batch[\"label\"].cpu().tolist())\n            all_pred.extend(preds)\n            all_seq.extend(batch[\"raw_seq\"])\n    swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n    return total_loss / n_items, swa, all_true, all_pred\n\n\n# ---------------- experiment container --------------------------------------\nexperiment_data = {\n    \"symbolic_only\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---------------- training loop ---------------------------------------------\nmax_epochs, patience = 20, 4\nmodel = SymbolicOnlyClassifier(sym_dim=3, n_cls=len(label2id)).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nbest_val, wait, best_state = math.inf, 0, None\n\nfor ep in range(1, max_epochs + 1):\n    model.train()\n    ep_loss = m = 0\n    for batch in train_loader:\n        sym = batch[\"sym\"].to(device)\n        lbl = batch[\"label\"].to(device)\n        optimizer.zero_grad()\n        logits = model(sym)\n        loss = criterion(logits, lbl)\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * lbl.size(0)\n        m += lbl.size(0)\n    train_loss = ep_loss / m\n    val_loss, val_swa, y_true, y_pred = evaluate(model, dev_loader)\n    print(f\"Epoch {ep}: val_loss={val_loss:.4f}, SWA={val_swa:.4f}\")\n    # log\n    exp = experiment_data[\"symbolic_only\"][\"SPR_BENCH\"]\n    exp[\"losses\"][\"train\"].append(train_loss)\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"train\"].append(None)\n    exp[\"metrics\"][\"val\"].append(val_swa)\n    exp[\"predictions\"].append(y_pred)\n    exp[\"ground_truth\"].append(y_true)\n    exp[\"epochs\"].append(ep)\n    # early stopping\n    if val_loss < best_val - 1e-4:\n        best_val, wait, best_state = val_loss, 0, copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping.\")\n        break\n\n# ---------------- test -------------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, y_tst, y_pst = evaluate(model, test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}\")\n\n# ---------------- save -------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "import os, pathlib, random, time, copy, math, warnings, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# --------------------- basic setup -------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# --------------------- metric -------------------------------------------------\ndef _count_shape(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# --------------------- dataset ------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        ds = load_spr_bench(DATA_PATH)\n        print(\"Loaded SPR_BENCH from disk.\")\n    except Exception as e:\n        print(\"Dataset not found, generating synthetic data.\", e)\n        shapes, colors = \"ABCD\", \"abcd\"\n\n        def make(n):\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        ds = DatasetDict({\"train\": make(2000), \"dev\": make(400), \"test\": make(400)})\n    return ds\n\n\nspr = get_dataset()\n\n# --------------------- vocab & label maps ------------------------------------\ntokens = {tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split()}\ntok2id = {t: i + 1 for i, t in enumerate(sorted(tokens))}  # 0 for PAD\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\nVOCAB_SIZE, NUM_CLS = len(tok2id) + 1, len(label2id)\n\n\n# --------------------- torch dataset (NO interaction term) -------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        tokens = seq.split()\n        token_ids = [tok2id[t] for t in tokens]\n        n_shape = _count_shape(seq)\n        n_color = len(set(tok[1] for tok in tokens if len(tok) > 1))\n        return {\n            \"input_ids\": torch.tensor(token_ids, dtype=torch.long),\n            \"length\": torch.tensor(len(token_ids)),\n            \"sym\": torch.tensor([n_shape, n_color], dtype=torch.float),\n            \"label\": torch.tensor(self.lbl[idx]),\n            \"raw_seq\": seq,\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    ids = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        ids[i, : b[\"length\"]] = b[\"input_ids\"]\n        mask[i, : b[\"length\"]] = True\n    return {\n        \"input_ids\": ids,\n        \"mask\": mask,\n        \"sym\": torch.stack([b[\"sym\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# --------------------- model --------------------------------------------------\nclass NeuroSymbolicTransformer(nn.Module):\n    def __init__(self, vocab, embed_dim=64, nhead=4, nlayers=2, sym_dim=2, n_cls=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(\n            embed_dim, nhead, dim_feedforward=128, batch_first=True\n        )\n        self.trans = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls = nn.Linear(embed_dim + sym_dim, n_cls)\n\n    def forward(self, ids, mask, sym_feats):\n        x = self.trans(self.emb(ids), src_key_padding_mask=~mask)\n        pooled = (x * mask.unsqueeze(-1)).sum(1) / mask.sum(1, keepdim=True).clamp(\n            min=1\n        )\n        return self.cls(torch.cat([pooled, sym_feats], -1))\n\n\n# --------------------- helpers ------------------------------------------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    tot_loss = n_items = 0\n    all_t, all_p, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n            loss = criterion(logits, batch[\"label\"])\n            tot_loss += loss.item() * batch[\"label\"].size(0)\n            n_items += batch[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            all_t.extend(batch[\"label\"].cpu().tolist())\n            all_p.extend(preds)\n            all_seqs.extend(batch[\"raw_seq\"])\n    swa = shape_weighted_accuracy(all_seqs, all_t, all_p)\n    return tot_loss / n_items, swa, all_t, all_p, all_seqs\n\n\n# --------------------- experiment logging dict -------------------------------\nexperiment_data = {\n    \"no_interaction_symbolic\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# --------------------- training ----------------------------------------------\nmax_epochs, patience = 20, 4\nmodel = NeuroSymbolicTransformer(VOCAB_SIZE, sym_dim=2, n_cls=NUM_CLS).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_val, wait, best_state = math.inf, 0, None\nfor epoch in range(1, max_epochs + 1):\n    model.train()\n    ep_loss = m = 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * batch[\"label\"].size(0)\n        m += batch[\"label\"].size(0)\n    train_loss = ep_loss / m\n    val_loss, val_swa, y_true, y_pred, _ = evaluate(model, dev_loader)\n    print(f\"Epoch {epoch}: val_loss={val_loss:.4f}, SWA={val_swa:.4f}\")\n\n    log = experiment_data[\"no_interaction_symbolic\"][\"SPR_BENCH\"]\n    log[\"losses\"][\"train\"].append(train_loss)\n    log[\"losses\"][\"val\"].append(val_loss)\n    log[\"metrics\"][\"train\"].append(None)\n    log[\"metrics\"][\"val\"].append(val_swa)\n    log[\"predictions\"].append(y_pred)\n    log[\"ground_truth\"].append(y_true)\n    log[\"epochs\"].append(epoch)\n\n    if val_loss < best_val - 1e-4:\n        best_val, wait, best_state = val_loss, 0, copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping.\")\n        break\n\n# --------------------- test evaluation ---------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, y_tst, y_pst, seqs = evaluate(model, test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}\")\n\n# --------------------- save ---------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, copy, math, warnings, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# -------------------- set-up -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# -------------------- metrics -----------------------------------------------\ndef _count_shape(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# -------------------- dataset ------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        ds = load_spr_bench(DATA_PATH)\n        print(\"Loaded SPR_BENCH.\")\n    except Exception as e:\n        print(\"Dataset not found, generating synthetic data.\", e)\n        shapes, colors = \"ABCD\", \"abcd\"\n\n        def make(n):\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        ds = DatasetDict({\"train\": make(2000), \"dev\": make(400), \"test\": make(400)})\n    return ds\n\n\nspr = get_dataset()\n\n# -------------------- vocab & labels ----------------------------------------\ntokens = {tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split()}\ntok2id = {tok: i + 1 for i, tok in enumerate(sorted(tokens))}  # 0 = PAD\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\nVOCAB_SIZE, NUM_CLS = len(tok2id) + 1, len(label2id)\n\n\n# -------------------- torch dataset -----------------------------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        toks = seq.split()\n        ids = [tok2id[t] for t in toks]\n        n_shape = _count_shape(seq)\n        n_color = len(set(t[1] for t in toks if len(t) > 1))\n        return {\n            \"input_ids\": torch.tensor(ids),\n            \"length\": torch.tensor(len(ids)),\n            \"sym\": torch.tensor(\n                [n_shape, n_color, n_shape * n_color], dtype=torch.float\n            ),\n            \"label\": torch.tensor(self.lbl[idx]),\n            \"raw_seq\": seq,\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch).item()\n    ids = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        ids[i, : b[\"length\"]] = b[\"input_ids\"]\n        mask[i, : b[\"length\"]] = 1\n    return {\n        \"input_ids\": ids,\n        \"mask\": mask,\n        \"sym\": torch.stack([b[\"sym\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# -------------------- model: Bag-of-Embeddings ------------------------------\nclass BagOfEmbeddings(nn.Module):\n    def __init__(self, vocab, embed_dim=64, sym_dim=3, n_cls=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.cls = nn.Linear(embed_dim + sym_dim, n_cls)\n\n    def forward(self, ids, mask, sym_feats):\n        x = self.emb(ids)  # B,L,E\n        pooled = (x * mask.unsqueeze(-1)).sum(1) / mask.sum(1, keepdim=True).clamp(\n            min=1\n        )\n        return self.cls(torch.cat([pooled, sym_feats], -1))\n\n\n# -------------------- helpers -----------------------------------------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    tot_loss, n = 0, 0\n    y_true, y_pred, seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n            loss = criterion(logits, batch[\"label\"])\n            tot_loss += loss.item() * batch[\"label\"].size(0)\n            n += batch[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            y_true.extend(batch[\"label\"].cpu().tolist())\n            y_pred.extend(preds)\n            seqs.extend(batch[\"raw_seq\"])\n    swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n    return tot_loss / n, swa, y_true, y_pred\n\n\n# -------------------- training ----------------------------------------------\nmax_epochs, patience = 20, 4\nmodel = BagOfEmbeddings(VOCAB_SIZE).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nexperiment_data = {\n    \"bag_of_embeddings\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\nbest_val, wait, best_state = math.inf, 0, None\nfor ep in range(1, max_epochs + 1):\n    model.train()\n    ep_loss, m = 0, 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * batch[\"label\"].size(0)\n        m += batch[\"label\"].size(0)\n    train_loss = ep_loss / m\n    val_loss, val_swa, y_true, y_pred = evaluate(model, dev_loader)\n    print(f\"Epoch {ep}: val_loss={val_loss:.4f}, SWA={val_swa:.4f}\")\n    # log\n    exp = experiment_data[\"bag_of_embeddings\"][\"SPR_BENCH\"]\n    exp[\"losses\"][\"train\"].append(train_loss)\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"train\"].append(None)\n    exp[\"metrics\"][\"val\"].append(val_swa)\n    exp[\"predictions\"].append(y_pred)\n    exp[\"ground_truth\"].append(y_true)\n    exp[\"epochs\"].append(ep)\n    # early stopping\n    if val_loss < best_val - 1e-4:\n        best_val, wait, best_state = val_loss, 0, copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping.\")\n        break\n\n# -------------------- test ---------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, y_tst, y_pst = evaluate(model, test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}\")\n\n# -------------------- save ---------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "# Frozen-Random-Embeddings Ablation -------------------------------------------------\nimport os, pathlib, random, copy, math, warnings, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- misc ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# ---------- metrics ---------------------------------------------------------------\ndef _count_shape(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------- data ------------------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef get_dataset():\n    try:\n        ds = load_spr_bench(pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\"))\n        print(\"Loaded SPR_BENCH.\")\n    except Exception as e:\n        print(\"Dataset not found, synthesising.\", e)\n        shapes, colors = \"ABCD\", \"abcd\"\n\n        def make(n):\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        ds = DatasetDict({\"train\": make(2000), \"dev\": make(400), \"test\": make(400)})\n    return ds\n\n\nspr = get_dataset()\n\n# ---------- vocab / label ---------------------------------------------------------\ntokens = {tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split()}\ntok2id = {t: i + 1 for i, t in enumerate(sorted(tokens))}  # 0 = PAD\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\nVOCAB_SIZE, NUM_CLS = len(tok2id) + 1, len(label2id)\n\n\n# ---------- torch dataset ---------------------------------------------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        toks = seq.split()\n        ids = [tok2id[t] for t in toks]\n        n_shape = _count_shape(seq)\n        n_color = len(set(t[1] for t in toks if len(t) > 1))\n        return {\n            \"input_ids\": torch.tensor(ids),\n            \"length\": len(ids),\n            \"sym\": torch.tensor(\n                [n_shape, n_color, n_shape * n_color], dtype=torch.float\n            ),\n            \"label\": self.lbl[idx],\n            \"raw_seq\": seq,\n        }\n\n\ndef collate(batch):\n    max_len = max(b[\"length\"] for b in batch)\n    ids = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        ids[i, : b[\"length\"]] = b[\"input_ids\"]\n        mask[i, : b[\"length\"]] = 1\n    return {\n        \"input_ids\": ids,\n        \"mask\": mask,\n        \"sym\": torch.stack([b[\"sym\"] for b in batch]),\n        \"label\": torch.tensor([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model (embedding frozen) -----------------------------------------------\nclass NeuroSymbolicTransformer(nn.Module):\n    def __init__(self, vocab, embed_dim=64, nhead=4, nlayers=2, sym_dim=3, n_cls=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.emb.weight.requires_grad = False  # <- freeze embeddings\n        enc_layer = nn.TransformerEncoderLayer(embed_dim, nhead, 128, batch_first=True)\n        self.trans = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls = nn.Linear(embed_dim + sym_dim, n_cls)\n\n    def forward(self, ids, mask, sym):\n        x = self.emb(ids)\n        x = self.trans(x, src_key_padding_mask=~mask)\n        pooled = (x * mask.unsqueeze(-1)).sum(1) / mask.sum(1, keepdim=True).clamp(\n            min=1\n        )\n        return self.cls(torch.cat([pooled, sym], -1))\n\n\n# ---------- helpers ---------------------------------------------------------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    tot_loss = 0\n    n = 0\n    y_true = []\n    y_pred = []\n    seqs = []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            out = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n            loss = criterion(out, batch[\"label\"])\n            tot_loss += loss.item() * batch[\"label\"].size(0)\n            n += batch[\"label\"].size(0)\n            preds = out.argmax(-1).cpu().tolist()\n            y_true.extend(batch[\"label\"].cpu().tolist())\n            y_pred.extend(preds)\n            seqs.extend(batch[\"raw_seq\"])\n    swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n    return tot_loss / n, swa, y_true, y_pred, seqs\n\n\n# ---------- training ---------------------------------------------------------------\nexperiment_data = {\n    \"Frozen-Random-Embeddings\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\nmodel = NeuroSymbolicTransformer(VOCAB_SIZE, n_cls=NUM_CLS).to(device)\noptimizer = torch.optim.Adam(\n    filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3\n)\n\nmax_epochs = 20\npatience = 4\nbest_val = math.inf\nwait = 0\nbest_state = None\nfor epoch in range(1, max_epochs + 1):\n    model.train()\n    ep_loss = 0\n    m = 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * batch[\"label\"].size(0)\n        m += batch[\"label\"].size(0)\n    train_loss = ep_loss / m\n    val_loss, val_swa, y_true, y_pred, _ = evaluate(model, dev_loader)\n    print(f\"Epoch {epoch}: val_loss={val_loss:.4f}  SWA={val_swa:.4f}\")\n    d = experiment_data[\"Frozen-Random-Embeddings\"][\"SPR_BENCH\"]\n    d[\"losses\"][\"train\"].append(train_loss)\n    d[\"losses\"][\"val\"].append(val_loss)\n    d[\"metrics\"][\"train\"].append(None)\n    d[\"metrics\"][\"val\"].append(val_swa)\n    d[\"predictions\"].append(y_pred)\n    d[\"ground_truth\"].append(y_true)\n    d[\"epochs\"].append(epoch)\n    if val_loss < best_val - 1e-4:\n        best_val = val_loss\n        wait = 0\n        best_state = copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping.\")\n        break\n\n# ---------- test ------------------------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, y_tst, y_pst, seqs = evaluate(model, test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}\")\n\n# ---------- save ------------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "import os, pathlib, random, math, copy, warnings, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# ----------------------- mandatory working dir ------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------------- device handling ------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ----------------------- reproducibility ------------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# ----------------------- metrics --------------------------------------------\ndef _count_shape(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef _count_color(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    corr = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(sum(w), 1)\n\n\ndef build_train_token_set(train_seqs):\n    tokens = set()\n    for s in train_seqs:\n        tokens.update(s.split())\n    return tokens\n\n\ndef novelty_weighted_accuracy(seqs, y_true, y_pred, train_token_set):\n    weights, correct = [], []\n    for s, t, p in zip(seqs, y_true, y_pred):\n        toks = set(s.split())\n        novelty = len([tok for tok in toks if tok not in train_token_set])\n        novelty = max(novelty, 1)  # avoid zero weight\n        weights.append(novelty)\n        correct.append(novelty if t == p else 0)\n    return sum(correct) / max(sum(weights), 1)\n\n\n# ----------------------- dataset helpers ------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        print(\"Trying to load SPR_BENCH ...\")\n        return load_spr_bench(DATA_PATH)\n    except Exception as e:\n        print(\"Dataset not found, generating synthetic data.\", e)\n        shapes, colors = \"ABCD\", \"abcd\"\n\n        def make(n):\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        return DatasetDict(\n            {\"train\": make(20000), \"dev\": make(5000), \"test\": make(10000)}\n        )\n\n\nspr = get_dataset()\n\n# ----------------------- label maps -----------------------------------------\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\n\n\n# ----------------------- torch dataset --------------------------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        n_shape = _count_shape(seq)\n        n_color = _count_color(seq)\n        length = len(seq.split())\n        # simple normalisation\n        feats = torch.tensor(\n            [n_shape / length, n_color / length, (n_shape * n_color) / (length**2)],\n            dtype=torch.float,\n        )\n        return {\n            \"sym\": feats,\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": seq,\n        }\n\n\ndef collate(batch):\n    return {\n        \"sym\": torch.stack([b[\"sym\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ----------------------- model ----------------------------------------------\nclass SymbolicOnlyClassifier(nn.Module):\n    def __init__(self, sym_dim=3, n_cls=2):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(sym_dim, 16), nn.ReLU(), nn.Linear(16, n_cls)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nmodel = SymbolicOnlyClassifier(sym_dim=3, n_cls=len(label2id)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ----------------------- experiment storage ---------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# ----------------------- helpers --------------------------------------------\ntrain_token_set = build_train_token_set(spr[\"train\"][\"sequence\"])\n\n\ndef evaluate(loader):\n    model.eval()\n    tot_loss = n_items = 0\n    y_true = []\n    y_pred = []\n    raw_seqs = []\n    with torch.no_grad():\n        for batch in loader:\n            # move to device\n            batch_t = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch_t[\"sym\"])\n            loss = criterion(logits, batch_t[\"label\"])\n            bs = batch_t[\"label\"].size(0)\n            tot_loss += loss.item() * bs\n            n_items += bs\n            preds = logits.argmax(-1).cpu().tolist()\n            y_true.extend(batch_t[\"label\"].cpu().tolist())\n            y_pred.extend(preds)\n            raw_seqs.extend(batch_t[\"raw_seq\"])\n    swa = shape_weighted_accuracy(raw_seqs, y_true, y_pred)\n    nwa = novelty_weighted_accuracy(raw_seqs, y_true, y_pred, train_token_set)\n    return tot_loss / n_items, swa, nwa, y_true, y_pred\n\n\n# ----------------------- training loop --------------------------------------\nmax_epochs, patience = 20, 4\nbest_val, wait, best_state = math.inf, 0, None\n\nfor epoch in range(1, max_epochs + 1):\n    model.train()\n    ep_loss = n_items = 0\n    for batch in train_loader:\n        # move tensors\n        batch_t = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"sym\"])\n        loss = criterion(logits, batch_t[\"label\"])\n        loss.backward()\n        optimizer.step()\n        bs = batch_t[\"label\"].size(0)\n        ep_loss += loss.item() * bs\n        n_items += bs\n    train_loss = ep_loss / n_items\n\n    val_loss, val_swa, val_nwa, y_true, y_pred = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch}: validation_loss = {val_loss:.4f}, SWA={val_swa:.4f}, NWA={val_nwa:.4f}\"\n    )\n\n    exp = experiment_data[\"SPR_BENCH\"]\n    exp[\"losses\"][\"train\"].append(train_loss)\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"train\"].append(None)\n    exp[\"metrics\"][\"val\"].append({\"SWA\": val_swa, \"NWA\": val_nwa})\n    exp[\"predictions\"].append(y_pred)\n    exp[\"ground_truth\"].append(y_true)\n    exp[\"epochs\"].append(epoch)\n\n    # early stopping\n    if val_loss < best_val - 1e-4:\n        best_val, wait, best_state = val_loss, 0, copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping.\")\n        break\n\n# ----------------------- test ------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_nwa, y_tst, y_pst = evaluate(test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}, NWA={test_nwa:.4f}\")\n\n# ----------------------- save ------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "# CLS-Token-Pooling ablation study : single-file runnable script\nimport os, pathlib, random, time, copy, math, warnings, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working dir & device -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- reproducibility ------------------------------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# ---------- metric: Shape-Weighted Accuracy --------------------------------------\ndef _count_shape(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------- load / fallback dataset ---------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        ds = load_spr_bench(DATA_PATH)\n        print(\"Loaded SPR_BENCH.\")\n    except Exception as e:\n        print(\"Dataset not found, generating synthetic data.\", e)\n        shapes, colors = \"ABCD\", \"abcd\"\n\n        def make(n):\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        ds = DatasetDict({\"train\": make(2000), \"dev\": make(400), \"test\": make(400)})\n    return ds\n\n\nspr = get_dataset()\n\n# ---------- vocabulary & label maps ---------------------------------------------\ntokens = {tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split()}\ntok2id = {t: i + 1 for i, t in enumerate(sorted(tokens))}  # 0 reserved for PAD\nCLS_ID = len(tok2id) + 1\nVOCAB_SIZE = CLS_ID + 1  # +1 because ids start at 0\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\nNUM_CLS = len(label2id)\n\n\n# ---------- torch dataset --------------------------------------------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        token_ids = [tok2id[t] for t in seq.split()]\n        n_shape = _count_shape(seq)\n        n_color = len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n        return {\n            \"input_ids\": torch.tensor(token_ids, dtype=torch.long),\n            \"sym\": torch.tensor(\n                [n_shape, n_color, n_shape * n_color], dtype=torch.float\n            ),\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": seq,\n        }\n\n\ndef collate(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch) + 1  # +1 for CLS\n    ids = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        ids[i, 0] = CLS_ID\n        seq_len = len(b[\"input_ids\"])\n        ids[i, 1 : seq_len + 1] = b[\"input_ids\"]\n        mask[i, : seq_len + 1] = 1\n    return {\n        \"input_ids\": ids,\n        \"mask\": mask,\n        \"sym\": torch.stack([b[\"sym\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(SPRTorch(spr[\"train\"]), batch_size, True, collate_fn=collate)\ndev_loader = DataLoader(SPRTorch(spr[\"dev\"]), batch_size, False, collate_fn=collate)\ntest_loader = DataLoader(SPRTorch(spr[\"test\"]), batch_size, False, collate_fn=collate)\n\n\n# ---------- model ----------------------------------------------------------------\nclass NeuroSymbolicTransformerCLS(nn.Module):\n    def __init__(self, vocab, embed_dim=64, nhead=4, nlayers=2, sym_dim=3, n_cls=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(embed_dim, nhead, 128, batch_first=True)\n        self.trans = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls_head = nn.Linear(embed_dim + sym_dim, n_cls)\n\n    def forward(self, ids, mask, sym_feats):\n        x = self.emb(ids)\n        x = self.trans(x, src_key_padding_mask=~mask)\n        cls_vec = x[:, 0, :]  # CLS token representation\n        return self.cls_head(torch.cat([cls_vec, sym_feats], -1))\n\n\n# ---------- helpers ---------------------------------------------------------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    total_loss = 0\n    n_items = 0\n    all_true, all_pred, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n            loss = criterion(logits, batch[\"label\"])\n            total_loss += loss.item() * batch[\"label\"].size(0)\n            n_items += batch[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            all_true.extend(batch[\"label\"].cpu().tolist())\n            all_pred.extend(preds)\n            all_seqs.extend(batch[\"raw_seq\"])\n    swa = shape_weighted_accuracy(all_seqs, all_true, all_pred)\n    return total_loss / n_items, swa, all_true, all_pred, all_seqs\n\n\n# ---------- experiment logging dict -----------------------------------------------\nexperiment_data = {\n    \"CLS-Token-Pooling\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---------- training loop ---------------------------------------------------------\nmax_epochs, patience = 20, 4\nmodel = NeuroSymbolicTransformerCLS(VOCAB_SIZE, n_cls=NUM_CLS).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nbest_val, wait, best_state = math.inf, 0, None\n\nfor epoch in range(1, max_epochs + 1):\n    model.train()\n    ep_loss = 0\n    m = 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * batch[\"label\"].size(0)\n        m += batch[\"label\"].size(0)\n    train_loss = ep_loss / m\n    val_loss, val_swa, y_true, y_pred, _ = evaluate(model, dev_loader)\n    print(f\"Epoch {epoch}: val_loss={val_loss:.4f}, SWA={val_swa:.4f}\")\n    # log\n    ed = experiment_data[\"CLS-Token-Pooling\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"].append(None)\n    ed[\"metrics\"][\"val\"].append(val_swa)\n    ed[\"predictions\"].append(y_pred)\n    ed[\"ground_truth\"].append(y_true)\n    ed[\"epochs\"].append(epoch)\n    # early stopping\n    if val_loss < best_val - 1e-4:\n        best_val, wait, best_state = val_loss, 0, copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping.\")\n        break\n\n# ---------- test evaluation -------------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, y_tst, y_pst, seqs = evaluate(model, test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}\")\n\n# ---------- save results ----------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "import os, random, math, copy, time, warnings, pathlib\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, Dataset, DatasetDict\n\n# --------------------------- working dir -------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --------------------------- device -----------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# --------------------------- reproducibility --------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# --------------------------- metrics ----------------------------------------\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef build_novelty_weights(train_seqs):\n    seen = set(tok for seq in train_seqs for tok in seq.split())\n\n    def _novelty(seq):\n        return len([tok for tok in seq.split() if tok not in seen])\n\n    return _novelty\n\n\ndef novelty_weighted_accuracy(seqs, y_true, y_pred, novelty_fn):\n    w = [novelty_fn(s) for s in seqs]\n    total = sum(w)\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        total, 1\n    )\n\n\n# --------------------------- dataset helpers --------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef generate_synthetic_dset():\n    shapes, colors = list(\"ABCD\"), list(\"abcd\")\n\n    def _make(n):\n        seqs, lbls = [], []\n        for _ in range(n):\n            tok_cnt = random.randint(3, 10)\n            seqs.append(\n                \" \".join(\n                    random.choice(shapes) + random.choice(colors)\n                    for _ in range(tok_cnt)\n                )\n            )\n            lbls.append(random.choice([\"yes\", \"no\"]))\n        return Dataset.from_dict(\n            {\"id\": list(range(n)), \"sequence\": seqs, \"label\": lbls}\n        )\n\n    return DatasetDict({\"train\": _make(2000), \"dev\": _make(400), \"test\": _make(400)})\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        if DATA_PATH.exists():\n            print(\"Loading SPR_BENCH from disk \u2026\")\n            return load_spr_bench(DATA_PATH)\n        raise FileNotFoundError\n    except Exception as e:\n        print(\"Falling back to synthetic data \u2192\", e)\n        return generate_synthetic_dset()\n\n\nspr = get_dataset()\n\n# --------------------------- label maps -------------------------------------\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\n\n\n# --------------------------- torch dataset ----------------------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbls = [label2id[lbl] for lbl in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        n_shape = count_shape_variety(seq)\n        n_color = count_color_variety(seq)\n        feats = (\n            torch.tensor([n_shape, n_color, n_shape * n_color], dtype=torch.float32)\n            / 10.0\n        )\n        return {\"sym\": feats, \"label\": torch.tensor(self.lbls[idx]), \"raw_seq\": seq}\n\n\ndef collate_fn(batch):\n    sym = torch.stack([b[\"sym\"] for b in batch])\n    lbl = torch.stack([b[\"label\"] for b in batch])\n    seqs = [b[\"raw_seq\"] for b in batch]\n    return {\"sym\": sym, \"label\": lbl, \"raw_seq\": seqs}\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorch(spr[\"train\"]), batch_size, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorch(spr[\"dev\"]), batch_size, shuffle=False, collate_fn=collate_fn\n)\ntest_loader = DataLoader(\n    SPRTorch(spr[\"test\"]), batch_size, shuffle=False, collate_fn=collate_fn\n)\n\n\n# --------------------------- model ------------------------------------------\nclass SymbolicOnlyClassifier(nn.Module):\n    def __init__(self, in_dim=3, n_cls=2):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(in_dim, 16), nn.ReLU(), nn.Linear(16, n_cls))\n\n    def forward(self, x):\n        return self.net(x)\n\n\nmodel = SymbolicOnlyClassifier(n_cls=len(label2id)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# --------------------------- evaluation util --------------------------------\nnovelty_fn = build_novelty_weights(spr[\"train\"][\"sequence\"])\n\n\ndef evaluate(loader):\n    model.eval()\n    tot_loss = n_items = 0\n    all_true, all_pred, all_seq = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"sym\"])\n            loss = criterion(logits, batch[\"label\"])\n            bs = batch[\"sym\"].size(0)\n            tot_loss += loss.item() * bs\n            n_items += bs\n            preds = logits.argmax(-1).cpu().tolist()\n            all_true.extend(batch[\"label\"].cpu().tolist())\n            all_pred.extend(preds)\n            all_seq.extend(batch[\"raw_seq\"])\n    swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n    nwa = novelty_weighted_accuracy(all_seq, all_true, all_pred, novelty_fn)\n    return tot_loss / n_items, swa, nwa, all_true, all_pred\n\n\n# --------------------------- experiment store -------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"SWA_train\": [], \"SWA_val\": [], \"NWA_val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# --------------------------- training loop ----------------------------------\nmax_epochs, patience = 20, 4\nbest_val, wait, best_state = math.inf, 0, None\n\nfor epoch in range(1, max_epochs + 1):\n    model.train()\n    ep_loss = n_items = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"sym\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        bs = batch[\"sym\"].size(0)\n        ep_loss += loss.item() * bs\n        n_items += bs\n    train_loss = ep_loss / n_items\n    val_loss, val_swa, val_nwa, y_true, y_pred = evaluate(dev_loader)\n\n    print(\n        f\"Epoch {epoch}: validation_loss = {val_loss:.4f}, SWA = {val_swa:.4f}, NWA = {val_nwa:.4f}\"\n    )\n\n    # log\n    exp = experiment_data[\"SPR_BENCH\"]\n    exp[\"losses\"][\"train\"].append(train_loss)\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"SWA_val\"].append(val_swa)\n    exp[\"metrics\"][\"NWA_val\"].append(val_nwa)\n    exp[\"epochs\"].append(epoch)\n\n    # early stopping\n    if val_loss < best_val - 1e-4:\n        best_val, wait, best_state = val_loss, 0, copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping triggered.\")\n        break\n\n# --------------------------- testing ----------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, test_nwa, y_test, y_pred_test = evaluate(test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}, NWA={test_nwa:.4f}\")\n\n# save\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = y_pred_test\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = y_test\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n# CLS-Token-Pooling ablation study : single-file runnable script\nimport os, pathlib, random, time, copy, math, warnings, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working dir & device -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- reproducibility ------------------------------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# ---------- metric: Shape-Weighted Accuracy --------------------------------------\ndef _count_shape(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------- load / fallback dataset ---------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        ds = load_spr_bench(DATA_PATH)\n        print(\"Loaded SPR_BENCH.\")\n    except Exception as e:\n        print(\"Dataset not found, generating synthetic data.\", e)\n        shapes, colors = \"ABCD\", \"abcd\"\n\n        def make(n):\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        ds = DatasetDict({\"train\": make(2000), \"dev\": make(400), \"test\": make(400)})\n    return ds\n\n\nspr = get_dataset()\n\n# ---------- vocabulary & label maps ---------------------------------------------\ntokens = {tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split()}\ntok2id = {t: i + 1 for i, t in enumerate(sorted(tokens))}  # 0 reserved for PAD\nCLS_ID = len(tok2id) + 1\nVOCAB_SIZE = CLS_ID + 1  # +1 because ids start at 0\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\nNUM_CLS = len(label2id)\n\n\n# ---------- torch dataset --------------------------------------------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        token_ids = [tok2id[t] for t in seq.split()]\n        n_shape = _count_shape(seq)\n        n_color = len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n        return {\n            \"input_ids\": torch.tensor(token_ids, dtype=torch.long),\n            \"sym\": torch.tensor(\n                [n_shape, n_color, n_shape * n_color], dtype=torch.float\n            ),\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": seq,\n        }\n\n\ndef collate(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch) + 1  # +1 for CLS\n    ids = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        ids[i, 0] = CLS_ID\n        seq_len = len(b[\"input_ids\"])\n        ids[i, 1 : seq_len + 1] = b[\"input_ids\"]\n        mask[i, : seq_len + 1] = 1\n    return {\n        \"input_ids\": ids,\n        \"mask\": mask,\n        \"sym\": torch.stack([b[\"sym\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(SPRTorch(spr[\"train\"]), batch_size, True, collate_fn=collate)\ndev_loader = DataLoader(SPRTorch(spr[\"dev\"]), batch_size, False, collate_fn=collate)\ntest_loader = DataLoader(SPRTorch(spr[\"test\"]), batch_size, False, collate_fn=collate)\n\n\n# ---------- model ----------------------------------------------------------------\nclass NeuroSymbolicTransformerCLS(nn.Module):\n    def __init__(self, vocab, embed_dim=64, nhead=4, nlayers=2, sym_dim=3, n_cls=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(embed_dim, nhead, 128, batch_first=True)\n        self.trans = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls_head = nn.Linear(embed_dim + sym_dim, n_cls)\n\n    def forward(self, ids, mask, sym_feats):\n        x = self.emb(ids)\n        x = self.trans(x, src_key_padding_mask=~mask)\n        cls_vec = x[:, 0, :]  # CLS token representation\n        return self.cls_head(torch.cat([cls_vec, sym_feats], -1))\n\n\n# ---------- helpers ---------------------------------------------------------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    total_loss = 0\n    n_items = 0\n    all_true, all_pred, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n            loss = criterion(logits, batch[\"label\"])\n            total_loss += loss.item() * batch[\"label\"].size(0)\n            n_items += batch[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            all_true.extend(batch[\"label\"].cpu().tolist())\n            all_pred.extend(preds)\n            all_seqs.extend(batch[\"raw_seq\"])\n    swa = shape_weighted_accuracy(all_seqs, all_true, all_pred)\n    return total_loss / n_items, swa, all_true, all_pred, all_seqs\n\n\n# ---------- experiment logging dict -----------------------------------------------\nexperiment_data = {\n    \"CLS-Token-Pooling\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---------- training loop ---------------------------------------------------------\nmax_epochs, patience = 20, 4\nmodel = NeuroSymbolicTransformerCLS(VOCAB_SIZE, n_cls=NUM_CLS).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nbest_val, wait, best_state = math.inf, 0, None\n\nfor epoch in range(1, max_epochs + 1):\n    model.train()\n    ep_loss = 0\n    m = 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * batch[\"label\"].size(0)\n        m += batch[\"label\"].size(0)\n    train_loss = ep_loss / m\n    val_loss, val_swa, y_true, y_pred, _ = evaluate(model, dev_loader)\n    print(f\"Epoch {epoch}: val_loss={val_loss:.4f}, SWA={val_swa:.4f}\")\n    # log\n    ed = experiment_data[\"CLS-Token-Pooling\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"].append(None)\n    ed[\"metrics\"][\"val\"].append(val_swa)\n    ed[\"predictions\"].append(y_pred)\n    ed[\"ground_truth\"].append(y_true)\n    ed[\"epochs\"].append(epoch)\n    # early stopping\n    if val_loss < best_val - 1e-4:\n        best_val, wait, best_state = val_loss, 0, copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping.\")\n        break\n\n# ---------- test evaluation -------------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, y_tst, y_pst, seqs = evaluate(model, test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}\")\n\n# ---------- save results ----------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n# CLS-Token-Pooling ablation study : single-file runnable script\nimport os, pathlib, random, time, copy, math, warnings, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working dir & device -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- reproducibility ------------------------------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# ---------- metric: Shape-Weighted Accuracy --------------------------------------\ndef _count_shape(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------- load / fallback dataset ---------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        ds = load_spr_bench(DATA_PATH)\n        print(\"Loaded SPR_BENCH.\")\n    except Exception as e:\n        print(\"Dataset not found, generating synthetic data.\", e)\n        shapes, colors = \"ABCD\", \"abcd\"\n\n        def make(n):\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        ds = DatasetDict({\"train\": make(2000), \"dev\": make(400), \"test\": make(400)})\n    return ds\n\n\nspr = get_dataset()\n\n# ---------- vocabulary & label maps ---------------------------------------------\ntokens = {tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split()}\ntok2id = {t: i + 1 for i, t in enumerate(sorted(tokens))}  # 0 reserved for PAD\nCLS_ID = len(tok2id) + 1\nVOCAB_SIZE = CLS_ID + 1  # +1 because ids start at 0\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\nNUM_CLS = len(label2id)\n\n\n# ---------- torch dataset --------------------------------------------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        token_ids = [tok2id[t] for t in seq.split()]\n        n_shape = _count_shape(seq)\n        n_color = len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n        return {\n            \"input_ids\": torch.tensor(token_ids, dtype=torch.long),\n            \"sym\": torch.tensor(\n                [n_shape, n_color, n_shape * n_color], dtype=torch.float\n            ),\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": seq,\n        }\n\n\ndef collate(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch) + 1  # +1 for CLS\n    ids = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        ids[i, 0] = CLS_ID\n        seq_len = len(b[\"input_ids\"])\n        ids[i, 1 : seq_len + 1] = b[\"input_ids\"]\n        mask[i, : seq_len + 1] = 1\n    return {\n        \"input_ids\": ids,\n        \"mask\": mask,\n        \"sym\": torch.stack([b[\"sym\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(SPRTorch(spr[\"train\"]), batch_size, True, collate_fn=collate)\ndev_loader = DataLoader(SPRTorch(spr[\"dev\"]), batch_size, False, collate_fn=collate)\ntest_loader = DataLoader(SPRTorch(spr[\"test\"]), batch_size, False, collate_fn=collate)\n\n\n# ---------- model ----------------------------------------------------------------\nclass NeuroSymbolicTransformerCLS(nn.Module):\n    def __init__(self, vocab, embed_dim=64, nhead=4, nlayers=2, sym_dim=3, n_cls=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(embed_dim, nhead, 128, batch_first=True)\n        self.trans = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls_head = nn.Linear(embed_dim + sym_dim, n_cls)\n\n    def forward(self, ids, mask, sym_feats):\n        x = self.emb(ids)\n        x = self.trans(x, src_key_padding_mask=~mask)\n        cls_vec = x[:, 0, :]  # CLS token representation\n        return self.cls_head(torch.cat([cls_vec, sym_feats], -1))\n\n\n# ---------- helpers ---------------------------------------------------------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    total_loss = 0\n    n_items = 0\n    all_true, all_pred, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n            loss = criterion(logits, batch[\"label\"])\n            total_loss += loss.item() * batch[\"label\"].size(0)\n            n_items += batch[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            all_true.extend(batch[\"label\"].cpu().tolist())\n            all_pred.extend(preds)\n            all_seqs.extend(batch[\"raw_seq\"])\n    swa = shape_weighted_accuracy(all_seqs, all_true, all_pred)\n    return total_loss / n_items, swa, all_true, all_pred, all_seqs\n\n\n# ---------- experiment logging dict -----------------------------------------------\nexperiment_data = {\n    \"CLS-Token-Pooling\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---------- training loop ---------------------------------------------------------\nmax_epochs, patience = 20, 4\nmodel = NeuroSymbolicTransformerCLS(VOCAB_SIZE, n_cls=NUM_CLS).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nbest_val, wait, best_state = math.inf, 0, None\n\nfor epoch in range(1, max_epochs + 1):\n    model.train()\n    ep_loss = 0\n    m = 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * batch[\"label\"].size(0)\n        m += batch[\"label\"].size(0)\n    train_loss = ep_loss / m\n    val_loss, val_swa, y_true, y_pred, _ = evaluate(model, dev_loader)\n    print(f\"Epoch {epoch}: val_loss={val_loss:.4f}, SWA={val_swa:.4f}\")\n    # log\n    ed = experiment_data[\"CLS-Token-Pooling\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"].append(None)\n    ed[\"metrics\"][\"val\"].append(val_swa)\n    ed[\"predictions\"].append(y_pred)\n    ed[\"ground_truth\"].append(y_true)\n    ed[\"epochs\"].append(epoch)\n    # early stopping\n    if val_loss < best_val - 1e-4:\n        best_val, wait, best_state = val_loss, 0, copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping.\")\n        break\n\n# ---------- test evaluation -------------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, y_tst, y_pst, seqs = evaluate(model, test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}\")\n\n# ---------- save results ----------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n# CLS-Token-Pooling ablation study : single-file runnable script\nimport os, pathlib, random, time, copy, math, warnings, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working dir & device -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- reproducibility ------------------------------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nwarnings.filterwarnings(\"ignore\")\n\n\n# ---------- metric: Shape-Weighted Accuracy --------------------------------------\ndef _count_shape(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------- load / fallback dataset ---------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef get_dataset():\n    try:\n        DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        ds = load_spr_bench(DATA_PATH)\n        print(\"Loaded SPR_BENCH.\")\n    except Exception as e:\n        print(\"Dataset not found, generating synthetic data.\", e)\n        shapes, colors = \"ABCD\", \"abcd\"\n\n        def make(n):\n            data = [\n                {\n                    \"id\": i,\n                    \"sequence\": \" \".join(\n                        random.choice(shapes) + random.choice(colors)\n                        for _ in range(random.randint(3, 10))\n                    ),\n                    \"label\": random.choice([\"yes\", \"no\"]),\n                }\n                for i in range(n)\n            ]\n            return load_dataset(\"json\", data_files={\"train\": data}, split=\"train\")\n\n        ds = DatasetDict({\"train\": make(2000), \"dev\": make(400), \"test\": make(400)})\n    return ds\n\n\nspr = get_dataset()\n\n# ---------- vocabulary & label maps ---------------------------------------------\ntokens = {tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split()}\ntok2id = {t: i + 1 for i, t in enumerate(sorted(tokens))}  # 0 reserved for PAD\nCLS_ID = len(tok2id) + 1\nVOCAB_SIZE = CLS_ID + 1  # +1 because ids start at 0\nlabel2id = {l: i for i, l in enumerate(sorted({ex[\"label\"] for ex in spr[\"train\"]}))}\nid2label = {v: k for k, v in label2id.items()}\nNUM_CLS = len(label2id)\n\n\n# ---------- torch dataset --------------------------------------------------------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.lbl = [label2id[l] for l in split[\"label\"]]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        token_ids = [tok2id[t] for t in seq.split()]\n        n_shape = _count_shape(seq)\n        n_color = len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n        return {\n            \"input_ids\": torch.tensor(token_ids, dtype=torch.long),\n            \"sym\": torch.tensor(\n                [n_shape, n_color, n_shape * n_color], dtype=torch.float\n            ),\n            \"label\": torch.tensor(self.lbl[idx], dtype=torch.long),\n            \"raw_seq\": seq,\n        }\n\n\ndef collate(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch) + 1  # +1 for CLS\n    ids = torch.zeros(len(batch), max_len, dtype=torch.long)\n    mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n    for i, b in enumerate(batch):\n        ids[i, 0] = CLS_ID\n        seq_len = len(b[\"input_ids\"])\n        ids[i, 1 : seq_len + 1] = b[\"input_ids\"]\n        mask[i, : seq_len + 1] = 1\n    return {\n        \"input_ids\": ids,\n        \"mask\": mask,\n        \"sym\": torch.stack([b[\"sym\"] for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(SPRTorch(spr[\"train\"]), batch_size, True, collate_fn=collate)\ndev_loader = DataLoader(SPRTorch(spr[\"dev\"]), batch_size, False, collate_fn=collate)\ntest_loader = DataLoader(SPRTorch(spr[\"test\"]), batch_size, False, collate_fn=collate)\n\n\n# ---------- model ----------------------------------------------------------------\nclass NeuroSymbolicTransformerCLS(nn.Module):\n    def __init__(self, vocab, embed_dim=64, nhead=4, nlayers=2, sym_dim=3, n_cls=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(embed_dim, nhead, 128, batch_first=True)\n        self.trans = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls_head = nn.Linear(embed_dim + sym_dim, n_cls)\n\n    def forward(self, ids, mask, sym_feats):\n        x = self.emb(ids)\n        x = self.trans(x, src_key_padding_mask=~mask)\n        cls_vec = x[:, 0, :]  # CLS token representation\n        return self.cls_head(torch.cat([cls_vec, sym_feats], -1))\n\n\n# ---------- helpers ---------------------------------------------------------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    total_loss = 0\n    n_items = 0\n    all_true, all_pred, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n            loss = criterion(logits, batch[\"label\"])\n            total_loss += loss.item() * batch[\"label\"].size(0)\n            n_items += batch[\"label\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            all_true.extend(batch[\"label\"].cpu().tolist())\n            all_pred.extend(preds)\n            all_seqs.extend(batch[\"raw_seq\"])\n    swa = shape_weighted_accuracy(all_seqs, all_true, all_pred)\n    return total_loss / n_items, swa, all_true, all_pred, all_seqs\n\n\n# ---------- experiment logging dict -----------------------------------------------\nexperiment_data = {\n    \"CLS-Token-Pooling\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---------- training loop ---------------------------------------------------------\nmax_epochs, patience = 20, 4\nmodel = NeuroSymbolicTransformerCLS(VOCAB_SIZE, n_cls=NUM_CLS).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nbest_val, wait, best_state = math.inf, 0, None\n\nfor epoch in range(1, max_epochs + 1):\n    model.train()\n    ep_loss = 0\n    m = 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"], batch[\"mask\"], batch[\"sym\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        ep_loss += loss.item() * batch[\"label\"].size(0)\n        m += batch[\"label\"].size(0)\n    train_loss = ep_loss / m\n    val_loss, val_swa, y_true, y_pred, _ = evaluate(model, dev_loader)\n    print(f\"Epoch {epoch}: val_loss={val_loss:.4f}, SWA={val_swa:.4f}\")\n    # log\n    ed = experiment_data[\"CLS-Token-Pooling\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"].append(None)\n    ed[\"metrics\"][\"val\"].append(val_swa)\n    ed[\"predictions\"].append(y_pred)\n    ed[\"ground_truth\"].append(y_true)\n    ed[\"epochs\"].append(epoch)\n    # early stopping\n    if val_loss < best_val - 1e-4:\n        best_val, wait, best_state = val_loss, 0, copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n    if wait >= patience:\n        print(\"Early stopping.\")\n        break\n\n# ---------- test evaluation -------------------------------------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, y_tst, y_pst, seqs = evaluate(model, test_loader)\nprint(f\"TEST: loss={test_loss:.4f}, SWA={test_swa:.4f}\")\n\n# ---------- save results ----------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'Loaded SPR_BENCH.', '\\n', 'Epoch 1:\nvalidation_loss = 0.2152, SWA = 0.9295', '\\n', 'Epoch 2: validation_loss =\n0.2040, SWA = 0.9323', '\\n', 'Epoch 3: validation_loss = 0.1774, SWA = 0.9443',\n'\\n', 'Epoch 4: validation_loss = 0.1684, SWA = 0.9447', '\\n', 'Epoch 5:\nvalidation_loss = 0.1659, SWA = 0.9447', '\\n', 'Epoch 6: validation_loss =\n0.1647, SWA = 0.9449', '\\n', 'Epoch 7: validation_loss = 0.1709, SWA = 0.9447',\n'\\n', 'Epoch 8: validation_loss = 0.1686, SWA = 0.9445', '\\n', 'Epoch 9:\nvalidation_loss = 0.1673, SWA = 0.9447', '\\n', 'Epoch 10: validation_loss =\n0.1688, SWA = 0.9444', '\\n', 'Early stopping triggered.', '\\n', 'TEST:\nloss=1.3306, SWA=0.6498', '\\n', 'Saved metrics to working/experiment_data.npy',\n'\\n', 'Execution time: 16 seconds seconds (time limit is 30 minutes).']", "['Device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 303015.05\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 146124.67\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 416928.83\nexamples/s]', '\\n', 'Loaded SPR_BENCH', '\\n', 'Epoch 1: val_loss=0.2101\nSWA=0.9313', '\\n', 'Epoch 2: val_loss=0.1926  SWA=0.9345', '\\n', 'Epoch 3:\nval_loss=0.1810  SWA=0.9408', '\\n', 'Epoch 4: val_loss=0.1747  SWA=0.9431',\n'\\n', 'Epoch 5: val_loss=0.1672  SWA=0.9447', '\\n', 'Epoch 6: val_loss=0.1656\nSWA=0.9447', '\\n', 'Epoch 7: val_loss=0.1640  SWA=0.9447', '\\n', 'Epoch 8:\nval_loss=0.1707  SWA=0.9447', '\\n', 'Epoch 9: val_loss=0.1657  SWA=0.9447',\n'\\n', 'Epoch 10: val_loss=0.1663  SWA=0.9447', '\\n', 'Epoch 11: val_loss=0.1702\nSWA=0.9440', '\\n', 'Early stopping.', '\\n', 'TEST: loss=1.4315, SWA=0.6500',\n'\\n', 'Saved to working/experiment_data.npy', '\\n', 'Execution time: 18 seconds\nseconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Trying to load SPR_BENCH ...', '\\n', '\\rGenerating\ntrain split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating train split:\n20000 examples [00:00, 244280.96 examples/s]', '\\n', '\\rGenerating train split:\n0 examples [00:00, ? examples/s]', '', '\\rGenerating train split: 5000 examples\n[00:00, 192561.80 examples/s]', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 10000 examples [00:00,\n468516.92 examples/s]', '\\n', 'Epoch 1: val_loss=0.6679, SWA=0.5857', '\\n',\n'Epoch 2: val_loss=0.6667, SWA=0.5857', '\\n', 'Epoch 3: val_loss=0.6652,\nSWA=0.5857', '\\n', 'Epoch 4: val_loss=0.6648, SWA=0.5857', '\\n', 'Epoch 5:\nval_loss=0.6650, SWA=0.5857', '\\n', 'Epoch 6: val_loss=0.6745, SWA=0.5857',\n'\\n', 'Epoch 7: val_loss=0.6672, SWA=0.5857', '\\n', 'Epoch 8: val_loss=0.6656,\nSWA=0.5857', '\\n', 'Early stopping.', '\\n', 'TEST: loss=0.6905, SWA=0.5287',\n'\\n', 'Saved metrics to working/experiment_data.npy', '\\n', 'Execution time: 5\nseconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '\\rGenerating train split: 20000 examples [00:00,\n193059.92 examples/s]', '', '\\rGenerating train split: 20000 examples [00:00,\n192473.43 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 252787.70\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 363432.69\nexamples/s]', '\\n', 'Loaded SPR_BENCH from disk.', '\\n', 'Epoch 1:\nval_loss=0.2598, SWA=0.9116', '\\n', 'Epoch 2: val_loss=0.2010, SWA=0.9350',\n'\\n', 'Epoch 3: val_loss=0.1802, SWA=0.9436', '\\n', 'Epoch 4: val_loss=0.1735,\nSWA=0.9447', '\\n', 'Epoch 5: val_loss=0.1674, SWA=0.9447', '\\n', 'Epoch 6:\nval_loss=0.1691, SWA=0.9447', '\\n', 'Epoch 7: val_loss=0.1648, SWA=0.9447',\n'\\n', 'Epoch 8: val_loss=0.1670, SWA=0.9445', '\\n', 'Epoch 9: val_loss=0.1665,\nSWA=0.9447', '\\n', 'Epoch 10: val_loss=0.1675, SWA=0.9447', '\\n', 'Epoch 11:\nval_loss=0.1758, SWA=0.9443', '\\n', 'Early stopping.', '\\n', 'TEST: loss=1.3844,\nSWA=0.6500', '\\n', 'Saved to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/0-\nrun/process_ForkProcess-18/working/experiment_data.npy', '\\n', 'Execution time:\n21 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '\\rGenerating train split: 20000 examples [00:00, 182215.27\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 181369.43\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 137173.66\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 675172.08\nexamples/s]', '\\n', 'Loaded SPR_BENCH.', '\\n', 'Epoch 1: val_loss=0.5141,\nSWA=0.7589', '\\n', 'Epoch 2: val_loss=0.4870, SWA=0.7762', '\\n', 'Epoch 3:\nval_loss=0.4779, SWA=0.7780', '\\n', 'Epoch 4: val_loss=0.4751, SWA=0.7787',\n'\\n', 'Epoch 5: val_loss=0.4695, SWA=0.7824', '\\n', 'Epoch 6: val_loss=0.4671,\nSWA=0.7811', '\\n', 'Epoch 7: val_loss=0.4654, SWA=0.7850', '\\n', 'Epoch 8:\nval_loss=0.4626, SWA=0.7818', '\\n', 'Epoch 9: val_loss=0.4615, SWA=0.7822',\n'\\n', 'Epoch 10: val_loss=0.4600, SWA=0.7829', '\\n', 'Epoch 11: val_loss=0.4610,\nSWA=0.7838', '\\n', 'Epoch 12: val_loss=0.4588, SWA=0.7832', '\\n', 'Epoch 13:\nval_loss=0.4574, SWA=0.7783', '\\n', 'Epoch 14: val_loss=0.4586, SWA=0.7776',\n'\\n', 'Epoch 15: val_loss=0.4567, SWA=0.7759', '\\n', 'Epoch 16: val_loss=0.4563,\nSWA=0.7765', '\\n', 'Epoch 17: val_loss=0.4572, SWA=0.7799', '\\n', 'Epoch 18:\nval_loss=0.4550, SWA=0.7762', '\\n', 'Epoch 19: val_loss=0.4551, SWA=0.7765',\n'\\n', 'Epoch 20: val_loss=0.4561, SWA=0.7762', '\\n', 'TEST: loss=0.7033,\nSWA=0.6173', '\\n', 'Saved metrics to working/experiment_data.npy', '\\n',\n'Execution time: 18 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded SPR_BENCH.', '\\n', 'Epoch 1:\nval_loss=0.2191  SWA=0.9269', '\\n', 'Epoch 2: val_loss=0.2065  SWA=0.9320',\n'\\n', 'Epoch 3: val_loss=0.1831  SWA=0.9413', '\\n', 'Epoch 4: val_loss=0.1684\nSWA=0.9440', '\\n', 'Epoch 5: val_loss=0.1660  SWA=0.9447', '\\n', 'Epoch 6:\nval_loss=0.1645  SWA=0.9449', '\\n', 'Epoch 7: val_loss=0.1708  SWA=0.9444',\n'\\n', 'Epoch 8: val_loss=0.1661  SWA=0.9447', '\\n', 'Epoch 9: val_loss=0.1665\nSWA=0.9447', '\\n', 'Epoch 10: val_loss=0.1715  SWA=0.9447', '\\n', 'Early\nstopping.', '\\n', 'TEST: loss=1.3068, SWA=0.6501', '\\n', 'Saved metrics to\nworking/experiment_data.npy', '\\n', 'Execution time: 15 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Trying to load SPR_BENCH ...', '\\n', 'Epoch 1:\nvalidation_loss = 0.6843, SWA=0.5752, NWA=0.5794', '\\n', 'Epoch 2:\nvalidation_loss = 0.6787, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 3:\nvalidation_loss = 0.6743, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 4:\nvalidation_loss = 0.6706, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 5:\nvalidation_loss = 0.6680, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 6:\nvalidation_loss = 0.6662, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 7:\nvalidation_loss = 0.6645, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 8:\nvalidation_loss = 0.6641, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 9:\nvalidation_loss = 0.6640, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 10:\nvalidation_loss = 0.6639, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 11:\nvalidation_loss = 0.6637, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 12:\nvalidation_loss = 0.6634, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 13:\nvalidation_loss = 0.6627, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 14:\nvalidation_loss = 0.6619, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 15:\nvalidation_loss = 0.6635, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 16:\nvalidation_loss = 0.6608, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 17:\nvalidation_loss = 0.6608, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 18:\nvalidation_loss = 0.6605, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 19:\nvalidation_loss = 0.6601, SWA=0.5857, NWA=0.5914', '\\n', 'Epoch 20:\nvalidation_loss = 0.6594, SWA=0.5857, NWA=0.5914', '\\n', 'TEST: loss=0.6870,\nSWA=0.5287, NWA=0.5441', '\\n', 'Saved metrics to working/experiment_data.npy',\n'\\n', 'Execution time: 14 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded SPR_BENCH.', '\\n', 'Epoch 1:\nval_loss=0.3840, SWA=0.8350', '\\n', 'Epoch 2: val_loss=0.2111, SWA=0.9269',\n'\\n', 'Epoch 3: val_loss=0.1805, SWA=0.9413', '\\n', 'Epoch 4: val_loss=0.1729,\nSWA=0.9425', '\\n', 'Epoch 5: val_loss=0.1684, SWA=0.9445', '\\n', 'Epoch 6:\nval_loss=0.1691, SWA=0.9438', '\\n', 'Epoch 7: val_loss=0.1654, SWA=0.9447',\n'\\n', 'Epoch 8: val_loss=0.1676, SWA=0.9447', '\\n', 'Epoch 9: val_loss=0.1673,\nSWA=0.9443', '\\n', 'Epoch 10: val_loss=0.1663, SWA=0.9444', '\\n', 'Epoch 11:\nval_loss=0.1641, SWA=0.9447', '\\n', 'Epoch 12: val_loss=0.1661, SWA=0.9447',\n'\\n', 'Epoch 13: val_loss=0.1645, SWA=0.9447', '\\n', 'Epoch 14: val_loss=0.1656,\nSWA=0.9447', '\\n', 'Epoch 15: val_loss=0.1632, SWA=0.9447', '\\n', 'Epoch 16:\nval_loss=0.1649, SWA=0.9447', '\\n', 'Epoch 17: val_loss=0.1644, SWA=0.9442',\n'\\n', 'Epoch 18: val_loss=0.1641, SWA=0.9447', '\\n', 'Epoch 19: val_loss=0.1673,\nSWA=0.9447', '\\n', 'Early stopping.', '\\n', 'TEST: loss=1.3500, SWA=0.6500',\n'\\n', 'Saved metrics to working/experiment_data.npy', '\\n', 'Execution time: 36\nseconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loading SPR_BENCH from disk \u2026', '\\n', 'Traceback\n(most recent call last):\\n  File \"runfile.py\", line 219, in <module>\\n    for\nbatch in train_loader:\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/utils/data/dataloader.py\", line 701, in __next__\\n    data =\nself._next_data()\\n           ^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/utils/data/dataloader.py\", line 757, in _next_data\\n    data =\nself._dataset_fetcher.fetch(index)  # may raise StopIteration\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\\n    data =\nself.dataset.__getitems__(possibly_batched_index)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/arrow_dataset.py\", line 2781, in __getitems__\\n    batch =\nself.__getitem__(keys)\\n            ^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\",\nline 130, in __getitem__\\n    seq = self.seqs[idx]\\n\n~~~~~~~~~^^^^^\\nTypeError: list indices must be integers or slices, not list\\n',\n'Execution time: 2 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded SPR_BENCH.', '\\n', 'Epoch 1:\nval_loss=0.3840, SWA=0.8350', '\\n', 'Epoch 2: val_loss=0.2111, SWA=0.9269',\n'\\n', 'Epoch 3: val_loss=0.1805, SWA=0.9413', '\\n', 'Epoch 4: val_loss=0.1729,\nSWA=0.9425', '\\n', 'Epoch 5: val_loss=0.1684, SWA=0.9445', '\\n', 'Epoch 6:\nval_loss=0.1691, SWA=0.9438', '\\n', 'Epoch 7: val_loss=0.1654, SWA=0.9447',\n'\\n', 'Epoch 8: val_loss=0.1676, SWA=0.9447', '\\n', 'Epoch 9: val_loss=0.1673,\nSWA=0.9443', '\\n', 'Epoch 10: val_loss=0.1663, SWA=0.9444', '\\n', 'Epoch 11:\nval_loss=0.1641, SWA=0.9447', '\\n', 'Epoch 12: val_loss=0.1661, SWA=0.9447',\n'\\n', 'Epoch 13: val_loss=0.1645, SWA=0.9447', '\\n', 'Epoch 14: val_loss=0.1656,\nSWA=0.9447', '\\n', 'Epoch 15: val_loss=0.1632, SWA=0.9447', '\\n', 'Epoch 16:\nval_loss=0.1649, SWA=0.9447', '\\n', 'Epoch 17: val_loss=0.1644, SWA=0.9442',\n'\\n', 'Epoch 18: val_loss=0.1641, SWA=0.9447', '\\n', 'Epoch 19: val_loss=0.1673,\nSWA=0.9447', '\\n', 'Early stopping.', '\\n', 'TEST: loss=1.3500, SWA=0.6500',\n'\\n', 'Saved metrics to working/experiment_data.npy', '\\n', 'Execution time: 31\nseconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded SPR_BENCH.', '\\n', 'Epoch 1:\nval_loss=0.3840, SWA=0.8350', '\\n', 'Epoch 2: val_loss=0.2111, SWA=0.9269',\n'\\n', 'Epoch 3: val_loss=0.1805, SWA=0.9413', '\\n', 'Epoch 4: val_loss=0.1729,\nSWA=0.9425', '\\n', 'Epoch 5: val_loss=0.1684, SWA=0.9445', '\\n', 'Epoch 6:\nval_loss=0.1691, SWA=0.9438', '\\n', 'Epoch 7: val_loss=0.1654, SWA=0.9447',\n'\\n', 'Epoch 8: val_loss=0.1676, SWA=0.9447', '\\n', 'Epoch 9: val_loss=0.1673,\nSWA=0.9443', '\\n', 'Epoch 10: val_loss=0.1663, SWA=0.9444', '\\n', 'Epoch 11:\nval_loss=0.1641, SWA=0.9447', '\\n', 'Epoch 12: val_loss=0.1661, SWA=0.9447',\n'\\n', 'Epoch 13: val_loss=0.1645, SWA=0.9447', '\\n', 'Epoch 14: val_loss=0.1656,\nSWA=0.9447', '\\n', 'Epoch 15: val_loss=0.1632, SWA=0.9447', '\\n', 'Epoch 16:\nval_loss=0.1649, SWA=0.9447', '\\n', 'Epoch 17: val_loss=0.1644, SWA=0.9442',\n'\\n', 'Epoch 18: val_loss=0.1641, SWA=0.9447', '\\n', 'Epoch 19: val_loss=0.1673,\nSWA=0.9447', '\\n', 'Early stopping.', '\\n', 'TEST: loss=1.3500, SWA=0.6500',\n'\\n', 'Saved metrics to working/experiment_data.npy', '\\n', 'Execution time: 30\nseconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded SPR_BENCH.', '\\n', 'Epoch 1:\nval_loss=0.3840, SWA=0.8350', '\\n', 'Epoch 2: val_loss=0.2111, SWA=0.9269',\n'\\n', 'Epoch 3: val_loss=0.1805, SWA=0.9413', '\\n', 'Epoch 4: val_loss=0.1729,\nSWA=0.9425', '\\n', 'Epoch 5: val_loss=0.1684, SWA=0.9445', '\\n', 'Epoch 6:\nval_loss=0.1691, SWA=0.9438', '\\n', 'Epoch 7: val_loss=0.1654, SWA=0.9447',\n'\\n', 'Epoch 8: val_loss=0.1676, SWA=0.9447', '\\n', 'Epoch 9: val_loss=0.1673,\nSWA=0.9443', '\\n', 'Epoch 10: val_loss=0.1663, SWA=0.9444', '\\n', 'Epoch 11:\nval_loss=0.1641, SWA=0.9447', '\\n', 'Epoch 12: val_loss=0.1661, SWA=0.9447',\n'\\n', 'Epoch 13: val_loss=0.1645, SWA=0.9447', '\\n', 'Epoch 14: val_loss=0.1656,\nSWA=0.9447', '\\n', 'Epoch 15: val_loss=0.1632, SWA=0.9447', '\\n', 'Epoch 16:\nval_loss=0.1649, SWA=0.9447', '\\n', 'Epoch 17: val_loss=0.1644, SWA=0.9442',\n'\\n', 'Epoch 18: val_loss=0.1641, SWA=0.9447', '\\n', 'Epoch 19: val_loss=0.1673,\nSWA=0.9447', '\\n', 'Early stopping.', '\\n', 'TEST: loss=1.3500, SWA=0.6500',\n'\\n', 'Saved metrics to working/experiment_data.npy', '\\n', 'Execution time: 29\nseconds seconds (time limit is 30 minutes).']", ""], "analysis": ["", "", "The training script encountered an issue where the validation Shape-Weighted\nAccuracy (SWA) metric remained constant at 0.5857 across all epochs, indicating\nthat the model failed to learn effectively during training. Additionally, the\ntest SWA metric dropped to 0.5287, which signifies poor generalization. This\nsuggests that the symbolic-only model might be too simplistic to capture the\ncomplexities of the SPR_BENCH dataset. To fix this, consider the following\nsteps: 1. Investigate the feature representation (e.g., symbolic features) to\nensure it captures sufficient information for classification. 2. Experiment with\na more complex model architecture, such as adding more layers or using a hybrid\napproach with symbolic and neural components. 3. Check the dataset for potential\nissues, such as label noise or imbalance. 4. Tune hyperparameters like learning\nrate and batch size to improve model performance.", "", "", "", "", "The execution of the training script was successful without any bugs. The model\nwas trained on the SPR_BENCH dataset, and the training process demonstrated\nimprovements in validation loss and Shape-Weighted Accuracy (SWA) over epochs.\nEarly stopping was correctly applied to prevent overfitting, and the final test\nevaluation was completed. The results were saved successfully, and the execution\ncompleted within the time limit.", "The execution failed due to a TypeError in the __getitem__ method of the\nSPRTorch dataset. The issue arises because the DataLoader attempts to fetch\nmultiple indices (a list of indices) at once, but the __getitem__ method is\nimplemented to handle only single integer indices. To fix this, modify the\n__getitem__ method to handle list indices by iterating through the list and\nreturning the corresponding data points.", "The training script executed successfully without any errors or bugs. The model\nachieved good performance on the validation set, with a Shape-Weighted Accuracy\n(SWA) of 0.9447. Early stopping was triggered after epoch 19, indicating the\nmodel converged. However, the test set performance was lower, with a SWA of\n0.6500. This could be due to overfitting or a domain gap between the\ntraining/validation and test sets. Further investigation into the dataset and\nmodel generalization might be needed.", "The execution of the training script completed successfully without any errors\nor bugs. The model trained over multiple epochs, with validation loss and Shape-\nWeighted Accuracy (SWA) improving steadily. Early stopping was triggered as\nexpected after the model stopped showing significant improvement on the\nvalidation set. Test evaluation was conducted, and metrics were saved\nsuccessfully. The only observation is that the test loss is relatively high\n(1.3500) compared to the validation loss, and the SWA on the test set is lower\n(0.6500). This might indicate some degree of overfitting or a challenging test\nset, which could be addressed in future iterations by implementing\nregularization techniques or improving the model's generalization capabilities.", "The execution completed successfully without any bugs. The training and\nevaluation process ran smoothly, with metrics being logged and early stopping\nimplemented. The final test results (loss=1.3500, SWA=0.6500) indicate that the\nmodel performed reasonably well, though there is room for improvement in the\ntest Shape-Weighted Accuracy (SWA). Metrics were saved as expected, and the\nexecution time was well within the time limit. No issues were detected.", ""], "exc_type": [null, null, null, null, null, null, null, null, "TypeError", null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, {"args": ["list indices must be integers or slices, not list"]}, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 219, "<module>", "for batch in train_loader:"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/utils/data/dataloader.py", 701, "__next__", "data = self._next_data()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/utils/data/dataloader.py", 757, "_next_data", "data = self._dataset_fetcher.fetch(index)  # may raise StopIteration"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", 50, "fetch", "data = self.dataset.__getitems__(possibly_batched_index)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/arrow_dataset.py", 2781, "__getitems__", "batch = self.__getitem__(keys)"], ["runfile.py", 130, "__getitem__", "seq = self.seqs[idx]"]], null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated on the training dataset during the final epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.168, "best_value": 0.168}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset, with the best value observed during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1647, "best_value": 0.1647}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy calculated on the validation dataset, with the best value observed during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9449, "best_value": 0.9449}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is performing on the training data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.169303, "best_value": 0.169303}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, indicating how well the model is performing on unseen validation data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.164049, "best_value": 0.164049}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy measure that accounts for shape-weighted factors in validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.944658, "best_value": 0.944658}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Loss during training phase, lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6551, "best_value": 0.6551}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss during validation phase, lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6648, "best_value": 0.6648}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "Accuracy during validation phase, higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5857, "best_value": 0.5857}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error in the model's predictions during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1691, "best_value": 0.1691}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error in the model's predictions on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1648, "best_value": 0.1648}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Measures the shape-weighted accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9447, "best_value": 0.9447}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.446781, "best_value": 0.446781}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.456104, "best_value": 0.456104}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.776189, "best_value": 0.776189}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1676909702539444, "best_value": 0.1676909702539444}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1644537564575672, "best_value": 0.1644537564575672}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "The shape weighted accuracy calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9448901290547611, "best_value": 0.9448901290547611}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss on the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.650792, "best_value": 0.650792}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Best validation loss on the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.659399, "best_value": 0.659399}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Best validation shape-weighted accuracy on the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.585688, "best_value": 0.585688}]}, {"metric_name": "validation novelty-weighted accuracy", "lower_is_better": false, "description": "Best validation novelty-weighted accuracy on the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5914, "best_value": 0.5914}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.168461, "best_value": 0.168461}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error during validation. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.16322, "best_value": 0.16322}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy during validation, weighted by shape. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.944658, "best_value": 0.944658}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.168461, "best_value": 0.168461}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error on the validation set. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.16322, "best_value": 0.16322}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy on the validation set, weighted by shape. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.944658, "best_value": 0.944658}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error in predictions during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.168461, "best_value": 0.168461}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error in predictions on the validation dataset. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.16322, "best_value": 0.16322}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy weighted by shape categories on the validation dataset. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.944658, "best_value": 0.944658}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.168461, "best_value": 0.168461}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.16322, "best_value": 0.16322}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "The shape weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.944658, "best_value": 0.944658}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, false, false, false, true, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_d4fc4965d09f4d549853d5ad6b6f0f04_proc_2950686/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_d4fc4965d09f4d549853d5ad6b6f0f04_proc_2950686/SPR_BENCH_val_SWA.png"], ["../../logs/0-run/experiment_results/experiment_3555ada69eb549efbbd3437db5d8ce86_proc_2952777/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_3555ada69eb549efbbd3437db5d8ce86_proc_2952777/SPR_BENCH_val_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_3555ada69eb549efbbd3437db5d8ce86_proc_2952777/SPR_BENCH_confusion_matrix.png"], [], ["../../logs/0-run/experiment_results/experiment_07b6756a0ef4491e927374d353dd070f_proc_2952779/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_07b6756a0ef4491e927374d353dd070f_proc_2952779/SPR_BENCH_val_SWA.png", "../../logs/0-run/experiment_results/experiment_07b6756a0ef4491e927374d353dd070f_proc_2952779/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_33f587c3087248319118a46ff02257f2_proc_2952780/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_33f587c3087248319118a46ff02257f2_proc_2952780/SPR_BENCH_val_SWA.png"], ["../../logs/0-run/experiment_results/experiment_1c142afb55ef4e0c9508838c8d55b0bf_proc_2952778/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_1c142afb55ef4e0c9508838c8d55b0bf_proc_2952778/SPR_BENCH_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_1c142afb55ef4e0c9508838c8d55b0bf_proc_2952778/SPR_BENCH_confusion_matrix_epoch6.png"], ["../../logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_NWA_curve.png", "../../logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_38b6a9671dd64f42a86de3295e273b77_proc_2952780/SPR_BENCH_CLS-Token-Pooling_loss_curves.png", "../../logs/0-run/experiment_results/experiment_38b6a9671dd64f42a86de3295e273b77_proc_2952780/SPR_BENCH_CLS-Token-Pooling_val_SWA.png", "../../logs/0-run/experiment_results/experiment_38b6a9671dd64f42a86de3295e273b77_proc_2952780/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"], [], ["../../logs/0-run/experiment_results/experiment_845932789bf54c1a970c17933c0314ec_proc_2952779/SPR_BENCH_CLS-Token-Pooling_loss_curves.png", "../../logs/0-run/experiment_results/experiment_845932789bf54c1a970c17933c0314ec_proc_2952779/SPR_BENCH_CLS-Token-Pooling_val_SWA.png", "../../logs/0-run/experiment_results/experiment_845932789bf54c1a970c17933c0314ec_proc_2952779/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"], ["../../logs/0-run/experiment_results/experiment_7b944347b81c460387c55a55dfe4564d_proc_2952778/SPR_BENCH_CLS-Token-Pooling_loss_curves.png", "../../logs/0-run/experiment_results/experiment_7b944347b81c460387c55a55dfe4564d_proc_2952778/SPR_BENCH_CLS-Token-Pooling_val_SWA.png", "../../logs/0-run/experiment_results/experiment_7b944347b81c460387c55a55dfe4564d_proc_2952778/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"], ["../../logs/0-run/experiment_results/experiment_d5fd905b777f435abca27b171b4f8fa8_proc_2952777/SPR_BENCH_CLS-Token-Pooling_loss_curves.png", "../../logs/0-run/experiment_results/experiment_d5fd905b777f435abca27b171b4f8fa8_proc_2952777/SPR_BENCH_CLS-Token-Pooling_val_SWA.png", "../../logs/0-run/experiment_results/experiment_d5fd905b777f435abca27b171b4f8fa8_proc_2952777/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"], ["../../logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_loss_mean_sem.png", "../../logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_val_SWA_mean_sem.png", "../../logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_hist_epoch1.png", "../../logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_hist_epoch5.png", "../../logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_hist_epoch10.png", "../../logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_hist_epoch14.png", "../../logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_hist_epoch19.png"]], "plot_paths": [["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_d4fc4965d09f4d549853d5ad6b6f0f04_proc_2950686/SPR_BENCH_loss_curve.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_d4fc4965d09f4d549853d5ad6b6f0f04_proc_2950686/SPR_BENCH_val_SWA.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_3555ada69eb549efbbd3437db5d8ce86_proc_2952777/SPR_BENCH_loss_curve.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_3555ada69eb549efbbd3437db5d8ce86_proc_2952777/SPR_BENCH_val_SWA_curve.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_3555ada69eb549efbbd3437db5d8ce86_proc_2952777/SPR_BENCH_confusion_matrix.png"], [], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_07b6756a0ef4491e927374d353dd070f_proc_2952779/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_07b6756a0ef4491e927374d353dd070f_proc_2952779/SPR_BENCH_val_SWA.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_07b6756a0ef4491e927374d353dd070f_proc_2952779/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33f587c3087248319118a46ff02257f2_proc_2952780/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33f587c3087248319118a46ff02257f2_proc_2952780/SPR_BENCH_val_SWA.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1c142afb55ef4e0c9508838c8d55b0bf_proc_2952778/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1c142afb55ef4e0c9508838c8d55b0bf_proc_2952778/SPR_BENCH_SWA_curve.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1c142afb55ef4e0c9508838c8d55b0bf_proc_2952778/SPR_BENCH_confusion_matrix_epoch6.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_loss_curve.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_SWA_curve.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_NWA_curve.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_38b6a9671dd64f42a86de3295e273b77_proc_2952780/SPR_BENCH_CLS-Token-Pooling_loss_curves.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_38b6a9671dd64f42a86de3295e273b77_proc_2952780/SPR_BENCH_CLS-Token-Pooling_val_SWA.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_38b6a9671dd64f42a86de3295e273b77_proc_2952780/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"], [], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_845932789bf54c1a970c17933c0314ec_proc_2952779/SPR_BENCH_CLS-Token-Pooling_loss_curves.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_845932789bf54c1a970c17933c0314ec_proc_2952779/SPR_BENCH_CLS-Token-Pooling_val_SWA.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_845932789bf54c1a970c17933c0314ec_proc_2952779/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7b944347b81c460387c55a55dfe4564d_proc_2952778/SPR_BENCH_CLS-Token-Pooling_loss_curves.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7b944347b81c460387c55a55dfe4564d_proc_2952778/SPR_BENCH_CLS-Token-Pooling_val_SWA.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7b944347b81c460387c55a55dfe4564d_proc_2952778/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_d5fd905b777f435abca27b171b4f8fa8_proc_2952777/SPR_BENCH_CLS-Token-Pooling_loss_curves.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_d5fd905b777f435abca27b171b4f8fa8_proc_2952777/SPR_BENCH_CLS-Token-Pooling_val_SWA.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_d5fd905b777f435abca27b171b4f8fa8_proc_2952777/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"], ["experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_loss_mean_sem.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_val_SWA_mean_sem.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_hist_epoch1.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_hist_epoch5.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_hist_epoch10.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_hist_epoch14.png", "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_16edcdbbb4af4d5b8e37d10d8bc7a0f2/SPR_BENCH_CLS-Token-Pooling_AGG_hist_epoch19.png"]], "plot_analyses": [[{"analysis": "This plot shows the training and validation loss over 10 epochs. The training loss decreases rapidly at the beginning, indicating that the model is learning effectively. The validation loss also decreases initially and stabilizes after a few epochs, suggesting that the model generalizes well to unseen data. There is no evidence of overfitting as the training and validation loss curves remain close to each other throughout the training process.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_d4fc4965d09f4d549853d5ad6b6f0f04_proc_2950686/SPR_BENCH_loss_curve.png"}, {"analysis": "This plot depicts the Shape-Weighted Accuracy (SWA) on the validation set across 10 epochs. The SWA remains consistently high, starting near 0.9 and approaching 1.0 as training progresses. This indicates that the model performs exceptionally well in terms of capturing shape-related patterns in the sequences, even in a zero-shot setting. The stability of the SWA suggests robust generalization to unseen rules.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_d4fc4965d09f4d549853d5ad6b6f0f04_proc_2950686/SPR_BENCH_val_SWA.png"}], [{"analysis": "The plot shows the training and validation loss over epochs. Both losses decrease steadily, indicating that the model is learning effectively. The validation loss stabilizes and converges with the training loss after a few epochs, suggesting that the model is not overfitting and generalizes well to unseen data.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_3555ada69eb549efbbd3437db5d8ce86_proc_2952777/SPR_BENCH_loss_curve.png"}, {"analysis": "The plot demonstrates the Shape-Weighted Accuracy (SWA) over epochs. The SWA rises sharply in the initial epochs and plateaus around epoch 5, maintaining a high value afterward. This indicates that the model quickly learns the shape-related rules and sustains its performance, showcasing the efficacy of the neural-symbolic integration in capturing shape-related information.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_3555ada69eb549efbbd3437db5d8ce86_proc_2952777/SPR_BENCH_val_SWA_curve.png"}, {"analysis": "The confusion matrix illustrates the model's performance at the final epoch. The true positive and true negative values are high, with minimal false positives. Notably, there are no false negatives, indicating that the model has a strong ability to correctly identify positive cases. However, the false positives suggest some room for improvement in distinguishing between certain categories.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_3555ada69eb549efbbd3437db5d8ce86_proc_2952777/SPR_BENCH_confusion_matrix.png"}], [], [{"analysis": "The plot illustrates the training and validation loss over epochs. The training loss decreases rapidly in the initial epochs and stabilizes around epoch 5. The validation loss follows a similar trend, indicating that the model is learning effectively without significant overfitting. The slight increase in validation loss after epoch 9 suggests potential overfitting if training continues, but overall, the loss curves demonstrate good convergence.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_07b6756a0ef4491e927374d353dd070f_proc_2952779/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot shows the Shape-Weighted Accuracy (SWA) on the validation set across epochs. The SWA improves rapidly in the first few epochs, reaching a plateau around epoch 4. This indicates that the model quickly learns to generalize well to unseen data in terms of shape-weighted reasoning. The stable accuracy after epoch 4 suggests that the model maintains consistent performance.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_07b6756a0ef4491e927374d353dd070f_proc_2952779/SPR_BENCH_val_SWA.png"}, {"analysis": "The confusion matrix for epoch 7 provides a detailed view of the model's classification performance. The true positive and true negative values are high, indicating that the model performs well in both classes. The false positives (254) are relatively low compared to the total number of predictions, and there are no false negatives, which is a strong indicator of the model's reliability in predicting positive instances. The overall performance appears robust, with minimal misclassification.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_07b6756a0ef4491e927374d353dd070f_proc_2952779/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The loss curves show a consistent decrease in both training and validation loss over the epochs, indicating that the model is learning effectively. The training loss decreases more rapidly initially, which is expected as the model adjusts to the data. The gap between training and validation loss remains small throughout the training process, suggesting that the model is not overfitting and is generalizing well to unseen data. The slight flattening of the curves towards the end may indicate that the model is approaching convergence.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33f587c3087248319118a46ff02257f2_proc_2952780/SPR_BENCH_loss_curves.png"}, {"analysis": "The validation Shape-Weighted Accuracy (SWA) curve shows an initial increase, peaking around epoch 8. This suggests that the model's ability to generalize to unseen data improves significantly during the early training stages. After the peak, there is a slight fluctuation in SWA, with minor decreases and increases, but the overall trend stabilizes. This could indicate that the model has reached its optimal performance level for SWA and is now oscillating due to small variations in the data or the optimization process. The stabilization of SWA after epoch 8 is a promising sign of consistent performance.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_33f587c3087248319118a46ff02257f2_proc_2952780/SPR_BENCH_val_SWA.png"}], [{"analysis": "The plot shows the training and validation loss over 10 epochs. Both losses decrease significantly during the initial epochs, indicating effective learning. The training loss stabilizes around epoch 6, while the validation loss remains slightly higher but follows a similar trend. This suggests that the model is learning effectively without significant overfitting.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1c142afb55ef4e0c9508838c8d55b0bf_proc_2952778/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the Shape-Weighted Accuracy (SWA) on the validation set across 10 epochs. The SWA improves rapidly in the first few epochs and stabilizes around epoch 6, achieving a high accuracy of approximately 0.945. This indicates that the model is effectively capturing shape-related features and generalizing well to the validation set.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1c142afb55ef4e0c9508838c8d55b0bf_proc_2952778/SPR_BENCH_SWA_curve.png"}, {"analysis": "The confusion matrix provides a detailed view of the model's performance at the best epoch (epoch 6). It shows a high number of correct predictions for both classes, with minimal misclassifications (253 false positives and no false negatives). This highlights the model's strong performance, particularly in avoiding false negatives, which is critical in many reasoning tasks.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1c142afb55ef4e0c9508838c8d55b0bf_proc_2952778/SPR_BENCH_confusion_matrix_epoch6.png"}], [{"analysis": "The training and validation loss curves decrease steadily over the epochs, indicating that the model is learning effectively. The gap between training and validation loss is minimal, suggesting that the model is not overfitting and has good generalization capabilities.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_loss_curve.png"}, {"analysis": "The validation Shape-Weighted Accuracy (SWA) metric stabilizes quickly after the first epoch and remains consistent throughout the training process. This indicates that the model learns the shape-related rules effectively early in the training process, and the performance does not degrade over time.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_SWA_curve.png"}, {"analysis": "The validation Novelty-Weighted Accuracy (NWA) metric also stabilizes after the first epoch, mirroring the behavior of the SWA metric. This consistency suggests that the model is capable of handling novel rules effectively and maintains robust performance across unseen scenarios.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_NWA_curve.png"}, {"analysis": "The confusion matrix shows a balanced performance across the two classes, with the true positives and true negatives being fairly comparable. However, there are still a significant number of misclassifications, as seen in the off-diagonal elements, which indicates room for improvement in model precision and recall.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_21cbcd2c97f64fadb3b582d4679c7139_proc_2952777/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The plot shows the training and validation loss over epochs for the CLS-Token-Pooling model on the SPR_BENCH dataset. Both losses decrease rapidly during the initial epochs, indicating effective learning. The validation loss stabilizes around epoch 5, closely aligning with the training loss, which suggests that the model generalizes well without significant overfitting. This behavior reflects a well-tuned training process.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_38b6a9671dd64f42a86de3295e273b77_proc_2952780/SPR_BENCH_CLS-Token-Pooling_loss_curves.png"}, {"analysis": "This plot presents the validation Shape-Weighted Accuracy (SWA) over epochs. The SWA improves significantly within the first few epochs, reaching a plateau at around 0.94 after epoch 5. This rapid convergence indicates that the model quickly learns to generalize well to the validation set. The consistently high SWA after convergence suggests robust performance in capturing shape-related features.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_38b6a9671dd64f42a86de3295e273b77_proc_2952780/SPR_BENCH_CLS-Token-Pooling_val_SWA.png"}, {"analysis": "The bar chart compares the ground truth and predicted label distributions for the final epoch. The predicted label distribution closely matches the ground truth, indicating that the model achieves a balanced representation of the two labels. However, there is a slight underprediction for label 0 and overprediction for label 1, which might suggest a minor bias in the model's predictions. This could be addressed by further fine-tuning or rebalancing the dataset.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_38b6a9671dd64f42a86de3295e273b77_proc_2952780/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"}], [], [{"analysis": "This plot shows the training and validation loss over epochs for the CLS-Token-Pooling model on the SPR_BENCH dataset. Both training and validation losses decrease sharply in the initial epochs and stabilize around epoch 5. The validation loss closely follows the training loss, indicating that the model generalizes well to unseen data without overfitting. The final stabilized loss values are low, suggesting effective learning and convergence.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_845932789bf54c1a970c17933c0314ec_proc_2952779/SPR_BENCH_CLS-Token-Pooling_loss_curves.png"}, {"analysis": "This plot illustrates the Shape-Weighted Accuracy (SWA) on the validation set over epochs. The SWA improves rapidly within the first few epochs and stabilizes around 0.94 after epoch 5. This indicates that the model quickly learns to generalize well in terms of shape-based reasoning and maintains consistent performance as training progresses.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_845932789bf54c1a970c17933c0314ec_proc_2952779/SPR_BENCH_CLS-Token-Pooling_val_SWA.png"}, {"analysis": "This plot compares the ground truth and predicted label distributions at the final epoch. The predicted distribution closely matches the ground truth distribution for both labels, indicating that the model achieves balanced performance across different classes. However, there is a slight underprediction for label 0 and overprediction for label 1, which might suggest a minor class imbalance in predictions.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_845932789bf54c1a970c17933c0314ec_proc_2952779/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"}], [{"analysis": "This plot illustrates the training and validation loss over epochs for the CLS-Token-Pooling model. The training loss decreases steadily, indicating that the model is learning effectively during training. The validation loss follows a similar downward trend and stabilizes at around epoch 5, suggesting that the model is not overfitting and achieves a good generalization performance. The close alignment between training and validation loss further supports this observation.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7b944347b81c460387c55a55dfe4564d_proc_2952778/SPR_BENCH_CLS-Token-Pooling_loss_curves.png"}, {"analysis": "This plot shows the validation Shape-Weighted Accuracy (SWA) over epochs. The SWA increases sharply within the first few epochs and stabilizes at a high value (~0.94) from epoch 5 onwards. This indicates that the model quickly learns to generalize well on the validation set, achieving high accuracy in predicting shape-weighted outcomes.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7b944347b81c460387c55a55dfe4564d_proc_2952778/SPR_BENCH_CLS-Token-Pooling_val_SWA.png"}, {"analysis": "This plot depicts the label distribution for ground truth and predicted labels at the final epoch. The predicted label distribution closely matches the ground truth distribution, indicating that the model is well-calibrated and effectively captures the underlying data distribution. However, there is a slight underprediction for Label ID 0 and overprediction for Label ID 1, which could be investigated further to ensure balanced performance across classes.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7b944347b81c460387c55a55dfe4564d_proc_2952778/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"}], [{"analysis": "The plot shows the cross-entropy loss for both the training and validation sets over 20 epochs. The training loss decreases rapidly in the initial epochs and stabilizes around a low value, indicating effective learning. Similarly, the validation loss decreases and remains stable, suggesting that the model generalizes well without overfitting. The close alignment between training and validation losses further supports this observation.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_d5fd905b777f435abca27b171b4f8fa8_proc_2952777/SPR_BENCH_CLS-Token-Pooling_loss_curves.png"}, {"analysis": "This plot depicts the Shape-Weighted Accuracy (SWA) on the validation set over 20 epochs. The SWA improves dramatically in the early epochs and stabilizes around 0.94, indicating that the model is able to generalize well to the validation data in terms of shape-related reasoning. The consistent performance after the initial rise suggests that the model has reached a stable state of learning.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_d5fd905b777f435abca27b171b4f8fa8_proc_2952777/SPR_BENCH_CLS-Token-Pooling_val_SWA.png"}, {"analysis": "This bar chart compares the ground truth and predicted label distributions for the final epoch. The predicted distribution closely matches the ground truth, indicating that the model has learned the underlying patterns effectively. However, there is a slight underestimation of Label ID 0 and an overestimation of Label ID 1, which suggests a minor bias in the predictions that may require further investigation.", "plot_path": "experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_d5fd905b777f435abca27b171b4f8fa8_proc_2952777/SPR_BENCH_CLS-Token-Pooling_final_epoch_hist.png"}], []], "vlm_feedback_summary": ["The plots indicate that the model is learning effectively and generalizing well\nto unseen data. The loss curves show no signs of overfitting, and the validation\nSWA is consistently high, demonstrating the model's strong performance in shape-\nweighted reasoning tasks.", "The plots indicate that the model performs well in terms of both loss\nminimization and accuracy metrics. The training and validation losses converge\nwithout overfitting, and the SWA metric achieves a high and stable value. The\nconfusion matrix highlights strong classification performance with minor areas\nfor improvement in false positive reduction.", "[]", "The plots indicate that the model achieves effective learning with minimal\noverfitting, as evidenced by the decreasing and stabilizing loss curves. The\nvalidation SWA demonstrates rapid improvement and stability, suggesting strong\ngeneralization capabilities. The confusion matrix highlights robust\nclassification performance with low error rates, particularly no false\nnegatives, which is a significant strength.", "The plots indicate that the model is learning effectively, with a steady\ndecrease in loss and stabilization in Shape-Weighted Accuracy. The results\nsuggest good generalization and minimal overfitting.", "The analysis of the provided plots indicates effective training and validation\nprocesses, with the model achieving high accuracy and minimal\nmisclassifications. The results suggest that the neural-symbolic integration\napproach is successful in generalizing to unseen tasks, as evidenced by the\nstable loss trends, high SWA, and the confusion matrix.", "The experimental results demonstrate effective learning and generalization\ncapabilities of the model. The metrics stabilize early, indicating efficient\ntraining, but the confusion matrix highlights areas for improvement in reducing\nmisclassifications.", "The plots demonstrate effective training and validation dynamics for the CLS-\nToken-Pooling model on the SPR_BENCH dataset. The rapid convergence of loss and\nSWA indicates robust learning, while the label distribution plot highlights a\nminor prediction bias that could be refined for better performance.", "[]", "The provided plots demonstrate effective learning and convergence of the CLS-\nToken-Pooling model on the SPR_BENCH dataset. The training and validation losses\nstabilize early, indicating good generalization. The validation SWA shows rapid\nimprovement and remains consistent, highlighting the model's shape-based\nreasoning capability. The final label distribution suggests balanced predictions\nwith a minor bias toward one class.", "The plots demonstrate effective model training and generalization, with the\nvalidation loss stabilizing early and high Shape-Weighted Accuracy achieved. The\nlabel distribution suggests good calibration but highlights a slight imbalance\nin predictions that could be addressed.", "The plots demonstrate effective training and validation performance, with stable\nloss and high accuracy metrics. The model shows good generalization and\nalignment with ground truth distributions, though minor biases in predictions\nare observed.", "[]"], "exec_time": [16.92879343032837, 18.561155796051025, 5.795737266540527, 21.879558086395264, 18.59573197364807, 15.37061357498169, 14.169663906097412, 36.942070722579956, 2.747981071472168, 31.285596132278442, 30.70683526992798, 29.969895601272583, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["['all_datasets_tested']"], ["['SPR_BENCH']"], [], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"experiment_data\"]"], ["['SPR_BENCH']"], [], ["['SPR_BENCH']"], ["['CLS-Token-Pooling']"], ["['dset_name']"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# helper ------------------------------------------------------------\ndef _count_shape(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [_count_shape(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# iterate over datasets --------------------------------------------\nfor ds_name, ds_data in experiment_data.items():\n    epochs = np.arange(1, len(ds_data[\"losses\"][\"train\"]) + 1)\n\n    # -------------- plot 1: loss curves ---------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ds_data[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(epochs, ds_data[\"losses\"][\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{ds_name}: Training vs Validation Loss\\nDataset: {ds_name}\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{ds_name}_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds_name}: {e}\")\n        plt.close()\n\n    # -------------- plot 2: validation SWA -----------------------\n    try:\n        val_swa = ds_data[\"metrics\"][\"val\"]\n        plt.figure()\n        plt.plot(epochs, val_swa, marker=\"o\", label=\"Validation SWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(f\"{ds_name}: Validation SWA Across Epochs\\nDataset: {ds_name}\")\n        plt.ylim(0, 1.05)\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{ds_name}_val_SWA.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot for {ds_name}: {e}\")\n        plt.close()\n\n    # -------------- evaluation printout --------------------------\n    try:\n        # best epoch based on stored SWA\n        swa_vals = np.array(\n            [v if v is not None else -1 for v in ds_data[\"metrics\"][\"val\"]]\n        )\n        best_idx = int(np.argmax(swa_vals))\n        preds = ds_data[\"predictions\"][best_idx]\n        gts = ds_data[\"ground_truth\"][best_idx]\n        # raw sequences were not stored for val set; reuse stored metric value\n        best_swa = swa_vals[best_idx]\n        # guard: if raw sequences available, recompute\n        if \"raw_seqs\" in ds_data:\n            best_swa = shape_weighted_accuracy(\n                ds_data[\"raw_seqs\"][best_idx], gts, preds\n            )\n        print(f\"{ds_name}: best Validation SWA={best_swa:.4f} at epoch {best_idx+1}\")\n    except Exception as e:\n        print(f\"Error computing best SWA for {ds_name}: {e}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exit(0)\n\n# Navigate to the only run we have\ntry:\n    d = experiment_data[\"no_symbolic_features\"][\"SPR_BENCH\"]\n    epochs = np.array(d[\"epochs\"])\n    train_loss = np.array(d[\"losses\"][\"train\"])\n    val_loss = np.array(d[\"losses\"][\"val\"])\n    val_swa = np.array(d[\"metrics\"][\"val\"])\n    y_true = np.array(d[\"ground_truth\"][-1])\n    y_pred = np.array(d[\"predictions\"][-1])\nexcept Exception as e:\n    print(f\"Error extracting data: {e}\")\n    exit(0)\n\n# -------------------------------------------------------------------------\n# 1) Loss curves\ntry:\n    plt.figure()\n    plt.plot(epochs, train_loss, label=\"Train Loss\")\n    plt.plot(epochs, val_loss, label=\"Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curve.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# -------------------------------------------------------------------------\n# 2) Validation SWA\ntry:\n    plt.figure()\n    plt.plot(epochs, val_swa, marker=\"o\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Shape-Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: Validation SWA over Epochs\")\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_SWA_curve.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA curve: {e}\")\n    plt.close()\n\n# -------------------------------------------------------------------------\n# 3) Confusion matrix for final epoch\ntry:\n    # Compute 2x2 confusion counts\n    num_cls = len(np.unique(np.concatenate([y_true, y_pred])))\n    cm = np.zeros((num_cls, num_cls), dtype=int)\n    for t, p in zip(y_true, y_pred):\n        cm[t, p] += 1\n\n    plt.figure()\n    im = plt.imshow(cm, cmap=\"Blues\")\n    plt.colorbar(im)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(\"SPR_BENCH: Confusion Matrix (Final Epoch)\")\n    for i in range(num_cls):\n        for j in range(num_cls):\n            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    exp = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    log = exp[\"no_interaction_symbolic\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    log = None\n\nsaved = []\nif log:\n    epochs = log[\"epochs\"]\n    tr_loss = log[\"losses\"][\"train\"]\n    va_loss = log[\"losses\"][\"val\"]\n    val_swa = log[\"metrics\"][\"val\"]\n    preds = log[\"predictions\"]\n    gts = log[\"ground_truth\"]\n    # best epoch idx\n    best_idx = int(np.argmin(va_loss))\n\n    # 1) loss curves\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_loss, label=\"Train Loss\")\n        plt.plot(epochs, va_loss, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH \u2014 Training vs Validation Loss\")\n        plt.legend()\n        f = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(f)\n        saved.append(f)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curves: {e}\")\n        plt.close()\n\n    # 2) validation accuracy curve\n    try:\n        plt.figure()\n        plt.plot(epochs, val_swa, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(\"SPR_BENCH \u2014 Validation SWA Across Epochs\")\n        f = os.path.join(working_dir, \"SPR_BENCH_val_SWA.png\")\n        plt.savefig(f)\n        saved.append(f)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot: {e}\")\n        plt.close()\n\n    # 3) confusion matrix at best epoch\n    try:\n        y_true = np.array(gts[best_idx])\n        y_pred = np.array(preds[best_idx])\n        n_cls = len(set(y_true) | set(y_pred))\n        cm = np.zeros((n_cls, n_cls), int)\n        for t, p in zip(y_true, y_pred):\n            cm[t, p] += 1\n\n        plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        for i in range(n_cls):\n            for j in range(n_cls):\n                plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n        plt.title(f\"SPR_BENCH \u2014 Confusion Matrix (Best Epoch {epochs[best_idx]})\")\n        f = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n        plt.savefig(f)\n        saved.append(f)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\nprint(\"Saved figures:\", saved)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --------------------------------------------------------------------------- #\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# Helper to safely fetch nested keys\ndef _get(dic, *keys, default=None):\n    for k in keys:\n        dic = dic.get(k, {})\n    return dic if dic else default\n\n\nrun = _get(experiment_data, \"bag_of_embeddings\", \"SPR_BENCH\", default={})\nepochs = np.array(run.get(\"epochs\", []))\ntrain_loss = np.array(run.get(\"losses\", {}).get(\"train\", []))\nval_loss = np.array(run.get(\"losses\", {}).get(\"val\", []))\nval_metric = np.array(run.get(\"metrics\", {}).get(\"val\", []))\n\n# --------------------------------------------------------------------------- #\n# Plot 1: Training & Validation Loss\ntry:\n    if epochs.size and train_loss.size and val_loss.size:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train Loss\")\n        plt.plot(epochs, val_loss, label=\"Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# --------------------------------------------------------------------------- #\n# Plot 2: Validation Shape-Weighted-Accuracy\ntry:\n    if epochs.size and val_metric.size:\n        plt.figure()\n        plt.plot(epochs, val_metric, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted-Accuracy\")\n        plt.title(\"SPR_BENCH Validation SWA over Epochs\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_val_SWA.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# Extract data\ntry:\n    d = experiment_data[\"Frozen-Random-Embeddings\"][\"SPR_BENCH\"]\n    epochs = d[\"epochs\"]\n    train_losses = d[\"losses\"][\"train\"]\n    val_losses = d[\"losses\"][\"val\"]\n    val_swa = d[\"metrics\"][\"val\"]\n    preds_all = d[\"predictions\"]\n    gts_all = d[\"ground_truth\"]\nexcept Exception as e:\n    print(f\"Error extracting data: {e}\")\n    d, epochs, train_losses, val_losses, val_swa, preds_all, gts_all = (\n        {},\n        [],\n        [],\n        [],\n        [],\n        [],\n        [],\n    )\n\n# Figure 1: loss curves\ntry:\n    plt.figure()\n    plt.plot(epochs, train_losses, label=\"Train Loss\")\n    plt.plot(epochs, val_losses, label=\"Val Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH \u2013 Training vs Validation Loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# Figure 2: validation SWA curve\ntry:\n    plt.figure()\n    plt.plot(epochs, val_swa, marker=\"o\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Shape-Weighted Accuracy (SWA)\")\n    plt.title(\"SPR_BENCH \u2013 Validation SWA\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_SWA_curve.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA plot: {e}\")\n    plt.close()\n\n# Figure 3: confusion matrix at best epoch\ntry:\n    best_idx = int(np.argmin(val_losses))\n    y_true = np.array(gts_all[best_idx])\n    y_pred = np.array(preds_all[best_idx])\n    n_cls = len(np.unique(np.concatenate([y_true, y_pred])))\n    cm = np.zeros((n_cls, n_cls), dtype=int)\n    for t, p in zip(y_true, y_pred):\n        cm[t, p] += 1\n    plt.figure()\n    im = plt.imshow(cm, cmap=\"Blues\")\n    plt.colorbar(im)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(f\"SPR_BENCH \u2013 Confusion Matrix (Best Epoch {epochs[best_idx]})\")\n    for i in range(n_cls):\n        for j in range(n_cls):\n            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n    plt.tight_layout()\n    fname = f\"SPR_BENCH_confusion_matrix_epoch{epochs[best_idx]}.png\"\n    plt.savefig(os.path.join(working_dir, fname))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nfor dset, rec in experiment_data.items():\n    epochs = np.array(rec.get(\"epochs\", []))\n    train_l = np.array(rec.get(\"losses\", {}).get(\"train\", []), dtype=float)\n    val_l = np.array(rec.get(\"losses\", {}).get(\"val\", []), dtype=float)\n    swa = np.array(\n        [m[\"SWA\"] if m else np.nan for m in rec.get(\"metrics\", {}).get(\"val\", [])],\n        dtype=float,\n    )\n    nwa = np.array(\n        [m[\"NWA\"] if m else np.nan for m in rec.get(\"metrics\", {}).get(\"val\", [])],\n        dtype=float,\n    )\n    preds = rec.get(\"predictions\", [])[-1] if rec.get(\"predictions\") else None\n    gts = rec.get(\"ground_truth\", [])[-1] if rec.get(\"ground_truth\") else None\n\n    # -------- 1. loss curves -------------------------------------------------\n    try:\n        if len(epochs):\n            plt.figure()\n            if len(train_l):\n                plt.plot(epochs, train_l, label=\"Train Loss\")\n            if len(val_l):\n                plt.plot(epochs, val_l, label=\"Val Loss\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{dset} \u2013 Training vs Validation Loss\")\n            plt.legend()\n            plt.tight_layout()\n            fname = os.path.join(working_dir, f\"{dset}_loss_curve.png\")\n            plt.savefig(fname)\n            print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error plotting loss for {dset}: {e}\")\n        plt.close()\n\n    # -------- 2. SWA curve ---------------------------------------------------\n    try:\n        if len(epochs) and not np.isnan(swa).all():\n            plt.figure()\n            plt.plot(epochs, swa, marker=\"o\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Shape-Weighted Accuracy\")\n            plt.title(f\"{dset} \u2013 Validation SWA over Epochs\")\n            plt.tight_layout()\n            fname = os.path.join(working_dir, f\"{dset}_SWA_curve.png\")\n            plt.savefig(fname)\n            print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error plotting SWA for {dset}: {e}\")\n        plt.close()\n\n    # -------- 3. NWA curve ---------------------------------------------------\n    try:\n        if len(epochs) and not np.isnan(nwa).all():\n            plt.figure()\n            plt.plot(epochs, nwa, marker=\"o\", color=\"green\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Novelty-Weighted Accuracy\")\n            plt.title(f\"{dset} \u2013 Validation NWA over Epochs\")\n            plt.tight_layout()\n            fname = os.path.join(working_dir, f\"{dset}_NWA_curve.png\")\n            plt.savefig(fname)\n            print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error plotting NWA for {dset}: {e}\")\n        plt.close()\n\n    # -------- 4. Confusion matrix (last epoch) ------------------------------\n    try:\n        if preds is not None and gts is not None:\n            preds = np.array(preds)\n            gts = np.array(gts)\n            n_cls = max(preds.max(), gts.max()) + 1\n            cm = np.zeros((n_cls, n_cls), dtype=int)\n            for t, p in zip(gts, preds):\n                cm[t, p] += 1\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(f\"{dset} \u2013 Confusion Matrix (Last Epoch)\")\n            for i in range(n_cls):\n                for j in range(n_cls):\n                    plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n            plt.tight_layout()\n            fname = os.path.join(working_dir, f\"{dset}_confusion_matrix.png\")\n            plt.savefig(fname)\n            print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error plotting confusion matrix for {dset}: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# ----------------------------------------------------------------------\n# Helper to fetch the single (model, dataset) entry\ndef _get_entry(edict):\n    for model_k, model_v in edict.items():\n        for dset_k, dset_v in model_v.items():\n            return model_k, dset_k, dset_v\n    return None, None, None\n\n\nmodel_name, dset_name, ed = _get_entry(experiment_data)\n\nif ed is None:\n    print(\"No experiment data found, nothing to plot.\")\nelse:\n    epochs = np.array(ed[\"epochs\"])\n    train_loss = np.array(ed[\"losses\"][\"train\"])\n    val_loss = np.array(ed[\"losses\"][\"val\"])\n    val_swa = np.array(ed[\"metrics\"][\"val\"])\n    # guard against None values that may appear in metrics\n    val_swa = np.where(val_swa == None, np.nan, val_swa.astype(float))\n\n    # ---------------- Plot 1: Loss curves ------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train Loss\")\n        plt.plot(epochs, val_loss, label=\"Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dset_name}: Train vs Val Loss ({model_name})\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dset_name}_{model_name}_loss_curves.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ---------------- Plot 2: Validation SWA ---------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_swa, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(f\"{dset_name}: Validation SWA ({model_name})\")\n        plt.savefig(os.path.join(working_dir, f\"{dset_name}_{model_name}_val_SWA.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot: {e}\")\n        plt.close()\n\n    # ---------------- Plot 3: Final epoch prediction histogram ---------\n    try:\n        final_gt = ed[\"ground_truth\"][-1]\n        final_pred = ed[\"predictions\"][-1]\n        labels = sorted(set(final_gt) | set(final_pred))\n        gt_counts = [final_gt.count(l) for l in labels]\n        pr_counts = [final_pred.count(l) for l in labels]\n\n        x = np.arange(len(labels))\n        width = 0.35\n        plt.figure()\n        plt.bar(x - width / 2, gt_counts, width, label=\"Ground Truth\")\n        plt.bar(x + width / 2, pr_counts, width, label=\"Predicted\")\n        plt.xlabel(\"Label ID\")\n        plt.ylabel(\"Count\")\n        plt.title(f\"{dset_name}: Final Epoch Label Distribution ({model_name})\")\n        plt.xticks(x, labels)\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dset_name}_{model_name}_final_epoch_hist.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating histogram plot: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Print summary metrics\n    try:\n        best_idx = np.nanargmin(val_loss)\n        best_val_loss = val_loss[best_idx]\n        best_swa = val_swa[best_idx]\n        print(f\"Best Validation Loss: {best_val_loss:.4f} at epoch {epochs[best_idx]}\")\n        print(f\"Corresponding Validation SWA: {best_swa:.4f}\")\n    except Exception as e:\n        print(f\"Error computing summary metrics: {e}\")\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# ----------------------------------------------------------------------\n# Helper to fetch the single (model, dataset) entry\ndef _get_entry(edict):\n    for model_k, model_v in edict.items():\n        for dset_k, dset_v in model_v.items():\n            return model_k, dset_k, dset_v\n    return None, None, None\n\n\nmodel_name, dset_name, ed = _get_entry(experiment_data)\n\nif ed is None:\n    print(\"No experiment data found, nothing to plot.\")\nelse:\n    epochs = np.array(ed[\"epochs\"])\n    train_loss = np.array(ed[\"losses\"][\"train\"])\n    val_loss = np.array(ed[\"losses\"][\"val\"])\n    val_swa = np.array(ed[\"metrics\"][\"val\"])\n    # guard against None values that may appear in metrics\n    val_swa = np.where(val_swa == None, np.nan, val_swa.astype(float))\n\n    # ---------------- Plot 1: Loss curves ------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train Loss\")\n        plt.plot(epochs, val_loss, label=\"Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dset_name}: Train vs Val Loss ({model_name})\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dset_name}_{model_name}_loss_curves.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ---------------- Plot 2: Validation SWA ---------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_swa, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(f\"{dset_name}: Validation SWA ({model_name})\")\n        plt.savefig(os.path.join(working_dir, f\"{dset_name}_{model_name}_val_SWA.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot: {e}\")\n        plt.close()\n\n    # ---------------- Plot 3: Final epoch prediction histogram ---------\n    try:\n        final_gt = ed[\"ground_truth\"][-1]\n        final_pred = ed[\"predictions\"][-1]\n        labels = sorted(set(final_gt) | set(final_pred))\n        gt_counts = [final_gt.count(l) for l in labels]\n        pr_counts = [final_pred.count(l) for l in labels]\n\n        x = np.arange(len(labels))\n        width = 0.35\n        plt.figure()\n        plt.bar(x - width / 2, gt_counts, width, label=\"Ground Truth\")\n        plt.bar(x + width / 2, pr_counts, width, label=\"Predicted\")\n        plt.xlabel(\"Label ID\")\n        plt.ylabel(\"Count\")\n        plt.title(f\"{dset_name}: Final Epoch Label Distribution ({model_name})\")\n        plt.xticks(x, labels)\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dset_name}_{model_name}_final_epoch_hist.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating histogram plot: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Print summary metrics\n    try:\n        best_idx = np.nanargmin(val_loss)\n        best_val_loss = val_loss[best_idx]\n        best_swa = val_swa[best_idx]\n        print(f\"Best Validation Loss: {best_val_loss:.4f} at epoch {epochs[best_idx]}\")\n        print(f\"Corresponding Validation SWA: {best_swa:.4f}\")\n    except Exception as e:\n        print(f\"Error computing summary metrics: {e}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# ----------------------------------------------------------------------\n# Helper to fetch the single (model, dataset) entry\ndef _get_entry(edict):\n    for model_k, model_v in edict.items():\n        for dset_k, dset_v in model_v.items():\n            return model_k, dset_k, dset_v\n    return None, None, None\n\n\nmodel_name, dset_name, ed = _get_entry(experiment_data)\n\nif ed is None:\n    print(\"No experiment data found, nothing to plot.\")\nelse:\n    epochs = np.array(ed[\"epochs\"])\n    train_loss = np.array(ed[\"losses\"][\"train\"])\n    val_loss = np.array(ed[\"losses\"][\"val\"])\n    val_swa = np.array(ed[\"metrics\"][\"val\"])\n    # guard against None values that may appear in metrics\n    val_swa = np.where(val_swa == None, np.nan, val_swa.astype(float))\n\n    # ---------------- Plot 1: Loss curves ------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train Loss\")\n        plt.plot(epochs, val_loss, label=\"Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dset_name}: Train vs Val Loss ({model_name})\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dset_name}_{model_name}_loss_curves.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ---------------- Plot 2: Validation SWA ---------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_swa, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(f\"{dset_name}: Validation SWA ({model_name})\")\n        plt.savefig(os.path.join(working_dir, f\"{dset_name}_{model_name}_val_SWA.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot: {e}\")\n        plt.close()\n\n    # ---------------- Plot 3: Final epoch prediction histogram ---------\n    try:\n        final_gt = ed[\"ground_truth\"][-1]\n        final_pred = ed[\"predictions\"][-1]\n        labels = sorted(set(final_gt) | set(final_pred))\n        gt_counts = [final_gt.count(l) for l in labels]\n        pr_counts = [final_pred.count(l) for l in labels]\n\n        x = np.arange(len(labels))\n        width = 0.35\n        plt.figure()\n        plt.bar(x - width / 2, gt_counts, width, label=\"Ground Truth\")\n        plt.bar(x + width / 2, pr_counts, width, label=\"Predicted\")\n        plt.xlabel(\"Label ID\")\n        plt.ylabel(\"Count\")\n        plt.title(f\"{dset_name}: Final Epoch Label Distribution ({model_name})\")\n        plt.xticks(x, labels)\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dset_name}_{model_name}_final_epoch_hist.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating histogram plot: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Print summary metrics\n    try:\n        best_idx = np.nanargmin(val_loss)\n        best_val_loss = val_loss[best_idx]\n        best_swa = val_swa[best_idx]\n        print(f\"Best Validation Loss: {best_val_loss:.4f} at epoch {epochs[best_idx]}\")\n        print(f\"Corresponding Validation SWA: {best_swa:.4f}\")\n    except Exception as e:\n        print(f\"Error computing summary metrics: {e}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# ----------------------------------------------------------------------\n# Helper to fetch the single (model, dataset) entry\ndef _get_entry(edict):\n    for model_k, model_v in edict.items():\n        for dset_k, dset_v in model_v.items():\n            return model_k, dset_k, dset_v\n    return None, None, None\n\n\nmodel_name, dset_name, ed = _get_entry(experiment_data)\n\nif ed is None:\n    print(\"No experiment data found, nothing to plot.\")\nelse:\n    epochs = np.array(ed[\"epochs\"])\n    train_loss = np.array(ed[\"losses\"][\"train\"])\n    val_loss = np.array(ed[\"losses\"][\"val\"])\n    val_swa = np.array(ed[\"metrics\"][\"val\"])\n    # guard against None values that may appear in metrics\n    val_swa = np.where(val_swa == None, np.nan, val_swa.astype(float))\n\n    # ---------------- Plot 1: Loss curves ------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train Loss\")\n        plt.plot(epochs, val_loss, label=\"Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dset_name}: Train vs Val Loss ({model_name})\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dset_name}_{model_name}_loss_curves.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ---------------- Plot 2: Validation SWA ---------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_swa, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(f\"{dset_name}: Validation SWA ({model_name})\")\n        plt.savefig(os.path.join(working_dir, f\"{dset_name}_{model_name}_val_SWA.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot: {e}\")\n        plt.close()\n\n    # ---------------- Plot 3: Final epoch prediction histogram ---------\n    try:\n        final_gt = ed[\"ground_truth\"][-1]\n        final_pred = ed[\"predictions\"][-1]\n        labels = sorted(set(final_gt) | set(final_pred))\n        gt_counts = [final_gt.count(l) for l in labels]\n        pr_counts = [final_pred.count(l) for l in labels]\n\n        x = np.arange(len(labels))\n        width = 0.35\n        plt.figure()\n        plt.bar(x - width / 2, gt_counts, width, label=\"Ground Truth\")\n        plt.bar(x + width / 2, pr_counts, width, label=\"Predicted\")\n        plt.xlabel(\"Label ID\")\n        plt.ylabel(\"Count\")\n        plt.title(f\"{dset_name}: Final Epoch Label Distribution ({model_name})\")\n        plt.xticks(x, labels)\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dset_name}_{model_name}_final_epoch_hist.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating histogram plot: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Print summary metrics\n    try:\n        best_idx = np.nanargmin(val_loss)\n        best_val_loss = val_loss[best_idx]\n        best_swa = val_swa[best_idx]\n        print(f\"Best Validation Loss: {best_val_loss:.4f} at epoch {epochs[best_idx]}\")\n        print(f\"Corresponding Validation SWA: {best_swa:.4f}\")\n    except Exception as e:\n        print(f\"Error computing summary metrics: {e}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------------------------------------------------------------\n# Collect every experiment_data.npy supplied by the host\nexperiment_data_path_list = [\n    \"experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_845932789bf54c1a970c17933c0314ec_proc_2952779/experiment_data.npy\",\n    \"experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7b944347b81c460387c55a55dfe4564d_proc_2952778/experiment_data.npy\",\n    \"experiments/2025-08-15_16-42-50_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_d5fd905b777f435abca27b171b4f8fa8_proc_2952777/experiment_data.npy\",\n]\n\nall_experiment_data = []\nfor rel_path in experiment_data_path_list:\n    try:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), rel_path)\n        ed = np.load(full_path, allow_pickle=True).item()\n        all_experiment_data.append(ed)\n    except Exception as e:\n        print(f\"Error loading {rel_path}: {e}\")\n\n\n# ----------------------------------------------------------------------\n# Helper to flatten entries into a dict keyed by (model, dataset)\ndef _flatten_entries(edict):\n    out = {}\n    for model_k, model_v in edict.items():\n        for dset_k, dset_v in model_v.items():\n            out.setdefault((model_k, dset_k), []).append(dset_v)\n    return out\n\n\ngrouped_runs = {}\nfor exp in all_experiment_data:\n    grouped = _flatten_entries(exp)\n    for k, v in grouped.items():\n        grouped_runs.setdefault(k, []).extend(v)\n\nif not grouped_runs:\n    print(\"No experiment data found, nothing to aggregate.\")\n# ----------------------------------------------------------------------\nfor (model_name, dset_name), runs in grouped_runs.items():\n    # Collect arrays; first infer global epoch grid (assume identical grids)\n    epoch_lists = [np.array(r[\"epochs\"]) for r in runs]\n    # Use the shortest epoch array length to align\n    min_len = min(len(e) for e in epoch_lists)\n    epochs = epoch_lists[0][:min_len]\n\n    def _stack(key_path):\n        arrs = []\n        for r in runs:\n            a = r\n            for k in key_path:\n                a = a[k]\n            arrs.append(np.array(a)[:min_len])\n        return np.vstack(arrs).astype(float)\n\n    train_stack = _stack([\"losses\", \"train\"])\n    val_stack = _stack([\"losses\", \"val\"])\n    swa_stack = _stack([\"metrics\", \"val\"])\n\n    # Mean and SEM\n    def mean_sem(stack):\n        mean = np.nanmean(stack, axis=0)\n        sem = np.nanstd(stack, axis=0, ddof=1) / np.sqrt(stack.shape[0])\n        return mean, sem\n\n    train_mean, train_sem = mean_sem(train_stack)\n    val_mean, val_sem = mean_sem(val_stack)\n    swa_mean, swa_sem = mean_sem(swa_stack)\n\n    # ------------------- Plot 1: Loss curves (mean \u00b1 SEM) ----------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_mean, label=\"Train Loss (mean)\", color=\"tab:blue\")\n        plt.fill_between(\n            epochs,\n            train_mean - train_sem,\n            train_mean + train_sem,\n            alpha=0.3,\n            color=\"tab:blue\",\n            label=\"Train Loss (SEM)\",\n        )\n        plt.plot(epochs, val_mean, label=\"Val Loss (mean)\", color=\"tab:orange\")\n        plt.fill_between(\n            epochs,\n            val_mean - val_sem,\n            val_mean + val_sem,\n            alpha=0.3,\n            color=\"tab:orange\",\n            label=\"Val Loss (SEM)\",\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dset_name}: Train vs Val Loss (mean \u00b1 SEM) [{model_name}]\")\n        plt.legend()\n        fname = f\"{dset_name}_{model_name}_AGG_loss_mean_sem.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated loss plot for {dset_name}: {e}\")\n        plt.close()\n\n    # --------------- Plot 2: Validation SWA (mean \u00b1 SEM) -----------------\n    try:\n        plt.figure()\n        plt.plot(\n            epochs, swa_mean, marker=\"o\", label=\"Val SWA (mean)\", color=\"tab:green\"\n        )\n        plt.fill_between(\n            epochs,\n            swa_mean - swa_sem,\n            swa_mean + swa_sem,\n            alpha=0.3,\n            color=\"tab:green\",\n            label=\"Val SWA (SEM)\",\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(f\"{dset_name}: Validation SWA (mean \u00b1 SEM) [{model_name}]\")\n        plt.legend()\n        fname = f\"{dset_name}_{model_name}_AGG_val_SWA_mean_sem.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated SWA plot for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------------- Optional Histogram snapshots --------------------\n    # Plot at no more than 5 evenly spaced epochs (including last)\n    try:\n        num_snaps = min(5, len(epochs))\n        snap_indices = np.linspace(0, len(epochs) - 1, num_snaps, dtype=int)\n        for idx in snap_indices:\n            # Each run\u2019s prediction counts; average across runs\n            label_counts = {}\n            for r in runs:\n                gt = r[\"ground_truth\"][idx]\n                pr = r[\"predictions\"][idx]\n                labels = set(gt) | set(pr)\n                for l in labels:\n                    label_counts.setdefault(l, {\"gt\": [], \"pr\": []})\n                    label_counts[l][\"gt\"].append(gt.count(l))\n                    label_counts[l][\"pr\"].append(pr.count(l))\n            labels_sorted = sorted(label_counts.keys())\n            gt_means = [np.mean(label_counts[l][\"gt\"]) for l in labels_sorted]\n            pr_means = [np.mean(label_counts[l][\"pr\"]) for l in labels_sorted]\n\n            x = np.arange(len(labels_sorted))\n            width = 0.35\n            plt.figure()\n            plt.bar(x - width / 2, gt_means, width, label=\"Ground Truth (mean)\")\n            plt.bar(x + width / 2, pr_means, width, label=\"Predicted (mean)\")\n            plt.xlabel(\"Label ID\")\n            plt.ylabel(\"Mean Count\")\n            plt.title(\n                f\"{dset_name}: Label Dist. Epoch {epochs[idx]} (mean of runs) [{model_name}]\"\n            )\n            plt.xticks(x, labels_sorted)\n            plt.legend()\n            fname = f\"{dset_name}_{model_name}_AGG_hist_epoch{epochs[idx]}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating histogram snapshots for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------------- Print summary metrics ---------------------------\n    try:\n        best_idx = np.nanargmin(val_mean)\n        best_val_loss = val_mean[best_idx]\n        best_swa = swa_mean[best_idx]\n        print(\n            f\"[{model_name} | {dset_name}] Best mean Val Loss={best_val_loss:.4f} \"\n            f\"at epoch {int(epochs[best_idx])} | Mean SWA={best_swa:.4f}\"\n        )\n    except Exception as e:\n        print(f\"Error computing summary metrics for {dset_name}: {e}\")\n"], "plot_plan": ["We load experiment_data.npy, iterate through each dataset key (here likely only \u2018SPR_BENCH\u2019), and extract stored training/validation losses, validation Shape-Weighted Accuracy (SWA), predictions and ground-truth sequences. For every dataset we create at most two figures: (1) Training vs. validation loss across epochs and (2) validation SWA across epochs. Each figure is wrapped in its own try-except block, given a clear title, saved to working_dir with a descriptive filename, and closed. To avoid clutter we plot all epochs because the run is short, but if the epoch count exceeds 50 we sample five evenly-spaced points. After plotting we identify the epoch that achieved the highest SWA, recompute that epoch\u2019s SWA via the helper function for safety, and print it. All code follows the required imports, uses only existing data, respects the naming guidelines, and prints the final best metric per dataset.", "We first load the saved experiment_data.npy and extract the entry corresponding to the \u201cno_symbolic_features / SPR_BENCH\u201d run. From it we pull epoch indices, the train/val loss lists, the validation Shape-Weighted Accuracy (SWA) list, and the ground-truth / prediction arrays for the last epoch. We create three separate plots inside independent try-except blocks: (1) a line plot comparing train and validation losses across epochs, (2) a line plot of validation SWA across epochs, and (3) a 2\u00d72 confusion-matrix heatmap for the final epoch. Each figure is given a clear title and saved to working_dir with descriptive filenames; we always close figures even when exceptions occur. We respect the \u201cat most 5 figures\u201d rule by limiting ourselves to these three plots. The code begins with the required imports, recreates working_dir, and contains concise logic. If experiment_data.npy cannot be loaded, the script will print an informative message and exit gracefully without plotting.", null, "We will load the serialized experiment_data.npy, pull out the arrays stored under the key path [\"no_interaction_symbolic\"][\"SPR_BENCH\"], and derive three simple visualizations: (1) training vs validation loss across epochs, (2) validation shape-weighted accuracy across epochs, and (3) a 2 \u00d7 2 confusion-matrix heat-map for the epoch with the lowest validation loss.  Each figure is wrapped in its own try-except so a failure in one plot does not interrupt the others, figures are given clear titles/subtitles, saved with descriptive names to working_dir, and always closed.  We limit to these three plots (<<5) so we satisfy the \u201cat most five\u201d rule.  Only data present in experiment_data is used\u2014no synthetic values.  The code is concise, uses base matplotlib, and prints nothing except possible error messages and the final path list of saved figures.", "We load the saved experiment_data.npy, extract the dictionary for the single run (model \u201cbag_of_embeddings\u201d, dataset \u201cSPR_BENCH\u201d), and pull out arrays of epochs, training losses, validation losses, and validation Shape-Weighted-Accuracy. Two separate figures are produced: (1) a line plot of training and validation losses across epochs, and (2) a line plot of validation SWA across epochs. Each figure is wrapped in an independent try-except block to guarantee graceful failure and figure closure. Figures receive informative titles and axis labels, and are saved into the predefined working_dir with descriptive filenames that include the dataset and plot type. We adhere strictly to the data stored in experiment_data.npy\u2014no synthetic values are introduced. All matplotlib figures are closed after saving to prevent memory leaks. Finally, the script prints basic confirmation messages so the user knows where plots are stored. No additional plots are created, keeping the total below the five-figure limit.", "We will load the saved dictionary from working/experiment_data.npy, extract the \u201cSPR_BENCH\u201d entry under the \u201cFrozen-Random-Embeddings\u201d experiment, and pull out the epoch numbers, training/validation losses, validation shape-weighted accuracies (SWA), and the lists of predictions/ground-truth.  \nThree figures will be generated (\u22645 as required): (1) a line plot of training vs validation loss across epochs, (2) a line plot of validation SWA across epochs, and (3) a confusion-matrix heat-map for the best epoch (minimum validation loss).  \nEach figure is produced inside its own try-except block, saved to the working directory with descriptive filenames containing the dataset name and plot type, titled appropriately, and the figure is closed afterward.  \nWe respect the \u201conly plot existing data\u201d rule by computing everything directly from the loaded dictionary and never fabricating values.  \nPlots use plain matplotlib; no custom styles.  \nThe code starts with the mandated imports, defines working_dir, ensures the folder exists, loads the .npy file, extracts the needed arrays, computes the best epoch index, builds a 2\u00d72 confusion matrix from id2label length, and finally saves the figures.  \nAll steps follow the guidelines on naming, intervals (all epochs are fine because \u226420), figure closing, and error handling.", "We will load experiment_data.npy from the working directory and iterate through every dataset key it contains.  For each dataset we extract the epoch indices, training losses, validation losses, and the validation SWA and NWA metrics that were stored during training.  In separate try-except blocks we create: (1) a line plot comparing training and validation losses over epochs; (2) a line plot for validation SWA across epochs; (3) a line plot for validation NWA across epochs; and (4) a confusion-matrix heat-map for the last saved epoch (using the final ground-truth and prediction arrays).  Every figure is given a concise, descriptive title and saved into the pre-defined working_dir with the dataset name embedded in the filename.  We make sure to close each figure in both success and failure paths to avoid memory leaks.  If any element (e.g. metrics, predictions) is missing we simply skip that particular plot while continuing with the others.  Finally, the script prints a short confirmation message after each successful save so users know which plots were created.", "We will load the stored experiment_data.npy, automatically detect the available model/dataset entry, and extract epoch indices, training/validation losses, and validation Shape-Weighted Accuracy (SWA). We then produce up to three clear plots: (1) training vs. validation loss over epochs, (2) validation SWA over epochs, and (3) a simple confusion-style bar chart comparing ground-truth and predicted label counts from the final saved epoch. Each plot is wrapped in its own try-except block, saved with descriptive filenames in working_dir, and the figure is closed afterwards. Finally, we compute and print the best validation loss and the corresponding maximum SWA so they can be inspected in notebook logs.", null, null, null, null, null], "ablation_name": [null, "No-Symbolic-Features (Pure Transformer Baseline)", "Symbolic-Only (Transformer Removed)", "No-Interaction\u2010Symbolic (Drop n_shape \u00d7 n_color Feature)", "Bag-of-Embeddings (Transformer-Encoder Removed)", "Frozen-Random-Embeddings", null, "CLS-Token-Pooling (Mean Pooling Removed)", null, null, null, null, null], "hyperparam_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["The script will locate the \u201cworking\u201d directory, load the saved NumPy dictionary,\nand iterate over each stored dataset (e.g., \u201cSPR_BENCH\u201d).   For each dataset it\nwill extract the lists that hold training losses, validation losses, and\nvalidation Shape-Weighted Accuracy (SWA).   The code will then compute the final\ntraining loss (last epoch), the best (minimum) validation loss, and the best\n(maximum) validation SWA, printing each value with explicit metric names\npreceded by the dataset name.   No plots are generated and everything runs\nimmediately at import time.", "We will load the saved dictionary, walk through every experiment entry, and for\neach dataset (e.g., \u201cSPR_BENCH\u201d) compute and print:   \u2022 the final training loss\n(last element of losses[\"train\"])   \u2022 the best validation loss (minimum of\nlosses[\"val\"])   \u2022 the best validation shape-weighted accuracy (maximum of\nmetrics[\"val\"]).   All printing is done immediately at script execution, with\nthe metric names spelled out explicitly.", "The script will load the saved NumPy file from the working directory, navigate\nthe nested dictionary, and compute the final or best values required. For each\ndataset (e.g., \u201cSPR_BENCH\u201d) it will print the dataset name first, followed by\nclearly-labeled metrics such as \u201ctrain loss,\u201d \u201cvalidation loss,\u201d and \u201cvalidation\nshape-weighted accuracy.\u201d The best value is chosen as the minimum for losses and\nthe maximum for accuracy. If any list is unexpectedly empty, the script skips\nthat metric gracefully.", "We load the saved numpy dictionary from the working directory, navigate its\nnested structure, and collect the recorded loss and accuracy values for each\ndataset. For every dataset we print: (1) the final training loss from the last\nepoch, (2) the best (minimum) validation loss observed, and (3) the best\n(maximum) validation shape-weighted accuracy observed. The script executes\nimmediately at global scope, produces no plots, and prints each metric with an\nexplicit, descriptive label.", "The script will (1) locate the working directory, (2) load\n`experiment_data.npy`, (3) walk through every stored model and dataset, (4)\nfetch the last (i.e., final) entry in each list of recorded values, and (5)\nprint them with unambiguous names such as \u201ctraining loss\u201d, \u201cvalidation loss\u201d,\nand \u201cvalidation shape-weighted accuracy\u201d. No entry-point guard or plots are\nused, so running the file immediately prints the requested information.", "Below is a short utility that immediately loads the saved NumPy file, parses the\nstored dictionaries, and prints the key performance numbers (final training\nloss, best validation loss, best validation shape-weighted accuracy) for every\ndataset it finds. The script follows the exact file/folder layout and data\nstructure in the original training code; no extra entry-point guard or plotting\nis used.", "We will load the saved NumPy dictionary from working/experiment_data.npy,\niterate through every stored dataset (only \u201cSPR_BENCH\u201d in this run), identify\nthe epoch that achieved the lowest validation loss, and then report: (1) the\nfinal training loss from the last epoch, (2) that best validation loss, (3) the\nshape-weighted accuracy (SWA) at that best epoch, and (4) the novelty-weighted\naccuracy (NWA) at the same epoch. All values are printed with explicit metric\nnames as required.", "The script will load the saved NumPy dictionary from the working directory,\niterate through every experiment and its datasets, and then compute the final\ntraining loss together with the best (lowest) validation loss and the best\n(highest) validation shape-weighted accuracy. It prints the dataset name first,\nfollowed by clearly labelled metric values, and runs immediately without any\nspecial entry point.", "", "The script will load the saved NumPy dictionary from the working directory,\niterate through every experiment and its datasets, and then compute the final\ntraining loss together with the best (lowest) validation loss and the best\n(highest) validation shape-weighted accuracy. It prints the dataset name first,\nfollowed by clearly labelled metric values, and runs immediately without any\nspecial entry point.", "The script will load the saved NumPy dictionary from the working directory,\niterate through every experiment and its datasets, and then compute the final\ntraining loss together with the best (lowest) validation loss and the best\n(highest) validation shape-weighted accuracy. It prints the dataset name first,\nfollowed by clearly labelled metric values, and runs immediately without any\nspecial entry point.", "The script will load the saved NumPy dictionary from the working directory,\niterate through every experiment and its datasets, and then compute the final\ntraining loss together with the best (lowest) validation loss and the best\n(highest) validation shape-weighted accuracy. It prints the dataset name first,\nfollowed by clearly labelled metric values, and runs immediately without any\nspecial entry point.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate and load the saved experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# helper to safely get best value while ignoring Nones\n# ------------------------------------------------------------------\ndef _best(values, fn):\n    # remove None entries first\n    cleaned = [v for v in values if v is not None]\n    if not cleaned:\n        return None\n    return fn(cleaned)\n\n\n# ------------------------------------------------------------------\n# iterate through each dataset and report metrics\n# ------------------------------------------------------------------\nfor dataset_name, dset in experiment_data.items():\n    print(f\"{dataset_name}\")  # dataset header\n\n    # losses\n    train_losses = dset.get(\"losses\", {}).get(\"train\", [])\n    val_losses = dset.get(\"losses\", {}).get(\"val\", [])\n\n    # metrics\n    val_swa = dset.get(\"metrics\", {}).get(\"val\", [])\n\n    # compute desired statistics\n    final_train_loss = train_losses[-1] if train_losses else None\n    best_validation_loss = _best(val_losses, min)\n    best_validation_swa = _best(val_swa, max)\n\n    # print results with explicit metric names\n    if final_train_loss is not None:\n        print(f\"final training loss: {final_train_loss:.4f}\")\n    if best_validation_loss is not None:\n        print(f\"best validation loss: {best_validation_loss:.4f}\")\n    if best_validation_swa is not None:\n        print(f\"best validation shape-weighted accuracy: {best_validation_swa:.4f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 0. locate and load the saved numpy dictionary\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# 1. iterate through experiments and datasets and report metrics\n# ------------------------------------------------------------------\nfor exp_variant, datasets in experiment_data.items():  # e.g. \"no_symbolic_features\"\n    for dataset_name, data in datasets.items():  # e.g. \"SPR_BENCH\"\n        print(f\"\\n{dataset_name}\")  # dataset header\n\n        # ---------- losses ----------\n        train_losses = data[\"losses\"][\"train\"]\n        val_losses = data[\"losses\"][\"val\"]\n\n        if train_losses:  # final training loss\n            final_train_loss = train_losses[-1]\n            print(f\"final training loss: {final_train_loss:.6f}\")\n\n        if val_losses:  # best (minimum) validation loss\n            best_val_loss = min(val_losses)\n            print(f\"best validation loss: {best_val_loss:.6f}\")\n\n        # ---------- metrics ----------\n        val_metrics = [v for v in data[\"metrics\"][\"val\"] if v is not None]\n\n        if val_metrics:  # best (maximum) validation accuracy\n            best_val_acc = max(val_metrics)\n            print(f\"best validation shape-weighted accuracy: {best_val_acc:.6f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------------\n# 0. Locate the working directory and load the experiment data\n# ---------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------------\n# 1. Iterate through experiments and datasets, printing best/final metrics\n# ---------------------------------------------------------------------------\nfor exp_name, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        print(dataset_name)  # Requirement #3\n\n        # ---- losses ----\n        train_losses = data.get(\"losses\", {}).get(\"train\", [])\n        val_losses = data.get(\"losses\", {}).get(\"val\", [])\n\n        if train_losses:\n            final_train_loss = train_losses[-1]\n            print(f\"train loss: {final_train_loss:.4f}\")\n\n        if val_losses:\n            best_val_loss = min(val_losses)\n            print(f\"validation loss: {best_val_loss:.4f}\")\n\n        # ---- metrics ----\n        val_metrics = data.get(\"metrics\", {}).get(\"val\", [])\n        if val_metrics:\n            best_val_metric = max(val_metrics)  # higher SWA is better\n            print(f\"validation shape weighted accuracy: {best_val_metric:.4f}\")\n\n        print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# locate and load the saved experiment information\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\ndef _best(values, higher_is_better=True):\n    \"\"\"Return best (max or min) value from a list, skipping None entries.\"\"\"\n    values = [v for v in values if v is not None]\n    if not values:\n        return None\n    return max(values) if higher_is_better else min(values)\n\n\n# iterate over all runs and datasets\nfor run_name, run_dict in experiment_data.items():\n    for dataset_name, data in run_dict.items():\n        print(f\"\\nDataset: {dataset_name}\")\n\n        # extract stored lists\n        train_losses = data[\"losses\"][\"train\"]\n        val_losses = data[\"losses\"][\"val\"]\n        val_metrics = data[\"metrics\"][\"val\"]  # shape-weighted accuracy\n\n        # compute required summaries\n        final_train_loss = train_losses[-1] if train_losses else None\n        best_validation_loss = _best(val_losses, higher_is_better=False)\n        best_validation_swa = _best(val_metrics, higher_is_better=True)\n\n        # print with explicit metric names\n        if final_train_loss is not None:\n            print(f\"final training loss: {final_train_loss:.4f}\")\n        if best_validation_loss is not None:\n            print(f\"best validation loss: {best_validation_loss:.4f}\")\n        if best_validation_swa is not None:\n            print(f\"best validation shape-weighted accuracy: {best_validation_swa:.4f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 0. Locate the file and load the experiment dictionary\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# 1\u20134. Iterate through models \u2192 datasets and print final metrics\n# ------------------------------------------------------------------\nfor model_name, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        # Retrieve the final entry of each list (last epoch that was run)\n        final_train_loss = (\n            data[\"losses\"][\"train\"][-1] if data[\"losses\"][\"train\"] else None\n        )\n        final_val_loss = data[\"losses\"][\"val\"][-1] if data[\"losses\"][\"val\"] else None\n        final_val_metric = (\n            data[\"metrics\"][\"val\"][-1] if data[\"metrics\"][\"val\"] else None\n        )\n\n        # 3. Print dataset name first\n        print(f\"\\nDataset: {dataset_name}   (model: {model_name})\")\n        # 4. Print clearly-labeled metrics\n        if final_train_loss is not None:\n            print(f\"training loss: {final_train_loss:.6f}\")\n        if final_val_loss is not None:\n            print(f\"validation loss: {final_val_loss:.6f}\")\n        if final_val_metric is not None:\n            print(f\"validation shape-weighted accuracy: {final_val_metric:.6f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# 1. Locate and load the experiment data file\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Unable to locate {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# 2. Iterate through all model \u2192 dataset combinations\n# ---------------------------------------------------------------------\nfor model_name, datasets in experiment_data.items():\n    for dataset_name, stats in datasets.items():\n        losses = stats.get(\"losses\", {})\n        metrics = stats.get(\"metrics\", {})\n\n        train_losses = losses.get(\"train\", [])\n        val_losses = losses.get(\"val\", [])\n        val_swa = metrics.get(\"val\", [])\n\n        # Safeguards for empty lists\n        final_train_loss = train_losses[-1] if train_losses else None\n        best_validation_loss = min(val_losses) if val_losses else None\n        best_validation_swa = max(val_swa) if val_swa else None\n\n        # -----------------------------------------------------------------\n        # 3. Print the results\n        # -----------------------------------------------------------------\n        print(f\"\\nDataset: {dataset_name}\")\n        print(f\"final training loss: {final_train_loss}\")\n        print(f\"best validation loss: {best_validation_loss}\")\n        print(f\"best validation shape weighted accuracy: {best_validation_swa}\")\n", "import os\nimport numpy as np\n\n# --------------------- locate & load ----------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# --------------------- helper to print one dataset --------------------------\ndef summarize_dataset(name, data_dict):\n    losses_train = data_dict[\"losses\"][\"train\"]\n    losses_val = data_dict[\"losses\"][\"val\"]\n    metrics_val = data_dict[\"metrics\"][\"val\"]\n\n    # Identify epoch with best (lowest) validation loss\n    best_epoch_idx = int(np.argmin(losses_val))\n\n    print(name)  # dataset name\n    print(f\"final training loss: {losses_train[-1]:.6f}\")\n    print(f\"best validation loss: {losses_val[best_epoch_idx]:.6f}\")\n\n    best_metrics = metrics_val[best_epoch_idx] or {}\n    swa = best_metrics.get(\"SWA\", None)\n    nwa = best_metrics.get(\"NWA\", None)\n\n    if swa is not None:\n        print(f\"best validation shape-weighted accuracy: {swa:.6f}\")\n    if nwa is not None:\n        print(f\"best validation novelty-weighted accuracy: {nwa:.6f}\")\n\n\n# --------------------- iterate over datasets --------------------------------\nfor dset_name, dset_dict in experiment_data.items():\n    summarize_dataset(dset_name, dset_dict)\n", "import os\nimport numpy as np\n\n# ---------- load data ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not locate {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- extract & print metrics ----------------------------------------------\nfor exp_name, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        print(f\"Dataset: {dataset_name}\")\n\n        # Losses\n        train_losses = data.get(\"losses\", {}).get(\"train\", [])\n        val_losses = data.get(\"losses\", {}).get(\"val\", [])\n\n        if train_losses:\n            print(f\"final training loss: {train_losses[-1]:.6f}\")\n\n        if val_losses:\n            print(f\"best validation loss: {min(val_losses):.6f}\")\n\n        # Metrics (Shape-Weighted Accuracy stored under 'val')\n        val_metrics = data.get(\"metrics\", {}).get(\"val\", [])\n        if val_metrics:\n            print(f\"best validation shape weighted accuracy: {max(val_metrics):.6f}\")\n\n        print()  # blank line between datasets\n", "", "import os\nimport numpy as np\n\n# ---------- load data ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not locate {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- extract & print metrics ----------------------------------------------\nfor exp_name, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        print(f\"Dataset: {dataset_name}\")\n\n        # Losses\n        train_losses = data.get(\"losses\", {}).get(\"train\", [])\n        val_losses = data.get(\"losses\", {}).get(\"val\", [])\n\n        if train_losses:\n            print(f\"final training loss: {train_losses[-1]:.6f}\")\n\n        if val_losses:\n            print(f\"best validation loss: {min(val_losses):.6f}\")\n\n        # Metrics (Shape-Weighted Accuracy stored under 'val')\n        val_metrics = data.get(\"metrics\", {}).get(\"val\", [])\n        if val_metrics:\n            print(f\"best validation shape weighted accuracy: {max(val_metrics):.6f}\")\n\n        print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ---------- load data ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not locate {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- extract & print metrics ----------------------------------------------\nfor exp_name, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        print(f\"Dataset: {dataset_name}\")\n\n        # Losses\n        train_losses = data.get(\"losses\", {}).get(\"train\", [])\n        val_losses = data.get(\"losses\", {}).get(\"val\", [])\n\n        if train_losses:\n            print(f\"final training loss: {train_losses[-1]:.6f}\")\n\n        if val_losses:\n            print(f\"best validation loss: {min(val_losses):.6f}\")\n\n        # Metrics (Shape-Weighted Accuracy stored under 'val')\n        val_metrics = data.get(\"metrics\", {}).get(\"val\", [])\n        if val_metrics:\n            print(f\"best validation shape weighted accuracy: {max(val_metrics):.6f}\")\n\n        print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ---------- load data ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not locate {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- extract & print metrics ----------------------------------------------\nfor exp_name, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        print(f\"Dataset: {dataset_name}\")\n\n        # Losses\n        train_losses = data.get(\"losses\", {}).get(\"train\", [])\n        val_losses = data.get(\"losses\", {}).get(\"val\", [])\n\n        if train_losses:\n            print(f\"final training loss: {train_losses[-1]:.6f}\")\n\n        if val_losses:\n            print(f\"best validation loss: {min(val_losses):.6f}\")\n\n        # Metrics (Shape-Weighted Accuracy stored under 'val')\n        val_metrics = data.get(\"metrics\", {}).get(\"val\", [])\n        if val_metrics:\n            print(f\"best validation shape weighted accuracy: {max(val_metrics):.6f}\")\n\n        print()  # blank line between datasets\n", ""], "parse_term_out": ["['SPR_BENCH', '\\n', 'final training loss: 0.1680', '\\n', 'best validation loss:\n0.1647', '\\n', 'best validation shape-weighted accuracy: 0.9449', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nSPR_BENCH', '\\n', 'final training loss: 0.169303', '\\n', 'best validation\nloss: 0.164049', '\\n', 'best validation shape-weighted accuracy: 0.944658',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'train loss: 0.6551', '\\n', 'validation loss: 0.6648', '\\n',\n'validation shape weighted accuracy: 0.5857', '\\n', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'final training loss: 0.1691', '\\n', 'best\nvalidation loss: 0.1648', '\\n', 'best validation shape-weighted accuracy:\n0.9447', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH   (model: bag_of_embeddings)', '\\n', 'training loss:\n0.446781', '\\n', 'validation loss: 0.456104', '\\n', 'validation shape-weighted\naccuracy: 0.776189', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'final training loss: 0.1676909702539444', '\\n',\n'best validation loss: 0.1644537564575672', '\\n', 'best validation shape\nweighted accuracy: 0.9448901290547611', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'final training loss: 0.650792', '\\n', 'best validation\nloss: 0.659399', '\\n', 'best validation shape-weighted accuracy: 0.585688',\n'\\n', 'best validation novelty-weighted accuracy: 0.591400', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', 'final training loss: 0.168461', '\\n', 'best\nvalidation loss: 0.163220', '\\n', 'best validation shape weighted accuracy:\n0.944658', '\\n', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "", "['Dataset: SPR_BENCH', '\\n', 'final training loss: 0.168461', '\\n', 'best\nvalidation loss: 0.163220', '\\n', 'best validation shape weighted accuracy:\n0.944658', '\\n', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Dataset: SPR_BENCH', '\\n', 'final training loss: 0.168461', '\\n', 'best\nvalidation loss: 0.163220', '\\n', 'best validation shape weighted accuracy:\n0.944658', '\\n', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Dataset: SPR_BENCH', '\\n', 'final training loss: 0.168461', '\\n', 'best\nvalidation loss: 0.163220', '\\n', 'best validation shape weighted accuracy:\n0.944658', '\\n', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"], "current_stage": "Stage_4"};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
