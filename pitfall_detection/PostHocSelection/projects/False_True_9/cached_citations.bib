
% This paper introduces SimCLR, a foundational method for self-supervised contrastive learning that demonstrates how effective feature representations can be learned without explicit supervision. It provides the basis for the context-aware contrastive learning framework proposed in this study and will be cited when discussing the core principles of contrastive learning.
@article{chakraborty2020gsimclrsc,
 author = {Souradip Chakraborty and A. R. Gosthipaty and Sayak Paul},
 booktitle = {2020 International Conference on Data Mining Workshops (ICDMW)},
 journal = {2020 International Conference on Data Mining Workshops (ICDMW)},
 pages = {912-916},
 title = {G-SimCLR: Self-Supervised Contrastive Learning with Guided Projection via Pseudo Labelling},
 year = {2020}
}

% This paper explores the use of masking as a data augmentation method in contrastive learning for convolutional neural networks. It identifies challenges in masking operations and introduces saliency-guided masking strategies to improve the quality of contrastive samples. This work is relevant to the context-aware data augmentation techniques employed in our study and will be cited when discussing advanced data augmentation strategies for symbolic sequences in contrastive learning.
@article{chin2023maskingic,
 author = {Zhi-Yi Chin and Chieh-Ming Jiang and Ching-Chun Huang and Pin-Yu Chen and Wei-Chen Chiu},
 booktitle = {IEEE Workshop/Winter Conference on Applications of Computer Vision},
 journal = {2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
 pages = {2749-2758},
 title = {Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where},
 year = {2023}
}

% This paper discusses neural-symbolic learning and reasoning, which is relevant to traditional symbolic reasoning methods and their challenges, particularly in terms of reliance on labeled data and generalization. It will be cited when summarizing the background and limitations of symbolic reasoning methods in our study.
@inproceedings{besold2015proceedingsot,
 author = {Tarek R. Besold and L. Lamb and Thomas F. Icard and R. Miikkulainen},
 title = {Proceedings of the 10 th International Workshop on Neural-Symbolic Learning and Reasoning NeSy ’ 15},
 year = {2015}
}

% This paper discusses the need for standardized datasets in neural-symbolic reasoning studies, which is relevant to the SPR_BENCH dataset's role as a benchmark for symbolic pattern recognition. It will be cited when discussing the importance of benchmarks in evaluating and advancing symbolic reasoning models and the contributions of SPR_BENCH to this field.
@article{ylmaz2016apf,
 author = {Özgür Yılmaz and A. Garcez and Daniel L. Silver},
 booktitle = {NeSy@HLAI},
 title = {A Proposal for Common Dataset in Neural-Symbolic Reasoning Studies},
 year = {2016}
}

% This paper introduces a novel denoising objective for self-supervised sentence representation learning and demonstrates its effectiveness in enhancing contrastive learning methods. By incorporating both discrete and continuous noise, the proposed approach generates robust representations, which aligns with the denoising strategies employed in the context-aware contrastive learning framework for symbolic sequences. It will be cited when discussing the role of denoising in improving representation learning in the proposed methodology.
@article{wang2024denosentad,
 author = {Xinghao Wang and Junliang He and Pengyu Wang and Yunhua Zhou and Tianxiang Sun and Xipeng Qiu},
 booktitle = {AAAI Conference on Artificial Intelligence},
 journal = {ArXiv},
 title = {DenoSent: A Denoising Objective for Self-Supervised Sentence Representation Learning},
 volume = {abs/2401.13621},
 year = {2024}
}

% This paper investigates the limitations of current deep learning models, including Structured State Space Models (SSMs) and Transformers, in handling complex reasoning tasks and function composition. It provides theoretical and empirical evidence of performance degradation in multi-step reasoning tasks, highlighting fundamental barriers in existing architectures. This work is relevant to discussing the challenges in symbolic sequence modeling and reasoning tasks, providing a context for the proposed context-aware contrastive learning framework's contributions in addressing these limitations.
@article{zubic2024limitsod,
 author = {Nikola Zubic and Federico Sold'a and Aurelio Sulser and Davide Scaramuzza},
 booktitle = {International Conference on Learning Representations},
 journal = {ArXiv},
 title = {Limits of Deep Learning: Sequence Modeling through the Lens of Complexity Theory},
 volume = {abs/2405.16674},
 year = {2024}
}

% This paper introduces the Symbolic Autoencoding framework ($\Sigma$AE), a self-supervised approach for learning representations of symbolic sequences. It demonstrates how this framework enhances transduction tasks between distinct symbolic systems, even with limited parallel data. This work is relevant to our focus on self-supervised techniques for symbolic sequence learning and will be cited to provide context and support for the proposed context-aware contrastive learning framework.
@article{amani2024symbolicaf,
 author = {Mohammad Hossein Amani and Nicolas Mario Baldwin and Amin Mansouri and Martin Josifoski and Maxime Peyrard and Robert West},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Symbolic Autoencoding for Self-Supervised Sequence Learning},
 volume = {abs/2402.10575},
 year = {2024}
}

% The paper introduces Geometry3K, a large-scale benchmark dataset for symbolic reasoning in geometry problems. It discusses the challenges of abstract understanding and symbolic reasoning with axiomatic knowledge, making it highly relevant for contextualizing the role of benchmarks like SPR_BENCH in advancing symbolic reasoning research. This citation will be used when discussing the importance of standardized benchmarks in evaluating and improving symbolic reasoning models.
@article{lu2021intergpsig,
 author = {Pan Lu and Ran Gong and Shibiao Jiang and Liang Qiu and Siyuan Huang and Xiaodan Liang and Song-Chun Zhu},
 booktitle = {Annual Meeting of the Association for Computational Linguistics},
 pages = {6774-6786},
 title = {Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning},
 year = {2021}
}
