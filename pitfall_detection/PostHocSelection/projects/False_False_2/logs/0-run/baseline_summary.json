{
  "best node": {
    "overall_plan": "The overall plan begins with establishing a lightweight neural-symbolic baseline that processes SPR sequences into symbolic histograms for shapes and colors, which are then fed into a 2-layer MLP. This system monitors loss and computes Shape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA), and PolyRule Harmonic Accuracy (PHA) to evaluate performance. The design is robust, supporting both GPU and CPU execution, and generates synthetic data if needed, ensuring functionality under different conditions. Metrics and loss curves are systematically stored. Building on this, the current plan focuses on hyperparameter tuning, specifically extending the training to a maximum of 50 epochs with early stopping based on PHA, enhancing efficiency and preventing overfitting. This refinement maintains the rest of the pipeline unchanged, preserving its self-contained nature, aiming to optimize performance and ensure the best model is evaluated.",
    "analysis": "The execution output indicates that the training script ran successfully without any errors or bugs. The model trained for 15 epochs before early stopping was triggered due to no improvement in the dev PHA metric. The final test metrics were SWA=0.2705, CWA=0.2622, and PHA=0.2663. All artefacts were saved as expected. No further action is required.",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "PHA",
            "lower_is_better": false,
            "description": "Percentage of Hits Agreement between predictions and ground truth.",
            "data": [
              {
                "dataset_name": "training",
                "final_value": 0.3643,
                "best_value": 0.3643
              },
              {
                "dataset_name": "development",
                "final_value": 0.2964,
                "best_value": 0.2964
              },
              {
                "dataset_name": "test",
                "final_value": 0.2663,
                "best_value": 0.2663
              }
            ]
          },
          {
            "metric_name": "loss",
            "lower_is_better": true,
            "description": "Loss measures how far predictions are from the actual values.",
            "data": [
              {
                "dataset_name": "training",
                "final_value": 1.3293,
                "best_value": 1.3293
              },
              {
                "dataset_name": "development",
                "final_value": 1.4225,
                "best_value": 1.4225
              }
            ]
          },
          {
            "metric_name": "SWA",
            "lower_is_better": false,
            "description": "Soft Weighted Accuracy of predictions on the test dataset.",
            "data": [
              {
                "dataset_name": "test",
                "final_value": 0.2705,
                "best_value": 0.2705
              }
            ]
          },
          {
            "metric_name": "CWA",
            "lower_is_better": false,
            "description": "Categorical Weighted Accuracy of predictions on the test dataset.",
            "data": [
              {
                "dataset_name": "test",
                "final_value": 0.2622,
                "best_value": 0.2622
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os, pathlib, random, string, warnings, sys, time, json\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# ------------------------------- paths / device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\", flush=True)\n\n# ------------------------------- try import helpers\ntry:\n    from SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy\nexcept Exception as e:\n    warnings.warn(\"Could not import SPR helpers, using fall-backs\")\n\n    def load_spr_bench(root: pathlib.Path):\n        raise FileNotFoundError(\"SPR_BENCH not found\")\n\n    def count_shape_variety(sequence: str):\n        return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n    def count_color_variety(sequence: str):\n        return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n    def shape_weighted_accuracy(seqs, y_true, y_pred):\n        w = [count_shape_variety(s) for s in seqs]\n        c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n        return sum(c) / (sum(w) + 1e-9)\n\n    def color_weighted_accuracy(seqs, y_true, y_pred):\n        w = [count_color_variety(s) for s in seqs]\n        c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n        return sum(c) / (sum(w) + 1e-9)\n\n\n# ------------------------------- synthetic dataset helper\ndef make_synthetic_dataset(n_rows):\n    shapes = list(string.ascii_uppercase[:6])\n    cols = list(string.ascii_lowercase[:6])\n    seqs, labels = [], []\n    for _ in range(n_rows):\n        length = random.randint(4, 9)\n        tokens = [random.choice(shapes) + random.choice(cols) for _ in range(length)]\n        seqs.append(\" \".join(tokens))\n        labels.append(random.randint(0, 3))\n    return {\"sequence\": seqs, \"label\": labels}\n\n\n# ------------------------------- load data\nroot_path = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\ntry:\n    dsets = load_spr_bench(root_path)\n    print(\"Loaded real SPR_BENCH.\")\n    train_seqs, train_labels = dsets[\"train\"][\"sequence\"], dsets[\"train\"][\"label\"]\n    dev_seqs, dev_labels = dsets[\"dev\"][\"sequence\"], dsets[\"dev\"][\"label\"]\n    test_seqs, test_labels = dsets[\"test\"][\"sequence\"], dsets[\"test\"][\"label\"]\nexcept Exception as e:\n    warnings.warn(f\"{e}\\nGenerating synthetic data instead.\")\n    train = make_synthetic_dataset(512)\n    dev = make_synthetic_dataset(128)\n    test = make_synthetic_dataset(256)\n    train_seqs, train_labels = train[\"sequence\"], train[\"label\"]\n    dev_seqs, dev_labels = dev[\"sequence\"], dev[\"label\"]\n    test_seqs, test_labels = test[\"sequence\"], test[\"label\"]\n\n# ------------------------------- vocab / featuriser\nshape_vocab = sorted({tok[0] for seq in train_seqs for tok in seq.split()})\ncolor_vocab = sorted(\n    {tok[1] for seq in train_seqs for tok in seq.split() if len(tok) > 1}\n)\nshape2idx = {s: i for i, s in enumerate(shape_vocab)}\ncolor2idx = {c: i for i, c in enumerate(color_vocab)}\nfeat_dim = len(shape2idx) + len(color2idx)\nprint(f\"Feature dim={feat_dim}\")\n\n\ndef seq_to_feature(seq: str) -> np.ndarray:\n    sh = np.zeros(len(shape2idx), dtype=np.float32)\n    co = np.zeros(len(color2idx), dtype=np.float32)\n    for tok in seq.split():\n        if not tok:\n            continue\n        sh[shape2idx.get(tok[0], 0)] += 1.0\n        if len(tok) > 1:\n            co[color2idx.get(tok[1], 0)] += 1.0\n    return np.concatenate([sh, co])\n\n\ndef encode_dataset(seqs, labels):\n    X = np.stack([seq_to_feature(s) for s in seqs])\n    y = np.asarray(labels, dtype=np.int64)\n    return X, y\n\n\nX_train, y_train = encode_dataset(train_seqs, train_labels)\nX_dev, y_dev = encode_dataset(dev_seqs, dev_labels)\nX_test, y_test = encode_dataset(test_seqs, test_labels)\nn_classes = int(max(y_train.max(), y_dev.max(), y_test.max())) + 1\nprint(f\"Detected {n_classes} classes\")\n\nbd = 128\ntrain_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train)),\n    batch_size=bd,\n    shuffle=True,\n)\ndev_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev)), batch_size=bd\n)\ntest_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test)), batch_size=bd\n)\n\n\n# ------------------------------- model def\nclass MLP(nn.Module):\n    def __init__(self, in_dim, nc):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(in_dim, 128), nn.ReLU(), nn.Linear(128, nc))\n\n    def forward(self, x):\n        return self.net(x)\n\n\ndef compute_metrics(seqs, y_true, y_pred):\n    swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(seqs, y_true, y_pred)\n    pha = 2 * swa * cwa / (swa + cwa + 1e-9)\n    return swa, cwa, pha\n\n\n# ------------------------------- experiment data container\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"spr_bench\": {\n            \"metrics\": {\"train_PHA\": [], \"dev_PHA\": []},\n            \"losses\": {\"train\": [], \"dev\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ------------------------------- training with early stopping\nmax_epochs = 50\npatience = 7\nmodel = MLP(feat_dim, n_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_dev_pha, wait = -1.0, 0\nbest_state = None\n\nfor epoch in range(1, max_epochs + 1):\n    # ---- train\n    model.train()\n    running = 0.0\n    for xb, yb in train_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        loss = criterion(model(xb), yb)\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * xb.size(0)\n    train_loss = running / len(train_loader.dataset)\n\n    # ---- validate\n    model.eval()\n    running = 0.0\n    dev_logits, dev_ys = [], []\n    with torch.no_grad():\n        for xb, yb in dev_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            logits = model(xb)\n            running += criterion(logits, yb).item() * xb.size(0)\n            dev_logits.append(logits.cpu())\n            dev_ys.append(yb.cpu())\n    dev_loss = running / len(dev_loader.dataset)\n    dev_pred = torch.cat(dev_logits).argmax(1).numpy()\n    dev_gt = torch.cat(dev_ys).numpy()\n\n    # ---- PHA metrics\n    _, _, train_pha = compute_metrics(\n        train_seqs,\n        y_train,\n        model(torch.from_numpy(X_train).to(device)).argmax(1).cpu().numpy(),\n    )\n    _, _, dev_pha = compute_metrics(dev_seqs, y_dev, dev_pred)\n\n    # ---- log\n    ep_log = experiment_data[\"epochs_tuning\"][\"spr_bench\"]\n    ep_log[\"epochs\"].append(epoch)\n    ep_log[\"losses\"][\"train\"].append(train_loss)\n    ep_log[\"losses\"][\"dev\"].append(dev_loss)\n    ep_log[\"metrics\"][\"train_PHA\"].append(train_pha)\n    ep_log[\"metrics\"][\"dev_PHA\"].append(dev_pha)\n\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f} dev_loss={dev_loss:.4f} dev_PHA={dev_pha:.4f}\"\n    )\n\n    # ---- early stopping on dev PHA\n    if dev_pha > best_dev_pha + 1e-5:\n        best_dev_pha = dev_pha\n        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n        wait = 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n\n# ------------------------------- restore best model\nif best_state is not None:\n    model.load_state_dict(best_state)\n\n# ------------------------------- test evaluation\nmodel.eval()\ntest_logits = []\nwith torch.no_grad():\n    for xb, _ in test_loader:\n        xb = xb.to(device)\n        test_logits.append(model(xb).cpu())\ntest_pred = torch.cat(test_logits).argmax(1).numpy()\nswa, cwa, pha = compute_metrics(test_seqs, y_test, test_pred)\nprint(f\"\\nTest SWA={swa:.4f} CWA={cwa:.4f} PHA={pha:.4f}\")\n\n# save predictions & gt\nep_log = experiment_data[\"epochs_tuning\"][\"spr_bench\"]\nep_log[\"predictions\"] = test_pred\nep_log[\"ground_truth\"] = y_test\nep_log[\"test_metrics\"] = {\"SWA\": swa, \"CWA\": cwa, \"PHA\": pha}\n\n# ------------------------------- save artefacts\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# ------------------------------- plot loss curves\nplt.figure()\nplt.plot(ep_log[\"epochs\"], ep_log[\"losses\"][\"train\"], label=\"train\")\nplt.plot(ep_log[\"epochs\"], ep_log[\"losses\"][\"dev\"], label=\"dev\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss Curve\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\nplt.close()\n\nprint(\"All done; artefacts written to ./working\")\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------- paths / load data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# --- helper for confusion matrix\ndef confusion_matrix(y_true, y_pred, n_classes):\n    cm = np.zeros((n_classes, n_classes), dtype=int)\n    for t, p in zip(y_true, y_pred):\n        cm[t, p] += 1\n    return cm\n\n\n# ---------------- plotting\nfor dataset_key in experiment_data.get(\"epochs_tuning\", {}):\n    log = experiment_data[\"epochs_tuning\"][dataset_key]\n    epochs = log.get(\"epochs\", [])\n\n    # 1) Loss curves\n    try:\n        plt.figure()\n        plt.plot(epochs, log[\"losses\"][\"train\"], label=\"train\")\n        plt.plot(epochs, log[\"losses\"][\"dev\"], label=\"dev\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"{dataset_key} Loss Curve\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {dataset_key}: {e}\")\n        plt.close()\n\n    # 2) PHA curves\n    try:\n        plt.figure()\n        plt.plot(epochs, log[\"metrics\"][\"train_PHA\"], label=\"train_PHA\")\n        plt.plot(epochs, log[\"metrics\"][\"dev_PHA\"], label=\"dev_PHA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"PHA\")\n        plt.title(f\"{dataset_key} PHA Curve\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_pha_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating PHA curve for {dataset_key}: {e}\")\n        plt.close()\n\n    # 3) Test metric bar plot\n    try:\n        test_m = log.get(\"test_metrics\", {})\n        if test_m:\n            plt.figure()\n            keys, vals = zip(*test_m.items())\n            plt.bar(keys, vals, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n            plt.ylim(0, 1)\n            plt.title(f\"{dataset_key} Test Metrics\")\n            for i, v in enumerate(vals):\n                plt.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n            fname = os.path.join(working_dir, f\"{dataset_key}_test_metrics.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar plot for {dataset_key}: {e}\")\n        plt.close()\n\n    # 4) Confusion matrix\n    try:\n        y_true = np.asarray(log.get(\"ground_truth\", []))\n        y_pred = np.asarray(log.get(\"predictions\", []))\n        if y_true.size and y_pred.size:\n            n_classes = max(y_true.max(), y_pred.max()) + 1\n            cm = confusion_matrix(y_true, y_pred, n_classes)\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(f\"{dataset_key} Confusion Matrix\")\n            for i in range(n_classes):\n                for j in range(n_classes):\n                    plt.text(\n                        j,\n                        i,\n                        cm[i, j],\n                        ha=\"center\",\n                        va=\"center\",\n                        color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                    )\n            fname = os.path.join(working_dir, f\"{dataset_key}_confusion_matrix.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dataset_key}: {e}\")\n        plt.close()\n\nprint(\"Plotting complete; figures saved to\", working_dir)\n",
    "plot_plan": "We will load the saved experiment_data.npy from the working directory and iterate over the single dataset entry (\u201cspr_bench\u201d) contained in the \u201cepochs_tuning\u201d section. From this dictionary we can directly access the epoch list, training/dev losses, training/dev PHA values, as well as the final test predictions, ground-truth labels and aggregated test metrics (SWA, CWA, PHA). We will visualise four things: (1) loss curves for train vs. dev, (2) PHA curves for train vs. dev, (3) a bar chart comparing the three final test metrics, and (4) a confusion-matrix style heat-map of ground-truth vs. predicted classes. Each plot is wrapped in its own try-except so that one failure does not stop the rest, and every figure is saved under a descriptive name that includes the dataset and plot type before being closed. No synthetic data are fabricated; everything is taken straight from experiment_data. We also ensure that at most the required number of figures (\u22645) is generated. The code respects all specified plotting guidelines and starts with the mandated imports. Finally, the script prints a brief confirmation once all plots have been written.",
    "plot_analyses": [
      {
        "analysis": "The loss curve shows a steady decrease in training loss over epochs, indicating that the model is learning effectively on the training data. However, the development loss initially decreases but then plateaus and slightly increases, suggesting potential overfitting after a certain number of epochs. This implies that regularization techniques or early stopping might be necessary to prevent overfitting and improve generalization.",
        "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318/loss_curve.png"
      },
      {
        "analysis": "This plot mirrors the previous loss curve and reinforces the observation that while the training loss continues to reduce, the development loss stagnates and rises slightly, pointing to overfitting. The model might be too focused on the training data and unable to generalize well to unseen data.",
        "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318/spr_bench_loss_curve.png"
      },
      {
        "analysis": "The PHA (Prediction-Weighted Accuracy) curve shows an improvement in training PHA over epochs, but the development PHA remains relatively low and stable. This indicates that while the model is learning to optimize for the training data, it struggles to maintain performance on the development set, further supporting the hypothesis of overfitting.",
        "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318/spr_bench_pha_curve.png"
      },
      {
        "analysis": "The bar chart for SWA, CWA, and PHA metrics on the test set shows relatively low scores across all metrics (around 0.26-0.27). This suggests that the model's ability to generalize to the test set is limited and aligns with the observed overfitting trends in the previous plots. Improving the model's generalization capabilities should be a priority.",
        "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318/spr_bench_test_metrics.png"
      },
      {
        "analysis": "The confusion matrix highlights that the model is struggling to make accurate predictions across all classes, with significant misclassifications evident. The diagonal values, representing correct predictions, are relatively low compared to off-diagonal values, which represent incorrect predictions. This indicates that the model's current state lacks robustness and requires further tuning or architectural adjustments to improve its classification performance.",
        "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318/spr_bench_confusion_matrix.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318/loss_curve.png",
      "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318/spr_bench_loss_curve.png",
      "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318/spr_bench_pha_curve.png",
      "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318/spr_bench_test_metrics.png",
      "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318/spr_bench_confusion_matrix.png"
    ],
    "vlm_feedback_summary": "The plots reveal that the model is overfitting to the training data, as evidenced by the divergence between training and development loss curves and low PHA performance on the development set. Test set metrics (SWA, CWA, PHA) are low, and the confusion matrix shows significant misclassifications, indicating poor generalization. Addressing overfitting and improving generalization should be the primary focus moving forward.",
    "exp_results_dir": "experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318",
    "exp_results_npy_files": [
      "experiment_results/experiment_1f0e024b9fe4461aa7e60322cf845911_proc_329318/experiment_data.npy"
    ]
  },
  "best node with different seeds": [
    {
      "overall_plan": "The overall plan begins with establishing a lightweight neural-symbolic baseline that processes SPR sequences into symbolic histograms for shapes and colors, which are then fed into a 2-layer MLP. This system monitors loss and computes Shape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA), and PolyRule Harmonic Accuracy (PHA) to evaluate performance. The design is robust, supporting both GPU and CPU execution, and generates synthetic data if needed, ensuring functionality under different conditions. Metrics and loss curves are systematically stored. Building on this, the plan focuses on hyperparameter tuning, specifically extending the training to a maximum of 50 epochs with early stopping based on PHA, enhancing efficiency and preventing overfitting. This refinement maintains the rest of the pipeline unchanged, preserving its self-contained nature, aiming to optimize performance and ensure the best model is evaluated.",
      "analysis": "",
      "metric": {
        "value": {
          "metric_names": [
            {
              "metric_name": "PHA",
              "lower_is_better": false,
              "description": "Proportional Hit Accuracy measures the accuracy of predictions.",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 0.3614,
                  "best_value": 0.3614
                },
                {
                  "dataset_name": "development",
                  "final_value": 0.3401,
                  "best_value": 0.3401
                },
                {
                  "dataset_name": "test",
                  "final_value": 0.2559,
                  "best_value": 0.2559
                }
              ]
            },
            {
              "metric_name": "loss",
              "lower_is_better": true,
              "description": "Loss measures the error of predictions compared to actual values.",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 1.3371,
                  "best_value": 1.3371
                },
                {
                  "dataset_name": "development",
                  "final_value": 1.3783,
                  "best_value": 1.3783
                }
              ]
            },
            {
              "metric_name": "SWA",
              "lower_is_better": false,
              "description": "Sliding Window Accuracy measures the average accuracy over a sliding window of predictions.",
              "data": [
                {
                  "dataset_name": "test",
                  "final_value": 0.2572,
                  "best_value": 0.2572
                }
              ]
            },
            {
              "metric_name": "CWA",
              "lower_is_better": false,
              "description": "Cumulative Window Accuracy measures the cumulative accuracy over a window of predictions.",
              "data": [
                {
                  "dataset_name": "test",
                  "final_value": 0.2546,
                  "best_value": 0.2546
                }
              ]
            }
          ]
        },
        "maximize": null,
        "name": null,
        "description": null
      },
      "code": "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, string, warnings, sys, time, json\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# ------------------------------- paths / device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\", flush=True)\n\n# ------------------------------- try import helpers\ntry:\n    from SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy\nexcept Exception as e:\n    warnings.warn(\"Could not import SPR helpers, using fall-backs\")\n\n    def load_spr_bench(root: pathlib.Path):\n        raise FileNotFoundError(\"SPR_BENCH not found\")\n\n    def count_shape_variety(sequence: str):\n        return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n    def count_color_variety(sequence: str):\n        return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n    def shape_weighted_accuracy(seqs, y_true, y_pred):\n        w = [count_shape_variety(s) for s in seqs]\n        c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n        return sum(c) / (sum(w) + 1e-9)\n\n    def color_weighted_accuracy(seqs, y_true, y_pred):\n        w = [count_color_variety(s) for s in seqs]\n        c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n        return sum(c) / (sum(w) + 1e-9)\n\n\n# ------------------------------- synthetic dataset helper\ndef make_synthetic_dataset(n_rows):\n    shapes = list(string.ascii_uppercase[:6])\n    cols = list(string.ascii_lowercase[:6])\n    seqs, labels = [], []\n    for _ in range(n_rows):\n        length = random.randint(4, 9)\n        tokens = [random.choice(shapes) + random.choice(cols) for _ in range(length)]\n        seqs.append(\" \".join(tokens))\n        labels.append(random.randint(0, 3))\n    return {\"sequence\": seqs, \"label\": labels}\n\n\n# ------------------------------- load data\nroot_path = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\ntry:\n    dsets = load_spr_bench(root_path)\n    print(\"Loaded real SPR_BENCH.\")\n    train_seqs, train_labels = dsets[\"train\"][\"sequence\"], dsets[\"train\"][\"label\"]\n    dev_seqs, dev_labels = dsets[\"dev\"][\"sequence\"], dsets[\"dev\"][\"label\"]\n    test_seqs, test_labels = dsets[\"test\"][\"sequence\"], dsets[\"test\"][\"label\"]\nexcept Exception as e:\n    warnings.warn(f\"{e}\\nGenerating synthetic data instead.\")\n    train = make_synthetic_dataset(512)\n    dev = make_synthetic_dataset(128)\n    test = make_synthetic_dataset(256)\n    train_seqs, train_labels = train[\"sequence\"], train[\"label\"]\n    dev_seqs, dev_labels = dev[\"sequence\"], dev[\"label\"]\n    test_seqs, test_labels = test[\"sequence\"], test[\"label\"]\n\n# ------------------------------- vocab / featuriser\nshape_vocab = sorted({tok[0] for seq in train_seqs for tok in seq.split()})\ncolor_vocab = sorted(\n    {tok[1] for seq in train_seqs for tok in seq.split() if len(tok) > 1}\n)\nshape2idx = {s: i for i, s in enumerate(shape_vocab)}\ncolor2idx = {c: i for i, c in enumerate(color_vocab)}\nfeat_dim = len(shape2idx) + len(color2idx)\nprint(f\"Feature dim={feat_dim}\")\n\n\ndef seq_to_feature(seq: str) -> np.ndarray:\n    sh = np.zeros(len(shape2idx), dtype=np.float32)\n    co = np.zeros(len(color2idx), dtype=np.float32)\n    for tok in seq.split():\n        if not tok:\n            continue\n        sh[shape2idx.get(tok[0], 0)] += 1.0\n        if len(tok) > 1:\n            co[color2idx.get(tok[1], 0)] += 1.0\n    return np.concatenate([sh, co])\n\n\ndef encode_dataset(seqs, labels):\n    X = np.stack([seq_to_feature(s) for s in seqs])\n    y = np.asarray(labels, dtype=np.int64)\n    return X, y\n\n\nX_train, y_train = encode_dataset(train_seqs, train_labels)\nX_dev, y_dev = encode_dataset(dev_seqs, dev_labels)\nX_test, y_test = encode_dataset(test_seqs, test_labels)\nn_classes = int(max(y_train.max(), y_dev.max(), y_test.max())) + 1\nprint(f\"Detected {n_classes} classes\")\n\nbd = 128\ntrain_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train)),\n    batch_size=bd,\n    shuffle=True,\n)\ndev_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev)), batch_size=bd\n)\ntest_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test)), batch_size=bd\n)\n\n\n# ------------------------------- model def\nclass MLP(nn.Module):\n    def __init__(self, in_dim, nc):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(in_dim, 128), nn.ReLU(), nn.Linear(128, nc))\n\n    def forward(self, x):\n        return self.net(x)\n\n\ndef compute_metrics(seqs, y_true, y_pred):\n    swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(seqs, y_true, y_pred)\n    pha = 2 * swa * cwa / (swa + cwa + 1e-9)\n    return swa, cwa, pha\n\n\n# ------------------------------- experiment data container\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"spr_bench\": {\n            \"metrics\": {\"train_PHA\": [], \"dev_PHA\": []},\n            \"losses\": {\"train\": [], \"dev\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ------------------------------- training with early stopping\nmax_epochs = 50\npatience = 7\nmodel = MLP(feat_dim, n_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_dev_pha, wait = -1.0, 0\nbest_state = None\n\nfor epoch in range(1, max_epochs + 1):\n    # ---- train\n    model.train()\n    running = 0.0\n    for xb, yb in train_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        loss = criterion(model(xb), yb)\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * xb.size(0)\n    train_loss = running / len(train_loader.dataset)\n\n    # ---- validate\n    model.eval()\n    running = 0.0\n    dev_logits, dev_ys = [], []\n    with torch.no_grad():\n        for xb, yb in dev_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            logits = model(xb)\n            running += criterion(logits, yb).item() * xb.size(0)\n            dev_logits.append(logits.cpu())\n            dev_ys.append(yb.cpu())\n    dev_loss = running / len(dev_loader.dataset)\n    dev_pred = torch.cat(dev_logits).argmax(1).numpy()\n    dev_gt = torch.cat(dev_ys).numpy()\n\n    # ---- PHA metrics\n    _, _, train_pha = compute_metrics(\n        train_seqs,\n        y_train,\n        model(torch.from_numpy(X_train).to(device)).argmax(1).cpu().numpy(),\n    )\n    _, _, dev_pha = compute_metrics(dev_seqs, y_dev, dev_pred)\n\n    # ---- log\n    ep_log = experiment_data[\"epochs_tuning\"][\"spr_bench\"]\n    ep_log[\"epochs\"].append(epoch)\n    ep_log[\"losses\"][\"train\"].append(train_loss)\n    ep_log[\"losses\"][\"dev\"].append(dev_loss)\n    ep_log[\"metrics\"][\"train_PHA\"].append(train_pha)\n    ep_log[\"metrics\"][\"dev_PHA\"].append(dev_pha)\n\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f} dev_loss={dev_loss:.4f} dev_PHA={dev_pha:.4f}\"\n    )\n\n    # ---- early stopping on dev PHA\n    if dev_pha > best_dev_pha + 1e-5:\n        best_dev_pha = dev_pha\n        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n        wait = 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n\n# ------------------------------- restore best model\nif best_state is not None:\n    model.load_state_dict(best_state)\n\n# ------------------------------- test evaluation\nmodel.eval()\ntest_logits = []\nwith torch.no_grad():\n    for xb, _ in test_loader:\n        xb = xb.to(device)\n        test_logits.append(model(xb).cpu())\ntest_pred = torch.cat(test_logits).argmax(1).numpy()\nswa, cwa, pha = compute_metrics(test_seqs, y_test, test_pred)\nprint(f\"\\nTest SWA={swa:.4f} CWA={cwa:.4f} PHA={pha:.4f}\")\n\n# save predictions & gt\nep_log = experiment_data[\"epochs_tuning\"][\"spr_bench\"]\nep_log[\"predictions\"] = test_pred\nep_log[\"ground_truth\"] = y_test\nep_log[\"test_metrics\"] = {\"SWA\": swa, \"CWA\": cwa, \"PHA\": pha}\n\n# ------------------------------- save artefacts\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# ------------------------------- plot loss curves\nplt.figure()\nplt.plot(ep_log[\"epochs\"], ep_log[\"losses\"][\"train\"], label=\"train\")\nplt.plot(ep_log[\"epochs\"], ep_log[\"losses\"][\"dev\"], label=\"dev\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss Curve\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\nplt.close()\n\nprint(\"All done; artefacts written to ./working\")\n",
      "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------- paths / load data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# --- helper for confusion matrix\ndef confusion_matrix(y_true, y_pred, n_classes):\n    cm = np.zeros((n_classes, n_classes), dtype=int)\n    for t, p in zip(y_true, y_pred):\n        cm[t, p] += 1\n    return cm\n\n\n# ---------------- plotting\nfor dataset_key in experiment_data.get(\"epochs_tuning\", {}):\n    log = experiment_data[\"epochs_tuning\"][dataset_key]\n    epochs = log.get(\"epochs\", [])\n\n    # 1) Loss curves\n    try:\n        plt.figure()\n        plt.plot(epochs, log[\"losses\"][\"train\"], label=\"train\")\n        plt.plot(epochs, log[\"losses\"][\"dev\"], label=\"dev\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"{dataset_key} Loss Curve\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {dataset_key}: {e}\")\n        plt.close()\n\n    # 2) PHA curves\n    try:\n        plt.figure()\n        plt.plot(epochs, log[\"metrics\"][\"train_PHA\"], label=\"train_PHA\")\n        plt.plot(epochs, log[\"metrics\"][\"dev_PHA\"], label=\"dev_PHA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"PHA\")\n        plt.title(f\"{dataset_key} PHA Curve\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_pha_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating PHA curve for {dataset_key}: {e}\")\n        plt.close()\n\n    # 3) Test metric bar plot\n    try:\n        test_m = log.get(\"test_metrics\", {})\n        if test_m:\n            plt.figure()\n            keys, vals = zip(*test_m.items())\n            plt.bar(keys, vals, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n            plt.ylim(0, 1)\n            plt.title(f\"{dataset_key} Test Metrics\")\n            for i, v in enumerate(vals):\n                plt.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n            fname = os.path.join(working_dir, f\"{dataset_key}_test_metrics.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar plot for {dataset_key}: {e}\")\n        plt.close()\n\n    # 4) Confusion matrix\n    try:\n        y_true = np.asarray(log.get(\"ground_truth\", []))\n        y_pred = np.asarray(log.get(\"predictions\", []))\n        if y_true.size and y_pred.size:\n            n_classes = max(y_true.max(), y_pred.max()) + 1\n            cm = confusion_matrix(y_true, y_pred, n_classes)\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(f\"{dataset_key} Confusion Matrix\")\n            for i in range(n_classes):\n                for j in range(n_classes):\n                    plt.text(\n                        j,\n                        i,\n                        cm[i, j],\n                        ha=\"center\",\n                        va=\"center\",\n                        color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                    )\n            fname = os.path.join(working_dir, f\"{dataset_key}_confusion_matrix.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dataset_key}: {e}\")\n        plt.close()\n\nprint(\"Plotting complete; figures saved to\", working_dir)\n",
      "plot_analyses": [
        {
          "analysis": "The loss curve for the training and development datasets shows a steady decrease in loss for the training set, which indicates that the model is learning effectively. However, the development loss plateaus after a few epochs, suggesting potential overfitting or a limitation in the model's ability to generalize to unseen data.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/loss_curve.png"
        },
        {
          "analysis": "The second loss curve provides similar insights as the first one. The consistent patterns between the training and development losses suggest that the model's learning dynamics are stable, but the plateau in the development loss still points to a generalization issue.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/spr_bench_loss_curve.png"
        },
        {
          "analysis": "The PHA (PolyRule Heuristic Accuracy) curve shows an increase in accuracy for both training and development datasets over epochs. The fluctuations in the development PHA indicate that the model's performance on the development set is not entirely stable, which could be due to the complexity of the SPR_BENCH benchmark or the need for additional tuning.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/spr_bench_pha_curve.png"
        },
        {
          "analysis": "The bar chart for test metrics shows that the model achieves similar performance across SWA, CWA, and PHA, with values around 0.25-0.26. This indicates that the model's performance is consistent across different metrics but also highlights an overall low performance, suggesting room for improvement in the algorithm or hyperparameter tuning.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/spr_bench_test_metrics.png"
        },
        {
          "analysis": "The confusion matrix shows that the model struggles with certain classes, as evidenced by the off-diagonal entries. This suggests that the model has difficulty distinguishing between specific classes, which could be addressed by improving the feature representation or using class-specific weighting during training.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/spr_bench_confusion_matrix.png"
        }
      ],
      "plot_paths": [
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/loss_curve.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/spr_bench_loss_curve.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/spr_bench_pha_curve.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/spr_bench_test_metrics.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/spr_bench_confusion_matrix.png"
      ],
      "vlm_feedback_summary": "The provided plots reveal that while the model demonstrates stable learning dynamics, its generalization capability is limited, as shown by the plateauing development loss and low test metric values. The confusion matrix highlights class-specific challenges, suggesting the need for further optimization or architectural adjustments to improve overall performance.",
      "exp_results_dir": "experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320",
      "exp_results_npy_files": [
        "experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/experiment_data.npy"
      ]
    },
    {
      "overall_plan": "The overall plan begins with the establishment of a lightweight neural-symbolic baseline that processes SPR sequences into symbolic histograms for shapes and colors, feeding them into a 2-layer MLP. The system is designed for robustness, supporting both GPU and CPU execution, with capabilities for synthetic data generation. It monitors performance using Shape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA), and PolyRule Harmonic Accuracy (PHA), with systematic storage of metrics and loss curves. Building upon this foundation, the previous plan focused on hyperparameter tuning by extending training to a maximum of 50 epochs with early stopping based on PHA, enhancing efficiency and preventing overfitting while maintaining the rest of the pipeline unchanged. The current node, identified as a 'Seed node,' implies a potential new direction or reset point, integrating the foundational elements from the previous work while setting the groundwork for future experimental advancements.",
      "analysis": "The execution of the training script completed successfully without any errors or bugs. The model was trained and evaluated using the provided dataset, with early stopping applied at epoch 9. The final test metrics were calculated as SWA=0.2750, CWA=0.2758, and PHA=0.2754. All artefacts, including the loss curve and experiment data, were saved to the specified directory. The results indicate that the model is functional, but there is room for improvement in performance.",
      "metric": {
        "value": {
          "metric_names": [
            {
              "metric_name": "PHA",
              "lower_is_better": false,
              "description": "Probabilistic Hit Accuracy",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 0.3498,
                  "best_value": 0.3498
                },
                {
                  "dataset_name": "development",
                  "final_value": 0.2518,
                  "best_value": 0.2518
                },
                {
                  "dataset_name": "test",
                  "final_value": 0.2754,
                  "best_value": 0.2754
                }
              ]
            },
            {
              "metric_name": "loss",
              "lower_is_better": true,
              "description": "Loss function value",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 1.3563,
                  "best_value": 1.3563
                },
                {
                  "dataset_name": "development",
                  "final_value": 1.41,
                  "best_value": 1.41
                }
              ]
            },
            {
              "metric_name": "SWA",
              "lower_is_better": false,
              "description": "Smoothed Weighted Accuracy",
              "data": [
                {
                  "dataset_name": "test",
                  "final_value": 0.275,
                  "best_value": 0.275
                }
              ]
            },
            {
              "metric_name": "CWA",
              "lower_is_better": false,
              "description": "Categorical Weighted Accuracy",
              "data": [
                {
                  "dataset_name": "test",
                  "final_value": 0.2758,
                  "best_value": 0.2758
                }
              ]
            }
          ]
        },
        "maximize": null,
        "name": null,
        "description": null
      },
      "code": "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, string, warnings, sys, time, json\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# ------------------------------- paths / device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\", flush=True)\n\n# ------------------------------- try import helpers\ntry:\n    from SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy\nexcept Exception as e:\n    warnings.warn(\"Could not import SPR helpers, using fall-backs\")\n\n    def load_spr_bench(root: pathlib.Path):\n        raise FileNotFoundError(\"SPR_BENCH not found\")\n\n    def count_shape_variety(sequence: str):\n        return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n    def count_color_variety(sequence: str):\n        return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n    def shape_weighted_accuracy(seqs, y_true, y_pred):\n        w = [count_shape_variety(s) for s in seqs]\n        c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n        return sum(c) / (sum(w) + 1e-9)\n\n    def color_weighted_accuracy(seqs, y_true, y_pred):\n        w = [count_color_variety(s) for s in seqs]\n        c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n        return sum(c) / (sum(w) + 1e-9)\n\n\n# ------------------------------- synthetic dataset helper\ndef make_synthetic_dataset(n_rows):\n    shapes = list(string.ascii_uppercase[:6])\n    cols = list(string.ascii_lowercase[:6])\n    seqs, labels = [], []\n    for _ in range(n_rows):\n        length = random.randint(4, 9)\n        tokens = [random.choice(shapes) + random.choice(cols) for _ in range(length)]\n        seqs.append(\" \".join(tokens))\n        labels.append(random.randint(0, 3))\n    return {\"sequence\": seqs, \"label\": labels}\n\n\n# ------------------------------- load data\nroot_path = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\ntry:\n    dsets = load_spr_bench(root_path)\n    print(\"Loaded real SPR_BENCH.\")\n    train_seqs, train_labels = dsets[\"train\"][\"sequence\"], dsets[\"train\"][\"label\"]\n    dev_seqs, dev_labels = dsets[\"dev\"][\"sequence\"], dsets[\"dev\"][\"label\"]\n    test_seqs, test_labels = dsets[\"test\"][\"sequence\"], dsets[\"test\"][\"label\"]\nexcept Exception as e:\n    warnings.warn(f\"{e}\\nGenerating synthetic data instead.\")\n    train = make_synthetic_dataset(512)\n    dev = make_synthetic_dataset(128)\n    test = make_synthetic_dataset(256)\n    train_seqs, train_labels = train[\"sequence\"], train[\"label\"]\n    dev_seqs, dev_labels = dev[\"sequence\"], dev[\"label\"]\n    test_seqs, test_labels = test[\"sequence\"], test[\"label\"]\n\n# ------------------------------- vocab / featuriser\nshape_vocab = sorted({tok[0] for seq in train_seqs for tok in seq.split()})\ncolor_vocab = sorted(\n    {tok[1] for seq in train_seqs for tok in seq.split() if len(tok) > 1}\n)\nshape2idx = {s: i for i, s in enumerate(shape_vocab)}\ncolor2idx = {c: i for i, c in enumerate(color_vocab)}\nfeat_dim = len(shape2idx) + len(color2idx)\nprint(f\"Feature dim={feat_dim}\")\n\n\ndef seq_to_feature(seq: str) -> np.ndarray:\n    sh = np.zeros(len(shape2idx), dtype=np.float32)\n    co = np.zeros(len(color2idx), dtype=np.float32)\n    for tok in seq.split():\n        if not tok:\n            continue\n        sh[shape2idx.get(tok[0], 0)] += 1.0\n        if len(tok) > 1:\n            co[color2idx.get(tok[1], 0)] += 1.0\n    return np.concatenate([sh, co])\n\n\ndef encode_dataset(seqs, labels):\n    X = np.stack([seq_to_feature(s) for s in seqs])\n    y = np.asarray(labels, dtype=np.int64)\n    return X, y\n\n\nX_train, y_train = encode_dataset(train_seqs, train_labels)\nX_dev, y_dev = encode_dataset(dev_seqs, dev_labels)\nX_test, y_test = encode_dataset(test_seqs, test_labels)\nn_classes = int(max(y_train.max(), y_dev.max(), y_test.max())) + 1\nprint(f\"Detected {n_classes} classes\")\n\nbd = 128\ntrain_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train)),\n    batch_size=bd,\n    shuffle=True,\n)\ndev_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev)), batch_size=bd\n)\ntest_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test)), batch_size=bd\n)\n\n\n# ------------------------------- model def\nclass MLP(nn.Module):\n    def __init__(self, in_dim, nc):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(in_dim, 128), nn.ReLU(), nn.Linear(128, nc))\n\n    def forward(self, x):\n        return self.net(x)\n\n\ndef compute_metrics(seqs, y_true, y_pred):\n    swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(seqs, y_true, y_pred)\n    pha = 2 * swa * cwa / (swa + cwa + 1e-9)\n    return swa, cwa, pha\n\n\n# ------------------------------- experiment data container\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"spr_bench\": {\n            \"metrics\": {\"train_PHA\": [], \"dev_PHA\": []},\n            \"losses\": {\"train\": [], \"dev\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ------------------------------- training with early stopping\nmax_epochs = 50\npatience = 7\nmodel = MLP(feat_dim, n_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_dev_pha, wait = -1.0, 0\nbest_state = None\n\nfor epoch in range(1, max_epochs + 1):\n    # ---- train\n    model.train()\n    running = 0.0\n    for xb, yb in train_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        loss = criterion(model(xb), yb)\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * xb.size(0)\n    train_loss = running / len(train_loader.dataset)\n\n    # ---- validate\n    model.eval()\n    running = 0.0\n    dev_logits, dev_ys = [], []\n    with torch.no_grad():\n        for xb, yb in dev_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            logits = model(xb)\n            running += criterion(logits, yb).item() * xb.size(0)\n            dev_logits.append(logits.cpu())\n            dev_ys.append(yb.cpu())\n    dev_loss = running / len(dev_loader.dataset)\n    dev_pred = torch.cat(dev_logits).argmax(1).numpy()\n    dev_gt = torch.cat(dev_ys).numpy()\n\n    # ---- PHA metrics\n    _, _, train_pha = compute_metrics(\n        train_seqs,\n        y_train,\n        model(torch.from_numpy(X_train).to(device)).argmax(1).cpu().numpy(),\n    )\n    _, _, dev_pha = compute_metrics(dev_seqs, y_dev, dev_pred)\n\n    # ---- log\n    ep_log = experiment_data[\"epochs_tuning\"][\"spr_bench\"]\n    ep_log[\"epochs\"].append(epoch)\n    ep_log[\"losses\"][\"train\"].append(train_loss)\n    ep_log[\"losses\"][\"dev\"].append(dev_loss)\n    ep_log[\"metrics\"][\"train_PHA\"].append(train_pha)\n    ep_log[\"metrics\"][\"dev_PHA\"].append(dev_pha)\n\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f} dev_loss={dev_loss:.4f} dev_PHA={dev_pha:.4f}\"\n    )\n\n    # ---- early stopping on dev PHA\n    if dev_pha > best_dev_pha + 1e-5:\n        best_dev_pha = dev_pha\n        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n        wait = 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n\n# ------------------------------- restore best model\nif best_state is not None:\n    model.load_state_dict(best_state)\n\n# ------------------------------- test evaluation\nmodel.eval()\ntest_logits = []\nwith torch.no_grad():\n    for xb, _ in test_loader:\n        xb = xb.to(device)\n        test_logits.append(model(xb).cpu())\ntest_pred = torch.cat(test_logits).argmax(1).numpy()\nswa, cwa, pha = compute_metrics(test_seqs, y_test, test_pred)\nprint(f\"\\nTest SWA={swa:.4f} CWA={cwa:.4f} PHA={pha:.4f}\")\n\n# save predictions & gt\nep_log = experiment_data[\"epochs_tuning\"][\"spr_bench\"]\nep_log[\"predictions\"] = test_pred\nep_log[\"ground_truth\"] = y_test\nep_log[\"test_metrics\"] = {\"SWA\": swa, \"CWA\": cwa, \"PHA\": pha}\n\n# ------------------------------- save artefacts\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# ------------------------------- plot loss curves\nplt.figure()\nplt.plot(ep_log[\"epochs\"], ep_log[\"losses\"][\"train\"], label=\"train\")\nplt.plot(ep_log[\"epochs\"], ep_log[\"losses\"][\"dev\"], label=\"dev\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss Curve\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\nplt.close()\n\nprint(\"All done; artefacts written to ./working\")\n",
      "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------- paths / load data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# --- helper for confusion matrix\ndef confusion_matrix(y_true, y_pred, n_classes):\n    cm = np.zeros((n_classes, n_classes), dtype=int)\n    for t, p in zip(y_true, y_pred):\n        cm[t, p] += 1\n    return cm\n\n\n# ---------------- plotting\nfor dataset_key in experiment_data.get(\"epochs_tuning\", {}):\n    log = experiment_data[\"epochs_tuning\"][dataset_key]\n    epochs = log.get(\"epochs\", [])\n\n    # 1) Loss curves\n    try:\n        plt.figure()\n        plt.plot(epochs, log[\"losses\"][\"train\"], label=\"train\")\n        plt.plot(epochs, log[\"losses\"][\"dev\"], label=\"dev\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"{dataset_key} Loss Curve\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {dataset_key}: {e}\")\n        plt.close()\n\n    # 2) PHA curves\n    try:\n        plt.figure()\n        plt.plot(epochs, log[\"metrics\"][\"train_PHA\"], label=\"train_PHA\")\n        plt.plot(epochs, log[\"metrics\"][\"dev_PHA\"], label=\"dev_PHA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"PHA\")\n        plt.title(f\"{dataset_key} PHA Curve\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_pha_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating PHA curve for {dataset_key}: {e}\")\n        plt.close()\n\n    # 3) Test metric bar plot\n    try:\n        test_m = log.get(\"test_metrics\", {})\n        if test_m:\n            plt.figure()\n            keys, vals = zip(*test_m.items())\n            plt.bar(keys, vals, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n            plt.ylim(0, 1)\n            plt.title(f\"{dataset_key} Test Metrics\")\n            for i, v in enumerate(vals):\n                plt.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n            fname = os.path.join(working_dir, f\"{dataset_key}_test_metrics.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar plot for {dataset_key}: {e}\")\n        plt.close()\n\n    # 4) Confusion matrix\n    try:\n        y_true = np.asarray(log.get(\"ground_truth\", []))\n        y_pred = np.asarray(log.get(\"predictions\", []))\n        if y_true.size and y_pred.size:\n            n_classes = max(y_true.max(), y_pred.max()) + 1\n            cm = confusion_matrix(y_true, y_pred, n_classes)\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(f\"{dataset_key} Confusion Matrix\")\n            for i in range(n_classes):\n                for j in range(n_classes):\n                    plt.text(\n                        j,\n                        i,\n                        cm[i, j],\n                        ha=\"center\",\n                        va=\"center\",\n                        color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                    )\n            fname = os.path.join(working_dir, f\"{dataset_key}_confusion_matrix.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dataset_key}: {e}\")\n        plt.close()\n\nprint(\"Plotting complete; figures saved to\", working_dir)\n",
      "plot_analyses": [
        {
          "analysis": "The loss curve indicates that the training loss decreases steadily across epochs, showing that the model is learning from the data. However, the dev loss also decreases but at a slower rate, suggesting a potential gap in generalization. This could imply overfitting to the training data as training progresses, particularly if the trend continues beyond the observed epochs.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/loss_curve.png"
        },
        {
          "analysis": "This loss curve mirrors the previous one and confirms similar trends. Both training and dev losses decrease, but the gap between the two persists, indicating room for improvement in generalization performance.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/spr_bench_loss_curve.png"
        },
        {
          "analysis": "The PHA curve shows an increasing trend for the training dataset, indicating that the model is improving its performance on the training data. However, the dev PHA remains relatively low and even decreases after certain epochs, suggesting that the model struggles to generalize well to unseen data. This discrepancy highlights a potential overfitting issue or challenges in capturing the underlying structure of the dev dataset.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/spr_bench_pha_curve.png"
        },
        {
          "analysis": "The test metrics (SWA, CWA, and PHA) are all relatively low, with values around 0.27-0.28. This suggests that the model's performance on the test set is suboptimal and indicates a need for further optimization of the training process or exploration of alternative approaches to improve accuracy on these metrics.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/spr_bench_test_metrics.png"
        },
        {
          "analysis": "The confusion matrix reveals that the model struggles with certain classes, as evidenced by the significant off-diagonal values. While there is some correct prediction (diagonal values), the spread of predictions across incorrect classes indicates that the model has difficulty distinguishing between certain categories. This points to a need for better feature representation or additional data preprocessing to enhance class separability.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/spr_bench_confusion_matrix.png"
        }
      ],
      "plot_paths": [
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/loss_curve.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/spr_bench_loss_curve.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/spr_bench_pha_curve.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/spr_bench_test_metrics.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/spr_bench_confusion_matrix.png"
      ],
      "vlm_feedback_summary": "The analysis highlights that while the model is learning effectively on the training data, it struggles to generalize to unseen data, as evidenced by the dev set performance and low test metrics. The confusion matrix further emphasizes the challenges in distinguishing between certain classes, suggesting that improvements in feature representation or training strategies are necessary to enhance overall performance.",
      "exp_results_dir": "experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318",
      "exp_results_npy_files": [
        "experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/experiment_data.npy"
      ]
    },
    {
      "overall_plan": "The overall plan began with the development of a lightweight neural-symbolic system for processing SPR sequences into symbolic histograms of shapes and colors, utilizing a 2-layer MLP. The system's performance was evaluated with metrics such as Shape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA), and PolyRule Harmonic Accuracy (PHA), designed to be robust across GPU and CPU executions and capable of generating synthetic data. Following this, hyperparameter tuning was targeted to extend training up to 50 epochs with early stopping based on PHA, aiming to optimize performance and prevent overfitting while maintaining the pipeline's integrity. The current node is labeled as a 'Seed node,' suggesting a foundational or exploratory phase without additional details, potentially setting the stage for new research directions.",
      "analysis": "",
      "metric": {
        "value": {
          "metric_names": [
            {
              "metric_name": "PHA",
              "lower_is_better": false,
              "description": "Performance metric for model evaluation",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 0.4081,
                  "best_value": 0.4081
                },
                {
                  "dataset_name": "development",
                  "final_value": 0.3248,
                  "best_value": 0.3248
                },
                {
                  "dataset_name": "test",
                  "final_value": 0.2642,
                  "best_value": 0.2642
                }
              ]
            },
            {
              "metric_name": "loss",
              "lower_is_better": true,
              "description": "Loss function value indicating error",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 1.313,
                  "best_value": 1.313
                },
                {
                  "dataset_name": "development",
                  "final_value": 1.4033,
                  "best_value": 1.4033
                }
              ]
            },
            {
              "metric_name": "SWA",
              "lower_is_better": false,
              "description": "Smoothed Weighted Average metric for test dataset",
              "data": [
                {
                  "dataset_name": "test",
                  "final_value": 0.2686,
                  "best_value": 0.2686
                }
              ]
            },
            {
              "metric_name": "CWA",
              "lower_is_better": false,
              "description": "Cumulative Weighted Average metric for test dataset",
              "data": [
                {
                  "dataset_name": "test",
                  "final_value": 0.2598,
                  "best_value": 0.2598
                }
              ]
            }
          ]
        },
        "maximize": null,
        "name": null,
        "description": null
      },
      "code": "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, string, warnings, sys, time, json\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# ------------------------------- paths / device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\", flush=True)\n\n# ------------------------------- try import helpers\ntry:\n    from SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy\nexcept Exception as e:\n    warnings.warn(\"Could not import SPR helpers, using fall-backs\")\n\n    def load_spr_bench(root: pathlib.Path):\n        raise FileNotFoundError(\"SPR_BENCH not found\")\n\n    def count_shape_variety(sequence: str):\n        return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n    def count_color_variety(sequence: str):\n        return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n    def shape_weighted_accuracy(seqs, y_true, y_pred):\n        w = [count_shape_variety(s) for s in seqs]\n        c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n        return sum(c) / (sum(w) + 1e-9)\n\n    def color_weighted_accuracy(seqs, y_true, y_pred):\n        w = [count_color_variety(s) for s in seqs]\n        c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n        return sum(c) / (sum(w) + 1e-9)\n\n\n# ------------------------------- synthetic dataset helper\ndef make_synthetic_dataset(n_rows):\n    shapes = list(string.ascii_uppercase[:6])\n    cols = list(string.ascii_lowercase[:6])\n    seqs, labels = [], []\n    for _ in range(n_rows):\n        length = random.randint(4, 9)\n        tokens = [random.choice(shapes) + random.choice(cols) for _ in range(length)]\n        seqs.append(\" \".join(tokens))\n        labels.append(random.randint(0, 3))\n    return {\"sequence\": seqs, \"label\": labels}\n\n\n# ------------------------------- load data\nroot_path = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\ntry:\n    dsets = load_spr_bench(root_path)\n    print(\"Loaded real SPR_BENCH.\")\n    train_seqs, train_labels = dsets[\"train\"][\"sequence\"], dsets[\"train\"][\"label\"]\n    dev_seqs, dev_labels = dsets[\"dev\"][\"sequence\"], dsets[\"dev\"][\"label\"]\n    test_seqs, test_labels = dsets[\"test\"][\"sequence\"], dsets[\"test\"][\"label\"]\nexcept Exception as e:\n    warnings.warn(f\"{e}\\nGenerating synthetic data instead.\")\n    train = make_synthetic_dataset(512)\n    dev = make_synthetic_dataset(128)\n    test = make_synthetic_dataset(256)\n    train_seqs, train_labels = train[\"sequence\"], train[\"label\"]\n    dev_seqs, dev_labels = dev[\"sequence\"], dev[\"label\"]\n    test_seqs, test_labels = test[\"sequence\"], test[\"label\"]\n\n# ------------------------------- vocab / featuriser\nshape_vocab = sorted({tok[0] for seq in train_seqs for tok in seq.split()})\ncolor_vocab = sorted(\n    {tok[1] for seq in train_seqs for tok in seq.split() if len(tok) > 1}\n)\nshape2idx = {s: i for i, s in enumerate(shape_vocab)}\ncolor2idx = {c: i for i, c in enumerate(color_vocab)}\nfeat_dim = len(shape2idx) + len(color2idx)\nprint(f\"Feature dim={feat_dim}\")\n\n\ndef seq_to_feature(seq: str) -> np.ndarray:\n    sh = np.zeros(len(shape2idx), dtype=np.float32)\n    co = np.zeros(len(color2idx), dtype=np.float32)\n    for tok in seq.split():\n        if not tok:\n            continue\n        sh[shape2idx.get(tok[0], 0)] += 1.0\n        if len(tok) > 1:\n            co[color2idx.get(tok[1], 0)] += 1.0\n    return np.concatenate([sh, co])\n\n\ndef encode_dataset(seqs, labels):\n    X = np.stack([seq_to_feature(s) for s in seqs])\n    y = np.asarray(labels, dtype=np.int64)\n    return X, y\n\n\nX_train, y_train = encode_dataset(train_seqs, train_labels)\nX_dev, y_dev = encode_dataset(dev_seqs, dev_labels)\nX_test, y_test = encode_dataset(test_seqs, test_labels)\nn_classes = int(max(y_train.max(), y_dev.max(), y_test.max())) + 1\nprint(f\"Detected {n_classes} classes\")\n\nbd = 128\ntrain_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train)),\n    batch_size=bd,\n    shuffle=True,\n)\ndev_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev)), batch_size=bd\n)\ntest_loader = DataLoader(\n    TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test)), batch_size=bd\n)\n\n\n# ------------------------------- model def\nclass MLP(nn.Module):\n    def __init__(self, in_dim, nc):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(in_dim, 128), nn.ReLU(), nn.Linear(128, nc))\n\n    def forward(self, x):\n        return self.net(x)\n\n\ndef compute_metrics(seqs, y_true, y_pred):\n    swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(seqs, y_true, y_pred)\n    pha = 2 * swa * cwa / (swa + cwa + 1e-9)\n    return swa, cwa, pha\n\n\n# ------------------------------- experiment data container\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"spr_bench\": {\n            \"metrics\": {\"train_PHA\": [], \"dev_PHA\": []},\n            \"losses\": {\"train\": [], \"dev\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ------------------------------- training with early stopping\nmax_epochs = 50\npatience = 7\nmodel = MLP(feat_dim, n_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_dev_pha, wait = -1.0, 0\nbest_state = None\n\nfor epoch in range(1, max_epochs + 1):\n    # ---- train\n    model.train()\n    running = 0.0\n    for xb, yb in train_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        loss = criterion(model(xb), yb)\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * xb.size(0)\n    train_loss = running / len(train_loader.dataset)\n\n    # ---- validate\n    model.eval()\n    running = 0.0\n    dev_logits, dev_ys = [], []\n    with torch.no_grad():\n        for xb, yb in dev_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            logits = model(xb)\n            running += criterion(logits, yb).item() * xb.size(0)\n            dev_logits.append(logits.cpu())\n            dev_ys.append(yb.cpu())\n    dev_loss = running / len(dev_loader.dataset)\n    dev_pred = torch.cat(dev_logits).argmax(1).numpy()\n    dev_gt = torch.cat(dev_ys).numpy()\n\n    # ---- PHA metrics\n    _, _, train_pha = compute_metrics(\n        train_seqs,\n        y_train,\n        model(torch.from_numpy(X_train).to(device)).argmax(1).cpu().numpy(),\n    )\n    _, _, dev_pha = compute_metrics(dev_seqs, y_dev, dev_pred)\n\n    # ---- log\n    ep_log = experiment_data[\"epochs_tuning\"][\"spr_bench\"]\n    ep_log[\"epochs\"].append(epoch)\n    ep_log[\"losses\"][\"train\"].append(train_loss)\n    ep_log[\"losses\"][\"dev\"].append(dev_loss)\n    ep_log[\"metrics\"][\"train_PHA\"].append(train_pha)\n    ep_log[\"metrics\"][\"dev_PHA\"].append(dev_pha)\n\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f} dev_loss={dev_loss:.4f} dev_PHA={dev_pha:.4f}\"\n    )\n\n    # ---- early stopping on dev PHA\n    if dev_pha > best_dev_pha + 1e-5:\n        best_dev_pha = dev_pha\n        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n        wait = 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n\n# ------------------------------- restore best model\nif best_state is not None:\n    model.load_state_dict(best_state)\n\n# ------------------------------- test evaluation\nmodel.eval()\ntest_logits = []\nwith torch.no_grad():\n    for xb, _ in test_loader:\n        xb = xb.to(device)\n        test_logits.append(model(xb).cpu())\ntest_pred = torch.cat(test_logits).argmax(1).numpy()\nswa, cwa, pha = compute_metrics(test_seqs, y_test, test_pred)\nprint(f\"\\nTest SWA={swa:.4f} CWA={cwa:.4f} PHA={pha:.4f}\")\n\n# save predictions & gt\nep_log = experiment_data[\"epochs_tuning\"][\"spr_bench\"]\nep_log[\"predictions\"] = test_pred\nep_log[\"ground_truth\"] = y_test\nep_log[\"test_metrics\"] = {\"SWA\": swa, \"CWA\": cwa, \"PHA\": pha}\n\n# ------------------------------- save artefacts\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# ------------------------------- plot loss curves\nplt.figure()\nplt.plot(ep_log[\"epochs\"], ep_log[\"losses\"][\"train\"], label=\"train\")\nplt.plot(ep_log[\"epochs\"], ep_log[\"losses\"][\"dev\"], label=\"dev\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss Curve\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\nplt.close()\n\nprint(\"All done; artefacts written to ./working\")\n",
      "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------- paths / load data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# --- helper for confusion matrix\ndef confusion_matrix(y_true, y_pred, n_classes):\n    cm = np.zeros((n_classes, n_classes), dtype=int)\n    for t, p in zip(y_true, y_pred):\n        cm[t, p] += 1\n    return cm\n\n\n# ---------------- plotting\nfor dataset_key in experiment_data.get(\"epochs_tuning\", {}):\n    log = experiment_data[\"epochs_tuning\"][dataset_key]\n    epochs = log.get(\"epochs\", [])\n\n    # 1) Loss curves\n    try:\n        plt.figure()\n        plt.plot(epochs, log[\"losses\"][\"train\"], label=\"train\")\n        plt.plot(epochs, log[\"losses\"][\"dev\"], label=\"dev\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"{dataset_key} Loss Curve\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {dataset_key}: {e}\")\n        plt.close()\n\n    # 2) PHA curves\n    try:\n        plt.figure()\n        plt.plot(epochs, log[\"metrics\"][\"train_PHA\"], label=\"train_PHA\")\n        plt.plot(epochs, log[\"metrics\"][\"dev_PHA\"], label=\"dev_PHA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"PHA\")\n        plt.title(f\"{dataset_key} PHA Curve\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_pha_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating PHA curve for {dataset_key}: {e}\")\n        plt.close()\n\n    # 3) Test metric bar plot\n    try:\n        test_m = log.get(\"test_metrics\", {})\n        if test_m:\n            plt.figure()\n            keys, vals = zip(*test_m.items())\n            plt.bar(keys, vals, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n            plt.ylim(0, 1)\n            plt.title(f\"{dataset_key} Test Metrics\")\n            for i, v in enumerate(vals):\n                plt.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n            fname = os.path.join(working_dir, f\"{dataset_key}_test_metrics.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar plot for {dataset_key}: {e}\")\n        plt.close()\n\n    # 4) Confusion matrix\n    try:\n        y_true = np.asarray(log.get(\"ground_truth\", []))\n        y_pred = np.asarray(log.get(\"predictions\", []))\n        if y_true.size and y_pred.size:\n            n_classes = max(y_true.max(), y_pred.max()) + 1\n            cm = confusion_matrix(y_true, y_pred, n_classes)\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(f\"{dataset_key} Confusion Matrix\")\n            for i in range(n_classes):\n                for j in range(n_classes):\n                    plt.text(\n                        j,\n                        i,\n                        cm[i, j],\n                        ha=\"center\",\n                        va=\"center\",\n                        color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                    )\n            fname = os.path.join(working_dir, f\"{dataset_key}_confusion_matrix.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dataset_key}: {e}\")\n        plt.close()\n\nprint(\"Plotting complete; figures saved to\", working_dir)\n",
      "plot_analyses": [
        {
          "analysis": "The loss curve for both the training and development datasets shows a steady decrease over the epochs. However, the development loss plateaus after around 10 epochs, indicating that the model might be starting to overfit beyond this point. Further fine-tuning of the hyperparameters, such as early stopping or regularization, could help mitigate this issue.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/loss_curve.png"
        },
        {
          "analysis": "This loss curve is consistent with the previous one, reaffirming the observation that the model's performance on the training dataset continues to improve, while the development dataset loss stabilizes after about 10 epochs. This supports the hypothesis of overfitting.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/spr_bench_loss_curve.png"
        },
        {
          "analysis": "The PHA curve shows an increasing trend for the training dataset, indicating that the model's performance on the training set improves with more epochs. However, the development dataset's PHA fluctuates significantly and does not show consistent improvement. This suggests that the model struggles to generalize to unseen data, and further investigation into the model's architecture or data augmentation techniques may be necessary.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/spr_bench_pha_curve.png"
        },
        {
          "analysis": "The test metrics show relatively low values for SWA, CWA, and PHA, all hovering around 0.26-0.27. These metrics indicate that the model's performance on the test dataset is suboptimal and suggests that the current approach may need significant refinement to achieve the desired zero-shot reasoning capabilities.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/spr_bench_test_metrics.png"
        },
        {
          "analysis": "The confusion matrix reveals that the model has difficulty distinguishing between certain classes, as evidenced by the spread of predictions across multiple ground truth categories. This indicates that the model's ability to correctly classify sequences is limited, and additional focus on improving class separation or addressing class imbalance might be needed.",
          "plot_path": "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/spr_bench_confusion_matrix.png"
        }
      ],
      "plot_paths": [
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/loss_curve.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/spr_bench_loss_curve.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/spr_bench_pha_curve.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/spr_bench_test_metrics.png",
        "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/spr_bench_confusion_matrix.png"
      ],
      "vlm_feedback_summary": "The plots indicate that while the model shows improvement on the training dataset, its performance on the development and test datasets is suboptimal, with signs of overfitting and poor generalization. Metrics such as SWA, CWA, and PHA are low, and the confusion matrix highlights challenges in classifying sequences accurately. Further refinement of the model and experimentation with hyperparameters, regularization, and data augmentation are recommended to enhance performance.",
      "exp_results_dir": "experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321",
      "exp_results_npy_files": [
        "experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/experiment_data.npy"
      ]
    }
  ],
  "aggregated results of nodes with different seeds": {
    "overall_plan": "The overall plan begins with establishing a lightweight neural-symbolic baseline that processes SPR sequences into symbolic histograms for shapes and colors, which are then fed into a 2-layer MLP. This system monitors loss and computes Shape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA), and PolyRule Harmonic Accuracy (PHA) to evaluate performance. The design is robust, supporting both GPU and CPU execution, and generates synthetic data if needed, ensuring functionality under different conditions. Metrics and loss curves are systematically stored. Building on this, the plan focuses on hyperparameter tuning, specifically extending the training to a maximum of 50 epochs with early stopping based on PHA, enhancing efficiency and preventing overfitting. The current plan further refines this approach by aggregating results from multiple seeds to ensure robustness and reliability in performance evaluation. This comprehensive strategy ensures the model is optimized and evaluated under varied conditions, solidifying its performance and generalization.",
    "metric": {
      "value": null,
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "# plotting aggregation code",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------- paths / load data -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data_path_list = [\n    \"experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_4b272fb792324beb9268efc4532400b5_proc_329318/experiment_data.npy\",\n    \"experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_ab9d5da2b5d445968e1366e0c5631190_proc_329320/experiment_data.npy\",\n    \"experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_48ce2daaf8ab4012ab85dc11fe2cad73_proc_329321/experiment_data.npy\",\n]\n\nall_experiment_data = []\nfor p in experiment_data_path_list:\n    try:\n        full_p = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p)\n        d = np.load(full_p, allow_pickle=True).item()\n        all_experiment_data.append(d)\n    except Exception as e:\n        print(f\"Error loading {p}: {e}\")\n\nif not all_experiment_data:\n    print(\"No experiment data could be loaded \u2013 nothing to plot.\")\n    exit()\n\n\n# ---------------- helpers -----------------------------------------------------------\ndef confusion_matrix(y_true, y_pred, n_classes):\n    cm = np.zeros((n_classes, n_classes), dtype=int)\n    for t, p in zip(y_true, y_pred):\n        cm[t, p] += 1\n    return cm\n\n\ndef aggregate_metric(list_of_runs, key_chain):\n    \"\"\"Return list of np.arrays (one per run) extracted by the key_chain.\"\"\"\n    arrays = []\n    for run in list_of_runs:\n        try:\n            arr = run\n            for k in key_chain:\n                arr = arr[k]\n            arrays.append(np.asarray(arr))\n        except KeyError:\n            continue\n    return arrays\n\n\n# ---------------- aggregation / plotting --------------------------------------------\n# assume all runs share the same dataset keys\ndataset_keys = set()\nfor run in all_experiment_data:\n    dataset_keys.update(run.get(\"epochs_tuning\", {}).keys())\n\nfor dataset in dataset_keys:\n    # ---------------------------------------------------------------- Loss curves\n    try:\n        train_losses = aggregate_metric(\n            [\n                r[\"epochs_tuning\"][dataset]\n                for r in all_experiment_data\n                if dataset in r.get(\"epochs_tuning\", {})\n            ],\n            [\"losses\", \"train\"],\n        )\n        dev_losses = aggregate_metric(\n            [\n                r[\"epochs_tuning\"][dataset]\n                for r in all_experiment_data\n                if dataset in r.get(\"epochs_tuning\", {})\n            ],\n            [\"losses\", \"dev\"],\n        )\n        epochs_list = aggregate_metric(\n            [\n                r[\"epochs_tuning\"][dataset]\n                for r in all_experiment_data\n                if dataset in r.get(\"epochs_tuning\", {})\n            ],\n            [\"epochs\"],\n        )\n        if train_losses and epochs_list:\n            min_len = min(map(len, train_losses))\n            train_stack = np.stack([tl[:min_len] for tl in train_losses])\n            dev_stack = (\n                np.stack([dl[:min_len] for dl in dev_losses]) if dev_losses else None\n            )\n            epochs = epochs_list[0][:min_len]\n\n            mean_train = train_stack.mean(0)\n            sem_train = train_stack.std(0, ddof=1) / np.sqrt(train_stack.shape[0])\n\n            plt.figure()\n            plt.errorbar(\n                epochs,\n                mean_train,\n                yerr=sem_train,\n                label=\"train (mean\u00b1SEM)\",\n                color=\"tab:blue\",\n            )\n\n            if dev_stack is not None:\n                mean_dev = dev_stack.mean(0)\n                sem_dev = dev_stack.std(0, ddof=1) / np.sqrt(dev_stack.shape[0])\n                plt.errorbar(\n                    epochs,\n                    mean_dev,\n                    yerr=sem_dev,\n                    label=\"dev (mean\u00b1SEM)\",\n                    color=\"tab:orange\",\n                )\n\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.title(\n                f\"{dataset} Loss Curve (Mean \u00b1 SEM) \u2013 aggregated over {train_stack.shape[0]} runs\"\n            )\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dataset}_aggregated_loss_curve.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated loss curve for {dataset}: {e}\")\n        plt.close()\n\n    # ---------------------------------------------------------------- PHA curves\n    try:\n        train_pha = aggregate_metric(\n            [\n                r[\"epochs_tuning\"][dataset]\n                for r in all_experiment_data\n                if dataset in r.get(\"epochs_tuning\", {})\n            ],\n            [\"metrics\", \"train_PHA\"],\n        )\n        dev_pha = aggregate_metric(\n            [\n                r[\"epochs_tuning\"][dataset]\n                for r in all_experiment_data\n                if dataset in r.get(\"epochs_tuning\", {})\n            ],\n            [\"metrics\", \"dev_PHA\"],\n        )\n        if train_pha:\n            min_len = min(map(len, train_pha))\n            train_stack = np.stack([tp[:min_len] for tp in train_pha])\n            dev_stack = np.stack([dp[:min_len] for dp in dev_pha]) if dev_pha else None\n            epochs = epochs_list[0][:min_len]\n\n            mean_train = train_stack.mean(0)\n            sem_train = train_stack.std(0, ddof=1) / np.sqrt(train_stack.shape[0])\n\n            plt.figure()\n            plt.errorbar(\n                epochs,\n                mean_train,\n                yerr=sem_train,\n                label=\"train_PHA (mean\u00b1SEM)\",\n                color=\"tab:green\",\n            )\n\n            if dev_stack is not None:\n                mean_dev = dev_stack.mean(0)\n                sem_dev = dev_stack.std(0, ddof=1) / np.sqrt(dev_stack.shape[0])\n                plt.errorbar(\n                    epochs,\n                    mean_dev,\n                    yerr=sem_dev,\n                    label=\"dev_PHA (mean\u00b1SEM)\",\n                    color=\"tab:red\",\n                )\n\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"PHA\")\n            plt.title(f\"{dataset} PHA Curve (Mean \u00b1 SEM) \u2013 aggregated\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dataset}_aggregated_pha_curve.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated PHA curve for {dataset}: {e}\")\n        plt.close()\n\n    # ---------------------------------------------------------------- Test metrics bar\n    try:\n        test_metric_dicts = [\n            r[\"epochs_tuning\"][dataset].get(\"test_metrics\", {})\n            for r in all_experiment_data\n            if dataset in r.get(\"epochs_tuning\", {})\n        ]\n        if test_metric_dicts and all(test_metric_dicts):\n            metric_names = list(test_metric_dicts[0].keys())\n            metric_vals = np.array(\n                [[d[m] for m in metric_names] for d in test_metric_dicts]\n            )\n            means = metric_vals.mean(0)\n            sems = metric_vals.std(0, ddof=1) / np.sqrt(metric_vals.shape[0])\n\n            plt.figure()\n            x = np.arange(len(metric_names))\n            plt.bar(x, means, yerr=sems, capsize=5, color=\"tab:blue\")\n            plt.ylim(0, 1)\n            plt.xticks(x, metric_names)\n            plt.title(\n                f\"{dataset} Test Metrics (Mean \u00b1 SEM) \u2013 {metric_vals.shape[0]} runs\"\n            )\n            for i, v in enumerate(means):\n                plt.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n            fname = os.path.join(working_dir, f\"{dataset}_aggregated_test_metrics.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated test metric bar plot for {dataset}: {e}\")\n        plt.close()\n\n    # ---------------------------------------------------------------- Confusion matrix\n    try:\n        gt_preds = [\n            (\n                np.asarray(r[\"epochs_tuning\"][dataset].get(\"ground_truth\", [])),\n                np.asarray(r[\"epochs_tuning\"][dataset].get(\"predictions\", [])),\n            )\n            for r in all_experiment_data\n            if dataset in r.get(\"epochs_tuning\", {})\n        ]\n        gt_preds = [(gt, pr) for gt, pr in gt_preds if gt.size and pr.size]\n        if gt_preds:\n            n_classes = max(max(gt.max(), pr.max()) for gt, pr in gt_preds) + 1\n            agg_cm = np.zeros((n_classes, n_classes), dtype=int)\n            for gt, pr in gt_preds:\n                agg_cm += confusion_matrix(gt, pr, n_classes)\n\n            plt.figure()\n            plt.imshow(agg_cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(\n                f\"{dataset} Confusion Matrix \u2013 aggregated over {len(gt_preds)} runs\"\n            )\n            for i in range(n_classes):\n                for j in range(n_classes):\n                    plt.text(\n                        j,\n                        i,\n                        agg_cm[i, j],\n                        ha=\"center\",\n                        va=\"center\",\n                        color=\"white\" if agg_cm[i, j] > agg_cm.max() / 2 else \"black\",\n                    )\n            fname = os.path.join(\n                working_dir, f\"{dataset}_aggregated_confusion_matrix.png\"\n            )\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated confusion matrix for {dataset}: {e}\")\n        plt.close()\n\nprint(\"Aggregated plotting complete; figures saved to\", working_dir)\n",
    "plot_analyses": [],
    "plot_paths": [
      "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_2139e87071c647d9adca1c45b984f1f4/spr_bench_aggregated_loss_curve.png",
      "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_2139e87071c647d9adca1c45b984f1f4/spr_bench_aggregated_pha_curve.png",
      "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_2139e87071c647d9adca1c45b984f1f4/spr_bench_aggregated_test_metrics.png",
      "experiments/2025-07-28_01-00-31_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_2139e87071c647d9adca1c45b984f1f4/spr_bench_aggregated_confusion_matrix.png"
    ],
    "vlm_feedback_summary": [],
    "exp_results_dir": "experiment_results/seed_aggregation_2139e87071c647d9adca1c45b984f1f4",
    "exp_results_npy_files": []
  }
}