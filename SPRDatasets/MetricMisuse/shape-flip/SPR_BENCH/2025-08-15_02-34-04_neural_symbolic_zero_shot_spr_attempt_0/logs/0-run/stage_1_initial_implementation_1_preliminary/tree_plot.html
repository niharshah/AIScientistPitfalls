<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 7], [0, 4], [0, 5], [2, 6], [4, 10], [4, 9], [4, 8], [4, 11]], "layout": [[0.45454545454545453, 0.0], [0.6363636363636364, 0.0], [0.8181818181818182, 0.0], [1.0, 0.0], [0.2727272727272727, 0.5], [0.45454545454545453, 0.5], [0.8181818181818182, 0.5], [0.6363636363636364, 0.5], [0.0, 1.0], [0.18181818181818182, 1.0], [0.36363636363636365, 1.0], [0.5454545454545454, 1.0]], "plan": ["We will build a small neural-symbolic baseline that encodes each shape-color\ntoken, feeds the sequence to a bidirectional GRU, and predicts the rule label.\nThe vocabulary is learned from the training split of SPR_BENCH, sequences are\npadded to the batch-max length, and the whole model is trained for a few quick\nepochs with Adam.  After every epoch we compute Shape-Weighted Accuracy (SWA),\nColor-Weighted Accuracy (CWA) and their Harmonic mean (HWA) on the dev set,\nprinting and recording them together with the validation loss.  All metrics,\nlosses, predictions and ground-truth labels are stored in the mandatory\nexperiment_data dict and saved to ./working/experiment_data.npy.  A\ntraining/validation loss curve is plotted and saved to\n./working/spr_loss_curve.png.  The script follows all GPU handling, data-saving\nand code-structure constraints so it can be run as a single self-contained file\nin under 30 minutes.", "We propose a simple yet effective neural-symbolic baseline: convert each SPR\nsequence into symbolic count features (bag-of-shapes, bag-of-colors, and bag-of-\ntoken-pairs), feed these interpretable vectors to a single-layer soft-max\nclassifier implemented in PyTorch, and train with cross-entropy on the train\nsplit. Because the features are explicit symbol statistics, they already encode\nrule-level information and allow zero-shot generalization to unseen\ncombinations; the neural layer supplies flexible weighting. We train for a small\nnumber of epochs, evaluate after every epoch on the dev set, and report Shape-\nWeighted Accuracy (SWA), Color-Weighted Accuracy (CWA), and their harmonic mean\n(HWA). All metrics, losses, predictions, and ground truth are stored in\nexperiment_data and saved; a loss/HWA curve is also plotted and written in\nworking_dir. This provides a fully working end-to-end pipeline (data \u2192 features\n\u2192 model \u2192 metrics/plots) that can later be extended with more sophisticated\nneural-symbolic reasoning.", "We begin with a minimal neural-symbolic baseline that treats each two-character\nshape-color token as a discrete symbol and performs reasoning by learning linear\ndecision boundaries over a symbolic multi-hot vector.  All unique tokens in the\ntraining split become a vocabulary; each sequence is converted to a binary\nvector that flags which rules (tokens) are present, giving the network purely\nsymbolic input.  A shallow multilayer perceptron (multi-hot \u2192 256-ReLU \u2192 output)\nis trained with cross-entropy, exploiting a GPU when available.  At every epoch\nwe compute Shape-Weighted Accuracy, Color-Weighted Accuracy and their Harmonic\nmean (HWA) on the dev set, logging the values into the required experiment_data\nstructure and printing validation loss.  After training we evaluate once on the\nheld-out test set, report the three metrics and save predictions, ground-truth\nand metric curves as .npy files inside ./working.  If the official SPR_BENCH\nfolder is absent we automatically synthesize a tiny toy dataset so the script\nalways runs.  Although simple, this model establishes a solid symbolic baseline\nthat later neural-symbolic variants (e.g., rule-induction Transformers) must\nbeat.", "We will treat each SPR sequence as a sentence whose \u201cwords\u2019\u2019 are the two-\ncharacter shape-color tokens; a small neural text classifier can already yield a\nmeaningful baseline.  After loading SPR_BENCH with the helper in SPR.py we build\na vocabulary from the training split, map every token to an integer (0 = pad),\nand create PyTorch datasets that return padded LongTensor sequences plus their\nlabels.  The model is an Embedding layer followed by a bi-directional LSTM whose\nfinal hidden state is fed to a linear classifier; this is trained with cross-\nentropy for a few epochs.  At the end of every epoch we compute validation loss\ntogether with Shape-Weighted Accuracy (SWA) and Color-Weighted Accuracy (CWA)\nusing the provided utility functions, then derive the Harmonic Weighted Accuracy\n(HWA).  All losses, metrics, predictions, and ground-truth labels are stored in\nthe experiment_data dictionary and saved to ./working/experiment_data.npy for\nlater analysis.  The script honours the GPU/CPU requirements, moves every tensor\nto the correct device, and prints epoch-wise progress.  Although simple, this\nbaseline gives us a solid reference point before attempting true zero-shot\nneural-symbolic integration in future iterations.", "The crash occurred because the code hard-coded a single absolute dataset path:\nif that directory is missing, every run fails.   I add a small utility that\nrobustly locates the SPR_BENCH folder: first the environment variable\n`$SPR_DIR`, then `./SPR_BENCH`, and finally a walk up the parent directories.\nIf the folder still isn\u2019t found we raise a clear error message.  All subsequent\nlogic is unchanged except for replacing the old path with the new finder, so\ntraining now starts as soon as the dataset is anywhere discoverable.", "The failure occurred because the script assumed the SPR_BENCH directory would\nalways be at \u201c./SPR_BENCH\u201d.  When the working directory changed (e.g. inside the\nexperiment sub-folder) the relative path became invalid and the loader crashed.\nThe fix is to add a small helper that automatically looks for the benchmark in a\nset of sensible locations: (1) the SPR_DIR environment variable, (2) the current\nworking directory, and (3) every parent directory upward until it finds the\nthree required CSV files.  This makes the code robust to being launched from any\nsub-folder without manually setting an environment variable.", "The issue arose because the subclass `SPRVectorDataset` unintentionally\ninherited from Hugging-Face\u2019s `datasets.Dataset` (after that name was re-\nimported) instead of PyTorch\u2019s `torch.utils.data.Dataset`.   `DataLoader`\ntherefore handed a *list* of indices to the dataset \u2015 a calling convention the\nHF class expects \u2015 and our `__getitem__` that assumed a single integer crashed.\nThe fix is to explicitly reference the correct base class (`TorchDataset`) and\nkeep the HF dataset object under a different alias to avoid name shadowing.\nWhile touching the dataset wrapper, we also store the original sequence so we\ncan compute evaluation metrics without awkward index bookkeeping.   Below is the\ncorrected, self-contained script that follows all GPU, logging, metric-tracking\nand saving requirements.", "The crash was caused by the data-folder path being hard-coded to a location that\ndoes not exist in many execution environments.   I add a small helper that (1)\nhonours an optional environment variable `SPR_DIR`, (2) looks for a folder named\n`SPR_BENCH` in the current directory, and (3) walks up a few parent directories\nuntil it finds the benchmark.  This makes the script robust across different\nlaunch locations.   I also comply with the execution-environment rules (GPU\nhandling, metric tracking, no `if __name__ == \"__main__\":` guard, etc.) and\nensure batches are moved to the correct device automatically.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, json, math, time\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# -------------------- device --------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------------- data loading utils --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(token[0] for token in sequence.strip().split() if token))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(token[1] for token in sequence.strip().split() if len(token) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_color_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\n# -------------------- SPR Dataset --------------------\nclass SPRDataset(Dataset):\n    def __init__(self, hf_split, token2idx, label2idx, max_len=30):\n        self.data = hf_split\n        self.token2idx = token2idx\n        self.label2idx = label2idx\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode_seq(self, seq):\n        ids = [\n            self.token2idx.get(tok, self.token2idx[\"<unk>\"])\n            for tok in seq.strip().split()\n        ]\n        if len(ids) > self.max_len:\n            ids = ids[: self.max_len]\n        pad = [self.token2idx[\"<pad>\"]] * (self.max_len - len(ids))\n        return ids + pad, len(ids)  # keep real length\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        seq_ids, real_len = self.encode_seq(row[\"sequence\"])\n        return {\n            \"input_ids\": torch.tensor(seq_ids, dtype=torch.long),\n            \"lengths\": torch.tensor(real_len, dtype=torch.long),\n            \"label\": torch.tensor(self.label2idx[row[\"label\"]], dtype=torch.long),\n            \"raw_seq\": row[\"sequence\"],  # for metric weights later\n        }\n\n\n# -------------------- model --------------------\nclass GRUClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes, pad_idx):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim * 2, n_classes)\n\n    def forward(self, x, lengths):\n        emb = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        out, _ = self.gru(packed)\n        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n        # Use last valid timestep from both directions\n        idx = (lengths - 1).unsqueeze(1).unsqueeze(2).expand(-1, 1, out.size(2))\n        last = out.gather(1, idx).squeeze(1)\n        return self.fc(last)\n\n\n# -------------------- prepare data --------------------\nDATA_PATH = pathlib.Path(os.getenv(\"SPR_DIR\", \"./SPR_BENCH\"))\nspr = load_spr_bench(DATA_PATH)\n\n# Build vocab from train\nspecials = [\"<pad>\", \"<unk>\"]\nvocab = set()\nfor s in spr[\"train\"][\"sequence\"]:\n    vocab.update(s.strip().split())\ntoken2idx = {tok: i + len(specials) for i, tok in enumerate(sorted(vocab))}\nfor i, tok in enumerate(specials):\n    token2idx[tok] = i\npad_idx = token2idx[\"<pad>\"]\n\n# Labels\nlabels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(labels)}\nidx2label = {i: l for l, i in label2idx.items()}\nn_classes = len(labels)\nprint(f\"Vocab size={len(token2idx)}, num classes={n_classes}\")\n\ntrain_ds = SPRDataset(spr[\"train\"], token2idx, label2idx)\ndev_ds = SPRDataset(spr[\"dev\"], token2idx, label2idx)\ntest_ds = SPRDataset(spr[\"test\"], token2idx, label2idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True, drop_last=False)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False)\n\n# -------------------- init model --------------------\nmodel = GRUClassifier(\n    vocab_size=len(token2idx),\n    emb_dim=32,\n    hidden_dim=64,\n    n_classes=n_classes,\n    pad_idx=pad_idx,\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# -------------------- experiment data store --------------------\nexperiment_data = {\n    \"spr_bench\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n# -------------------- training loop --------------------\nnum_epochs = 5\n\n\ndef run_epoch(loader, train=True):\n    if train:\n        model.train()\n    else:\n        model.eval()\n    total_loss, total = 0.0, 0\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            x = batch[\"input_ids\"].to(device)\n            lengths = batch[\"lengths\"].to(device)\n            y = batch[\"label\"].to(device)\n\n            logits = model(x, lengths)\n            loss = criterion(logits, y)\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            total_loss += loss.item() * len(y)\n            total += len(y)\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(y.cpu().numpy())\n            all_seqs.extend(batch[\"raw_seq\"])\n    avg_loss = total_loss / total\n    # Metrics\n    y_true = [idx2label[i] for i in all_labels]\n    y_pred = [idx2label[i] for i in all_preds]\n    swa = shape_weighted_accuracy(all_seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(all_seqs, y_true, y_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    return avg_loss, (swa, cwa, hwa), y_true, y_pred\n\n\nfor epoch in range(1, num_epochs + 1):\n    t0 = time.time()\n    tr_loss, tr_metrics, _, _ = run_epoch(train_loader, train=True)\n    val_loss, val_metrics, y_true_val, y_pred_val = run_epoch(dev_loader, train=False)\n\n    # store metrics\n    experiment_data[\"spr_bench\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"spr_bench\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"train\"].append(tr_metrics)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"val\"].append(val_metrics)\n    experiment_data[\"spr_bench\"][\"timestamps\"].append(time.time())\n\n    print(\n        f\"Epoch {epoch}: \"\n        f\"train_loss={tr_loss:.4f}, val_loss={val_loss:.4f}, \"\n        f\"val_SWA={val_metrics[0]:.4f}, val_CWA={val_metrics[1]:.4f}, \"\n        f\"val_HWA={val_metrics[2]:.4f}  (elapsed {time.time()-t0:.1f}s)\"\n    )\n\n# -------------------- test evaluation --------------------\ntest_loss, test_metrics, y_true_test, y_pred_test = run_epoch(test_loader, train=False)\nprint(\n    \"\\nTest set results -> \"\n    f\"SWA={test_metrics[0]:.4f}  CWA={test_metrics[1]:.4f}  HWA={test_metrics[2]:.4f}\"\n)\n\nexperiment_data[\"spr_bench\"][\"predictions\"] = y_pred_test\nexperiment_data[\"spr_bench\"][\"ground_truth\"] = y_true_test\nexperiment_data[\"spr_bench\"][\"metrics\"][\"test\"] = test_metrics\nexperiment_data[\"spr_bench\"][\"losses\"][\"test\"] = test_loss\n\n# -------------------- save experiment data --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# -------------------- visualization --------------------\nfig, ax = plt.subplots()\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"train\"], label=\"train\")\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"val\"], label=\"val\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"SPR GRU loss curve\")\nax.legend()\nplt.savefig(os.path.join(working_dir, \"spr_loss_curve.png\"))\nplt.close(fig)\nprint(f\"All outputs saved to {working_dir}\")\n", "import os, pathlib, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy\n\n# ------------------------------------------------------------------\n# mandatory working directory and GPU/CPU handling\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n# ------------------------------------------------------------------\n# experiment data container\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_HWA\": [], \"val_HWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": {\"dev\": []},\n        \"ground_truth\": {\"dev\": []},\n        \"SWA\": {\"train\": [], \"val\": []},\n        \"CWA\": {\"train\": [], \"val\": []},\n    }\n}\n\n\n# ----------------------- utility functions ------------------------\ndef build_vocabs(dataset_dict):\n    shapes, colors, pairs = set(), set(), set()\n    for ex in dataset_dict[\"train\"]:\n        for tok in ex[\"sequence\"].strip().split():\n            if not tok:\n                continue\n            shapes.add(tok[0])\n            if len(tok) > 1:\n                colors.add(tok[1])\n            pairs.add(tok)\n    shape2idx = {s: i for i, s in enumerate(sorted(shapes))}\n    color2idx = {c: i for i, c in enumerate(sorted(colors), start=len(shape2idx))}\n    pair2idx = {\n        p: i for i, p in enumerate(sorted(pairs), start=len(shape2idx) + len(color2idx))\n    }\n    return shape2idx, color2idx, pair2idx\n\n\ndef featurize(seq, shape2idx, color2idx, pair2idx, dim):\n    vec = np.zeros(dim, dtype=np.float32)\n    for tok in seq.strip().split():\n        if not tok:\n            continue\n        s = tok[0]\n        if s in shape2idx:\n            vec[shape2idx[s]] += 1.0\n        if len(tok) > 1 and tok[1] in color2idx:\n            vec[color2idx[tok[1]]] += 1.0\n        if tok in pair2idx:\n            vec[pair2idx[tok]] += 1.0\n    return vec\n\n\nclass SPRBagDataset(Dataset):\n    def __init__(self, hf_dataset, shape2idx, color2idx, pair2idx, dim):\n        self.hf_dataset = hf_dataset\n        self.shape2idx, self.color2idx, self.pair2idx, self.dim = (\n            shape2idx,\n            color2idx,\n            pair2idx,\n            dim,\n        )\n\n    def __len__(self):\n        return len(self.hf_dataset)\n\n    def __getitem__(self, idx):\n        seq = self.hf_dataset[idx][\"sequence\"]\n        x = featurize(seq, self.shape2idx, self.color2idx, self.pair2idx, self.dim)\n        y = self.hf_dataset[idx][\"label\"]\n        return {\"x\": torch.from_numpy(x), \"y\": torch.tensor(y, dtype=torch.long)}\n\n\ndef get_dataloaders(dset, shape2idx, color2idx, pair2idx, dim, bs=128):\n    train_ds = SPRBagDataset(dset[\"train\"], shape2idx, color2idx, pair2idx, dim)\n    dev_ds = SPRBagDataset(dset[\"dev\"], shape2idx, color2idx, pair2idx, dim)\n    train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True)\n    dev_loader = DataLoader(dev_ds, batch_size=bs, shuffle=False)\n    return train_loader, dev_loader\n\n\ndef evaluate(model, loader, sequences, labels):\n    model.eval()\n    all_pred = []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)\n            }\n            logits = model(batch[\"x\"])\n            preds = logits.argmax(dim=1).cpu().tolist()\n            all_pred.extend(preds)\n    swa = shape_weighted_accuracy(sequences, labels, all_pred)\n    cwa = color_weighted_accuracy(sequences, labels, all_pred)\n    hwa = 2 * swa * cwa / (swa + cwa + 1e-8)\n    return swa, cwa, hwa, all_pred\n\n\n# -------------------------- main script ---------------------------\n# 1. Load data\nDATA_PATH = pathlib.Path(\n    os.environ.get(\"SPR_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr_bench = load_spr_bench(DATA_PATH)\nprint(\"Loaded SPR_BENCH splits:\", spr_bench.keys())\n\n# 2. Build vocabularies & dataloaders\nshape2idx, color2idx, pair2idx = build_vocabs(spr_bench)\ninput_dim = len(shape2idx) + len(color2idx) + len(pair2idx)\nprint(f\"Feature dimension: {input_dim}\")\n\ntrain_loader, dev_loader = get_dataloaders(\n    spr_bench, shape2idx, color2idx, pair2idx, input_dim\n)\n\nnum_classes = len(set(spr_bench[\"train\"][\"label\"]))\nprint(f\"Number of classes: {num_classes}\")\n\n# 3. Define model\nmodel = nn.Sequential(nn.Linear(input_dim, num_classes)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# 4. Training loop\nEPOCHS = 10\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    running_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"x\"])\n        loss = criterion(logits, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch[\"x\"].size(0)\n\n    train_loss = running_loss / len(train_loader.dataset)\n    # compute train metrics\n    train_sequences = spr_bench[\"train\"][\"sequence\"]\n    train_labels = spr_bench[\"train\"][\"label\"]\n    train_swa, train_cwa, train_hwa, _ = evaluate(\n        model, train_loader, train_sequences, train_labels\n    )\n\n    # validation\n    val_sequences = spr_bench[\"dev\"][\"sequence\"]\n    val_labels = spr_bench[\"dev\"][\"label\"]\n    val_swa, val_cwa, val_hwa, val_pred = evaluate(\n        model, dev_loader, val_sequences, val_labels\n    )\n\n    # logging\n    print(\n        f\"Epoch {epoch}: \"\n        f\"train_loss={train_loss:.4f}, \"\n        f\"val_loss=N/A, SWA={val_swa:.4f}, CWA={val_cwa:.4f}, HWA={val_hwa:.4f}\"\n    )\n\n    # store metrics\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"SWA\"][\"train\"].append(train_swa)\n    experiment_data[\"SPR_BENCH\"][\"CWA\"][\"train\"].append(train_cwa)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train_HWA\"].append(train_hwa)\n\n    experiment_data[\"SPR_BENCH\"][\"SWA\"][\"val\"].append(val_swa)\n    experiment_data[\"SPR_BENCH\"][\"CWA\"][\"val\"].append(val_cwa)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_HWA\"].append(val_hwa)\n\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(np.nan)  # placeholder\n    print(f\"Epoch {epoch}: validation_loss = N/A\")\n\n# keep last dev predictions\nexperiment_data[\"SPR_BENCH\"][\"predictions\"][\"dev\"] = val_pred\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"][\"dev\"] = val_labels\n\n# 5. Plot loss & HWA curves\nepochs = np.arange(1, EPOCHS + 1)\nplt.figure()\nplt.plot(epochs, experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"], label=\"train_loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend()\nplt.title(\"Training Loss\")\nplt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curve.png\"))\n\nplt.figure()\nplt.plot(\n    epochs, experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train_HWA\"], label=\"train_HWA\"\n)\nplt.plot(epochs, experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_HWA\"], label=\"dev_HWA\")\nplt.ylabel(\"HWA\")\nplt.xlabel(\"Epoch\")\nplt.legend()\nplt.title(\"Harmonic Weighted Accuracy\")\nplt.savefig(os.path.join(working_dir, \"SPR_BENCH_HWA_curve.png\"))\n\n# 6. Save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Experiment data and plots saved in\", working_dir)\n", "import os, pathlib, random, time, json, math\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# GPU/CPU handling ------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------- SPR utilities (given) --------------------------------------\ntry:\n    from SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy\nexcept ImportError:\n    # if packaged differently, copy the helper here\n    from datasets import load_dataset, DatasetDict\n\n    def load_spr_bench(root: pathlib.Path):\n        def _load(split_csv: str):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / split_csv),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        d = DatasetDict()\n        for sp in [\"train\", \"dev\", \"test\"]:\n            d[sp] = _load(f\"{sp}.csv\")\n        return d\n\n    def count_shape_variety(sequence: str) -> int:\n        return len(set(token[0] for token in sequence.strip().split() if token))\n\n    def count_color_variety(sequence: str) -> int:\n        return len(\n            set(token[1] for token in sequence.strip().split() if len(token) > 1)\n        )\n\n    def shape_weighted_accuracy(seqs, y_true, y_pred):\n        w = [count_shape_variety(s) for s in seqs]\n        c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n        return sum(c) / sum(w) if sum(w) else 0.0\n\n    def color_weighted_accuracy(seqs, y_true, y_pred):\n        w = [count_color_variety(s) for s in seqs]\n        c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n        return sum(c) / sum(w) if sum(w) else 0.0\n\n\n# ---------------- load or create dataset -------------------------------------\nDATA_PATH = pathlib.Path(os.getenv(\"SPR_DATA_PATH\", \"SPR_BENCH\"))\nif DATA_PATH.exists():\n    spr = load_spr_bench(DATA_PATH)\nelse:\n    # create tiny synthetic dataset so the script can run end-to-end\n    print(\"SPR_BENCH not found, generating synthetic toy data.\")\n\n    def gen_row(i):\n        seq = \" \".join(\n            random.choice([\"SC\", \"SR\", \"TC\", \"TR\", \"HC\", \"HR\"])\n            for _ in range(random.randint(3, 7))\n        )\n        label = random.choice([\"A\", \"B\"])\n        return {\"id\": str(i), \"sequence\": seq, \"label\": label}\n\n    def make_split(n):\n        return {\n            \"id\": [str(i) for i in range(n)],\n            \"sequence\": [\n                \" \".join(\n                    random.choice([\"SC\", \"SR\", \"TC\", \"TR\", \"HC\", \"HR\"])\n                    for _ in range(random.randint(3, 7))\n                )\n                for _ in range(n)\n            ],\n            \"label\": [random.choice([\"A\", \"B\"]) for _ in range(n)],\n        }\n\n    from datasets import Dataset, DatasetDict\n\n    spr = DatasetDict()\n    for sp, n in [(\"train\", 200), (\"dev\", 60), (\"test\", 60)]:\n        spr[sp] = Dataset.from_dict(make_split(n))\n\n\n# ---------------- build vocab & label maps -----------------------------------\ndef tokenize(seq):\n    return seq.strip().split()\n\n\nall_tokens = set()\nfor seq in spr[\"train\"][\"sequence\"]:\n    all_tokens.update(tokenize(seq))\ntoken2id = {tok: i for i, tok in enumerate(sorted(all_tokens))}\nvocab_size = len(token2id)\nprint(f\"Vocabulary size: {vocab_size}\")\n\nlabels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {lab: i for i, lab in enumerate(labels)}\nnum_labels = len(labels)\nprint(f\"Num labels: {num_labels}\")\n\n\n# ---------------- Dataset wrapper --------------------------------------------\nclass SPRVectorDataset(Dataset):\n    def __init__(self, hf_dataset, token2id, label2id):\n        self.seqs = hf_dataset[\"sequence\"]\n        self.X = [self.vectorize(s, token2id) for s in self.seqs]\n        self.y = [label2id[l] for l in hf_dataset[\"label\"]]\n\n    @staticmethod\n    def vectorize(seq, token2id):\n        vec = np.zeros(len(token2id), dtype=np.float32)\n        for tok in set(tokenize(seq)):  # multi-hot\n            if tok in token2id:\n                vec[token2id[tok]] = 1.0\n        return vec\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return {\"input\": torch.tensor(self.X[idx]), \"label\": torch.tensor(self.y[idx])}\n\n\ntrain_set = SPRVectorDataset(spr[\"train\"], token2id, label2id)\ndev_set = SPRVectorDataset(spr[\"dev\"], token2id, label2id)\ntest_set = SPRVectorDataset(spr[\"test\"], token2id, label2id)\n\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True)\ndev_loader = DataLoader(dev_set, batch_size=256, shuffle=False)\ntest_loader = DataLoader(test_set, batch_size=256, shuffle=False)\n\n\n# ---------------- model -------------------------------------------------------\nclass MLP(nn.Module):\n    def __init__(self, d_in, d_hid, d_out):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(d_in, d_hid), nn.ReLU(), nn.Linear(d_hid, d_out)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nmodel = MLP(vocab_size, 256, num_labels).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------------- experiment data dict ---------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# ---------------- training loop ----------------------------------------------\nEPOCHS = 10\nfor epoch in range(1, EPOCHS + 1):\n    # ---- train ----\n    model.train()\n    total_loss, n_batches = 0.0, 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        n_batches += 1\n    train_loss = total_loss / n_batches\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n\n    # ---- validate ----\n    model.eval()\n    val_loss, preds, trues, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            seqs.extend(\n                [s for s in spr[\"dev\"][\"sequence\"]][\n                    len(seqs) : len(seqs) + len(batch[\"label\"])\n                ]\n            )  # align seqs\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input\"])\n            loss = criterion(logits, batch[\"label\"])\n            val_loss += loss.item()\n            preds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n            trues.extend(batch[\"label\"].cpu().tolist())\n    val_loss /= len(dev_loader)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n\n    # metrics\n    pred_labels = [labels[i] for i in preds]\n    true_labels = [labels[i] for i in trues]\n    swa = shape_weighted_accuracy(spr[\"dev\"][\"sequence\"], true_labels, pred_labels)\n    cwa = color_weighted_accuracy(spr[\"dev\"][\"sequence\"], true_labels, pred_labels)\n    hwa = 0.0 if (swa + cwa) == 0 else 2 * swa * cwa / (swa + cwa)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\n    )\n    experiment_data[\"SPR_BENCH\"][\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f}, validation_loss = {val_loss:.4f}, HWA={hwa:.4f}\"\n    )\n\n# ------------------ test evaluation ------------------------------------------\nmodel.eval()\npreds, trues = [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        logits = model(batch[\"input\"])\n        preds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n        trues.extend(batch[\"label\"].cpu().tolist())\npred_labels = [labels[i] for i in preds]\ntrue_labels = [labels[i] for i in trues]\nswa = shape_weighted_accuracy(spr[\"test\"][\"sequence\"], true_labels, pred_labels)\ncwa = color_weighted_accuracy(spr[\"test\"][\"sequence\"], true_labels, pred_labels)\nhwa = 0.0 if (swa + cwa) == 0 else 2 * swa * cwa / (swa + cwa)\nprint(f\"\\nTEST  | SWA={swa:.4f}  CWA={cwa:.4f}  HWA={hwa:.4f}\")\n\nexperiment_data[\"SPR_BENCH\"][\"metrics\"][\"test\"] = {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = pred_labels\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = true_labels\n\n# ------------------ save ------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, torch, numpy as np, time, math\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy\n\n# ------------------------------------------------------------------\n#   House-keeping & device handling\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------------------------------------------------------\n#   Load SPR_BENCH\n# ------------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # adjust path if needed\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# ------------------------------------------------------------------\n#   Vocabulary\n# ------------------------------------------------------------------\nPAD = \"<pad>\"\ntokens = set()\nfor seq in spr[\"train\"][\"sequence\"]:\n    tokens.update(seq.strip().split())\nstoi = {PAD: 0}\nstoi.update({tok: i + 1 for i, tok in enumerate(sorted(tokens))})\nitos = {i: s for s, i in stoi.items()}\nvocab_size = len(stoi)\nprint(f\"Vocab size = {vocab_size}\")\n\n\ndef encode(seq):\n    return [stoi[tok] for tok in seq.strip().split()]\n\n\n# ------------------------------------------------------------------\n#   Dataset / Dataloader\n# ------------------------------------------------------------------\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.x = [encode(s) for s in split[\"sequence\"]]\n        self.y = torch.tensor(split[\"label\"], dtype=torch.long)\n        self.seq_str = split[\"sequence\"]  # keep original for metrics\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.x[idx], dtype=torch.long),\n            \"label\": self.y[idx],\n            \"sequence\": self.seq_str[idx],\n        }\n\n\ndef collate(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.zeros(len(batch), max_len, dtype=torch.long)\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"sequence\"] for b in batch]\n    for i, b in enumerate(batch):\n        ids = b[\"input_ids\"]\n        input_ids[i, : len(ids)] = ids\n    return {\n        \"input_ids\": input_ids.to(device),\n        \"label\": labels.to(device),\n        \"sequence\": seqs,\n    }\n\n\nbatch_size = 256\ntrain_loader = DataLoader(\n    SPRDataset(spr[\"train\"]), batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRDataset(spr[\"dev\"]), batch_size, shuffle=False, collate_fn=collate\n)\n\nnum_labels = len(set(spr[\"train\"][\"label\"]))\nprint(f\"#labels = {num_labels}\")\n\n\n# ------------------------------------------------------------------\n#   Model\n# ------------------------------------------------------------------\nclass SPRClassifier(nn.Module):\n    def __init__(self, vocab, num_labels, emb_dim=64, hid=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb_dim, padding_idx=0)\n        self.lstm = nn.LSTM(emb_dim, hid, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hid * 2, num_labels)\n\n    def forward(self, x):\n        x = self.emb(x)\n        lengths = (x.abs().sum(-1) != 0).sum(-1)  # rough lengths\n        packed = nn.utils.rnn.pack_padded_sequence(\n            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        h = torch.cat([h[-2], h[-1]], dim=-1)\n        return self.fc(h)\n\n\nmodel = SPRClassifier(vocab_size, num_labels).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ------------------------------------------------------------------\n#   Experiment data storage\n# ------------------------------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\n# ------------------------------------------------------------------\n#   Training loop\n# ------------------------------------------------------------------\ndef evaluate(loader):\n    model.eval()\n    total_loss, n = 0.0, 0\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            bs = batch[\"label\"].size(0)\n            total_loss += loss.item() * bs\n            n += bs\n            preds = logits.argmax(-1).cpu().tolist()\n            all_preds.extend(preds)\n            all_labels.extend(batch[\"label\"].cpu().tolist())\n            all_seqs.extend(batch[\"sequence\"])\n    val_loss = total_loss / n\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    return val_loss, swa, cwa, hwa, all_preds, all_labels\n\n\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    t0 = time.time()\n    model.train()\n    running, denom = 0.0, 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch[\"label\"].size(0)\n        denom += batch[\"label\"].size(0)\n    train_loss = running / denom\n    val_loss, swa, cwa, hwa, preds, gts = evaluate(dev_loader)\n\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\n    )\n    experiment_data[\"SPR_BENCH\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  HWA={hwa:.4f} (SWA={swa:.4f}, CWA={cwa:.4f})  time={time.time()-t0:.1f}s\"\n    )\n\n# ------------------------------------------------------------------\n#   Save experiment data & final evaluation on test\n# ------------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\ntest_loader = DataLoader(\n    SPRDataset(spr[\"test\"]), batch_size, shuffle=False, collate_fn=collate\n)\ntest_loss, swa, cwa, hwa, _, _ = evaluate(test_loader)\nprint(f\"Test: loss={test_loss:.4f}  HWA={hwa:.4f} (SWA={swa:.4f}, CWA={cwa:.4f})\")\n", "import os, pathlib, time, json, math\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ------------------------------------------------------------------\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------------\n# -------------------- dataset location helper ---------------------\ndef find_spr_root() -> pathlib.Path:\n    \"\"\"\n    Search for SPR_BENCH folder in a few sensible locations.\n    Priority:\n        1. Env var SPR_DIR\n        2. ./SPR_BENCH    (current working dir)\n        3. Any parent of cwd that contains /SPR_BENCH\n    \"\"\"\n    candidates = []\n    env_path = os.getenv(\"SPR_DIR\")\n    if env_path:\n        candidates.append(pathlib.Path(env_path))\n    candidates.append(pathlib.Path.cwd() / \"SPR_BENCH\")\n    for parent in pathlib.Path.cwd().resolve().parents:\n        candidates.append(parent / \"SPR_BENCH\")\n\n    for cand in candidates:\n        if (cand / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at: {cand}\")\n            return cand\n    raise FileNotFoundError(\n        \"Unable to locate SPR_BENCH dataset. \"\n        \"Set $SPR_DIR or place SPR_BENCH folder in the current/parent directory.\"\n    )\n\n\n# -------------------- load utils --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\n# -------------------- Dataset class --------------------\nclass SPRDataset(Dataset):\n    def __init__(self, hf_split, token2idx, label2idx, max_len=30):\n        self.data = hf_split\n        self.tok2id = token2idx\n        self.lab2id = label2idx\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode(self, seq):\n        ids = [\n            self.tok2id.get(tok, self.tok2id[\"<unk>\"]) for tok in seq.strip().split()\n        ]\n        ids = ids[: self.max_len]\n        pad_len = self.max_len - len(ids)\n        return ids + [self.tok2id[\"<pad>\"]] * pad_len, len(ids)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        ids, real_len = self.encode(row[\"sequence\"])\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"lengths\": torch.tensor(real_len, dtype=torch.long),\n            \"label\": torch.tensor(self.lab2id[row[\"label\"]], dtype=torch.long),\n            \"raw_seq\": row[\"sequence\"],\n        }\n\n\n# -------------------- model --------------------\nclass GRUClassifier(nn.Module):\n    def __init__(self, vocab, emb_dim, hid_dim, n_cls, pad_idx):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb_dim, padding_idx=pad_idx)\n        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hid_dim * 2, n_cls)\n\n    def forward(self, x, lengths):\n        emb = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        out, _ = self.gru(packed)\n        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n        idx = (lengths - 1).unsqueeze(1).unsqueeze(2).expand(-1, 1, out.size(2))\n        last = out.gather(1, idx).squeeze(1)\n        return self.fc(last)\n\n\n# -------------------- prepare data --------------------\nspr_root = find_spr_root()\nspr = load_spr_bench(spr_root)\n\nspecials = [\"<pad>\", \"<unk>\"]\nvocab_set = set()\nfor s in spr[\"train\"][\"sequence\"]:\n    vocab_set.update(s.strip().split())\ntoken2idx = {tok: i + len(specials) for i, tok in enumerate(sorted(vocab_set))}\nfor i, tok in enumerate(specials):\n    token2idx[tok] = i\npad_idx = token2idx[\"<pad>\"]\n\nlabels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(labels)}\nidx2label = {i: l for l, i in label2idx.items()}\n\ntrain_ds = SPRDataset(spr[\"train\"], token2idx, label2idx)\ndev_ds = SPRDataset(spr[\"dev\"], token2idx, label2idx)\ntest_ds = SPRDataset(spr[\"test\"], token2idx, label2idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False)\n\n# -------------------- init model & optimiser --------------------\nmodel = GRUClassifier(len(token2idx), 32, 64, len(labels), pad_idx).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# -------------------- experiment data dict --------------------\nexperiment_data = {\n    \"spr_bench\": {\n        \"metrics\": {\"train\": [], \"val\": [], \"test\": None},\n        \"losses\": {\"train\": [], \"val\": [], \"test\": None},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\n# -------------------- training utils --------------------\ndef run_epoch(loader, train=True):\n    model.train() if train else model.eval()\n    total_loss, total = 0.0, 0\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            # move tensor fields to device\n            bt = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(bt[\"input_ids\"], bt[\"lengths\"])\n            loss = criterion(logits, bt[\"label\"])\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            total_loss += loss.item() * bt[\"label\"].size(0)\n            total += bt[\"label\"].size(0)\n            preds = logits.argmax(dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(bt[\"label\"].cpu().numpy())\n            all_seqs.extend(bt[\"raw_seq\"])\n    avg_loss = total_loss / total\n    y_true = [idx2label[i] for i in all_labels]\n    y_pred = [idx2label[i] for i in all_preds]\n    swa = shape_weighted_accuracy(all_seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(all_seqs, y_true, y_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    return avg_loss, (swa, cwa, hwa), y_true, y_pred\n\n\n# -------------------- training loop --------------------\nnum_epochs = 5\nfor epoch in range(1, num_epochs + 1):\n    t0 = time.time()\n    tr_loss, tr_met, _, _ = run_epoch(train_loader, train=True)\n    val_loss, val_met, _, _ = run_epoch(dev_loader, train=False)\n    experiment_data[\"spr_bench\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"spr_bench\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"train\"].append(tr_met)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"val\"].append(val_met)\n    experiment_data[\"spr_bench\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: val_loss={val_loss:.4f}  SWA={val_met[0]:.4f}  CWA={val_met[1]:.4f}  HWA={val_met[2]:.4f}  ({time.time()-t0:.1f}s)\"\n    )\n\n# -------------------- test evaluation --------------------\ntest_loss, test_met, y_true_test, y_pred_test = run_epoch(test_loader, train=False)\nprint(f\"\\nTest -> SWA={test_met[0]:.4f}  CWA={test_met[1]:.4f}  HWA={test_met[2]:.4f}\")\n\nexperiment_data[\"spr_bench\"][\"losses\"][\"test\"] = test_loss\nexperiment_data[\"spr_bench\"][\"metrics\"][\"test\"] = test_met\nexperiment_data[\"spr_bench\"][\"predictions\"] = y_pred_test\nexperiment_data[\"spr_bench\"][\"ground_truth\"] = y_true_test\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# -------------------- visualization --------------------\nfig, ax = plt.subplots()\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"train\"], label=\"train\")\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"val\"], label=\"val\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"SPR GRU Loss\")\nax.legend()\nplt.savefig(os.path.join(working_dir, \"spr_loss_curve.png\"))\nplt.close(fig)\nprint(f\"Outputs saved to {working_dir}\")\n", "import os, pathlib, json, math, time, sys\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# -------------------- I/O & device --------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------------- robust SPR_BENCH finder --------------------\ndef find_spr_bench_dir() -> pathlib.Path:\n    \"\"\"\n    Look for a folder that contains train.csv, dev.csv, test.csv.\n    Search order:\n    1. SPR_DIR env variable\n    2. ./SPR_BENCH relative to cwd\n    3. Any parent directory having SPR_BENCH\n    \"\"\"\n    env_path = os.getenv(\"SPR_DIR\")\n    candidates = []\n    if env_path:\n        candidates.append(pathlib.Path(env_path))\n    # direct sub-dir\n    candidates.append(pathlib.Path.cwd() / \"SPR_BENCH\")\n    # parents\n    for parent in pathlib.Path.cwd().parents:\n        candidates.append(parent / \"SPR_BENCH\")\n\n    for cand in candidates:\n        if cand.is_dir():\n            needed = [\"train.csv\", \"dev.csv\", \"test.csv\"]\n            if all((cand / f).is_file() for f in needed):\n                print(f\"Found SPR_BENCH at: {cand}\")\n                return cand.resolve()\n    raise FileNotFoundError(\n        \"Could not locate SPR_BENCH directory. \"\n        \"Set SPR_DIR env variable or place SPR_BENCH with csv files in cwd/parents.\"\n    )\n\n\n# -------------------- data loading utils --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_color_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# -------------------- dataset class --------------------\nclass SPRDataset(Dataset):\n    def __init__(self, hf_split, token2idx, label2idx, max_len=30):\n        self.data = hf_split\n        self.token2idx = token2idx\n        self.label2idx = label2idx\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def _encode_seq(self, seq: str):\n        ids = [\n            self.token2idx.get(tok, self.token2idx[\"<unk>\"])\n            for tok in seq.strip().split()\n        ]\n        if len(ids) > self.max_len:\n            ids = ids[: self.max_len]\n        pad = [self.token2idx[\"<pad>\"]] * (self.max_len - len(ids))\n        return ids + pad, len(ids)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        token_ids, real_len = self._encode_seq(row[\"sequence\"])\n        return {\n            \"input_ids\": torch.tensor(token_ids, dtype=torch.long),\n            \"lengths\": torch.tensor(real_len, dtype=torch.long),\n            \"label\": torch.tensor(self.label2idx[row[\"label\"]], dtype=torch.long),\n            \"raw_seq\": row[\"sequence\"],\n        }\n\n\n# -------------------- model --------------------\nclass GRUClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes, pad_idx):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim * 2, n_classes)\n\n    def forward(self, x, lengths):\n        emb = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        out, _ = self.gru(packed)\n        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n\n        # gather last timestep (for both directions)\n        idx = (lengths - 1).view(-1, 1, 1).expand(-1, 1, out.size(2))\n        last = out.gather(1, idx).squeeze(1)\n        return self.fc(last)\n\n\n# -------------------- prepare data --------------------\nDATA_PATH = find_spr_bench_dir()\nspr = load_spr_bench(DATA_PATH)\n\n# vocab\nspecials = [\"<pad>\", \"<unk>\"]\nvocab = set()\nfor s in spr[\"train\"][\"sequence\"]:\n    vocab.update(s.strip().split())\ntoken2idx = {tok: i + len(specials) for i, tok in enumerate(sorted(vocab))}\nfor i, tok in enumerate(specials):\n    token2idx[tok] = i\npad_idx = token2idx[\"<pad>\"]\n\n# labels\nlabels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(labels)}\nidx2label = {i: l for l, i in label2idx.items()}\n\ntrain_ds = SPRDataset(spr[\"train\"], token2idx, label2idx)\ndev_ds = SPRDataset(spr[\"dev\"], token2idx, label2idx)\ntest_ds = SPRDataset(spr[\"test\"], token2idx, label2idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True, drop_last=False)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False)\n\n# -------------------- model, loss, optimizer --------------------\nmodel = GRUClassifier(len(token2idx), 32, 64, len(labels), pad_idx).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# -------------------- experiment data store --------------------\nexperiment_data = {\n    \"spr_bench\": {\n        \"metrics\": {\"train\": [], \"val\": [], \"test\": None},\n        \"losses\": {\"train\": [], \"val\": [], \"test\": None},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\n# -------------------- helpers --------------------\ndef run_epoch(loader, train=True):\n    model.train() if train else model.eval()\n    total_loss, total = 0.0, 0\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            # move tensors\n            tensor_batch = {\n                k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)\n            }\n            raw_seq = batch[\"raw_seq\"]\n\n            logits = model(tensor_batch[\"input_ids\"], tensor_batch[\"lengths\"])\n            loss = criterion(logits, tensor_batch[\"label\"])\n\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n            bs = tensor_batch[\"label\"].size(0)\n            total_loss += loss.item() * bs\n            total += bs\n\n            preds = logits.argmax(dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(tensor_batch[\"label\"].cpu().numpy())\n            all_seqs.extend(raw_seq)\n\n    avg_loss = total_loss / total\n    y_true = [idx2label[i] for i in all_labels]\n    y_pred = [idx2label[i] for i in all_preds]\n    swa = shape_weighted_accuracy(all_seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(all_seqs, y_true, y_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) else 0.0\n    return avg_loss, (swa, cwa, hwa), y_true, y_pred\n\n\n# -------------------- training loop --------------------\nnum_epochs = 5\nfor epoch in range(1, num_epochs + 1):\n    t0 = time.time()\n    train_loss, train_metrics, _, _ = run_epoch(train_loader, train=True)\n    val_loss, val_metrics, _, _ = run_epoch(dev_loader, train=False)\n\n    experiment_data[\"spr_bench\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"spr_bench\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"train\"].append(train_metrics)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"val\"].append(val_metrics)\n    experiment_data[\"spr_bench\"][\"timestamps\"].append(time.time())\n\n    print(\n        f\"Epoch {epoch}: \"\n        f\"val_loss = {val_loss:.4f} \"\n        f\"SWA = {val_metrics[0]:.4f} \"\n        f\"CWA = {val_metrics[1]:.4f} \"\n        f\"HWA = {val_metrics[2]:.4f}   \"\n        f\"(elapsed {time.time() - t0:.1f}s)\"\n    )\n\n# -------------------- test evaluation --------------------\ntest_loss, test_metrics, y_true_test, y_pred_test = run_epoch(test_loader, train=False)\nprint(\n    \"\\nTest set -> \"\n    f\"SWA={test_metrics[0]:.4f}  CWA={test_metrics[1]:.4f}  HWA={test_metrics[2]:.4f}\"\n)\n\nexperiment_data[\"spr_bench\"][\"losses\"][\"test\"] = test_loss\nexperiment_data[\"spr_bench\"][\"metrics\"][\"test\"] = test_metrics\nexperiment_data[\"spr_bench\"][\"predictions\"] = y_pred_test\nexperiment_data[\"spr_bench\"][\"ground_truth\"] = y_true_test\n\n# -------------------- save experiment data --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# -------------------- visualize loss --------------------\nfig, ax = plt.subplots()\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"train\"], label=\"train\")\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"val\"], label=\"val\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"SPR GRU Loss Curve\")\nax.legend()\nplt.savefig(os.path.join(working_dir, \"spr_loss_curve.png\"))\nplt.close(fig)\n\nprint(f\"All outputs saved in {working_dir}\")\n", "import os, pathlib, random, time, json, math\n\n# ---------------- working dir -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------- std / torch imports ----------------------------------------\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset as TorchDataset\nfrom torch.utils.data import DataLoader\n\n# ---------------- device ------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------- SPR helpers -------------------------------------------------\ntry:\n    from SPR import (\n        load_spr_bench,\n        shape_weighted_accuracy,\n        color_weighted_accuracy,\n    )\nexcept ImportError:\n    # Minimal re-implementation so the file is standalone\n    from datasets import load_dataset, DatasetDict\n\n    def load_spr_bench(root: pathlib.Path):\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        d = DatasetDict()\n        for sp in [\"train\", \"dev\", \"test\"]:\n            d[sp] = _load(f\"{sp}.csv\")\n        return d\n\n    def _count_variety(sequence, idx):\n        return len(\n            set(token[idx] for token in sequence.strip().split() if len(token) > idx)\n        )\n\n    def shape_weighted_accuracy(seqs, y_true, y_pred):\n        w = [_count_variety(s, 0) for s in seqs]\n        correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n        return sum(correct) / sum(w) if sum(w) else 0.0\n\n    def color_weighted_accuracy(seqs, y_true, y_pred):\n        w = [_count_variety(s, 1) for s in seqs]\n        correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n        return sum(correct) / sum(w) if sum(w) else 0.0\n\n\n# ---------------- load / make dataset ----------------------------------------\nDATA_PATH = pathlib.Path(os.getenv(\"SPR_DATA_PATH\", \"SPR_BENCH\"))\nif DATA_PATH.exists():\n    spr = load_spr_bench(DATA_PATH)\nelse:\n    print(\"SPR_BENCH not found, generating synthetic toy data.\")\n    # Use HF dataset object but keep alias to avoid name clash\n    from datasets import Dataset as HFDataset, DatasetDict\n\n    TOKEN_CHOICES = [\"SC\", \"SR\", \"TC\", \"TR\", \"HC\", \"HR\"]\n    LABEL_CHOICES = [\"A\", \"B\"]\n\n    def make_split(n_rows):\n        sequences = [\n            \" \".join(random.choice(TOKEN_CHOICES) for _ in range(random.randint(3, 7)))\n            for _ in range(n_rows)\n        ]\n        return {\n            \"id\": [str(i) for i in range(n_rows)],\n            \"sequence\": sequences,\n            \"label\": [random.choice(LABEL_CHOICES) for _ in range(n_rows)],\n        }\n\n    spr = DatasetDict()\n    for split, n in [(\"train\", 200), (\"dev\", 60), (\"test\", 60)]:\n        spr[split] = HFDataset.from_dict(make_split(n))\n\n\n# ---------------- vocab / label maps -----------------------------------------\ndef tokenize(seq: str):\n    return seq.strip().split()\n\n\nall_tokens = set()\nfor seq in spr[\"train\"][\"sequence\"]:\n    all_tokens.update(tokenize(seq))\ntoken2id = {tok: i for i, tok in enumerate(sorted(all_tokens))}\nvocab_size = len(token2id)\nprint(f\"Vocabulary size: {vocab_size}\")\n\nlabels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {lab: i for i, lab in enumerate(labels)}\nnum_labels = len(labels)\nprint(f\"Number of labels: {num_labels}\")\n\n\n# ---------------- PyTorch dataset wrapper ------------------------------------\nclass SPRVectorDataset(TorchDataset):\n    def __init__(self, hf_dataset, token2id, label2id):\n        self.seqs = hf_dataset[\"sequence\"]\n        self.X = [self._vectorize(seq, token2id) for seq in self.seqs]\n        self.y = [label2id[lbl] for lbl in hf_dataset[\"label\"]]\n\n    @staticmethod\n    def _vectorize(sequence: str, token2id: dict):\n        vec = np.zeros(len(token2id), dtype=np.float32)\n        for tok in set(tokenize(sequence)):  # multi-hot\n            if tok in token2id:\n                vec[token2id[tok]] = 1.0\n        return vec\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx: int):\n        return {\n            \"input\": torch.tensor(self.X[idx], dtype=torch.float32),\n            \"label\": torch.tensor(self.y[idx], dtype=torch.long),\n            \"sequence\": self.seqs[idx],\n        }\n\n\ntrain_set = SPRVectorDataset(spr[\"train\"], token2id, label2id)\ndev_set = SPRVectorDataset(spr[\"dev\"], token2id, label2id)\ntest_set = SPRVectorDataset(spr[\"test\"], token2id, label2id)\n\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True)\ndev_loader = DataLoader(dev_set, batch_size=256, shuffle=False)\ntest_loader = DataLoader(test_set, batch_size=256, shuffle=False)\n\n\n# ---------------- simple MLP model -------------------------------------------\nclass MLP(nn.Module):\n    def __init__(self, d_in, d_hid, d_out):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(d_in, d_hid),\n            nn.ReLU(),\n            nn.Linear(d_hid, d_out),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nmodel = MLP(vocab_size, 256, num_labels).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------------- experiment data logging ------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# ---------------- training loop ----------------------------------------------\nEPOCHS = 10\nfor epoch in range(1, EPOCHS + 1):\n    # ---- training -----------------------------------------------------------\n    model.train()\n    total_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    train_loss = total_loss / len(train_loader)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n\n    # ---- validation ---------------------------------------------------------\n    model.eval()\n    val_loss, preds, trues = 0.0, [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input\"])\n            loss = criterion(logits, batch[\"label\"])\n            val_loss += loss.item()\n            preds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n            trues.extend(batch[\"label\"].cpu().tolist())\n    val_loss /= len(dev_loader)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n\n    # ---- metrics ------------------------------------------------------------\n    pred_labels = [labels[i] for i in preds]\n    true_labels = [labels[i] for i in trues]\n    swa = shape_weighted_accuracy(dev_set.seqs, true_labels, pred_labels)\n    cwa = color_weighted_accuracy(dev_set.seqs, true_labels, pred_labels)\n    hwa = 0.0 if (swa + cwa) == 0 else 2 * swa * cwa / (swa + cwa)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\n    )\n    experiment_data[\"SPR_BENCH\"][\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f}  \"\n        f\"validation_loss={val_loss:.4f}  HWA={hwa:.4f}\"\n    )\n\n# ---------------- test evaluation --------------------------------------------\nmodel.eval()\npreds, trues = [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        logits = model(batch[\"input\"])\n        preds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n        trues.extend(batch[\"label\"].cpu().tolist())\n\npred_labels = [labels[i] for i in preds]\ntrue_labels = [labels[i] for i in trues]\nswa = shape_weighted_accuracy(test_set.seqs, true_labels, pred_labels)\ncwa = color_weighted_accuracy(test_set.seqs, true_labels, pred_labels)\nhwa = 0.0 if (swa + cwa) == 0 else 2 * swa * cwa / (swa + cwa)\n\nprint(f\"\\nTEST | SWA={swa:.4f}  CWA={cwa:.4f}  HWA={hwa:.4f}\")\n\nexperiment_data[\"SPR_BENCH\"][\"metrics\"][\"test\"] = {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = pred_labels\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = true_labels\n\n# ---------------- save everything -------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, time, math, json\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ----------------- device -----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------- robust data finder -----------------\ndef locate_spr_bench() -> pathlib.Path:\n    \"\"\"Return a valid SPR_BENCH directory or raise FileNotFoundError.\"\"\"\n    # 1) explicit env var\n    cand = os.getenv(\"SPR_DIR\")\n    if cand and pathlib.Path(cand).is_dir():\n        return pathlib.Path(cand)\n    # 2) ./SPR_BENCH\n    cand = pathlib.Path.cwd() / \"SPR_BENCH\"\n    if cand.is_dir():\n        return cand\n    # 3) walk up max 4 levels\n    base = pathlib.Path.cwd()\n    for _ in range(4):\n        base = base.parent\n        cand = base / \"SPR_BENCH\"\n        if cand.is_dir():\n            return cand\n    raise FileNotFoundError(\n        \"Unable to locate SPR_BENCH folder. Set SPR_DIR env variable or place \"\n        \"the folder in the current (or parent) directory.\"\n    )\n\n\n# ----------------- dataset loading -----------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(sequences, y_true, y_pred):\n    w = [count_shape_variety(s) for s in sequences]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(sequences, y_true, y_pred):\n    w = [count_color_variety(s) for s in sequences]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) else 0.0\n\n\n# ----------------- Dataset class -----------------\nclass SPRDataset(Dataset):\n    def __init__(self, split, token2idx, label2idx, max_len=30):\n        self.data = split\n        self.t2i = token2idx\n        self.l2i = label2idx\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode(self, seq):\n        ids = [self.t2i.get(tok, self.t2i[\"<unk>\"]) for tok in seq.strip().split()]\n        ids = ids[: self.max_len]\n        pad = [self.t2i[\"<pad>\"]] * (self.max_len - len(ids))\n        return ids + pad, len(ids)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        ids, real_len = self.encode(row[\"sequence\"])\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"lengths\": torch.tensor(real_len, dtype=torch.long),\n            \"label\": torch.tensor(self.l2i[row[\"label\"]], dtype=torch.long),\n            \"raw_seq\": row[\"sequence\"],\n        }\n\n\n# ----------------- Model -----------------\nclass GRUClassifier(nn.Module):\n    def __init__(self, vocab, emb_dim, hid_dim, n_cls, pad_idx):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb_dim, padding_idx=pad_idx)\n        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hid_dim * 2, n_cls)\n\n    def forward(self, x, lengths):\n        emb = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        out, _ = self.gru(packed)\n        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n        idx = (lengths - 1).unsqueeze(1).unsqueeze(2).expand(-1, 1, out.size(2))\n        last = out.gather(1, idx).squeeze(1)\n        return self.fc(last)\n\n\n# ----------------- Load data -----------------\nDATA_PATH = locate_spr_bench()\nspr = load_spr_bench(DATA_PATH)\nprint(\"Dataset sizes:\", {k: len(v) for k, v in spr.items()})\n\n# vocab and label maps\nspecials = [\"<pad>\", \"<unk>\"]\nvocab = {tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()}\ntoken2idx = {tok: i + len(specials) for i, tok in enumerate(sorted(vocab))}\nfor i, tok in enumerate(specials):\n    token2idx[tok] = i\npad_idx = token2idx[\"<pad>\"]\nlabels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(labels)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n# datasets / loaders\ntrain_ds = SPRDataset(spr[\"train\"], token2idx, label2idx)\ndev_ds = SPRDataset(spr[\"dev\"], token2idx, label2idx)\ntest_ds = SPRDataset(spr[\"test\"], token2idx, label2idx)\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=512)\ntest_loader = DataLoader(test_ds, batch_size=512)\n\n# ----------------- Model / Optim / Loss -----------------\nmodel = GRUClassifier(len(token2idx), 32, 64, len(labels), pad_idx).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ----------------- experiment data store -----------------\nexperiment_data = {\n    \"spr_bench\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\n# ----------------- training helpers -----------------\ndef run_epoch(loader, train=True):\n    model.train() if train else model.eval()\n    total_loss, n_items = 0.0, 0\n    preds_all, labels_all, seqs_all = [], [], []\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            # move tensors\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            out = model(batch[\"input_ids\"], batch[\"lengths\"])\n            loss = criterion(out, batch[\"label\"])\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            total_loss += loss.item() * batch[\"label\"].size(0)\n            n_items += batch[\"label\"].size(0)\n            preds_all.extend(out.argmax(1).cpu().numpy())\n            labels_all.extend(batch[\"label\"].cpu().numpy())\n            seqs_all.extend(batch[\"raw_seq\"])\n    avg_loss = total_loss / n_items\n    y_true = [idx2label[i] for i in labels_all]\n    y_pred = [idx2label[i] for i in preds_all]\n    swa = shape_weighted_accuracy(seqs_all, y_true, y_pred)\n    cwa = color_weighted_accuracy(seqs_all, y_true, y_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) else 0.0\n    return avg_loss, (swa, cwa, hwa), y_true, y_pred\n\n\n# ----------------- training loop -----------------\nnum_epochs = 5\nfor epoch in range(1, num_epochs + 1):\n    start = time.time()\n    tr_loss, tr_metric, _, _ = run_epoch(train_loader, True)\n    val_loss, val_metric, _, _ = run_epoch(dev_loader, False)\n    experiment_data[\"spr_bench\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"spr_bench\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"train\"].append(tr_metric)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"val\"].append(val_metric)\n    experiment_data[\"spr_bench\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: val_loss={val_loss:.4f}, \"\n        f\"SWA={val_metric[0]:.4f}, CWA={val_metric[1]:.4f}, HWA={val_metric[2]:.4f} \"\n        f\"(elapsed {time.time()-start:.1f}s)\"\n    )\n\n# ----------------- final test -----------------\ntest_loss, test_metric, y_true_test, y_pred_test = run_epoch(test_loader, False)\nprint(\n    f\"\\nTest: SWA={test_metric[0]:.4f} CWA={test_metric[1]:.4f} HWA={test_metric[2]:.4f}\"\n)\nexperiment_data[\"spr_bench\"][\"losses\"][\"test\"] = test_loss\nexperiment_data[\"spr_bench\"][\"metrics\"][\"test\"] = test_metric\nexperiment_data[\"spr_bench\"][\"predictions\"] = y_pred_test\nexperiment_data[\"spr_bench\"][\"ground_truth\"] = y_true_test\n\n# ----------------- save -----------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# ----------------- plot -----------------\nfig, ax = plt.subplots()\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"train\"], label=\"train\")\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"val\"], label=\"val\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"SPR GRU loss curve\")\nax.legend()\nplt.savefig(os.path.join(working_dir, \"spr_loss_curve.png\"))\nplt.close(fig)\nprint(f\"Outputs saved to {working_dir}\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, time, json, math\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ------------------------------------------------------------------\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------------\n# -------------------- dataset location helper ---------------------\ndef find_spr_root() -> pathlib.Path:\n    \"\"\"\n    Search for SPR_BENCH folder in a few sensible locations.\n    Priority:\n        1. Env var SPR_DIR\n        2. ./SPR_BENCH    (current working dir)\n        3. Any parent of cwd that contains /SPR_BENCH\n    \"\"\"\n    candidates = []\n    env_path = os.getenv(\"SPR_DIR\")\n    if env_path:\n        candidates.append(pathlib.Path(env_path))\n    candidates.append(pathlib.Path.cwd() / \"SPR_BENCH\")\n    for parent in pathlib.Path.cwd().resolve().parents:\n        candidates.append(parent / \"SPR_BENCH\")\n\n    for cand in candidates:\n        if (cand / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at: {cand}\")\n            return cand\n    raise FileNotFoundError(\n        \"Unable to locate SPR_BENCH dataset. \"\n        \"Set $SPR_DIR or place SPR_BENCH folder in the current/parent directory.\"\n    )\n\n\n# -------------------- load utils --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\n# -------------------- Dataset class --------------------\nclass SPRDataset(Dataset):\n    def __init__(self, hf_split, token2idx, label2idx, max_len=30):\n        self.data = hf_split\n        self.tok2id = token2idx\n        self.lab2id = label2idx\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode(self, seq):\n        ids = [\n            self.tok2id.get(tok, self.tok2id[\"<unk>\"]) for tok in seq.strip().split()\n        ]\n        ids = ids[: self.max_len]\n        pad_len = self.max_len - len(ids)\n        return ids + [self.tok2id[\"<pad>\"]] * pad_len, len(ids)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        ids, real_len = self.encode(row[\"sequence\"])\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"lengths\": torch.tensor(real_len, dtype=torch.long),\n            \"label\": torch.tensor(self.lab2id[row[\"label\"]], dtype=torch.long),\n            \"raw_seq\": row[\"sequence\"],\n        }\n\n\n# -------------------- model --------------------\nclass GRUClassifier(nn.Module):\n    def __init__(self, vocab, emb_dim, hid_dim, n_cls, pad_idx):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb_dim, padding_idx=pad_idx)\n        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hid_dim * 2, n_cls)\n\n    def forward(self, x, lengths):\n        emb = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        out, _ = self.gru(packed)\n        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n        idx = (lengths - 1).unsqueeze(1).unsqueeze(2).expand(-1, 1, out.size(2))\n        last = out.gather(1, idx).squeeze(1)\n        return self.fc(last)\n\n\n# -------------------- prepare data --------------------\nspr_root = find_spr_root()\nspr = load_spr_bench(spr_root)\n\nspecials = [\"<pad>\", \"<unk>\"]\nvocab_set = set()\nfor s in spr[\"train\"][\"sequence\"]:\n    vocab_set.update(s.strip().split())\ntoken2idx = {tok: i + len(specials) for i, tok in enumerate(sorted(vocab_set))}\nfor i, tok in enumerate(specials):\n    token2idx[tok] = i\npad_idx = token2idx[\"<pad>\"]\n\nlabels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(labels)}\nidx2label = {i: l for l, i in label2idx.items()}\n\ntrain_ds = SPRDataset(spr[\"train\"], token2idx, label2idx)\ndev_ds = SPRDataset(spr[\"dev\"], token2idx, label2idx)\ntest_ds = SPRDataset(spr[\"test\"], token2idx, label2idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False)\n\n# -------------------- init model & optimiser --------------------\nmodel = GRUClassifier(len(token2idx), 32, 64, len(labels), pad_idx).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# -------------------- experiment data dict --------------------\nexperiment_data = {\n    \"spr_bench\": {\n        \"metrics\": {\"train\": [], \"val\": [], \"test\": None},\n        \"losses\": {\"train\": [], \"val\": [], \"test\": None},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\n# -------------------- training utils --------------------\ndef run_epoch(loader, train=True):\n    model.train() if train else model.eval()\n    total_loss, total = 0.0, 0\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            # move tensor fields to device\n            bt = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(bt[\"input_ids\"], bt[\"lengths\"])\n            loss = criterion(logits, bt[\"label\"])\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            total_loss += loss.item() * bt[\"label\"].size(0)\n            total += bt[\"label\"].size(0)\n            preds = logits.argmax(dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(bt[\"label\"].cpu().numpy())\n            all_seqs.extend(bt[\"raw_seq\"])\n    avg_loss = total_loss / total\n    y_true = [idx2label[i] for i in all_labels]\n    y_pred = [idx2label[i] for i in all_preds]\n    swa = shape_weighted_accuracy(all_seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(all_seqs, y_true, y_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    return avg_loss, (swa, cwa, hwa), y_true, y_pred\n\n\n# -------------------- training loop --------------------\nnum_epochs = 5\nfor epoch in range(1, num_epochs + 1):\n    t0 = time.time()\n    tr_loss, tr_met, _, _ = run_epoch(train_loader, train=True)\n    val_loss, val_met, _, _ = run_epoch(dev_loader, train=False)\n    experiment_data[\"spr_bench\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"spr_bench\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"train\"].append(tr_met)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"val\"].append(val_met)\n    experiment_data[\"spr_bench\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: val_loss={val_loss:.4f}  SWA={val_met[0]:.4f}  CWA={val_met[1]:.4f}  HWA={val_met[2]:.4f}  ({time.time()-t0:.1f}s)\"\n    )\n\n# -------------------- test evaluation --------------------\ntest_loss, test_met, y_true_test, y_pred_test = run_epoch(test_loader, train=False)\nprint(f\"\\nTest -> SWA={test_met[0]:.4f}  CWA={test_met[1]:.4f}  HWA={test_met[2]:.4f}\")\n\nexperiment_data[\"spr_bench\"][\"losses\"][\"test\"] = test_loss\nexperiment_data[\"spr_bench\"][\"metrics\"][\"test\"] = test_met\nexperiment_data[\"spr_bench\"][\"predictions\"] = y_pred_test\nexperiment_data[\"spr_bench\"][\"ground_truth\"] = y_true_test\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# -------------------- visualization --------------------\nfig, ax = plt.subplots()\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"train\"], label=\"train\")\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"val\"], label=\"val\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"SPR GRU Loss\")\nax.legend()\nplt.savefig(os.path.join(working_dir, \"spr_loss_curve.png\"))\nplt.close(fig)\nprint(f\"Outputs saved to {working_dir}\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, time, json, math\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ------------------------------------------------------------------\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------------\n# -------------------- dataset location helper ---------------------\ndef find_spr_root() -> pathlib.Path:\n    \"\"\"\n    Search for SPR_BENCH folder in a few sensible locations.\n    Priority:\n        1. Env var SPR_DIR\n        2. ./SPR_BENCH    (current working dir)\n        3. Any parent of cwd that contains /SPR_BENCH\n    \"\"\"\n    candidates = []\n    env_path = os.getenv(\"SPR_DIR\")\n    if env_path:\n        candidates.append(pathlib.Path(env_path))\n    candidates.append(pathlib.Path.cwd() / \"SPR_BENCH\")\n    for parent in pathlib.Path.cwd().resolve().parents:\n        candidates.append(parent / \"SPR_BENCH\")\n\n    for cand in candidates:\n        if (cand / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at: {cand}\")\n            return cand\n    raise FileNotFoundError(\n        \"Unable to locate SPR_BENCH dataset. \"\n        \"Set $SPR_DIR or place SPR_BENCH folder in the current/parent directory.\"\n    )\n\n\n# -------------------- load utils --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\n# -------------------- Dataset class --------------------\nclass SPRDataset(Dataset):\n    def __init__(self, hf_split, token2idx, label2idx, max_len=30):\n        self.data = hf_split\n        self.tok2id = token2idx\n        self.lab2id = label2idx\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode(self, seq):\n        ids = [\n            self.tok2id.get(tok, self.tok2id[\"<unk>\"]) for tok in seq.strip().split()\n        ]\n        ids = ids[: self.max_len]\n        pad_len = self.max_len - len(ids)\n        return ids + [self.tok2id[\"<pad>\"]] * pad_len, len(ids)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        ids, real_len = self.encode(row[\"sequence\"])\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"lengths\": torch.tensor(real_len, dtype=torch.long),\n            \"label\": torch.tensor(self.lab2id[row[\"label\"]], dtype=torch.long),\n            \"raw_seq\": row[\"sequence\"],\n        }\n\n\n# -------------------- model --------------------\nclass GRUClassifier(nn.Module):\n    def __init__(self, vocab, emb_dim, hid_dim, n_cls, pad_idx):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb_dim, padding_idx=pad_idx)\n        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hid_dim * 2, n_cls)\n\n    def forward(self, x, lengths):\n        emb = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        out, _ = self.gru(packed)\n        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n        idx = (lengths - 1).unsqueeze(1).unsqueeze(2).expand(-1, 1, out.size(2))\n        last = out.gather(1, idx).squeeze(1)\n        return self.fc(last)\n\n\n# -------------------- prepare data --------------------\nspr_root = find_spr_root()\nspr = load_spr_bench(spr_root)\n\nspecials = [\"<pad>\", \"<unk>\"]\nvocab_set = set()\nfor s in spr[\"train\"][\"sequence\"]:\n    vocab_set.update(s.strip().split())\ntoken2idx = {tok: i + len(specials) for i, tok in enumerate(sorted(vocab_set))}\nfor i, tok in enumerate(specials):\n    token2idx[tok] = i\npad_idx = token2idx[\"<pad>\"]\n\nlabels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(labels)}\nidx2label = {i: l for l, i in label2idx.items()}\n\ntrain_ds = SPRDataset(spr[\"train\"], token2idx, label2idx)\ndev_ds = SPRDataset(spr[\"dev\"], token2idx, label2idx)\ntest_ds = SPRDataset(spr[\"test\"], token2idx, label2idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False)\n\n# -------------------- init model & optimiser --------------------\nmodel = GRUClassifier(len(token2idx), 32, 64, len(labels), pad_idx).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# -------------------- experiment data dict --------------------\nexperiment_data = {\n    \"spr_bench\": {\n        \"metrics\": {\"train\": [], \"val\": [], \"test\": None},\n        \"losses\": {\"train\": [], \"val\": [], \"test\": None},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\n# -------------------- training utils --------------------\ndef run_epoch(loader, train=True):\n    model.train() if train else model.eval()\n    total_loss, total = 0.0, 0\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            # move tensor fields to device\n            bt = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(bt[\"input_ids\"], bt[\"lengths\"])\n            loss = criterion(logits, bt[\"label\"])\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            total_loss += loss.item() * bt[\"label\"].size(0)\n            total += bt[\"label\"].size(0)\n            preds = logits.argmax(dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(bt[\"label\"].cpu().numpy())\n            all_seqs.extend(bt[\"raw_seq\"])\n    avg_loss = total_loss / total\n    y_true = [idx2label[i] for i in all_labels]\n    y_pred = [idx2label[i] for i in all_preds]\n    swa = shape_weighted_accuracy(all_seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(all_seqs, y_true, y_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    return avg_loss, (swa, cwa, hwa), y_true, y_pred\n\n\n# -------------------- training loop --------------------\nnum_epochs = 5\nfor epoch in range(1, num_epochs + 1):\n    t0 = time.time()\n    tr_loss, tr_met, _, _ = run_epoch(train_loader, train=True)\n    val_loss, val_met, _, _ = run_epoch(dev_loader, train=False)\n    experiment_data[\"spr_bench\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"spr_bench\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"train\"].append(tr_met)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"val\"].append(val_met)\n    experiment_data[\"spr_bench\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: val_loss={val_loss:.4f}  SWA={val_met[0]:.4f}  CWA={val_met[1]:.4f}  HWA={val_met[2]:.4f}  ({time.time()-t0:.1f}s)\"\n    )\n\n# -------------------- test evaluation --------------------\ntest_loss, test_met, y_true_test, y_pred_test = run_epoch(test_loader, train=False)\nprint(f\"\\nTest -> SWA={test_met[0]:.4f}  CWA={test_met[1]:.4f}  HWA={test_met[2]:.4f}\")\n\nexperiment_data[\"spr_bench\"][\"losses\"][\"test\"] = test_loss\nexperiment_data[\"spr_bench\"][\"metrics\"][\"test\"] = test_met\nexperiment_data[\"spr_bench\"][\"predictions\"] = y_pred_test\nexperiment_data[\"spr_bench\"][\"ground_truth\"] = y_true_test\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# -------------------- visualization --------------------\nfig, ax = plt.subplots()\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"train\"], label=\"train\")\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"val\"], label=\"val\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"SPR GRU Loss\")\nax.legend()\nplt.savefig(os.path.join(working_dir, \"spr_loss_curve.png\"))\nplt.close(fig)\nprint(f\"Outputs saved to {working_dir}\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, time, json, math\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ------------------------------------------------------------------\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------------\n# -------------------- dataset location helper ---------------------\ndef find_spr_root() -> pathlib.Path:\n    \"\"\"\n    Search for SPR_BENCH folder in a few sensible locations.\n    Priority:\n        1. Env var SPR_DIR\n        2. ./SPR_BENCH    (current working dir)\n        3. Any parent of cwd that contains /SPR_BENCH\n    \"\"\"\n    candidates = []\n    env_path = os.getenv(\"SPR_DIR\")\n    if env_path:\n        candidates.append(pathlib.Path(env_path))\n    candidates.append(pathlib.Path.cwd() / \"SPR_BENCH\")\n    for parent in pathlib.Path.cwd().resolve().parents:\n        candidates.append(parent / \"SPR_BENCH\")\n\n    for cand in candidates:\n        if (cand / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at: {cand}\")\n            return cand\n    raise FileNotFoundError(\n        \"Unable to locate SPR_BENCH dataset. \"\n        \"Set $SPR_DIR or place SPR_BENCH folder in the current/parent directory.\"\n    )\n\n\n# -------------------- load utils --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\n# -------------------- Dataset class --------------------\nclass SPRDataset(Dataset):\n    def __init__(self, hf_split, token2idx, label2idx, max_len=30):\n        self.data = hf_split\n        self.tok2id = token2idx\n        self.lab2id = label2idx\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode(self, seq):\n        ids = [\n            self.tok2id.get(tok, self.tok2id[\"<unk>\"]) for tok in seq.strip().split()\n        ]\n        ids = ids[: self.max_len]\n        pad_len = self.max_len - len(ids)\n        return ids + [self.tok2id[\"<pad>\"]] * pad_len, len(ids)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        ids, real_len = self.encode(row[\"sequence\"])\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"lengths\": torch.tensor(real_len, dtype=torch.long),\n            \"label\": torch.tensor(self.lab2id[row[\"label\"]], dtype=torch.long),\n            \"raw_seq\": row[\"sequence\"],\n        }\n\n\n# -------------------- model --------------------\nclass GRUClassifier(nn.Module):\n    def __init__(self, vocab, emb_dim, hid_dim, n_cls, pad_idx):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb_dim, padding_idx=pad_idx)\n        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hid_dim * 2, n_cls)\n\n    def forward(self, x, lengths):\n        emb = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        out, _ = self.gru(packed)\n        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n        idx = (lengths - 1).unsqueeze(1).unsqueeze(2).expand(-1, 1, out.size(2))\n        last = out.gather(1, idx).squeeze(1)\n        return self.fc(last)\n\n\n# -------------------- prepare data --------------------\nspr_root = find_spr_root()\nspr = load_spr_bench(spr_root)\n\nspecials = [\"<pad>\", \"<unk>\"]\nvocab_set = set()\nfor s in spr[\"train\"][\"sequence\"]:\n    vocab_set.update(s.strip().split())\ntoken2idx = {tok: i + len(specials) for i, tok in enumerate(sorted(vocab_set))}\nfor i, tok in enumerate(specials):\n    token2idx[tok] = i\npad_idx = token2idx[\"<pad>\"]\n\nlabels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(labels)}\nidx2label = {i: l for l, i in label2idx.items()}\n\ntrain_ds = SPRDataset(spr[\"train\"], token2idx, label2idx)\ndev_ds = SPRDataset(spr[\"dev\"], token2idx, label2idx)\ntest_ds = SPRDataset(spr[\"test\"], token2idx, label2idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False)\n\n# -------------------- init model & optimiser --------------------\nmodel = GRUClassifier(len(token2idx), 32, 64, len(labels), pad_idx).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# -------------------- experiment data dict --------------------\nexperiment_data = {\n    \"spr_bench\": {\n        \"metrics\": {\"train\": [], \"val\": [], \"test\": None},\n        \"losses\": {\"train\": [], \"val\": [], \"test\": None},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\n# -------------------- training utils --------------------\ndef run_epoch(loader, train=True):\n    model.train() if train else model.eval()\n    total_loss, total = 0.0, 0\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            # move tensor fields to device\n            bt = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(bt[\"input_ids\"], bt[\"lengths\"])\n            loss = criterion(logits, bt[\"label\"])\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            total_loss += loss.item() * bt[\"label\"].size(0)\n            total += bt[\"label\"].size(0)\n            preds = logits.argmax(dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(bt[\"label\"].cpu().numpy())\n            all_seqs.extend(bt[\"raw_seq\"])\n    avg_loss = total_loss / total\n    y_true = [idx2label[i] for i in all_labels]\n    y_pred = [idx2label[i] for i in all_preds]\n    swa = shape_weighted_accuracy(all_seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(all_seqs, y_true, y_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    return avg_loss, (swa, cwa, hwa), y_true, y_pred\n\n\n# -------------------- training loop --------------------\nnum_epochs = 5\nfor epoch in range(1, num_epochs + 1):\n    t0 = time.time()\n    tr_loss, tr_met, _, _ = run_epoch(train_loader, train=True)\n    val_loss, val_met, _, _ = run_epoch(dev_loader, train=False)\n    experiment_data[\"spr_bench\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"spr_bench\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"train\"].append(tr_met)\n    experiment_data[\"spr_bench\"][\"metrics\"][\"val\"].append(val_met)\n    experiment_data[\"spr_bench\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: val_loss={val_loss:.4f}  SWA={val_met[0]:.4f}  CWA={val_met[1]:.4f}  HWA={val_met[2]:.4f}  ({time.time()-t0:.1f}s)\"\n    )\n\n# -------------------- test evaluation --------------------\ntest_loss, test_met, y_true_test, y_pred_test = run_epoch(test_loader, train=False)\nprint(f\"\\nTest -> SWA={test_met[0]:.4f}  CWA={test_met[1]:.4f}  HWA={test_met[2]:.4f}\")\n\nexperiment_data[\"spr_bench\"][\"losses\"][\"test\"] = test_loss\nexperiment_data[\"spr_bench\"][\"metrics\"][\"test\"] = test_met\nexperiment_data[\"spr_bench\"][\"predictions\"] = y_pred_test\nexperiment_data[\"spr_bench\"][\"ground_truth\"] = y_true_test\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# -------------------- visualization --------------------\nfig, ax = plt.subplots()\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"train\"], label=\"train\")\nax.plot(experiment_data[\"spr_bench\"][\"losses\"][\"val\"], label=\"val\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"SPR GRU Loss\")\nax.legend()\nplt.savefig(os.path.join(working_dir, \"spr_loss_curve.png\"))\nplt.close(fig)\nprint(f\"Outputs saved to {working_dir}\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 109, in <module>\\n    spr = load_spr_bench(DATA_PATH)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 28, in load_spr_bench\\n\ndset[\"train\"] = _load(\"train.csv\")\\n                    ^^^^^^^^^^^^^^^^^^\\n\nFile \"runfile.py\", line 20, in _load\\n    return load_dataset(\\n\n^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 2062, in load_dataset\\n    builder_instance =\nload_dataset_builder(\\n                       ^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1782, in load_dataset_builder\\n\ndataset_module = dataset_module_factory(\\n\n^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1497, in dataset_module_factory\\n\n).get_module()\\n      ^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 913, in get_module\\n    data_files =\nDataFilesDict.from_patterns(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\nFile \"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 690, in from_patterns\\n    else\nDataFilesList.from_patterns(\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 583, in from_patterns\\n\nresolve_pattern(\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 384, in resolve_pattern\\n    raise\nFileNotFoundError(error_msg)\\nFileNotFoundError: Unable to find\n\\'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_02-34-\n04_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-\n1/SPR_BENCH/train.csv\\'\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Traceback (most recent call last):\\n  File \"runfile.py\", line 4, in <module>\\n\nfrom SPR import load_spr_bench, shape_weighted_accuracy,\ncolor_weighted_accuracy\\nModuleNotFoundError: No module named \\'SPR\\'\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found, generating synthetic toy\ndata.', '\\n', 'Vocabulary size: 6', '\\n', 'Num labels: 2', '\\n', 'Traceback\n(most recent call last):\\n  File \"runfile.py\", line 173, in <module>\\n    for\nbatch in train_loader:\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/utils/data/dataloader.py\", line 701, in __next__\\n    data =\nself._next_data()\\n           ^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/utils/data/dataloader.py\", line 757, in _next_data\\n    data =\nself._dataset_fetcher.fetch(index)  # may raise StopIteration\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\\n    data =\nself.dataset.__getitems__(possibly_batched_index)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/arrow_dataset.py\", line 2781, in __getitems__\\n    batch =\nself.__getitem__(keys)\\n            ^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\",\nline 128, in __getitem__\\n    return {\"input\": torch.tensor(self.X[idx]),\n\"label\": torch.tensor(self.y[idx])}\\n\n~~~~~~^^^^^\\nTypeError: list indices must be integers or slices, not list\\n',\n'Execution time: a second seconds (time limit is 30 minutes).']", "['Traceback (most recent call last):\\n  File \"runfile.py\", line 4, in <module>\\n\nfrom SPR import load_spr_bench, shape_weighted_accuracy,\ncolor_weighted_accuracy\\nModuleNotFoundError: No module named \\'SPR\\'\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 363828.33\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 470477.17\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 497426.94\nexamples/s]', '\\n', 'Epoch 1: val_loss=0.2213  SWA=0.9212  CWA=0.9176\nHWA=0.9194  (1.8s)', '\\n', 'Epoch 2: val_loss=0.1494  SWA=0.9536  CWA=0.9517\nHWA=0.9527  (1.5s)', '\\n', 'Epoch 3: val_loss=0.1279  SWA=0.9626  CWA=0.9611\nHWA=0.9618  (1.6s)', '\\n', 'Epoch 4: val_loss=0.1072  SWA=0.9680  CWA=0.9673\nHWA=0.9676  (1.5s)', '\\n', 'Epoch 5: val_loss=0.0845  SWA=0.9795  CWA=0.9797\nHWA=0.9796  (1.6s)', '\\n', '\\nTest -> SWA=0.6454  CWA=0.6913  HWA=0.6676', '\\n',\n'Outputs saved to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_02-34-\n04_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-4/working',\n'\\n', 'Execution time: 11 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 531503.16\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 679063.56\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 379180.40\nexamples/s]', '\\n', 'Epoch 1: val_loss = 0.2213 SWA = 0.9212 CWA = 0.9176 HWA =\n0.9194   (elapsed 1.8s)', '\\n', 'Epoch 2: val_loss = 0.1494 SWA = 0.9536 CWA =\n0.9517 HWA = 0.9527   (elapsed 1.6s)', '\\n', 'Epoch 3: val_loss = 0.1279 SWA =\n0.9626 CWA = 0.9611 HWA = 0.9618   (elapsed 1.5s)', '\\n', 'Epoch 4: val_loss =\n0.1072 SWA = 0.9680 CWA = 0.9673 HWA = 0.9676   (elapsed 1.6s)', '\\n', 'Epoch 5:\nval_loss = 0.0845 SWA = 0.9795 CWA = 0.9797 HWA = 0.9796   (elapsed 1.6s)',\n'\\n', '\\nTest set -> SWA=0.6454  CWA=0.6913  HWA=0.6676', '\\n', 'All outputs\nsaved in /home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_02-34-\n04_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-1/working',\n'\\n', 'Execution time: 11 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found, generating synthetic toy\ndata.', '\\n', 'Vocabulary size: 6', '\\n', 'Number of labels: 2', '\\n', 'Epoch 1:\ntrain_loss=0.6972  validation_loss=0.6867  HWA=0.6040', '\\n', 'Epoch 2:\ntrain_loss=0.6895  validation_loss=0.6871  HWA=0.5664', '\\n', 'Epoch 3:\ntrain_loss=0.6881  validation_loss=0.6825  HWA=0.6007', '\\n', 'Epoch 4:\ntrain_loss=0.6945  validation_loss=0.6820  HWA=0.6007', '\\n', 'Epoch 5:\ntrain_loss=0.6958  validation_loss=0.6866  HWA=0.5630', '\\n', 'Epoch 6:\ntrain_loss=0.6984  validation_loss=0.6998  HWA=0.4302', '\\n', 'Epoch 7:\ntrain_loss=0.6901  validation_loss=0.7168  HWA=0.4336', '\\n', 'Epoch 8:\ntrain_loss=0.6901  validation_loss=0.7219  HWA=0.3770', '\\n', 'Epoch 9:\ntrain_loss=0.6950  validation_loss=0.7256  HWA=0.3770', '\\n', 'Epoch 10:\ntrain_loss=0.6891  validation_loss=0.7240  HWA=0.3770', '\\n', '\\nTEST |\nSWA=0.3758  CWA=0.3894  HWA=0.3825', '\\n', 'Execution time: 2 seconds seconds\n(time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 353605.05\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 497887.51\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 708736.74\nexamples/s]', '\\n', 'Dataset sizes:', ' ', \"{'train': 20000, 'dev': 5000,\n'test': 10000}\", '\\n', 'Epoch 1: val_loss=0.2213, SWA=0.9212, CWA=0.9176,\nHWA=0.9194 (elapsed 1.7s)', '\\n', 'Epoch 2: val_loss=0.1494, SWA=0.9536,\nCWA=0.9517, HWA=0.9527 (elapsed 1.5s)', '\\n', 'Epoch 3: val_loss=0.1279,\nSWA=0.9626, CWA=0.9611, HWA=0.9618 (elapsed 1.5s)', '\\n', 'Epoch 4:\nval_loss=0.1072, SWA=0.9680, CWA=0.9673, HWA=0.9676 (elapsed 1.5s)', '\\n',\n'Epoch 5: val_loss=0.0845, SWA=0.9795, CWA=0.9797, HWA=0.9796 (elapsed 1.5s)',\n'\\n', '\\nTest: SWA=0.6454 CWA=0.6913 HWA=0.6676', '\\n', 'Outputs saved to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_02-34-\n04_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-3/working',\n'\\n', 'Execution time: 10 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Epoch 1: val_loss=0.1995  SWA=0.9348  CWA=0.9315\nHWA=0.9332  (1.8s)', '\\n', 'Epoch 2: val_loss=0.1603  SWA=0.9511  CWA=0.9485\nHWA=0.9498  (1.5s)', '\\n', 'Epoch 3: val_loss=0.1362  SWA=0.9644  CWA=0.9624\nHWA=0.9634  (1.5s)', '\\n', 'Epoch 4: val_loss=0.1227  SWA=0.9649  CWA=0.9632\nHWA=0.9640  (1.5s)', '\\n', 'Epoch 5: val_loss=0.1083  SWA=0.9706  CWA=0.9694\nHWA=0.9700  (1.5s)', '\\n', '\\nTest -> SWA=0.6430  CWA=0.6870  HWA=0.6643', '\\n',\n'Outputs saved to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_02-34-\n04_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-1/working',\n'\\n', 'Execution time: 11 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Epoch 1: val_loss=0.2144  SWA=0.9246  CWA=0.9218\nHWA=0.9232  (1.9s)', '\\n', 'Epoch 2: val_loss=0.1606  SWA=0.9511  CWA=0.9490\nHWA=0.9500  (1.5s)', '\\n', 'Epoch 3: val_loss=0.1447  SWA=0.9595  CWA=0.9572\nHWA=0.9584  (1.5s)', '\\n', 'Epoch 4: val_loss=0.1320  SWA=0.9608  CWA=0.9588\nHWA=0.9598  (1.6s)', '\\n', 'Epoch 5: val_loss=0.1185  SWA=0.9646  CWA=0.9627\nHWA=0.9637  (1.5s)', '\\n', '\\nTest -> SWA=0.6385  CWA=0.6823  HWA=0.6597', '\\n',\n'Outputs saved to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_02-34-\n04_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-3/working',\n'\\n', 'Execution time: 11 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Epoch 1: val_loss=0.1929  SWA=0.9376  CWA=0.9353\nHWA=0.9365  (3.0s)', '\\n', 'Epoch 2: val_loss=0.1611  SWA=0.9494  CWA=0.9471\nHWA=0.9483  (2.7s)', '\\n', 'Epoch 3: val_loss=0.1465  SWA=0.9608  CWA=0.9583\nHWA=0.9595  (2.6s)', '\\n', 'Epoch 4: val_loss=0.1344  SWA=0.9605  CWA=0.9579\nHWA=0.9592  (2.5s)', '\\n', 'Epoch 5: val_loss=0.1213  SWA=0.9612  CWA=0.9593\nHWA=0.9603  (2.7s)', '\\n', '\\nTest -> SWA=0.6386  CWA=0.6819  HWA=0.6596', '\\n',\n'Outputs saved to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_02-34-\n04_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-4/working',\n'\\n', 'Execution time: 17 seconds seconds (time limit is 30 minutes).']", ""], "analysis": ["The execution failed due to a FileNotFoundError. The script was unable to locate\nthe dataset file 'train.csv' in the specified directory '/home/zxl240011/AI-Scie\nntist-v2/experiments/2025-08-15_02-34-\n04_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-\n1/SPR_BENCH/'. This indicates that the dataset path provided is either incorrect\nor the dataset files are missing.  Proposed Fix: 1. Verify that the dataset\nfiles ('train.csv', 'dev.csv', 'test.csv') are present in the specified\ndirectory. 2. Ensure that the 'DATA_PATH' variable is correctly set to the\ndirectory containing the SPR_BENCH dataset. 3. If the dataset files are located\nelsewhere, update the 'DATA_PATH' variable to point to the correct directory. 4.\nAdditionally, check for any permissions issues that might prevent access to the\ndataset files.", "The execution failed due to a `ModuleNotFoundError` for the module 'SPR'. This\nindicates that the script is unable to locate the 'SPR.py' file or it is not in\nthe Python path. To fix this issue, ensure that the 'SPR.py' file is in the same\ndirectory as the script being executed or add its directory to the Python path\nusing `sys.path.append('/path/to/SPR.py')`. Alternatively, verify that the file\nexists and is named correctly.", "The execution failed due to a TypeError in the `__getitem__` method of the\n`SPRVectorDataset` class. The error occurred because `idx` was a list, but the\ncode expected `idx` to be an integer or slice. This happened because the\n`__getitem__` method was not designed to handle batched indices. To fix this,\nmodify the `__getitem__` method to handle lists (batched indices) by returning a\nbatch of data when `idx` is a list. Specifically, update `__getitem__` to check\nif `idx` is a list and handle it appropriately, such as by iterating over the\nindices and returning a list of dictionaries for the batch.", "The script failed due to a `ModuleNotFoundError` for the module 'SPR'. This\nerror occurred because the script attempted to import 'SPR', but the module is\nnot available in the Python environment. To fix this issue, ensure that the\n'SPR.py' file is present in the current working directory or in the Python path.\nAlternatively, directly use the provided code for 'SPR' functions in the script\nor adjust the import statement to match the correct module location.", "", "", "", "The execution of the training script was successful without any bugs. The\ndataset was loaded correctly, the model was trained over 5 epochs, and the\nvalidation loss steadily decreased, indicating effective learning. The Shape-\nWeighted Accuracy (SWA), Color-Weighted Accuracy (CWA), and Harmonic Weighted\nAccuracy (HWA) metrics showed consistent improvement on the validation set. The\nfinal test metrics were also computed, and the results were saved as outputs,\nincluding a loss curve plot. Everything functioned as expected.", "The code executed successfully without any issues. The model was trained and\nvalidated over 5 epochs, showing a consistent improvement in validation metrics\nsuch as SWA, CWA, and HWA. The test results were also successfully computed and\nsaved, although the test metrics (SWA=0.6430, CWA=0.6870, HWA=0.6643) were\nsignificantly lower compared to the validation metrics. This discrepancy might\nindicate overfitting or a difference in data distribution between the validation\nand test sets. However, this is not a bug but rather an observation that might\nrequire further investigation in future experimentation.", "", "", ""], "exc_type": ["FileNotFoundError", "ModuleNotFoundError", "TypeError", "ModuleNotFoundError", null, null, null, null, null, null, null, null], "exc_info": [{"args": ["Unable to find '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-1/SPR_BENCH/train.csv'"]}, {"args": ["No module named 'SPR'"], "name": "SPR", "msg": "No module named 'SPR'"}, {"args": ["list indices must be integers or slices, not list"]}, {"args": ["No module named 'SPR'"], "name": "SPR", "msg": "No module named 'SPR'"}, null, null, null, null, null, null, null, null], "exc_stack": [[["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 109, "<module>", "spr = load_spr_bench(DATA_PATH)"], ["runfile.py", 28, "load_spr_bench", "dset[\"train\"] = _load(\"train.csv\")"], ["runfile.py", 20, "_load", "return load_dataset("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 2062, "load_dataset", "builder_instance = load_dataset_builder("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1782, "load_dataset_builder", "dataset_module = dataset_module_factory("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1497, "dataset_module_factory", ").get_module()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 913, "get_module", "data_files = DataFilesDict.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 690, "from_patterns", "else DataFilesList.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 583, "from_patterns", "resolve_pattern("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 384, "resolve_pattern", "raise FileNotFoundError(error_msg)"]], [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 4, "<module>", "from SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy"]], [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 173, "<module>", "for batch in train_loader:"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/utils/data/dataloader.py", 701, "__next__", "data = self._next_data()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/utils/data/dataloader.py", 757, "_next_data", "data = self._dataset_fetcher.fetch(index)  # may raise StopIteration"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", 50, "fetch", "data = self.dataset.__getitems__(possibly_batched_index)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/arrow_dataset.py", 2781, "__getitems__", "batch = self.__getitem__(keys)"], ["runfile.py", 128, "__getitem__", "return {\"input\": torch.tensor(self.X[idx]), \"label\": torch.tensor(self.y[idx])}"]], [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 4, "<module>", "from SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy"]], null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value for the training dataset at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.0953, "best_value": 0.0953}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value for the validation dataset at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.0845, "best_value": 0.0845}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value for the test dataset.", "data": [{"dataset_name": "spr_bench", "final_value": 1.629, "best_value": 1.629}]}, {"metric_name": "train Shape-Weighted Accuracy", "lower_is_better": false, "description": "The Shape-Weighted Accuracy for the training dataset at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9736, "best_value": 0.9736}]}, {"metric_name": "train Color-Weighted Accuracy", "lower_is_better": false, "description": "The Color-Weighted Accuracy for the training dataset at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9735, "best_value": 0.9735}]}, {"metric_name": "train Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The Harmonic-Weighted Accuracy for the training dataset at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9736, "best_value": 0.9736}]}, {"metric_name": "validation Shape-Weighted Accuracy", "lower_is_better": false, "description": "The Shape-Weighted Accuracy for the validation dataset at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9795, "best_value": 0.9795}]}, {"metric_name": "validation Color-Weighted Accuracy", "lower_is_better": false, "description": "The Color-Weighted Accuracy for the validation dataset at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9797, "best_value": 0.9797}]}, {"metric_name": "validation Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The Harmonic-Weighted Accuracy for the validation dataset at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9796, "best_value": 0.9796}]}, {"metric_name": "test Shape-Weighted Accuracy", "lower_is_better": false, "description": "The Shape-Weighted Accuracy for the test dataset.", "data": [{"dataset_name": "spr_bench", "final_value": 0.6454, "best_value": 0.6454}]}, {"metric_name": "test Color-Weighted Accuracy", "lower_is_better": false, "description": "The Color-Weighted Accuracy for the test dataset.", "data": [{"dataset_name": "spr_bench", "final_value": 0.6913, "best_value": 0.6913}]}, {"metric_name": "test Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The Harmonic-Weighted Accuracy for the test dataset.", "data": [{"dataset_name": "spr_bench", "final_value": 0.6676, "best_value": 0.6676}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures how well the model's predictions match the actual values. Lower is better.", "data": [{"dataset_name": "training", "final_value": 0.0953, "best_value": 0.0953}, {"dataset_name": "validation", "final_value": 0.0845, "best_value": 0.0845}, {"dataset_name": "test", "final_value": 1.629, "best_value": 1.629}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions weighted by their shape. Higher is better.", "data": [{"dataset_name": "training", "final_value": 0.9736, "best_value": 0.9736}, {"dataset_name": "validation", "final_value": 0.9795, "best_value": 0.9795}, {"dataset_name": "test", "final_value": 0.6454, "best_value": 0.6454}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions weighted by their color. Higher is better.", "data": [{"dataset_name": "training", "final_value": 0.9735, "best_value": 0.9735}, {"dataset_name": "validation", "final_value": 0.9797, "best_value": 0.9797}, {"dataset_name": "test", "final_value": 0.6913, "best_value": 0.6913}]}, {"metric_name": "harmonic-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions weighted harmonically. Higher is better.", "data": [{"dataset_name": "training", "final_value": 0.9736, "best_value": 0.9736}, {"dataset_name": "validation", "final_value": 0.9796, "best_value": 0.9796}, {"dataset_name": "test", "final_value": 0.6676, "best_value": 0.6676}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value on the training dataset.", "data": [{"dataset_name": "training dataset", "final_value": 0.6891, "best_value": 0.6891}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset.", "data": [{"dataset_name": "validation dataset", "final_value": 0.724, "best_value": 0.724}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "The shape weighted accuracy on the validation dataset.", "data": [{"dataset_name": "validation dataset", "final_value": 0.3716, "best_value": 0.3716}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "The color weighted accuracy on the validation dataset.", "data": [{"dataset_name": "validation dataset", "final_value": 0.3826, "best_value": 0.3826}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy on the validation dataset.", "data": [{"dataset_name": "validation dataset", "final_value": 0.377, "best_value": 0.377}]}, {"metric_name": "test shape weighted accuracy", "lower_is_better": false, "description": "The shape weighted accuracy on the test dataset.", "data": [{"dataset_name": "test dataset", "final_value": 0.3758, "best_value": 0.3758}]}, {"metric_name": "test color weighted accuracy", "lower_is_better": false, "description": "The color weighted accuracy on the test dataset.", "data": [{"dataset_name": "test dataset", "final_value": 0.3894, "best_value": 0.3894}]}, {"metric_name": "test harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy on the test dataset.", "data": [{"dataset_name": "test dataset", "final_value": 0.3825, "best_value": 0.3825}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Loss measures the error of the model. Lower values indicate better performance.", "data": [{"dataset_name": "training set", "final_value": 0.0953, "best_value": 0.0953}, {"dataset_name": "validation set", "final_value": 0.0845, "best_value": 0.0845}, {"dataset_name": "test set", "final_value": 1.629, "best_value": 1.629}]}, {"metric_name": "shape-weighted accuracy (SWA)", "lower_is_better": false, "description": "Shape-weighted accuracy evaluates accuracy with a focus on shape features.", "data": [{"dataset_name": "training set", "final_value": 0.9736, "best_value": 0.9736}, {"dataset_name": "validation set", "final_value": 0.9795, "best_value": 0.9795}, {"dataset_name": "test set", "final_value": 0.6454, "best_value": 0.6454}]}, {"metric_name": "color-weighted accuracy (CWA)", "lower_is_better": false, "description": "Color-weighted accuracy evaluates accuracy with a focus on color features.", "data": [{"dataset_name": "training set", "final_value": 0.9735, "best_value": 0.9735}, {"dataset_name": "validation set", "final_value": 0.9797, "best_value": 0.9797}, {"dataset_name": "test set", "final_value": 0.6913, "best_value": 0.6913}]}, {"metric_name": "harmonic-weighted accuracy (HWA)", "lower_is_better": false, "description": "Harmonic-weighted accuracy evaluates accuracy with a balance between shape and color features.", "data": [{"dataset_name": "training set", "final_value": 0.9736, "best_value": 0.9736}, {"dataset_name": "validation set", "final_value": 0.9796, "best_value": 0.9796}, {"dataset_name": "test set", "final_value": 0.6676, "best_value": 0.6676}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss calculated on the training dataset during the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.1153, "best_value": 0.1153}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset during the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.1083, "best_value": 0.1083}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss calculated on the test dataset.", "data": [{"dataset_name": "spr_bench", "final_value": 1.4609, "best_value": 1.4609}]}, {"metric_name": "train Shape-Weighted Accuracy", "lower_is_better": false, "description": "The Shape-Weighted Accuracy calculated on the training dataset during the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9672, "best_value": 0.9672}]}, {"metric_name": "train Color-Weighted Accuracy", "lower_is_better": false, "description": "The Color-Weighted Accuracy calculated on the training dataset during the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9664, "best_value": 0.9664}]}, {"metric_name": "train Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The Harmonic-Weighted Accuracy calculated on the training dataset during the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9668, "best_value": 0.9668}]}, {"metric_name": "validation Shape-Weighted Accuracy", "lower_is_better": false, "description": "The Shape-Weighted Accuracy calculated on the validation dataset during the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9706, "best_value": 0.9706}]}, {"metric_name": "validation Color-Weighted Accuracy", "lower_is_better": false, "description": "The Color-Weighted Accuracy calculated on the validation dataset during the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9694, "best_value": 0.9694}]}, {"metric_name": "validation Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The Harmonic-Weighted Accuracy calculated on the validation dataset during the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.97, "best_value": 0.97}]}, {"metric_name": "test Shape-Weighted Accuracy", "lower_is_better": false, "description": "The Shape-Weighted Accuracy calculated on the test dataset.", "data": [{"dataset_name": "spr_bench", "final_value": 0.643, "best_value": 0.643}]}, {"metric_name": "test Color-Weighted Accuracy", "lower_is_better": false, "description": "The Color-Weighted Accuracy calculated on the test dataset.", "data": [{"dataset_name": "spr_bench", "final_value": 0.687, "best_value": 0.687}]}, {"metric_name": "test Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The Harmonic-Weighted Accuracy calculated on the test dataset.", "data": [{"dataset_name": "spr_bench", "final_value": 0.6643, "best_value": 0.6643}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The training loss at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.1223, "best_value": 0.1223}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The validation loss at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.1185, "best_value": 0.1185}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The test loss.", "data": [{"dataset_name": "spr_bench", "final_value": 1.6345, "best_value": 1.6345}]}, {"metric_name": "train Shape-Weighted Accuracy", "lower_is_better": false, "description": "The training Shape-Weighted Accuracy at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.965, "best_value": 0.965}]}, {"metric_name": "train Color-Weighted Accuracy", "lower_is_better": false, "description": "The training Color-Weighted Accuracy at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9634, "best_value": 0.9634}]}, {"metric_name": "train Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The training Harmonic-Weighted Accuracy at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9642, "best_value": 0.9642}]}, {"metric_name": "validation Shape-Weighted Accuracy", "lower_is_better": false, "description": "The validation Shape-Weighted Accuracy at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9646, "best_value": 0.9646}]}, {"metric_name": "validation Color-Weighted Accuracy", "lower_is_better": false, "description": "The validation Color-Weighted Accuracy at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9627, "best_value": 0.9627}]}, {"metric_name": "validation Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The validation Harmonic-Weighted Accuracy at the final epoch.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9637, "best_value": 0.9637}]}, {"metric_name": "test Shape-Weighted Accuracy", "lower_is_better": false, "description": "The test Shape-Weighted Accuracy.", "data": [{"dataset_name": "spr_bench", "final_value": 0.6385, "best_value": 0.6385}]}, {"metric_name": "test Color-Weighted Accuracy", "lower_is_better": false, "description": "The test Color-Weighted Accuracy.", "data": [{"dataset_name": "spr_bench", "final_value": 0.6823, "best_value": 0.6823}]}, {"metric_name": "test Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The test Harmonic-Weighted Accuracy.", "data": [{"dataset_name": "spr_bench", "final_value": 0.6597, "best_value": 0.6597}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training, with lower values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 0.1229, "best_value": 0.1229}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, with lower values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 0.1213, "best_value": 0.1213}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value during testing, with lower values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 1.6401, "best_value": 1.6401}]}, {"metric_name": "train Shape-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy weighted by shape during training, with higher values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9638, "best_value": 0.9638}]}, {"metric_name": "train Color-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy weighted by color during training, with higher values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9624, "best_value": 0.9624}]}, {"metric_name": "train Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy weighted harmonically during training, with higher values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9631, "best_value": 0.9631}]}, {"metric_name": "validation Shape-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy weighted by shape during validation, with higher values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9612, "best_value": 0.9612}]}, {"metric_name": "validation Color-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy weighted by color during validation, with higher values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9593, "best_value": 0.9593}]}, {"metric_name": "validation Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy weighted harmonically during validation, with higher values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9603, "best_value": 0.9603}]}, {"metric_name": "test Shape-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy weighted by shape during testing, with higher values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 0.6386, "best_value": 0.6386}]}, {"metric_name": "test Color-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy weighted by color during testing, with higher values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 0.6819, "best_value": 0.6819}]}, {"metric_name": "test Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy weighted harmonically during testing, with higher values indicating better performance.", "data": [{"dataset_name": "spr_bench", "final_value": 0.6596, "best_value": 0.6596}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, true, false, false, false, false, false, false, false], "plots": [[], [], [], [], ["../../logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_loss_curve.png", "../../logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_bench_loss_curves.png", "../../logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_bench_metric_curves.png", "../../logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_bench_label_distribution.png"], ["../../logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_loss_curve.png", "../../logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_loss_curve.png", "../../logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_metric_curves.png", "../../logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_test_metrics.png", "../../logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_loss_curve.png", "../../logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_hwa_curve.png", "../../logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_swa_cwa_curve.png", "../../logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_test_metrics_bar.png"], ["../../logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_loss_curve.png", "../../logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_bench_loss_curve.png", "../../logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_bench_metric_curves.png", "../../logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_bench_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_loss_curve.png", "../../logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_bench_loss_curves.png", "../../logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_bench_metric_curves.png", "../../logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_bench_label_distribution.png"], ["../../logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_loss_curve.png", "../../logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_bench_loss_curves.png", "../../logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_bench_metric_curves.png", "../../logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_bench_label_distribution.png"], ["../../logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_loss_curve.png", "../../logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_bench_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_bench_metric_curves.png", "../../logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_bench_label_distribution.png"], ["../../logs/0-run/experiment_results/seed_aggregation_2ad77d2deae94fa4ad694ed46bbdcf68/spr_bench_loss_curves_agg.png", "../../logs/0-run/experiment_results/seed_aggregation_2ad77d2deae94fa4ad694ed46bbdcf68/spr_bench_metric_curves_agg.png"]], "plot_paths": [[], [], [], [], ["experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_loss_curve.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_bench_loss_curves.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_bench_metric_curves.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_bench_label_distribution.png"], ["experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_loss_curve.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_loss_curve.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_metric_curves.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_test_metrics.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_confusion_matrix.png"], ["experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_loss_curve.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_hwa_curve.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_swa_cwa_curve.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_test_metrics_bar.png"], ["experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_loss_curve.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_bench_loss_curve.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_bench_metric_curves.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_bench_test_metrics.png"], ["experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_loss_curve.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_bench_loss_curves.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_bench_metric_curves.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_bench_label_distribution.png"], ["experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_loss_curve.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_bench_loss_curves.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_bench_metric_curves.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_bench_label_distribution.png"], ["experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_loss_curve.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_bench_loss_curves.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_bench_metric_curves.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_bench_label_distribution.png"], ["experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_2ad77d2deae94fa4ad694ed46bbdcf68/spr_bench_loss_curves_agg.png", "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_2ad77d2deae94fa4ad694ed46bbdcf68/spr_bench_metric_curves_agg.png"]], "plot_analyses": [[], [], [], [], [{"analysis": "The plot shows the loss curves for both training and validation data over 5 epochs. The training loss decreases rapidly in the first epoch and continues to decline steadily, indicating that the model is learning effectively. The validation loss follows a similar trend, suggesting that the model generalizes well to unseen data without significant overfitting. The convergence of the two curves towards the end further supports this observation.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_loss_curve.png"}, {"analysis": "This plot presents a comparison of training and validation loss curves. Both curves exhibit a similar downward trend, with the training loss decreasing slightly faster than the validation loss. This consistency between the two curves implies that the model maintains generalization while improving performance. The rapid loss reduction in the initial epochs highlights effective learning during early training stages.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_bench_loss_curves.png"}, {"analysis": "This plot illustrates the accuracy metrics (SWA, CWA, and HWA) over epochs for both training and validation datasets. All metrics show a steep improvement in the first epoch, followed by a gradual increase, eventually converging to high accuracy levels. The close alignment of training and validation curves across all metrics indicates robust generalization and suggests that the model is effectively handling both shape and color variations in the Synthetic PolyRule Reasoning task.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_bench_metric_curves.png"}, {"analysis": "The label distribution plot compares the ground truth and predicted labels. The alignment between the two distributions is reasonably close, indicating that the model's predictions align well with the actual labels. However, there are slight discrepancies, suggesting room for further improvement in prediction accuracy. The balanced distribution across classes indicates that the model does not exhibit significant bias towards any particular class.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_017e058a574846e58a2197fd53acaf90_proc_2808981/spr_bench_label_distribution.png"}], [{"analysis": "The loss curves for training and validation show a consistent decrease over the epochs, indicating that the model is learning effectively. The validation loss consistently remains lower than the training loss, which suggests that the model is not overfitting and is generalizing well to unseen data.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_loss_curve.png"}, {"analysis": "This plot again shows the decreasing trend of training and validation loss. The slight gap between the two curves indicates that the model maintains a good balance between training and generalization. The decreasing loss towards the final epochs suggests convergence.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_loss_curve.png"}, {"analysis": "The weighted accuracy curves for Shape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA), and Hybrid-Weighted Accuracy (HWA) show an improvement over epochs for both training and validation. The convergence of training and validation curves indicates that the model generalizes well across these metrics. The slight upward trend towards the end suggests that further training might yield marginal improvements.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_metric_curves.png"}, {"analysis": "The bar chart shows the final test weighted accuracies for SWA, CWA, and HWA. Among them, CWA has the highest accuracy at 0.691, followed by HWA at 0.668, and SWA at 0.645. This indicates that the model performs slightly better on color-related reasoning tasks compared to shape-related ones.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_test_metrics.png"}, {"analysis": "The confusion matrix reveals that the model achieves a reasonable balance between true positives and true negatives. However, there is still room for improvement as the number of false positives and false negatives is significant. This indicates that the model may struggle with certain edge cases or ambiguous inputs.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_569abe601bdd4b79a299dd649612efc6_proc_2808978/spr_bench_confusion_matrix.png"}], [{"analysis": "The training loss decreases steadily across epochs, indicating that the model is learning from the training data. However, the validation loss increases significantly after epoch 5, suggesting overfitting. This indicates that the model is not generalizing well to the validation data, and the learning process may need regularization or early stopping to prevent overfitting.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_loss_curve.png"}, {"analysis": "The validation HWA starts at a relatively high value but decreases steadily after epoch 4, and it plateaus at a low value after epoch 7. This drop in HWA indicates that the model's ability to handle more complex hierarchical reasoning tasks diminishes as training progresses, likely due to overfitting or an inability to generalize to unseen patterns in the validation set.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_hwa_curve.png"}, {"analysis": "Both SWA and CWA metrics show a similar trend, starting at higher values and gradually dropping after epoch 4. This suggests that the model initially performs well in recognizing shape and color-weighted patterns but loses this capability as training progresses, possibly because of overfitting or a lack of robustness in the learned representations.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_swa_cwa_curve.png"}, {"analysis": "The test metrics for SWA, CWA, and HWA are all relatively low and close to each other, indicating a uniform but suboptimal performance across all three evaluation criteria. This suggests that the model is not effectively capturing the complexities of the synthetic PolyRule reasoning tasks and requires further refinement or additional techniques to improve its generalization capabilities.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bfe9e83f4b9c492cb0848714c7707c88_proc_2808979/spr_bench_test_metrics_bar.png"}], [{"analysis": "The loss curves for both training and validation indicate a steady decrease in loss over the epochs, with the validation loss being consistently lower than the training loss. This suggests that the model is learning effectively without overfitting. The gap between the training and validation loss is small, indicating good generalization.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_loss_curve.png"}, {"analysis": "Similar to the previous plot, this loss curve shows consistent decreases in both training and validation losses over epochs. The validation loss is slightly lower than the training loss, which again implies that the model is not overfitting and is generalizing well to unseen data.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_bench_loss_curve.png"}, {"analysis": "The weighted accuracy metrics (SWA, CWA, and HWA) for both training and validation improve steadily over epochs, reaching values close to 1.0. This demonstrates that the model is achieving high accuracy across all metrics and is capable of generalizing to the validation set. The close alignment of the training and validation curves further confirms the robustness of the model.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_bench_metric_curves.png"}, {"analysis": "The final test metrics show that the model achieves reasonably high performance across all three weighted accuracy metrics: SWA (0.645), CWA (0.691), and HWA (0.668). Among these, the model performs best on CWA, followed by HWA and SWA. This indicates that the model is slightly better at reasoning about colors compared to shapes or a combination of the two.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_0bbc03affa414b20a24fef701c0650f6_proc_2808980/spr_bench_test_metrics.png"}], [{"analysis": "The training and validation loss curves show a clear downward trend, indicating that the model is learning effectively. The training loss decreases rapidly in the initial epochs and then converges, while the validation loss follows a similar pattern with minimal overfitting. This suggests that the model generalizes well to unseen data.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_loss_curve.png"}, {"analysis": "This plot reaffirms the trends observed in the previous loss curve. Both the training and validation losses decrease consistently and converge as training progresses, further supporting the conclusion that the model is learning effectively without significant overfitting.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_bench_loss_curves.png"}, {"analysis": "The accuracy metrics (SWA, CWA, and HWA) for both training and validation datasets show a consistent upward trend, with the validation accuracy closely tracking the training accuracy. This indicates that the model achieves high performance on both metrics and generalizes well to unseen data. The convergence of the curves suggests stability in training.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_bench_metric_curves.png"}, {"analysis": "The label distribution comparison between ground truth and model predictions shows a close match, indicating that the model is capable of accurately predicting the label distribution. However, there is a slight underestimation in one class, which might need further investigation to ensure balanced performance across classes.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/spr_bench_label_distribution.png"}], [{"analysis": "This plot shows the training and validation loss for the GRU model over 5 epochs. The training loss decreases steadily, indicating that the model is learning from the data. The validation loss also decreases and closely follows the training loss, suggesting that the model generalizes well to unseen data without overfitting.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_loss_curve.png"}, {"analysis": "This plot essentially replicates the previous one, showing the loss curves for both training and validation sets over 5 epochs. The consistent decrease in both curves confirms the model's ability to learn and generalize effectively, maintaining a low gap between the two losses.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_bench_loss_curves.png"}, {"analysis": "This plot tracks multiple accuracy metrics (SWA, CWA, HWA) for both training and validation sets over 5 epochs. All metrics improve rapidly in the initial epochs and converge to high values, indicating strong performance and consistency across different evaluation criteria. The close alignment of training and validation metrics further highlights good generalization.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_bench_metric_curves.png"}, {"analysis": "This plot compares the distribution of ground truth labels and model predictions. The distributions are similar, indicating that the model performs well in predicting the correct labels. However, there is a slight imbalance, as predictions for one class are marginally lower than the ground truth, which could be an area for further improvement.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/spr_bench_label_distribution.png"}], [{"analysis": "This plot shows the training and validation loss curves over epochs for the SPR GRU model. The training loss decreases sharply in the first epoch and continues to decline steadily, indicating that the model is learning effectively. The validation loss also decreases at a similar rate, which suggests that the model generalizes well to unseen data. The convergence of the two curves by the final epoch indicates minimal overfitting.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_loss_curve.png"}, {"analysis": "This plot displays the training and validation loss curves for the SPR_BENCH dataset. Similar to the previous plot, both curves decrease steadily over epochs, with the training loss dropping sharply initially and then stabilizing. The validation loss follows a similar trend, converging closely with the training loss by the end of the training process. This indicates good generalization and effective learning.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_bench_loss_curves.png"}, {"analysis": "This plot illustrates the accuracy metrics (SWA, CWA, and HWA) for both training and validation sets over epochs. The solid lines represent training metrics, while the dashed lines represent validation metrics. All metrics show rapid improvement in the initial epochs and converge to high values (above 0.95) by the final epoch. The close alignment between training and validation metrics across all epochs indicates that the model performs consistently on both seen and unseen data.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_bench_metric_curves.png"}, {"analysis": "This plot compares the label distribution between the ground truth and the model's predictions. The counts for the two classes (0 and 1) are similar between the ground truth and predictions, suggesting that the model maintains a balanced prediction distribution and aligns well with the true label distribution.", "plot_path": "experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/spr_bench_label_distribution.png"}], []], "vlm_feedback_summary": ["[]", "[]", "[]", "[]", "The experimental results demonstrate effective learning and generalization in\nthe Synthetic PolyRule Reasoning task. The loss curves indicate consistent\nperformance improvements without overfitting, while the accuracy metrics confirm\nrobust handling of shape and color variations. The label distribution analysis\nreveals a good alignment between predictions and ground truth, with minor\ndiscrepancies that could be addressed in future iterations.", "The experimental results show consistent learning and generalization across\nmetrics. The model demonstrates effective training with no signs of overfitting.\nWeighted accuracies highlight that the model performs better on color-related\ntasks, and the confusion matrix suggests areas for improvement in handling\nambiguous cases.", "The plots indicate that the model suffers from overfitting, as evidenced by the\ndivergence between training and validation loss and the decline in validation\nmetrics (HWA, SWA, and CWA) over epochs. The test metrics also show uniformly\nlow performance, suggesting the need for better generalization strategies.", "The provided plots indicate that the model is learning effectively and\ngeneralizing well to unseen data. The loss curves show steady decreases for both\ntraining and validation, with no signs of overfitting. The weighted accuracy\nmetrics demonstrate high performance, with the model performing best on CWA,\nfollowed by HWA and SWA. Overall, the results suggest that the proposed neural-\nsymbolic integration approach is effective for zero-shot reasoning in Synthetic\nPolyRule Reasoning.", "The plots indicate that the model is learning effectively, with consistent\nimprovements in loss and accuracy metrics over epochs and good generalization to\nunseen data. The label distribution comparison shows accurate predictions with\nminor discrepancies.", "The plots provide a comprehensive view of the model's performance, showcasing\neffective learning and generalization across loss and accuracy metrics. The\nlabel distribution plot indicates strong prediction capabilities with minor\nimbalances to address.", "The plots show effective learning and generalization of the model, with training\nand validation losses decreasing steadily and converging. Accuracy metrics are\nhigh and consistent across training and validation, indicating robust\nperformance. The label distribution plot confirms that the model's predictions\nalign well with the ground truth distribution.", "[]"], "exec_time": [0.635890007019043, 0.0028791427612304688, 1.519731044769287, 0.0038869380950927734, 11.275168657302856, 11.201059341430664, 2.054851531982422, 10.52658224105835, 11.27690052986145, 11.657594919204712, 17.44348955154419, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [[], [], [], [], ["['SPR_BENCH']"], ["[\"spr_bench\"]"], ["[]"], ["['SPR_BENCH']"], ["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], []], "plot_code": [null, null, null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    spr = experiment_data[\"spr_bench\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    spr = None\n\nif spr is not None:\n    # ------------------------------------------------------------------\n    # print final test metrics\n    test_swa, test_cwa, test_hwa = spr[\"metrics\"][\"test\"]\n    print(\n        f\"Test Metrics  ->  SWA={test_swa:.4f}  CWA={test_cwa:.4f}  HWA={test_hwa:.4f}\"\n    )\n\n    # ------------------------------------------------------------------\n    # Plot 1: Loss curves\n    try:\n        plt.figure()\n        plt.plot(spr[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(spr[\"losses\"][\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Plot 2: Metric curves\n    try:\n        epochs = range(1, len(spr[\"metrics\"][\"train\"]) + 1)\n        train_metrics = np.array(spr[\"metrics\"][\"train\"])  # shape [E, 3]\n        val_metrics = np.array(spr[\"metrics\"][\"val\"])\n        labels = [\"SWA\", \"CWA\", \"HWA\"]\n        plt.figure()\n        for i, lab in enumerate(labels):\n            plt.plot(epochs, train_metrics[:, i], label=f\"Train-{lab}\")\n            plt.plot(epochs, val_metrics[:, i], label=f\"Val-{lab}\", linestyle=\"--\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(\n            \"SPR_BENCH Accuracy Metrics Over Epochs\\nSolid: Train, Dashed: Validation\"\n        )\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_metric_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric curve: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Plot 3: Ground truth vs Predictions distribution\n    try:\n        gt = np.array(spr[\"ground_truth\"])\n        pred = np.array(spr[\"predictions\"])\n        labels_sorted = sorted(list(set(gt) | set(pred)))\n        gt_counts = [np.sum(gt == l) for l in labels_sorted]\n        pred_counts = [np.sum(pred == l) for l in labels_sorted]\n\n        x = np.arange(len(labels_sorted))\n        width = 0.35\n        plt.figure(figsize=(10, 4))\n        plt.bar(x - width / 2, gt_counts, width, label=\"Ground Truth\")\n        plt.bar(x + width / 2, pred_counts, width, label=\"Predictions\")\n        plt.xticks(x, labels_sorted, rotation=45, ha=\"right\")\n        plt.ylabel(\"Count\")\n        plt.title(\"SPR_BENCH Label Distribution\\nLeft: Ground Truth, Right: Predicted\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_bench_label_distribution.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating label distribution plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    spr = experiment_data[\"spr_bench\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    spr = None\n\nif spr is not None:\n    losses_tr = spr[\"losses\"][\"train\"]\n    losses_val = spr[\"losses\"][\"val\"]\n    metrics_tr = np.array(spr[\"metrics\"][\"train\"])  # shape (E,3)\n    metrics_val = np.array(spr[\"metrics\"][\"val\"])\n    test_metrics = spr[\"metrics\"][\"test\"]  # (SWA,CWA,HWA)\n    y_true = np.array(spr[\"ground_truth\"])\n    y_pred = np.array(spr[\"predictions\"])\n\n    # ---------- 1) loss curve ----------\n    try:\n        plt.figure()\n        plt.plot(losses_tr, label=\"Train\")\n        plt.plot(losses_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH: Train vs Validation Loss\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"spr_bench_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # ---------- 2) metric curves ----------\n    try:\n        epochs = range(1, len(metrics_tr) + 1)\n        labels = [\"SWA\", \"CWA\", \"HWA\"]\n        plt.figure()\n        for i, lab in enumerate(labels):\n            plt.plot(epochs, metrics_tr[:, i], \"--\", label=f\"Train {lab}\")\n            plt.plot(epochs, metrics_val[:, i], \"-\", label=f\"Val {lab}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH: Weighted Accuracy Curves\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"spr_bench_metric_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric curves: {e}\")\n        plt.close()\n\n    # ---------- 3) test metric bar chart ----------\n    try:\n        plt.figure()\n        x = np.arange(3)\n        plt.bar(x, test_metrics, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n        plt.xticks(x, [\"SWA\", \"CWA\", \"HWA\"])\n        plt.ylim(0, 1)\n        plt.title(\"SPR_BENCH Test Weighted Accuracies\")\n        for i, v in enumerate(test_metrics):\n            plt.text(i, v + 0.02, f\"{v:.3f}\", ha=\"center\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"spr_bench_test_metrics.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar chart: {e}\")\n        plt.close()\n\n    # ---------- 4) confusion matrix ----------\n    try:\n        unique_labels = sorted(set(y_true) | set(y_pred))\n        label_to_idx = {l: i for i, l in enumerate(unique_labels)}\n        cm = np.zeros((len(unique_labels), len(unique_labels)), dtype=int)\n        for t, p in zip(y_true, y_pred):\n            cm[label_to_idx[t], label_to_idx[p]] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im, fraction=0.046, pad=0.04)\n        plt.xticks(range(len(unique_labels)), unique_labels, rotation=45, ha=\"right\")\n        plt.yticks(range(len(unique_labels)), unique_labels)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR_BENCH: Confusion Matrix\")\n        for i in range(cm.shape[0]):\n            for j in range(cm.shape[1]):\n                plt.text(\n                    j,\n                    i,\n                    cm[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                    fontsize=7,\n                )\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"spr_bench_confusion_matrix.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\n    # ---------- console output ----------\n    print(f\"Test metrics (SWA, CWA, HWA): {test_metrics}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    data = experiment_data[\"SPR_BENCH\"]\nexcept Exception as e:\n    raise RuntimeError(f\"Error loading experiment data: {e}\")\n\nepochs = data.get(\"epochs\", [])\ntrain_losses = data.get(\"losses\", {}).get(\"train\", [])\nval_losses = data.get(\"losses\", {}).get(\"val\", [])\nval_metrics = data.get(\"metrics\", {}).get(\"val\", [])\ntest_metrics = data.get(\"metrics\", {}).get(\"test\", {})\n\n\n# Helper to pull metric series safely\ndef metric_series(metric_name):\n    return [m.get(metric_name, np.nan) for m in val_metrics] if val_metrics else []\n\n\n# ----------------------------- FIGURE 1 -----------------------------------\ntry:\n    plt.figure()\n    plt.plot(epochs, train_losses, label=\"Train Loss\")\n    plt.plot(epochs, val_losses, label=\"Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"spr_bench_loss_curve.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# ----------------------------- FIGURE 2 -----------------------------------\ntry:\n    hwa_vals = metric_series(\"hwa\")\n    if hwa_vals:\n        plt.figure()\n        plt.plot(epochs, hwa_vals, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HWA\")\n        plt.title(\"SPR_BENCH: Validation HWA Across Epochs\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"spr_bench_hwa_curve.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curve: {e}\")\n    plt.close()\n\n# ----------------------------- FIGURE 3 -----------------------------------\ntry:\n    swa_vals, cwa_vals = metric_series(\"swa\"), metric_series(\"cwa\")\n    if swa_vals and cwa_vals:\n        plt.figure()\n        plt.plot(epochs, swa_vals, label=\"SWA\")\n        plt.plot(epochs, cwa_vals, label=\"CWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Metric Value\")\n        plt.title(\"SPR_BENCH: Validation SWA and CWA Across Epochs\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"spr_bench_swa_cwa_curve.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA/CWA curve: {e}\")\n    plt.close()\n\n# ----------------------------- FIGURE 4 -----------------------------------\ntry:\n    if test_metrics:\n        plt.figure()\n        names, vals = zip(*test_metrics.items())\n        plt.bar(names, vals, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n        plt.ylim(0, 1)\n        plt.title(\"SPR_BENCH: Test Metrics (SWA, CWA, HWA)\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"spr_bench_test_metrics_bar.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metrics bar: {e}\")\n    plt.close()\n\n# ----------------------------- PRINT METRICS ------------------------------\nif test_metrics:\n    print(\"Final Test Metrics:\", test_metrics)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nspr_data = experiment_data.get(\"spr_bench\", {})\n\n\n# Helper to extract series safely\ndef get_series(key1, key2):\n    return spr_data.get(key1, {}).get(key2, [])\n\n\n# 1) Loss curve ---------------------------------------------------------------\ntry:\n    train_loss = get_series(\"losses\", \"train\")\n    val_loss = get_series(\"losses\", \"val\")\n    if train_loss and val_loss:\n        plt.figure()\n        epochs = range(1, len(train_loss) + 1)\n        plt.plot(epochs, train_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH: Train vs Val Loss\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_bench_loss_curve.png\")\n        plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# 2) Metric curves ------------------------------------------------------------\ntry:\n    tr_metrics = get_series(\"metrics\", \"train\")  # list of (SWA,CWA,HWA)\n    va_metrics = get_series(\"metrics\", \"val\")\n    if tr_metrics and va_metrics:\n        tr_metrics = np.array(tr_metrics)  # shape [E,3]\n        va_metrics = np.array(va_metrics)\n        epochs = range(1, len(tr_metrics) + 1)\n        plt.figure(figsize=(6, 4))\n        labels = [\"SWA\", \"CWA\", \"HWA\"]\n        for i, lbl in enumerate(labels):\n            plt.plot(epochs, tr_metrics[:, i], label=f\"Train {lbl}\")\n            plt.plot(epochs, va_metrics[:, i], linestyle=\"--\", label=f\"Val {lbl}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.title(\"SPR_BENCH: Train/Val Metric Curves\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_bench_metric_curves.png\")\n        plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating metric curves: {e}\")\n    plt.close()\n\n# 3) Final test metrics -------------------------------------------------------\ntry:\n    test_metric = spr_data.get(\"metrics\", {}).get(\"test\", None)  # tuple (SWA,CWA,HWA)\n    if test_metric:\n        plt.figure()\n        labels = [\"SWA\", \"CWA\", \"HWA\"]\n        plt.bar(labels, test_metric, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n        plt.ylim(0, 1)\n        for i, v in enumerate(test_metric):\n            plt.text(i, v + 0.02, f\"{v:.3f}\", ha=\"center\")\n        plt.title(\"SPR_BENCH: Final Test Metrics\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_bench_test_metrics.png\")\n        plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metric bar plot: {e}\")\n    plt.close()\n\n# Print test metrics to console\nif test_metric:\n    print(\n        f\"Test metrics -> SWA: {test_metric[0]:.4f}, CWA: {test_metric[1]:.4f}, HWA: {test_metric[2]:.4f}\"\n    )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    spr = experiment_data[\"spr_bench\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    spr = None\n\nif spr is not None:\n    # ------------------------------------------------------------------\n    # print final test metrics\n    test_swa, test_cwa, test_hwa = spr[\"metrics\"][\"test\"]\n    print(\n        f\"Test Metrics  ->  SWA={test_swa:.4f}  CWA={test_cwa:.4f}  HWA={test_hwa:.4f}\"\n    )\n\n    # ------------------------------------------------------------------\n    # Plot 1: Loss curves\n    try:\n        plt.figure()\n        plt.plot(spr[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(spr[\"losses\"][\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Plot 2: Metric curves\n    try:\n        epochs = range(1, len(spr[\"metrics\"][\"train\"]) + 1)\n        train_metrics = np.array(spr[\"metrics\"][\"train\"])  # shape [E, 3]\n        val_metrics = np.array(spr[\"metrics\"][\"val\"])\n        labels = [\"SWA\", \"CWA\", \"HWA\"]\n        plt.figure()\n        for i, lab in enumerate(labels):\n            plt.plot(epochs, train_metrics[:, i], label=f\"Train-{lab}\")\n            plt.plot(epochs, val_metrics[:, i], label=f\"Val-{lab}\", linestyle=\"--\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(\n            \"SPR_BENCH Accuracy Metrics Over Epochs\\nSolid: Train, Dashed: Validation\"\n        )\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_metric_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric curve: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Plot 3: Ground truth vs Predictions distribution\n    try:\n        gt = np.array(spr[\"ground_truth\"])\n        pred = np.array(spr[\"predictions\"])\n        labels_sorted = sorted(list(set(gt) | set(pred)))\n        gt_counts = [np.sum(gt == l) for l in labels_sorted]\n        pred_counts = [np.sum(pred == l) for l in labels_sorted]\n\n        x = np.arange(len(labels_sorted))\n        width = 0.35\n        plt.figure(figsize=(10, 4))\n        plt.bar(x - width / 2, gt_counts, width, label=\"Ground Truth\")\n        plt.bar(x + width / 2, pred_counts, width, label=\"Predictions\")\n        plt.xticks(x, labels_sorted, rotation=45, ha=\"right\")\n        plt.ylabel(\"Count\")\n        plt.title(\"SPR_BENCH Label Distribution\\nLeft: Ground Truth, Right: Predicted\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_bench_label_distribution.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating label distribution plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    spr = experiment_data[\"spr_bench\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    spr = None\n\nif spr is not None:\n    # ------------------------------------------------------------------\n    # print final test metrics\n    test_swa, test_cwa, test_hwa = spr[\"metrics\"][\"test\"]\n    print(\n        f\"Test Metrics  ->  SWA={test_swa:.4f}  CWA={test_cwa:.4f}  HWA={test_hwa:.4f}\"\n    )\n\n    # ------------------------------------------------------------------\n    # Plot 1: Loss curves\n    try:\n        plt.figure()\n        plt.plot(spr[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(spr[\"losses\"][\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Plot 2: Metric curves\n    try:\n        epochs = range(1, len(spr[\"metrics\"][\"train\"]) + 1)\n        train_metrics = np.array(spr[\"metrics\"][\"train\"])  # shape [E, 3]\n        val_metrics = np.array(spr[\"metrics\"][\"val\"])\n        labels = [\"SWA\", \"CWA\", \"HWA\"]\n        plt.figure()\n        for i, lab in enumerate(labels):\n            plt.plot(epochs, train_metrics[:, i], label=f\"Train-{lab}\")\n            plt.plot(epochs, val_metrics[:, i], label=f\"Val-{lab}\", linestyle=\"--\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(\n            \"SPR_BENCH Accuracy Metrics Over Epochs\\nSolid: Train, Dashed: Validation\"\n        )\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_metric_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric curve: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Plot 3: Ground truth vs Predictions distribution\n    try:\n        gt = np.array(spr[\"ground_truth\"])\n        pred = np.array(spr[\"predictions\"])\n        labels_sorted = sorted(list(set(gt) | set(pred)))\n        gt_counts = [np.sum(gt == l) for l in labels_sorted]\n        pred_counts = [np.sum(pred == l) for l in labels_sorted]\n\n        x = np.arange(len(labels_sorted))\n        width = 0.35\n        plt.figure(figsize=(10, 4))\n        plt.bar(x - width / 2, gt_counts, width, label=\"Ground Truth\")\n        plt.bar(x + width / 2, pred_counts, width, label=\"Predictions\")\n        plt.xticks(x, labels_sorted, rotation=45, ha=\"right\")\n        plt.ylabel(\"Count\")\n        plt.title(\"SPR_BENCH Label Distribution\\nLeft: Ground Truth, Right: Predicted\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_bench_label_distribution.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating label distribution plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    spr = experiment_data[\"spr_bench\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    spr = None\n\nif spr is not None:\n    # ------------------------------------------------------------------\n    # print final test metrics\n    test_swa, test_cwa, test_hwa = spr[\"metrics\"][\"test\"]\n    print(\n        f\"Test Metrics  ->  SWA={test_swa:.4f}  CWA={test_cwa:.4f}  HWA={test_hwa:.4f}\"\n    )\n\n    # ------------------------------------------------------------------\n    # Plot 1: Loss curves\n    try:\n        plt.figure()\n        plt.plot(spr[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(spr[\"losses\"][\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Plot 2: Metric curves\n    try:\n        epochs = range(1, len(spr[\"metrics\"][\"train\"]) + 1)\n        train_metrics = np.array(spr[\"metrics\"][\"train\"])  # shape [E, 3]\n        val_metrics = np.array(spr[\"metrics\"][\"val\"])\n        labels = [\"SWA\", \"CWA\", \"HWA\"]\n        plt.figure()\n        for i, lab in enumerate(labels):\n            plt.plot(epochs, train_metrics[:, i], label=f\"Train-{lab}\")\n            plt.plot(epochs, val_metrics[:, i], label=f\"Val-{lab}\", linestyle=\"--\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(\n            \"SPR_BENCH Accuracy Metrics Over Epochs\\nSolid: Train, Dashed: Validation\"\n        )\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_metric_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric curve: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Plot 3: Ground truth vs Predictions distribution\n    try:\n        gt = np.array(spr[\"ground_truth\"])\n        pred = np.array(spr[\"predictions\"])\n        labels_sorted = sorted(list(set(gt) | set(pred)))\n        gt_counts = [np.sum(gt == l) for l in labels_sorted]\n        pred_counts = [np.sum(pred == l) for l in labels_sorted]\n\n        x = np.arange(len(labels_sorted))\n        width = 0.35\n        plt.figure(figsize=(10, 4))\n        plt.bar(x - width / 2, gt_counts, width, label=\"Ground Truth\")\n        plt.bar(x + width / 2, pred_counts, width, label=\"Predictions\")\n        plt.xticks(x, labels_sorted, rotation=45, ha=\"right\")\n        plt.ylabel(\"Count\")\n        plt.title(\"SPR_BENCH Label Distribution\\nLeft: Ground Truth, Right: Predicted\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_bench_label_distribution.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating label distribution plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\n# aggregate experiment data from multiple runs\nexperiment_data_path_list = [\n    \"experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_a1bd646e973a490ab38f7be4a1193535_proc_2808978/experiment_data.npy\",\n    \"experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_7edad94c3c494d23baa42b3e30f7cfd2_proc_2808980/experiment_data.npy\",\n    \"experiments/2025-08-15_02-34-04_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_6705e6a9051246f9891effaa9d34e8a5_proc_2808981/experiment_data.npy\",\n]\n\nall_spr_runs = []\nfor rel_path in experiment_data_path_list:\n    try:\n        load_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), rel_path)\n        data = np.load(load_path, allow_pickle=True).item()\n        if \"spr_bench\" in data:\n            all_spr_runs.append(data[\"spr_bench\"])\n        else:\n            print(f\"'spr_bench' key not found in {rel_path}\")\n    except Exception as e:\n        print(f\"Error loading {rel_path}: {e}\")\n\nif len(all_spr_runs) == 0:\n    print(\"No runs could be loaded \u2013 nothing to plot.\")\nelse:\n    n_runs = len(all_spr_runs)\n\n    # ------------------------------------------------------------------\n    # stack losses (truncate to min length so shapes match)\n    train_loss_min_len = min(len(run[\"losses\"][\"train\"]) for run in all_spr_runs)\n    val_loss_min_len = min(len(run[\"losses\"][\"val\"]) for run in all_spr_runs)\n    loss_epochs = np.arange(1, train_loss_min_len + 1)\n\n    train_losses = np.stack(\n        [\n            np.asarray(run[\"losses\"][\"train\"][:train_loss_min_len])\n            for run in all_spr_runs\n        ]\n    )  # [R, E]\n    val_losses = np.stack(\n        [np.asarray(run[\"losses\"][\"val\"][:val_loss_min_len]) for run in all_spr_runs]\n    )\n\n    train_loss_mean = train_losses.mean(axis=0)\n    train_loss_sem = train_losses.std(axis=0, ddof=1) / np.sqrt(n_runs)\n    val_loss_mean = val_losses.mean(axis=0)\n    val_loss_sem = val_losses.std(axis=0, ddof=1) / np.sqrt(n_runs)\n\n    # ------------------------------------------------------------------\n    # stack metrics (truncate to min length)\n    train_metric_min_len = min(len(run[\"metrics\"][\"train\"]) for run in all_spr_runs)\n    val_metric_min_len = min(len(run[\"metrics\"][\"val\"]) for run in all_spr_runs)\n    metric_epochs = np.arange(1, train_metric_min_len + 1)\n\n    train_metrics = np.stack(\n        [\n            np.asarray(run[\"metrics\"][\"train\"][:train_metric_min_len])\n            for run in all_spr_runs\n        ]\n    )  # [R, E, 3]\n    val_metrics = np.stack(\n        [np.asarray(run[\"metrics\"][\"val\"][:val_metric_min_len]) for run in all_spr_runs]\n    )\n\n    train_metric_mean = train_metrics.mean(axis=0)  # [E,3]\n    train_metric_sem = train_metrics.std(axis=0, ddof=1) / np.sqrt(n_runs)\n    val_metric_mean = val_metrics.mean(axis=0)\n    val_metric_sem = val_metrics.std(axis=0, ddof=1) / np.sqrt(n_runs)\n\n    # ------------------------------------------------------------------\n    # aggregate test metrics\n    test_metrics = np.stack(\n        [np.asarray(run[\"metrics\"][\"test\"]) for run in all_spr_runs]\n    )  # [R,3]\n    test_mean = test_metrics.mean(axis=0)\n    test_sem = test_metrics.std(axis=0, ddof=1) / np.sqrt(n_runs)\n    print(\n        f\"Aggregated Test Metrics (mean \u00b1 SEM)  ->  \"\n        f\"SWA={test_mean[0]:.4f}\u00b1{test_sem[0]:.4f}  \"\n        f\"CWA={test_mean[1]:.4f}\u00b1{test_sem[1]:.4f}  \"\n        f\"HWA={test_mean[2]:.4f}\u00b1{test_sem[2]:.4f}\"\n    )\n\n    # ------------------------------------------------------------------\n    # Plot 1: Aggregated loss curves\n    try:\n        plt.figure()\n        plt.plot(loss_epochs, train_loss_mean, label=\"Mean Train Loss\", color=\"blue\")\n        plt.fill_between(\n            loss_epochs,\n            train_loss_mean - train_loss_sem,\n            train_loss_mean + train_loss_sem,\n            color=\"blue\",\n            alpha=0.2,\n            label=\"Train SEM\",\n        )\n        plt.plot(loss_epochs, val_loss_mean, label=\"Mean Val Loss\", color=\"orange\")\n        plt.fill_between(\n            loss_epochs,\n            val_loss_mean - val_loss_sem,\n            val_loss_mean + val_loss_sem,\n            color=\"orange\",\n            alpha=0.2,\n            label=\"Val SEM\",\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH Aggregated Loss Curves\\nMean \u00b1 Standard Error Across Runs\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_loss_curves_agg.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated loss curve: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # Plot 2: Aggregated metric curves\n    try:\n        labels = [\"SWA\", \"CWA\", \"HWA\"]\n        colors = [\"green\", \"red\", \"purple\"]\n        plt.figure()\n        for i, (lab, col) in enumerate(zip(labels, colors)):\n            # Train line\n            plt.plot(\n                metric_epochs,\n                train_metric_mean[:, i],\n                label=f\"Train-{lab} Mean\",\n                color=col,\n            )\n            plt.fill_between(\n                metric_epochs,\n                train_metric_mean[:, i] - train_metric_sem[:, i],\n                train_metric_mean[:, i] + train_metric_sem[:, i],\n                color=col,\n                alpha=0.15,\n            )\n            # Val line (dashed)\n            plt.plot(\n                metric_epochs,\n                val_metric_mean[:, i],\n                label=f\"Val-{lab} Mean\",\n                color=col,\n                linestyle=\"--\",\n            )\n            plt.fill_between(\n                metric_epochs,\n                val_metric_mean[:, i] - val_metric_sem[:, i],\n                val_metric_mean[:, i] + val_metric_sem[:, i],\n                color=col,\n                alpha=0.15,\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(\n            \"SPR_BENCH Aggregated Accuracy Metrics\\n\"\n            \"Solid: Train, Dashed: Val | Shaded: \u00b1SEM\"\n        )\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_metric_curves_agg.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated metric curve: {e}\")\n        plt.close()\n"], "plot_plan": [null, null, null, null, "The code will begin by loading experiment_data.npy from the working directory and extracting the \u2018spr_bench\u2019 section. We will first compute and print the final test-set Shape-Weighted, Color-Weighted, and Harmonic accuracies that were stored during training. Three visualizations will be generated: (1) a loss curve comparing train and validation loss over epochs, (2) a metric curve showing the evolution of SWA, CWA, and HWA for both train and validation sets, and (3) a side-by-side bar chart comparing the distribution of ground-truth labels to the model\u2019s predictions on the test set. Each plot is wrapped in its own try-except block, saved with descriptive filenames in working_dir, given informative titles and subtitles, and the corresponding figure is closed after saving. The script follows all specified matplotlib conventions and avoids plotting nonexistent data. At most the three plots ensure clarity without redundancy. Finally, concise print statements confirm where the plots are saved and echo the key evaluation results to the console.", "We will first load experiment_data.npy from the working directory and extract the SPR Bench section. From this we obtain per-epoch losses (train/val), per-epoch metrics (shape/color/harmonic weighted accuracies), the final test metrics tuple, and the test set ground-truth and predicted labels. Four concise visualizations will be generated: \u2460 the train/validation loss curve, \u2461 the three weighted-accuracy curves for train/validation, \u2462 a bar chart summarising the three final test accuracies, and \u2463 a confusion-matrix style heat-map comparing test predictions to ground truth. Each figure is wrapped in a try-except block, saved with a descriptive name that includes the dataset tag, and then closed. We ensure that no more than these four figures are created, staying within the five-plot limit. Only data actually stored in experiment_data.npy is used\u2014no synthetic values are introduced. After plotting, the script prints the numeric test metrics so the user can verify them directly from stdout.", "We will load the serialized experiment_data.npy, extract losses and metrics for the SPR_BENCH dataset, and build up to four standard visualizations: (1) training vs validation loss across epochs, (2) validation HWA across epochs, (3) SWA and CWA across epochs, and (4) a bar chart of final test SWA/CWA/HWA. Each figure will be produced inside its own try-except block, saved into working_dir with descriptive names, and closed afterward. Titles will clearly state the dataset and what is being shown, and subtitles will clarify left/right or metric details when relevant. No synthetic data are introduced; we only plot what is present inside experiment_data.npy and limit ourselves to a maximum of four figures. After plotting, we print the final test metrics so the notebook/console shows the quantitative outcome alongside the saved plots. All matplotlib calls use default styling, and figures are spaced to avoid over-plotting. This concise script can be run in any environment once experiment_data.npy is available in working_dir.", "We load experiment_data.npy, pull out the per-epoch loss lists and metric tuples, then plot three separate figures: (1) train/validation loss curves; (2) train/validation curves for SWA, CWA and HWA in a single figure; (3) a bar chart comparing the three final test metrics. Each figure is wrapped in a try\u2013except so that a failure in one plot does not stop the rest, and every figure is saved to working_dir with descriptive names before being closed. All plotting is done with basic matplotlib defaults, and we never exceed five figures. After plotting, the script prints the final test metrics to the console so users can also read the values directly. Data is used exactly as stored\u2014no synthetic values or extrapolation. The whole routine is self-contained: it creates working_dir if absent, loads the .npy file, generates the figures, prints the metrics, and exits.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": [null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["", "", "", "", "The script will load the saved numpy dictionary, pull out the losses and (SWA,\nCWA, HWA) tuples, pick the final-epoch entry for the train/validation splits\n(the test split only has one entry), and print each value with an explicit\nlabel. Everything runs immediately on import and nothing is hidden behind a\nspecial entry point.", "The script will (1) locate the working directory, (2) load the stored NumPy\ndictionary, (3) pull out the lists of per-epoch losses and accuracy tuples, (4)\ndetermine the \u201cbest\u201d value for each metric (lowest loss, highest accuracies for\ntraining/validation; test is already single-shot), and (5) print the results in\na clearly labeled, human-readable form that satisfies the formatting rules.\nEverything executes at top level\u2014no special entry-point blocks and no plots.", "Below is a concise script that loads the saved NumPy file, extracts the stored\ntraining, validation and test statistics, selects the final recorded value for\neach metric and prints them in a clear, labeled format. The code resides at\nglobal scope so it executes immediately when the file is run.", "The script below directly loads the saved experiment_data.npy file from the\n\u201cworking\u201d directory, extracts the final loss and accuracy-style metrics recorded\nfor the training, validation, and test splits, and prints them with explicit,\nself-descriptive names.  It assumes the structure produced by the original\ntraining script: lists of per-epoch values for \u201ctrain\u201d and \u201cval,\u201d and a single\ntuple for \u201ctest.\u201d  The code runs immediately on execution and produces no plots.\nSimply place it in the same environment where the working directory exists and\nrun it to view the summarized results.", "The script will load the saved numpy dictionary, pull out the losses and (SWA,\nCWA, HWA) tuples, pick the final-epoch entry for the train/validation splits\n(the test split only has one entry), and print each value with an explicit\nlabel. Everything runs immediately on import and nothing is hidden behind a\nspecial entry point.", "The script will load the saved numpy dictionary, pull out the losses and (SWA,\nCWA, HWA) tuples, pick the final-epoch entry for the train/validation splits\n(the test split only has one entry), and print each value with an explicit\nlabel. Everything runs immediately on import and nothing is hidden behind a\nspecial entry point.", "The script will load the saved numpy dictionary, pull out the losses and (SWA,\nCWA, HWA) tuples, pick the final-epoch entry for the train/validation splits\n(the test split only has one entry), and print each value with an explicit\nlabel. Everything runs immediately on import and nothing is hidden behind a\nspecial entry point.", ""], "parse_metrics_code": ["", "", "", "", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# Helper to print a metric with clear naming\ndef print_metric(ds_name: str, metric_name: str, value: float):\n    print(f\"{ds_name} - {metric_name}: {value:.4f}\")\n\n\n# ------------------------------------------------------------------\n# Iterate over all datasets stored in the experiment dictionary\nfor ds_name, ds_dict in experiment_data.items():\n    print(f\"\\nDataset: {ds_name}\")\n\n    # ---------- losses ----------\n    train_loss_final = (\n        ds_dict[\"losses\"][\"train\"][-1] if ds_dict[\"losses\"][\"train\"] else None\n    )\n    val_loss_final = ds_dict[\"losses\"][\"val\"][-1] if ds_dict[\"losses\"][\"val\"] else None\n    test_loss = ds_dict[\"losses\"][\"test\"]\n\n    if train_loss_final is not None:\n        print_metric(ds_name, \"train loss (final epoch)\", train_loss_final)\n    if val_loss_final is not None:\n        print_metric(ds_name, \"validation loss (final epoch)\", val_loss_final)\n    if test_loss is not None:\n        print_metric(ds_name, \"test loss\", test_loss)\n\n    # ---------- accuracy-style metrics ----------\n    metric_names = [\n        \"Shape-Weighted Accuracy\",\n        \"Color-Weighted Accuracy\",\n        \"Harmonic-Weighted Accuracy\",\n    ]\n\n    if ds_dict[\"metrics\"][\"train\"]:\n        train_final = ds_dict[\"metrics\"][\"train\"][-1]  # (SWA, CWA, HWA)\n        for name, val in zip(metric_names, train_final):\n            print_metric(ds_name, f\"train {name} (final epoch)\", val)\n\n    if ds_dict[\"metrics\"][\"val\"]:\n        val_final = ds_dict[\"metrics\"][\"val\"][-1]\n        for name, val in zip(metric_names, val_final):\n            print_metric(ds_name, f\"validation {name} (final epoch)\", val)\n\n    test_metrics = ds_dict[\"metrics\"][\"test\"]\n    if test_metrics is not None:\n        for name, val in zip(metric_names, test_metrics):\n            print_metric(ds_name, f\"test {name}\", val)\n", "import os\nimport numpy as np\n\n# -------------------- locate saved file --------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy in {working_dir}\")\n\n# -------------------- load data --------------------\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# We assume the only key is \"spr_bench\" as produced by the training script\nbench_data = experiment_data[\"spr_bench\"]\ntrain_losses = bench_data[\"losses\"][\"train\"]  # list[float]\nval_losses = bench_data[\"losses\"][\"val\"]  # list[float]\ntest_loss = bench_data[\"losses\"][\"test\"]  # float\n\ntrain_metrics = bench_data[\"metrics\"][\"train\"]  # list[tuple]  (swa,cwa,hwa)\nval_metrics = bench_data[\"metrics\"][\"val\"]  # list[tuple]\ntest_metrics = bench_data[\"metrics\"][\"test\"]  # single tuple\n\n# Helper to pick best index: min loss, max accuracies\nbest_train_idx = int(np.argmin(train_losses))  # lowest loss\nbest_val_idx = int(np.argmax([m[2] for m in val_metrics]))  # highest HWA on val\n\n# -------------------- PRINT RESULTS --------------------\n# TRAINING SET\nprint(\"TRAINING SET:\")\nprint(f\"  best training loss: {train_losses[best_train_idx]:.4f}\")\nprint(\n    f\"  best training shape-weighted accuracy:    {train_metrics[best_train_idx][0]:.4f}\"\n)\nprint(\n    f\"  best training color-weighted accuracy:    {train_metrics[best_train_idx][1]:.4f}\"\n)\nprint(\n    f\"  best training harmonic-weighted accuracy: {train_metrics[best_train_idx][2]:.4f}\"\n)\n\n# VALIDATION SET\nprint(\"\\nVALIDATION SET:\")\nprint(f\"  best validation loss: {val_losses[best_val_idx]:.4f}\")\nprint(\n    f\"  best validation shape-weighted accuracy:    {val_metrics[best_val_idx][0]:.4f}\"\n)\nprint(\n    f\"  best validation color-weighted accuracy:    {val_metrics[best_val_idx][1]:.4f}\"\n)\nprint(\n    f\"  best validation harmonic-weighted accuracy: {val_metrics[best_val_idx][2]:.4f}\"\n)\n\n# TEST SET\nprint(\"\\nTEST SET:\")\nprint(f\"  final test loss: {test_loss:.4f}\")\nprint(f\"  final test shape-weighted accuracy:    {test_metrics[0]:.4f}\")\nprint(f\"  final test color-weighted accuracy:    {test_metrics[1]:.4f}\")\nprint(f\"  final test harmonic-weighted accuracy: {test_metrics[2]:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------- locate and load file ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\nspr_data = experiment_data[\"SPR_BENCH\"]  # convenience alias\n\n\n# ---------------- helper: fetch last entry ------------\ndef last(lst, default=None):\n    return lst[-1] if lst else default\n\n\n# ---------------- TRAINING METRICS --------------------\nprint(\"TRAINING DATASET\")\nfinal_train_loss = last(spr_data[\"losses\"][\"train\"], float(\"nan\"))\nprint(f\"final training loss: {final_train_loss:.4f}\")\n\n# ---------------- VALIDATION METRICS ------------------\nprint(\"\\nVALIDATION DATASET\")\nfinal_val_loss = last(spr_data[\"losses\"][\"val\"], float(\"nan\"))\nprint(f\"final validation loss: {final_val_loss:.4f}\")\n\nval_metrics_list = spr_data[\"metrics\"].get(\"val\", [])\nfinal_val_metrics = last(val_metrics_list, {})\nif final_val_metrics:\n    print(\n        f\"final validation shape weighted accuracy: {final_val_metrics.get('swa', float('nan')):.4f}\"\n    )\n    print(\n        f\"final validation color  weighted accuracy: {final_val_metrics.get('cwa', float('nan')):.4f}\"\n    )\n    print(\n        f\"final validation harmonic weighted accuracy: {final_val_metrics.get('hwa', float('nan')):.4f}\"\n    )\n\n# ---------------- TEST METRICS ------------------------\nprint(\"\\nTEST DATASET\")\ntest_metrics = spr_data[\"metrics\"].get(\"test\", {})\nif test_metrics:\n    print(f\"test shape weighted accuracy: {test_metrics.get('swa', float('nan')):.4f}\")\n    print(f\"test color  weighted accuracy: {test_metrics.get('cwa', float('nan')):.4f}\")\n    print(\n        f\"test harmonic weighted accuracy: {test_metrics.get('hwa', float('nan')):.4f}\"\n    )\n", "import os\nimport numpy as np\n\n# -------- locate saved results --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\nbench = experiment_data[\"spr_bench\"]\n\n\n# -------- helper to print nicely --------\ndef report_split(name, loss_value, metric_tuple):\n    swa, cwa, hwa = metric_tuple\n    print(f\"{name}:\")\n    print(f\"  {name.lower()} loss: {loss_value:.4f}\")\n    print(f\"  {name.lower()} shape-weighted accuracy (SWA): {swa:.4f}\")\n    print(f\"  {name.lower()} color-weighted accuracy (CWA): {cwa:.4f}\")\n    print(f\"  {name.lower()} harmonic-weighted accuracy (HWA): {hwa:.4f}\")\n    print()\n\n\n# -------- extract final / best values --------\n# For train and validation we take the final epoch values\ntrain_loss_final = bench[\"losses\"][\"train\"][-1]\nval_loss_final = bench[\"losses\"][\"val\"][-1]\n\ntrain_metric_final = bench[\"metrics\"][\"train\"][-1]  # (swa, cwa, hwa)\nval_metric_final = bench[\"metrics\"][\"val\"][-1]\n\n# Test already stored as a single value/tuple\ntest_loss_final = bench[\"losses\"][\"test\"]\ntest_metric_final = bench[\"metrics\"][\"test\"]\n\n# -------- print results --------\nreport_split(\"Training set\", train_loss_final, train_metric_final)\nreport_split(\"Validation set\", val_loss_final, val_metric_final)\nreport_split(\"Test set\", test_loss_final, test_metric_final)\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# Helper to print a metric with clear naming\ndef print_metric(ds_name: str, metric_name: str, value: float):\n    print(f\"{ds_name} - {metric_name}: {value:.4f}\")\n\n\n# ------------------------------------------------------------------\n# Iterate over all datasets stored in the experiment dictionary\nfor ds_name, ds_dict in experiment_data.items():\n    print(f\"\\nDataset: {ds_name}\")\n\n    # ---------- losses ----------\n    train_loss_final = (\n        ds_dict[\"losses\"][\"train\"][-1] if ds_dict[\"losses\"][\"train\"] else None\n    )\n    val_loss_final = ds_dict[\"losses\"][\"val\"][-1] if ds_dict[\"losses\"][\"val\"] else None\n    test_loss = ds_dict[\"losses\"][\"test\"]\n\n    if train_loss_final is not None:\n        print_metric(ds_name, \"train loss (final epoch)\", train_loss_final)\n    if val_loss_final is not None:\n        print_metric(ds_name, \"validation loss (final epoch)\", val_loss_final)\n    if test_loss is not None:\n        print_metric(ds_name, \"test loss\", test_loss)\n\n    # ---------- accuracy-style metrics ----------\n    metric_names = [\n        \"Shape-Weighted Accuracy\",\n        \"Color-Weighted Accuracy\",\n        \"Harmonic-Weighted Accuracy\",\n    ]\n\n    if ds_dict[\"metrics\"][\"train\"]:\n        train_final = ds_dict[\"metrics\"][\"train\"][-1]  # (SWA, CWA, HWA)\n        for name, val in zip(metric_names, train_final):\n            print_metric(ds_name, f\"train {name} (final epoch)\", val)\n\n    if ds_dict[\"metrics\"][\"val\"]:\n        val_final = ds_dict[\"metrics\"][\"val\"][-1]\n        for name, val in zip(metric_names, val_final):\n            print_metric(ds_name, f\"validation {name} (final epoch)\", val)\n\n    test_metrics = ds_dict[\"metrics\"][\"test\"]\n    if test_metrics is not None:\n        for name, val in zip(metric_names, test_metrics):\n            print_metric(ds_name, f\"test {name}\", val)\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# Helper to print a metric with clear naming\ndef print_metric(ds_name: str, metric_name: str, value: float):\n    print(f\"{ds_name} - {metric_name}: {value:.4f}\")\n\n\n# ------------------------------------------------------------------\n# Iterate over all datasets stored in the experiment dictionary\nfor ds_name, ds_dict in experiment_data.items():\n    print(f\"\\nDataset: {ds_name}\")\n\n    # ---------- losses ----------\n    train_loss_final = (\n        ds_dict[\"losses\"][\"train\"][-1] if ds_dict[\"losses\"][\"train\"] else None\n    )\n    val_loss_final = ds_dict[\"losses\"][\"val\"][-1] if ds_dict[\"losses\"][\"val\"] else None\n    test_loss = ds_dict[\"losses\"][\"test\"]\n\n    if train_loss_final is not None:\n        print_metric(ds_name, \"train loss (final epoch)\", train_loss_final)\n    if val_loss_final is not None:\n        print_metric(ds_name, \"validation loss (final epoch)\", val_loss_final)\n    if test_loss is not None:\n        print_metric(ds_name, \"test loss\", test_loss)\n\n    # ---------- accuracy-style metrics ----------\n    metric_names = [\n        \"Shape-Weighted Accuracy\",\n        \"Color-Weighted Accuracy\",\n        \"Harmonic-Weighted Accuracy\",\n    ]\n\n    if ds_dict[\"metrics\"][\"train\"]:\n        train_final = ds_dict[\"metrics\"][\"train\"][-1]  # (SWA, CWA, HWA)\n        for name, val in zip(metric_names, train_final):\n            print_metric(ds_name, f\"train {name} (final epoch)\", val)\n\n    if ds_dict[\"metrics\"][\"val\"]:\n        val_final = ds_dict[\"metrics\"][\"val\"][-1]\n        for name, val in zip(metric_names, val_final):\n            print_metric(ds_name, f\"validation {name} (final epoch)\", val)\n\n    test_metrics = ds_dict[\"metrics\"][\"test\"]\n    if test_metrics is not None:\n        for name, val in zip(metric_names, test_metrics):\n            print_metric(ds_name, f\"test {name}\", val)\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# Helper to print a metric with clear naming\ndef print_metric(ds_name: str, metric_name: str, value: float):\n    print(f\"{ds_name} - {metric_name}: {value:.4f}\")\n\n\n# ------------------------------------------------------------------\n# Iterate over all datasets stored in the experiment dictionary\nfor ds_name, ds_dict in experiment_data.items():\n    print(f\"\\nDataset: {ds_name}\")\n\n    # ---------- losses ----------\n    train_loss_final = (\n        ds_dict[\"losses\"][\"train\"][-1] if ds_dict[\"losses\"][\"train\"] else None\n    )\n    val_loss_final = ds_dict[\"losses\"][\"val\"][-1] if ds_dict[\"losses\"][\"val\"] else None\n    test_loss = ds_dict[\"losses\"][\"test\"]\n\n    if train_loss_final is not None:\n        print_metric(ds_name, \"train loss (final epoch)\", train_loss_final)\n    if val_loss_final is not None:\n        print_metric(ds_name, \"validation loss (final epoch)\", val_loss_final)\n    if test_loss is not None:\n        print_metric(ds_name, \"test loss\", test_loss)\n\n    # ---------- accuracy-style metrics ----------\n    metric_names = [\n        \"Shape-Weighted Accuracy\",\n        \"Color-Weighted Accuracy\",\n        \"Harmonic-Weighted Accuracy\",\n    ]\n\n    if ds_dict[\"metrics\"][\"train\"]:\n        train_final = ds_dict[\"metrics\"][\"train\"][-1]  # (SWA, CWA, HWA)\n        for name, val in zip(metric_names, train_final):\n            print_metric(ds_name, f\"train {name} (final epoch)\", val)\n\n    if ds_dict[\"metrics\"][\"val\"]:\n        val_final = ds_dict[\"metrics\"][\"val\"][-1]\n        for name, val in zip(metric_names, val_final):\n            print_metric(ds_name, f\"validation {name} (final epoch)\", val)\n\n    test_metrics = ds_dict[\"metrics\"][\"test\"]\n    if test_metrics is not None:\n        for name, val in zip(metric_names, test_metrics):\n            print_metric(ds_name, f\"test {name}\", val)\n", ""], "parse_term_out": ["", "", "", "", "['\\nDataset: spr_bench', '\\n', 'spr_bench - train loss (final epoch): 0.0953',\n'\\n', 'spr_bench - validation loss (final epoch): 0.0845', '\\n', 'spr_bench -\ntest loss: 1.6290', '\\n', 'spr_bench - train Shape-Weighted Accuracy (final\nepoch): 0.9736', '\\n', 'spr_bench - train Color-Weighted Accuracy (final epoch):\n0.9735', '\\n', 'spr_bench - train Harmonic-Weighted Accuracy (final epoch):\n0.9736', '\\n', 'spr_bench - validation Shape-Weighted Accuracy (final epoch):\n0.9795', '\\n', 'spr_bench - validation Color-Weighted Accuracy (final epoch):\n0.9797', '\\n', 'spr_bench - validation Harmonic-Weighted Accuracy (final epoch):\n0.9796', '\\n', 'spr_bench - test Shape-Weighted Accuracy: 0.6454', '\\n',\n'spr_bench - test Color-Weighted Accuracy: 0.6913', '\\n', 'spr_bench - test\nHarmonic-Weighted Accuracy: 0.6676', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['TRAINING SET:', '\\n', '  best training loss: 0.0953', '\\n', '  best training\nshape-weighted accuracy:    0.9736', '\\n', '  best training color-weighted\naccuracy:    0.9735', '\\n', '  best training harmonic-weighted accuracy:\n0.9736', '\\n', '\\nVALIDATION SET:', '\\n', '  best validation loss: 0.0845',\n'\\n', '  best validation shape-weighted accuracy:    0.9795', '\\n', '  best\nvalidation color-weighted accuracy:    0.9797', '\\n', '  best validation\nharmonic-weighted accuracy: 0.9796', '\\n', '\\nTEST SET:', '\\n', '  final test\nloss: 1.6290', '\\n', '  final test shape-weighted accuracy:    0.6454', '\\n', '\nfinal test color-weighted accuracy:    0.6913', '\\n', '  final test harmonic-\nweighted accuracy: 0.6676', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['TRAINING DATASET', '\\n', 'final training loss: 0.6891', '\\n', '\\nVALIDATION\nDATASET', '\\n', 'final validation loss: 0.7240', '\\n', 'final validation shape\nweighted accuracy: 0.3716', '\\n', 'final validation color  weighted accuracy:\n0.3826', '\\n', 'final validation harmonic weighted accuracy: 0.3770', '\\n',\n'\\nTEST DATASET', '\\n', 'test shape weighted accuracy: 0.3758', '\\n', 'test\ncolor  weighted accuracy: 0.3894', '\\n', 'test harmonic weighted accuracy:\n0.3825', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Training set:', '\\n', '  training set loss: 0.0953', '\\n', '  training set\nshape-weighted accuracy (SWA): 0.9736', '\\n', '  training set color-weighted\naccuracy (CWA): 0.9735', '\\n', '  training set harmonic-weighted accuracy (HWA):\n0.9736', '\\n', '\\n', 'Validation set:', '\\n', '  validation set loss: 0.0845',\n'\\n', '  validation set shape-weighted accuracy (SWA): 0.9795', '\\n', '\nvalidation set color-weighted accuracy (CWA): 0.9797', '\\n', '  validation set\nharmonic-weighted accuracy (HWA): 0.9796', '\\n', '\\n', 'Test set:', '\\n', '\ntest set loss: 1.6290', '\\n', '  test set shape-weighted accuracy (SWA):\n0.6454', '\\n', '  test set color-weighted accuracy (CWA): 0.6913', '\\n', '  test\nset harmonic-weighted accuracy (HWA): 0.6676', '\\n', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['\\nDataset: spr_bench', '\\n', 'spr_bench - train loss (final epoch): 0.1153',\n'\\n', 'spr_bench - validation loss (final epoch): 0.1083', '\\n', 'spr_bench -\ntest loss: 1.4609', '\\n', 'spr_bench - train Shape-Weighted Accuracy (final\nepoch): 0.9672', '\\n', 'spr_bench - train Color-Weighted Accuracy (final epoch):\n0.9664', '\\n', 'spr_bench - train Harmonic-Weighted Accuracy (final epoch):\n0.9668', '\\n', 'spr_bench - validation Shape-Weighted Accuracy (final epoch):\n0.9706', '\\n', 'spr_bench - validation Color-Weighted Accuracy (final epoch):\n0.9694', '\\n', 'spr_bench - validation Harmonic-Weighted Accuracy (final epoch):\n0.9700', '\\n', 'spr_bench - test Shape-Weighted Accuracy: 0.6430', '\\n',\n'spr_bench - test Color-Weighted Accuracy: 0.6870', '\\n', 'spr_bench - test\nHarmonic-Weighted Accuracy: 0.6643', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['\\nDataset: spr_bench', '\\n', 'spr_bench - train loss (final epoch): 0.1223',\n'\\n', 'spr_bench - validation loss (final epoch): 0.1185', '\\n', 'spr_bench -\ntest loss: 1.6345', '\\n', 'spr_bench - train Shape-Weighted Accuracy (final\nepoch): 0.9650', '\\n', 'spr_bench - train Color-Weighted Accuracy (final epoch):\n0.9634', '\\n', 'spr_bench - train Harmonic-Weighted Accuracy (final epoch):\n0.9642', '\\n', 'spr_bench - validation Shape-Weighted Accuracy (final epoch):\n0.9646', '\\n', 'spr_bench - validation Color-Weighted Accuracy (final epoch):\n0.9627', '\\n', 'spr_bench - validation Harmonic-Weighted Accuracy (final epoch):\n0.9637', '\\n', 'spr_bench - test Shape-Weighted Accuracy: 0.6385', '\\n',\n'spr_bench - test Color-Weighted Accuracy: 0.6823', '\\n', 'spr_bench - test\nHarmonic-Weighted Accuracy: 0.6597', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['\\nDataset: spr_bench', '\\n', 'spr_bench - train loss (final epoch): 0.1229',\n'\\n', 'spr_bench - validation loss (final epoch): 0.1213', '\\n', 'spr_bench -\ntest loss: 1.6401', '\\n', 'spr_bench - train Shape-Weighted Accuracy (final\nepoch): 0.9638', '\\n', 'spr_bench - train Color-Weighted Accuracy (final epoch):\n0.9624', '\\n', 'spr_bench - train Harmonic-Weighted Accuracy (final epoch):\n0.9631', '\\n', 'spr_bench - validation Shape-Weighted Accuracy (final epoch):\n0.9612', '\\n', 'spr_bench - validation Color-Weighted Accuracy (final epoch):\n0.9593', '\\n', 'spr_bench - validation Harmonic-Weighted Accuracy (final epoch):\n0.9603', '\\n', 'spr_bench - test Shape-Weighted Accuracy: 0.6386', '\\n',\n'spr_bench - test Color-Weighted Accuracy: 0.6819', '\\n', 'spr_bench - test\nHarmonic-Weighted Accuracy: 0.6596', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
