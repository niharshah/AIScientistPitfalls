<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 6], [0, 2], [0, 5], [0, 3], [0, 4], [0, 1], [0, 7], [0, 8], [8, 9], [8, 11], [8, 12], [8, 10]], "layout": [[0.4117647058823529, 0.0], [0.0, 0.5], [0.11764705882352941, 0.5], [0.23529411764705882, 0.5], [0.35294117647058826, 0.5], [0.47058823529411764, 0.5], [0.5882352941176471, 0.5], [0.7058823529411765, 0.5], [0.8235294117647058, 0.5], [0.6470588235294118, 1.0], [0.7647058823529411, 1.0], [0.8823529411764706, 1.0], [1.0, 1.0]], "plan": ["We switch from the earlier Bi-GRU baseline to a lightweight Transformer encoder\nthat can model long-range, multi-factor symbolic dependencies more naturally.\nEach symbol is embedded, enriched with sinusoidal positional encodings, and\nprocessed by 2 self-attention layers; the mean of non-pad outputs is passed to a\nclassifier.  We explore two dropout rates (0.1 / 0.3) and train for a few epochs\non a (potentially down-sampled) training set to stay within run-time limits.\nDuring training we record per-epoch loss, macro-F1, and the required Matthews\nCorrelation Coefficient (MCC); we print validation loss each epoch, pick the\nbest dev MCC model, and finally report test scores.  All metrics, losses,\npredictions and labels are stored in experiment_data and saved to\n./working/experiment_data.npy, while loss curves are saved as PNGs.  This\nprovides a stronger, attention-based baseline and the extra MCC analysis\ndemanded by the guidelines.", "Ablation name: Remove Positional Encoding (No-PE). The solution adds a boolean\nflag to the Transformer that controls whether sinusoidal positional encodings\nare added. Two runs are executed on the same SPR dataset: the baseline \u201cwith-PE\u201d\nand the ablation \u201cno-PE\u201d. Training/validation MCC and losses are logged, the\nbest model for each variant is evaluated on the test set, curves are plotted,\nand everything is stored in an experiment_data dictionary (saved as\nexperiment_data.npy). The rest of the pipeline (data loading, training loop,\nevaluation, plotting) remains unchanged.", "Ablation name: No-Transformer / Bag-of-Embeddings. The solution re-uses the\noriginal training pipeline, adds a light-weight Bag-of-Embeddings model that\nreplaces the Transformer encoder with simple mean pooling, and records all\nresults in the same format for fair comparison. Two dropout settings (0.1, 0.3)\nare explored for both models, the best checkpoint (by dev MCC) is evaluated on\nthe test set, curves are plotted, and every plottable artifact is stored in\n`experiment_data.npy`.", "Ablation name: Max-Pool Aggregation (Mean\u2192Max). Below is a compact re-\nimplementation of the original experiment where the sequence summarisation is\nchanged from length-normalised mean to element-wise max pooling. All results are\nlogged under the ablation tag \u201cmax_pool\u201d and saved to experiment_data.npy\nexactly as requested.", "Ablation name: No-PadMask (Disable Padding Mask). The script below reproduces\nthe baseline pipeline but realises the No-PadMask ablation: whenever the\nTransformer encoder is called, src_key_padding_mask is set to None, allowing\nattention over PAD tokens. All other components (data, training loop, pooling\nthat still ignores PAD tokens when averaging, logging, plotting, saving) remain\nunchanged. Results are stored under experiment_data['no_padmask']['spr'] and\nwritten to experiment_data.npy.", "Ablation name: Multi-Synthetic Dataset Training. We will create three\nindependent synthetic SPR datasets, each produced by a distinct latent labeling\nrule (rule-1: even \u201cA\u201d & last\u2208{B,C}; rule-2: most-frequent char == \u2018D\u2019; rule-3:\nlast\u2208{A,B}).   All three training splits are concatenated to form a single\n\u201ccombined\u201d corpus used to train the same Transformer that the baseline employs.\nValidation is done on the combined dev set to choose the best checkpoint, after\nwhich we compute MCC/F1 on every held-out split (rule-1, rule-2, rule-3)\nseparately to detect rule-specific over-fitting.   Per-dataset metrics, losses,\npredictions and ground-truth are stored in the hierarchical experiment_data\nstructure and written to experiment_data.npy; a loss curve for the combined\ncorpus is also saved.", "Ablation name: Learned Positional Embedding (Sinusoidal \u2192 Learned). Below is the\ncomplete script.   It trains two Transformer variants that are identical except\nfor how they encode absolute position: (1) the original fixed sinusoidal table\nand (2) a learned positional-embedding table.   Both variants are trained with\ntwo dropout settings, the best checkpoint for each is selected on the dev set,\nand final results are reported and stored in a unified experiment_data\nstructure.", "Ablation name: No-FFN (Attention-Only Transformer). Below is a compact\nimplementation that introduces a custom `NoFFNEncoderLayer`, identical to the\nPyTorch encoder layer except that the position-wise feed-forward block is\nreplaced by an identity mapping (residual, layer-norms and dropout kept).  All\nhyper-parameters, data handling, training loop, logging and saving follow the\noriginal baseline, thereby isolating the effect of removing the FFN sub-layer.", "Ablation name: No-LayerNorm (Remove all Layer Normalization). We replicate the\noriginal training/evaluation pipeline but introduce a custom\nTransformerEncoderLayerNoLN in which both LayerNorms are replaced by identity\n(i.e., removed). A CharTransformerNoLN model is built from these layers and\ntrained on SPR with two dropout settings. During training we log losses / MCC,\nkeep the best\u2010dev checkpoint, evaluate on the test set, plot loss curves, and\nsave every piece of plottable information in the required experiment_data.npy\nfile. The script is fully self-contained and executable.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, random, math, time\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.metrics import f1_score, matthews_corrcoef\nimport matplotlib.pyplot as plt\n\n# -------- working dir & device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------- SPR loading -----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _ld(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = _ld(\"train.csv\"), _ld(\"dev.csv\"), _ld(\"test.csv\")\n    return d\n\n\ndef get_spr() -> DatasetDict:\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(\"Loading real SPR_BENCH from\", p)\n            return load_spr_bench(p)\n\n    # synthetic fallback if real data absent\n    print(\"SPR_BENCH not found, generating synthetic toy data\")\n\n    def synth(n):\n        rows, shapes = \"ABCD\"\n        data = []\n        for i in range(n):\n            seq = \"\".join(random.choices(shapes, k=random.randint(5, 15)))\n            lbl = int(\n                seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\"\n            )  # slightly harder rule\n            data.append({\"id\": i, \"sequence\": seq, \"label\": lbl})\n        return load_dataset(\n            \"json\", data_files={\"data\": data}, field=\"data\", split=\"train\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = synth(4000), synth(1000), synth(1000)\n    return d\n\n\nspr = get_spr()\n\n# ------------- vocab & encoding --------------\nall_text = \"\".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text))\nstoi = {ch: i + 1 for i, ch in enumerate(vocab)}  # 0 = PAD\nitos = {i: ch for ch, i in enumerate([\"<PAD>\"] + vocab)}\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, spr[\"train\"][\"sequence\"])))\n\n\ndef encode(seq: str):\n    ids = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return ids + [0] * (max_len - len(ids))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.labels[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(name, bs=128, shuffle=False, max_items=None):\n    ds = SPRDataset(spr[name])\n    if max_items and len(ds) > max_items:\n        ids = torch.randperm(len(ds))[:max_items]\n        ds = Subset(ds, ids)\n    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n\n\n# Sub-sample to keep runtime reasonable on large data\ntrain_loader = lambda: make_loader(\"train\", shuffle=True, max_items=10000)\ndev_loader = lambda: make_loader(\"dev\", shuffle=False, max_items=2000)\ntest_loader = lambda: make_loader(\"test\", shuffle=False)\n\n\n# ---------- sinusoidal positional encoding ----------\ndef positional_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)  # (1, seq, d)\n\n\n# ---------- Transformer model -------------\nclass CharTransformer(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=4 * d_model,\n            dropout=dropout,\n            batch_first=True,\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.fc = nn.Linear(d_model, 1)\n        self.register_buffer(\n            \"pe\", positional_encoding(max_len, d_model, torch.device(\"cpu\"))\n        )\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        mask = x == 0\n        h = self.emb(x) + self.pe[:, : x.size(1), :].to(x.device)\n        h = self.encoder(h, src_key_padding_mask=mask)\n        # mean over non-pad tokens\n        lengths = (~mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled = (h.masked_fill(mask.unsqueeze(2), 0.0).sum(1)) / lengths\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\n# ---------- experiment setup ----------\nexperiment_data = {\n    \"transformer\": {\n        \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\ndropouts = [0.1, 0.3]\nbest_dev_mcc = -1\nbest_state = None\ncriterion = nn.BCEWithLogitsLoss()\nepochs = 6\n\nfor dp in dropouts:\n    print(f\"\\n=== Dropout {dp} ===\")\n    model = CharTransformer(\n        vocab_size, d_model=128, nhead=4, num_layers=2, dropout=dp\n    ).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    for epoch in range(1, epochs + 1):\n        # train\n        model.train()\n        tr_losses, tr_preds, tr_labels = [], [], []\n        for batch in train_loader():\n            batch = {\n                k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer.step()\n            tr_losses.append(loss.item())\n            tr_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            tr_labels.extend(batch[\"label\"].cpu().numpy())\n        train_mcc = matthews_corrcoef(tr_labels, tr_preds)\n\n        # validation\n        model.eval()\n        val_losses, val_preds, val_labels = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader():\n                batch = {\n                    k: v.to(device)\n                    for k, v in batch.items()\n                    if isinstance(v, torch.Tensor)\n                }\n                logits = model(batch[\"input_ids\"])\n                val_losses.append(criterion(logits, batch[\"label\"]).item())\n                val_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                val_labels.extend(batch[\"label\"].cpu().numpy())\n        val_mcc = matthews_corrcoef(val_labels, val_preds)\n        print(\n            f\"Epoch {epoch}: validation_loss = {np.mean(val_losses):.4f} | train_MCC={train_mcc:.3f} val_MCC={val_mcc:.3f}\"\n        )\n\n        # store\n        experiment_data[\"transformer\"][\"metrics\"][\"train_MCC\"].append(train_mcc)\n        experiment_data[\"transformer\"][\"metrics\"][\"val_MCC\"].append(val_mcc)\n        experiment_data[\"transformer\"][\"losses\"][\"train\"].append(np.mean(tr_losses))\n        experiment_data[\"transformer\"][\"losses\"][\"val\"].append(np.mean(val_losses))\n        experiment_data[\"transformer\"][\"epochs\"].append((dp, epoch))\n\n        # keep best\n        if val_mcc > best_dev_mcc:\n            best_dev_mcc = val_mcc\n            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n            best_dp = dp\n\n# ---------- test with best model ----------\nprint(\n    f\"\\nBest dev MCC={best_dev_mcc:.3f} (dropout={best_dp}). Evaluating on test set...\"\n)\nbest_model = CharTransformer(\n    vocab_size, d_model=128, nhead=4, num_layers=2, dropout=best_dp\n).to(device)\nbest_model.load_state_dict(best_state)\nbest_model.eval()\ntest_preds, test_labels = [], []\nwith torch.no_grad():\n    for batch in test_loader():\n        batch = {\n            k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)\n        }\n        logits = best_model(batch[\"input_ids\"])\n        test_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n        test_labels.extend(batch[\"label\"].cpu().numpy())\ntest_mcc = matthews_corrcoef(test_labels, test_preds)\ntest_f1 = f1_score(test_labels, test_preds, average=\"macro\")\nprint(f\"Test MCC={test_mcc:.3f} | Test Macro-F1={test_f1:.3f}\")\n\nexperiment_data[\"transformer\"][\"predictions\"] = test_preds\nexperiment_data[\"transformer\"][\"ground_truth\"] = test_labels\nexperiment_data[\"transformer\"][\"test_MCC\"] = test_mcc\nexperiment_data[\"transformer\"][\"test_F1\"] = test_f1\n\n# --------- plots ----------\nplt.figure(figsize=(6, 4))\nplt.plot(experiment_data[\"transformer\"][\"losses\"][\"train\"], label=\"train\")\nplt.plot(experiment_data[\"transformer\"][\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"update (epochs aggregated)\")\nplt.ylabel(\"BCE loss\")\nplt.legend()\nplt.title(\"Loss curve Transformer\")\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"loss_curve_transformer.png\"))\nplt.close()\n\n# -------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# -------- No-PE ablation study (single-file script) ----------\nimport os, pathlib, random, math, time\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.metrics import matthews_corrcoef, f1_score\nimport matplotlib.pyplot as plt\n\n# ---------- dir / device -----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- load (real or synthetic) SPR -----------\ndef _load_csv_dir(root: pathlib.Path) -> DatasetDict:\n    def _ld(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        {\"train\": _ld(\"train.csv\"), \"dev\": _ld(\"dev.csv\"), \"test\": _ld(\"test.csv\")}\n    )\n\n\ndef get_spr() -> DatasetDict:\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(\"Loading real SPR_BENCH from\", p)\n            return _load_csv_dir(p)\n\n    # ---------- synthetic fallback ----------\n    print(\"SPR_BENCH not found \u2013 generating synthetic toy data\")\n\n    def synth(n):\n        rows = \"ABCD\"\n        d = []\n        for i in range(n):\n            seq = \"\".join(random.choices(rows, k=random.randint(5, 15)))\n            lbl = int(seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\")\n            d.append({\"id\": i, \"sequence\": seq, \"label\": lbl})\n        return load_dataset(\"json\", data_files={\"data\": d}, field=\"data\", split=\"train\")\n\n    return DatasetDict({\"train\": synth(4000), \"dev\": synth(1000), \"test\": synth(1000)})\n\n\nspr = get_spr()\n\n# ---------- vocabulary / encoding ----------\nall_text = \"\".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text))\nstoi = {ch: i + 1 for i, ch in enumerate(vocab)}  # 0 = PAD\nitos = {i: ch for ch, i in enumerate([\"<PAD>\"] + vocab)}\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, spr[\"train\"][\"sequence\"])))\n\n\ndef encode(seq: str):\n    ids = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return ids + [0] * (max_len - len(ids))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.labels[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(name, bs=128, shuffle=False, max_items=None):\n    ds = SPRDataset(spr[name])\n    if max_items is not None and len(ds) > max_items:\n        ids = torch.randperm(len(ds))[:max_items]\n        ds = Subset(ds, ids)\n    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n\n\ntrain_loader = lambda: make_loader(\"train\", shuffle=True, max_items=10000)\ndev_loader = lambda: make_loader(\"dev\", shuffle=False, max_items=2000)\ntest_loader = lambda: make_loader(\"test\", shuffle=False)\n\n\n# ---------- positional encoding ----------\ndef positional_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)  # (1, seq, d)\n\n\n# ---------- Transformer (toggle PE) ----------\nclass CharTransformer(nn.Module):\n    def __init__(\n        self, vocab_size, d_model=128, nhead=4, num_layers=2, dropout=0.1, use_pe=True\n    ):\n        super().__init__()\n        self.use_pe = use_pe\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=4 * d_model,\n            dropout=dropout,\n            batch_first=True,\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n        self.fc = nn.Linear(d_model, 1)\n        self.register_buffer(\n            \"pe\", positional_encoding(max_len, d_model, torch.device(\"cpu\"))\n        )\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        mask = x == 0\n        h = self.emb(x)\n        if self.use_pe:\n            h = h + self.pe[:, : x.size(1), :].to(x.device)\n        h = self.encoder(h, src_key_padding_mask=mask)\n        # mean pooling over non-pad tokens\n        lengths = (~mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled = (h.masked_fill(mask.unsqueeze(2), 0.0).sum(1)) / lengths\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\n# ---------- experiment dict ----------\nexperiment_data = {\n    \"with_positional_encoding\": {\n        \"SPR\": {\n            \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    },\n    \"no_positional_encoding\": {\n        \"SPR\": {\n            \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    },\n}\n\n\n# ---------- run helper ----------\ndef run_experiment(use_pe: bool, tag: str, dropout=0.1, epochs=6, lr=1e-3):\n    crit = nn.BCEWithLogitsLoss()\n    model = CharTransformer(\n        vocab_size, d_model=128, nhead=4, num_layers=2, dropout=dropout, use_pe=use_pe\n    ).to(device)\n    opt = torch.optim.Adam(model.parameters(), lr=lr)\n    best_mcc, best_state, best_epoch = -1, None, 0\n\n    for ep in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        tr_loss, tr_preds, tr_lbls = [], [], []\n        for batch in train_loader():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            opt.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = crit(logits, batch[\"label\"])\n            loss.backward()\n            opt.step()\n            tr_loss.append(loss.item())\n            tr_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            tr_lbls.extend(batch[\"label\"].cpu().numpy())\n        train_mcc = matthews_corrcoef(tr_lbls, tr_preds)\n\n        # ---- val ----\n        model.eval()\n        val_loss, val_preds, val_lbls = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader():\n                batch = {k: v.to(device) for k, v in batch.items()}\n                logits = model(batch[\"input_ids\"])\n                val_loss.append(crit(logits, batch[\"label\"]).item())\n                val_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                val_lbls.extend(batch[\"label\"].cpu().numpy())\n        val_mcc = matthews_corrcoef(val_lbls, val_preds)\n        print(f\"[{tag}] Epoch {ep}: train_MCC={train_mcc:.3f} val_MCC={val_mcc:.3f}\")\n\n        # log\n        d = experiment_data[tag][\"SPR\"]\n        d[\"metrics\"][\"train_MCC\"].append(train_mcc)\n        d[\"metrics\"][\"val_MCC\"].append(val_mcc)\n        d[\"losses\"][\"train\"].append(np.mean(tr_loss))\n        d[\"losses\"][\"val\"].append(np.mean(val_loss))\n        d[\"epochs\"].append(ep)\n\n        if val_mcc > best_mcc:\n            best_mcc, best_epoch = val_mcc, ep\n            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n\n    print(f\"[{tag}] Best val_MCC={best_mcc:.3f} at epoch {best_epoch}\")\n    # ---- test best ----\n    best_model = CharTransformer(\n        vocab_size, d_model=128, nhead=4, num_layers=2, dropout=dropout, use_pe=use_pe\n    ).to(device)\n    best_model.load_state_dict(best_state)\n    best_model.eval()\n    preds, gts = [], []\n    with torch.no_grad():\n        for batch in test_loader():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            logits = best_model(batch[\"input_ids\"])\n            preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            gts.extend(batch[\"label\"].cpu().numpy())\n    test_mcc = matthews_corrcoef(gts, preds)\n    test_f1 = f1_score(gts, preds, average=\"macro\")\n    print(f\"[{tag}] Test MCC={test_mcc:.3f} | Test F1={test_f1:.3f}\")\n\n    d[\"predictions\"] = preds\n    d[\"ground_truth\"] = gts\n    d[\"test_MCC\"] = test_mcc\n    d[\"test_F1\"] = test_f1\n    return d\n\n\n# ---------- run both variants ----------\nwith_pe_data = run_experiment(use_pe=True, tag=\"with_positional_encoding\")\nno_pe_data = run_experiment(use_pe=False, tag=\"no_positional_encoding\")\n\n# ---------- plots ----------\nfor tag in experiment_data:\n    d = experiment_data[tag][\"SPR\"]\n    plt.figure(figsize=(6, 4))\n    plt.plot(d[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(d[\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"Loss curve ({tag})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"BCE loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f\"loss_{tag}.png\"))\n    plt.close()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, math, time, numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.metrics import f1_score, matthews_corrcoef\nimport matplotlib.pyplot as plt\n\n# ---------- working dir & device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- SPR data ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _ld(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = _ld(\"train.csv\"), _ld(\"dev.csv\"), _ld(\"test.csv\")\n    return d\n\n\ndef get_spr() -> DatasetDict:\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(\"Loading real SPR_BENCH from\", p)\n            return load_spr_bench(p)\n    print(\"SPR_BENCH not found \u2013 creating synthetic toy data\")\n\n    def synth(n):\n        rows, shapes = \"ABCD\"\n        data = []\n        for i in range(n):\n            seq = \"\".join(random.choices(shapes, k=random.randint(5, 15)))\n            lbl = int(seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\")\n            data.append({\"id\": i, \"sequence\": seq, \"label\": lbl})\n        return load_dataset(\n            \"json\", data_files={\"data\": data}, field=\"data\", split=\"train\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = synth(4000), synth(1000), synth(1000)\n    return d\n\n\nspr = get_spr()\n\n# ---------- vocab / encoding ----------\nall_text = \"\".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text))\nstoi = {ch: i + 1 for i, ch in enumerate(vocab)}  # 0 = PAD\nitos = {i: ch for i, ch in enumerate([\"<PAD>\"] + vocab)}\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, spr[\"train\"][\"sequence\"])))\n\n\ndef encode(seq: str):\n    ids = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return ids + [0] * (max_len - len(ids))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seq, self.lbl = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.seq)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seq[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.lbl[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(name, bs=128, shuffle=False, max_items=None):\n    ds = SPRDataset(spr[name])\n    if max_items and len(ds) > max_items:\n        idx = torch.randperm(len(ds))[:max_items]\n        ds = Subset(ds, idx)\n    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n\n\ntrain_loader = lambda: make_loader(\"train\", shuffle=True, max_items=10000)\ndev_loader = lambda: make_loader(\"dev\", shuffle=False, max_items=2000)\ntest_loader = lambda: make_loader(\"test\", shuffle=False)\n\n\n# ---------- positional encoding ----------\ndef positional_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)\n\n\n# ---------- models ----------\nclass CharTransformer(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        layer = nn.TransformerEncoderLayer(\n            d_model, nhead, 4 * d_model, dropout, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(layer, num_layers)\n        self.fc = nn.Linear(d_model, 1)\n        self.register_buffer(\n            \"pe\", positional_encoding(max_len, d_model, torch.device(\"cpu\"))\n        )\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        mask = x == 0\n        h = self.emb(x) + self.pe[:, : x.size(1), :].to(x.device)\n        h = self.encoder(h, src_key_padding_mask=mask)\n        lengths = (~mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled = h.masked_fill(mask.unsqueeze(2), 0.0).sum(1) / lengths\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\nclass BagOfEmbeddings(nn.Module):\n    def __init__(self, vocab_size, d_model=128, dropout=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        self.drop = nn.Dropout(dropout)\n        self.fc = nn.Linear(d_model, 1)\n\n    def forward(self, x):\n        mask = x != 0\n        h = self.drop(self.emb(x))\n        lengths = mask.sum(1).clamp(min=1).unsqueeze(1)\n        pooled = (h * mask.unsqueeze(2)).sum(1) / lengths\n        return self.fc(pooled).squeeze(1)\n\n\n# ---------- experiment container ----------\nexperiment_data = {\n    \"transformer\": {\n        \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    },\n    \"bag_of_embeddings\": {\n        \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    },\n}\n\ncriterion = nn.BCEWithLogitsLoss()\ndropouts = [0.1, 0.3]\nepochs = 6\n\n\ndef run_experiment(tag, ModelClass):\n    best_dev, best_state, best_dp = -1, None, None\n    for dp in dropouts:\n        print(f\"\\n=== {tag} | dropout {dp} ===\")\n        model = ModelClass(vocab_size, d_model=128, dropout=dp).to(device)\n        opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n        for ep in range(1, epochs + 1):\n            # train\n            model.train()\n            tr_losses, tr_preds, tr_labels = [], [], []\n            for batch in train_loader():\n                batch = {k: v.to(device) for k, v in batch.items()}\n                opt.zero_grad()\n                logit = model(batch[\"input_ids\"])\n                loss = criterion(logit, batch[\"label\"])\n                loss.backward()\n                opt.step()\n                tr_losses.append(loss.item())\n                tr_preds.extend((torch.sigmoid(logit) > 0.5).cpu().numpy())\n                tr_labels.extend(batch[\"label\"].cpu().numpy())\n            train_mcc = matthews_corrcoef(tr_labels, tr_preds)\n\n            # val\n            model.eval()\n            v_losses, v_preds, v_labels = [], [], []\n            with torch.no_grad():\n                for batch in dev_loader():\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    logit = model(batch[\"input_ids\"])\n                    v_losses.append(criterion(logit, batch[\"label\"]).item())\n                    v_preds.extend((torch.sigmoid(logit) > 0.5).cpu().numpy())\n                    v_labels.extend(batch[\"label\"].cpu().numpy())\n            val_mcc = matthews_corrcoef(v_labels, v_preds)\n            print(\n                f\"Epoch {ep}: val_loss={np.mean(v_losses):.4f} | train_MCC={train_mcc:.3f} val_MCC={val_mcc:.3f}\"\n            )\n\n            # record\n            experiment_data[tag][\"metrics\"][\"train_MCC\"].append(train_mcc)\n            experiment_data[tag][\"metrics\"][\"val_MCC\"].append(val_mcc)\n            experiment_data[tag][\"losses\"][\"train\"].append(np.mean(tr_losses))\n            experiment_data[tag][\"losses\"][\"val\"].append(np.mean(v_losses))\n            experiment_data[tag][\"epochs\"].append((dp, ep))\n\n            if val_mcc > best_dev:\n                best_dev, val_losses_best = val_mcc, np.mean(v_losses)\n                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n                best_dp = dp\n    # test\n    print(f\"\\nBest dev MCC for {tag} = {best_dev:.3f} (dropout={best_dp})\")\n    best_model = ModelClass(vocab_size, d_model=128, dropout=best_dp).to(device)\n    best_model.load_state_dict(best_state)\n    best_model.eval()\n    t_preds, t_labels = [], []\n    with torch.no_grad():\n        for batch in test_loader():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            logit = best_model(batch[\"input_ids\"])\n            t_preds.extend((torch.sigmoid(logit) > 0.5).cpu().numpy())\n            t_labels.extend(batch[\"label\"].cpu().numpy())\n    test_mcc = matthews_corrcoef(t_labels, t_preds)\n    test_f1 = f1_score(t_labels, t_preds, average=\"macro\")\n    print(f\"{tag} | Test MCC={test_mcc:.3f} | Test F1={test_f1:.3f}\")\n    experiment_data[tag][\"predictions\"] = t_preds\n    experiment_data[tag][\"ground_truth\"] = t_labels\n    experiment_data[tag][\"test_MCC\"] = test_mcc\n    experiment_data[tag][\"test_F1\"] = test_f1\n\n    # plot\n    plt.figure(figsize=(6, 4))\n    plt.plot(experiment_data[tag][\"losses\"][\"train\"], label=\"train\")\n    plt.plot(experiment_data[tag][\"losses\"][\"val\"], label=\"val\")\n    plt.xlabel(\"update (epochs aggregated)\")\n    plt.ylabel(\"BCE loss\")\n    plt.legend()\n    plt.title(f\"Loss curve {tag}\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_{tag}.png\"))\n    plt.close()\n\n\nrun_experiment(\"transformer\", CharTransformer)\nrun_experiment(\"bag_of_embeddings\", BagOfEmbeddings)\n\n# -------- save all ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All experiment data saved to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, math, time\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.metrics import matthews_corrcoef, f1_score\nimport matplotlib.pyplot as plt\n\n# ---------- dirs / device ----------\nwork_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(work_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"device:\", device)\n\n\n# ---------- load / build SPR_BENCH ----------\ndef _load_csv(p, name):\n    return load_dataset(\n        \"csv\", data_files=str(p / name), split=\"train\", cache_dir=\".cache_dsets\"\n    )\n\n\ndef load_real_spr():\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            return DatasetDict(\n                {s: _load_csv(p, f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]}\n            )\n    return None\n\n\nspr = load_real_spr()\nif spr is None:  # synthetic fallback\n    print(\"Real SPR_BENCH not found \u2013 creating toy data.\")\n\n    def synth(n):\n        rows = []\n        for i in range(n):\n            seq = \"\".join(random.choices(\"ABCD\", k=random.randint(5, 15)))\n            lbl = int(seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\")\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": lbl})\n        return load_dataset(\n            \"json\", data_files={\"data\": rows}, field=\"data\", split=\"train\"\n        )\n\n    spr = DatasetDict(\n        {s: synth(m) for s, m in zip([\"train\", \"dev\", \"test\"], [4000, 1000, 1000])}\n    )\n\n# ---------- vocab / encoding ----------\nall_chars = sorted(set(\"\".join(spr[\"train\"][\"sequence\"])))\nstoi = {ch: i + 1 for i, ch in enumerate(all_chars)}  # 0 = PAD\nitos = {i: ch for ch, i in enumerate([\"<PAD>\"] + all_chars)}\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, spr[\"train\"][\"sequence\"])))\n\n\ndef encode(seq):\n    ids = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return ids + [0] * (max_len - len(ids))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.labels[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(name, bs=128, shuffle=False, max_items=None):\n    ds = SPRDataset(spr[name])\n    if max_items and len(ds) > max_items:\n        ds = Subset(ds, torch.randperm(len(ds))[:max_items])\n    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n\n\ntrain_loader = lambda: make_loader(\"train\", shuffle=True, max_items=10000)\ndev_loader = lambda: make_loader(\"dev\", shuffle=False, max_items=2000)\ntest_loader = lambda: make_loader(\"test\", shuffle=False)\n\n\n# ---------- positional enc ----------\ndef positional_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)\n\n\n# ---------- Transformer w/ MAX pooling ----------\nclass CharTransformerMax(nn.Module):\n    def __init__(self, vocab, d_model=128, nhead=4, layers=2, drop=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, 4 * d_model, drop, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=layers)\n        self.fc = nn.Linear(d_model, 1)\n        self.register_buffer(\n            \"pe\", positional_encoding(max_len, d_model, torch.device(\"cpu\"))\n        )\n        self.drop = nn.Dropout(drop)\n\n    def forward(self, x):\n        mask = x == 0\n        h = self.emb(x) + self.pe[:, : x.size(1), :].to(x.device)\n        h = self.encoder(h, src_key_padding_mask=mask)\n        # element-wise max over sequence dim ignoring PADs\n        h_masked = h.masked_fill(mask.unsqueeze(2), -1e9)\n        pooled = h_masked.max(1).values\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\n# ---------- experiment container ----------\nexperiment_data = {\n    \"max_pool\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------- training loop ----------\ncriterion = nn.BCEWithLogitsLoss()\nepochs = 6\ndropouts = [0.1, 0.3]\nbest_val = -1\nbest_state = None\nbest_dp = None\nfor dp in dropouts:\n    print(f\"\\n=== Dropout={dp} ===\")\n    model = CharTransformerMax(vocab_size, drop=dp).to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n    for ep in range(1, epochs + 1):\n        # train\n        model.train()\n        tr_loss = []\n        tr_pred = []\n        tr_lbl = []\n        for batch in train_loader():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optim.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optim.step()\n            tr_loss.append(loss.item())\n            tr_pred.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            tr_lbl.extend(batch[\"label\"].cpu().numpy())\n        train_mcc = matthews_corrcoef(tr_lbl, tr_pred)\n        # val\n        model.eval()\n        v_loss = []\n        v_pred = []\n        v_lbl = []\n        with torch.no_grad():\n            for batch in dev_loader():\n                batch = {k: v.to(device) for k, v in batch.items()}\n                logits = model(batch[\"input_ids\"])\n                v_loss.append(criterion(logits, batch[\"label\"]).item())\n                v_pred.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                v_lbl.extend(batch[\"label\"].cpu().numpy())\n        val_mcc = matthews_corrcoef(v_lbl, v_pred)\n        print(\n            f\"Epoch {ep}: val_loss={np.mean(v_loss):.4f} | train_MCC={train_mcc:.3f} val_MCC={val_mcc:.3f}\"\n        )\n        # log\n        ed = experiment_data[\"max_pool\"][\"SPR_BENCH\"]\n        ed[\"metrics\"][\"train_MCC\"].append(train_mcc)\n        ed[\"metrics\"][\"val_MCC\"].append(val_mcc)\n        ed[\"losses\"][\"train\"].append(np.mean(tr_loss))\n        ed[\"losses\"][\"val\"].append(np.mean(v_loss))\n        ed[\"epochs\"].append((dp, ep))\n        # best\n        if val_mcc > best_val:\n            best_val = val_mcc\n            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n            best_dp = dp\n\n# ---------- evaluate best on test ----------\nprint(f\"\\nBest dev MCC={best_val:.3f} (dropout={best_dp}) \u2013 testing.\")\nbest_model = CharTransformerMax(vocab_size, drop=best_dp).to(device)\nbest_model.load_state_dict(best_state)\nbest_model.eval()\ntest_pred, test_lbl = [], []\nwith torch.no_grad():\n    for batch in test_loader():\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = best_model(batch[\"input_ids\"])\n        test_pred.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n        test_lbl.extend(batch[\"label\"].cpu().numpy())\ntest_mcc = matthews_corrcoef(test_lbl, test_pred)\ntest_f1 = f1_score(test_lbl, test_pred, average=\"macro\")\nprint(f\"Test MCC={test_mcc:.3f} | Test Macro-F1={test_f1:.3f}\")\n\ned = experiment_data[\"max_pool\"][\"SPR_BENCH\"]\ned[\"predictions\"] = test_pred\ned[\"ground_truth\"] = test_lbl\ned[\"test_MCC\"] = test_mcc\ned[\"test_F1\"] = test_f1\n\n# ---------- plots ----------\nplt.figure(figsize=(6, 4))\nplt.plot(ed[\"losses\"][\"train\"], label=\"train\")\nplt.plot(ed[\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"update (epochs aggregated)\")\nplt.ylabel(\"BCE loss\")\nplt.title(\"Loss curve \u2013 MAX pool\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(work_dir, \"loss_curve_max_pool.png\"))\nplt.close()\n\n# ---------- save ----------\nnp.save(os.path.join(work_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(work_dir, \"experiment_data.npy\"))\n", "# -------------- No-PadMask ablation : single-file runnable script --------------\nimport os, pathlib, random, math, time, numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.metrics import matthews_corrcoef, f1_score\nimport matplotlib.pyplot as plt\n\n# ------------------- misc -------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ------------------- SPR loading (unchanged) -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _ld(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = _ld(\"train.csv\"), _ld(\"dev.csv\"), _ld(\"test.csv\")\n    return d\n\n\ndef get_spr() -> DatasetDict:\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(\"Loading real SPR_BENCH from\", p)\n            return load_spr_bench(p)\n\n    print(\"SPR_BENCH not found, generating synthetic toy data\")\n\n    def synth(n):\n        rows, shapes = \"ABCD\"\n        data = []\n        for i in range(n):\n            seq = \"\".join(random.choices(shapes, k=random.randint(5, 15)))\n            lbl = int(seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\")\n            data.append({\"id\": i, \"sequence\": seq, \"label\": lbl})\n        return load_dataset(\n            \"json\", data_files={\"data\": data}, field=\"data\", split=\"train\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = synth(4000), synth(1000), synth(1000)\n    return d\n\n\nspr = get_spr()\n\n# ------------------- vocab -------------------\nall_text = \"\".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text))\nstoi = {ch: i + 1 for i, ch in enumerate(vocab)}  # 0 reserved for PAD\nitos = {i: ch for i, ch in enumerate([\"<PAD>\"] + vocab)}  # only for completeness\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, spr[\"train\"][\"sequence\"])))\n\n\ndef encode(seq: str):\n    ids = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return ids + [0] * (max_len - len(ids))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.labels[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(name, bs=128, shuffle=False, max_items=None):\n    ds = SPRDataset(spr[name])\n    if max_items and len(ds) > max_items:\n        ids = torch.randperm(len(ds))[:max_items]\n        ds = Subset(ds, ids)\n    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n\n\ntrain_loader = lambda: make_loader(\"train\", shuffle=True, max_items=10000)\ndev_loader = lambda: make_loader(\"dev\", shuffle=False, max_items=2000)\ntest_loader = lambda: make_loader(\"test\", shuffle=False)\n\n\n# ------------------- positional encoding -------------------\ndef positional_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)  # (1, seq, d)\n\n\n# ------------------- Transformer WITHOUT padding mask -------------------\nclass CharTransformer(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, 4 * d_model, dropout=dropout, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n        self.fc = nn.Linear(d_model, 1)\n        self.register_buffer(\n            \"pe\", positional_encoding(max_len, d_model, torch.device(\"cpu\"))\n        )\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):  # x : (B, L)\n        mask = x == 0  # still used for pooling\n        h = self.emb(x) + self.pe[:, : x.size(1)].to(x.device)\n        h = self.encoder(h, src_key_padding_mask=None)  #  <------------- key ablation\n        lengths = (~mask).sum(1).clamp(min=1).unsqueeze(1)  # avoid div/0\n        pooled = (h.masked_fill(mask.unsqueeze(2), 0).sum(1)) / lengths\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\n# ------------------- training & evaluation -------------------\nexperiment_data = {\n    \"no_padmask\": {\n        \"spr\": {\n            \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\ncriterion = nn.BCEWithLogitsLoss()\ndropouts = [0.1, 0.3]\nepochs = 6\nbest_dev_mcc, best_state, best_dp = -1, None, None\n\nfor dp in dropouts:\n    print(f\"\\n=== Dropout {dp} ===\")\n    model = CharTransformer(\n        vocab_size, d_model=128, nhead=4, num_layers=2, dropout=dp\n    ).to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for ep in range(1, epochs + 1):\n        # ------ train ------\n        model.train()\n        tr_losses, tr_preds, tr_lbls = [], [], []\n        for batch in train_loader():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optim.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optim.step()\n            tr_losses.append(loss.item())\n            tr_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            tr_lbls.extend(batch[\"label\"].cpu().numpy())\n        train_mcc = matthews_corrcoef(tr_lbls, tr_preds)\n\n        # ------ val ------\n        model.eval()\n        val_losses, val_preds, val_lbls = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader():\n                batch = {k: v.to(device) for k, v in batch.items()}\n                logits = model(batch[\"input_ids\"])\n                val_losses.append(criterion(logits, batch[\"label\"]).item())\n                val_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                val_lbls.extend(batch[\"label\"].cpu().numpy())\n        val_mcc = matthews_corrcoef(val_lbls, val_preds)\n        print(\n            f\"Epoch {ep}: val_loss={np.mean(val_losses):.4f} | train_MCC={train_mcc:.3f} val_MCC={val_mcc:.3f}\"\n        )\n\n        # log\n        ed = experiment_data[\"no_padmask\"][\"spr\"]\n        ed[\"metrics\"][\"train_MCC\"].append(train_mcc)\n        ed[\"metrics\"][\"val_MCC\"].append(val_mcc)\n        ed[\"losses\"][\"train\"].append(np.mean(tr_losses))\n        ed[\"losses\"][\"val\"].append(np.mean(val_losses))\n        ed[\"epochs\"].append((dp, ep))\n\n        # keep best\n        if val_mcc > best_dev_mcc:\n            best_dev_mcc, best_state, best_dp = (\n                val_mcc,\n                {k: v.cpu().clone() for k, v in model.state_dict().items()},\n                dp,\n            )\n\n# ------------------- test with best model -------------------\nprint(\n    f\"\\nBest dev MCC={best_dev_mcc:.3f} (dropout={best_dp}). Evaluating on test set...\"\n)\nbest_model = CharTransformer(\n    vocab_size, d_model=128, nhead=4, num_layers=2, dropout=best_dp\n).to(device)\nbest_model.load_state_dict(best_state)\nbest_model.eval()\ntest_preds, test_lbls = [], []\nwith torch.no_grad():\n    for batch in test_loader():\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = best_model(batch[\"input_ids\"])\n        test_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n        test_lbls.extend(batch[\"label\"].cpu().numpy())\n\ntest_mcc = matthews_corrcoef(test_lbls, test_preds)\ntest_f1 = f1_score(test_lbls, test_preds, average=\"macro\")\nprint(f\"Test MCC={test_mcc:.3f} | Test macro-F1={test_f1:.3f}\")\n\ned = experiment_data[\"no_padmask\"][\"spr\"]\ned[\"predictions\"], ed[\"ground_truth\"] = test_preds, test_lbls\ned[\"test_MCC\"], ed[\"test_F1\"] = test_mcc, test_f1\n\n# ------------------- plot & save -------------------\nplt.figure(figsize=(6, 4))\nplt.plot(ed[\"losses\"][\"train\"], label=\"train\")\nplt.plot(ed[\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"update (epochs aggregated)\")\nplt.ylabel(\"BCE loss\")\nplt.legend()\nplt.title(\"Loss curve (No-PadMask)\")\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"loss_curve_no_padmask.png\"))\nplt.close()\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, math, time, json, itertools\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict, concatenate_datasets\nfrom sklearn.metrics import matthews_corrcoef, f1_score\nimport matplotlib.pyplot as plt\n\n# ---------- misc ----------\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nprint(\"Using device:\", device)\n\n# ---------- three synthetic rules ----------\nSHAPES = \"ABCD\"\n\n\ndef gen_seq():\n    return \"\".join(random.choices(SHAPES, k=random.randint(5, 15)))\n\n\ndef rule1(seq):  # even #A and last in B/C\n    return int(seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\")\n\n\ndef rule2(seq):  # majority char is D\n    from collections import Counter\n\n    return int(Counter(seq).most_common(1)[0][0] == \"D\")\n\n\ndef rule3(seq):  # last char in A/B\n    return int(seq[-1] in \"AB\")\n\n\nRULE_FNS = [rule1, rule2, rule3]\nRULE_NAMES = [\"rule1\", \"rule2\", \"rule3\"]\n\n\ndef make_hf_dataset(rule_fn, n):\n    data = [\n        {\"id\": i, \"sequence\": gen_seq(), \"label\": rule_fn(s := gen_seq())}\n        for i in range(n)\n    ]\n    # need to use sequence that was evaluated\n    data = []\n    for i in range(n):\n        seq = gen_seq()\n        data.append({\"id\": i, \"sequence\": seq, \"label\": rule_fn(seq)})\n    return load_dataset(\"json\", data_files={\"data\": data}, field=\"data\", split=\"train\")\n\n\ndef synth_dataset_dict(rule_fn, n_train=4000, n_dev=1000, n_test=1000):\n    return DatasetDict(\n        {\n            \"train\": make_hf_dataset(rule_fn, n_train),\n            \"dev\": make_hf_dataset(rule_fn, n_dev),\n            \"test\": make_hf_dataset(rule_fn, n_test),\n        }\n    )\n\n\ndatasets_list = [synth_dataset_dict(fn) for fn in RULE_FNS]\n\n# ---------- combined corpus ----------\ncombined = DatasetDict(\n    {\n        \"train\": concatenate_datasets([d[\"train\"] for d in datasets_list]),\n        \"dev\": concatenate_datasets([d[\"dev\"] for d in datasets_list]),\n    }\n)\nprint(\"Combined train size:\", len(combined[\"train\"]))\n\n# ---------- vocab / encoding ----------\nall_text = \"\".join(combined[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text))\nstoi = {ch: i + 1 for i, ch in enumerate(vocab)}  # 0=PAD\nitos = {i: ch for ch, i in stoi.items()}\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, combined[\"train\"][\"sequence\"])))\n\n\ndef encode(seq):\n    ids = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return ids + [0] * (max_len - len(ids))\n\n\nclass CharDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs, self.labels = hf_split[\"sequence\"], hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.labels[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(hf_split, bs=128, shuffle=False):\n    return DataLoader(\n        CharDataset(hf_split), batch_size=bs, shuffle=shuffle, drop_last=False\n    )\n\n\ntrain_loader = lambda: make_loader(combined[\"train\"], shuffle=True)\ndev_loader = lambda: make_loader(combined[\"dev\"], shuffle=False)\n\n\n# ---------- model ----------\ndef positional_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)\n\n\nclass CharTransformer(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=4 * d_model,\n            dropout=dropout,\n            batch_first=True,\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n        self.fc = nn.Linear(d_model, 1)\n        self.register_buffer(\n            \"pe\", positional_encoding(max_len, d_model, torch.device(\"cpu\"))\n        )\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        mask = x == 0\n        h = self.emb(x) + self.pe[:, : x.size(1), :].to(x.device)\n        h = self.encoder(h, src_key_padding_mask=mask)\n        lengths = (~mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled = (h.masked_fill(mask.unsqueeze(2), 0.0).sum(1)) / lengths\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\n# ---------- training ----------\nexperiment_data = {\"multi_synth\": {}}\nfor name in RULE_NAMES + [\"combined\"]:\n    experiment_data[\"multi_synth\"][name] = {\n        \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\ndropouts = [0.1, 0.3]\nepochs = 6\ncriterion = nn.BCEWithLogitsLoss()\nbest_state, best_dev_mcc, best_dp = None, -1, None\n\nfor dp in dropouts:\n    print(f\"\\n=== Dropout {dp} ===\")\n    model = CharTransformer(vocab_size, dropout=dp).to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n    for ep in range(1, epochs + 1):\n        # train\n        model.train()\n        tr_losses, tr_preds, tr_labels = [], [], []\n        for batch in train_loader():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optim.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optim.step()\n            tr_losses.append(loss.item())\n            tr_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            tr_labels.extend(batch[\"label\"].cpu().numpy())\n        train_mcc = matthews_corrcoef(tr_labels, tr_preds)\n        # val on combined\n        model.eval()\n        val_losses, val_preds, val_labels = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader():\n                batch = {k: v.to(device) for k, v in batch.items()}\n                logits = model(batch[\"input_ids\"])\n                val_losses.append(criterion(logits, batch[\"label\"]).item())\n                val_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                val_labels.extend(batch[\"label\"].cpu().numpy())\n        val_mcc = matthews_corrcoef(val_labels, val_preds)\n        print(\n            f\"Epoch {ep}: loss {np.mean(val_losses):.4f} | train_MCC {train_mcc:.3f} val_MCC {val_mcc:.3f}\"\n        )\n        experiment_data[\"multi_synth\"][\"combined\"][\"metrics\"][\"train_MCC\"].append(\n            train_mcc\n        )\n        experiment_data[\"multi_synth\"][\"combined\"][\"metrics\"][\"val_MCC\"].append(val_mcc)\n        experiment_data[\"multi_synth\"][\"combined\"][\"losses\"][\"train\"].append(\n            np.mean(tr_losses)\n        )\n        experiment_data[\"multi_synth\"][\"combined\"][\"losses\"][\"val\"].append(\n            np.mean(val_losses)\n        )\n        if val_mcc > best_dev_mcc:\n            best_dev_mcc, best_state, best_dp = (\n                val_mcc,\n                {k: v.cpu() for k, v in model.state_dict().items()},\n                dp,\n            )\n\n# ---------- evaluation per dataset ----------\nbest_model = CharTransformer(vocab_size, dropout=best_dp).to(device)\nbest_model.load_state_dict(best_state)\nbest_model.eval()\n\n\ndef eval_dataset(hf_split):\n    preds, labels = [], []\n    with torch.no_grad():\n        for batch in make_loader(hf_split, shuffle=False):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            logits = best_model(batch[\"input_ids\"])\n            preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            labels.extend(batch[\"label\"].cpu().numpy())\n    mcc = matthews_corrcoef(labels, preds)\n    f1 = f1_score(labels, preds, average=\"macro\")\n    return mcc, f1, preds, labels\n\n\nfor name, ds in zip(RULE_NAMES, datasets_list):\n    mcc, f1, preds, labels = eval_dataset(ds[\"test\"])\n    experiment_data[\"multi_synth\"][name][\"predictions\"] = preds\n    experiment_data[\"multi_synth\"][name][\"ground_truth\"] = labels\n    experiment_data[\"multi_synth\"][name][\"test_MCC\"] = mcc\n    experiment_data[\"multi_synth\"][name][\"test_F1\"] = f1\n    print(f\"Test results {name}: MCC={mcc:.3f} F1={f1:.3f}\")\n\n# also store combined test (concat)\ncombined_test = concatenate_datasets([d[\"test\"] for d in datasets_list])\nmcc, f1, preds, labels = eval_dataset(combined_test)\nexperiment_data[\"multi_synth\"][\"combined\"][\"predictions\"] = preds\nexperiment_data[\"multi_synth\"][\"combined\"][\"ground_truth\"] = labels\nexperiment_data[\"multi_synth\"][\"combined\"][\"test_MCC\"] = mcc\nexperiment_data[\"multi_synth\"][\"combined\"][\"test_F1\"] = f1\nprint(f\"Combined test MCC={mcc:.3f} F1={f1:.3f}\")\n\n# ---------- plot ----------\nplt.figure(figsize=(6, 4))\nplt.plot(experiment_data[\"multi_synth\"][\"combined\"][\"losses\"][\"train\"], label=\"train\")\nplt.plot(experiment_data[\"multi_synth\"][\"combined\"][\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"BCE loss\")\nplt.legend()\nplt.title(\"Loss curve (combined)\")\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"loss_curve_multi_synth.png\"))\nplt.close()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, math, time, json\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.metrics import matthews_corrcoef, f1_score\nimport matplotlib.pyplot as plt\n\n# ---------- working dir & device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- SPR loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _ld(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = _ld(\"train.csv\"), _ld(\"dev.csv\"), _ld(\"test.csv\")\n    return d\n\n\ndef get_spr() -> DatasetDict:\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(\"Loading real SPR_BENCH from\", p)\n            return load_spr_bench(p)\n    # fallback synthetic\n    print(\"SPR_BENCH not found, generating synthetic toy data\")\n\n    def synth(n):\n        rows = \"ABCD\"\n        data = []\n        for i in range(n):\n            seq = \"\".join(random.choices(rows, k=random.randint(5, 15)))\n            lbl = int(seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\")\n            data.append({\"id\": i, \"sequence\": seq, \"label\": lbl})\n        return load_dataset(\n            \"json\", data_files={\"data\": data}, field=\"data\", split=\"train\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = synth(4000), synth(1000), synth(1000)\n    return d\n\n\nspr = get_spr()\n\n# ------------- vocab & encoding --------------\nall_text = \"\".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text))\nstoi = {ch: i + 1 for i, ch in enumerate(vocab)}  # 0 reserved for PAD\nitos = {i: ch for ch, i in enumerate([\"<PAD>\"] + vocab)}\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, spr[\"train\"][\"sequence\"])))\n\n\ndef encode(seq: str):\n    ids = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return ids + [0] * (max_len - len(ids))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.labels[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(name, bs=128, shuffle=False, max_items=None):\n    ds = SPRDataset(spr[name])\n    if max_items and len(ds) > max_items:\n        idx = torch.randperm(len(ds))[:max_items]\n        ds = Subset(ds, idx)\n    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n\n\ntrain_loader = lambda: make_loader(\"train\", shuffle=True, max_items=10000)\ndev_loader = lambda: make_loader(\"dev\", max_items=2000)\ntest_loader = lambda: make_loader(\"test\")\n\n\n# ---------- positional encoding helpers ----------\ndef sinusoidal_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)  # (1, seq, d)\n\n\n# ---------- model ----------\nclass CharTransformer(nn.Module):\n    def __init__(\n        self,\n        vocab_size,\n        d_model=128,\n        nhead=4,\n        num_layers=2,\n        dropout=0.1,\n        pe_type=\"sinusoidal\",\n    ):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        self.pe_type = pe_type\n        if pe_type == \"sinusoidal\":\n            self.register_buffer(\n                \"pe\", sinusoidal_encoding(max_len, d_model, torch.device(\"cpu\"))\n            )\n        else:  # learned positional embedding\n            self.pos_emb = nn.Embedding(max_len, d_model)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=4 * d_model,\n            dropout=dropout,\n            batch_first=True,\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n        self.fc = nn.Linear(d_model, 1)\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        mask = x.eq(0)\n        tok = self.emb(x)\n        if self.pe_type == \"sinusoidal\":\n            pos = self.pe[:, : x.size(1)].to(x.device)\n        else:\n            idx = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n            pos = self.pos_emb(idx)\n        h = tok + pos\n        h = self.encoder(h, src_key_padding_mask=mask)\n        lengths = (~mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled = (h.masked_fill(mask.unsqueeze(2), 0.0).sum(1)) / lengths\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\n# ---------- experiment setup ----------\nexperiment_data = {\n    \"positional_encoding\": {\n        \"sinusoidal\": {\n            \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"learned\": {\n            \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    }\n}\n\ncriterion = nn.BCEWithLogitsLoss()\ndropouts = [0.1, 0.3]\nepochs = 6\npe_variants = [\"sinusoidal\", \"learned\"]\n\nfor variant in pe_variants:\n    print(f\"\\n### Positional Encoding: {variant.upper()} ###\")\n    best_dev_mcc, best_state, best_dp = -1, None, None\n    for dp in dropouts:\n        print(f\"\\n--- Dropout {dp} ---\")\n        model = CharTransformer(\n            vocab_size, d_model=128, nhead=4, num_layers=2, dropout=dp, pe_type=variant\n        ).to(device)\n        optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n        for ep in range(1, epochs + 1):\n            # ----- train -----\n            model.train()\n            tr_losses, tr_preds, tr_lbls = [], [], []\n            for batch in train_loader():\n                batch = {k: v.to(device) for k, v in batch.items()}\n                optim.zero_grad()\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                loss.backward()\n                optim.step()\n                tr_losses.append(loss.item())\n                tr_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                tr_lbls.extend(batch[\"label\"].cpu().numpy())\n            train_mcc = matthews_corrcoef(tr_lbls, tr_preds)\n\n            # ----- validation -----\n            model.eval()\n            val_losses, val_preds, val_lbls = [], [], []\n            with torch.no_grad():\n                for batch in dev_loader():\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    logits = model(batch[\"input_ids\"])\n                    val_losses.append(criterion(logits, batch[\"label\"]).item())\n                    val_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                    val_lbls.extend(batch[\"label\"].cpu().numpy())\n            val_mcc = matthews_corrcoef(val_lbls, val_preds)\n            print(\n                f\"Epoch {ep}: val_loss={np.mean(val_losses):.4f} | \"\n                f\"train_MCC={train_mcc:.3f} val_MCC={val_mcc:.3f}\"\n            )\n\n            # record\n            exp = experiment_data[\"positional_encoding\"][variant]\n            exp[\"metrics\"][\"train_MCC\"].append(train_mcc)\n            exp[\"metrics\"][\"val_MCC\"].append(val_mcc)\n            exp[\"losses\"][\"train\"].append(np.mean(tr_losses))\n            exp[\"losses\"][\"val\"].append(np.mean(val_losses))\n            exp[\"epochs\"].append((dp, ep))\n\n            if val_mcc > best_dev_mcc:\n                best_dev_mcc = val_mcc\n                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n                best_dp = dp\n\n    # ---------- test best checkpoint ----------\n    print(\n        f\"\\nBest dev MCC for {variant}: {best_dev_mcc:.3f} (dropout={best_dp}). \"\n        \"Evaluating on test set...\"\n    )\n    best_model = CharTransformer(\n        vocab_size, d_model=128, nhead=4, num_layers=2, dropout=best_dp, pe_type=variant\n    ).to(device)\n    best_model.load_state_dict(best_state)\n    best_model.eval()\n    test_preds, test_lbls = [], []\n    with torch.no_grad():\n        for batch in test_loader():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            logits = best_model(batch[\"input_ids\"])\n            test_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            test_lbls.extend(batch[\"label\"].cpu().numpy())\n    test_mcc = matthews_corrcoef(test_lbls, test_preds)\n    test_f1 = f1_score(test_lbls, test_preds, average=\"macro\")\n    print(f\"Test MCC={test_mcc:.3f} | Test Macro-F1={test_f1:.3f}\")\n\n    exp = experiment_data[\"positional_encoding\"][variant]\n    exp[\"predictions\"] = test_preds\n    exp[\"ground_truth\"] = test_lbls\n    exp[\"test_MCC\"] = test_mcc\n    exp[\"test_F1\"] = test_f1\n\n    # ---------- plot ----------\n    plt.figure(figsize=(6, 4))\n    plt.plot(exp[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(exp[\"losses\"][\"val\"], label=\"val\")\n    plt.xlabel(\"update (epochs aggregated)\")\n    plt.ylabel(\"BCE loss\")\n    plt.title(f\"Loss curve ({variant})\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_{variant}.png\"))\n    plt.close()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, math, time\nimport numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.metrics import matthews_corrcoef, f1_score\nimport matplotlib.pyplot as plt\n\n# ---------- misc ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using\", device)\n\n\n# ---------- SPR loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _ld(csv):  # helper\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    dd = DatasetDict()\n    dd[\"train\"], dd[\"dev\"], dd[\"test\"] = (\n        _ld(\"train.csv\"),\n        _ld(\"dev.csv\"),\n        _ld(\"test.csv\"),\n    )\n    return dd\n\n\ndef get_spr() -> DatasetDict:\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(\"Loading real SPR_BENCH from\", p)\n            return load_spr_bench(p)\n    print(\"SPR_BENCH not found -> generating synthetic toy data\")\n\n    def synth(n):\n        rows = \"ABCD\"\n        data = []\n        for i in range(n):\n            seq = \"\".join(random.choices(rows, k=random.randint(5, 15)))\n            lbl = int(seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\")\n            data.append({\"id\": i, \"sequence\": seq, \"label\": lbl})\n        return load_dataset(\n            \"json\", data_files={\"data\": data}, field=\"data\", split=\"train\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = synth(4000), synth(1000), synth(1000)\n    return d\n\n\nspr = get_spr()\n\n# ---------- vocab ----------\nall_text = \"\".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text))\nstoi = {ch: i + 1 for i, ch in enumerate(vocab)}  # 0 pad\nitos = {i: ch for ch, i in stoi.items()}\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, spr[\"train\"][\"sequence\"])))\n\n\ndef encode(seq: str):\n    ids = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return ids + [0] * (max_len - len(ids))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.labels[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(name, bs=128, shuffle=False, max_items=None):\n    ds = SPRDataset(spr[name])\n    if max_items and len(ds) > max_items:\n        ids = torch.randperm(len(ds))[:max_items]\n        ds = Subset(ds, ids)\n    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n\n\ntrain_loader = lambda: make_loader(\"train\", shuffle=True, max_items=10000)\ndev_loader = lambda: make_loader(\"dev\", shuffle=False, max_items=2000)\ntest_loader = lambda: make_loader(\"test\", shuffle=False)\n\n\n# ---------- positional encoding ----------\ndef positional_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)  # (1,seq,d)\n\n\n# ---------- No-FFN encoder layer ----------\nclass NoFFNEncoderLayer(nn.Module):\n    def __init__(self, d_model, nhead, dropout=0.1):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(\n            d_model, nhead, dropout=dropout, batch_first=True\n        )\n        self.dropout1 = nn.Dropout(dropout)\n        self.norm1 = nn.LayerNorm(d_model)\n        # second sublayer: identity + norm, keep dropout & residual\n        self.dropout2 = nn.Dropout(dropout)\n        self.norm2 = nn.LayerNorm(d_model)\n\n    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n        # sub-layer 1: MHA\n        attn_out = self.self_attn(\n            src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask\n        )[0]\n        src = src + self.dropout1(attn_out)\n        src = self.norm1(src)\n        # sub-layer 2: identity\n        id_out = self.dropout2(src)  # optional dropout on the pass-through\n        src = src + id_out  # residual (effectively 1+dropout mask)\n        src = self.norm2(src)\n        return src\n\n\n# ---------- Transformer (attention-only) ----------\nclass CharTransformerNoFFN(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        layers = [NoFFNEncoderLayer(d_model, nhead, dropout) for _ in range(num_layers)]\n        self.encoder = nn.ModuleList(layers)\n        self.fc = nn.Linear(d_model, 1)\n        self.register_buffer(\n            \"pe\", positional_encoding(max_len, d_model, torch.device(\"cpu\"))\n        )\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        mask = x == 0  # pad mask\n        h = self.emb(x) + self.pe[:, : x.size(1), :].to(x.device)\n        for layer in self.encoder:\n            h = layer(h, src_key_padding_mask=mask)\n        lengths = (~mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled = (h.masked_fill(mask.unsqueeze(2), 0.0).sum(1)) / lengths\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\n# ---------- experiment dict ----------\nexperiment_data = {\n    \"no_ffn\": {\n        \"SPR\": {\n            \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------- training ----------\ndropouts = [0.1, 0.3]\nbest_dev_mcc = -1\nbest_state = None\ncriterion = nn.BCEWithLogitsLoss()\nepochs = 6\nfor dp in dropouts:\n    print(f\"\\n=== Dropout={dp} (No-FFN) ===\")\n    model = CharTransformerNoFFN(\n        vocab_size, d_model=128, nhead=4, num_layers=2, dropout=dp\n    ).to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n    for ep in range(1, epochs + 1):\n        # train\n        model.train()\n        tr_loss, tr_preds, tr_lbls = [], [], []\n        for batch in train_loader():\n            batch = {k: v.to(device) for k, v in batch.items() if torch.is_tensor(v)}\n            optim.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optim.step()\n            tr_loss.append(loss.item())\n            tr_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            tr_lbls.extend(batch[\"label\"].cpu().numpy())\n        train_mcc = matthews_corrcoef(tr_lbls, tr_preds)\n\n        # val\n        model.eval()\n        val_loss, val_preds, val_lbls = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader():\n                batch = {\n                    k: v.to(device) for k, v in batch.items() if torch.is_tensor(v)\n                }\n                logits = model(batch[\"input_ids\"])\n                val_loss.append(criterion(logits, batch[\"label\"]).item())\n                val_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                val_lbls.extend(batch[\"label\"].cpu().numpy())\n        val_mcc = matthews_corrcoef(val_lbls, val_preds)\n        print(\n            f\"Epoch {ep}: val_loss={np.mean(val_loss):.4f} | \"\n            f\"train_MCC={train_mcc:.3f} val_MCC={val_mcc:.3f}\"\n        )\n\n        # log\n        exp = experiment_data[\"no_ffn\"][\"SPR\"]\n        exp[\"metrics\"][\"train_MCC\"].append(train_mcc)\n        exp[\"metrics\"][\"val_MCC\"].append(val_mcc)\n        exp[\"losses\"][\"train\"].append(np.mean(tr_loss))\n        exp[\"losses\"][\"val\"].append(np.mean(val_loss))\n        exp[\"epochs\"].append((dp, ep))\n        if val_mcc > best_dev_mcc:\n            best_dev_mcc = val_mcc\n            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n            best_dp = dp\n\n# ---------- test ----------\nprint(f\"\\nBest dev MCC={best_dev_mcc:.3f} (dropout={best_dp}) -> Testing\")\nbest_model = CharTransformerNoFFN(vocab_size, 128, 4, 2, best_dp).to(device)\nbest_model.load_state_dict(best_state)\nbest_model.eval()\ntest_preds, test_lbls = [], []\nwith torch.no_grad():\n    for batch in test_loader():\n        batch = {k: v.to(device) for k, v in batch.items() if torch.is_tensor(v)}\n        logits = best_model(batch[\"input_ids\"])\n        test_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n        test_lbls.extend(batch[\"label\"].cpu().numpy())\ntest_mcc = matthews_corrcoef(test_lbls, test_preds)\ntest_f1 = f1_score(test_lbls, test_preds, average=\"macro\")\nprint(f\"Test MCC={test_mcc:.3f} | Macro-F1={test_f1:.3f}\")\nexp = experiment_data[\"no_ffn\"][\"SPR\"]\nexp[\"predictions\"] = test_preds\nexp[\"ground_truth\"] = test_lbls\nexp[\"test_MCC\"] = test_mcc\nexp[\"test_F1\"] = test_f1\n\n# ---------- plot & save ----------\nplt.figure(figsize=(6, 4))\nplt.plot(exp[\"losses\"][\"train\"], label=\"train\")\nplt.plot(exp[\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"update (epochs aggregated)\")\nplt.ylabel(\"BCE loss\")\nplt.legend()\nplt.title(\"Loss curve No-FFN Transformer\")\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"loss_curve_no_ffn.png\"))\nplt.close()\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved results to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# No-LayerNorm ablation study for SPR \u2013 single-file script\nimport os, pathlib, random, math, time\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.metrics import matthews_corrcoef, f1_score\nimport matplotlib.pyplot as plt\n\n# ---------- paths / device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- data loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _ld(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    out = DatasetDict()\n    out[\"train\"], out[\"dev\"], out[\"test\"] = (\n        _ld(\"train.csv\"),\n        _ld(\"dev.csv\"),\n        _ld(\"test.csv\"),\n    )\n    return out\n\n\ndef get_spr() -> DatasetDict:\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(\"Loading real SPR_BENCH from\", p)\n            return load_spr_bench(p)\n\n    # synthetic fallback\n    print(\"SPR_BENCH not found \u2014 generating toy data\")\n\n    def _synth(n):\n        rows, shapes = \"ABCD\"\n        data = []\n        for i in range(n):\n            seq = \"\".join(random.choices(shapes, k=random.randint(5, 15)))\n            lbl = int(seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\")\n            data.append({\"id\": i, \"sequence\": seq, \"label\": lbl})\n        return load_dataset(\n            \"json\", data_files={\"data\": data}, field=\"data\", split=\"train\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = _synth(4000), _synth(1000), _synth(1000)\n    return d\n\n\nspr = get_spr()\n\n# ---------- vocabulary ----------\nall_text = \"\".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text))\nstoi = {ch: i + 1 for i, ch in enumerate(vocab)}  # 0 = PAD\nitos = {i: ch for ch, i in enumerate([\"<PAD>\"] + vocab)}\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, spr[\"train\"][\"sequence\"])))\n\n\ndef encode(seq: str):\n    out = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return out + [0] * (max_len - len(out))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.labels[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(name, bs=128, shuffle=False, max_items=None):\n    ds = SPRDataset(spr[name])\n    if max_items and len(ds) > max_items:\n        idx = torch.randperm(len(ds))[:max_items]\n        ds = Subset(ds, idx)\n    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n\n\ntrain_loader = lambda: make_loader(\"train\", shuffle=True, max_items=10000)\ndev_loader = lambda: make_loader(\"dev\", max_items=2000)\ntest_loader = lambda: make_loader(\"test\")\n\n\n# ---------- positional enc ----------\ndef positional_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)\n\n\n# ---------- No-LayerNorm encoder layer ----------\nclass TransformerEncoderLayerNoLN(nn.Module):\n    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(\n            d_model, nhead, dropout=dropout, batch_first=True\n        )\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n        self.dropout = nn.Dropout(dropout)\n        self.dropout_ff = nn.Dropout(dropout)\n        self.activation = nn.ReLU()\n\n    def forward(self, src, src_mask=None, src_key_padding_mask=None, is_causal=False):\n        # Self-attention block without LayerNorm\n        attn_out, _ = self.self_attn(\n            src,\n            src,\n            src,\n            attn_mask=src_mask,\n            key_padding_mask=src_key_padding_mask,\n            need_weights=False,\n            is_causal=is_causal,\n        )\n        src = src + self.dropout(attn_out)\n\n        # Feed-forward block without LayerNorm\n        ff = self.linear2(self.dropout_ff(self.activation(self.linear1(src))))\n        src = src + self.dropout(ff)\n        return src\n\n\n# ---------- Char transformer w/o LayerNorm ----------\nclass CharTransformerNoLN(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        layer = TransformerEncoderLayerNoLN(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=4 * d_model,\n            dropout=dropout,\n        )\n        self.encoder = nn.TransformerEncoder(layer, num_layers=num_layers, norm=None)\n        self.fc = nn.Linear(d_model, 1)\n        self.register_buffer(\n            \"pe\", positional_encoding(max_len, d_model, torch.device(\"cpu\"))\n        )\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        pad_mask = x == 0\n        h = self.emb(x) + self.pe[:, : x.size(1), :].to(x.device)\n        h = self.encoder(h, src_key_padding_mask=pad_mask)\n        lengths = (~pad_mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled = (h.masked_fill(pad_mask.unsqueeze(2), 0).sum(1)) / lengths\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\n# ---------- experiment bookkeeping ----------\nexperiment_data = {\n    \"no_layernorm\": {\n        \"SPR\": {\n            \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\ncriterion = nn.BCEWithLogitsLoss()\ndropouts = [0.1, 0.3]\nepochs = 6\nbest_dev_mcc, best_state, best_dp = -1, None, None\n\n# ---------- training loop ----------\nfor dp in dropouts:\n    print(f\"\\n=== Dropout {dp} ===\")\n    model = CharTransformerNoLN(\n        vocab_size, d_model=128, nhead=4, num_layers=2, dropout=dp\n    ).to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for ep in range(1, epochs + 1):\n        # train\n        model.train()\n        tr_losses, tr_preds, tr_labels = [], [], []\n        for batch in train_loader():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optim.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optim.step()\n            tr_losses.append(loss.item())\n            tr_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            tr_labels.extend(batch[\"label\"].cpu().numpy())\n        train_mcc = matthews_corrcoef(tr_labels, tr_preds)\n\n        # validation\n        model.eval()\n        val_losses, val_preds, val_labels = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader():\n                batch = {k: v.to(device) for k, v in batch.items()}\n                logits = model(batch[\"input_ids\"])\n                val_losses.append(criterion(logits, batch[\"label\"]).item())\n                val_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                val_labels.extend(batch[\"label\"].cpu().numpy())\n        val_mcc = matthews_corrcoef(val_labels, val_preds)\n\n        print(\n            f\"Epoch {ep}: val_loss={np.mean(val_losses):.4f} | train_MCC={train_mcc:.3f} val_MCC={val_mcc:.3f}\"\n        )\n\n        # log\n        e = experiment_data[\"no_layernorm\"][\"SPR\"]\n        e[\"metrics\"][\"train_MCC\"].append(train_mcc)\n        e[\"metrics\"][\"val_MCC\"].append(val_mcc)\n        e[\"losses\"][\"train\"].append(np.mean(tr_losses))\n        e[\"losses\"][\"val\"].append(np.mean(val_losses))\n        e[\"epochs\"].append((dp, ep))\n\n        if val_mcc > best_dev_mcc:\n            best_dev_mcc, best_dp = val_mcc, dp\n            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n\n# ---------- test ----------\nprint(f\"\\nBest dev MCC={best_dev_mcc:.3f} (dropout={best_dp}) \u2014 evaluating on test\")\nbest_model = CharTransformerNoLN(\n    vocab_size, d_model=128, nhead=4, num_layers=2, dropout=best_dp\n).to(device)\nbest_model.load_state_dict(best_state)\nbest_model.eval()\ntest_preds, test_labels = [], []\nwith torch.no_grad():\n    for batch in test_loader():\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = best_model(batch[\"input_ids\"])\n        test_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n        test_labels.extend(batch[\"label\"].cpu().numpy())\ntest_mcc = matthews_corrcoef(test_labels, test_preds)\ntest_f1 = f1_score(test_labels, test_preds, average=\"macro\")\nprint(f\"Test MCC={test_mcc:.3f} | Test macro-F1={test_f1:.3f}\")\n\n# store predictions\ne = experiment_data[\"no_layernorm\"][\"SPR\"]\ne[\"predictions\"] = test_preds\ne[\"ground_truth\"] = test_labels\ne[\"test_MCC\"] = test_mcc\ne[\"test_F1\"] = test_f1\n\n# ---------- plots ----------\nplt.figure(figsize=(6, 4))\nplt.plot(e[\"losses\"][\"train\"], label=\"train\")\nplt.plot(e[\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"update (epochs aggregated)\")\nplt.ylabel(\"BCE loss\")\nplt.legend()\nplt.title(\"Loss curve \u2013 No-LayerNorm Transformer\")\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"loss_curve_no_layernorm.png\"))\nplt.close()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n# No-LayerNorm ablation study for SPR \u2013 single-file script\nimport os, pathlib, random, math, time\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.metrics import matthews_corrcoef, f1_score\nimport matplotlib.pyplot as plt\n\n# ---------- paths / device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- data loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _ld(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    out = DatasetDict()\n    out[\"train\"], out[\"dev\"], out[\"test\"] = (\n        _ld(\"train.csv\"),\n        _ld(\"dev.csv\"),\n        _ld(\"test.csv\"),\n    )\n    return out\n\n\ndef get_spr() -> DatasetDict:\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(\"Loading real SPR_BENCH from\", p)\n            return load_spr_bench(p)\n\n    # synthetic fallback\n    print(\"SPR_BENCH not found \u2014 generating toy data\")\n\n    def _synth(n):\n        rows, shapes = \"ABCD\"\n        data = []\n        for i in range(n):\n            seq = \"\".join(random.choices(shapes, k=random.randint(5, 15)))\n            lbl = int(seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\")\n            data.append({\"id\": i, \"sequence\": seq, \"label\": lbl})\n        return load_dataset(\n            \"json\", data_files={\"data\": data}, field=\"data\", split=\"train\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = _synth(4000), _synth(1000), _synth(1000)\n    return d\n\n\nspr = get_spr()\n\n# ---------- vocabulary ----------\nall_text = \"\".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text))\nstoi = {ch: i + 1 for i, ch in enumerate(vocab)}  # 0 = PAD\nitos = {i: ch for ch, i in enumerate([\"<PAD>\"] + vocab)}\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, spr[\"train\"][\"sequence\"])))\n\n\ndef encode(seq: str):\n    out = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return out + [0] * (max_len - len(out))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.labels[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(name, bs=128, shuffle=False, max_items=None):\n    ds = SPRDataset(spr[name])\n    if max_items and len(ds) > max_items:\n        idx = torch.randperm(len(ds))[:max_items]\n        ds = Subset(ds, idx)\n    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n\n\ntrain_loader = lambda: make_loader(\"train\", shuffle=True, max_items=10000)\ndev_loader = lambda: make_loader(\"dev\", max_items=2000)\ntest_loader = lambda: make_loader(\"test\")\n\n\n# ---------- positional enc ----------\ndef positional_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)\n\n\n# ---------- No-LayerNorm encoder layer ----------\nclass TransformerEncoderLayerNoLN(nn.Module):\n    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(\n            d_model, nhead, dropout=dropout, batch_first=True\n        )\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n        self.dropout = nn.Dropout(dropout)\n        self.dropout_ff = nn.Dropout(dropout)\n        self.activation = nn.ReLU()\n\n    def forward(self, src, src_mask=None, src_key_padding_mask=None, is_causal=False):\n        # Self-attention block without LayerNorm\n        attn_out, _ = self.self_attn(\n            src,\n            src,\n            src,\n            attn_mask=src_mask,\n            key_padding_mask=src_key_padding_mask,\n            need_weights=False,\n            is_causal=is_causal,\n        )\n        src = src + self.dropout(attn_out)\n\n        # Feed-forward block without LayerNorm\n        ff = self.linear2(self.dropout_ff(self.activation(self.linear1(src))))\n        src = src + self.dropout(ff)\n        return src\n\n\n# ---------- Char transformer w/o LayerNorm ----------\nclass CharTransformerNoLN(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        layer = TransformerEncoderLayerNoLN(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=4 * d_model,\n            dropout=dropout,\n        )\n        self.encoder = nn.TransformerEncoder(layer, num_layers=num_layers, norm=None)\n        self.fc = nn.Linear(d_model, 1)\n        self.register_buffer(\n            \"pe\", positional_encoding(max_len, d_model, torch.device(\"cpu\"))\n        )\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        pad_mask = x == 0\n        h = self.emb(x) + self.pe[:, : x.size(1), :].to(x.device)\n        h = self.encoder(h, src_key_padding_mask=pad_mask)\n        lengths = (~pad_mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled = (h.masked_fill(pad_mask.unsqueeze(2), 0).sum(1)) / lengths\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\n# ---------- experiment bookkeeping ----------\nexperiment_data = {\n    \"no_layernorm\": {\n        \"SPR\": {\n            \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\ncriterion = nn.BCEWithLogitsLoss()\ndropouts = [0.1, 0.3]\nepochs = 6\nbest_dev_mcc, best_state, best_dp = -1, None, None\n\n# ---------- training loop ----------\nfor dp in dropouts:\n    print(f\"\\n=== Dropout {dp} ===\")\n    model = CharTransformerNoLN(\n        vocab_size, d_model=128, nhead=4, num_layers=2, dropout=dp\n    ).to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for ep in range(1, epochs + 1):\n        # train\n        model.train()\n        tr_losses, tr_preds, tr_labels = [], [], []\n        for batch in train_loader():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optim.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optim.step()\n            tr_losses.append(loss.item())\n            tr_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            tr_labels.extend(batch[\"label\"].cpu().numpy())\n        train_mcc = matthews_corrcoef(tr_labels, tr_preds)\n\n        # validation\n        model.eval()\n        val_losses, val_preds, val_labels = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader():\n                batch = {k: v.to(device) for k, v in batch.items()}\n                logits = model(batch[\"input_ids\"])\n                val_losses.append(criterion(logits, batch[\"label\"]).item())\n                val_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                val_labels.extend(batch[\"label\"].cpu().numpy())\n        val_mcc = matthews_corrcoef(val_labels, val_preds)\n\n        print(\n            f\"Epoch {ep}: val_loss={np.mean(val_losses):.4f} | train_MCC={train_mcc:.3f} val_MCC={val_mcc:.3f}\"\n        )\n\n        # log\n        e = experiment_data[\"no_layernorm\"][\"SPR\"]\n        e[\"metrics\"][\"train_MCC\"].append(train_mcc)\n        e[\"metrics\"][\"val_MCC\"].append(val_mcc)\n        e[\"losses\"][\"train\"].append(np.mean(tr_losses))\n        e[\"losses\"][\"val\"].append(np.mean(val_losses))\n        e[\"epochs\"].append((dp, ep))\n\n        if val_mcc > best_dev_mcc:\n            best_dev_mcc, best_dp = val_mcc, dp\n            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n\n# ---------- test ----------\nprint(f\"\\nBest dev MCC={best_dev_mcc:.3f} (dropout={best_dp}) \u2014 evaluating on test\")\nbest_model = CharTransformerNoLN(\n    vocab_size, d_model=128, nhead=4, num_layers=2, dropout=best_dp\n).to(device)\nbest_model.load_state_dict(best_state)\nbest_model.eval()\ntest_preds, test_labels = [], []\nwith torch.no_grad():\n    for batch in test_loader():\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = best_model(batch[\"input_ids\"])\n        test_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n        test_labels.extend(batch[\"label\"].cpu().numpy())\ntest_mcc = matthews_corrcoef(test_labels, test_preds)\ntest_f1 = f1_score(test_labels, test_preds, average=\"macro\")\nprint(f\"Test MCC={test_mcc:.3f} | Test macro-F1={test_f1:.3f}\")\n\n# store predictions\ne = experiment_data[\"no_layernorm\"][\"SPR\"]\ne[\"predictions\"] = test_preds\ne[\"ground_truth\"] = test_labels\ne[\"test_MCC\"] = test_mcc\ne[\"test_F1\"] = test_f1\n\n# ---------- plots ----------\nplt.figure(figsize=(6, 4))\nplt.plot(e[\"losses\"][\"train\"], label=\"train\")\nplt.plot(e[\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"update (epochs aggregated)\")\nplt.ylabel(\"BCE loss\")\nplt.legend()\nplt.title(\"Loss curve \u2013 No-LayerNorm Transformer\")\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"loss_curve_no_layernorm.png\"))\nplt.close()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n# No-LayerNorm ablation study for SPR \u2013 single-file script\nimport os, pathlib, random, math, time\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.metrics import matthews_corrcoef, f1_score\nimport matplotlib.pyplot as plt\n\n# ---------- paths / device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- data loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _ld(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    out = DatasetDict()\n    out[\"train\"], out[\"dev\"], out[\"test\"] = (\n        _ld(\"train.csv\"),\n        _ld(\"dev.csv\"),\n        _ld(\"test.csv\"),\n    )\n    return out\n\n\ndef get_spr() -> DatasetDict:\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(\"Loading real SPR_BENCH from\", p)\n            return load_spr_bench(p)\n\n    # synthetic fallback\n    print(\"SPR_BENCH not found \u2014 generating toy data\")\n\n    def _synth(n):\n        rows, shapes = \"ABCD\"\n        data = []\n        for i in range(n):\n            seq = \"\".join(random.choices(shapes, k=random.randint(5, 15)))\n            lbl = int(seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\")\n            data.append({\"id\": i, \"sequence\": seq, \"label\": lbl})\n        return load_dataset(\n            \"json\", data_files={\"data\": data}, field=\"data\", split=\"train\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = _synth(4000), _synth(1000), _synth(1000)\n    return d\n\n\nspr = get_spr()\n\n# ---------- vocabulary ----------\nall_text = \"\".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text))\nstoi = {ch: i + 1 for i, ch in enumerate(vocab)}  # 0 = PAD\nitos = {i: ch for ch, i in enumerate([\"<PAD>\"] + vocab)}\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, spr[\"train\"][\"sequence\"])))\n\n\ndef encode(seq: str):\n    out = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return out + [0] * (max_len - len(out))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.labels[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(name, bs=128, shuffle=False, max_items=None):\n    ds = SPRDataset(spr[name])\n    if max_items and len(ds) > max_items:\n        idx = torch.randperm(len(ds))[:max_items]\n        ds = Subset(ds, idx)\n    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n\n\ntrain_loader = lambda: make_loader(\"train\", shuffle=True, max_items=10000)\ndev_loader = lambda: make_loader(\"dev\", max_items=2000)\ntest_loader = lambda: make_loader(\"test\")\n\n\n# ---------- positional enc ----------\ndef positional_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)\n\n\n# ---------- No-LayerNorm encoder layer ----------\nclass TransformerEncoderLayerNoLN(nn.Module):\n    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(\n            d_model, nhead, dropout=dropout, batch_first=True\n        )\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n        self.dropout = nn.Dropout(dropout)\n        self.dropout_ff = nn.Dropout(dropout)\n        self.activation = nn.ReLU()\n\n    def forward(self, src, src_mask=None, src_key_padding_mask=None, is_causal=False):\n        # Self-attention block without LayerNorm\n        attn_out, _ = self.self_attn(\n            src,\n            src,\n            src,\n            attn_mask=src_mask,\n            key_padding_mask=src_key_padding_mask,\n            need_weights=False,\n            is_causal=is_causal,\n        )\n        src = src + self.dropout(attn_out)\n\n        # Feed-forward block without LayerNorm\n        ff = self.linear2(self.dropout_ff(self.activation(self.linear1(src))))\n        src = src + self.dropout(ff)\n        return src\n\n\n# ---------- Char transformer w/o LayerNorm ----------\nclass CharTransformerNoLN(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        layer = TransformerEncoderLayerNoLN(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=4 * d_model,\n            dropout=dropout,\n        )\n        self.encoder = nn.TransformerEncoder(layer, num_layers=num_layers, norm=None)\n        self.fc = nn.Linear(d_model, 1)\n        self.register_buffer(\n            \"pe\", positional_encoding(max_len, d_model, torch.device(\"cpu\"))\n        )\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        pad_mask = x == 0\n        h = self.emb(x) + self.pe[:, : x.size(1), :].to(x.device)\n        h = self.encoder(h, src_key_padding_mask=pad_mask)\n        lengths = (~pad_mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled = (h.masked_fill(pad_mask.unsqueeze(2), 0).sum(1)) / lengths\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\n# ---------- experiment bookkeeping ----------\nexperiment_data = {\n    \"no_layernorm\": {\n        \"SPR\": {\n            \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\ncriterion = nn.BCEWithLogitsLoss()\ndropouts = [0.1, 0.3]\nepochs = 6\nbest_dev_mcc, best_state, best_dp = -1, None, None\n\n# ---------- training loop ----------\nfor dp in dropouts:\n    print(f\"\\n=== Dropout {dp} ===\")\n    model = CharTransformerNoLN(\n        vocab_size, d_model=128, nhead=4, num_layers=2, dropout=dp\n    ).to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for ep in range(1, epochs + 1):\n        # train\n        model.train()\n        tr_losses, tr_preds, tr_labels = [], [], []\n        for batch in train_loader():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optim.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optim.step()\n            tr_losses.append(loss.item())\n            tr_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            tr_labels.extend(batch[\"label\"].cpu().numpy())\n        train_mcc = matthews_corrcoef(tr_labels, tr_preds)\n\n        # validation\n        model.eval()\n        val_losses, val_preds, val_labels = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader():\n                batch = {k: v.to(device) for k, v in batch.items()}\n                logits = model(batch[\"input_ids\"])\n                val_losses.append(criterion(logits, batch[\"label\"]).item())\n                val_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                val_labels.extend(batch[\"label\"].cpu().numpy())\n        val_mcc = matthews_corrcoef(val_labels, val_preds)\n\n        print(\n            f\"Epoch {ep}: val_loss={np.mean(val_losses):.4f} | train_MCC={train_mcc:.3f} val_MCC={val_mcc:.3f}\"\n        )\n\n        # log\n        e = experiment_data[\"no_layernorm\"][\"SPR\"]\n        e[\"metrics\"][\"train_MCC\"].append(train_mcc)\n        e[\"metrics\"][\"val_MCC\"].append(val_mcc)\n        e[\"losses\"][\"train\"].append(np.mean(tr_losses))\n        e[\"losses\"][\"val\"].append(np.mean(val_losses))\n        e[\"epochs\"].append((dp, ep))\n\n        if val_mcc > best_dev_mcc:\n            best_dev_mcc, best_dp = val_mcc, dp\n            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n\n# ---------- test ----------\nprint(f\"\\nBest dev MCC={best_dev_mcc:.3f} (dropout={best_dp}) \u2014 evaluating on test\")\nbest_model = CharTransformerNoLN(\n    vocab_size, d_model=128, nhead=4, num_layers=2, dropout=best_dp\n).to(device)\nbest_model.load_state_dict(best_state)\nbest_model.eval()\ntest_preds, test_labels = [], []\nwith torch.no_grad():\n    for batch in test_loader():\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = best_model(batch[\"input_ids\"])\n        test_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n        test_labels.extend(batch[\"label\"].cpu().numpy())\ntest_mcc = matthews_corrcoef(test_labels, test_preds)\ntest_f1 = f1_score(test_labels, test_preds, average=\"macro\")\nprint(f\"Test MCC={test_mcc:.3f} | Test macro-F1={test_f1:.3f}\")\n\n# store predictions\ne = experiment_data[\"no_layernorm\"][\"SPR\"]\ne[\"predictions\"] = test_preds\ne[\"ground_truth\"] = test_labels\ne[\"test_MCC\"] = test_mcc\ne[\"test_F1\"] = test_f1\n\n# ---------- plots ----------\nplt.figure(figsize=(6, 4))\nplt.plot(e[\"losses\"][\"train\"], label=\"train\")\nplt.plot(e[\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"update (epochs aggregated)\")\nplt.ylabel(\"BCE loss\")\nplt.legend()\nplt.title(\"Loss curve \u2013 No-LayerNorm Transformer\")\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"loss_curve_no_layernorm.png\"))\nplt.close()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n# No-LayerNorm ablation study for SPR \u2013 single-file script\nimport os, pathlib, random, math, time\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.metrics import matthews_corrcoef, f1_score\nimport matplotlib.pyplot as plt\n\n# ---------- paths / device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- data loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _ld(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    out = DatasetDict()\n    out[\"train\"], out[\"dev\"], out[\"test\"] = (\n        _ld(\"train.csv\"),\n        _ld(\"dev.csv\"),\n        _ld(\"test.csv\"),\n    )\n    return out\n\n\ndef get_spr() -> DatasetDict:\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(\"Loading real SPR_BENCH from\", p)\n            return load_spr_bench(p)\n\n    # synthetic fallback\n    print(\"SPR_BENCH not found \u2014 generating toy data\")\n\n    def _synth(n):\n        rows, shapes = \"ABCD\"\n        data = []\n        for i in range(n):\n            seq = \"\".join(random.choices(shapes, k=random.randint(5, 15)))\n            lbl = int(seq.count(\"A\") % 2 == 0 and seq[-1] in \"BC\")\n            data.append({\"id\": i, \"sequence\": seq, \"label\": lbl})\n        return load_dataset(\n            \"json\", data_files={\"data\": data}, field=\"data\", split=\"train\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"], d[\"dev\"], d[\"test\"] = _synth(4000), _synth(1000), _synth(1000)\n    return d\n\n\nspr = get_spr()\n\n# ---------- vocabulary ----------\nall_text = \"\".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text))\nstoi = {ch: i + 1 for i, ch in enumerate(vocab)}  # 0 = PAD\nitos = {i: ch for ch, i in enumerate([\"<PAD>\"] + vocab)}\nvocab_size = len(stoi) + 1\nmax_len = min(120, max(map(len, spr[\"train\"][\"sequence\"])))\n\n\ndef encode(seq: str):\n    out = [stoi.get(ch, 0) for ch in seq[:max_len]]\n    return out + [0] * (max_len - len(out))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"label\": torch.tensor(int(self.labels[idx]), dtype=torch.float),\n        }\n\n\ndef make_loader(name, bs=128, shuffle=False, max_items=None):\n    ds = SPRDataset(spr[name])\n    if max_items and len(ds) > max_items:\n        idx = torch.randperm(len(ds))[:max_items]\n        ds = Subset(ds, idx)\n    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=False)\n\n\ntrain_loader = lambda: make_loader(\"train\", shuffle=True, max_items=10000)\ndev_loader = lambda: make_loader(\"dev\", max_items=2000)\ntest_loader = lambda: make_loader(\"test\")\n\n\n# ---------- positional enc ----------\ndef positional_encoding(seq_len, d_model, device):\n    pe = torch.zeros(seq_len, d_model, device=device)\n    pos = torch.arange(0, seq_len, device=device).float().unsqueeze(1)\n    div = torch.exp(\n        torch.arange(0, d_model, 2, device=device).float()\n        * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div)\n    pe[:, 1::2] = torch.cos(pos * div)\n    return pe.unsqueeze(0)\n\n\n# ---------- No-LayerNorm encoder layer ----------\nclass TransformerEncoderLayerNoLN(nn.Module):\n    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(\n            d_model, nhead, dropout=dropout, batch_first=True\n        )\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n        self.dropout = nn.Dropout(dropout)\n        self.dropout_ff = nn.Dropout(dropout)\n        self.activation = nn.ReLU()\n\n    def forward(self, src, src_mask=None, src_key_padding_mask=None, is_causal=False):\n        # Self-attention block without LayerNorm\n        attn_out, _ = self.self_attn(\n            src,\n            src,\n            src,\n            attn_mask=src_mask,\n            key_padding_mask=src_key_padding_mask,\n            need_weights=False,\n            is_causal=is_causal,\n        )\n        src = src + self.dropout(attn_out)\n\n        # Feed-forward block without LayerNorm\n        ff = self.linear2(self.dropout_ff(self.activation(self.linear1(src))))\n        src = src + self.dropout(ff)\n        return src\n\n\n# ---------- Char transformer w/o LayerNorm ----------\nclass CharTransformerNoLN(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        layer = TransformerEncoderLayerNoLN(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=4 * d_model,\n            dropout=dropout,\n        )\n        self.encoder = nn.TransformerEncoder(layer, num_layers=num_layers, norm=None)\n        self.fc = nn.Linear(d_model, 1)\n        self.register_buffer(\n            \"pe\", positional_encoding(max_len, d_model, torch.device(\"cpu\"))\n        )\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        pad_mask = x == 0\n        h = self.emb(x) + self.pe[:, : x.size(1), :].to(x.device)\n        h = self.encoder(h, src_key_padding_mask=pad_mask)\n        lengths = (~pad_mask).sum(1).clamp(min=1).unsqueeze(1)\n        pooled = (h.masked_fill(pad_mask.unsqueeze(2), 0).sum(1)) / lengths\n        pooled = self.drop(pooled)\n        return self.fc(pooled).squeeze(1)\n\n\n# ---------- experiment bookkeeping ----------\nexperiment_data = {\n    \"no_layernorm\": {\n        \"SPR\": {\n            \"metrics\": {\"train_MCC\": [], \"val_MCC\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\ncriterion = nn.BCEWithLogitsLoss()\ndropouts = [0.1, 0.3]\nepochs = 6\nbest_dev_mcc, best_state, best_dp = -1, None, None\n\n# ---------- training loop ----------\nfor dp in dropouts:\n    print(f\"\\n=== Dropout {dp} ===\")\n    model = CharTransformerNoLN(\n        vocab_size, d_model=128, nhead=4, num_layers=2, dropout=dp\n    ).to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for ep in range(1, epochs + 1):\n        # train\n        model.train()\n        tr_losses, tr_preds, tr_labels = [], [], []\n        for batch in train_loader():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optim.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optim.step()\n            tr_losses.append(loss.item())\n            tr_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n            tr_labels.extend(batch[\"label\"].cpu().numpy())\n        train_mcc = matthews_corrcoef(tr_labels, tr_preds)\n\n        # validation\n        model.eval()\n        val_losses, val_preds, val_labels = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader():\n                batch = {k: v.to(device) for k, v in batch.items()}\n                logits = model(batch[\"input_ids\"])\n                val_losses.append(criterion(logits, batch[\"label\"]).item())\n                val_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n                val_labels.extend(batch[\"label\"].cpu().numpy())\n        val_mcc = matthews_corrcoef(val_labels, val_preds)\n\n        print(\n            f\"Epoch {ep}: val_loss={np.mean(val_losses):.4f} | train_MCC={train_mcc:.3f} val_MCC={val_mcc:.3f}\"\n        )\n\n        # log\n        e = experiment_data[\"no_layernorm\"][\"SPR\"]\n        e[\"metrics\"][\"train_MCC\"].append(train_mcc)\n        e[\"metrics\"][\"val_MCC\"].append(val_mcc)\n        e[\"losses\"][\"train\"].append(np.mean(tr_losses))\n        e[\"losses\"][\"val\"].append(np.mean(val_losses))\n        e[\"epochs\"].append((dp, ep))\n\n        if val_mcc > best_dev_mcc:\n            best_dev_mcc, best_dp = val_mcc, dp\n            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n\n# ---------- test ----------\nprint(f\"\\nBest dev MCC={best_dev_mcc:.3f} (dropout={best_dp}) \u2014 evaluating on test\")\nbest_model = CharTransformerNoLN(\n    vocab_size, d_model=128, nhead=4, num_layers=2, dropout=best_dp\n).to(device)\nbest_model.load_state_dict(best_state)\nbest_model.eval()\ntest_preds, test_labels = [], []\nwith torch.no_grad():\n    for batch in test_loader():\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = best_model(batch[\"input_ids\"])\n        test_preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy())\n        test_labels.extend(batch[\"label\"].cpu().numpy())\ntest_mcc = matthews_corrcoef(test_labels, test_preds)\ntest_f1 = f1_score(test_labels, test_preds, average=\"macro\")\nprint(f\"Test MCC={test_mcc:.3f} | Test macro-F1={test_f1:.3f}\")\n\n# store predictions\ne = experiment_data[\"no_layernorm\"][\"SPR\"]\ne[\"predictions\"] = test_preds\ne[\"ground_truth\"] = test_labels\ne[\"test_MCC\"] = test_mcc\ne[\"test_F1\"] = test_f1\n\n# ---------- plots ----------\nplt.figure(figsize=(6, 4))\nplt.plot(e[\"losses\"][\"train\"], label=\"train\")\nplt.plot(e[\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"update (epochs aggregated)\")\nplt.ylabel(\"BCE loss\")\nplt.legend()\nplt.title(\"Loss curve \u2013 No-LayerNorm Transformer\")\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"loss_curve_no_layernorm.png\"))\nplt.close()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'Loading real SPR_BENCH from', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0\nexamples [00:00, ? examples/s]', '', '\\rGenerating train split: 2000 examples\n[00:00, 122888.40 examples/s]', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 500 examples [00:00,\n98703.44 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 134652.93\nexamples/s]', '\\n', '\\n=== Dropout 0.1 ===', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: validation_loss = 0.6333\n| train_MCC=0.169 val_MCC=0.356', '\\n', 'Epoch 2: validation_loss = 0.6318 |\ntrain_MCC=0.364 val_MCC=0.348', '\\n', 'Epoch 3: validation_loss = 0.6392 |\ntrain_MCC=0.362 val_MCC=0.334', '\\n', 'Epoch 4: validation_loss = 0.6328 |\ntrain_MCC=0.374 val_MCC=0.372', '\\n', 'Epoch 5: validation_loss = 0.6313 |\ntrain_MCC=0.367 val_MCC=0.372', '\\n', 'Epoch 6: validation_loss = 0.6373 |\ntrain_MCC=0.392 val_MCC=0.384', '\\n', '\\n=== Dropout 0.3 ===', '\\n', 'Epoch 1:\nvalidation_loss = 0.6538 | train_MCC=0.077 val_MCC=0.277', '\\n', 'Epoch 2:\nvalidation_loss = 0.6441 | train_MCC=0.324 val_MCC=0.388', '\\n', 'Epoch 3:\nvalidation_loss = 0.6327 | train_MCC=0.359 val_MCC=0.368', '\\n', 'Epoch 4:\nvalidation_loss = 0.6411 | train_MCC=0.387 val_MCC=0.384', '\\n', 'Epoch 5:\nvalidation_loss = 0.6315 | train_MCC=0.381 val_MCC=0.364', '\\n', 'Epoch 6:\nvalidation_loss = 0.6619 | train_MCC=0.373 val_MCC=0.292', '\\n', '\\nBest dev\nMCC=0.388 (dropout=0.3). Evaluating on test set...', '\\n', 'Test MCC=0.390 |\nTest Macro-F1=0.695', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-17_18-48-\n09_symblic_polyrule_reasoning_attempt_0/0-run/process_ForkProcess-\n11/working/experiment_data.npy', '\\n', 'Execution time: 10 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Loading real SPR_BENCH from', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0\nexamples [00:00, ? examples/s]', '', '\\rGenerating train split: 2000 examples\n[00:00, 109560.48 examples/s]', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 500 examples [00:00,\n88689.50 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '\\rGenerating train split: 1000 examples [00:00, 3030.10\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 3022.78\nexamples/s]', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', '[with_positional_encoding] Epoch\n1: train_MCC=0.151 val_MCC=0.329', '\\n', '[with_positional_encoding] Epoch 2:\ntrain_MCC=0.368 val_MCC=0.352', '\\n', '[with_positional_encoding] Epoch 3:\ntrain_MCC=0.361 val_MCC=0.323', '\\n', '[with_positional_encoding] Epoch 4:\ntrain_MCC=0.379 val_MCC=0.376', '\\n', '[with_positional_encoding] Epoch 5:\ntrain_MCC=0.367 val_MCC=0.364', '\\n', '[with_positional_encoding] Epoch 6:\ntrain_MCC=0.388 val_MCC=0.380', '\\n', '[with_positional_encoding] Best\nval_MCC=0.380 at epoch 6', '\\n', '[with_positional_encoding] Test MCC=0.384 |\nTest F1=0.692', '\\n', '[no_positional_encoding] Epoch 1: train_MCC=0.108\nval_MCC=0.336', '\\n', '[no_positional_encoding] Epoch 2: train_MCC=0.339\nval_MCC=0.223', '\\n', '[no_positional_encoding] Epoch 3: train_MCC=0.333\nval_MCC=0.332', '\\n', '[no_positional_encoding] Epoch 4: train_MCC=0.370\nval_MCC=0.334', '\\n', '[no_positional_encoding] Epoch 5: train_MCC=0.369\nval_MCC=0.372', '\\n', '[no_positional_encoding] Epoch 6: train_MCC=0.381\nval_MCC=0.372', '\\n', '[no_positional_encoding] Best val_MCC=0.372 at epoch 5',\n'\\n', '[no_positional_encoding] Test MCC=0.383 | Test F1=0.692', '\\n', 'Saved\nexperiment data to', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-\n17_18-48-09_symblic_polyrule_reasoning_attempt_0/0-run/process_ForkProcess-\n16/working/experiment_data.npy', '\\n', 'Execution time: 11 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Loading real SPR_BENCH from', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0\nexamples [00:00, ? examples/s]', '', '\\rGenerating train split: 2000 examples\n[00:00, 157618.38 examples/s]', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 500 examples [00:00,\n110017.42 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 101382.71\nexamples/s]', '\\n', '\\n=== transformer | dropout 0.1 ===', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: val_loss=0.6370 |\ntrain_MCC=0.145 val_MCC=0.324', '\\n', 'Epoch 2: val_loss=0.6314 |\ntrain_MCC=0.371 val_MCC=0.352', '\\n', 'Epoch 3: val_loss=0.6428 |\ntrain_MCC=0.360 val_MCC=0.331', '\\n', 'Epoch 4: val_loss=0.6352 |\ntrain_MCC=0.375 val_MCC=0.384', '\\n', 'Epoch 5: val_loss=0.6327 |\ntrain_MCC=0.371 val_MCC=0.368', '\\n', 'Epoch 6: val_loss=0.6386 |\ntrain_MCC=0.387 val_MCC=0.388', '\\n', '\\n=== transformer | dropout 0.3 ===',\n'\\n', 'Epoch 1: val_loss=0.6508 | train_MCC=0.095 val_MCC=0.334', '\\n', 'Epoch\n2: val_loss=0.6619 | train_MCC=0.328 val_MCC=0.380', '\\n', 'Epoch 3:\nval_loss=0.6325 | train_MCC=0.354 val_MCC=0.364', '\\n', 'Epoch 4:\nval_loss=0.6404 | train_MCC=0.382 val_MCC=0.392', '\\n', 'Epoch 5:\nval_loss=0.6343 | train_MCC=0.383 val_MCC=0.372', '\\n', 'Epoch 6:\nval_loss=0.6486 | train_MCC=0.379 val_MCC=0.342', '\\n', '\\nBest dev MCC for\ntransformer = 0.392 (dropout=0.3)', '\\n', 'transformer | Test MCC=0.384 | Test\nF1=0.692', '\\n', '\\n=== bag_of_embeddings | dropout 0.1 ===', '\\n', 'Epoch 1:\nval_loss=0.6941 | train_MCC=-0.087 val_MCC=-0.035', '\\n', 'Epoch 2:\nval_loss=0.6879 | train_MCC=0.051 val_MCC=0.086', '\\n', 'Epoch 3:\nval_loss=0.6813 | train_MCC=0.254 val_MCC=0.335', '\\n', 'Epoch 4:\nval_loss=0.6760 | train_MCC=0.340 val_MCC=0.349', '\\n', 'Epoch 5:\nval_loss=0.6715 | train_MCC=0.351 val_MCC=0.340', '\\n', 'Epoch 6:\nval_loss=0.6669 | train_MCC=0.357 val_MCC=0.337', '\\n', '\\n=== bag_of_embeddings\n| dropout 0.3 ===', '\\n', 'Epoch 1: val_loss=0.6881 | train_MCC=0.106\nval_MCC=0.001', '\\n', 'Epoch 2: val_loss=0.6826 | train_MCC=0.135\nval_MCC=0.250', '\\n', 'Epoch 3: val_loss=0.6786 | train_MCC=0.281\nval_MCC=0.288', '\\n', 'Epoch 4: val_loss=0.6735 | train_MCC=0.311\nval_MCC=0.333', '\\n', 'Epoch 5: val_loss=0.6693 | train_MCC=0.313\nval_MCC=0.321', '\\n', 'Epoch 6: val_loss=0.6663 | train_MCC=0.342\nval_MCC=0.336', '\\n', '\\nBest dev MCC for bag_of_embeddings = 0.349\n(dropout=0.1)', '\\n', 'bag_of_embeddings | Test MCC=0.361 | Test F1=0.680',\n'\\n', 'All experiment data saved to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/0-\nrun/process_ForkProcess-17/working/experiment_data.npy', '\\n', 'Execution time:\n6 seconds seconds (time limit is 30 minutes).']", "['device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 2000 examples [00:00, 161003.57\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 500 examples [00:00, 145101.50\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 154259.07\nexamples/s]', '\\n', '\\n=== Dropout=0.1 ===', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: val_loss=0.7065 |\ntrain_MCC=0.015 val_MCC=0.000', '\\n', 'Epoch 2: val_loss=0.6350 |\ntrain_MCC=0.248 val_MCC=0.341', '\\n', 'Epoch 3: val_loss=0.6262 |\ntrain_MCC=0.376 val_MCC=0.392', '\\n', 'Epoch 4: val_loss=0.6326 |\ntrain_MCC=0.386 val_MCC=0.388', '\\n', 'Epoch 5: val_loss=0.6317 |\ntrain_MCC=0.378 val_MCC=0.376', '\\n', 'Epoch 6: val_loss=0.6458 |\ntrain_MCC=0.387 val_MCC=0.365', '\\n', '\\n=== Dropout=0.3 ===', '\\n', 'Epoch 1:\nval_loss=0.6950 | train_MCC=-0.002 val_MCC=0.000', '\\n', 'Epoch 2:\nval_loss=0.6951 | train_MCC=0.061 val_MCC=0.000', '\\n', 'Epoch 3:\nval_loss=0.6316 | train_MCC=0.224 val_MCC=0.380', '\\n', 'Epoch 4:\nval_loss=0.6439 | train_MCC=0.356 val_MCC=0.340', '\\n', 'Epoch 5:\nval_loss=0.6466 | train_MCC=0.347 val_MCC=0.332', '\\n', 'Epoch 6:\nval_loss=0.6363 | train_MCC=0.357 val_MCC=0.369', '\\n', '\\nBest dev MCC=0.392\n(dropout=0.1) \u2013 testing.', '\\n', 'Test MCC=0.390 | Test Macro-F1=0.695', '\\n',\n'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/0-\nrun/process_ForkProcess-18/working/experiment_data.npy', '\\n', 'Execution time:\n5 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Loading real SPR_BENCH from', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0\nexamples [00:00, ? examples/s]', '', '\\rGenerating train split: 2000 examples\n[00:00, 52615.92 examples/s]', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 500 examples [00:00,\n91510.76 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 200339.32\nexamples/s]', '\\n', '\\n=== Dropout 0.1 ===', '\\n', 'Epoch 1: val_loss=0.6339 |\ntrain_MCC=0.148 val_MCC=0.340', '\\n', 'Epoch 2: val_loss=0.6313 |\ntrain_MCC=0.366 val_MCC=0.352', '\\n', 'Epoch 3: val_loss=0.6400 |\ntrain_MCC=0.358 val_MCC=0.334', '\\n', 'Epoch 4: val_loss=0.6332 |\ntrain_MCC=0.371 val_MCC=0.372', '\\n', 'Epoch 5: val_loss=0.6311 |\ntrain_MCC=0.370 val_MCC=0.364', '\\n', 'Epoch 6: val_loss=0.6380 |\ntrain_MCC=0.386 val_MCC=0.384', '\\n', '\\n=== Dropout 0.3 ===', '\\n', 'Epoch 1:\nval_loss=0.6671 | train_MCC=0.089 val_MCC=0.148', '\\n', 'Epoch 2:\nval_loss=0.6351 | train_MCC=0.306 val_MCC=0.376', '\\n', 'Epoch 3:\nval_loss=0.6349 | train_MCC=0.375 val_MCC=0.380', '\\n', 'Epoch 4:\nval_loss=0.6391 | train_MCC=0.387 val_MCC=0.380', '\\n', 'Epoch 5:\nval_loss=0.6348 | train_MCC=0.382 val_MCC=0.376', '\\n', 'Epoch 6:\nval_loss=0.6456 | train_MCC=0.376 val_MCC=0.342', '\\n', '\\nBest dev MCC=0.384\n(dropout=0.1). Evaluating on test set...', '\\n', 'Test MCC=0.390 | Test\nmacro-F1=0.695', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scie\nntist-v2/experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/0-\nrun/process_ForkProcess-19/working/experiment_data.npy', '\\n', 'Execution time:\n8 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 67, in <module>\\n    datasets_list = [synth_dataset_dict(fn)\nfor fn in RULE_FNS]\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 67, in\n<listcomp>\\n    datasets_list = [synth_dataset_dict(fn) for fn in RULE_FNS]\\n\n^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 60, in synth_dataset_dict\\n\n\"train\": make_hf_dataset(rule_fn, n_train),\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 54, in\nmake_hf_dataset\\n    return load_dataset(\"json\", data_files={\"data\": data},\nfield=\"data\", split=\"train\")\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\nFile \"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 2062, in load_dataset\\n    builder_instance =\nload_dataset_builder(\\n                       ^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1782, in load_dataset_builder\\n\ndataset_module = dataset_module_factory(\\n\n^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1497, in dataset_module_factory\\n\n).get_module()\\n      ^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 913, in get_module\\n    data_files =\nDataFilesDict.from_patterns(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\nFile \"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 690, in from_patterns\\n    else\nDataFilesList.from_patterns(\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 583, in from_patterns\\n\nresolve_pattern(\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 344, in resolve_pattern\\n    if\nis_relative_path(pattern):\\n       ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/utils/file_utils.py\", line 88, in is_relative_path\\n    return\nurlparse(url_or_filename).scheme == \"\" and not os.path.isabs(url_or_filename)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py\",\nline 394, in urlparse\\n    url, scheme, _coerce_result = _coerce_args(url,\nscheme)\\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py\",\nline 133, in _coerce_args\\n    return _decode_args(args) + (_encode_result,)\\n\n^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py\",\nline 117, in _decode_args\\n    return tuple(x.decode(encoding, errors) if x else\n\\'\\' for x in args)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py\",\nline 117, in <genexpr>\\n    return tuple(x.decode(encoding, errors) if x else\n\\'\\' for x in args)\\n                 ^^^^^^^^\\nAttributeError: \\'dict\\' object\nhas no attribute \\'decode\\'\\n', 'Execution time: a second seconds (time limit is\n30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Loading real SPR_BENCH from', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', '\\n### Positional Encoding:\nSINUSOIDAL ###', '\\n', '\\n--- Dropout 0.1 ---', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: val_loss=0.6358 |\ntrain_MCC=0.146 val_MCC=0.332', '\\n', 'Epoch 2: val_loss=0.6324 |\ntrain_MCC=0.376 val_MCC=0.340', '\\n', 'Epoch 3: val_loss=0.6402 |\ntrain_MCC=0.367 val_MCC=0.330', '\\n', 'Epoch 4: val_loss=0.6337 |\ntrain_MCC=0.377 val_MCC=0.372', '\\n', 'Epoch 5: val_loss=0.6315 |\ntrain_MCC=0.369 val_MCC=0.360', '\\n', 'Epoch 6: val_loss=0.6389 |\ntrain_MCC=0.382 val_MCC=0.388', '\\n', '\\n--- Dropout 0.3 ---', '\\n', 'Epoch 1:\nval_loss=0.6687 | train_MCC=0.090 val_MCC=0.131', '\\n', 'Epoch 2:\nval_loss=0.6354 | train_MCC=0.313 val_MCC=0.380', '\\n', 'Epoch 3:\nval_loss=0.6360 | train_MCC=0.380 val_MCC=0.380', '\\n', 'Epoch 4:\nval_loss=0.6456 | train_MCC=0.388 val_MCC=0.365', '\\n', 'Epoch 5:\nval_loss=0.6427 | train_MCC=0.366 val_MCC=0.353', '\\n', 'Epoch 6:\nval_loss=0.6310 | train_MCC=0.368 val_MCC=0.372', '\\n', '\\nBest dev MCC for\nsinusoidal: 0.388 (dropout=0.1). Evaluating on test set...', '\\n', 'Test\nMCC=0.386 | Test Macro-F1=0.693', '\\n', '\\n### Positional Encoding: LEARNED\n###', '\\n', '\\n--- Dropout 0.1 ---', '\\n', 'Epoch 1: val_loss=0.6805 |\ntrain_MCC=0.017 val_MCC=0.011', '\\n', 'Epoch 2: val_loss=0.6678 |\ntrain_MCC=0.256 val_MCC=0.359', '\\n', 'Epoch 3: val_loss=0.6453 |\ntrain_MCC=0.358 val_MCC=0.330', '\\n', 'Epoch 4: val_loss=0.6491 |\ntrain_MCC=0.371 val_MCC=0.340', '\\n', 'Epoch 5: val_loss=0.6449 |\ntrain_MCC=0.381 val_MCC=0.342', '\\n', 'Epoch 6: val_loss=0.6389 |\ntrain_MCC=0.380 val_MCC=0.340', '\\n', '\\n--- Dropout 0.3 ---', '\\n', 'Epoch 1:\nval_loss=0.6538 | train_MCC=0.098 val_MCC=0.322', '\\n', 'Epoch 2:\nval_loss=0.6292 | train_MCC=0.307 val_MCC=0.368', '\\n', 'Epoch 3:\nval_loss=0.6330 | train_MCC=0.379 val_MCC=0.368', '\\n', 'Epoch 4:\nval_loss=0.6346 | train_MCC=0.385 val_MCC=0.380', '\\n', 'Epoch 5:\nval_loss=0.6372 | train_MCC=0.383 val_MCC=0.380', '\\n', 'Epoch 6:\nval_loss=0.6489 | train_MCC=0.390 val_MCC=0.340', '\\n', '\\nBest dev MCC for\nlearned: 0.380 (dropout=0.3). Evaluating on test set...', '\\n', 'Test MCC=0.383\n| Test Macro-F1=0.691', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-17_18-48-\n09_symblic_polyrule_reasoning_attempt_0/0-run/process_ForkProcess-\n16/working/experiment_data.npy', '\\n', 'Execution time: 8 seconds seconds (time\nlimit is 30 minutes).']", "['Using', ' ', 'cuda', '\\n', 'Loading real SPR_BENCH from', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', '\\n=== Dropout=0.1 (No-FFN)\n===', '\\n', 'Epoch 1: val_loss=0.6682 | train_MCC=0.219 val_MCC=0.268', '\\n',\n'Epoch 2: val_loss=0.6595 | train_MCC=0.347 val_MCC=0.340', '\\n', 'Epoch 3:\nval_loss=0.6667 | train_MCC=0.342 val_MCC=0.332', '\\n', 'Epoch 4:\nval_loss=0.6347 | train_MCC=0.382 val_MCC=0.364', '\\n', 'Epoch 5:\nval_loss=0.6324 | train_MCC=0.379 val_MCC=0.364', '\\n', 'Epoch 6:\nval_loss=0.6384 | train_MCC=0.388 val_MCC=0.376', '\\n', '\\n=== Dropout=0.3 (No-\nFFN) ===', '\\n', 'Epoch 1: val_loss=0.6333 | train_MCC=0.139 val_MCC=0.329',\n'\\n', 'Epoch 2: val_loss=0.6304 | train_MCC=0.350 val_MCC=0.376', '\\n', 'Epoch\n3: val_loss=0.6340 | train_MCC=0.358 val_MCC=0.337', '\\n', 'Epoch 4:\nval_loss=0.6318 | train_MCC=0.383 val_MCC=0.372', '\\n', 'Epoch 5:\nval_loss=0.6462 | train_MCC=0.368 val_MCC=0.388', '\\n', 'Epoch 6:\nval_loss=0.6308 | train_MCC=0.386 val_MCC=0.376', '\\n', '\\nBest dev MCC=0.388\n(dropout=0.3) -> Testing', '\\n', 'Test MCC=0.397 | Macro-F1=0.698', '\\n', 'Saved\nresults to', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-17_18-48-\n09_symblic_polyrule_reasoning_attempt_0/0-run/process_ForkProcess-\n19/working/experiment_data.npy', '\\n', 'Execution time: 5 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Loading real SPR_BENCH from', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', '\\n=== Dropout 0.1 ===',\n'\\n', 'Epoch 1: val_loss=0.6913 | train_MCC=0.123 val_MCC=-0.025', '\\n', 'Epoch\n2: val_loss=0.6370 | train_MCC=0.305 val_MCC=0.372', '\\n', 'Epoch 3:\nval_loss=0.6486 | train_MCC=0.362 val_MCC=0.299', '\\n', 'Epoch 4:\nval_loss=0.6355 | train_MCC=0.360 val_MCC=0.372', '\\n', 'Epoch 5:\nval_loss=0.6325 | train_MCC=0.368 val_MCC=0.360', '\\n', 'Epoch 6:\nval_loss=0.6398 | train_MCC=0.377 val_MCC=0.384', '\\n', '\\n=== Dropout 0.3 ===',\n'\\n', 'Epoch 1: val_loss=0.7091 | train_MCC=0.049 val_MCC=0.000', '\\n', 'Epoch\n2: val_loss=0.6425 | train_MCC=0.126 val_MCC=0.380', '\\n', 'Epoch 3:\nval_loss=0.6585 | train_MCC=0.293 val_MCC=0.396', '\\n', 'Epoch 4:\nval_loss=0.6317 | train_MCC=0.372 val_MCC=0.372', '\\n', 'Epoch 5:\nval_loss=0.6310 | train_MCC=0.385 val_MCC=0.372', '\\n', 'Epoch 6:\nval_loss=0.6467 | train_MCC=0.387 val_MCC=0.293', '\\n', '\\nBest dev MCC=0.396\n(dropout=0.3) \u2014 evaluating on test', '\\n', 'Test MCC=0.399 | Test\nmacro-F1=0.699', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scie\nntist-v2/experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/0-\nrun/process_ForkProcess-17/working/experiment_data.npy', '\\n', 'Execution time:\n7 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Loading real SPR_BENCH from', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', '\\n=== Dropout 0.1 ===',\n'\\n', 'Epoch 1: val_loss=0.7178 | train_MCC=0.048 val_MCC=0.000', '\\n', 'Epoch\n2: val_loss=0.6383 | train_MCC=0.176 val_MCC=0.344', '\\n', 'Epoch 3:\nval_loss=0.6422 | train_MCC=0.379 val_MCC=0.380', '\\n', 'Epoch 4:\nval_loss=0.6329 | train_MCC=0.379 val_MCC=0.352', '\\n', 'Epoch 5:\nval_loss=0.6339 | train_MCC=0.373 val_MCC=0.376', '\\n', 'Epoch 6:\nval_loss=0.6344 | train_MCC=0.379 val_MCC=0.361', '\\n', '\\n=== Dropout 0.3 ===',\n'\\n', 'Epoch 1: val_loss=0.6764 | train_MCC=0.032 val_MCC=0.056', '\\n', 'Epoch\n2: val_loss=0.6399 | train_MCC=0.169 val_MCC=0.341', '\\n', 'Epoch 3:\nval_loss=0.6464 | train_MCC=0.295 val_MCC=0.376', '\\n', 'Epoch 4:\nval_loss=0.6426 | train_MCC=0.357 val_MCC=0.309', '\\n', 'Epoch 5:\nval_loss=0.6359 | train_MCC=0.371 val_MCC=0.368', '\\n', 'Epoch 6:\nval_loss=0.6349 | train_MCC=0.381 val_MCC=0.349', '\\n', '\\nBest dev MCC=0.380\n(dropout=0.1) \u2014 evaluating on test', '\\n', 'Test MCC=0.394 | Test\nmacro-F1=0.697', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scie\nntist-v2/experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/0-\nrun/process_ForkProcess-18/working/experiment_data.npy', '\\n', 'Execution time:\n9 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Loading real SPR_BENCH from', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', '\\n=== Dropout 0.1 ===',\n'\\n', 'Epoch 1: val_loss=0.7087 | train_MCC=-0.021 val_MCC=0.000', '\\n', 'Epoch\n2: val_loss=0.6585 | train_MCC=0.172 val_MCC=0.340', '\\n', 'Epoch 3:\nval_loss=0.6340 | train_MCC=0.369 val_MCC=0.352', '\\n', 'Epoch 4:\nval_loss=0.6332 | train_MCC=0.343 val_MCC=0.360', '\\n', 'Epoch 5:\nval_loss=0.6733 | train_MCC=0.383 val_MCC=0.236', '\\n', 'Epoch 6:\nval_loss=0.6337 | train_MCC=0.330 val_MCC=0.348', '\\n', '\\n=== Dropout 0.3 ===',\n'\\n', 'Epoch 1: val_loss=0.6652 | train_MCC=0.010 val_MCC=0.368', '\\n', 'Epoch\n2: val_loss=0.6423 | train_MCC=0.234 val_MCC=0.335', '\\n', 'Epoch 3:\nval_loss=0.6358 | train_MCC=0.359 val_MCC=0.333', '\\n', 'Epoch 4:\nval_loss=0.6400 | train_MCC=0.360 val_MCC=0.384', '\\n', 'Epoch 5:\nval_loss=0.6366 | train_MCC=0.375 val_MCC=0.372', '\\n', 'Epoch 6:\nval_loss=0.6446 | train_MCC=0.372 val_MCC=0.388', '\\n', '\\nBest dev MCC=0.388\n(dropout=0.3) \u2014 evaluating on test', '\\n', 'Test MCC=0.388 | Test\nmacro-F1=0.694', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scie\nntist-v2/experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/0-\nrun/process_ForkProcess-16/working/experiment_data.npy', '\\n', 'Execution time:\n6 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Loading real SPR_BENCH from', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', '\\n=== Dropout 0.1 ===',\n'\\n', 'Epoch 1: val_loss=0.6854 | train_MCC=0.002 val_MCC=0.027', '\\n', 'Epoch\n2: val_loss=0.6451 | train_MCC=0.156 val_MCC=0.328', '\\n', 'Epoch 3:\nval_loss=0.6334 | train_MCC=0.363 val_MCC=0.344', '\\n', 'Epoch 4:\nval_loss=0.6765 | train_MCC=0.343 val_MCC=0.161', '\\n', 'Epoch 5:\nval_loss=0.6399 | train_MCC=0.347 val_MCC=0.380', '\\n', 'Epoch 6:\nval_loss=0.6379 | train_MCC=0.383 val_MCC=0.380', '\\n', '\\n=== Dropout 0.3 ===',\n'\\n', 'Epoch 1: val_loss=0.6572 | train_MCC=0.048 val_MCC=0.372', '\\n', 'Epoch\n2: val_loss=0.6546 | train_MCC=0.300 val_MCC=0.314', '\\n', 'Epoch 3:\nval_loss=0.6518 | train_MCC=0.309 val_MCC=0.364', '\\n', 'Epoch 4:\nval_loss=0.6364 | train_MCC=0.370 val_MCC=0.353', '\\n', 'Epoch 5:\nval_loss=0.6480 | train_MCC=0.379 val_MCC=0.376', '\\n', 'Epoch 6:\nval_loss=0.6576 | train_MCC=0.336 val_MCC=0.299', '\\n', '\\nBest dev MCC=0.380\n(dropout=0.1) \u2014 evaluating on test', '\\n', 'Test MCC=0.388 | Test\nmacro-F1=0.694', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scie\nntist-v2/experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/0-\nrun/process_ForkProcess-19/working/experiment_data.npy', '\\n', 'Execution time:\n5 seconds seconds (time limit is 30 minutes).']", ""], "analysis": ["", "", "", "", "", "The execution failed due to an incorrect usage of the `load_dataset` function\nfrom the `datasets` library. Specifically, the `data_files` parameter was\nincorrectly passed a dictionary containing the dataset itself (in-memory data),\ninstead of a file path or URL. This caused an `AttributeError` because the\nlibrary attempted to parse the dictionary as if it were a file path.  To fix\nthis issue, replace the `load_dataset` call in the `make_hf_dataset` function\nwith a method that directly loads in-memory data. Use the `Dataset.from_dict`\nmethod from the `datasets` library to create a dataset from the `data` list\ndirectly. For example:  ```python from datasets import Dataset  def\nmake_hf_dataset(rule_fn, n):     data = []     for i in range(n):         seq =\ngen_seq()         data.append({\"id\": i, \"sequence\": seq, \"label\": rule_fn(seq)})\nreturn Dataset.from_dict(data) ```", "", "", "The training script executed successfully, and the ablation study for the No-\nLayerNorm Transformer model was conducted as intended. The model was trained\nwith two different dropout rates (0.1 and 0.3). The best dev MCC achieved was\n0.396 with a dropout of 0.3, and the test results showed an MCC of 0.399 and a\nmacro-F1 score of 0.699. The experiment data was saved successfully, and no\nerrors or bugs were encountered during execution. Overall, the implementation\naligns with the experimental goals of the ablation study.", "", "The execution of the training script completed successfully without any bugs.\nThe experiment tested a No-LayerNorm Transformer model with two dropout rates\n(0.1 and 0.3). The best validation MCC was achieved with a dropout rate of 0.3,\nand the test MCC and macro-F1 scores were 0.388 and 0.694, respectively. Results\nwere saved as expected, and there is no indication of any errors in the output.", "The execution completed successfully without any bugs. The experiment evaluated\nthe No-LayerNorm Transformer on the SPR_BENCH dataset using two dropout rates\n(0.1 and 0.3). The best validation MCC was achieved with a dropout of 0.1, and\nthe corresponding test MCC was 0.388 with a macro-F1 of 0.694. The results were\nsaved and the loss curves were plotted. The implementation and results align\nwith the experiment's goals.", ""], "exc_type": [null, null, null, null, null, "AttributeError", null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, {"args": ["'dict' object has no attribute 'decode'"], "name": "decode", "obj": "{'id': 0, 'sequence': 'CBBACABBD', 'label': 0}"}, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 67, "<module>", "datasets_list = [synth_dataset_dict(fn) for fn in RULE_FNS]"], ["runfile.py", 67, "<listcomp>", "datasets_list = [synth_dataset_dict(fn) for fn in RULE_FNS]"], ["runfile.py", 60, "synth_dataset_dict", "\"train\": make_hf_dataset(rule_fn, n_train),"], ["runfile.py", 54, "make_hf_dataset", "return load_dataset(\"json\", data_files={\"data\": data}, field=\"data\", split=\"train\")"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 2062, "load_dataset", "builder_instance = load_dataset_builder("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1782, "load_dataset_builder", "dataset_module = dataset_module_factory("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1497, "dataset_module_factory", ").get_module()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 913, "get_module", "data_files = DataFilesDict.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 690, "from_patterns", "else DataFilesList.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 583, "from_patterns", "resolve_pattern("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 344, "resolve_pattern", "if is_relative_path(pattern):"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/utils/file_utils.py", 88, "is_relative_path", "return urlparse(url_or_filename).scheme == \"\" and not os.path.isabs(url_or_filename)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py", 394, "urlparse", "url, scheme, _coerce_result = _coerce_args(url, scheme)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py", 133, "_coerce_args", "return _decode_args(args) + (_encode_result,)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py", 117, "_decode_args", "return tuple(x.decode(encoding, errors) if x else '' for x in args)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py", 117, "<genexpr>", "return tuple(x.decode(encoding, errors) if x else '' for x in args)"]], null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "Matthews correlation coefficient", "lower_is_better": false, "description": "A measure of the quality of binary classifications, ranging from -1 to +1.", "data": [{"dataset_name": "Training set", "final_value": 0.373, "best_value": 0.373}, {"dataset_name": "Validation set", "final_value": 0.2919, "best_value": 0.2919}, {"dataset_name": "Test set", "final_value": 0.3899, "best_value": 0.3899}]}, {"metric_name": "binary cross-entropy loss", "lower_is_better": true, "description": "A loss function used for binary classification tasks, where lower values indicate better performance.", "data": [{"dataset_name": "Training set", "final_value": 0.6213, "best_value": 0.6213}, {"dataset_name": "Validation set", "final_value": 0.6619, "best_value": 0.6619}]}, {"metric_name": "macro F1 score", "lower_is_better": false, "description": "The unweighted mean of F1 scores calculated for each label, useful for imbalanced datasets.", "data": [{"dataset_name": "Test set", "final_value": 0.6949, "best_value": 0.6949}]}]}, {"metric_names": [{"metric_name": "Matthews correlation coefficient", "lower_is_better": false, "description": "A measure of the quality of binary classifications, ranging from -1 (worst) to +1 (best).", "data": [{"dataset_name": "SPR (with_positional_encoding)", "final_value": 0.3839, "best_value": 0.3878}, {"dataset_name": "SPR (no_positional_encoding)", "final_value": 0.3835, "best_value": 0.381}]}, {"metric_name": "binary cross-entropy loss", "lower_is_better": true, "description": "A loss metric used for binary classification tasks, where lower values indicate a better fit.", "data": [{"dataset_name": "SPR (with_positional_encoding)", "final_value": 0.636967, "best_value": 0.615064}, {"dataset_name": "SPR (no_positional_encoding)", "final_value": 0.629401, "best_value": 0.625089}]}, {"metric_name": "macro-averaged F1 score", "lower_is_better": false, "description": "The harmonic mean of precision and recall, averaged across classes, giving equal weight to each class.", "data": [{"dataset_name": "SPR (with_positional_encoding)", "final_value": 0.6919, "best_value": 0.6919}, {"dataset_name": "SPR (no_positional_encoding)", "final_value": 0.6917, "best_value": 0.6917}]}]}, {"metric_names": [{"metric_name": "MCC", "lower_is_better": false, "description": "Matthew's Correlation Coefficient, a measure of the quality of binary classifications.", "data": [{"dataset_name": "transformer", "final_value": 0.3844, "best_value": 0.392}, {"dataset_name": "bag_of_embeddings", "final_value": 0.3611, "best_value": 0.3492}]}, {"metric_name": "BCE loss", "lower_is_better": true, "description": "Binary Cross-Entropy Loss, a measure of the error in binary classification tasks.", "data": [{"dataset_name": "transformer", "final_value": 0.6235, "best_value": 0.6314}, {"dataset_name": "bag_of_embeddings", "final_value": 0.6635, "best_value": 0.6663}]}, {"metric_name": "F1 score", "lower_is_better": false, "description": "Harmonic mean of precision and recall, used to evaluate binary classification models.", "data": [{"dataset_name": "transformer", "final_value": 0.692, "best_value": 0.692}, {"dataset_name": "bag_of_embeddings", "final_value": 0.6798, "best_value": 0.6798}]}]}, {"metric_names": [{"metric_name": "Matthews correlation coefficient", "lower_is_better": false, "description": "A measure of the quality of binary classifications, ranging from -1 to +1.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.3898, "best_value": 0.392}]}, {"metric_name": "loss", "lower_is_better": true, "description": "The objective function value; lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6363, "best_value": 0.6316}]}, {"metric_name": "macro-F1 score", "lower_is_better": false, "description": "The harmonic mean of precision and recall, treating all classes equally.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6949, "best_value": 0.6949}]}]}, {"metric_names": [{"metric_name": "Matthews correlation coefficient", "lower_is_better": false, "description": "A measure of the quality of binary classifications.", "data": [{"dataset_name": "spr", "final_value": 0.3899, "best_value": 0.3899}]}, {"metric_name": "binary cross-entropy loss", "lower_is_better": true, "description": "A loss function used for binary classification tasks.", "data": [{"dataset_name": "spr", "final_value": 0.6456, "best_value": 0.6265}]}, {"metric_name": "macro-averaged F1 score", "lower_is_better": false, "description": "The harmonic mean of precision and recall, averaged across classes with equal weight.", "data": [{"dataset_name": "spr", "final_value": 0.6949, "best_value": 0.6949}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train MCC", "lower_is_better": false, "description": "Matthews Correlation Coefficient for training dataset.", "data": [{"dataset_name": "sinusoidal", "final_value": 0.3682, "best_value": 0.3682}, {"dataset_name": "learned", "final_value": 0.3902, "best_value": 0.3902}]}, {"metric_name": "validation MCC", "lower_is_better": false, "description": "Matthews Correlation Coefficient for validation dataset.", "data": [{"dataset_name": "sinusoidal", "final_value": 0.3879, "best_value": 0.3879}, {"dataset_name": "learned", "final_value": 0.3803, "best_value": 0.3803}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Training loss value.", "data": [{"dataset_name": "sinusoidal", "final_value": 0.6231, "best_value": 0.6231}, {"dataset_name": "learned", "final_value": 0.6103, "best_value": 0.6103}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss value.", "data": [{"dataset_name": "sinusoidal", "final_value": 0.631, "best_value": 0.631}, {"dataset_name": "learned", "final_value": 0.6292, "best_value": 0.6292}]}, {"metric_name": "test MCC", "lower_is_better": false, "description": "Matthews Correlation Coefficient for test dataset.", "data": [{"dataset_name": "sinusoidal", "final_value": 0.3861, "best_value": 0.3861}, {"dataset_name": "learned", "final_value": 0.3831, "best_value": 0.3831}]}, {"metric_name": "test F1 score", "lower_is_better": false, "description": "F1 score for test dataset.", "data": [{"dataset_name": "sinusoidal", "final_value": 0.6929, "best_value": 0.6929}, {"dataset_name": "learned", "final_value": 0.6913, "best_value": 0.6913}]}]}, {"metric_names": [{"metric_name": "MCC", "lower_is_better": false, "description": "Matthews correlation coefficient, a measure of the quality of binary classifications.", "data": [{"dataset_name": "SPR", "final_value": 0.3971, "best_value": 0.3883}]}, {"metric_name": "F1 score", "lower_is_better": false, "description": "F1 score, the harmonic mean of precision and recall.", "data": [{"dataset_name": "SPR", "final_value": 0.698, "best_value": 0.698}]}, {"metric_name": "Loss", "lower_is_better": true, "description": "Loss, measures the error of the model's predictions.", "data": [{"dataset_name": "SPR", "final_value": 0.6308, "best_value": 0.6207}]}]}, {"metric_names": [{"metric_name": "Matthews correlation coefficient", "lower_is_better": false, "description": "A metric used in binary and multiclass classification to measure the quality of predictions.", "data": [{"dataset_name": "training", "final_value": 0.3866, "best_value": 0.3866}, {"dataset_name": "validation", "final_value": 0.2927, "best_value": 0.2927}, {"dataset_name": "test", "final_value": 0.3989, "best_value": 0.3989}]}, {"metric_name": "loss (BCE)", "lower_is_better": true, "description": "Binary Cross-Entropy Loss, a common loss function for classification tasks.", "data": [{"dataset_name": "training", "final_value": 0.6265, "best_value": 0.6265}, {"dataset_name": "validation", "final_value": 0.6467, "best_value": 0.6467}]}, {"metric_name": "macro F1 score", "lower_is_better": false, "description": "The harmonic mean of precision and recall, calculated for each class and averaged.", "data": [{"dataset_name": "test", "final_value": 0.699, "best_value": 0.699}]}]}, {"metric_names": [{"metric_name": "Matthews correlation coefficient", "lower_is_better": false, "description": "A measure of the quality of binary classifications.", "data": [{"dataset_name": "training", "final_value": 0.3808, "best_value": 0.3808}, {"dataset_name": "validation", "final_value": 0.3494, "best_value": 0.3494}, {"dataset_name": "test", "final_value": 0.3936, "best_value": 0.3936}]}, {"metric_name": "loss (BCE)", "lower_is_better": true, "description": "Binary cross-entropy loss, commonly used for binary classification tasks.", "data": [{"dataset_name": "training", "final_value": 0.6277, "best_value": 0.6277}, {"dataset_name": "validation", "final_value": 0.6349, "best_value": 0.6349}]}, {"metric_name": "macro F1 score", "lower_is_better": false, "description": "The macro-averaged F1 score, which calculates F1 score for each label and then averages them.", "data": [{"dataset_name": "test", "final_value": 0.6968, "best_value": 0.6968}]}]}, {"metric_names": [{"metric_name": "Matthews correlation coefficient", "lower_is_better": false, "description": "A measure of the quality of binary classifications.", "data": [{"dataset_name": "training", "final_value": 0.3716, "best_value": 0.3716}, {"dataset_name": "validation", "final_value": 0.3879, "best_value": 0.3879}, {"dataset_name": "test", "final_value": 0.3878, "best_value": 0.3878}]}, {"metric_name": "loss (BCE)", "lower_is_better": true, "description": "Binary Cross-Entropy loss, used for binary classification tasks.", "data": [{"dataset_name": "training", "final_value": 0.6264, "best_value": 0.6264}, {"dataset_name": "validation", "final_value": 0.6446, "best_value": 0.6446}]}, {"metric_name": "macro F1 score", "lower_is_better": false, "description": "A metric that calculates the F1 score for each label, and then computes their unweighted mean.", "data": [{"dataset_name": "test", "final_value": 0.6939, "best_value": 0.6939}]}]}, {"metric_names": [{"metric_name": "Matthews correlation coefficient", "lower_is_better": false, "description": "A measure of the quality of binary classifications.", "data": [{"dataset_name": "training", "final_value": 0.336, "best_value": 0.336}, {"dataset_name": "validation", "final_value": 0.2986, "best_value": 0.2986}, {"dataset_name": "test", "final_value": 0.3876, "best_value": 0.3876}]}, {"metric_name": "loss (BCE)", "lower_is_better": true, "description": "Binary Cross-Entropy loss, a measure of classification error.", "data": [{"dataset_name": "training", "final_value": 0.6351, "best_value": 0.6351}, {"dataset_name": "validation", "final_value": 0.6576, "best_value": 0.6576}]}, {"metric_name": "macro F1 score", "lower_is_better": false, "description": "A measure of the balance between precision and recall for multi-class classification.", "data": [{"dataset_name": "test", "final_value": 0.6938, "best_value": 0.6938}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, false, false, false, false, true, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/loss_curve_transformer.png", "../../logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_mcc_curves.png", "../../logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_dev_mcc_bar.png", "../../logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_confusion_matrix.png", "../../logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/loss_with_positional_encoding.png", "../../logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/loss_no_positional_encoding.png", "../../logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_loss_curve_with_positional_encoding.png", "../../logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_MCC_curve_with_positional_encoding.png", "../../logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_confusion_matrix_with_positional_encoding.png", "../../logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_loss_curve_no_positional_encoding.png", "../../logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_MCC_curve_no_positional_encoding.png", "../../logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_confusion_matrix_no_positional_encoding.png", "../../logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_test_MCC_comparison.png"], ["../../logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/loss_curve_transformer.png", "../../logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/loss_curve_bag_of_embeddings.png", "../../logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/mcc_curve_transformer.png", "../../logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/mcc_curve_bag_of_embeddings.png", "../../logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/confusion_matrix_transformer.png", "../../logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/confusion_matrix_bag_of_embeddings.png", "../../logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/test_mcc_comparison.png"], ["../../logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/loss_curve_max_pool.png", "../../logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/SPR_BENCH_MCC_curves.png", "../../logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/SPR_BENCH_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/loss_curve_no_padmask.png", "../../logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_loss_curve.png", "../../logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_mcc_curve.png", "../../logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_test_metrics.png", "../../logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_confusion_matrix.png"], [], ["../../logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/loss_curve_sinusoidal.png", "../../logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/loss_curve_learned.png", "../../logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_loss_curve_sinusoidal.png", "../../logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_loss_curve_learned.png", "../../logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_test_test_mcc_comparison.png", "../../logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_test_test_f1_comparison.png"], ["../../logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/loss_curve_no_ffn.png", "../../logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/SPR_no_ffn_loss_curve.png", "../../logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/SPR_no_ffn_MCC_curve.png", "../../logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/SPR_no_ffn_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/loss_curve_no_layernorm.png", "../../logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_loss_curve.png", "../../logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_mcc_curve.png", "../../logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_confusion_counts.png", "../../logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_label_distribution.png"], ["../../logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/loss_curve_no_layernorm.png", "../../logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_loss_curve.png", "../../logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_mcc_curve.png", "../../logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_confusion_counts.png", "../../logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_label_distribution.png"], ["../../logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/loss_curve_no_layernorm.png", "../../logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_loss_curve.png", "../../logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_mcc_curve.png", "../../logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_confusion_counts.png", "../../logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_label_distribution.png"], ["../../logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/loss_curve_no_layernorm.png", "../../logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_loss_curve.png", "../../logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_mcc_curve.png", "../../logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_confusion_counts.png", "../../logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_label_distribution.png"], ["../../logs/0-run/experiment_results/seed_aggregation_473cf62973264b9d9bf374358dbe9a48/SPR_no_layernorm_loss_curve_aggregate.png", "../../logs/0-run/experiment_results/seed_aggregation_473cf62973264b9d9bf374358dbe9a48/SPR_no_layernorm_mcc_curve_aggregate.png", "../../logs/0-run/experiment_results/seed_aggregation_473cf62973264b9d9bf374358dbe9a48/SPR_no_layernorm_confusion_counts_aggregate.png"]], "plot_paths": [["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/loss_curve_transformer.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_loss_curves.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_mcc_curves.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_dev_mcc_bar.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_confusion_matrix.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_test_metrics.png"], ["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/loss_with_positional_encoding.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/loss_no_positional_encoding.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_loss_curve_with_positional_encoding.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_MCC_curve_with_positional_encoding.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_confusion_matrix_with_positional_encoding.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_loss_curve_no_positional_encoding.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_MCC_curve_no_positional_encoding.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_confusion_matrix_no_positional_encoding.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_test_MCC_comparison.png"], ["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/loss_curve_transformer.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/loss_curve_bag_of_embeddings.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/mcc_curve_transformer.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/mcc_curve_bag_of_embeddings.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/confusion_matrix_transformer.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/confusion_matrix_bag_of_embeddings.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/test_mcc_comparison.png"], ["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/loss_curve_max_pool.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/SPR_BENCH_loss_curves.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/SPR_BENCH_MCC_curves.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/SPR_BENCH_test_metrics.png"], ["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/loss_curve_no_padmask.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_loss_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_mcc_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_test_metrics.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_confusion_matrix.png"], [], ["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/loss_curve_sinusoidal.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/loss_curve_learned.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_loss_curve_sinusoidal.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_loss_curve_learned.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_test_test_mcc_comparison.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_test_test_f1_comparison.png"], ["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/loss_curve_no_ffn.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/SPR_no_ffn_loss_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/SPR_no_ffn_MCC_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/SPR_no_ffn_confusion_matrix.png"], ["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/loss_curve_no_layernorm.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_loss_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_mcc_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_confusion_counts.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_label_distribution.png"], ["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/loss_curve_no_layernorm.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_loss_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_mcc_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_confusion_counts.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_label_distribution.png"], ["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/loss_curve_no_layernorm.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_loss_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_mcc_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_confusion_counts.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_label_distribution.png"], ["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/loss_curve_no_layernorm.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_loss_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_mcc_curve.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_confusion_counts.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_label_distribution.png"], ["experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/seed_aggregation_473cf62973264b9d9bf374358dbe9a48/SPR_no_layernorm_loss_curve_aggregate.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/seed_aggregation_473cf62973264b9d9bf374358dbe9a48/SPR_no_layernorm_mcc_curve_aggregate.png", "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/seed_aggregation_473cf62973264b9d9bf374358dbe9a48/SPR_no_layernorm_confusion_counts_aggregate.png"]], "plot_analyses": [[{"analysis": "The loss curve for the Transformer model shows a decreasing trend for the training loss, indicating that the model is learning during training. However, the validation loss exhibits fluctuations, suggesting that the model might not be generalizing well or that the training process is unstable. The spike in validation loss around the 6th epoch could indicate overfitting or a learning rate issue.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/loss_curve_transformer.png"}, {"analysis": "The loss curves for different dropout rates (dp=0.1 and dp=0.3) reveal that a lower dropout rate (dp=0.1) leads to more stable and lower validation loss compared to dp=0.3. This suggests that higher dropout may be overly regularizing the model, leading to suboptimal performance on the validation set.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_loss_curves.png"}, {"analysis": "The MCC curves show an increasing trend initially, indicating that the model is improving in its classification ability. However, the validation MCC for dp=0.3 drops in later epochs, while dp=0.1 maintains a more consistent performance. This further supports the observation that dp=0.1 is a better choice for this task.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_mcc_curves.png"}, {"analysis": "The bar chart comparing final MCC values for different dropout rates shows that dp=0.1 achieves a higher MCC than dp=0.3. This confirms that a lower dropout rate is more effective for this task.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_dev_mcc_bar.png"}, {"analysis": "The confusion matrix shows that the model is better at predicting True 1 than True 0, as evidenced by the higher count of correctly predicted True 1 (357) compared to True 0 (338). However, the misclassification rates (148 for True 0 and 157 for True 1) suggest room for improvement in both classes.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_confusion_matrix.png"}, {"analysis": "The test metrics chart shows that the Macro-F1 score is significantly higher than the MCC. This indicates that while the overall balance between precision and recall is good, the model's correlation-based performance (MCC) is relatively lower, suggesting potential issues in handling imbalanced predictions or capturing the underlying relationships in the data.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8af726a4e254464ab5b3062661aa2bbd_proc_3336029/spr_bench_test_metrics.png"}], [{"analysis": "The loss curve shows that the model with positional encoding exhibits a steady decline in training loss over epochs, with validation loss following a similar trend but stabilizing around epoch 3. This indicates that the model is learning effectively without significant overfitting, as the gap between training and validation loss is minimal.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/loss_with_positional_encoding.png"}, {"analysis": "The loss curve without positional encoding shows a similar decline in training loss, but the validation loss exhibits a sharp increase at epoch 1 before stabilizing. This suggests that the model struggles to generalize initially but adjusts over time. The absence of positional encoding might affect the model's ability to capture sequence dependencies effectively.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/loss_no_positional_encoding.png"}, {"analysis": "This loss curve reiterates the performance of the model with positional encoding. The training loss decreases steadily, and the validation loss stabilizes early, reinforcing the earlier observation that positional encoding aids in effective learning and generalization.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_loss_curve_with_positional_encoding.png"}, {"analysis": "The MCC curve with positional encoding shows a consistent improvement in both training and validation MCC over epochs, with validation MCC closely tracking the training MCC. This indicates that the model is not only learning effectively but also generalizing well to unseen data.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_MCC_curve_with_positional_encoding.png"}, {"analysis": "The confusion matrix for the model with positional encoding reveals relatively balanced performance across classes, with a slight bias towards false negatives (159) compared to false positives (149). This indicates that the model is slightly conservative in predicting the positive class.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_confusion_matrix_with_positional_encoding.png"}, {"analysis": "The loss curve for the model without positional encoding shows a steady decline in training loss, but the validation loss fluctuates more, suggesting less stability in generalization compared to the model with positional encoding.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_loss_curve_no_positional_encoding.png"}, {"analysis": "The MCC curve without positional encoding shows an initial drop in validation MCC before improving and stabilizing. This indicates that the model struggles with generalization early on, likely due to the absence of positional encoding, which could hinder its ability to capture sequence-level patterns effectively.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_MCC_curve_no_positional_encoding.png"}, {"analysis": "The confusion matrix for the model without positional encoding shows a similar pattern to the one with positional encoding, with slightly higher false positives (155) and marginally lower false negatives (153). This suggests that the absence of positional encoding may lead to a marginally less conservative model.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_confusion_matrix_no_positional_encoding.png"}, {"analysis": "The bar chart comparing test MCC for models with and without positional encoding shows a slight advantage for the model with positional encoding. This indicates that positional encoding contributes positively to the model's ability to generalize to unseen data.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_06227a0558ba414888e9901088a64960_proc_3341727/SPR_test_MCC_comparison.png"}], [{"analysis": "This plot illustrates the loss curves for the transformer model during training and validation. The training loss decreases over time, but the validation loss exhibits fluctuations, particularly around epoch 6. This behavior may indicate overfitting or instability in the learning process at certain points. The gap between training and validation loss is relatively small, suggesting that the model generalizes reasonably well, but the peak in validation loss suggests potential challenges with certain validation samples.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/loss_curve_transformer.png"}, {"analysis": "For the bag-of-embeddings model, the loss curves show a steady decline for both training and validation datasets. This indicates that the model is learning effectively and generalizing well without significant overfitting. The absence of abrupt spikes in the validation loss suggests a more stable training process compared to the transformer.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/loss_curve_bag_of_embeddings.png"}, {"analysis": "This plot shows the Matthews Correlation Coefficient (MCC) for the transformer model on the training and validation datasets. The MCC values fluctuate significantly, with a sharp drop at epoch 6 followed by recovery. The instability in MCC suggests that the model's predictions are inconsistent during certain epochs, likely due to the complex nature of the task or insufficient regularization.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/mcc_curve_transformer.png"}, {"analysis": "The MCC plot for the bag-of-embeddings model shows a more consistent trend compared to the transformer. While there is a slight dip around epoch 6, the model quickly recovers and maintains a stable MCC for both training and validation datasets. This indicates that the bag-of-embeddings model is better at maintaining prediction consistency over epochs.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/mcc_curve_bag_of_embeddings.png"}, {"analysis": "The confusion matrix for the transformer model reveals that it correctly predicts a substantial number of samples in both classes. However, there is a notable imbalance in misclassifications, with more false negatives (163) compared to false positives (145). This suggests that the model may be biased towards predicting one class over the other.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/confusion_matrix_transformer.png"}, {"analysis": "The confusion matrix for the bag-of-embeddings model shows a similar pattern of misclassifications as the transformer, but with slightly fewer false negatives (143) and more false positives (176). This indicates a different bias compared to the transformer, with the bag-of-embeddings model favoring the opposite class in some cases.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/confusion_matrix_bag_of_embeddings.png"}, {"analysis": "This bar chart compares the test MCC of the transformer and bag-of-embeddings models. The transformer achieves a slightly higher MCC (0.38) than the bag-of-embeddings model (0.36). While the difference is small, it suggests that the transformer has a marginal edge in handling the complexity of the task. However, the performance gap is not substantial, indicating that both models are relatively comparable in their ability to classify sequences governed by poly-factor symbolic rules.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_cf6c600544354624af8d8a1860baf831_proc_3341728/test_mcc_comparison.png"}], [{"analysis": "This plot shows the loss curves for training and validation using a MAX pooling strategy. The training and validation loss curves exhibit significant oscillations, with sharp peaks and troughs, indicating instability in the training process. The validation loss generally follows the trend of the training loss but with a slightly smoother trajectory. This instability could be due to learning rate fluctuations, model architecture issues, or overfitting. Despite the oscillations, there is a gradual decrease in loss over epochs, suggesting some learning progress.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/loss_curve_max_pool.png"}, {"analysis": "This plot is another representation of the loss curves for training and validation using a Transformer with MAX pooling. The trends are consistent with the earlier plot, showing oscillatory behavior with sharp peaks and troughs. The validation curve closely mirrors the training curve, suggesting that the model is not overfitting significantly, but the oscillations still point to potential instability in the optimization process. Further investigation into hyperparameters or regularization techniques may be needed to stabilize training.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the Matthews Correlation Coefficient (MCC) for training and validation over epochs. The MCC curves show a sharp increase during the initial epochs, followed by a significant drop midway, and a recovery towards the end. This pattern aligns with the oscillatory behavior observed in the loss curves, reinforcing the hypothesis of training instability. The MCC values for training and validation are closely aligned, indicating a lack of overfitting but also suggesting that the model struggles to consistently capture the underlying patterns in the data.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/SPR_BENCH_MCC_curves.png"}, {"analysis": "This plot displays the test metrics, specifically the Matthews Correlation Coefficient (MCC) and F1 score, for the Transformer with MAX pooling. The MCC value of 0.39 indicates moderate performance, while the F1 score of 0.695 suggests better performance in balancing precision and recall. The disparity between MCC and F1 highlights potential issues with class imbalance or the model's ability to handle certain rule complexities effectively. These results suggest room for improvement, particularly in optimizing the model for higher MCC values to enhance overall reliability.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f2eba17077454b8ea1998869cbe13395_proc_3341729/SPR_BENCH_test_metrics.png"}], [{"analysis": "The loss curve for both training and validation shows a general downward trend, indicating that the model is learning effectively. However, there is a noticeable spike in loss around the 6th epoch, which may indicate instability or overfitting issues at that stage. The validation loss is consistently higher than the training loss, suggesting a potential gap in generalization.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/loss_curve_no_padmask.png"}, {"analysis": "This loss curve reinforces the observations from the earlier plot. While the overall trend is downward, the spike in loss at the 6th epoch is prominent. This might suggest a need to revisit the training process to address potential overfitting or optimization instability.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_loss_curve.png"}, {"analysis": "The Matthews Correlation Coefficient (MCC) curves for training and validation show an overall upward trend, which is a positive sign of improving model performance. However, the sharp drop around the 6th epoch aligns with the loss spikes observed earlier, indicating a temporary breakdown in model performance. This drop suggests that the training process might require further tuning, such as adjusting the learning rate or introducing regularization.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_mcc_curve.png"}, {"analysis": "The test metrics show an MCC of 0.390 and an F1 score of 0.695. While the F1 score is relatively high, indicating good balance between precision and recall, the MCC value is moderate, revealing room for improvement in capturing the overall correlation between predictions and true labels. This suggests that the model performs reasonably well but struggles with certain cases.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_test_metrics.png"}, {"analysis": "The confusion matrix indicates that the model correctly classifies a significant portion of both positive and negative samples. However, there are notable misclassifications, particularly 157 false negatives and 148 false positives. This imbalance suggests that the model may benefit from techniques to handle class imbalance or improve its sensitivity and specificity.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_f9639073656545ef9eefde1a358ef47c_proc_3341730/spr_no_padmask_confusion_matrix.png"}], [], [{"analysis": "The loss curves for the sinusoidal variant show a high degree of oscillation, particularly in the training loss, which suggests potential instability during training. The validation loss also exhibits fluctuations, indicating that the model may struggle to generalize well. However, the overall trend suggests a slight decrease in loss for both training and validation as training progresses, though the fluctuations make it difficult to ascertain clear convergence.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/loss_curve_sinusoidal.png"}, {"analysis": "The loss curves for the learned variant demonstrate a more stable training process compared to the sinusoidal variant. Both training and validation losses show a general downward trend, with fewer oscillations in the validation loss. This indicates that the learned variant may generalize better and is less prone to instability during training. However, the validation loss starts to increase slightly towards the end, suggesting potential overfitting.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/loss_curve_learned.png"}, {"analysis": "This plot reiterates the observed behavior of the sinusoidal variant, highlighting the oscillatory nature of the training process. The trends and fluctuations in both training and validation losses are consistent with the first plot, emphasizing the instability and potential challenges in achieving convergence.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_loss_curve_sinusoidal.png"}, {"analysis": "This plot corroborates the earlier observation that the learned variant exhibits a more stable training process. The overall downward trend in losses and reduced oscillations in validation loss suggest that this variant is better suited for the SPR task. However, the slight increase in validation loss towards the end is a point of concern for overfitting.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_loss_curve_learned.png"}, {"analysis": "The test MCC comparison shows that the learned variant slightly outperforms the sinusoidal variant in terms of test MCC. This suggests that the learned variant has better predictive power and generalization ability for the classification task. However, the difference between the two is not substantial, indicating room for further improvement.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_test_test_mcc_comparison.png"}, {"analysis": "The test F1 comparison reveals a similar trend as the MCC comparison, with the learned variant outperforming the sinusoidal variant. The higher F1 score for the learned variant indicates better balance between precision and recall, making it more effective for the SPR classification task.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_3c09a4163dfc413ebf953d8a4a75308b_proc_3341727/spr_test_test_f1_comparison.png"}], [{"analysis": "The loss curves for both training and validation exhibit a general downward trend, indicating that the model is learning over time. However, there are fluctuations in the validation loss, which may suggest some instability in the model's generalization ability or sensitivity to the data. The gap between training and validation loss is relatively small, which is a positive sign as it suggests limited overfitting. The periodic spikes in training loss could be due to optimization challenges or the learning rate schedule.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/loss_curve_no_ffn.png"}, {"analysis": "This plot also shows the loss curves for training and validation. Similar to the previous plot, there is a downward trend overall, but the validation loss shows more variability. This variability may indicate that the model struggles with certain validation examples or that the validation set is not fully representative of the training set. The small gap between training and validation loss suggests that the model is not heavily overfitting.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/SPR_no_ffn_loss_curve.png"}, {"analysis": "The MCC (Matthews Correlation Coefficient) plot shows an upward trend for both training and validation metrics, which is a good indicator of improving classification performance. However, the sharp dip in training MCC at one point suggests a temporary optimization issue or instability in the training process. The validation MCC follows the training MCC closely, which is a positive sign of generalization. The overall MCC values, however, are relatively low, indicating room for improvement in the model's performance.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/SPR_no_ffn_MCC_curve.png"}, {"analysis": "The confusion matrix indicates that the model has a balanced performance in predicting both classes, with 349 correct predictions for each class. However, there are also significant misclassifications (137 false positives and 165 false negatives), highlighting areas where the model can be improved. The overall accuracy appears moderate, but the confusion matrix suggests that the model might benefit from additional tuning or architectural changes to handle the complexities of the SPR task.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_c78a45dfa87049ea9220a2bb10acaf7b_proc_3341730/SPR_no_ffn_confusion_matrix.png"}], [{"analysis": "The loss curves for training and validation indicate instability in the learning process. The training loss shows significant fluctuations, particularly around epoch 6, where a sharp spike is observed. Validation loss follows a similar pattern, with a noticeable increase at the same point. This suggests potential issues with overfitting or inadequate regularization, possibly due to the absence of LayerNorm in the architecture.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/loss_curve_no_layernorm.png"}, {"analysis": "This plot mirrors the earlier loss curve and reinforces the observation of instability in the loss trends. The sharp rise at epoch 6 is particularly concerning as it indicates that the model struggles to maintain consistent learning. Both training and validation losses decrease after this spike, but the overall pattern suggests that the model's learning process is not smooth.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_loss_curve.png"}, {"analysis": "The MCC (Matthews Correlation Coefficient) plot shows a different trend. While there is a sharp dip at epoch 6, the MCC values for both training and validation recover and stabilize towards the later epochs. This suggests that despite the loss instability, the model's predictive capability improves as training progresses. However, the dip indicates a potential sensitivity to certain training dynamics or data characteristics.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_mcc_curve.png"}, {"analysis": "The confusion matrix counts reveal that the model performs reasonably well in distinguishing between true positives (TP) and true negatives (TN). However, the number of false positives (FP) and false negatives (FN) is non-negligible. This indicates room for improvement in reducing misclassifications, particularly in handling edge cases or ambiguous sequences.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_confusion_counts.png"}, {"analysis": "The label distribution plot shows a good alignment between the ground truth and predictions for both classes (0 and 1). This suggests that the model is not biased towards any particular class and achieves a balanced classification performance. However, given the earlier observations on loss instability and misclassifications, further fine-tuning may be needed to enhance overall accuracy.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_a29dea39105247a4bd6465be93403dea_proc_3341728/SPR_no_layernorm_label_distribution.png"}], [{"analysis": "This plot shows the loss curves for training and validation using a No-LayerNorm Transformer. The training loss fluctuates significantly, indicating instability during optimization, possibly due to the absence of Layer Normalization. The validation loss, however, is more stable and shows a gradual decrease, suggesting some learning progress. The gap between training and validation losses indicates potential overfitting or optimization difficulties.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/loss_curve_no_layernorm.png"}, {"analysis": "The training and validation loss curves are displayed in this plot. The trends are similar to the previous plot, with training loss showing high fluctuations and validation loss being relatively stable. The overall decrease in validation loss suggests the model is learning, but the instability in training loss highlights issues with the optimization process, likely due to the lack of Layer Normalization.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_loss_curve.png"}, {"analysis": "This plot depicts the Matthews Correlation Coefficient (MCC) for training and validation. The MCC values for training drop to near zero at certain points, reflecting the instability observed in the training loss curves. Validation MCC shows a more consistent trend, with occasional dips. The general upward trend in MCC for both training and validation indicates some improvement in classification performance, but the variability suggests optimization challenges.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_mcc_curve.png"}, {"analysis": "The confusion matrix counts for the test set are shown here. True Positives (TP) and True Negatives (TN) are higher compared to False Positives (FP) and False Negatives (FN), indicating the model's ability to correctly classify a significant portion of the data. However, the presence of a notable number of FP and FN suggests room for improvement in the model's precision and recall.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_confusion_counts.png"}, {"analysis": "This plot compares the label distribution of ground truth and predictions on the test set. The distributions are well-aligned, indicating that the model's predictions are balanced and do not exhibit significant bias toward any class. This is a positive outcome for ensuring fairness in classification.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/SPR_no_layernorm_label_distribution.png"}], [{"analysis": "This plot shows the training and validation loss curves for a model without LayerNorm. The training loss decreases rapidly initially, indicating that the model learns effectively in the early epochs. However, the validation loss exhibits fluctuations, suggesting potential overfitting or instability in generalization. The absence of LayerNorm might contribute to these fluctuations as it affects model stability during training.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/loss_curve_no_layernorm.png"}, {"analysis": "This plot also represents the training and validation loss but extends the view for more epochs. The same trend of fluctuating validation loss is observed, reinforcing the hypothesis of instability in the model's generalization. The training loss stabilizes at a low value, indicating that the model has successfully minimized the loss on the training data.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_loss_curve.png"}, {"analysis": "This plot illustrates the Matthews Correlation Coefficient (MCC) for training and validation. The MCC for validation fluctuates significantly, while the training MCC shows a more stable increase. This further supports the observation that the model struggles with consistent generalization across epochs, possibly due to the lack of LayerNorm.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_mcc_curve.png"}, {"analysis": "The confusion matrix counts for the test set indicate that the model performs reasonably well, with a higher count of true positives (TP) and true negatives (TN) compared to false positives (FP) and false negatives (FN). However, the FN count suggests that the model might struggle with certain types of sequences, leading to missed classifications.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_confusion_counts.png"}, {"analysis": "The label distribution plot for the test set shows that the model's predictions align closely with the ground truth distribution. This indicates that the model does not exhibit significant bias towards any particular class, a positive sign for balanced classification performance.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/SPR_no_layernorm_label_distribution.png"}], [{"analysis": "The plot shows the BCE loss for both training and validation sets over epochs. The training loss decreases initially, indicating the model is learning. However, there is a noticeable fluctuation in the validation loss, suggesting instability or overfitting. The lack of LayerNorm could be contributing to this behavior as it may hinder stable training dynamics.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/loss_curve_no_layernorm.png"}, {"analysis": "This plot also depicts the training and validation BCE loss. The trends are consistent with the previous plot, showing a decrease in training loss but significant fluctuations in validation loss. This highlights potential issues with generalization and robustness of the model without LayerNorm.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_loss_curve.png"}, {"analysis": "This plot shows the Matthews Correlation Coefficient (MCC) for training and validation. While the MCC for validation peaks early and then fluctuates, the training MCC shows a sharp decline at one point, indicating instability during training. This suggests that the lack of LayerNorm might be affecting the model's ability to maintain consistent performance.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_mcc_curve.png"}, {"analysis": "The confusion matrix counts show that the model has a higher number of true positives (TP) and true negatives (TN) compared to false positives (FP) and false negatives (FN). While the model is making more correct predictions than incorrect ones, the imbalance in errors (FP > FN) might indicate a bias or a specific weakness in handling certain classes.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_confusion_counts.png"}, {"analysis": "The label distribution plot for the test set shows a good alignment between the ground truth and predictions for both classes. This suggests that the model is not significantly biased towards one class, which is a positive outcome. However, this does not fully address the fluctuations and instability observed in the loss and MCC plots.", "plot_path": "experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/SPR_no_layernorm_label_distribution.png"}], []], "vlm_feedback_summary": ["The results highlight that a lower dropout rate (dp=0.1) improves model\nstability and performance. The Transformer model shows learning capability but\nstruggles with generalization, as indicated by unstable validation loss. The MCC\nand confusion matrix analyses reveal that while the model performs reasonably\nwell, there is room for improvement in class balance and capturing complex\nrelationships in the data.", "The analysis of the plots highlights the importance of positional encoding in\nimproving model performance, particularly in terms of generalization and\nstability. The models with positional encoding consistently show better\nvalidation loss trends, higher MCC scores, and slightly better test MCC compared\nto those without positional encoding.", "The plots provide insights into the performance and behavior of the transformer\nand bag-of-embeddings models. The transformer shows higher test MCC but exhibits\ninstability during training, while the bag-of-embeddings model demonstrates more\nstable learning. Both models face challenges with misclassifications, as seen in\nthe confusion matrices, and their performance is relatively close, highlighting\nthe complexity of the task.", "The plots reveal significant oscillations in loss and MCC curves during\ntraining, indicating instability in the optimization process. While the model\nshows some learning progress, the moderate MCC and relatively better F1 score on\nthe test set suggest a need for further fine-tuning and potentially addressing\nclass imbalance or rule complexity challenges.", "The plots reveal that the model shows promise in learning symbolic poly-factor\nrules, with overall improving trends in loss and MCC. However, the spike in loss\nand drop in MCC around the 6th epoch indicate training instability that needs to\nbe addressed. The test metrics and confusion matrix suggest reasonable\nperformance but highlight areas for improvement, particularly in handling\nmisclassifications and achieving better generalization.", "[]", "The analysis highlights that the learned variant generally performs better than\nthe sinusoidal variant, with more stable training dynamics and superior test\nmetrics. However, both variants exhibit areas for improvement, particularly in\nterms of generalization and mitigating overfitting.", "The plots indicate that the model is learning and generalizing to some extent,\nbut there are signs of instability and areas for improvement. The loss curves\nshow a general downward trend with some fluctuations, and the MCC plot suggests\nimproving performance despite occasional dips. The confusion matrix highlights\nmoderate accuracy with significant misclassifications, suggesting potential for\nfurther optimization.", "The provided plots reveal instability in the training process, particularly with\nfluctuations in loss and MCC metrics. Despite this, the model demonstrates\nbalanced label predictions and reasonable classification performance.\nImprovements in regularization and handling of edge cases are recommended to\nachieve better stability and accuracy.", "The plots reveal significant insights into the performance and challenges of the\nNo-LayerNorm Transformer model. While the model demonstrates some learning\ncapability, as evidenced by the decreasing validation loss and improving MCC,\nthe instability in training loss and MCC highlights optimization issues. The\nconfusion matrix and label distribution plots show that the model achieves a\nreasonable balance in predictions but still has room for improvement in\nprecision and recall. Addressing the instability, possibly by incorporating\nLayer Normalization or other stabilization techniques, could enhance\nperformance.", "The analysis highlights that the absence of LayerNorm in the model leads to\ninstability in validation performance, as evidenced by fluctuating loss and MCC\nmetrics. While the model achieves reasonable performance on the test set, with\nbalanced label predictions and a good number of true positives and true\nnegatives, the fluctuations in validation metrics suggest a need for improved\nstability mechanisms, such as incorporating normalization techniques.", "The results indicate that the model without LayerNorm is learning but exhibits\ninstability and generalization issues. Training loss decreases as expected, but\nvalidation loss and MCC show significant fluctuations, pointing to challenges in\nconsistent performance. The confusion matrix and label distribution suggest\nreasonable performance, but further analysis and enhancements, such as\nincorporating LayerNorm, are needed to improve robustness and stability.", "[]"], "exec_time": [10.26547908782959, 11.207462549209595, 6.137336015701294, 5.459230899810791, 8.945488214492798, 1.2300975322723389, 8.29571795463562, 5.098167181015015, 7.7845799922943115, 9.466980218887329, 6.138337850570679, 5.541296720504761, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[]"], ["['with_positional_encoding']"], ["['transformer'", "'bag-of-embeddings']"], ["[]"], ["[]"], [], ["[\"learned\"]"], ["[\"SPR\"]"], ["[]"], ["[]"], ["[]"], ["[]"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths & data loading ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    logs = experiment_data.get(\"transformer\", {})\n    epochs_info = logs.get(\"epochs\", [])\n    tr_loss = logs.get(\"losses\", {}).get(\"train\", [])\n    val_loss = logs.get(\"losses\", {}).get(\"val\", [])\n    tr_mcc = logs.get(\"metrics\", {}).get(\"train_MCC\", [])\n    val_mcc = logs.get(\"metrics\", {}).get(\"val_MCC\", [])\n\n    # ------------- organise by dropout -------------\n    by_dp = {}\n    for i, (dp, ep) in enumerate(epochs_info):\n        d = by_dp.setdefault(\n            dp,\n            {\"epoch\": [], \"tr_loss\": [], \"val_loss\": [], \"tr_mcc\": [], \"val_mcc\": []},\n        )\n        d[\"epoch\"].append(ep)\n        d[\"tr_loss\"].append(tr_loss[i] if i < len(tr_loss) else np.nan)\n        d[\"val_loss\"].append(val_loss[i] if i < len(val_loss) else np.nan)\n        d[\"tr_mcc\"].append(tr_mcc[i] if i < len(tr_mcc) else np.nan)\n        d[\"val_mcc\"].append(val_mcc[i] if i < len(val_mcc) else np.nan)\n\n    # -------------------- 1. loss curves --------------------\n    try:\n        plt.figure(figsize=(6, 4))\n        for dp, d in by_dp.items():\n            plt.plot(d[\"epoch\"], d[\"tr_loss\"], label=f\"Train dp={dp}\")\n            plt.plot(d[\"epoch\"], d[\"val_loss\"], linestyle=\"--\", label=f\"Val dp={dp}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"BCE Loss\")\n        plt.title(\"Loss Curves \u2014 synthetic SPR_BENCH\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"spr_bench_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error plotting loss curves: {e}\")\n        plt.close()\n\n    # -------------------- 2. MCC curves --------------------\n    try:\n        plt.figure(figsize=(6, 4))\n        for dp, d in by_dp.items():\n            plt.plot(d[\"epoch\"], d[\"tr_mcc\"], label=f\"Train dp={dp}\")\n            plt.plot(d[\"epoch\"], d[\"val_mcc\"], linestyle=\"--\", label=f\"Val dp={dp}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"MCC\")\n        plt.title(\"MCC Curves \u2014 synthetic SPR_BENCH\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"spr_bench_mcc_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error plotting MCC curves: {e}\")\n        plt.close()\n\n    # -------------------- 3. bar chart dev MCC --------------------\n    try:\n        dps, final_dev = [], []\n        for dp, d in by_dp.items():\n            if d[\"val_mcc\"]:\n                dps.append(str(dp))\n                final_dev.append(d[\"val_mcc\"][-1])\n        plt.figure(figsize=(5, 4))\n        plt.bar(dps, final_dev, color=\"steelblue\")\n        plt.xlabel(\"Dropout\")\n        plt.ylabel(\"Final Dev MCC\")\n        plt.title(\"Final Dev MCC by Dropout \u2014 synthetic SPR_BENCH\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"spr_bench_dev_mcc_bar.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error plotting dev MCC bar chart: {e}\")\n        plt.close()\n\n    # -------------------- 4. confusion matrix --------------------\n    try:\n        y_pred = np.array(logs.get(\"predictions\", []))\n        y_true = np.array(logs.get(\"ground_truth\", []))\n        if y_pred.size and y_true.size:\n            tp = np.sum((y_true == 1) & (y_pred == 1))\n            tn = np.sum((y_true == 0) & (y_pred == 0))\n            fp = np.sum((y_true == 0) & (y_pred == 1))\n            fn = np.sum((y_true == 1) & (y_pred == 0))\n            cm = np.array([[tn, fp], [fn, tp]])\n            plt.figure(figsize=(4, 4))\n            plt.imshow(cm, cmap=\"Blues\")\n            for i in range(2):\n                for j in range(2):\n                    plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n            plt.xticks([0, 1], [\"Pred 0\", \"Pred 1\"])\n            plt.yticks([0, 1], [\"True 0\", \"True 1\"])\n            plt.title(\"Confusion Matrix \u2014 synthetic SPR_BENCH\")\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, \"spr_bench_confusion_matrix.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error plotting confusion matrix: {e}\")\n        plt.close()\n\n    # -------------------- 5. test metric bars --------------------\n    try:\n        test_mcc = logs.get(\"test_MCC\")\n        test_f1 = logs.get(\"test_F1\")\n        if test_mcc is not None and test_f1 is not None:\n            metrics = [\"MCC\", \"Macro-F1\"]\n            scores = [test_mcc, test_f1]\n            plt.figure(figsize=(4, 4))\n            plt.bar(metrics, scores, color=[\"salmon\", \"seagreen\"])\n            plt.ylim(0, 1)\n            plt.title(\"Test Metrics \u2014 synthetic SPR_BENCH\")\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, \"spr_bench_test_metrics.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error plotting test metric bars: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ntags = list(experiment_data.keys())\ntest_mcc_scores = []\n\nfor tag in tags:\n    d = experiment_data[tag][\"SPR\"]\n    epochs = d[\"epochs\"]\n    # -------- Loss curve --------\n    try:\n        plt.figure()\n        plt.plot(epochs, d[\"losses\"][\"train\"], label=\"train\")\n        plt.plot(epochs, d[\"losses\"][\"val\"], label=\"val\")\n        plt.title(f\"SPR Loss Curve ({tag})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"BCE Loss\")\n        plt.legend()\n        fname = f\"SPR_loss_curve_{tag}.png\"\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {tag}: {e}\")\n        plt.close()\n\n    # -------- MCC curve --------\n    try:\n        plt.figure()\n        plt.plot(epochs, d[\"metrics\"][\"train_MCC\"], label=\"train\")\n        plt.plot(epochs, d[\"metrics\"][\"val_MCC\"], label=\"val\")\n        plt.title(f\"SPR MCC Curve ({tag})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"MCC\")\n        plt.legend()\n        fname = f\"SPR_MCC_curve_{tag}.png\"\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating MCC curve for {tag}: {e}\")\n        plt.close()\n\n    # -------- Confusion matrix --------\n    try:\n        preds = np.array(d[\"predictions\"])\n        gts = np.array(d[\"ground_truth\"])\n        cm = np.zeros((2, 2), dtype=int)\n        for gt, pr in zip(gts, preds):\n            cm[int(gt), int(pr)] += 1\n        plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        for i in range(2):\n            for j in range(2):\n                plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n        plt.colorbar()\n        plt.title(\n            f\"SPR Confusion Matrix ({tag})\\nLeft: Ground Truth, Right: Predictions\"\n        )\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.xticks([0, 1], [0, 1])\n        plt.yticks([0, 1], [0, 1])\n        fname = f\"SPR_confusion_matrix_{tag}.png\"\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {tag}: {e}\")\n        plt.close()\n\n    # collect test MCC for comparison bar plot\n    test_mcc_scores.append(d.get(\"test_MCC\", np.nan))\n    print(f\"{tag}: Test MCC={d.get('test_MCC'):.3f}, Test F1={d.get('test_F1'):.3f}\")\n\n# -------- bar chart comparing test MCC --------\ntry:\n    plt.figure()\n    plt.bar(tags, test_mcc_scores, color=[\"tab:blue\", \"tab:orange\"])\n    plt.title(\n        \"SPR Test MCC Comparison\\nLeft: with_positional_encoding, Right: no_positional_encoding\"\n    )\n    plt.ylabel(\"Test MCC\")\n    fname = \"SPR_test_MCC_comparison.png\"\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, fname))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating MCC comparison bar chart: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nmodels = list(experiment_data.keys())\n\n# 1-2) Train/val MCC curves\nfor model in models:\n    try:\n        mcc_train = experiment_data[model][\"metrics\"][\"train_MCC\"]\n        mcc_val = experiment_data[model][\"metrics\"][\"val_MCC\"]\n        plt.figure()\n        plt.plot(mcc_train, label=\"Train MCC\")\n        plt.plot(mcc_val, label=\"Val MCC\")\n        plt.xlabel(\"Epoch update\")\n        plt.ylabel(\"MCC\")\n        plt.title(f\"{model} \u2013 Train vs Val MCC\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"mcc_curve_{model}.png\")\n        plt.tight_layout()\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating MCC curve for {model}: {e}\")\n        plt.close()\n\n# 3-4) Confusion matrices\nfor model in models:\n    try:\n        gt = np.array(experiment_data[model][\"ground_truth\"])\n        pred = np.array(experiment_data[model][\"predictions\"])\n        if gt.size == 0 or pred.size == 0:\n            raise ValueError(\"Empty predictions or labels\")\n        cm = np.zeros((2, 2), dtype=int)\n        for g, p in zip(gt, pred):\n            cm[int(g), int(p)] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\", vmin=0)\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(f\"{model} \u2013 Confusion Matrix\\nLeft: GT rows, Right: Pred cols\")\n        for i in range(2):\n            for j in range(2):\n                plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n        fname = os.path.join(working_dir, f\"confusion_matrix_{model}.png\")\n        plt.tight_layout()\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {model}: {e}\")\n        plt.close()\n\n# 5) Bar chart of test MCC\ntry:\n    test_mccs = [experiment_data[m].get(\"test_MCC\", np.nan) for m in models]\n    plt.figure()\n    plt.bar(models, test_mccs, color=[\"tab:blue\", \"tab:orange\"])\n    for i, v in enumerate(test_mccs):\n        plt.text(i, v, f\"{v:.2f}\", ha=\"center\", va=\"bottom\")\n    plt.ylabel(\"Test MCC\")\n    plt.title(\"Model Comparison \u2013 Test MCC\")\n    fname = os.path.join(working_dir, \"test_mcc_comparison.png\")\n    plt.tight_layout()\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test MCC bar chart: {e}\")\n    plt.close()\n\n# Print numeric summary\nfor m in models:\n    print(\n        f\"{m}: Test MCC = {experiment_data[m].get('test_MCC')}, \"\n        f\"Test F1 = {experiment_data[m].get('test_F1')}\"\n    )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# helper to fetch nested dict safely\ndef get(dic, *ks, default=None):\n    for k in ks:\n        dic = dic.get(k, {})\n    return dic if dic else default\n\n\nds_key = \"SPR_BENCH\"\nmdl_key = \"max_pool\"\ned = get(experiment_data, mdl_key, ds_key, default={})\n\n# ---------- plots ----------\n# 1. Loss curves\ntry:\n    epochs = list(range(1, len(ed[\"losses\"][\"train\"]) + 1))\n    plt.figure()\n    plt.plot(epochs, ed[\"losses\"][\"train\"], label=\"Train\")\n    plt.plot(epochs, ed[\"losses\"][\"val\"], label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"BCE Loss\")\n    plt.title(f\"{ds_key}: Loss Curves (Transformer MaxPool)\")\n    plt.legend()\n    plt.tight_layout()\n    fname = f\"{ds_key}_loss_curves.png\"\n    plt.savefig(os.path.join(working_dir, fname))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# 2. MCC curves\ntry:\n    epochs = list(range(1, len(ed[\"metrics\"][\"train_MCC\"]) + 1))\n    plt.figure()\n    plt.plot(epochs, ed[\"metrics\"][\"train_MCC\"], label=\"Train MCC\")\n    plt.plot(epochs, ed[\"metrics\"][\"val_MCC\"], label=\"Val MCC\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Matthews CorrCoef\")\n    plt.title(f\"{ds_key}: MCC Curves (Transformer MaxPool)\")\n    plt.legend()\n    plt.tight_layout()\n    fname = f\"{ds_key}_MCC_curves.png\"\n    plt.savefig(os.path.join(working_dir, fname))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating MCC plot: {e}\")\n    plt.close()\n\n# 3. Test metric comparison\ntry:\n    plt.figure()\n    metrics = [\"Test_MCC\", \"Test_F1\"]\n    values = [ed.get(\"test_MCC\", 0), ed.get(\"test_F1\", 0)]\n    plt.bar(metrics, values, color=[\"steelblue\", \"orange\"])\n    for i, v in enumerate(values):\n        plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\")\n    plt.ylim(0, 1)\n    plt.title(f\"{ds_key}: Test Metrics (Transformer MaxPool)\")\n    plt.tight_layout()\n    fname = f\"{ds_key}_test_metrics.png\"\n    plt.savefig(os.path.join(working_dir, fname))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metric plot: {e}\")\n    plt.close()\n\n# ---------- print evaluation ----------\nif ed:\n    print(\n        f\"Test MCC: {ed.get('test_MCC', 'NA'):.3f}, Test Macro-F1: {ed.get('test_F1', 'NA'):.3f}\"\n    )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- load data -----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    ed = experiment_data[\"no_padmask\"][\"spr\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    ed = None\n\nif ed:\n    # convenient shorthands\n    epochs = np.arange(1, len(ed[\"losses\"][\"train\"]) + 1)\n    tr_loss, va_loss = ed[\"losses\"][\"train\"], ed[\"losses\"][\"val\"]\n    tr_mcc, va_mcc = ed[\"metrics\"][\"train_MCC\"], ed[\"metrics\"][\"val_MCC\"]\n    test_mcc = ed.get(\"test_MCC\")\n    test_f1 = ed.get(\"test_F1\")\n    preds, gt = np.array(ed[\"predictions\"]), np.array(ed[\"ground_truth\"])\n\n    # ------------- 1. Loss curve -------------\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_loss, label=\"Train\")\n        plt.plot(epochs, va_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"BCE Loss\")\n        plt.title(\"SPR \u2013 Loss Curve (No-PadMask)\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_no_padmask_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # ------------- 2. MCC curve --------------\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_mcc, label=\"Train\")\n        plt.plot(epochs, va_mcc, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Matthews CorrCoef\")\n        plt.title(\"SPR \u2013 MCC Curve (No-PadMask)\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_no_padmask_mcc_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating MCC curve: {e}\")\n        plt.close()\n\n    # ------------- 3. Test metrics bar -------\n    try:\n        plt.figure()\n        plt.bar(\n            [\"Test MCC\", \"Test F1\"], [test_mcc, test_f1], color=[\"skyblue\", \"salmon\"]\n        )\n        for i, v in enumerate([test_mcc, test_f1]):\n            plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\")\n        plt.ylim(0, 1)\n        plt.title(\"SPR \u2013 Test Metrics (No-PadMask)\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_no_padmask_test_metrics.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metrics bar: {e}\")\n        plt.close()\n\n    # ------------- 4. Confusion matrix -------\n    try:\n        from itertools import product\n\n        cm = np.zeros((2, 2), dtype=int)\n        for p, y in zip(preds, gt):\n            cm[int(y), int(p)] += 1\n        plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        classes = [\"Neg\", \"Pos\"]\n        tick_marks = np.arange(len(classes))\n        plt.xticks(tick_marks, classes)\n        plt.yticks(tick_marks, classes)\n        for i, j in product(range(2), range(2)):\n            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.title(\"SPR \u2013 Confusion Matrix (No-PadMask)\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_no_padmask_confusion_matrix.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\n    # ------------- print final numbers -------\n    print(f\"Loaded metrics \u2013 Test MCC: {test_mcc:.3f}, Test macro-F1: {test_f1:.3f}\")\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------- load data -------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# helper\nvariants = [\"sinusoidal\", \"learned\"]\n\n# ------------------- loss curves -------------------\nfor variant in variants:\n    try:\n        exp = experiment_data[\"positional_encoding\"][variant]\n        train_loss = exp[\"losses\"][\"train\"]\n        val_loss = exp[\"losses\"][\"val\"]\n\n        plt.figure(figsize=(6, 4))\n        plt.plot(train_loss, label=\"Train\")\n        plt.plot(val_loss, label=\"Validation\")\n        plt.xlabel(\"Updates (epochs aggregated)\")\n        plt.ylabel(\"BCE Loss\")\n        plt.title(f\"SPR_BENCH Loss Curve\\nVariant: {variant.capitalize()}\")\n        plt.legend()\n        fname = f\"spr_loss_curve_{variant}.png\"\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating loss curve for {variant}: {e}\")\n        plt.close()\n\n# ------------------- test metric comparison -------------------\ntry:\n    metrics = [\"test_MCC\", \"test_F1\"]\n    width = 0.35\n    x = np.arange(len(variants))\n\n    for idx, metric in enumerate(metrics):\n        plt.figure(figsize=(5, 4))\n        vals = [experiment_data[\"positional_encoding\"][v][metric] for v in variants]\n        plt.bar(x, vals, width, color=[\"steelblue\", \"orange\"])\n        plt.xticks(x, [v.capitalize() for v in variants])\n        plt.ylabel(metric)\n        plt.title(f\"SPR_BENCH Test {metric} Comparison\")\n        fname = f\"spr_test_{metric.lower()}_comparison.png\"\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n        print(f\"Saved {fname}\")\nexcept Exception as e:\n    print(f\"Error creating test metric comparison plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set / make working dir\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment results\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# short-circuit if data missing\nif not experiment_data:\n    print(\"No experiment data found \u2013 nothing to plot.\")\nelse:\n    exp = experiment_data[\"no_ffn\"][\"SPR\"]\n\n    # 1) BCE-loss curves -------------------------------------------------------\n    try:\n        plt.figure(figsize=(6, 4))\n        plt.plot(exp[\"losses\"][\"train\"], label=\"train\")\n        plt.plot(exp[\"losses\"][\"val\"], label=\"val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"BCE loss\")\n        plt.legend()\n        plt.title(\"SPR \u2013 No-FFN Transformer\\nTraining vs Validation Loss\")\n        fname = os.path.join(working_dir, \"SPR_no_ffn_loss_curve.png\")\n        plt.tight_layout()\n        plt.savefig(fname)\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # 2) MCC curves -----------------------------------------------------------\n    try:\n        plt.figure(figsize=(6, 4))\n        plt.plot(exp[\"metrics\"][\"train_MCC\"], label=\"train\")\n        plt.plot(exp[\"metrics\"][\"val_MCC\"], label=\"val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"MCC\")\n        plt.legend()\n        plt.title(\"SPR \u2013 No-FFN Transformer\\nTraining vs Validation MCC\")\n        fname = os.path.join(working_dir, \"SPR_no_ffn_MCC_curve.png\")\n        plt.tight_layout()\n        plt.savefig(fname)\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating MCC curve: {e}\")\n        plt.close()\n\n    # 3) Confusion matrix heat-map -------------------------------------------\n    try:\n        # compute 2\u00d72 confusion matrix\n        preds = np.array(exp[\"predictions\"], dtype=int)\n        gts = np.array(exp[\"ground_truth\"], dtype=int)\n        if preds.size and gts.size:\n            cm = np.zeros((2, 2), dtype=int)\n            for p, g in zip(preds, gts):\n                cm[g, p] += 1  # rows: truth, cols: pred\n            plt.figure(figsize=(4, 4))\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im, fraction=0.046, pad=0.04)\n            for i in range(2):\n                for j in range(2):\n                    plt.text(\n                        j,\n                        i,\n                        cm[i, j],\n                        ha=\"center\",\n                        va=\"center\",\n                        color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                    )\n            plt.xticks([0, 1], [\"Pred 0\", \"Pred 1\"])\n            plt.yticks([0, 1], [\"True 0\", \"True 1\"])\n            plt.title(\"SPR \u2013 No-FFN Transformer\\nTest Confusion Matrix\")\n            fname = os.path.join(working_dir, \"SPR_no_ffn_confusion_matrix.png\")\n            plt.tight_layout()\n            plt.savefig(fname)\n            plt.close()\n            print(f\"Saved {fname}\")\n            print(f\"Test MCC={exp['test_MCC']:.3f} | Macro-F1={exp['test_F1']:.3f}\")\n        else:\n            print(\"Prediction / ground-truth arrays empty \u2013 skipping confusion matrix.\")\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# --- setup ---\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --- load experiment data ---\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# --- iterate over entries ---\nfor model_name, datasets in experiment_data.items():\n    for dset_name, record in datasets.items():\n        # helpers\n        ep_labels = list(range(1, len(record[\"losses\"][\"train\"]) + 1))\n        # 1) Loss curves -------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(ep_labels, record[\"losses\"][\"train\"], label=\"train\")\n            plt.plot(ep_labels, record[\"losses\"][\"val\"], label=\"val\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"BCE Loss\")\n            plt.title(f\"{dset_name} \u2013 {model_name}\\nTraining vs Validation Loss\")\n            plt.legend()\n            fname = f\"{dset_name}_{model_name}_loss_curve.png\"\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 2) MCC curves --------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(ep_labels, record[\"metrics\"][\"train_MCC\"], label=\"train_MCC\")\n            plt.plot(ep_labels, record[\"metrics\"][\"val_MCC\"], label=\"val_MCC\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"MCC\")\n            plt.title(f\"{dset_name} \u2013 {model_name}\\nTraining vs Validation MCC\")\n            plt.legend()\n            fname = f\"{dset_name}_{model_name}_mcc_curve.png\"\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating MCC plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 3) Confusion matrix style bar plot ----------------------------------\n        try:\n            preds = np.array(record.get(\"predictions\", []))\n            gts = np.array(record.get(\"ground_truth\", []))\n            if preds.size and gts.size:\n                tp = np.sum((preds == 1) & (gts == 1))\n                fp = np.sum((preds == 1) & (gts == 0))\n                tn = np.sum((preds == 0) & (gts == 0))\n                fn = np.sum((preds == 0) & (gts == 1))\n                plt.figure()\n                plt.bar(\n                    [\"TP\", \"FP\", \"TN\", \"FN\"],\n                    [tp, fp, tn, fn],\n                    color=[\"g\", \"r\", \"b\", \"y\"],\n                )\n                plt.ylabel(\"Count\")\n                plt.title(f\"{dset_name} \u2013 {model_name}\\nConfusion Matrix Counts (Test)\")\n                fname = f\"{dset_name}_{model_name}_confusion_counts.png\"\n                plt.tight_layout()\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating confusion plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 4) Label distribution -----------------------------------------------\n        try:\n            if preds.size and gts.size:\n                plt.figure()\n                plt.hist(\n                    [gts, preds],\n                    bins=[-0.5, 0.5, 1.5],\n                    label=[\"Ground Truth\", \"Predictions\"],\n                    alpha=0.7,\n                )\n                plt.xticks([0, 1])\n                plt.xlabel(\"Label\")\n                plt.ylabel(\"Count\")\n                plt.title(f\"{dset_name} \u2013 {model_name}\\nLabel Distribution (Test)\")\n                plt.legend()\n                fname = f\"{dset_name}_{model_name}_label_distribution.png\"\n                plt.tight_layout()\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(\n                f\"Error creating label distribution for {dset_name}-{model_name}: {e}\"\n            )\n            plt.close()\n        # 5) Print stored metrics ---------------------------------------------\n        print(\n            f\"{dset_name} \u2013 {model_name}: Test MCC={record.get('test_MCC', 'NA'):.3f}, \"\n            f\"Test macro-F1={record.get('test_F1', 'NA'):.3f}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# --- setup ---\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --- load experiment data ---\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# --- iterate over entries ---\nfor model_name, datasets in experiment_data.items():\n    for dset_name, record in datasets.items():\n        # helpers\n        ep_labels = list(range(1, len(record[\"losses\"][\"train\"]) + 1))\n        # 1) Loss curves -------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(ep_labels, record[\"losses\"][\"train\"], label=\"train\")\n            plt.plot(ep_labels, record[\"losses\"][\"val\"], label=\"val\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"BCE Loss\")\n            plt.title(f\"{dset_name} \u2013 {model_name}\\nTraining vs Validation Loss\")\n            plt.legend()\n            fname = f\"{dset_name}_{model_name}_loss_curve.png\"\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 2) MCC curves --------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(ep_labels, record[\"metrics\"][\"train_MCC\"], label=\"train_MCC\")\n            plt.plot(ep_labels, record[\"metrics\"][\"val_MCC\"], label=\"val_MCC\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"MCC\")\n            plt.title(f\"{dset_name} \u2013 {model_name}\\nTraining vs Validation MCC\")\n            plt.legend()\n            fname = f\"{dset_name}_{model_name}_mcc_curve.png\"\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating MCC plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 3) Confusion matrix style bar plot ----------------------------------\n        try:\n            preds = np.array(record.get(\"predictions\", []))\n            gts = np.array(record.get(\"ground_truth\", []))\n            if preds.size and gts.size:\n                tp = np.sum((preds == 1) & (gts == 1))\n                fp = np.sum((preds == 1) & (gts == 0))\n                tn = np.sum((preds == 0) & (gts == 0))\n                fn = np.sum((preds == 0) & (gts == 1))\n                plt.figure()\n                plt.bar(\n                    [\"TP\", \"FP\", \"TN\", \"FN\"],\n                    [tp, fp, tn, fn],\n                    color=[\"g\", \"r\", \"b\", \"y\"],\n                )\n                plt.ylabel(\"Count\")\n                plt.title(f\"{dset_name} \u2013 {model_name}\\nConfusion Matrix Counts (Test)\")\n                fname = f\"{dset_name}_{model_name}_confusion_counts.png\"\n                plt.tight_layout()\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating confusion plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 4) Label distribution -----------------------------------------------\n        try:\n            if preds.size and gts.size:\n                plt.figure()\n                plt.hist(\n                    [gts, preds],\n                    bins=[-0.5, 0.5, 1.5],\n                    label=[\"Ground Truth\", \"Predictions\"],\n                    alpha=0.7,\n                )\n                plt.xticks([0, 1])\n                plt.xlabel(\"Label\")\n                plt.ylabel(\"Count\")\n                plt.title(f\"{dset_name} \u2013 {model_name}\\nLabel Distribution (Test)\")\n                plt.legend()\n                fname = f\"{dset_name}_{model_name}_label_distribution.png\"\n                plt.tight_layout()\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(\n                f\"Error creating label distribution for {dset_name}-{model_name}: {e}\"\n            )\n            plt.close()\n        # 5) Print stored metrics ---------------------------------------------\n        print(\n            f\"{dset_name} \u2013 {model_name}: Test MCC={record.get('test_MCC', 'NA'):.3f}, \"\n            f\"Test macro-F1={record.get('test_F1', 'NA'):.3f}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# --- setup ---\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --- load experiment data ---\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# --- iterate over entries ---\nfor model_name, datasets in experiment_data.items():\n    for dset_name, record in datasets.items():\n        # helpers\n        ep_labels = list(range(1, len(record[\"losses\"][\"train\"]) + 1))\n        # 1) Loss curves -------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(ep_labels, record[\"losses\"][\"train\"], label=\"train\")\n            plt.plot(ep_labels, record[\"losses\"][\"val\"], label=\"val\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"BCE Loss\")\n            plt.title(f\"{dset_name} \u2013 {model_name}\\nTraining vs Validation Loss\")\n            plt.legend()\n            fname = f\"{dset_name}_{model_name}_loss_curve.png\"\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 2) MCC curves --------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(ep_labels, record[\"metrics\"][\"train_MCC\"], label=\"train_MCC\")\n            plt.plot(ep_labels, record[\"metrics\"][\"val_MCC\"], label=\"val_MCC\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"MCC\")\n            plt.title(f\"{dset_name} \u2013 {model_name}\\nTraining vs Validation MCC\")\n            plt.legend()\n            fname = f\"{dset_name}_{model_name}_mcc_curve.png\"\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating MCC plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 3) Confusion matrix style bar plot ----------------------------------\n        try:\n            preds = np.array(record.get(\"predictions\", []))\n            gts = np.array(record.get(\"ground_truth\", []))\n            if preds.size and gts.size:\n                tp = np.sum((preds == 1) & (gts == 1))\n                fp = np.sum((preds == 1) & (gts == 0))\n                tn = np.sum((preds == 0) & (gts == 0))\n                fn = np.sum((preds == 0) & (gts == 1))\n                plt.figure()\n                plt.bar(\n                    [\"TP\", \"FP\", \"TN\", \"FN\"],\n                    [tp, fp, tn, fn],\n                    color=[\"g\", \"r\", \"b\", \"y\"],\n                )\n                plt.ylabel(\"Count\")\n                plt.title(f\"{dset_name} \u2013 {model_name}\\nConfusion Matrix Counts (Test)\")\n                fname = f\"{dset_name}_{model_name}_confusion_counts.png\"\n                plt.tight_layout()\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating confusion plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 4) Label distribution -----------------------------------------------\n        try:\n            if preds.size and gts.size:\n                plt.figure()\n                plt.hist(\n                    [gts, preds],\n                    bins=[-0.5, 0.5, 1.5],\n                    label=[\"Ground Truth\", \"Predictions\"],\n                    alpha=0.7,\n                )\n                plt.xticks([0, 1])\n                plt.xlabel(\"Label\")\n                plt.ylabel(\"Count\")\n                plt.title(f\"{dset_name} \u2013 {model_name}\\nLabel Distribution (Test)\")\n                plt.legend()\n                fname = f\"{dset_name}_{model_name}_label_distribution.png\"\n                plt.tight_layout()\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(\n                f\"Error creating label distribution for {dset_name}-{model_name}: {e}\"\n            )\n            plt.close()\n        # 5) Print stored metrics ---------------------------------------------\n        print(\n            f\"{dset_name} \u2013 {model_name}: Test MCC={record.get('test_MCC', 'NA'):.3f}, \"\n            f\"Test macro-F1={record.get('test_F1', 'NA'):.3f}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# --- setup ---\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --- load experiment data ---\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# --- iterate over entries ---\nfor model_name, datasets in experiment_data.items():\n    for dset_name, record in datasets.items():\n        # helpers\n        ep_labels = list(range(1, len(record[\"losses\"][\"train\"]) + 1))\n        # 1) Loss curves -------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(ep_labels, record[\"losses\"][\"train\"], label=\"train\")\n            plt.plot(ep_labels, record[\"losses\"][\"val\"], label=\"val\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"BCE Loss\")\n            plt.title(f\"{dset_name} \u2013 {model_name}\\nTraining vs Validation Loss\")\n            plt.legend()\n            fname = f\"{dset_name}_{model_name}_loss_curve.png\"\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 2) MCC curves --------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(ep_labels, record[\"metrics\"][\"train_MCC\"], label=\"train_MCC\")\n            plt.plot(ep_labels, record[\"metrics\"][\"val_MCC\"], label=\"val_MCC\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"MCC\")\n            plt.title(f\"{dset_name} \u2013 {model_name}\\nTraining vs Validation MCC\")\n            plt.legend()\n            fname = f\"{dset_name}_{model_name}_mcc_curve.png\"\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating MCC plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 3) Confusion matrix style bar plot ----------------------------------\n        try:\n            preds = np.array(record.get(\"predictions\", []))\n            gts = np.array(record.get(\"ground_truth\", []))\n            if preds.size and gts.size:\n                tp = np.sum((preds == 1) & (gts == 1))\n                fp = np.sum((preds == 1) & (gts == 0))\n                tn = np.sum((preds == 0) & (gts == 0))\n                fn = np.sum((preds == 0) & (gts == 1))\n                plt.figure()\n                plt.bar(\n                    [\"TP\", \"FP\", \"TN\", \"FN\"],\n                    [tp, fp, tn, fn],\n                    color=[\"g\", \"r\", \"b\", \"y\"],\n                )\n                plt.ylabel(\"Count\")\n                plt.title(f\"{dset_name} \u2013 {model_name}\\nConfusion Matrix Counts (Test)\")\n                fname = f\"{dset_name}_{model_name}_confusion_counts.png\"\n                plt.tight_layout()\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating confusion plot for {dset_name}-{model_name}: {e}\")\n            plt.close()\n        # 4) Label distribution -----------------------------------------------\n        try:\n            if preds.size and gts.size:\n                plt.figure()\n                plt.hist(\n                    [gts, preds],\n                    bins=[-0.5, 0.5, 1.5],\n                    label=[\"Ground Truth\", \"Predictions\"],\n                    alpha=0.7,\n                )\n                plt.xticks([0, 1])\n                plt.xlabel(\"Label\")\n                plt.ylabel(\"Count\")\n                plt.title(f\"{dset_name} \u2013 {model_name}\\nLabel Distribution (Test)\")\n                plt.legend()\n                fname = f\"{dset_name}_{model_name}_label_distribution.png\"\n                plt.tight_layout()\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(\n                f\"Error creating label distribution for {dset_name}-{model_name}: {e}\"\n            )\n            plt.close()\n        # 5) Print stored metrics ---------------------------------------------\n        print(\n            f\"{dset_name} \u2013 {model_name}: Test MCC={record.get('test_MCC', 'NA'):.3f}, \"\n            f\"Test macro-F1={record.get('test_F1', 'NA'):.3f}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom collections import defaultdict\n\n# ---------------------------------------------------------------------\n# basic setup\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# load every experiment_data.npy that actually exists\n# ---------------------------------------------------------------------\nexperiment_data_path_list = [\n    \"experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_595d6e9b770e4115b1ed7b242c547043_proc_3341729/experiment_data.npy\",\n    \"experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_32dd5b2adbf54c99875f895d48d2b04d_proc_3341727/experiment_data.npy\",\n    \"experiments/2025-08-17_18-48-09_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_5abd3c72bf2d46d0ba9264c6715a2a96_proc_3341730/experiment_data.npy\",\n]\n\nall_experiment_data = []\nfor p in experiment_data_path_list:\n    try:\n        data = np.load(\n            os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p), allow_pickle=True\n        ).item()\n        all_experiment_data.append(data)\n    except Exception as e:\n        print(f\"Error loading {p}: {e}\")\n\n# ---------------------------------------------------------------------\n# aggregate per (model, dataset)\n# ---------------------------------------------------------------------\nagg_curves = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\nagg_preds = defaultdict(lambda: defaultdict(lambda: {\"preds\": [], \"gts\": []}))\nagg_tests = defaultdict(lambda: defaultdict(lambda: {\"mcc\": [], \"f1\": []}))\n\nfor run in all_experiment_data:\n    for model_name, datasets in run.items():\n        for dset_name, rec in datasets.items():\n            # store curves\n            agg_curves[model_name][dset_name][\"loss_train\"].append(\n                np.asarray(rec[\"losses\"][\"train\"])\n            )\n            agg_curves[model_name][dset_name][\"loss_val\"].append(\n                np.asarray(rec[\"losses\"][\"val\"])\n            )\n            agg_curves[model_name][dset_name][\"mcc_train\"].append(\n                np.asarray(rec[\"metrics\"][\"train_MCC\"])\n            )\n            agg_curves[model_name][dset_name][\"mcc_val\"].append(\n                np.asarray(rec[\"metrics\"][\"val_MCC\"])\n            )\n            # store test metrics\n            agg_tests[model_name][dset_name][\"mcc\"].append(rec.get(\"test_MCC\", np.nan))\n            agg_tests[model_name][dset_name][\"f1\"].append(rec.get(\"test_F1\", np.nan))\n            # store predictions for confusion aggregation if available\n            if \"predictions\" in rec and \"ground_truth\" in rec:\n                agg_preds[model_name][dset_name][\"preds\"].extend(rec[\"predictions\"])\n                agg_preds[model_name][dset_name][\"gts\"].extend(rec[\"ground_truth\"])\n\n\n# ---------------------------------------------------------------------\n# helper to compute mean & sem (aligned to shortest run)\n# ---------------------------------------------------------------------\ndef mean_sem(list_of_1d_arrays):\n    min_len = min(arr.shape[0] for arr in list_of_1d_arrays)\n    stacked = np.stack([arr[:min_len] for arr in list_of_1d_arrays], axis=0)\n    mean = stacked.mean(axis=0)\n    sem = stacked.std(axis=0, ddof=1) / np.sqrt(stacked.shape[0])\n    return mean, sem, np.arange(1, min_len + 1)\n\n\n# ---------------------------------------------------------------------\n# create aggregate plots\n# ---------------------------------------------------------------------\nfor model_name, dsets in agg_curves.items():\n    for dset_name, curves in dsets.items():\n\n        # -------------------- aggregate loss curves --------------------\n        try:\n            m_tr, se_tr, epochs = mean_sem(curves[\"loss_train\"])\n            m_val, se_val, _ = mean_sem(curves[\"loss_val\"])\n            plt.figure()\n            plt.plot(epochs, m_tr, label=\"train mean\")\n            plt.fill_between(\n                epochs, m_tr - se_tr, m_tr + se_tr, alpha=0.3, label=\"train \u00b1 SEM\"\n            )\n            plt.plot(epochs, m_val, label=\"val mean\")\n            plt.fill_between(\n                epochs, m_val - se_val, m_val + se_val, alpha=0.3, label=\"val \u00b1 SEM\"\n            )\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"BCE Loss\")\n            plt.title(\n                f\"{dset_name} \u2013 {model_name}\\nLoss (mean \u00b1 SEM over {len(curves['loss_train'])} runs)\"\n            )\n            plt.legend()\n            fname = f\"{dset_name}_{model_name}_loss_curve_aggregate.png\"\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(\n                f\"Error creating aggregate loss plot for {dset_name}-{model_name}: {e}\"\n            )\n            plt.close()\n\n        # -------------------- aggregate MCC curves ---------------------\n        try:\n            m_tr, se_tr, epochs = mean_sem(curves[\"mcc_train\"])\n            m_val, se_val, _ = mean_sem(curves[\"mcc_val\"])\n            plt.figure()\n            plt.plot(epochs, m_tr, label=\"train mean\")\n            plt.fill_between(\n                epochs, m_tr - se_tr, m_tr + se_tr, alpha=0.3, label=\"train \u00b1 SEM\"\n            )\n            plt.plot(epochs, m_val, label=\"val mean\")\n            plt.fill_between(\n                epochs, m_val - se_val, m_val + se_val, alpha=0.3, label=\"val \u00b1 SEM\"\n            )\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"MCC\")\n            plt.title(\n                f\"{dset_name} \u2013 {model_name}\\nMCC (mean \u00b1 SEM over {len(curves['mcc_train'])} runs)\"\n            )\n            plt.legend()\n            fname = f\"{dset_name}_{model_name}_mcc_curve_aggregate.png\"\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(\n                f\"Error creating aggregate MCC plot for {dset_name}-{model_name}: {e}\"\n            )\n            plt.close()\n\n        # -------------------- aggregate confusion counts ---------------\n        try:\n            preds = np.asarray(agg_preds[model_name][dset_name][\"preds\"])\n            gts = np.asarray(agg_preds[model_name][dset_name][\"gts\"])\n            if preds.size and gts.size:\n                tp = np.sum((preds == 1) & (gts == 1))\n                fp = np.sum((preds == 1) & (gts == 0))\n                tn = np.sum((preds == 0) & (gts == 0))\n                fn = np.sum((preds == 0) & (gts == 1))\n                plt.figure()\n                plt.bar(\n                    [\"TP\", \"FP\", \"TN\", \"FN\"],\n                    [tp, fp, tn, fn],\n                    color=[\"g\", \"r\", \"b\", \"y\"],\n                )\n                plt.ylabel(\"Count\")\n                plt.title(f\"{dset_name} \u2013 {model_name}\\nConfusion Counts (all runs)\")\n                fname = f\"{dset_name}_{model_name}_confusion_counts_aggregate.png\"\n                plt.tight_layout()\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(\n                f\"Error creating aggregate confusion plot for {dset_name}-{model_name}: {e}\"\n            )\n            plt.close()\n\n        # -------------------- print aggregated final test metrics -------\n        mcc_arr = np.asarray(agg_tests[model_name][dset_name][\"mcc\"], dtype=float)\n        f1_arr = np.asarray(agg_tests[model_name][dset_name][\"f1\"], dtype=float)\n        if mcc_arr.size:\n            print(\n                f\"{dset_name} \u2013 {model_name}: \"\n                f\"Test MCC = {np.nanmean(mcc_arr):.3f} \u00b1 {np.nanstd(mcc_arr, ddof=1):.3f} \"\n                f\"(N={len(mcc_arr)}) ; \"\n                f\"macro-F1 = {np.nanmean(f1_arr):.3f} \u00b1 {np.nanstd(f1_arr, ddof=1):.3f}\"\n            )\n"], "plot_plan": ["We will load experiment_data.npy, reorganise the transformer logs by dropout value, and then generate at most five figures: (1) training vs validation loss per\u2010dropout, (2) training vs validation MCC per\u2010dropout, (3) bar chart of final dev MCC for each dropout, (4) confusion-matrix heat-map on the test set for the best model, and (5) bar chart comparing test MCC and test F1 of that best model.  Each figure is wrapped in its own try\u2013except block, saved with descriptive names inside working_dir, titled clearly and referencing the synthetic SPR_BENCH dataset.  We ensure plots are closed after saving, and handle missing or corrupt data gracefully.  Only data present inside experiment_data.npy are used; no new values are fabricated.  The code starts with the required imports, creates working_dir, loads the numpy file, builds helper structures, and then executes the plotting sections.  The design keeps the code concise, self-contained and fully compliant with the provided guidelines while producing standard yet informative visualisations.", "We will begin by loading the saved experiment_data.npy file and extracting the two experiment tags (with and without positional encoding). For each tag we will create two time-series plots: one for the training/validation BCE loss and another for the training/validation Matthews Correlation Coefficient (MCC) across epochs. Next, we will build a 2\u00d72 confusion-matrix heat-map for every tag using the stored test-set predictions and ground-truth labels. Finally, we will generate a single bar chart comparing the final test MCC scores of the two runs, giving us a total of five figures. Every plot is wrapped in an independent try-except block, saved to working_dir with descriptive filenames, closed after saving, and titled clearly with dataset name and plot type. After plotting, the script prints each tag\u2019s test MCC and test F1 that were stored in the file. Only data found in experiment_data.npy are used\u2014no synthetic values are introduced. The code is concise, uses plain Matplotlib, and respects the plotting guidelines.", "We load the serialized dictionary from experiment_data.npy, extract per-epoch losses and MCC scores for both models, and visualise them.  For each model we draw a line plot of train vs validation MCC to show learning dynamics, saving the figure with the model name embedded.  Next we build 2 \u00d7 2 confusion-matrix heatmaps for the test split (ground-truth on y-axis, predictions on x-axis) to inspect the error structure; we limit ourselves to a single epoch, so only one heatmap per model is produced.  Finally we create a bar chart comparing the final test MCC of the two models side-by-side.  Each plot is wrapped in its own try-except guard, saved in working_dir with descriptive filenames, and the figure is always closed.  We avoid generating more than five figures in total (two MCC curves, two confusion matrices, one bar chart).  After plotting, the script prints the test MCC/F1 that are stored in the dict so users can see the numeric results in the console as well.  No synthetic data are fabricated; everything comes directly from experiment_data.npy.", "We will load experiment_data.npy, extract curves and metrics for the only model/dataset present, and then make three basic plots: (1) BCE loss vs epochs, (2) MCC vs epochs, and (3) a bar plot comparing test MCC and Macro-F1.  Each plot is wrapped in a try-except so failures are logged and figures are always closed.  The code starts with the required imports, defines working_dir, and saves figures with descriptive names that include the dataset and plot type.  Finally, it prints out the test metrics read from the file so users can verify numbers quickly.", "We will load the saved experiment_data.npy, extract the loss history, MCC history, test metrics and per-example predictions for the \u201cspr\u201d dataset of the \u201cno_padmask\u201d experiment, and then create up to four standard plots:  \n1) training vs. validation BCE loss over epochs,  \n2) training vs. validation MCC over epochs,  \n3) a bar chart comparing the final test MCC and macro-F1,  \n4) a 2\u00d72 confusion-matrix heat-map built directly from ground-truth and predicted labels.  \nEach plot is wrapped in its own try/except block, titled clearly (e.g. \u201cSPR \u2013 Loss Curve (No-PadMask)\u201d) and saved under descriptive filenames in working_dir. Figures are always closed after saving. Finally, the script prints the exact test MCC and F1 that it read from the file so that numerical results are shown alongside the plots.", null, "We load the saved experiment_data.npy, extract metrics for the two positional-encoding variants, and create at most three standard visualizations that rely only on those stored values.  First, for each variant we draw a loss curve (train vs. validation) so users can see convergence behaviour; these are saved separately and closed in a try-except block.  Second, we build a bar chart that compares final test MCC and macro-F1 across variants to highlight which positional scheme generalises better.  All plots include the dataset name (\u201cSPR_BENCH\u201d), explicit titles/subtitles, are saved to the working directory with descriptive filenames, and figures are always closed even on error.  We stay within the five-figure limit, use only basic matplotlib, and refrain from inventing any data.  The code begins with the required imports and working_dir definition, loads the .npy file safely, iterates through the stored structures, and prints simple confirmations after each save.  This provides clear visual feedback on model training and final performance without exceeding the specified constraints.", "We will first load the saved experiment_data.npy and pull out the only run (model \u201cno_ffn\u201d on dataset \u201cSPR\u201d).  We then prepare three visualizations: (1) the train/val BCE-loss curves, (2) the train/val MCC curves, and (3) a 2\u00d72 heat-map style confusion matrix of the best model\u2019s test predictions vs. ground-truth.  Each figure is created in its own try-except block, saved to working_dir with a clear, descriptive filename that includes the dataset name (\u201cSPR\u201d) and the plot type, and then the figure is closed.  For safety we create working_dir if it does not yet exist.  The code prints a confirmation of every successfully saved figure as well as the final test metrics for quick reference.  Only data actually present in experiment_data.npy are used\u2014no synthetic values are invented.  At most one figure is created for each plot type, staying well within the guideline of < 5 similar plots.  The entire routine is short, self-contained, and can be run after training to inspect results.", "We will load the stored experiment_data.npy, identify every dataset\u2013model combination inside, and iterate through them. For each, we will extract the per-epoch training/validation BCE loss series and MCC series already logged by the training script. We then create two separate line plots: one for the loss curves and another for the MCC curves, both saved with informative filenames that include the dataset name and the plot type. Next, we build a simple confusion-matrix\u2010style bar plot (TP, FP, TN, FN counts) based solely on the stored test predictions and ground-truth labels. To give a sense of class balance and model output, we also add a histogram of predicted probabilities if logits were saved; otherwise we plot label distribution only. All plotting is wrapped in individual try-except blocks, figures are closed after saving, and results are written to the working_dir created earlier. Finally, we print the test MCC and macro-F1 that were serialized in experiment_data so users immediately see evaluation numbers in the console.", null, null, null, null], "ablation_name": [null, "Remove Positional Encoding (No-PE)", "No-Transformer / Bag-of-Embeddings", "Max-Pool Aggregation (Mean\u2192Max)", "No-PadMask (Disable Padding Mask)", "Multi-Synthetic Dataset Training", "Learned Positional Embedding (Sinusoidal \u2192 Learned)", "No-FFN (Attention-Only Transformer)", "No-LayerNorm (Remove all Layer Normalization)", null, null, null, null], "hyperparam_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["Below is a small script that immediately loads the saved NumPy file, extracts\nthe requested values, and prints the final (last-epoch) or single test metrics\nin a clearly-labeled way for each data split. No plots are produced.", "The script will (1) build the working directory path, (2) load\nexperiment_data.npy with pickle support, (3) iterate over each configuration\n(with / without positional encoding) and its dataset entry, and (4) print the\nrequested final or best values with clear, explicit metric names. Lists are\nsummarised by the last value for training loss/MCC and by the maximum value for\nvalidation MCC. No plots are produced and everything runs at the top level.", "We will load the numpy file from the working directory, iterate through its two\nstored experiment results, and extract the final training metrics, the best\n(i.e., max or min) validation metrics, and the stored test metrics. The script\nprints the dataset name first, followed by clearly-labeled metric values. No\nfigures are produced and the code runs immediately on execution.", "We first load the numpy file stored in the working directory and convert it back\nto a regular Python dict.   The dictionary is nested: technique \u2192 dataset \u2192\nresults.   For every dataset we compute (or pick) the required single numbers:\nthe best train/validation Matthews correlation coefficients, the final\ntraining/validation losses, and the stored test Matthews-corrcoef and Macro-F1.\nFinally we print the dataset name followed by each metric name and its value,\nusing clear, explicit labels.", "Below is a small utility that immediately loads the stored NumPy file, fetches\nthe recorded metrics, selects the best (maximum for MCC, minimum for losses) or\nthe final values as appropriate, and prints them with explicit names for easy\nreading. Just run the script in the same environment where the training script\nsaved working/experiment_data.npy.", "", "Below is a small utility that immediately loads the saved NumPy file, extracts\nthe requested statistics for each positional-encoding variant, and prints the\nfinal or best values with explicit metric names.", "The script loads the saved NumPy dictionary, walks through each architecture and\ndataset, extracts the recorded metric arrays, selects the most relevant single\nvalue for each metric (best MCC scores, minimum losses, final-epoch entries\nwhere appropriate), and prints them with clear, explicit labels. All logic is\nplaced at the global scope so the file runs immediately on execution.", "Below is a concise plan followed by executable code.   The script determines the\nworking directory, loads the saved NumPy dictionary, digs into its hierarchical\nstructure (model variant \u2192 dataset), extracts the final entry for every recorded\nlist of losses and MCC scores, and prints those values with fully-qualified\nmetric names (e.g., \u201ctraining Matthews correlation coefficient\u201d). No plots are\ngenerated and the file runs immediately when executed.", "Below is a concise plan followed by executable code.   The script determines the\nworking directory, loads the saved NumPy dictionary, digs into its hierarchical\nstructure (model variant \u2192 dataset), extracts the final entry for every recorded\nlist of losses and MCC scores, and prints those values with fully-qualified\nmetric names (e.g., \u201ctraining Matthews correlation coefficient\u201d). No plots are\ngenerated and the file runs immediately when executed.", "Below is a concise plan followed by executable code.   The script determines the\nworking directory, loads the saved NumPy dictionary, digs into its hierarchical\nstructure (model variant \u2192 dataset), extracts the final entry for every recorded\nlist of losses and MCC scores, and prints those values with fully-qualified\nmetric names (e.g., \u201ctraining Matthews correlation coefficient\u201d). No plots are\ngenerated and the file runs immediately when executed.", "Below is a concise plan followed by executable code.   The script determines the\nworking directory, loads the saved NumPy dictionary, digs into its hierarchical\nstructure (model variant \u2192 dataset), extracts the final entry for every recorded\nlist of losses and MCC scores, and prints those values with fully-qualified\nmetric names (e.g., \u201ctraining Matthews correlation coefficient\u201d). No plots are\ngenerated and the file runs immediately when executed.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ---------------- Load ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# The experiments were stored under the single key \"transformer\"\nexp = experiment_data[\"transformer\"]\n\n# Convenience handles\ntrain_mcc_list = exp[\"metrics\"][\"train_MCC\"]\nval_mcc_list = exp[\"metrics\"][\"val_MCC\"]\ntrain_loss_list = exp[\"losses\"][\"train\"]\nval_loss_list = exp[\"losses\"][\"val\"]\n\n# ---------------- Report ----------------\n# 1) Training set\nprint(\"Training set\")\nprint(f\"train Matthews correlation coefficient: {train_mcc_list[-1]:.4f}\")\nprint(f\"train binary cross-entropy loss: {train_loss_list[-1]:.4f}\")\n\n# 2) Validation set\nprint(\"\\nValidation set\")\nprint(f\"validation Matthews correlation coefficient: {val_mcc_list[-1]:.4f}\")\nprint(f\"validation binary cross-entropy loss: {val_loss_list[-1]:.4f}\")\n\n# 3) Test set\nprint(\"\\nTest set\")\nprint(f\"test Matthews correlation coefficient: {exp['test_MCC']:.4f}\")\nprint(f\"test macro F1 score: {exp['test_F1']:.4f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 0. Locate the working directory and load the stored experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# 1. Parse and print metrics\n# ------------------------------------------------------------------\nfor config_name, datasets in experiment_data.items():  # e.g. \"with_positional_encoding\"\n    for (\n        dataset_name,\n        data,\n    ) in datasets.items():  # only \"SPR\" here, but loop for generality\n        print(f\"\\nDataset: {dataset_name}  |  Configuration: {config_name}\")\n\n        # ----- training metrics (take final epoch) -----\n        if data[\"metrics\"][\"train_MCC\"]:\n            final_train_mcc = data[\"metrics\"][\"train_MCC\"][-1]\n            print(\n                f\"Final training Matthews correlation coefficient: {final_train_mcc:.4f}\"\n            )\n\n        if data[\"losses\"][\"train\"]:\n            final_train_loss = data[\"losses\"][\"train\"][-1]\n            print(f\"Final training binary cross-entropy loss: {final_train_loss:.6f}\")\n\n        # ----- validation metrics (take best MCC, final loss) -----\n        if data[\"metrics\"][\"val_MCC\"]:\n            best_val_mcc = max(data[\"metrics\"][\"val_MCC\"])\n            print(\n                f\"Best validation Matthews correlation coefficient: {best_val_mcc:.4f}\"\n            )\n\n        if data[\"losses\"][\"val\"]:\n            final_val_loss = data[\"losses\"][\"val\"][-1]\n            print(f\"Final validation binary cross-entropy loss: {final_val_loss:.6f}\")\n\n        # ----- test metrics (single value stored) -----\n        if \"test_MCC\" in data:\n            print(f\"Test Matthews correlation coefficient: {data['test_MCC']:.4f}\")\n\n        if \"test_F1\" in data:\n            print(f\"Test macro-averaged F1 score: {data['test_F1']:.4f}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# locate and load stored experiment information\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------\n# helper for safe extraction\n# -------------------------------------------------\ndef last(lst):\n    return lst[-1] if lst else float(\"nan\")\n\n\n# -------------------------------------------------\n# print requested statistics\n# -------------------------------------------------\nfor model_name, record in experiment_data.items():\n    print(f\"Dataset: {model_name}\")\n\n    # training metrics\n    train_mcc_final = last(record[\"metrics\"][\"train_MCC\"])\n    train_loss_final = last(record[\"losses\"][\"train\"])\n    print(f\"train MCC (final): {train_mcc_final:.4f}\")\n    print(f\"train BCE loss (final): {train_loss_final:.4f}\")\n\n    # validation metrics (best)\n    val_mcc_best = (\n        max(record[\"metrics\"][\"val_MCC\"])\n        if record[\"metrics\"][\"val_MCC\"]\n        else float(\"nan\")\n    )\n    val_loss_best = (\n        min(record[\"losses\"][\"val\"]) if record[\"losses\"][\"val\"] else float(\"nan\")\n    )\n    print(f\"validation MCC (best): {val_mcc_best:.4f}\")\n    print(f\"validation BCE loss (best): {val_loss_best:.4f}\")\n\n    # test metrics\n    if \"test_MCC\" in record:\n        print(f\"test MCC: {record['test_MCC']:.4f}\")\n    if \"test_F1\" in record:\n        print(f\"test F1 score: {record['test_F1']:.4f}\")\n    print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nwork_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(work_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper to choose best / final ----------\ndef summarize_dataset(results: dict):\n    \"\"\"\n    Given the innermost dictionary (e.g. experiment_data['max_pool']['SPR_BENCH']),\n    return a dict with single scalar values for the metrics that need reporting.\n    \"\"\"\n    train_mcc_history = results[\"metrics\"][\"train_MCC\"]\n    val_mcc_history = results[\"metrics\"][\"val_MCC\"]\n    train_loss_history = results[\"losses\"][\"train\"]\n    val_loss_history = results[\"losses\"][\"val\"]\n\n    summary = {\n        \"Best train Matthews correlation coefficient\": max(train_mcc_history),\n        \"Best validation Matthews correlation coefficient\": max(val_mcc_history),\n        \"Final training loss\": train_loss_history[-1],\n        \"Final validation loss\": val_loss_history[-1],\n        \"Test Matthews correlation coefficient\": results.get(\"test_MCC\", float(\"nan\")),\n        \"Test macro-F1 score\": results.get(\"test_F1\", float(\"nan\")),\n    }\n    return summary\n\n\n# ---------- iterate and print ----------\nfor technique_name, datasets in experiment_data.items():\n    for dataset_name, res in datasets.items():\n        print(f\"\\nDataset: {dataset_name}\")\n        summary = summarize_dataset(res)\n        for metric_name, value in summary.items():\n            # Decide formatting based on value type\n            if isinstance(value, float):\n                print(f\"{metric_name}: {value:.4f}\")\n            else:\n                print(f\"{metric_name}: {value}\")\n", "import os\nimport numpy as np\n\n# ----------------------------------------------------------------------\n# Locate and load the experiment data\n# ----------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_path):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_path}\")\n\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ----------------------------------------------------------------------\n# Helper functions\n# ----------------------------------------------------------------------\ndef best_value(values, mode=\"max\"):\n    \"\"\"Return the best value given the optimisation mode ('max' or 'min').\"\"\"\n    if not values:\n        return None\n    return max(values) if mode == \"max\" else min(values)\n\n\n# ----------------------------------------------------------------------\n# Iterate over every model setting and dataset, print metrics\n# ----------------------------------------------------------------------\nfor model_name, datasets in experiment_data.items():\n    for dataset_name, content in datasets.items():\n        print(f\"\\nDataset: {dataset_name}\")\n\n        # --- Training & validation metrics ---\n        train_mcc_best = best_value(content[\"metrics\"].get(\"train_MCC\", []), mode=\"max\")\n        val_mcc_best = best_value(content[\"metrics\"].get(\"val_MCC\", []), mode=\"max\")\n\n        train_loss_final = (\n            content[\"losses\"][\"train\"][-1] if content[\"losses\"][\"train\"] else None\n        )\n        val_loss_final = (\n            content[\"losses\"][\"val\"][-1] if content[\"losses\"][\"val\"] else None\n        )\n\n        # --- Test metrics (single values) ---\n        test_mcc = content.get(\"test_MCC\")\n        test_f1 = content.get(\"test_F1\")\n\n        # Print metrics with explicit names\n        if train_mcc_best is not None:\n            print(f\"best train Matthews correlation coefficient: {train_mcc_best:.4f}\")\n        if val_mcc_best is not None:\n            print(\n                f\"best validation Matthews correlation coefficient: {val_mcc_best:.4f}\"\n            )\n        if train_loss_final is not None:\n            print(f\"final train binary cross-entropy loss: {train_loss_final:.4f}\")\n        if val_loss_final is not None:\n            print(f\"final validation binary cross-entropy loss: {val_loss_final:.4f}\")\n        if test_mcc is not None:\n            print(f\"test Matthews correlation coefficient: {test_mcc:.4f}\")\n        if test_f1 is not None:\n            print(f\"test macro-averaged F1 score: {test_f1:.4f}\")\n", "", "import os\nimport numpy as np\n\n# ---------- locate & load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper ----------\ndef summarize_variant(name: str, data: dict):\n    # final / best computations\n    final_train_mcc = (\n        data[\"metrics\"][\"train_MCC\"][-1] if data[\"metrics\"][\"train_MCC\"] else None\n    )\n    best_val_mcc = (\n        max(data[\"metrics\"][\"val_MCC\"]) if data[\"metrics\"][\"val_MCC\"] else None\n    )\n    final_train_loss = data[\"losses\"][\"train\"][-1] if data[\"losses\"][\"train\"] else None\n    best_val_loss = min(data[\"losses\"][\"val\"]) if data[\"losses\"][\"val\"] else None\n    test_mcc = data.get(\"test_MCC\", None)\n    test_f1 = data.get(\"test_F1\", None)\n\n    # printing\n    print(f\"Dataset: {name}\")\n    if final_train_mcc is not None:\n        print(f\"final train MCC: {final_train_mcc:.4f}\")\n    if best_val_mcc is not None:\n        print(f\"best validation MCC: {best_val_mcc:.4f}\")\n    if final_train_loss is not None:\n        print(f\"final training loss: {final_train_loss:.4f}\")\n    if best_val_loss is not None:\n        print(f\"best validation loss: {best_val_loss:.4f}\")\n    if test_mcc is not None:\n        print(f\"test MCC: {test_mcc:.4f}\")\n    if test_f1 is not None:\n        print(f\"test F1 score: {test_f1:.4f}\")\n    print(\"-\" * 40)\n\n\n# ---------- iterate over positional encodings ----------\nfor variant_name, variant_data in experiment_data[\"positional_encoding\"].items():\n    summarize_variant(variant_name, variant_data)\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# locate and load the saved experiment data\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy at {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# helper functions\n# ---------------------------------------------------------------------\ndef best_or_final(seq, mode=\"max\"):\n    \"\"\"\n    Return the most relevant single number from a sequence.\n    mode = 'max'  -> highest value\n    mode = 'min'  -> lowest value\n    mode = 'last' -> last element\n    \"\"\"\n    if not seq:  # empty list safeguard\n        return None\n    if mode == \"max\":\n        return max(seq)\n    if mode == \"min\":\n        return min(seq)\n    return seq[-1]\n\n\n# ---------------------------------------------------------------------\n# iterate through architectures and datasets, printing metrics\n# ---------------------------------------------------------------------\nfor arch_name, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        print(f\"\\nDataset: {dataset_name} (architecture: {arch_name})\")\n\n        # --- MCC scores ------------------------------------------------\n        train_mcc_best = best_or_final(data[\"metrics\"].get(\"train_MCC\", []), mode=\"max\")\n        val_mcc_best = best_or_final(data[\"metrics\"].get(\"val_MCC\", []), mode=\"max\")\n\n        if train_mcc_best is not None:\n            print(f\"Best train MCC: {train_mcc_best:.4f}\")\n        if val_mcc_best is not None:\n            print(f\"Best validation MCC: {val_mcc_best:.4f}\")\n\n        # --- losses ----------------------------------------------------\n        train_loss_final = best_or_final(data[\"losses\"].get(\"train\", []), mode=\"last\")\n        val_loss_final = best_or_final(data[\"losses\"].get(\"val\", []), mode=\"last\")\n\n        if train_loss_final is not None:\n            print(f\"Final training loss: {train_loss_final:.4f}\")\n        if val_loss_final is not None:\n            print(f\"Final validation loss: {val_loss_final:.4f}\")\n\n        # --- test metrics ---------------------------------------------\n        if \"test_MCC\" in data:\n            print(f\"Test MCC: {data['test_MCC']:.4f}\")\n        if \"test_F1\" in data:\n            print(f\"Test F1 score: {data['test_F1']:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate & load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------- pretty printing helper ----------\ndef print_metric(name: str, value: float):\n    print(f\"  {name}: {value:.4f}\")\n\n\n# ---------- iterate and report ----------\nfor model_variant, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        # header\n        print(f\"{dataset_name} ({model_variant})\")\n\n        # extract final (last) values from training history\n        train_mcc = data[\"metrics\"][\"train_MCC\"][-1]\n        val_mcc = data[\"metrics\"][\"val_MCC\"][-1]\n        train_loss = data[\"losses\"][\"train\"][-1]\n        val_loss = data[\"losses\"][\"val\"][-1]\n\n        # print metrics\n        print_metric(\"training Matthews correlation coefficient\", train_mcc)\n        print_metric(\"validation Matthews correlation coefficient\", val_mcc)\n        print_metric(\"training loss (BCE)\", train_loss)\n        print_metric(\"validation loss (BCE)\", val_loss)\n\n        # test-set metrics (if present)\n        if \"test_MCC\" in data:\n            print_metric(\"test Matthews correlation coefficient\", data[\"test_MCC\"])\n        if \"test_F1\" in data:\n            print_metric(\"test macro F1 score\", data[\"test_F1\"])\n", "import os\nimport numpy as np\n\n# ---------- locate & load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------- pretty printing helper ----------\ndef print_metric(name: str, value: float):\n    print(f\"  {name}: {value:.4f}\")\n\n\n# ---------- iterate and report ----------\nfor model_variant, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        # header\n        print(f\"{dataset_name} ({model_variant})\")\n\n        # extract final (last) values from training history\n        train_mcc = data[\"metrics\"][\"train_MCC\"][-1]\n        val_mcc = data[\"metrics\"][\"val_MCC\"][-1]\n        train_loss = data[\"losses\"][\"train\"][-1]\n        val_loss = data[\"losses\"][\"val\"][-1]\n\n        # print metrics\n        print_metric(\"training Matthews correlation coefficient\", train_mcc)\n        print_metric(\"validation Matthews correlation coefficient\", val_mcc)\n        print_metric(\"training loss (BCE)\", train_loss)\n        print_metric(\"validation loss (BCE)\", val_loss)\n\n        # test-set metrics (if present)\n        if \"test_MCC\" in data:\n            print_metric(\"test Matthews correlation coefficient\", data[\"test_MCC\"])\n        if \"test_F1\" in data:\n            print_metric(\"test macro F1 score\", data[\"test_F1\"])\n", "import os\nimport numpy as np\n\n# ---------- locate & load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------- pretty printing helper ----------\ndef print_metric(name: str, value: float):\n    print(f\"  {name}: {value:.4f}\")\n\n\n# ---------- iterate and report ----------\nfor model_variant, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        # header\n        print(f\"{dataset_name} ({model_variant})\")\n\n        # extract final (last) values from training history\n        train_mcc = data[\"metrics\"][\"train_MCC\"][-1]\n        val_mcc = data[\"metrics\"][\"val_MCC\"][-1]\n        train_loss = data[\"losses\"][\"train\"][-1]\n        val_loss = data[\"losses\"][\"val\"][-1]\n\n        # print metrics\n        print_metric(\"training Matthews correlation coefficient\", train_mcc)\n        print_metric(\"validation Matthews correlation coefficient\", val_mcc)\n        print_metric(\"training loss (BCE)\", train_loss)\n        print_metric(\"validation loss (BCE)\", val_loss)\n\n        # test-set metrics (if present)\n        if \"test_MCC\" in data:\n            print_metric(\"test Matthews correlation coefficient\", data[\"test_MCC\"])\n        if \"test_F1\" in data:\n            print_metric(\"test macro F1 score\", data[\"test_F1\"])\n", "import os\nimport numpy as np\n\n# ---------- locate & load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------- pretty printing helper ----------\ndef print_metric(name: str, value: float):\n    print(f\"  {name}: {value:.4f}\")\n\n\n# ---------- iterate and report ----------\nfor model_variant, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        # header\n        print(f\"{dataset_name} ({model_variant})\")\n\n        # extract final (last) values from training history\n        train_mcc = data[\"metrics\"][\"train_MCC\"][-1]\n        val_mcc = data[\"metrics\"][\"val_MCC\"][-1]\n        train_loss = data[\"losses\"][\"train\"][-1]\n        val_loss = data[\"losses\"][\"val\"][-1]\n\n        # print metrics\n        print_metric(\"training Matthews correlation coefficient\", train_mcc)\n        print_metric(\"validation Matthews correlation coefficient\", val_mcc)\n        print_metric(\"training loss (BCE)\", train_loss)\n        print_metric(\"validation loss (BCE)\", val_loss)\n\n        # test-set metrics (if present)\n        if \"test_MCC\" in data:\n            print_metric(\"test Matthews correlation coefficient\", data[\"test_MCC\"])\n        if \"test_F1\" in data:\n            print_metric(\"test macro F1 score\", data[\"test_F1\"])\n", ""], "parse_term_out": ["['Training set', '\\n', 'train Matthews correlation coefficient: 0.3730', '\\n',\n'train binary cross-entropy loss: 0.6213', '\\n', '\\nValidation set', '\\n',\n'validation Matthews correlation coefficient: 0.2919', '\\n', 'validation binary\ncross-entropy loss: 0.6619', '\\n', '\\nTest set', '\\n', 'test Matthews\ncorrelation coefficient: 0.3899', '\\n', 'test macro F1 score: 0.6949', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR  |  Configuration: with_positional_encoding', '\\n', 'Final\ntraining Matthews correlation coefficient: 0.3878', '\\n', 'Final training binary\ncross-entropy loss: 0.615064', '\\n', 'Best validation Matthews correlation\ncoefficient: 0.3799', '\\n', 'Final validation binary cross-entropy loss:\n0.636967', '\\n', 'Test Matthews correlation coefficient: 0.3839', '\\n', 'Test\nmacro-averaged F1 score: 0.6919', '\\n', '\\nDataset: SPR  |  Configuration:\nno_positional_encoding', '\\n', 'Final training Matthews correlation coefficient:\n0.3810', '\\n', 'Final training binary cross-entropy loss: 0.625089', '\\n', 'Best\nvalidation Matthews correlation coefficient: 0.3719', '\\n', 'Final validation\nbinary cross-entropy loss: 0.629401', '\\n', 'Test Matthews correlation\ncoefficient: 0.3835', '\\n', 'Test macro-averaged F1 score: 0.6917', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: transformer', '\\n', 'train MCC (final): 0.3790', '\\n', 'train BCE\nloss (final): 0.6235', '\\n', 'validation MCC (best): 0.3920', '\\n', 'validation\nBCE loss (best): 0.6314', '\\n', 'test MCC: 0.3844', '\\n', 'test F1 score:\n0.6920', '\\n', '\\n', 'Dataset: bag_of_embeddings', '\\n', 'train MCC (final):\n0.3417', '\\n', 'train BCE loss (final): 0.6635', '\\n', 'validation MCC (best):\n0.3492', '\\n', 'validation BCE loss (best): 0.6663', '\\n', 'test MCC: 0.3611',\n'\\n', 'test F1 score: 0.6798', '\\n', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'Best train Matthews correlation coefficient:\n0.3867', '\\n', 'Best validation Matthews correlation coefficient: 0.3920', '\\n',\n'Final training loss: 0.6316', '\\n', 'Final validation loss: 0.6363', '\\n',\n'Test Matthews correlation coefficient: 0.3898', '\\n', 'Test macro-F1 score:\n0.6949', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: spr', '\\n', 'best train Matthews correlation coefficient: 0.3867',\n'\\n', 'best validation Matthews correlation coefficient: 0.3839', '\\n', 'final\ntrain binary cross-entropy loss: 0.6265', '\\n', 'final validation binary cross-\nentropy loss: 0.6456', '\\n', 'test Matthews correlation coefficient: 0.3899',\n'\\n', 'test macro-averaged F1 score: 0.6949', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "", "['Dataset: sinusoidal', '\\n', 'final train MCC: 0.3682', '\\n', 'best validation\nMCC: 0.3879', '\\n', 'final training loss: 0.6231', '\\n', 'best validation loss:\n0.6310', '\\n', 'test MCC: 0.3861', '\\n', 'test F1 score: 0.6929', '\\n',\n'----------------------------------------', '\\n', 'Dataset: learned', '\\n',\n'final train MCC: 0.3902', '\\n', 'best validation MCC: 0.3803', '\\n', 'final\ntraining loss: 0.6103', '\\n', 'best validation loss: 0.6292', '\\n', 'test MCC:\n0.3831', '\\n', 'test F1 score: 0.6913', '\\n',\n'----------------------------------------', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['\\nDataset: SPR (architecture: no_ffn)', '\\n', 'Best train MCC: 0.3882', '\\n',\n'Best validation MCC: 0.3883', '\\n', 'Final training loss: 0.6207', '\\n', 'Final\nvalidation loss: 0.6308', '\\n', 'Test MCC: 0.3971', '\\n', 'Test F1 score:\n0.6980', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR (no_layernorm)', '\\n', '  training Matthews correlation coefficient:\n0.3866', '\\n', '  validation Matthews correlation coefficient: 0.2927', '\\n', '\ntraining loss (BCE): 0.6265', '\\n', '  validation loss (BCE): 0.6467', '\\n', '\ntest Matthews correlation coefficient: 0.3989', '\\n', '  test macro F1 score:\n0.6990', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR (no_layernorm)', '\\n', '  training Matthews correlation coefficient:\n0.3808', '\\n', '  validation Matthews correlation coefficient: 0.3494', '\\n', '\ntraining loss (BCE): 0.6277', '\\n', '  validation loss (BCE): 0.6349', '\\n', '\ntest Matthews correlation coefficient: 0.3936', '\\n', '  test macro F1 score:\n0.6968', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR (no_layernorm)', '\\n', '  training Matthews correlation coefficient:\n0.3716', '\\n', '  validation Matthews correlation coefficient: 0.3879', '\\n', '\ntraining loss (BCE): 0.6264', '\\n', '  validation loss (BCE): 0.6446', '\\n', '\ntest Matthews correlation coefficient: 0.3878', '\\n', '  test macro F1 score:\n0.6939', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR (no_layernorm)', '\\n', '  training Matthews correlation coefficient:\n0.3360', '\\n', '  validation Matthews correlation coefficient: 0.2986', '\\n', '\ntraining loss (BCE): 0.6351', '\\n', '  validation loss (BCE): 0.6576', '\\n', '\ntest Matthews correlation coefficient: 0.3876', '\\n', '  test macro F1 score:\n0.6938', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
