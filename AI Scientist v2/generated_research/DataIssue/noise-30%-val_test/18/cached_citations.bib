
% This paper provides a comprehensive review of Neurosymbolic AI, discussing the integration of symbolic reasoning with neural networks, challenges in the field, and theoretical foundations. It is relevant to introduce the importance of symbolic reasoning in AI and the challenges that the Symbolic PolyRule Reasoning task aims to address. This paper will be cited in the introduction to highlight the broader context of symbolic reasoning and its integration with machine learning.
@article{ansari2025advancingna,
 author = {Tabish Ali Ansari and Darshan Thube and Arin Verma},
 booktitle = {International Journal of Research Publication and Reviews},
 journal = {International Journal of Research Publication and Reviews},
 title = {Advancing Neurosymbolic AI: A Comprehensive Review of Hybrid Reasoning Frameworks and Applications},
 year = {2025}
}

% This paper introduces a fuzzy rule-based classification model (FRCM) for incremental learning and fuzzy granular rule mining. It is relevant to the discussion of existing methods for rule-based classification, particularly in handling complex datasets, and provides a foundation for highlighting the gap that the proposed research addresses by focusing on multi-factor symbolic rules. This citation will be included in the related work section to contextualize the challenges and limitations of current methods.
@article{niu2022fuzzyrc,
 author = {Jiaojiao Niu and De-gang Chen and Jinhai Li and Hui Wang},
 booktitle = {IEEE transactions on fuzzy systems},
 journal = {IEEE Transactions on Fuzzy Systems},
 pages = {3748-3761},
 title = {Fuzzy Rule-Based Classification Method for Incremental Rule Learning},
 volume = {30},
 year = {2022}
}

% The paper 'FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial Reasoning' introduces a symbolic benchmark for multi-step reasoning tasks in the financial domain. It provides a systematic approach to evaluating symbolic reasoning capabilities in machine learning models and highlights challenges in reasoning complexity and domain adaptation. This paper will be cited in the related work section to contextualize the importance of benchmarks for symbolic reasoning and to compare the SPR_BENCH dataset's focus on multi-factor symbolic rules with other benchmarks.
@article{xie2025finchainas,
 author = {Zhuohan Xie and Dhruv Sahnan and Debopriyo Banerjee and Georgi N. Georgiev and Rushil Thareja and Hachem Madmoun and Jinyan Su and Aaryamonvikram Singh and Yuxia Wang and Rui Xing and Fajri Koto and Haonan Li and Ivan Koychev and Tanmoy Chakraborty and Salem Lahlou and Veselin Stoyanov and Preslav Nakov},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial Reasoning},
 volume = {abs/2506.02515},
 year = {2025}
}

% The paper 'LR-XFL: Logical Reasoning-based Explainable Federated Learning' introduces a method for integrating logical reasoning into federated learning by using logic rules to enhance model explainability and robustness. This work is relevant to our study as it provides a methodology for incorporating logical reasoning into machine learning, which aligns with our focus on symbolic poly-factor rules. It will be cited in the related work section to highlight existing approaches for integrating logical reasoning in machine learning systems.
@article{zhang2023lrxfllr,
 author = {Yanci Zhang and Hanyou Yu},
 booktitle = {AAAI Conference on Artificial Intelligence},
 journal = {ArXiv},
 title = {LR-XFL: Logical Reasoning-based Explainable Federated Learning},
 volume = {abs/2308.12681},
 year = {2023}
}

% The paper 'GNS: Solving Plane Geometry Problems by Neural-Symbolic Reasoning with Multi-Modal LLMs' introduces the GNS-260K dataset, a symbolic reasoning benchmark for solving plane geometry problems. This work is relevant as it highlights the use of symbolic reasoning datasets in machine learning tasks, with an emphasis on reasoning and computation. It will be cited in the related work section to compare the GNS-260K dataset with SPR_BENCH and to underline the uniqueness of our dataset's focus on multi-factor symbolic rules.
@article{ning2025gnssp,
 author = {Maizhen Ning and Zihao Zhou and Qiufeng Wang and Xiaowei Huang and Kaizhu Huang},
 booktitle = {AAAI Conference on Artificial Intelligence},
 pages = {24957-24965},
 title = {GNS: Solving Plane Geometry Problems by Neural-Symbolic Reasoning with Multi-Modal LLMs},
 year = {2025}
}

% The paper 'Attention is All You Need' introduces the Transformer architecture, which replaces recurrent and convolutional components with self-attention mechanisms for sequence transduction. This work is directly relevant to the proposed hybrid model that leverages Transformers for handling complex symbolic relations. It will be cited in the methodology section to justify the use of attention mechanisms in the proposed model and to highlight the foundational principles of the Transformer architecture.
@article{vaswani2017attentionia,
 author = {Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and I. Polosukhin},
 booktitle = {Neural Information Processing Systems},
 pages = {5998-6008},
 title = {Attention is All you Need},
 year = {2017}
}

% The paper 'SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning' introduces a modular neuro-symbolic architecture and conducts ablation studies to evaluate the contribution of different modules to performance. This work is relevant to the planned ablation studies in Symbolic PolyRule Reasoning for understanding the role of different model components in handling symbolic tasks. It will be cited in the methodology section to support the design of ablation experiments and the analysis of model components.
@article{amador2025symdqnsk,
 author = {Ivo Amador and Nina Gierasimczuk},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning},
 volume = {abs/2504.02654},
 year = {2025}
}

% The paper 'Qualitative Spatial and Temporal Reasoning: Current Status and Future Challenges' provides an overview of reasoning approaches in symbolic AI, highlighting challenges in representing and reasoning with abstract spatio-temporal information. This is relevant to the discussion of challenges in data representation for symbolic reasoning tasks within the SPR_BENCH benchmark. It will be cited in the risk factors and limitations section to contextualize the difficulty of effectively representing symbolic sequences and rules in machine learning models.
@article{sioutis2021qualitativesa,
 author = {Michael Sioutis and D. Wolter},
 booktitle = {International Joint Conference on Artificial Intelligence},
 pages = {4594-4601},
 title = {Qualitative Spatial and Temporal Reasoning: Current Status and Future Challenges},
 year = {2021}
}

% The paper 'The KANDY Benchmark: Incremental Neuro-Symbolic Learning and Reasoning with Kandinsky Patterns' introduces a benchmarking framework for symbolic reasoning tasks, focusing on symbol compositionality and incremental learning. This work is relevant to the SPR_BENCH dataset as it provides a foundation for the use of benchmarks in symbolic reasoning and highlights challenges in evaluating neuro-symbolic methods. This citation will be included in the related work section to emphasize the importance of benchmarks in advancing symbolic reasoning capabilities in machine learning.
@article{lorello2024thekb,
 author = {Luca Salvatore Lorello and Marco Lippi and S. Melacci},
 booktitle = {Machine-mediated learning},
 journal = {Mach. Learn.},
 pages = {161},
 title = {The KANDY Benchmark: Incremental Neuro-Symbolic Learning and Reasoning with Kandinsky Patterns},
 volume = {114},
 year = {2024}
}
