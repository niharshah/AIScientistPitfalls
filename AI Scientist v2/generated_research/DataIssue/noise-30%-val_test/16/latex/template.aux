\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{goodfellow2016deep,hossain2022rulebasedcb}
\citation{chudasama2025towardih,doula2024nesymofan}
\citation{shah2024causallm,mejri2024resolverr}
\citation{xie2025finchainas}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Method}{1}{section.3}\protected@file@percent }
\citation{fila2024mitigatingoi}
\citation{wan2024towardsca}
\citation{wang2022towardsdk}
\bibdata{references}
\bibcite{chudasama2025towardih}{{1}{2025}{{Chudasama et~al.}}{{Chudasama, Huang, Purohit, and Vidal}}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Partial improvements are observed, but MCC remains modest, and confusion matrices reveal frequent misclassifications.}}{2}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Baseline training vs.\ validation loss and validation MCC.}}}{2}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Research Transformer MCC trajectory and confusion matrix.}}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:results_main}{{1}{2}{Partial improvements are observed, but MCC remains modest, and confusion matrices reveal frequent misclassifications}{figure.1}{}}
\newlabel{fig:results_main@cref}{{[figure][1][]1}{[1][2][]2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{2}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Implementation Details.}{2}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Findings.}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{2}{section.5}\protected@file@percent }
\bibcite{doula2024nesymofan}{{2}{2024}{{Doula et~al.}}{{Doula, Yin, Mühlhäuser, and Guinea}}}
\bibcite{fila2024mitigatingoi}{{3}{2024}{{Fila et~al.}}{{Fila, Attri, and Sharma}}}
\bibcite{goodfellow2016deep}{{4}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, Courville, and Bengio}}}
\bibcite{hossain2022rulebasedcb}{{5}{2022}{{Hossain et~al.}}{{Hossain, Ema, and Sohn}}}
\bibcite{mejri2024resolverr}{{6}{2024}{{Mejri et~al.}}{{Mejri, Amarnath, and Chatterjee}}}
\bibcite{shah2024causallm}{{7}{2024}{{Shah et~al.}}{{Shah, Dikkala, Wang, and Panigrahy}}}
\bibcite{wan2024towardsca}{{8}{2024}{{Wan et~al.}}{{Wan, Liu, Yang, Li, You, Fu, Wan, Krishna, Lin, and Raychowdhury}}}
\bibcite{wang2022towardsdk}{{9}{2022}{{Wang \& Yang}}{{Wang and Yang}}}
\bibcite{xie2025finchainas}{{10}{2025}{{Xie et~al.}}{{Xie, Sahnan, Banerjee, Georgiev, Thareja, Madmoun, Su, Singh, Wang, Xing, Koto, Li, Koychev, Chakraborty, Lahlou, Stoyanov, and Nakov}}}
\bibstyle{iclr2025}
\newlabel{sec:appendix}{{5}{3}{\LARGE Supplementary Material}{section*.4}{}}
\newlabel{sec:appendix@cref}{{[section][5][]5}{[1][3][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Additional Figures}{3}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Additional Unused Experiment Figures}{3}{subsection.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B}Extended Implementation Details}{3}{appendix.B}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Transformer prediction distribution on the test set. Bar heights indicate counts of each predicted label.}}{4}{figure.2}\protected@file@percent }
\newlabel{fig:research_pred_dist}{{2}{4}{Transformer prediction distribution on the test set. Bar heights indicate counts of each predicted label}{figure.2}{}}
\newlabel{fig:research_pred_dist@cref}{{[figure][2][2147483647]2}{[1][3][]4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparison of best validation MCC (left) and test MCC (right) across different epoch settings for the Bi-LSTM baseline.}}{4}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Ablation study showing test accuracy for various feature/architecture removals.}}{4}{figure.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Test loss across ablation experiments.}}{5}{figure.5}\protected@file@percent }
\newlabel{fig:unused_loss}{{5}{5}{Test loss across ablation experiments}{figure.5}{}}
\newlabel{fig:unused_loss@cref}{{[figure][5][2147483647]5}{[1][3][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Test MCC across ablation experiments.}}{5}{figure.6}\protected@file@percent }
\newlabel{fig:unused_mcc}{{6}{5}{Test MCC across ablation experiments}{figure.6}{}}
\newlabel{fig:unused_mcc@cref}{{[figure][6][2147483647]6}{[1][3][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Relative misclassification across ablation experiments.}}{5}{figure.7}\protected@file@percent }
\newlabel{fig:unused_rma}{{7}{5}{Relative misclassification across ablation experiments}{figure.7}{}}
\newlabel{fig:unused_rma@cref}{{[figure][7][2147483647]7}{[1][3][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Aggregated validation accuracy over training epochs across multiple seeds.}}{6}{figure.8}\protected@file@percent }
\newlabel{fig:unused_valacc}{{8}{6}{Aggregated validation accuracy over training epochs across multiple seeds}{figure.8}{}}
\newlabel{fig:unused_valacc@cref}{{[figure][8][2147483647]8}{[1][3][]6}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Aggregated validation loss over training epochs across multiple seeds.}}{6}{figure.9}\protected@file@percent }
\newlabel{fig:unused_valloss}{{9}{6}{Aggregated validation loss over training epochs across multiple seeds}{figure.9}{}}
\newlabel{fig:unused_valloss@cref}{{[figure][9][2147483647]9}{[1][3][]6}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Composite view of the Research Transformer showing both loss and accuracy over training epochs.}}{6}{figure.10}\protected@file@percent }
\newlabel{fig:unused_composite}{{10}{6}{Composite view of the Research Transformer showing both loss and accuracy over training epochs}{figure.10}{}}
\newlabel{fig:unused_composite@cref}{{[figure][10][2147483647]10}{[1][3][]6}}
\gdef \@abspage@last{6}
