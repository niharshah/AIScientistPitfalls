
% The foundational paper introducing the transformer architecture, which is the backbone of the proposed model for adapting contextual embeddings to symbolic reasoning tasks. This citation is critical for explaining the model's design and its reliance on attention mechanisms. It should be cited in the methodology section when describing the transformer-based model architecture.
@article{vaswani2017attentionia,
 author = {Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and I. Polosukhin},
 booktitle = {Neural Information Processing Systems},
 pages = {5998-6008},
 title = {Attention is All you Need},
 year = {2017}
}

% This paper provides a foundational analysis of contextual embeddings, comparing models like BERT, ELMo, and GPT-2, and demonstrating their ability to generate context-specific representations. It is relevant to the proposed work as it supports the adaptation of these embeddings for synthetic symbolic reasoning tasks, highlighting their effectiveness in capturing dependencies within sequences. This citation will be used in the related work and methodology sections to discuss the properties of contextual embeddings.
@article{ethayarajh2019howca,
 author = {Kawin Ethayarajh},
 booktitle = {Conference on Empirical Methods in Natural Language Processing},
 pages = {55-65},
 title = {How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings},
 year = {2019}
}

% The paper 'A Neuro-Symbolic Benchmark Suite for Concept Quality and Reasoning Shortcuts' introduces rsbench, a benchmark suite designed to evaluate reasoning tasks and address reasoning shortcuts. This is relevant to the SPR_BENCH dataset used in the proposed research, as it provides context on challenges in symbolic reasoning and emphasizes the importance of addressing reasoning shortcuts. This citation should be included in the related work section and when describing the SPR_BENCH dataset and its significance.
@article{bortolotti2024anb,
 author = {Samuele Bortolotti and Emanuele Marconato and Tommaso Carraro and Paolo Morettin and Emile van Krieken and Antonio Vergari and Stefano Teso and Andrea Passerini},
 booktitle = {Neural Information Processing Systems},
 title = {A Neuro-Symbolic Benchmark Suite for Concept Quality and Reasoning Shortcuts},
 year = {2024}
}

% This paper reviews neuro-symbolic approaches, focusing on challenges like interpretability, performance trade-offs, and the complexity of integrating neural networks with symbolic reasoning. It is relevant to highlight the research gap and motivate the need for adapting contextual embeddings for symbolic reasoning tasks. This citation should be used in the related work section to discuss the challenges of neuro-symbolic integration and support the motivation for the proposed study.
@article{lu2024surveyingna,
 author = {Zhen Lu and Imran Afridi and Hong Jin Kang and Ivan Ruchkin and Xi Zheng},
 booktitle = {Journal of Reliable Intelligent Environments},
 journal = {J. Reliab. Intell. Environ.},
 pages = {257-279},
 title = {Surveying neuro-symbolic approaches for reliable artificial intelligence of things},
 volume = {10},
 year = {2024}
}

% Paper 0 provides a mathematical foundation for the Adam optimizer, refining it with gradient clipping and weight decay techniques. This is relevant for the methodology section, where optimization strategies such as AdamW and gradient clipping are discussed. Paper 3 introduces an advanced method for gradient norm clipping incorporating weight decay under non-Euclidean smoothness properties. It is also pertinent to the methodology, highlighting innovative approaches to optimization in deep learning.
@article{hwang2024fadamai,
 author = {Dongseong Hwang},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {FAdam: Adam is a natural gradient optimizer using diagonal empirical Fisher information},
 volume = {abs/2405.12807},
 year = {2024}
}

@article{pethick2025generalizedgn,
 author = {Thomas Pethick and Wanyun Xie and Mete Erdogan and Kimon Antonakopoulos and Tony Silveti-Falls and V. Cevher},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Generalized Gradient Norm Clipping & Non-Euclidean (L0,L1)-Smoothness},
 volume = {abs/2506.01913},
 year = {2025}
}
