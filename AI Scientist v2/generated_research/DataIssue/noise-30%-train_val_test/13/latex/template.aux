\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{vaswani2017attentionia}
\citation{goodfellow2016deep}
\citation{bergen2021systematicgw}
\citation{pung2021orchardab}
\citation{patel2024multilogievalte}
\citation{garcez2015neuralsymbolicla}
\citation{vaswani2017attentionia}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Method and Experiments}{1}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Baseline transformer performance by depth.} ({\em  (Left)\/}) Training (solid) vs.\ validation (dashed) F1 curves; ({\em  (Right)\/}) cross-entropy losses. Overfitting is evident.}}{2}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Macro-F1}}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:baseline_curves}{{1}{2}{\textbf {Baseline transformer performance by depth.} (\figleft ) Training (solid) vs.\ validation (dashed) F1 curves; (\figright ) cross-entropy losses. Overfitting is evident}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Hybrid model.} ({\em  (Left)\/}) Training saturates near\nobreakspace  {}1.0,\ while validation stabilizes at\nobreakspace  {}0.70. ({\em  (Right)\/}) Loss curves mirror the overfitting trend.}}{2}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Macro-F1}}}{2}{figure.2}\protected@file@percent }
\newlabel{fig:research_curves}{{2}{2}{\textbf {Hybrid model.} (\figleft ) Training saturates near~1.0,\ while validation stabilizes at~0.70. (\figright ) Loss curves mirror the overfitting trend}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Overfitting in Baseline Transformers}{2}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Hybrid Neural-Symbolic Approach}{2}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Ablation Studies (Appendix)}{2}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{2}{section.4}\protected@file@percent }
\bibdata{references}
\bibcite{bergen2021systematicgw}{{1}{2021}{{Bergen et~al.}}{{Bergen, O’Donnell, and Bahdanau}}}
\bibcite{garcez2015neuralsymbolicla}{{2}{2015}{{Garcez et~al.}}{{Garcez, Besold, Raedt, Földiák, Hitzler, Icard, Kühnberger, Lamb, Miikkulainen, and Silver}}}
\bibcite{goodfellow2016deep}{{3}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, Courville, and Bengio}}}
\bibcite{patel2024multilogievalte}{{4}{2024}{{Patel et~al.}}{{Patel, Kulkarni, Parmar, Budhiraja, Nakamura, Varshney, and Baral}}}
\bibcite{pung2021orchardab}{{5}{2021}{{Pung \& Chan}}{{Pung and Chan}}}
\bibcite{vaswani2017attentionia}{{6}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibstyle{iclr2025}
\@writefile{toc}{\contentsline {section}{\numberline {A}Ablation Details and Additional Results}{4}{appendix.A}\protected@file@percent }
\newlabel{appendix:ablations}{{A}{4}{Ablation Details and Additional Results}{appendix.A}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Ablation without \texttt  {[CLS]} token.} Results remain overfit with $\sim $0.70 validation F1.}}{4}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Confusion Matrix}}}{4}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Training \& Validation}}}{4}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Final Metrics}}}{4}{figure.3}\protected@file@percent }
\newlabel{fig:app_clstoken}{{3}{4}{\textbf {Ablation without \texttt {[CLS]} token.} Results remain overfit with $\sim $0.70 validation F1}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Additional ablation results.} Removing positional encoding or restricting embeddings does not prevent overfitting.}}{4}{figure.4}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {No Positional Enc.}}}{4}{figure.4}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {No Positional: Confusion}}}{4}{figure.4}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Symbols-Only}}}{4}{figure.4}\protected@file@percent }
\newlabel{fig:app_ablation_all}{{4}{4}{\textbf {Additional ablation results.} Removing positional encoding or restricting embeddings does not prevent overfitting}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Baseline test macro-F1 over depths.} Gains plateau around 70\%.}}{5}{figure.5}\protected@file@percent }
\newlabel{fig:baseline_testf1_bar}{{5}{5}{\textbf {Baseline test macro-F1 over depths.} Gains plateau around 70\%}{figure.5}{}}
\gdef \@abspage@last{5}
