\documentclass{article} % For LaTeX2e
\usepackage{iclr2025,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{amssymb,amsmath}
\usepackage{amsthm}
\usepackage{xspace}

% Apply italic corrections:
\renewcommand{\figleft}{{\em (Left)\/}}
\renewcommand{\figcenter}{{\em (Center)\/}}
\renewcommand{\figright}{{\em (Right)\/}}
\renewcommand{\figtop}{{\em (Top)\/}}
\renewcommand{\figbottom}{{\em (Bottom)\/}}
\renewcommand{\captiona}{{\em (a)\/}}
\renewcommand{\captionb}{{\em (b)\/}}
\renewcommand{\captionc}{{\em (c)\/}}
\renewcommand{\captiond}{{\em (d)\/}}

% Capitalize Section and Chapter references:
\def\secref#1{Section~\ref{#1}}
\def\chapref#1{Chapter~\ref{#1}}

\graphicspath{{../figures/}} % DO NOT REMOVE OR CHANGE

\begin{filecontents}{references.bib}
@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  year={2016},
  publisher={MIT Press}
}

@article{vaswani2017attentionia,
 author = {Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and I. Polosukhin},
 booktitle = {Neural Information Processing Systems},
 pages = {5998-6008},
 title = {Attention is All you Need},
 year = {2017}
}

@article{garcez2015neuralsymbolicla,
 author = {A. Garcez and Tarek R. Besold and L. D. Raedt and Peter Földiák and P. Hitzler and Thomas F. Icard and Kai-Uwe Kühnberger and L. Lamb and R. Miikkulainen and Daniel L. Silver},
 booktitle = {AAAI Spring Symposia},
 title = {Neural-Symbolic Learning and Reasoning: Contributions and Challenges},
 year = {2015}
}

@article{bergen2021systematicgw,
 author = {Leon Bergen and T. O'Donnell and Dzmitry Bahdanau},
 booktitle = {Neural Information Processing Systems},
 pages = {1390-1402},
 title = {Systematic Generalization with Edge Transformers},
 year = {2021}
}

@article{patel2024multilogievalte,
 author = {Nisarg Patel and Mohith Kulkarni and Mihir Parmar and Aashna Budhiraja and Mutsumi Nakamura and Neeraj Varshney and Chitta Baral},
 booktitle = {Conference on Empirical Methods in Natural Language Processing},
 journal = {ArXiv},
 title = {Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models},
 volume = {abs/2406.17169},
 year = {2024}
}

@article{xu2024faithfullr,
 author = {Jundong Xu and Hao Fei and Liangming Pan and Qian Liu and M. Lee and W. Hsu},
 booktitle = {Annual Meeting of the Association for Computational Linguistics},
 pages = {13326-13365},
 title = {Faithful Logical Reasoning via Symbolic Chain-of-Thought},
 year = {2024}
}

@article{pung2021orchardab,
 author = {B. Pung and Alvin Chan},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {ORCHARD: A Benchmark For Measuring Systematic Generalization of Multi-Hierarchical Reasoning},
 volume = {abs/2111.14034},
 year = {2021}
}
\end{filecontents}

\title{Combating Hidden-Rule Overfitting in Transformer Models\\ for Symbolic PolyRule Reasoning}
\author{Anonymous}

\begin{document}
\maketitle
\begin{abstract}
We investigate the conceptual generalization capabilities of transformer models on a symbolic classification task, Symbolic PolyRule Reasoning (SPR). SPR involves sequences of abstract symbols whose labels depend on hidden poly-factor rules. Our experiments compare baseline transformers of varying depth with a hybrid neural-symbolic approach. Although models achieve near-perfect training accuracy, systematic generalization falls short of expectations, saturating at about 70\% macro-F1. Our findings reveal that sub-symbolic patterns dominate whenever unseen factor combinations appear, highlighting difficulties in bridging learned representations with robust rule-based inference in real-world contexts.
\end{abstract}

\section{Introduction}
Symbolic reasoning tasks require extrapolation to novel combinations of rules and patterns. In realistic deployments, deep models often fail when distribution shifts occur, partly due to spurious correlations learned during training. Neural-symbolic frameworks aim to enhance interpretability and logical consistency, but it remains unclear whether they effectively mitigate hidden-rule overfitting. We propose the Symbolic PolyRule Reasoning (SPR) benchmark, wherein multi-factor classification rules generate abstract symbol sequences. SPR systematically holds out certain rule combinations in validation/test splits to test extrapolation capabilities. We train (a) baseline transformers~\citep{vaswani2017attentionia}, and (b) a hybrid neural-symbolic variant. Both approaches easily memorize training samples yet plateau at about 70\% macro-F1 on held-out sequences. This shortfall suggests that deeper integration of discrete logic or explicit rule induction may be needed.

\section{Related Work}
Deep neural networks have shown remarkable pattern-recognition capabilities~\citep{goodfellow2016deep}, but frequently rely on non-robust cues rather than genuine rule learning~\citep{bergen2021systematicgw}. Datasets like ORCHARD~\citep{pung2021orchardab} and Multi-LogiEval~\citep{patel2024multilogievalte} expose such weaknesses via controlled extrapolation tasks. Research on neural-symbolic learning merges neural embeddings with logic-based inference~\citep{garcez2015neuralsymbolicla}, but broad improvements remain elusive.

\section{Method and Experiments}
\textbf{Symbolic PolyRule Reasoning (SPR).} We construct sequences labeled via a hidden combination of factor rules, using 20k~train, 5k~validation, and 10k~test sequences with partially unseen rule combos.

\textbf{Models.} We train transformer encoders~\citep{vaswani2017attentionia} (1--4 layers) using Adam (lr~$10^{-4}$). A neural-symbolic version concatenates symbolic features with embeddings. Macro-F1 is the main metric.

\subsection{Overfitting in Baseline Transformers}
Figure~\ref{fig:baseline_curves} shows the baseline's training vs.\ validation performance. Training F1 reaches nearly~1.0, but validation saturates at~0.70, indicating overfitting and a shortfall in true rule-based extrapolation.

\begin{figure}[t]
\centering
\subfigure[Macro-F1]{\includegraphics[width=0.46\textwidth]{Baseline_MacroF1_Curves.png}
\hspace{0.5em}
\includegraphics[width=0.46\textwidth]{Baseline_Loss_Curves.png}}
\caption{\textbf{Baseline transformer performance by depth.} (\figleft) Training (solid) vs.\ validation (dashed) F1 curves; (\figright) cross-entropy losses. Overfitting is evident.}
\label{fig:baseline_curves}
\end{figure}

\subsection{Hybrid Neural-Symbolic Approach}
Figure~\ref{fig:research_curves} shows the hybrid model's training/validation curves. Although symbolic features aid some interpretability, the model still converges to near-perfect training but $\sim$0.70 validation F1.

\begin{figure}[t]
\centering
\subfigure[Macro-F1]{\includegraphics[width=0.46\textwidth]{Research_SPR_BENCH_F1_Curve.png}
\hspace{0.5em}
\includegraphics[width=0.46\textwidth]{Research_SPR_BENCH_Loss_Curve.png}}
\caption{\textbf{Hybrid model.} (\figleft) Training saturates near~1.0,\ while validation stabilizes at~0.70. (\figright) Loss curves mirror the overfitting trend.}
\label{fig:research_curves}
\end{figure}

\subsection{Ablation Studies (Appendix)}
We tested removing the \texttt{[CLS]} token, eliminating positional encodings, and restricting embeddings. All configurations retained similar overfitting patterns, reinforcing the primary challenge of hidden-rule extrapolation.

\section{Conclusion}
We introduced SPR to evaluate whether transformers and hybrid approaches learn multi-factor symbolic rules rather than overfitting. Despite near-perfect training accuracy, generalization consistently stalls around 70\% on new rule combinations. Straightforward neural-symbolic concatenations do not resolve hidden-rule overfitting. Future work may explore specialized rule modules or data-augmentation schemes for bridging sub-symbolic embeddings with explicit logical inference.

\clearpage
\bibliography{references}
\bibliographystyle{iclr2025}

\appendix

\section*{\LARGE Supplementary Material}

\section{Ablation Details and Additional Results}
\label{appendix:ablations}
Ablation experiments tested the influence of architectural elements (e.g.\ \texttt{[CLS]} removal, no positional encodings). None significantly improved extrapolation. Figures \ref{fig:app_clstoken}--\ref{fig:baseline_testf1_bar} show confusion matrices, training/validation curves, and final metrics.

\begin{figure}[h]
\centering
\subfigure[Confusion Matrix]{\includegraphics[width=0.31\textwidth]{Ablation_CLSToken_SPR_BENCH_Confusion.png}}
\subfigure[Training \& Validation]{\includegraphics[width=0.31\textwidth]{Ablation_CLSToken_SPR_BENCH_Curves.png}}
\subfigure[Final Metrics]{\includegraphics[width=0.31\textwidth]{Ablation_CLSToken_SPR_BENCH_FinalMetrics.png}}
\caption{\textbf{Ablation without \texttt{[CLS]} token.} Results remain overfit with $\sim$0.70 validation F1.}
\label{fig:app_clstoken}
\end{figure}

\begin{figure}[h]
\centering
\subfigure[No Positional Enc.]{
\includegraphics[width=0.31\textwidth]{Ablation_NoPositional_Combined.png}}
\subfigure[No Positional: Confusion]{
\includegraphics[width=0.31\textwidth]{Ablation_NoPositional_Confusion_Matrix.png}}
\subfigure[Symbols-Only]{\includegraphics[width=0.31\textwidth]{Ablation_SymbolsOnly_SPR_BENCH_F1_Curve.png}}
\caption{\textbf{Additional ablation results.} Removing positional encoding or restricting embeddings does not prevent overfitting.}
\label{fig:app_ablation_all}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.4\textwidth]{Baseline_TestF1_Bar.png}
\caption{\textbf{Baseline test macro-F1 over depths.} Gains plateau around 70\%.}
\label{fig:baseline_testf1_bar}
\end{figure}

\vfill
\end{document}