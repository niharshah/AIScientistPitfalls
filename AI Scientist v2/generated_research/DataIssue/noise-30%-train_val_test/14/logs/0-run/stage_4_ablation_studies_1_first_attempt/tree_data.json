{"edges": [[0, 1], [0, 4], [0, 3], [0, 2]], "layout": [[0.5, 0.0], [0.0, 1.0], [0.3333333333333333, 1.0], [0.6666666666666666, 1.0], [1.0, 1.0]], "plan": ["We extend the symbolic branch by making it a first-class \u201creasoning token\u2019\u2019 that\nthe Transformer can attend to throughout all layers.  Concretely, for each\nsequence we form a bag-of-symbols count vector, project it to the model\ndimension, and prepend this embedding in front of the usual [CLS] token and word\ntokens.  This allows bidirectional information flow between symbolic statistics\nand contextual pattern learning instead of the late fusion used previously.  A\nsmall gating MLP on the [CLS] output further modulates the contribution of the\nreasoning token.  We train this SymbolicTokenTransformer together with the\nearlier baseline for three epochs, track loss, macro-F1 and our proxy Rule-\nGeneralization-Accuracy (dev accuracy), and save everything for later analysis.\nThe whole script is self-contained, GPU-aware, and finishes within the time\nbudget.", "Ablation name: SymToken-NoGate. Implemented an additional SymbolicToken-NoGate\ntransformer that omits the multiplicative gate on the CLS representation.\nTraining the baseline, the original gated SymToken model, and the ungated\nablation on SPR-Bench allows direct assessment of the gate\u2019s contribution. All\nruns log losses, macro-F1, and accuracy (RGA) into the unified experiment_data\nstructure, which is saved to experiment_data.npy for later analysis.", "Ablation name: SymToken-RandomSym. The solution introduces a new\nSymbolicToken\u2010RandomSym transformer that retains the extra symbolic token yet\nreplaces the informative bag-of-symbols vector with a single frozen random noise\nvector, ensuring the model still benefits from the additional parameters and\ngating/cross-attention while stripping away symbolic content. We add this model\nto the training loop alongside the original Baseline and SymbolicToken variants\nand log results in the same experiment_data structure before saving everything\nto experiment_data.npy.", "Ablation name: SymToken-FrozenSymProj. The solution adds a new SymbolicToken\nvariant whose bag-of-symbols projection layer is frozen. By inheriting from the\nexisting SymbolicTokenTransformer and disabling gradient updates on `sym_proj`,\nwe isolate the effect of the learned symbolic embedding. The script keeps the\nrest of the training pipeline unchanged, appends a new entry to\n`experiment_data`, trains the frozen model, and finally stores all results in\nthe required `experiment_data.npy`.", "Ablation name: NoPositionalEmbedding. The solution adds two new transformer\nvariants\u2014BaselineNoPos and SymbolicTokenTransformerNoPos\u2014whose only difference\nfrom the originals is the complete removal of the learned positional-embedding\nparameters. Both models therefore receive purely content-based embeddings,\nletting the self-attention mechanism infer token order implicitly. We train the\ntwo ablation models on SPR-BENCH for three epochs, log the same metrics/losses\nas before under the top-level key \"NoPositionalEmbedding\", and save everything\nto `experiment_data.npy`."], "code": ["import os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom datasets import load_dataset, DatasetDict\n\n# ------------------------------------------------------------------ paths / utils\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"Baseline\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"SymToken\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    }\n}\n\n\n# ------------------------------------------------------------ dataset / encoding\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\nSPR_PATH = pathlib.Path(\n    os.getenv(\"SPR_DATA_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\n)\ndsets = load_spr_bench(SPR_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\nCLS, PAD, UNK = \"[CLS]\", \"[PAD]\", \"[UNK]\"\nvocab = {PAD: 0, CLS: 1, UNK: 2}\nfor seq in dsets[\"train\"][\"sequence\"]:\n    for tok in seq.strip().split():\n        if tok not in vocab:\n            vocab[tok] = len(vocab)\nvocab_size = len(vocab)\n\nlabels = sorted(set(dsets[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\n\nMAX_LEN = 128\n\n\ndef encode_sequence(seq: str):\n    toks = seq.strip().split()\n    ids = [vocab[CLS]] + [vocab.get(t, vocab[UNK]) for t in toks]\n    ids = ids[:MAX_LEN]\n    attn = [1] * len(ids)\n    if len(ids) < MAX_LEN:\n        pad = MAX_LEN - len(ids)\n        ids += [vocab[PAD]] * pad\n        attn += [0] * pad\n    return ids, attn\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, hf):\n        self.seqs, self.labels = hf[\"sequence\"], hf[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        token_ids, attn = encode_sequence(self.seqs[idx])\n        return {\n            \"input_ids\": torch.tensor(token_ids),\n            \"attention_mask\": torch.tensor(attn),\n            \"labels\": torch.tensor(label2id[self.labels[idx]]),\n        }\n\n\ndef collate(batch):\n    return {k: torch.stack([b[k] for b in batch]) for k in batch[0]}\n\n\nBATCH = 64\ntrain_loader = DataLoader(\n    SPRDataset(dsets[\"train\"]), batch_size=BATCH, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRDataset(dsets[\"dev\"]), batch_size=BATCH, shuffle=False, collate_fn=collate\n)\n\n\n# ------------------------------------------------------------------- models\nclass BaselineTransformer(nn.Module):\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.d_model = d_model\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        self.pos = nn.Parameter(torch.randn(1, MAX_LEN, d_model))\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.cls = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        x = self.emb(ids) + self.pos[:, : ids.size(1)]\n        x = self.enc(x, src_key_padding_mask=~attn_mask.bool())\n        return self.cls(x[:, 0])\n\n\nclass SymbolicTokenTransformer(nn.Module):\n    \"\"\"\n    Prepends a 'reasoning' token derived from bag-of-symbols counts,\n    allowing full cross-attention with sequence tokens.\n    \"\"\"\n\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.d_model = d_model\n        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        self.sym_proj = nn.Linear(vocab_size, d_model)\n        self.pos = nn.Parameter(\n            torch.randn(1, MAX_LEN + 2, d_model)\n        )  # +2 for CLS + sym\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.gate = nn.Sequential(nn.Linear(d_model, d_model), nn.Sigmoid())\n        self.head = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        B, L = ids.shape\n        # bag-of-symbols counts\n        counts = torch.zeros(B, vocab_size, device=ids.device)\n        ones = torch.ones_like(ids, dtype=torch.float)\n        counts.scatter_add_(1, ids, ones)\n        sym_tok = self.sym_proj(counts).unsqueeze(1)  # (B,1,d)\n        cls_tok = self.token_emb(torch.full((B, 1), vocab[CLS], device=ids.device))\n        tok_emb = self.token_emb(ids)  # (B,L,d)\n        x = torch.cat([cls_tok, sym_tok, tok_emb], dim=1) + self.pos[:, : L + 2]\n        # build new attention mask (1 for real, 0 for pad)\n        new_mask = torch.cat([torch.ones(B, 2, device=ids.device), attn_mask], dim=1)\n        x = self.enc(x, src_key_padding_mask=~new_mask.bool())\n        cls_out = x[:, 0]\n        gated = cls_out * self.gate(cls_out)\n        return self.head(gated)\n\n\n# ---------------------------------------------------------------- training helpers\ncriterion = nn.CrossEntropyLoss()\n\n\ndef run_epoch(model, loader, optim=None):\n    train = optim is not None\n    model.train() if train else model.eval()\n    tot_loss, preds, gts = 0.0, [], []\n    for batch in loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = model(batch[\"input_ids\"], batch[\"attention_mask\"])\n        loss = criterion(logits, batch[\"labels\"])\n        if train:\n            optim.zero_grad()\n            loss.backward()\n            optim.step()\n        tot_loss += loss.item() * batch[\"labels\"].size(0)\n        preds.extend(torch.argmax(logits, 1).cpu().tolist())\n        gts.extend(batch[\"labels\"].cpu().tolist())\n    macro_f1 = f1_score(gts, preds, average=\"macro\")\n    acc = accuracy_score(gts, preds)\n    return tot_loss / len(loader.dataset), macro_f1, acc, preds, gts\n\n\ndef train(model, name, epochs=3, lr=3e-4):\n    model.to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    for ep in range(1, epochs + 1):\n        t0 = time.time()\n        tr_loss, tr_f1, _, _, _ = run_epoch(model, train_loader, optimizer)\n        val_loss, val_f1, val_acc, preds, gts = run_epoch(model, dev_loader)\n        exp = experiment_data[\"SPR_BENCH\"][name]\n        exp[\"losses\"][\"train\"].append({\"epoch\": ep, \"loss\": tr_loss})\n        exp[\"losses\"][\"val\"].append({\"epoch\": ep, \"loss\": val_loss})\n        exp[\"metrics\"][\"train\"].append({\"epoch\": ep, \"macro_f1\": tr_f1, \"RGA\": None})\n        exp[\"metrics\"][\"val\"].append({\"epoch\": ep, \"macro_f1\": val_f1, \"RGA\": val_acc})\n        print(\n            f\"{name} Epoch {ep}: tr_loss={tr_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"trF1={tr_f1:.3f} valF1={val_f1:.3f} RGA={val_acc:.3f} \"\n            f\"({time.time()-t0:.1f}s)\"\n        )\n    exp[\"predictions\"], exp[\"ground_truth\"] = preds, gts\n\n\n# ------------------------------------------------------------------- run training\ntrain(BaselineTransformer(), \"Baseline\")\ntrain(SymbolicTokenTransformer(), \"SymToken\")\n\n# ------------------------------------------------------------ save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom datasets import load_dataset, DatasetDict\n\n# ------------------------------------------------------------------ paths / utils\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"Baseline\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"SymToken\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"SymToken-NoGate\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    }\n}\n\n\n# ------------------------------------------------------------ dataset / encoding\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\nSPR_PATH = pathlib.Path(\n    os.getenv(\"SPR_DATA_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\n)\ndsets = load_spr_bench(SPR_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\nCLS, PAD, UNK = \"[CLS]\", \"[PAD]\", \"[UNK]\"\nvocab = {PAD: 0, CLS: 1, UNK: 2}\nfor seq in dsets[\"train\"][\"sequence\"]:\n    for tok in seq.strip().split():\n        if tok not in vocab:\n            vocab[tok] = len(vocab)\nvocab_size = len(vocab)\n\nlabels = sorted(set(dsets[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\n\nMAX_LEN = 128\n\n\ndef encode_sequence(seq: str):\n    toks = seq.strip().split()\n    ids = [vocab[CLS]] + [vocab.get(t, vocab[UNK]) for t in toks]\n    ids = ids[:MAX_LEN]\n    attn = [1] * len(ids)\n    if len(ids) < MAX_LEN:\n        pad = MAX_LEN - len(ids)\n        ids += [vocab[PAD]] * pad\n        attn += [0] * pad\n    return ids, attn\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, hf):\n        self.seqs, self.labels = hf[\"sequence\"], hf[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        token_ids, attn = encode_sequence(self.seqs[idx])\n        return {\n            \"input_ids\": torch.tensor(token_ids),\n            \"attention_mask\": torch.tensor(attn),\n            \"labels\": torch.tensor(label2id[self.labels[idx]]),\n        }\n\n\ndef collate(batch):\n    return {k: torch.stack([b[k] for b in batch]) for k in batch[0]}\n\n\nBATCH = 64\ntrain_loader = DataLoader(\n    SPRDataset(dsets[\"train\"]), batch_size=BATCH, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRDataset(dsets[\"dev\"]), batch_size=BATCH, shuffle=False, collate_fn=collate\n)\n\n\n# ------------------------------------------------------------------- models\nclass BaselineTransformer(nn.Module):\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        self.pos = nn.Parameter(torch.randn(1, MAX_LEN, d_model))\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.cls = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        x = self.emb(ids) + self.pos[:, : ids.size(1)]\n        x = self.enc(x, src_key_padding_mask=~attn_mask.bool())\n        return self.cls(x[:, 0])\n\n\nclass SymbolicTokenTransformer(nn.Module):\n    \"\"\"Original SymToken with gating\"\"\"\n\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        self.sym_proj = nn.Linear(vocab_size, d_model)\n        self.pos = nn.Parameter(torch.randn(1, MAX_LEN + 2, d_model))\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.gate = nn.Sequential(nn.Linear(d_model, d_model), nn.Sigmoid())\n        self.head = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        B, L = ids.shape\n        counts = torch.zeros(B, vocab_size, device=ids.device)\n        ones = torch.ones_like(ids, dtype=torch.float)\n        counts.scatter_add_(1, ids, ones)\n        sym_tok = self.sym_proj(counts).unsqueeze(1)\n        cls_tok = self.token_emb(torch.full((B, 1), vocab[CLS], device=ids.device))\n        tok_emb = self.token_emb(ids)\n        x = torch.cat([cls_tok, sym_tok, tok_emb], dim=1) + self.pos[:, : L + 2]\n        new_mask = torch.cat([torch.ones(B, 2, device=ids.device), attn_mask], dim=1)\n        x = self.enc(x, src_key_padding_mask=~new_mask.bool())\n        cls_out = x[:, 0]\n        return self.head(cls_out * self.gate(cls_out))\n\n\nclass SymbolicTokenNoGateTransformer(nn.Module):\n    \"\"\"Ablation: SymToken without gating\"\"\"\n\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        self.sym_proj = nn.Linear(vocab_size, d_model)\n        self.pos = nn.Parameter(torch.randn(1, MAX_LEN + 2, d_model))\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.head = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        B, L = ids.shape\n        counts = torch.zeros(B, vocab_size, device=ids.device)\n        ones = torch.ones_like(ids, dtype=torch.float)\n        counts.scatter_add_(1, ids, ones)\n        sym_tok = self.sym_proj(counts).unsqueeze(1)\n        cls_tok = self.token_emb(torch.full((B, 1), vocab[CLS], device=ids.device))\n        tok_emb = self.token_emb(ids)\n        x = torch.cat([cls_tok, sym_tok, tok_emb], dim=1) + self.pos[:, : L + 2]\n        new_mask = torch.cat([torch.ones(B, 2, device=ids.device), attn_mask], dim=1)\n        x = self.enc(x, src_key_padding_mask=~new_mask.bool())\n        cls_out = x[:, 0]\n        return self.head(cls_out)\n\n\n# ---------------------------------------------------------------- training helpers\ncriterion = nn.CrossEntropyLoss()\n\n\ndef run_epoch(model, loader, optim=None):\n    train = optim is not None\n    model.train() if train else model.eval()\n    tot_loss, preds, gts = 0.0, [], []\n    for batch in loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = model(batch[\"input_ids\"], batch[\"attention_mask\"])\n        loss = criterion(logits, batch[\"labels\"])\n        if train:\n            optim.zero_grad()\n            loss.backward()\n            optim.step()\n        tot_loss += loss.item() * batch[\"labels\"].size(0)\n        preds.extend(torch.argmax(logits, 1).cpu().tolist())\n        gts.extend(batch[\"labels\"].cpu().tolist())\n    macro_f1 = f1_score(gts, preds, average=\"macro\")\n    acc = accuracy_score(gts, preds)\n    return tot_loss / len(loader.dataset), macro_f1, acc, preds, gts\n\n\ndef train_model(model, name, epochs=3, lr=3e-4):\n    model.to(device)\n    optim = torch.optim.AdamW(model.parameters(), lr=lr)\n    for ep in range(1, epochs + 1):\n        t0 = time.time()\n        tr_loss, tr_f1, _, _, _ = run_epoch(model, train_loader, optim)\n        val_loss, val_f1, val_acc, preds, gts = run_epoch(model, dev_loader)\n        exp = experiment_data[\"SPR_BENCH\"][name]\n        exp[\"losses\"][\"train\"].append({\"epoch\": ep, \"loss\": tr_loss})\n        exp[\"losses\"][\"val\"].append({\"epoch\": ep, \"loss\": val_loss})\n        exp[\"metrics\"][\"train\"].append({\"epoch\": ep, \"macro_f1\": tr_f1, \"RGA\": None})\n        exp[\"metrics\"][\"val\"].append({\"epoch\": ep, \"macro_f1\": val_f1, \"RGA\": val_acc})\n        print(\n            f\"{name} Ep{ep}: tr_loss={tr_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"trF1={tr_f1:.3f} valF1={val_f1:.3f} RGA={val_acc:.3f} \"\n            f\"({time.time()-t0:.1f}s)\"\n        )\n    exp[\"predictions\"], exp[\"ground_truth\"] = preds, gts\n\n\n# ------------------------------------------------------------------- run training\ntrain_model(BaselineTransformer(), \"Baseline\")\ntrain_model(SymbolicTokenTransformer(), \"SymToken\")\ntrain_model(SymbolicTokenNoGateTransformer(), \"SymToken-NoGate\")\n\n# ------------------------------------------------------------ save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom datasets import load_dataset, DatasetDict\n\n# ------------------------------------------------------------- paths / utils\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\nexperiment_data = {\n    \"Baseline\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    },\n    \"SymToken\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    },\n    \"SymToken_RandomSym\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    },\n}\n\n\n# ------------------------------------------------------------ dataset / encoding\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\nSPR_PATH = pathlib.Path(\n    os.getenv(\"SPR_DATA_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\n)\ndsets = load_spr_bench(SPR_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\nCLS, PAD, UNK = \"[CLS]\", \"[PAD]\", \"[UNK]\"\nvocab = {PAD: 0, CLS: 1, UNK: 2}\nfor seq in dsets[\"train\"][\"sequence\"]:\n    for tok in seq.strip().split():\n        if tok not in vocab:\n            vocab[tok] = len(vocab)\nvocab_size = len(vocab)\n\nlabels = sorted(set(dsets[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\n\nMAX_LEN = 128\nBATCH = 64\n\n\ndef encode_sequence(seq: str):\n    toks = seq.strip().split()\n    ids = [vocab[CLS]] + [vocab.get(t, vocab[UNK]) for t in toks]\n    ids = ids[:MAX_LEN]\n    attn = [1] * len(ids)\n    if len(ids) < MAX_LEN:\n        pad = MAX_LEN - len(ids)\n        ids += [vocab[PAD]] * pad\n        attn += [0] * pad\n    return ids, attn\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, hf):\n        self.seqs, self.labels = hf[\"sequence\"], hf[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        token_ids, attn = encode_sequence(self.seqs[idx])\n        return {\n            \"input_ids\": torch.tensor(token_ids),\n            \"attention_mask\": torch.tensor(attn),\n            \"labels\": torch.tensor(label2id[self.labels[idx]]),\n        }\n\n\ndef collate(batch):\n    return {k: torch.stack([b[k] for b in batch]) for k in batch[0]}\n\n\ntrain_loader = DataLoader(\n    SPRDataset(dsets[\"train\"]), batch_size=BATCH, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRDataset(dsets[\"dev\"]), batch_size=BATCH, shuffle=False, collate_fn=collate\n)\n\n\n# ------------------------------------------------------------------- models\nclass BaselineTransformer(nn.Module):\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.d_model = d_model\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        self.pos = nn.Parameter(torch.randn(1, MAX_LEN, d_model))\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.cls = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        x = self.emb(ids) + self.pos[:, : ids.size(1)]\n        x = self.enc(x, src_key_padding_mask=~attn_mask.bool())\n        return self.cls(x[:, 0])\n\n\nclass SymbolicTokenTransformer(nn.Module):\n    \"\"\"\n    Prepends reasoning token derived from bag-of-symbol counts.\n    \"\"\"\n\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.d_model = d_model\n        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        self.sym_proj = nn.Linear(vocab_size, d_model)\n        self.pos = nn.Parameter(torch.randn(1, MAX_LEN + 2, d_model))  # +2 for CLS+sym\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.gate = nn.Sequential(nn.Linear(d_model, d_model), nn.Sigmoid())\n        self.head = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        B, L = ids.shape\n        counts = torch.zeros(B, vocab_size, device=ids.device)\n        ones = torch.ones_like(ids, dtype=torch.float)\n        counts.scatter_add_(1, ids, ones)\n        sym_tok = self.sym_proj(counts).unsqueeze(1)  # (B,1,d)\n        cls_tok = self.token_emb(torch.full((B, 1), vocab[CLS], device=ids.device))\n        tok_emb = self.token_emb(ids)\n        x = torch.cat([cls_tok, sym_tok, tok_emb], dim=1) + self.pos[:, : L + 2]\n        new_mask = torch.cat([torch.ones(B, 2, device=ids.device), attn_mask], dim=1)\n        x = self.enc(x, src_key_padding_mask=~new_mask.bool())\n        cls_out = x[:, 0]\n        gated = cls_out * self.gate(cls_out)\n        return self.head(gated)\n\n\nclass SymbolicTokenRandomSym(nn.Module):\n    \"\"\"\n    Identical to SymbolicTokenTransformer, but sym token is produced from\n    a single frozen random noise vector, eliminating any real symbolic info.\n    \"\"\"\n\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.d_model = d_model\n        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        self.sym_proj = nn.Linear(vocab_size, d_model)\n        # frozen random epsilon vector\n        epsilon = torch.randn(vocab_size)\n        self.register_buffer(\"rand_sym_vec\", epsilon)\n        self.pos = nn.Parameter(torch.randn(1, MAX_LEN + 2, d_model))\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.gate = nn.Sequential(nn.Linear(d_model, d_model), nn.Sigmoid())\n        self.head = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        B, L = ids.shape\n        # use the same sym token for every sequence, replicate along batch\n        sym_in = self.rand_sym_vec.expand(B, -1)\n        sym_tok = self.sym_proj(sym_in).unsqueeze(1)  # (B,1,d)\n        cls_tok = self.token_emb(torch.full((B, 1), vocab[CLS], device=ids.device))\n        tok_emb = self.token_emb(ids)\n        x = torch.cat([cls_tok, sym_tok, tok_emb], dim=1) + self.pos[:, : L + 2]\n        new_mask = torch.cat([torch.ones(B, 2, device=ids.device), attn_mask], dim=1)\n        x = self.enc(x, src_key_padding_mask=~new_mask.bool())\n        cls_out = x[:, 0]\n        gated = cls_out * self.gate(cls_out)\n        return self.head(gated)\n\n\n# ---------------------------------------------------------------- training helpers\ncriterion = nn.CrossEntropyLoss()\n\n\ndef run_epoch(model, loader, optim=None):\n    train = optim is not None\n    model.train() if train else model.eval()\n    tot_loss, preds, gts = 0.0, [], []\n    for batch in loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = model(batch[\"input_ids\"], batch[\"attention_mask\"])\n        loss = criterion(logits, batch[\"labels\"])\n        if train:\n            optim.zero_grad()\n            loss.backward()\n            optim.step()\n        tot_loss += loss.item() * batch[\"labels\"].size(0)\n        preds.extend(torch.argmax(logits, 1).cpu().tolist())\n        gts.extend(batch[\"labels\"].cpu().tolist())\n    macro_f1 = f1_score(gts, preds, average=\"macro\")\n    acc = accuracy_score(gts, preds)\n    return tot_loss / len(loader.dataset), macro_f1, acc, preds, gts\n\n\ndef train(model, exp_key, epochs=3, lr=3e-4):\n    model.to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    for ep in range(1, epochs + 1):\n        t0 = time.time()\n        tr_loss, tr_f1, _, _, _ = run_epoch(model, train_loader, optimizer)\n        val_loss, val_f1, val_acc, preds, gts = run_epoch(model, dev_loader)\n        exp = experiment_data[exp_key][\"SPR_BENCH\"]\n        exp[\"losses\"][\"train\"].append({\"epoch\": ep, \"loss\": tr_loss})\n        exp[\"losses\"][\"val\"].append({\"epoch\": ep, \"loss\": val_loss})\n        exp[\"metrics\"][\"train\"].append({\"epoch\": ep, \"macro_f1\": tr_f1, \"RGA\": None})\n        exp[\"metrics\"][\"val\"].append({\"epoch\": ep, \"macro_f1\": val_f1, \"RGA\": val_acc})\n        print(\n            f\"{exp_key} Epoch {ep}: tr_loss={tr_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"trF1={tr_f1:.3f} valF1={val_f1:.3f} RGA={val_acc:.3f} \"\n            f\"({time.time()-t0:.1f}s)\"\n        )\n    exp[\"predictions\"], exp[\"ground_truth\"] = preds, gts\n\n\n# ------------------------------------------------------------------- run training\ntrain(BaselineTransformer(), \"Baseline\")\ntrain(SymbolicTokenTransformer(), \"SymToken\")\ntrain(SymbolicTokenRandomSym(), \"SymToken_RandomSym\")\n\n# ------------------------------------------------------------ save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom datasets import load_dataset, DatasetDict\n\n# ------------------------------------------------------------------ paths / utils\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"Baseline\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"SymToken\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"SymToken-FrozenSymProj\": {  # new ablation entry\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    }\n}\n\n\n# ------------------------------------------------------------ dataset / encoding\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\nSPR_PATH = pathlib.Path(\n    os.getenv(\"SPR_DATA_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\n)\ndsets = load_spr_bench(SPR_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\nCLS, PAD, UNK = \"[CLS]\", \"[PAD]\", \"[UNK]\"\nvocab = {PAD: 0, CLS: 1, UNK: 2}\nfor seq in dsets[\"train\"][\"sequence\"]:\n    for tok in seq.strip().split():\n        if tok not in vocab:\n            vocab[tok] = len(vocab)\nvocab_size = len(vocab)\n\nlabels = sorted(set(dsets[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\n\nMAX_LEN = 128\n\n\ndef encode_sequence(seq: str):\n    toks = seq.strip().split()\n    ids = [vocab[CLS]] + [vocab.get(t, vocab[UNK]) for t in toks]\n    ids = ids[:MAX_LEN]\n    attn = [1] * len(ids)\n    if len(ids) < MAX_LEN:\n        pad = MAX_LEN - len(ids)\n        ids += [vocab[PAD]] * pad\n        attn += [0] * pad\n    return ids, attn\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, hf):\n        self.seqs, self.labels = hf[\"sequence\"], hf[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        token_ids, attn = encode_sequence(self.seqs[idx])\n        return {\n            \"input_ids\": torch.tensor(token_ids),\n            \"attention_mask\": torch.tensor(attn),\n            \"labels\": torch.tensor(label2id[self.labels[idx]]),\n        }\n\n\ndef collate(batch):\n    return {k: torch.stack([b[k] for b in batch]) for k in batch[0]}\n\n\nBATCH = 64\ntrain_loader = DataLoader(\n    SPRDataset(dsets[\"train\"]), batch_size=BATCH, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRDataset(dsets[\"dev\"]), batch_size=BATCH, shuffle=False, collate_fn=collate\n)\n\n\n# ------------------------------------------------------------------- models\nclass BaselineTransformer(nn.Module):\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.d_model = d_model\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        self.pos = nn.Parameter(torch.randn(1, MAX_LEN, d_model))\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.cls = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        x = self.emb(ids) + self.pos[:, : ids.size(1)]\n        x = self.enc(x, src_key_padding_mask=~attn_mask.bool())\n        return self.cls(x[:, 0])\n\n\nclass SymbolicTokenTransformer(nn.Module):\n    \"\"\"\n    Prepends a 'reasoning' token derived from bag-of-symbols counts,\n    allowing full cross-attention with sequence tokens.\n    \"\"\"\n\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.d_model = d_model\n        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        self.sym_proj = nn.Linear(vocab_size, d_model)\n        self.pos = nn.Parameter(\n            torch.randn(1, MAX_LEN + 2, d_model)\n        )  # +2 for CLS + sym\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.gate = nn.Sequential(nn.Linear(d_model, d_model), nn.Sigmoid())\n        self.head = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        B, L = ids.shape\n        counts = torch.zeros(B, vocab_size, device=ids.device)\n        ones = torch.ones_like(ids, dtype=torch.float)\n        counts.scatter_add_(1, ids, ones)  # bag-of-symbols\n        sym_tok = self.sym_proj(counts).unsqueeze(1)  # (B,1,d)\n        cls_tok = self.token_emb(torch.full((B, 1), vocab[CLS], device=ids.device))\n        tok_emb = self.token_emb(ids)  # (B,L,d)\n        x = torch.cat([cls_tok, sym_tok, tok_emb], dim=1) + self.pos[:, : L + 2]\n        new_mask = torch.cat([torch.ones(B, 2, device=ids.device), attn_mask], dim=1)\n        x = self.enc(x, src_key_padding_mask=~new_mask.bool())\n        cls_out = x[:, 0]\n        gated = cls_out * self.gate(cls_out)\n        return self.head(gated)\n\n\nclass SymTokenFrozenSymProjTransformer(SymbolicTokenTransformer):\n    \"\"\"\n    Same as SymbolicTokenTransformer but the sym_proj parameters are frozen.\n    \"\"\"\n\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__(d_model, n_head, n_layer, ff)\n        # Freeze projection parameters\n        for p in [self.sym_proj.weight, self.sym_proj.bias]:\n            p.requires_grad = False\n\n\n# ---------------------------------------------------------------- training helpers\ncriterion = nn.CrossEntropyLoss()\n\n\ndef run_epoch(model, loader, optim=None):\n    train = optim is not None\n    model.train() if train else model.eval()\n    tot_loss, preds, gts = 0.0, [], []\n    for batch in loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = model(batch[\"input_ids\"], batch[\"attention_mask\"])\n        loss = criterion(logits, batch[\"labels\"])\n        if train:\n            optim.zero_grad()\n            loss.backward()\n            optim.step()\n        tot_loss += loss.item() * batch[\"labels\"].size(0)\n        preds.extend(torch.argmax(logits, 1).cpu().tolist())\n        gts.extend(batch[\"labels\"].cpu().tolist())\n    macro_f1 = f1_score(gts, preds, average=\"macro\")\n    acc = accuracy_score(gts, preds)\n    return tot_loss / len(loader.dataset), macro_f1, acc, preds, gts\n\n\ndef train(model, name, epochs=3, lr=3e-4):\n    model.to(device)\n    optimizer = torch.optim.AdamW(\n        filter(lambda p: p.requires_grad, model.parameters()), lr=lr\n    )\n    for ep in range(1, epochs + 1):\n        t0 = time.time()\n        tr_loss, tr_f1, _, _, _ = run_epoch(model, train_loader, optimizer)\n        val_loss, val_f1, val_acc, preds, gts = run_epoch(model, dev_loader)\n        exp = experiment_data[\"SPR_BENCH\"][name]\n        exp[\"losses\"][\"train\"].append({\"epoch\": ep, \"loss\": tr_loss})\n        exp[\"losses\"][\"val\"].append({\"epoch\": ep, \"loss\": val_loss})\n        exp[\"metrics\"][\"train\"].append({\"epoch\": ep, \"macro_f1\": tr_f1, \"RGA\": None})\n        exp[\"metrics\"][\"val\"].append({\"epoch\": ep, \"macro_f1\": val_f1, \"RGA\": val_acc})\n        print(\n            f\"{name} Epoch {ep}: tr_loss={tr_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"trF1={tr_f1:.3f} valF1={val_f1:.3f} RGA={val_acc:.3f} \"\n            f\"({time.time()-t0:.1f}s)\"\n        )\n    exp[\"predictions\"], exp[\"ground_truth\"] = preds, gts\n\n\n# ------------------------------------------------------------------- run training\ntrain(BaselineTransformer(), \"Baseline\")\ntrain(SymbolicTokenTransformer(), \"SymToken\")\ntrain(SymTokenFrozenSymProjTransformer(), \"SymToken-FrozenSymProj\")\n\n# ------------------------------------------------------------ save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom datasets import load_dataset, DatasetDict\n\n# ----------------------------------------------------------------- paths / utils\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\nexperiment_data = {\n    \"NoPositionalEmbedding\": {\n        \"SPR_BENCH\": {\n            \"Baseline\": {\n                \"metrics\": {\"train\": [], \"val\": []},\n                \"losses\": {\"train\": [], \"val\": []},\n                \"predictions\": [],\n                \"ground_truth\": [],\n            },\n            \"SymToken\": {\n                \"metrics\": {\"train\": [], \"val\": []},\n                \"losses\": {\"train\": [], \"val\": []},\n                \"predictions\": [],\n                \"ground_truth\": [],\n            },\n        }\n    }\n}\n\n\n# ----------------------------------------------------------- dataset / encoding\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\nSPR_PATH = pathlib.Path(\n    os.getenv(\"SPR_DATA_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\")\n)\ndsets = load_spr_bench(SPR_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\nCLS, PAD, UNK = \"[CLS]\", \"[PAD]\", \"[UNK]\"\nvocab = {PAD: 0, CLS: 1, UNK: 2}\nfor seq in dsets[\"train\"][\"sequence\"]:\n    for tok in seq.strip().split():\n        vocab.setdefault(tok, len(vocab))\nvocab_size = len(vocab)\n\nlabels = sorted(set(dsets[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\n\nMAX_LEN = 128\n\n\ndef encode_sequence(seq: str):\n    toks = seq.strip().split()\n    ids = [vocab[CLS]] + [vocab.get(t, vocab[UNK]) for t in toks]\n    ids = ids[:MAX_LEN]\n    attn = [1] * len(ids)\n    if len(ids) < MAX_LEN:\n        pad = MAX_LEN - len(ids)\n        ids += [vocab[PAD]] * pad\n        attn += [0] * pad\n    return ids, attn\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, hf):\n        self.seqs, self.labels = hf[\"sequence\"], hf[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        token_ids, attn = encode_sequence(self.seqs[idx])\n        return {\n            \"input_ids\": torch.tensor(token_ids),\n            \"attention_mask\": torch.tensor(attn),\n            \"labels\": torch.tensor(label2id[self.labels[idx]]),\n        }\n\n\ndef collate(batch):\n    return {k: torch.stack([b[k] for b in batch]) for k in batch[0]}\n\n\nBATCH = 64\ntrain_loader = DataLoader(\n    SPRDataset(dsets[\"train\"]), batch_size=BATCH, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRDataset(dsets[\"dev\"]), batch_size=BATCH, shuffle=False, collate_fn=collate\n)\n\n\n# -------------------------------------------------------------- no-pos models\nclass BaselineNoPos(nn.Module):\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.cls = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        x = self.emb(ids)  # no positional embedding\n        x = self.enc(x, src_key_padding_mask=~attn_mask.bool())\n        return self.cls(x[:, 0])\n\n\nclass SymbolicTokenTransformerNoPos(nn.Module):\n    def __init__(self, d_model=128, n_head=4, n_layer=2, ff=256):\n        super().__init__()\n        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=vocab[PAD])\n        self.sym_proj = nn.Linear(vocab_size, d_model)\n        enc_layer = nn.TransformerEncoderLayer(d_model, n_head, ff, batch_first=True)\n        self.enc = nn.TransformerEncoder(enc_layer, n_layer)\n        self.gate = nn.Sequential(nn.Linear(d_model, d_model), nn.Sigmoid())\n        self.head = nn.Linear(d_model, num_labels)\n\n    def forward(self, ids, attn_mask):\n        B, L = ids.shape\n        counts = torch.zeros(B, vocab_size, device=ids.device)\n        ones = torch.ones_like(ids, dtype=torch.float)\n        counts.scatter_add_(1, ids, ones)\n        sym_tok = self.sym_proj(counts).unsqueeze(1)  # (B,1,d)\n        cls_tok = self.token_emb(torch.full((B, 1), vocab[CLS], device=ids.device))\n        tok_emb = self.token_emb(ids)  # (B,L,d)\n        x = torch.cat([cls_tok, sym_tok, tok_emb], dim=1)  # no positional bias\n        new_mask = torch.cat([torch.ones(B, 2, device=ids.device), attn_mask], dim=1)\n        x = self.enc(x, src_key_padding_mask=~new_mask.bool())\n        cls_out = x[:, 0]\n        gated = cls_out * self.gate(cls_out)\n        return self.head(gated)\n\n\n# -------------------------------------------------------- training / evaluation\ncriterion = nn.CrossEntropyLoss()\n\n\ndef run_epoch(model, loader, optim=None):\n    train = optim is not None\n    model.train() if train else model.eval()\n    tot_loss, preds, gts = 0.0, [], []\n    for batch in loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = model(batch[\"input_ids\"], batch[\"attention_mask\"])\n        loss = criterion(logits, batch[\"labels\"])\n        if train:\n            optim.zero_grad()\n            loss.backward()\n            optim.step()\n        tot_loss += loss.item() * batch[\"labels\"].size(0)\n        preds.extend(torch.argmax(logits, 1).cpu().tolist())\n        gts.extend(batch[\"labels\"].cpu().tolist())\n    macro_f1 = f1_score(gts, preds, average=\"macro\")\n    acc = accuracy_score(gts, preds)\n    return tot_loss / len(loader.dataset), macro_f1, acc, preds, gts\n\n\ndef train(model, model_key, epochs=3, lr=3e-4):\n    model.to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    for ep in range(1, epochs + 1):\n        t0 = time.time()\n        tr_loss, tr_f1, _, _, _ = run_epoch(model, train_loader, optimizer)\n        val_loss, val_f1, val_acc, preds, gts = run_epoch(model, dev_loader)\n        exp = experiment_data[\"NoPositionalEmbedding\"][\"SPR_BENCH\"][model_key]\n        exp[\"losses\"][\"train\"].append({\"epoch\": ep, \"loss\": tr_loss})\n        exp[\"losses\"][\"val\"].append({\"epoch\": ep, \"loss\": val_loss})\n        exp[\"metrics\"][\"train\"].append({\"epoch\": ep, \"macro_f1\": tr_f1, \"RGA\": None})\n        exp[\"metrics\"][\"val\"].append({\"epoch\": ep, \"macro_f1\": val_f1, \"RGA\": val_acc})\n        print(\n            f\"{model_key} Epoch {ep}: tr_loss={tr_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"trF1={tr_f1:.3f} valF1={val_f1:.3f} RGA={val_acc:.3f} \"\n            f\"({time.time()-t0:.1f}s)\"\n        )\n    exp[\"predictions\"], exp[\"ground_truth\"] = preds, gts\n\n\n# -------------------------------------------------------------- run ablation\ntrain(BaselineNoPos(), \"Baseline\")\ntrain(SymbolicTokenTransformerNoPos(), \"SymToken\")\n\n# ---------------------------------------------------------- save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n"], "term_out": ["['Using device: cuda', '\\n', \"{'train': 2000, 'dev': 500, 'test': 1000}\", '\\n',\n'Baseline Epoch 1: tr_loss=0.4121 val_loss=1.3240 trF1=0.815 valF1=0.688\nRGA=0.688 (1.1s)', '\\n', 'Baseline Epoch 2: tr_loss=0.0751 val_loss=1.8213\ntrF1=0.977 valF1=0.692 RGA=0.692 (0.8s)', '\\n', 'Baseline Epoch 3:\ntr_loss=0.0405 val_loss=1.9424 trF1=0.988 valF1=0.698 RGA=0.698 (0.8s)', '\\n',\n'SymToken Epoch 1: tr_loss=0.6287 val_loss=0.6744 trF1=0.646 valF1=0.682\nRGA=0.682 (0.8s)', '\\n', 'SymToken Epoch 2: tr_loss=0.1318 val_loss=1.4574\ntrF1=0.967 valF1=0.696 RGA=0.696 (0.8s)', '\\n', 'SymToken Epoch 3:\ntr_loss=0.0489 val_loss=1.5619 trF1=0.985 valF1=0.696 RGA=0.696 (0.8s)', '\\n',\n'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-17_23-44-\n22_conceptual_generalization_poly_rule_attempt_0/0-run/process_ForkProcess-\n11/working/experiment_data.npy', '\\n', 'Execution time: 8 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 2000 examples [00:00, 94802.60\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 500 examples [00:00, 84074.41\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 92708.19\nexamples/s]', '\\n', \"{'train': 2000, 'dev': 500, 'test': 1000}\", '\\n', 'Baseline\nEp1: tr_loss=0.4121 val_loss=1.3240 trF1=0.815 valF1=0.688 RGA=0.688 (1.3s)',\n'\\n', 'Baseline Ep2: tr_loss=0.0751 val_loss=1.8213 trF1=0.977 valF1=0.692\nRGA=0.692 (0.9s)', '\\n', 'Baseline Ep3: tr_loss=0.0405 val_loss=1.9424\ntrF1=0.988 valF1=0.698 RGA=0.698 (0.9s)', '\\n', 'SymToken Ep1: tr_loss=0.6287\nval_loss=0.6744 trF1=0.646 valF1=0.682 RGA=0.682 (0.9s)', '\\n', 'SymToken Ep2:\ntr_loss=0.1318 val_loss=1.4574 trF1=0.967 valF1=0.696 RGA=0.696 (0.9s)', '\\n',\n'SymToken Ep3: tr_loss=0.0489 val_loss=1.5619 trF1=0.985 valF1=0.696 RGA=0.696\n(0.9s)', '\\n', 'SymToken-NoGate Ep1: tr_loss=0.6209 val_loss=0.7252 trF1=0.659\nvalF1=0.635 RGA=0.642 (0.9s)', '\\n', 'SymToken-NoGate Ep2: tr_loss=0.1957\nval_loss=1.5471 trF1=0.926 valF1=0.678 RGA=0.678 (0.9s)', '\\n', 'SymToken-NoGate\nEp3: tr_loss=0.0803 val_loss=1.8258 trF1=0.973 valF1=0.686 RGA=0.686 (0.9s)',\n'\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-17_23-44-\n22_conceptual_generalization_poly_rule_attempt_0/0-run/process_ForkProcess-\n16/working/experiment_data.npy', '\\n', 'Execution time: 11 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 2000 examples [00:00,\n132758.45 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 500 examples [00:00, 107057.63\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 171077.37\nexamples/s]', '\\n', \"{'train': 2000, 'dev': 500, 'test': 1000}\", '\\n', 'Baseline\nEpoch 1: tr_loss=0.4121 val_loss=1.3240 trF1=0.815 valF1=0.688 RGA=0.688\n(0.6s)', '\\n', 'Baseline Epoch 2: tr_loss=0.0751 val_loss=1.8213 trF1=0.977\nvalF1=0.692 RGA=0.692 (0.3s)', '\\n', 'Baseline Epoch 3: tr_loss=0.0405\nval_loss=1.9424 trF1=0.988 valF1=0.698 RGA=0.698 (0.3s)', '\\n', 'SymToken Epoch\n1: tr_loss=0.6287 val_loss=0.6744 trF1=0.646 valF1=0.682 RGA=0.682 (0.3s)',\n'\\n', 'SymToken Epoch 2: tr_loss=0.1318 val_loss=1.4574 trF1=0.967 valF1=0.696\nRGA=0.696 (0.3s)', '\\n', 'SymToken Epoch 3: tr_loss=0.0489 val_loss=1.5619\ntrF1=0.985 valF1=0.696 RGA=0.696 (0.3s)', '\\n', 'SymToken_RandomSym Epoch 1:\ntr_loss=0.4581 val_loss=1.0605 trF1=0.810 valF1=0.680 RGA=0.680 (0.3s)', '\\n',\n'SymToken_RandomSym Epoch 2: tr_loss=0.1195 val_loss=1.3939 trF1=0.958\nvalF1=0.688 RGA=0.688 (0.3s)', '\\n', 'SymToken_RandomSym Epoch 3: tr_loss=0.0630\nval_loss=1.5903 trF1=0.978 valF1=0.694 RGA=0.694 (0.3s)', '\\n', 'Saved\nexperiment data to', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-\n17_23-44-22_conceptual_generalization_poly_rule_attempt_0/0-\nrun/process_ForkProcess-17/working/experiment_data.npy', '\\n', 'Execution time:\n5 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 2000 examples [00:00, 127042.37\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 500 examples [00:00, 120609.16\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 196684.83\nexamples/s]', '\\n', \"{'train': 2000, 'dev': 500, 'test': 1000}\", '\\n', 'Baseline\nEpoch 1: tr_loss=0.4121 val_loss=1.3240 trF1=0.815 valF1=0.688 RGA=0.688\n(0.6s)', '\\n', 'Baseline Epoch 2: tr_loss=0.0751 val_loss=1.8213 trF1=0.977\nvalF1=0.692 RGA=0.692 (0.3s)', '\\n', 'Baseline Epoch 3: tr_loss=0.0405\nval_loss=1.9424 trF1=0.988 valF1=0.698 RGA=0.698 (0.3s)', '\\n', 'SymToken Epoch\n1: tr_loss=0.6287 val_loss=0.6744 trF1=0.646 valF1=0.682 RGA=0.682 (0.3s)',\n'\\n', 'SymToken Epoch 2: tr_loss=0.1318 val_loss=1.4574 trF1=0.967 valF1=0.696\nRGA=0.696 (0.3s)', '\\n', 'SymToken Epoch 3: tr_loss=0.0489 val_loss=1.5619\ntrF1=0.985 valF1=0.696 RGA=0.696 (0.3s)', '\\n', 'SymToken-FrozenSymProj Epoch 1:\ntr_loss=0.5686 val_loss=0.8791 trF1=0.722 valF1=0.682 RGA=0.682 (0.3s)', '\\n',\n'SymToken-FrozenSymProj Epoch 2: tr_loss=0.1132 val_loss=1.4533 trF1=0.959\nvalF1=0.696 RGA=0.696 (0.3s)', '\\n', 'SymToken-FrozenSymProj Epoch 3:\ntr_loss=0.0464 val_loss=1.5682 trF1=0.988 valF1=0.700 RGA=0.700 (0.3s)', '\\n',\n'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-17_23-44-\n22_conceptual_generalization_poly_rule_attempt_0/0-run/process_ForkProcess-\n18/working/experiment_data.npy', '\\n', 'Execution time: 5 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 2000 examples [00:00, 159312.66\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 500 examples [00:00, 118436.32\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 196860.23\nexamples/s]', '\\n', \"{'train': 2000, 'dev': 500, 'test': 1000}\", '\\n', 'Baseline\nEpoch 1: tr_loss=0.3181 val_loss=1.5100 trF1=0.876 valF1=0.674 RGA=0.674\n(1.1s)', '\\n', 'Baseline Epoch 2: tr_loss=0.0667 val_loss=1.7268 trF1=0.980\nvalF1=0.688 RGA=0.688 (0.8s)', '\\n', 'Baseline Epoch 3: tr_loss=0.0586\nval_loss=1.7083 trF1=0.984 valF1=0.684 RGA=0.684 (0.8s)', '\\n', 'SymToken Epoch\n1: tr_loss=0.4359 val_loss=1.1713 trF1=0.813 valF1=0.672 RGA=0.672 (0.8s)',\n'\\n', 'SymToken Epoch 2: tr_loss=0.1336 val_loss=1.3505 trF1=0.960 valF1=0.692\nRGA=0.692 (0.8s)', '\\n', 'SymToken Epoch 3: tr_loss=0.0711 val_loss=1.6104\ntrF1=0.980 valF1=0.694 RGA=0.694 (0.8s)', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-17_23-44-\n22_conceptual_generalization_poly_rule_attempt_0/0-run/process_ForkProcess-\n19/working/experiment_data.npy', '\\n', 'Execution time: 7 seconds seconds (time\nlimit is 30 minutes).']"], "analysis": ["", "", "", "", ""], "exc_type": [null, null, null, null, null], "exc_info": [null, null, null, null, null], "exc_stack": [null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "macro_f1", "lower_is_better": false, "description": "Macro-averaged F1 score for classification tasks.", "data": [{"dataset_name": "Baseline - train", "final_value": 0.9885, "best_value": 0.9885}, {"dataset_name": "Baseline - validation", "final_value": 0.698, "best_value": 0.698}, {"dataset_name": "SymToken - train", "final_value": 0.985, "best_value": 0.985}, {"dataset_name": "SymToken - validation", "final_value": 0.696, "best_value": 0.696}]}, {"metric_name": "accuracy", "lower_is_better": false, "description": "Accuracy of the model on the validation dataset.", "data": [{"dataset_name": "Baseline - validation", "final_value": 0.698, "best_value": 0.698}, {"dataset_name": "SymToken - validation", "final_value": 0.696, "best_value": 0.696}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss value indicating model performance, lower is better.", "data": [{"dataset_name": "Baseline - training", "final_value": 0.0405, "best_value": 0.0405}, {"dataset_name": "Baseline - validation", "final_value": 1.9424, "best_value": 1.9424}, {"dataset_name": "SymToken - training", "final_value": 0.0489, "best_value": 0.0489}, {"dataset_name": "SymToken - validation", "final_value": 1.5619, "best_value": 1.5619}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0803, "best_value": 0.0405}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.8258, "best_value": 1.5619}]}, {"metric_name": "train macro F1 score", "lower_is_better": false, "description": "The macro F1 score during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9735, "best_value": 0.9885}]}, {"metric_name": "validation macro F1 score", "lower_is_better": false, "description": "The macro F1 score during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.686, "best_value": 0.698}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.686, "best_value": 0.698}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0405, "best_value": 0.0405}, {"dataset_name": "SPR_BENCH", "final_value": 0.0489, "best_value": 0.0489}, {"dataset_name": "SPR_BENCH", "final_value": 0.063, "best_value": 0.063}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.9424, "best_value": 1.9424}, {"dataset_name": "SPR_BENCH", "final_value": 1.5619, "best_value": 1.5619}, {"dataset_name": "SPR_BENCH", "final_value": 1.5903, "best_value": 1.5903}]}, {"metric_name": "train macro F1", "lower_is_better": false, "description": "The macro-averaged F1 score of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9885, "best_value": 0.9885}, {"dataset_name": "SPR_BENCH", "final_value": 0.985, "best_value": 0.985}, {"dataset_name": "SPR_BENCH", "final_value": 0.978, "best_value": 0.978}]}, {"metric_name": "validation macro F1", "lower_is_better": false, "description": "The macro-averaged F1 score of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.698, "best_value": 0.698}, {"dataset_name": "SPR_BENCH", "final_value": 0.696, "best_value": 0.696}, {"dataset_name": "SPR_BENCH", "final_value": 0.694, "best_value": 0.694}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.698, "best_value": 0.698}, {"dataset_name": "SPR_BENCH", "final_value": 0.696, "best_value": 0.696}, {"dataset_name": "SPR_BENCH", "final_value": 0.694, "best_value": 0.694}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss on the training dataset.", "data": [{"dataset_name": "Baseline", "final_value": 0.0405, "best_value": 0.0405}, {"dataset_name": "SymToken", "final_value": 0.0489, "best_value": 0.0489}, {"dataset_name": "SymToken-FrozenSymProj", "final_value": 0.0464, "best_value": 0.0464}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss on the validation dataset.", "data": [{"dataset_name": "Baseline", "final_value": 1.9424, "best_value": 1.9424}, {"dataset_name": "SymToken", "final_value": 1.5619, "best_value": 1.5619}, {"dataset_name": "SymToken-FrozenSymProj", "final_value": 1.5682, "best_value": 1.5682}]}, {"metric_name": "train macro F1 score", "lower_is_better": false, "description": "The macro F1 score on the training dataset.", "data": [{"dataset_name": "Baseline", "final_value": 0.9885, "best_value": 0.9885}, {"dataset_name": "SymToken", "final_value": 0.985, "best_value": 0.985}, {"dataset_name": "SymToken-FrozenSymProj", "final_value": 0.988, "best_value": 0.988}]}, {"metric_name": "validation macro F1 score", "lower_is_better": false, "description": "The macro F1 score on the validation dataset.", "data": [{"dataset_name": "Baseline", "final_value": 0.698, "best_value": 0.698}, {"dataset_name": "SymToken", "final_value": 0.696, "best_value": 0.696}, {"dataset_name": "SymToken-FrozenSymProj", "final_value": 0.7, "best_value": 0.7}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy on the validation dataset.", "data": [{"dataset_name": "Baseline", "final_value": 0.698, "best_value": 0.698}, {"dataset_name": "SymToken", "final_value": 0.696, "best_value": 0.696}, {"dataset_name": "SymToken-FrozenSymProj", "final_value": 0.7, "best_value": 0.7}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value on the training dataset.", "data": [{"dataset_name": "Baseline", "final_value": 0.05863941958546638, "best_value": 0.05863941958546638}, {"dataset_name": "SymToken", "final_value": 0.07114528150856494, "best_value": 0.07114528150856494}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset.", "data": [{"dataset_name": "Baseline", "final_value": 1.7082951860427857, "best_value": 1.7082951860427857}, {"dataset_name": "SymToken", "final_value": 1.6104203786849975, "best_value": 1.6104203786849975}]}, {"metric_name": "train macro F1", "lower_is_better": false, "description": "The macro F1 score on the training dataset.", "data": [{"dataset_name": "Baseline", "final_value": 0.9839983998399839, "best_value": 0.9839983998399839}, {"dataset_name": "SymToken", "final_value": 0.9799971195852203, "best_value": 0.9799971195852203}]}, {"metric_name": "validation macro F1", "lower_is_better": false, "description": "The macro F1 score on the validation dataset.", "data": [{"dataset_name": "Baseline", "final_value": 0.6839797747055811, "best_value": 0.6839797747055811}, {"dataset_name": "SymToken", "final_value": 0.693969396939694, "best_value": 0.693969396939694}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy on the validation dataset.", "data": [{"dataset_name": "Baseline", "final_value": 0.684, "best_value": 0.684}, {"dataset_name": "SymToken", "final_value": 0.694, "best_value": 0.694}]}]}], "is_best_node": [false, false, false, true, false], "plots": [["../../logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_f1_curves.png", "../../logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_final_val_f1_bar.png", "../../logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_confusion_Baseline.png"], ["../../logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_loss_curves.png", "../../logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_macro_f1_curves.png", "../../logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_final_scores.png"], ["../../logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_macroF1_curves.png", "../../logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_val_accuracy.png", "../../logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_baseline_confusion.png"], ["../../logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_macroF1_curves.png", "../../logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_GT_vs_Pred_Baseline.png"], ["../../logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_Baseline_loss_curve.png", "../../logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_Baseline_f1_curve.png", "../../logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_SymToken_loss_curve.png", "../../logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_SymToken_f1_curve.png", "../../logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_val_macro_f1_comparison.png"]], "plot_paths": [["experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_loss_curves.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_f1_curves.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_final_val_f1_bar.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_confusion_Baseline.png"], ["experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_loss_curves.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_macro_f1_curves.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_accuracy_curves.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_final_scores.png"], ["experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_loss_curves.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_macroF1_curves.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_val_accuracy.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_baseline_confusion.png"], ["experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_loss_curves.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_macroF1_curves.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_accuracy_curves.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_GT_vs_Pred_Baseline.png"], ["experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_Baseline_loss_curve.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_Baseline_f1_curve.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_SymToken_loss_curve.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_SymToken_f1_curve.png", "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_val_macro_f1_comparison.png"]], "plot_analyses": [[{"analysis": "This plot shows the training and validation loss trends for the baseline and symbolic token (SymToken) models. The baseline model achieves consistently lower training and validation loss compared to the SymToken model. While the baseline model converges quickly, the SymToken model struggles with higher loss values, indicating challenges in learning or optimization for the symbolic reasoning modules. The gap between training and validation losses for the SymToken model suggests potential overfitting or a need for better hyperparameter tuning.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot compares the macro-F1 scores of the baseline and SymToken models during training and validation. The baseline model achieves significantly higher macro-F1 scores, indicating better performance on the classification task. The SymToken model shows minimal improvement over epochs, suggesting difficulty in leveraging symbolic reasoning for enhanced performance. The lack of significant improvement in validation scores for the SymToken model points to possible generalization issues.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_f1_curves.png"}, {"analysis": "This bar chart compares the final validation macro-F1 scores of the baseline and SymToken models. Both models achieve similar final scores, with the baseline slightly outperforming the SymToken model. This result suggests that the symbolic reasoning modules in the SymToken model do not provide a clear advantage in terms of overall performance on the validation set.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_final_val_f1_bar.png"}, {"analysis": "This confusion matrix visualizes the performance of the baseline model on the test set. The diagonal elements represent correct predictions, while off-diagonal elements indicate misclassifications. The matrix shows a reasonable balance in the classification performance across classes, with relatively low misclassification rates. This supports the baseline model's robustness and effectiveness in handling the SPR_BENCH dataset.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_2b7eac33c2d341b4867b07e86ce4f259_proc_3469037/SPR_BENCH_confusion_Baseline.png"}], [{"analysis": "The training and validation loss curves indicate that the baseline model overfits significantly, as the validation loss increases while the training loss decreases. The SymToken and SymToken-NoGate models show better alignment between training and validation losses, suggesting improved generalization. The SymToken model demonstrates the lowest training and validation losses, indicating superior performance in learning the underlying patterns of the SPR task.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_loss_curves.png"}, {"analysis": "The Macro-F1 scores reveal that the SymToken model achieves the highest performance on both training and validation sets, closely followed by the SymToken-NoGate model. The baseline model lags significantly, especially in validation performance, highlighting its inability to generalize well. The SymToken model's consistent improvement across epochs reflects its robustness and effectiveness in capturing complex symbolic reasoning rules.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_macro_f1_curves.png"}, {"analysis": "Validation accuracy trends show that the SymToken model consistently outperforms the baseline and SymToken-NoGate models. While the baseline model demonstrates a steady improvement, it is surpassed by the SymToken model, which achieves the highest validation accuracy. The SymToken-NoGate model also improves steadily but remains below its counterparts, suggesting that gating mechanisms in SymToken contribute to its superior performance.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_accuracy_curves.png"}, {"analysis": "Final validation scores confirm that the SymToken model outperforms both the baseline and SymToken-NoGate models in Macro-F1 and accuracy metrics. The SymToken-NoGate model performs slightly better than the baseline but falls short of the SymToken model, emphasizing the importance of the gating mechanism in achieving higher performance. Overall, the results validate the hypothesis that augmenting transformer models with symbolic reasoning capabilities enhances their performance on the SPR task.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_322c00cc6df34f13a329982c7bfc55b9_proc_3475546/spr_bench_final_scores.png"}], [{"analysis": "The training and validation loss curves indicate that the baseline model exhibits a significant gap between training and validation losses, suggesting overfitting. The SymToken and SymToken_RandomSym models show a better balance between training and validation losses, with lower overall loss values. Among these, SymToken demonstrates the lowest validation loss, indicating better generalization compared to SymToken_RandomSym.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_loss_curves.png"}, {"analysis": "The validation Macro-F1 scores show that the SymToken model outperforms both the baseline and SymToken_RandomSym models, with a notable improvement over the training epochs. The SymToken_RandomSym model also improves over time but lags behind SymToken. The baseline model's performance improves steadily but remains below both augmented models.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_macroF1_curves.png"}, {"analysis": "The final validation accuracy comparison shows that all models achieve similar accuracy levels, with the baseline slightly outperforming the SymToken and SymToken_RandomSym models. This suggests that while accuracy is comparable, other metrics like loss and Macro-F1 highlight the advantages of the augmented models.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_val_accuracy.png"}, {"analysis": "The baseline confusion matrix reveals that the model struggles with certain classes, as indicated by the off-diagonal elements. This highlights potential areas where the baseline model could be improved, particularly in better handling specific categories.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_576e9219385544aba93ceec801370404_proc_3475547/SPR_BENCH_baseline_confusion.png"}], [{"analysis": "The loss curves indicate that the Baseline model struggles to converge on the validation set, as its validation loss increases over epochs. In contrast, the SymToken and SymToken-FrozenSymProj models show better convergence behavior, with decreasing validation loss over time. This suggests that the symbolic reasoning enhancements improve the model's ability to generalize and avoid overfitting to the training data.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_loss_curves.png"}, {"analysis": "The Macro-F1 curves demonstrate that the SymToken-FrozenSymProj model achieves the best performance on both the training and validation sets. The Baseline model has a significant gap between its training and validation Macro-F1 scores, indicating potential overfitting. The SymToken model performs better than the Baseline but is outperformed by the SymToken-FrozenSymProj model, highlighting the importance of the frozen symbolic projection component.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_macroF1_curves.png"}, {"analysis": "The validation accuracy curves reveal that the SymToken-FrozenSymProj model outperforms both the Baseline and SymToken models consistently across epochs. This suggests that the frozen symbolic projection contributes positively to the model's reasoning capabilities, enabling better generalization on the validation set.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_accuracy_curves.png"}, {"analysis": "The comparison of ground truth and baseline predictions shows a balanced distribution of class IDs in the ground truth data. The baseline predictions also exhibit a similar distribution, indicating that the baseline model learns to predict classes in a manner consistent with the dataset's distribution. However, this does not necessarily imply high accuracy or reasoning capability, as the model could still be making errors within each class.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_45a4a49951cb4c2095f7560ab0f8eabe_proc_3475548/SPR_BENCH_GT_vs_Pred_Baseline.png"}], [{"analysis": "The training loss decreases steadily and approaches zero by the end of the third epoch, indicating that the baseline model is effectively learning the training data. However, the validation loss increases consistently, suggesting significant overfitting. This indicates that the baseline model struggles to generalize to unseen data.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_Baseline_loss_curve.png"}, {"analysis": "The Macro-F1 score for training improves steadily and approaches 1.0 by the end of the third epoch, confirming the model's strong performance on the training data. However, the validation Macro-F1 score remains relatively stagnant, with only a slight increase before plateauing, further highlighting the overfitting problem.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_Baseline_f1_curve.png"}, {"analysis": "The SymToken model exhibits a similar trend to the baseline model, with the training loss decreasing steadily and approaching zero. However, the validation loss increases over time, indicating that this model also suffers from overfitting despite the added symbolic reasoning capabilities.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_SymToken_loss_curve.png"}, {"analysis": "The training Macro-F1 score for the SymToken model improves significantly, reaching near-perfect performance by the third epoch. The validation Macro-F1 score shows a slight improvement over the baseline but still plateaus early, indicating limited generalization improvements.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_SymToken_f1_curve.png"}, {"analysis": "The SymToken model outperforms the baseline model in validation Macro-F1 score across all epochs, with a noticeable improvement in the early epochs. This suggests that the symbolic reasoning augmentation provides some benefit in terms of generalization, but the overall trend indicates that the improvement is not substantial enough to overcome overfitting issues.", "plot_path": "experiments/2025-08-17_23-44-22_conceptual_generalization_poly_rule_attempt_0/logs/0-run/experiment_results/experiment_4eec595c58a3449482fb6981589176c9_proc_3475549/SPR_BENCH_val_macro_f1_comparison.png"}]], "vlm_feedback_summary": ["The analysis reveals that the baseline model outperforms the SymToken model in\nterms of training/validation loss, macro-F1 scores, and overall classification\nperformance. The symbolic reasoning modules in the SymToken model do not provide\na clear performance advantage, and further optimization or architectural\nadjustments may be needed to harness their potential.", "The plots effectively demonstrate the improved performance of the SymToken\nmodel, particularly in terms of generalization and symbolic reasoning\ncapabilities. The analyses highlight the contributions of the symbolic reasoning\nmodules and gating mechanisms, showcasing their impact on achieving state-of-\nthe-art results for the SPR task.", "The analysis highlights that the SymToken model exhibits superior generalization\nand performance metrics compared to the baseline and SymToken_RandomSym models,\nparticularly in terms of validation loss and Macro-F1 scores. However, the final\nvalidation accuracy is similar across models, suggesting that other metrics\nprovide more nuanced insights into model performance.", "The plots provide valuable insights into the performance of different models on\nthe SPR_BENCH dataset. The symbolic reasoning enhancements, particularly the\nfrozen symbolic projection, improve the model's generalization capabilities, as\nevidenced by better loss convergence, higher Macro-F1 scores, and improved\nvalidation accuracy. The results indicate that the proposed symbolic reasoning\nmodules contribute positively to the model's ability to handle complex reasoning\ntasks.", "The experimental results indicate that both the baseline and SymToken models\neffectively learn the training data, as evidenced by the decreasing training\nloss and increasing training Macro-F1 scores. However, both models struggle with\ngeneralization, as indicated by the increasing validation loss and plateauing\nvalidation Macro-F1 scores. The SymToken model shows a slight improvement over\nthe baseline in validation performance, suggesting that the symbolic reasoning\naugmentation provides some benefit, but further work is needed to address\noverfitting and improve generalization."], "exec_time": [8.033915042877197, 11.32346248626709, 5.327534437179565, 5.693298816680908, 7.69118070602417], "exec_time_feedback": ["", "", "", "", ""], "datasets_successfully_tested": [["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], ["[]"]], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ndataset_name = \"SPR_BENCH\"\nruns = experiment_data.get(dataset_name, {})\n\n# gather per-model statistics\nepochs, loss_tr, loss_val, f1_tr, f1_val, final_val_f1 = {}, {}, {}, {}, {}, {}\nfor model_name, run in runs.items():\n    loss_tr[model_name] = [x[\"loss\"] for x in run[\"losses\"][\"train\"]]\n    loss_val[model_name] = [x[\"loss\"] for x in run[\"losses\"][\"val\"]]\n    f1_tr[model_name] = [x[\"macro_f1\"] for x in run[\"metrics\"][\"train\"]]\n    f1_val[model_name] = [x[\"macro_f1\"] for x in run[\"metrics\"][\"val\"]]\n    epochs[model_name] = [x[\"epoch\"] for x in run[\"metrics\"][\"train\"]]\n    final_val_f1[model_name] = f1_val[model_name][-1] if f1_val[model_name] else 0.0\n\n# 1) Loss curves\ntry:\n    plt.figure()\n    for m in runs:\n        plt.plot(epochs[m], loss_tr[m], \"--\", label=f\"{m}-train\")\n        plt.plot(epochs[m], loss_val[m], label=f\"{m}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"Training vs Validation Loss\\nDataset: SPR_BENCH\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# 2) Macro-F1 curves\ntry:\n    plt.figure()\n    for m in runs:\n        plt.plot(epochs[m], f1_tr[m], \"--\", label=f\"{m}-train\")\n        plt.plot(epochs[m], f1_val[m], label=f\"{m}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Macro-F1\")\n    plt.title(\"Training vs Validation Macro-F1\\nDataset: SPR_BENCH\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_f1_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating F1 curves: {e}\")\n    plt.close()\n\n# 3) Bar chart of final val Macro-F1\ntry:\n    plt.figure()\n    models = list(runs.keys())\n    vals = [final_val_f1[m] for m in models]\n    plt.bar(np.arange(len(models)), vals, tick_label=models)\n    plt.ylabel(\"Final Val Macro-F1\")\n    plt.xlabel(\"Model\")\n    plt.title(\"Final Validation Macro-F1 per Model\\nDataset: SPR_BENCH\")\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_val_f1_bar.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating bar chart: {e}\")\n    plt.close()\n\n# 4) Confusion matrix for best model\nbest_model = max(final_val_f1, key=final_val_f1.get) if final_val_f1 else None\nif best_model:\n    try:\n        preds = runs[best_model][\"predictions\"]\n        gts = runs[best_model][\"ground_truth\"]\n        cm = confusion_matrix(gts, preds)\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.title(f\"Confusion Matrix\\nDataset: SPR_BENCH; Model: {best_model}\")\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.savefig(os.path.join(working_dir, f\"SPR_BENCH_confusion_{best_model}.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\n# ------------------------------------------------------------------\nif final_val_f1:\n    print(f\"Best model: {best_model} ({final_val_f1[best_model]:.4f} Macro-F1)\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------- load data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ndataset = \"SPR_BENCH\"\nmodels = list(experiment_data.get(dataset, {}).keys())\nif not models:\n    print(\"No data found, aborting plots.\")\nelse:\n    epoch_nums = range(\n        1, len(experiment_data[dataset][models[0]][\"losses\"][\"train\"]) + 1\n    )\n\n    # -------------------------------------------------------- 1) loss curves\n    try:\n        plt.figure()\n        for m in models:\n            tr = [d[\"loss\"] for d in experiment_data[dataset][m][\"losses\"][\"train\"]]\n            val = [d[\"loss\"] for d in experiment_data[dataset][m][\"losses\"][\"val\"]]\n            plt.plot(epoch_nums, tr, label=f\"{m}-train\")\n            plt.plot(epoch_nums, val, \"--\", label=f\"{m}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_bench_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # -------------------------------------------------------- 2) macro-F1 curves\n    try:\n        plt.figure()\n        for m in models:\n            tr = [\n                d[\"macro_f1\"] for d in experiment_data[dataset][m][\"metrics\"][\"train\"]\n            ]\n            val = [d[\"macro_f1\"] for d in experiment_data[dataset][m][\"metrics\"][\"val\"]]\n            plt.plot(epoch_nums, tr, label=f\"{m}-train\")\n            plt.plot(epoch_nums, val, \"--\", label=f\"{m}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Macro-F1\")\n        plt.title(\"SPR_BENCH: Training vs Validation Macro-F1\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_bench_macro_f1_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating macro-F1 plot: {e}\")\n        plt.close()\n\n    # -------------------------------------------------------- 3) RGA / accuracy curves\n    try:\n        plt.figure()\n        for m in models:\n            val = [d[\"RGA\"] for d in experiment_data[dataset][m][\"metrics\"][\"val\"]]\n            plt.plot(epoch_nums, val, label=f\"{m}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy (RGA)\")\n        plt.title(\"SPR_BENCH: Validation Accuracy over Epochs\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_bench_accuracy_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot: {e}\")\n        plt.close()\n\n    # -------------------------------------------------------- 4) final-epoch bar chart\n    try:\n        last_f1 = [\n            experiment_data[dataset][m][\"metrics\"][\"val\"][-1][\"macro_f1\"]\n            for m in models\n        ]\n        last_acc = [\n            experiment_data[dataset][m][\"metrics\"][\"val\"][-1][\"RGA\"] for m in models\n        ]\n        x = np.arange(len(models))\n        width = 0.35\n        plt.figure()\n        plt.bar(x - width / 2, last_f1, width, label=\"Macro-F1\")\n        plt.bar(x + width / 2, last_acc, width, label=\"Accuracy\")\n        plt.xticks(x, models)\n        plt.ylim(0, 1)\n        plt.ylabel(\"Score\")\n        plt.title(\"SPR_BENCH: Final Validation Scores\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"spr_bench_final_scores.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating final score bar chart: {e}\")\n        plt.close()\n\n    # -------------------------------------------------------- print final metrics\n    print(\"\\nFinal Validation Metrics:\")\n    for m in models:\n        f1 = experiment_data[dataset][m][\"metrics\"][\"val\"][-1][\"macro_f1\"]\n        acc = experiment_data[dataset][m][\"metrics\"][\"val\"][-1][\"RGA\"]\n        print(f\"{m}: Macro-F1={f1:.3f}, Accuracy={acc:.3f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\n\n# ---- paths / loading ----\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\ntry:\n    experiment_data = np.load(exp_path, allow_pickle=True).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nmodels = list(experiment_data.keys())\n\n\n# Helper to grab lists\ndef grab(path):\n    out = []\n    for d in path:\n        out.append(d[list(d.keys() - {\"epoch\"})[0]])  # pick the sole metric/loss key\n    return out\n\n\n# ---- Plot 1: Loss curves ----\ntry:\n    plt.figure()\n    for m in models:\n        exp = experiment_data[m][\"SPR_BENCH\"]\n        ep = [d[\"epoch\"] for d in exp[\"losses\"][\"train\"]]\n        plt.plot(ep, grab(exp[\"losses\"][\"train\"]), label=f\"{m} Train\")\n        plt.plot(ep, grab(exp[\"losses\"][\"val\"]), label=f\"{m} Val\", linestyle=\"--\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ---- Plot 2: Macro-F1 curves ----\ntry:\n    plt.figure()\n    for m in models:\n        exp = experiment_data[m][\"SPR_BENCH\"]\n        ep = [d[\"epoch\"] for d in exp[\"metrics\"][\"val\"]]\n        plt.plot(ep, [d[\"macro_f1\"] for d in exp[\"metrics\"][\"val\"]], label=m)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Macro-F1\")\n    plt.title(\"SPR_BENCH: Validation Macro-F1 over Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_macroF1_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating F1 plot: {e}\")\n    plt.close()\n\n# ---- Plot 3: Final validation accuracy bar chart ----\ntry:\n    plt.figure()\n    accs = [\n        experiment_data[m][\"SPR_BENCH\"][\"metrics\"][\"val\"][-1][\"RGA\"] for m in models\n    ]\n    plt.bar(models, accs)\n    plt.ylabel(\"Validation Accuracy (RGA)\")\n    plt.title(\"SPR_BENCH: Final Validation Accuracy Comparison\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_val_accuracy.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy plot: {e}\")\n    plt.close()\n\n# ---- Plot 4: Confusion matrix for Baseline ----\ntry:\n    base = experiment_data[\"Baseline\"][\"SPR_BENCH\"]\n    y_true, y_pred = base[\"ground_truth\"], base[\"predictions\"]\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure()\n    im = plt.imshow(cm, cmap=\"Blues\")\n    plt.colorbar(im)\n    plt.title(\"SPR_BENCH: Baseline Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_baseline_confusion.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ---- Print final summary ----\nprint(\"Final Validation Metrics:\")\nfor m in models:\n    val = experiment_data[m][\"SPR_BENCH\"][\"metrics\"][\"val\"][-1]\n    print(f\"{m:20s}  Macro-F1: {val['macro_f1']:.3f}  RGA: {val['RGA']:.3f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\n\n# ------------------------------------------------- paths / load\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    exp_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp_data = {}\n\nds_name = \"SPR_BENCH\"\nif ds_name not in exp_data:\n    print(f\"{ds_name} not found in experiment data\")\n    exit()\n\ndset = exp_data[ds_name]\nmodels = list(dset.keys())\n\n# ------------------------------------------------- figure 1 : loss curves\ntry:\n    plt.figure()\n    for m in models:\n        ep = [d[\"epoch\"] for d in dset[m][\"losses\"][\"train\"]]\n        tr = [d[\"loss\"] for d in dset[m][\"losses\"][\"train\"]]\n        val = [d[\"loss\"] for d in dset[m][\"losses\"][\"val\"]]\n        plt.plot(ep, tr, label=f\"{m}-train\")\n        plt.plot(ep, val, \"--\", label=f\"{m}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-entropy loss\")\n    plt.title(f\"{ds_name} Loss Curves\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f\"{ds_name}_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------- figure 2 : macro-F1 curves\ntry:\n    plt.figure()\n    for m in models:\n        ep = [d[\"epoch\"] for d in dset[m][\"metrics\"][\"train\"]]\n        tr = [d[\"macro_f1\"] for d in dset[m][\"metrics\"][\"train\"]]\n        val = [d[\"macro_f1\"] for d in dset[m][\"metrics\"][\"val\"]]\n        plt.plot(ep, tr, label=f\"{m}-train\")\n        plt.plot(ep, val, \"--\", label=f\"{m}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Macro-F1\")\n    plt.title(f\"{ds_name} Macro-F1 Curves\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f\"{ds_name}_macroF1_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating macro-F1 plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------- figure 3 : accuracy curves (RGA in exp dict)\ntry:\n    plt.figure()\n    for m in models:\n        ep = [d[\"epoch\"] for d in dset[m][\"metrics\"][\"val\"]]\n        acc = [d[\"RGA\"] for d in dset[m][\"metrics\"][\"val\"]]\n        plt.plot(ep, acc, label=m)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Validation Accuracy (RGA)\")\n    plt.title(f\"{ds_name} Validation Accuracy Curves\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, f\"{ds_name}_accuracy_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------- figure 4 : ground truth vs baseline predictions\ntry:\n    base_preds = dset[\"Baseline\"][\"predictions\"]\n    base_gts = dset[\"Baseline\"][\"ground_truth\"]\n    if base_preds and len(base_preds) == len(base_gts):\n        classes = sorted(set(base_gts))\n        gt_counts = [base_gts.count(c) for c in classes]\n        pr_counts = [base_preds.count(c) for c in classes]\n\n        fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n        ax[0].bar(classes, gt_counts, color=\"tab:blue\")\n        ax[0].set_title(\"Ground Truth\")\n        ax[1].bar(classes, pr_counts, color=\"tab:orange\")\n        ax[1].set_title(\"Baseline Predictions\")\n        fig.suptitle(f\"{ds_name} \u2013 Left: Ground Truth, Right: Generated Samples\")\n        for a in ax:\n            a.set_xlabel(\"Class id\")\n            a.set_ylabel(\"Count\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_GT_vs_Pred_Baseline.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating GT vs prediction plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------- quick metric printout\nfor m in models:\n    last_val = dset[m][\"metrics\"][\"val\"][-1]\n    print(\n        f\"{m:25s} | Epoch {last_val['epoch']} | Val Macro-F1={last_val['macro_f1']:.3f} | RGA={last_val['RGA']:.3f}\"\n    )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# create / verify working dir\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    exp_path = os.path.join(working_dir, \"experiment_data.npy\")\n    experiment_data = np.load(exp_path, allow_pickle=True).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nbench_key = \"SPR_BENCH\"\nroot = experiment_data.get(\"NoPositionalEmbedding\", {}).get(bench_key, {})\n\nval_f1_compare = {}  # for final overlay plot\n\nfor model_name, logs in root.items():\n    # --------- gather data ----------\n    tr_loss = [(d[\"epoch\"], d[\"loss\"]) for d in logs[\"losses\"][\"train\"]]\n    val_loss = [(d[\"epoch\"], d[\"loss\"]) for d in logs[\"losses\"][\"val\"]]\n    tr_f1 = [(d[\"epoch\"], d[\"macro_f1\"]) for d in logs[\"metrics\"][\"train\"]]\n    val_f1 = [(d[\"epoch\"], d[\"macro_f1\"]) for d in logs[\"metrics\"][\"val\"]]\n    # save val f1 curve for comparison plot\n    val_f1_compare[model_name] = val_f1\n\n    # --------- loss curve ----------\n    try:\n        plt.figure()\n        if tr_loss:\n            ep, loss = zip(*tr_loss)\n            plt.plot(ep, loss, label=\"Train\")\n        if val_loss:\n            ep_v, loss_v = zip(*val_loss)\n            plt.plot(ep_v, loss_v, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"SPR_BENCH {model_name} Loss Curve\")\n        plt.legend()\n        fname = f\"SPR_BENCH_{model_name}_loss_curve.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {model_name}: {e}\")\n        plt.close()\n\n    # --------- F1 curve ----------\n    try:\n        plt.figure()\n        if tr_f1:\n            ep, f1 = zip(*tr_f1)\n            plt.plot(ep, f1, label=\"Train\")\n        if val_f1:\n            ep_v, f1_v = zip(*val_f1)\n            plt.plot(ep_v, f1_v, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Macro-F1\")\n        plt.title(f\"SPR_BENCH {model_name} Macro-F1 Curve\")\n        plt.legend()\n        fname = f\"SPR_BENCH_{model_name}_f1_curve.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating F1 plot for {model_name}: {e}\")\n        plt.close()\n\n    # --------- print final metrics ----------\n    if logs[\"metrics\"][\"val\"]:\n        last = logs[\"metrics\"][\"val\"][-1]\n        print(\n            f\"{model_name} | Final Val Macro-F1: {last['macro_f1']:.3f} | RGA(Acc): {last['RGA']:.3f}\"\n        )\n\n# --------- comparison plot ----------\ntry:\n    if val_f1_compare:\n        plt.figure()\n        for model_name, curve in val_f1_compare.items():\n            ep, f1 = zip(*curve)\n            plt.plot(ep, f1, label=model_name)\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Macro-F1\")\n        plt.title(\"SPR_BENCH Validation Macro-F1 Comparison\")\n        plt.legend()\n        fname = \"SPR_BENCH_val_macro_f1_comparison.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating comparison plot: {e}\")\n    plt.close()\n"], "plot_plan": ["We load the saved experiment_data.npy, extract per-model train/val losses and Macro-F1 across epochs, and identify the best model by final val Macro-F1. Four separate try-except blocks then generate (1) loss curves, (2) Macro-F1 curves, (3) a bar chart comparing final val Macro-F1 of Baseline vs SymToken, and (4) a confusion matrix for the best model\u2019s predictions vs ground truth. Every figure is titled, saved under a descriptive name in working_dir, and properly closed to conserve resources. We rely solely on data present in experiment_data.npy, plotting at most one figure per category to stay within the 5-figure cap. Finally, we print the best model and its score to stdout.", "We first load the saved experiment_data.npy, extract the nested dict for the SPR_BENCH dataset, and gather epoch-wise losses and metrics for the three models. Four visualizations will be generated (loss curves, macro-F1 curves, RGA/accuracy curves, and a final-epoch bar chart) and each will be wrapped in its own try-except block to satisfy robustness requirements. For every curve plot we place training and validation lines side-by-side\u2014using solid and dashed linestyles\u2014to make comparisons clear; all three models share the same axes to reduce the total number of figures (<5). Each plot is titled, saved to working_dir with descriptive filenames, and the figure object is closed immediately afterwards. After plotting, we compute the final-epoch validation macro-F1 and RGA for every model and print them so the notebook log contains explicit numeric results. No synthetic data are created; everything is read directly from experiment_data. Paths are constructed with os.path.join to keep compatibility across execution environments. The code remains minimal and uses only basic matplotlib defaults in accordance with the guidelines.", "We will load the saved experiment_data.npy, loop through the three model variants and extract per-epoch losses, macro-F1 scores, and final validation accuracies. Four plots will be produced: (1) combined training/validation loss curves, (2) combined validation macro-F1 curves, (3) a bar chart comparing final validation accuracies (RGA) for the three models, and (4) a confusion-matrix heat-map for the Baseline model\u2019s final predictions vs. ground truth.  Each figure is wrapped in its own try-except block, titled clearly, saved under descriptive filenames that include the dataset name, and then closed.  We respect the \u22645-figure guideline.  After plotting, we also print a small table of the final macro-F1 and RGA values for quick inspection.  No synthetic data are generated\u2014everything comes directly from experiment_data.npy.  The script starts with the required imports, ensures working_dir exists, and runs end-to-end in a few concise lines.", "We will load the saved numpy dictionary, iterate over the single dataset (SPR_BENCH) and all available model variants, and then:\n1) draw loss curves (train / val) for every model;\n2) draw macro-F1 curves (train / val) for every model;\n3) draw validation accuracy (RGA) curves for every model;\n4) show a two-panel figure comparing ground-truth class distribution (left) with the Baseline model\u2019s predictions (right) so that we satisfy the \u201cLeft: Ground Truth, Right: Generated Samples\u201d subtitle guideline.  \nEach figure is wrapped in its own try/except block and saved with descriptive names inside the mandatory working directory; figures are always closed.  \nAt the end we print final validation macro-F1 and RGA for every model to give a quick numerical summary.", "We first load the saved experiment_data.npy, then iterate through each model under the SPR_BENCH dataset. For every model we extract epoch-wise training/validation losses and macro-F1 scores, building two basic line plots per model (loss curve and F1 curve). Each plot is wrapped in its own try-except block, given a clear title and saved with a descriptive filename inside the working directory. Finally, after plotting we print the last-epoch validation macro-F1 and accuracy (RGA) so users can quickly view final metrics on stdout. At most one additional comparison plot is produced that overlays the validation macro-F1 curves of all models, keeping total figures \u22645. All figures are closed after saving to prevent memory leaks."], "ablation_name": [null, "SymToken-NoGate", "SymToken-RandomSym", "SymToken-FrozenSymProj", "NoPositionalEmbedding"], "hyperparam_name": [null, null, null, null, null], "is_seed_node": [false, false, false, false, false], "is_seed_agg_node": [false, false, false, false, false], "parse_metrics_plan": ["The solution loads the saved NumPy file, walks through the nested dictionary to\nreach the two experimental runs (Baseline and SymToken), and then prints the\nfinal-epoch values for every recorded metric and loss in a clear, labelled way.\nAll logic is in the global scope so the script runs immediately.", "Below is a small utility that loads the saved NumPy dictionary, walks through\nits nested structure, and prints the final-epoch metrics for every model inside\neach dataset.  It respects the required wording for each metric label and prints\nthe dataset name first, followed by all models and their final values.", "The script will load the saved NumPy dictionary, iterate over every experiment\n(Baseline, SymToken, SymToken_RandomSym) and its contained dataset(s) (e.g.,\nSPR_BENCH), fetch the last entry recorded for each loss/metric list, and print\nthe dataset name followed by clearly-labelled final metrics (train loss,\nvalidation loss, train macro F1, validation macro F1, validation accuracy).\nNothing is placed under an `if __name__ == \"__main__\":` guard, so the code\nexecutes immediately upon running.", "The script will load the serialized results dictionary from\nworking/experiment_data.npy, iterate through the three experiment entries stored\nunder the key \"SPR_BENCH\", and for each one print the final-epoch values of\nevery recorded metric.  We extract the last element of the \u201ctrain\u201d and \u201cval\u201d\nlists in both the metrics and losses sub-dictionaries, then report them with\nexplicit labels such as \u201cFinal train macro F1 score\u201d, \u201cFinal validation\naccuracy\u201d, etc., preceded by the experiment name.  No plots or special entry\npoint are used, so the code runs immediately on execution.", "We will load the NumPy file from the working directory, turn it back into a\nPython dictionary, and then walk through the nested structure: top configuration\n\u279c dataset \u279c model.   For each dataset we print its name once, then for every\nmodel under it we fetch the last (i.e., final\u2010epoch) entry from the losses and\nmetrics lists, extract the desired statistics, and print them with fully\nqualified labels such as \u201ctrain macro F1\u201d or \u201cvalidation accuracy.\u201d   No\nplotting or special entry-point guard is used; the script executes immediately\nwhen run."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# --------------------------------------------------------------------- load data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------- print metrics\n# The outermost key is the benchmark; inside are the individual experiment runs.\nbenchmark_name, benchmark_dict = next(iter(experiment_data.items()))\n\nfor run_name, run_dict in benchmark_dict.items():\n    print(run_name)  # dataset / run name first\n\n    # ----- losses\n    final_train_loss = run_dict[\"losses\"][\"train\"][-1][\"loss\"]\n    final_val_loss = run_dict[\"losses\"][\"val\"][-1][\"loss\"]\n\n    # ----- metrics\n    final_train_metrics = run_dict[\"metrics\"][\"train\"][-1]\n    final_val_metrics = run_dict[\"metrics\"][\"val\"][-1]\n\n    # training metrics\n    print(f\"train macro_f1: {final_train_metrics['macro_f1']:.4f}\")\n    # validation metrics\n    print(f\"validation macro_f1: {final_val_metrics['macro_f1']:.4f}\")\n    print(f\"validation accuracy: {final_val_metrics['RGA']:.4f}\")\n    # losses\n    print(f\"training loss: {final_train_loss:.4f}\")\n    print(f\"validation loss: {final_val_loss:.4f}\")\n    print()  # blank line between runs\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------- paths / loading\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------- pretty printer\ndef safe_last(lst, default=None):\n    \"\"\"Return last element of a list or default if list is empty.\"\"\"\n    return lst[-1] if lst else default\n\n\nfor dataset_name, models in experiment_data.items():\n    print(f\"Dataset: {dataset_name}\")\n    for model_name, results in models.items():\n        # Grab final (last epoch) entries\n        train_metrics_last = safe_last(results[\"metrics\"][\"train\"], {})\n        val_metrics_last = safe_last(results[\"metrics\"][\"val\"], {})\n        train_loss_last = safe_last(results[\"losses\"][\"train\"], {})\n        val_loss_last = safe_last(results[\"losses\"][\"val\"], {})\n\n        print(f\"  Model: {model_name}\")\n        if train_loss_last:\n            print(f\"    train loss: {train_loss_last.get('loss'):.4f}\")\n        if val_loss_last:\n            print(f\"    validation loss: {val_loss_last.get('loss'):.4f}\")\n        if train_metrics_last:\n            print(f\"    train macro F1 score: {train_metrics_last.get('macro_f1'):.4f}\")\n        if val_metrics_last:\n            print(\n                f\"    validation macro F1 score: {val_metrics_last.get('macro_f1'):.4f}\"\n            )\n            # 'RGA' in the original code is actually validation accuracy\n            val_acc = val_metrics_last.get(\"RGA\")\n            if val_acc is not None:\n                print(f\"    validation accuracy: {val_acc:.4f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------ load data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------- helper extractor\ndef last_value(list_of_dicts, key, default=None):\n    \"\"\"Return the value of `key` from the last dictionary in the list.\"\"\"\n    if list_of_dicts:\n        return list_of_dicts[-1].get(key, default)\n    return default\n\n\n# --------------------------------------------------------------- print metrics\nfor exp_name, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        # Fetch final / best values (using last epoch recorded)\n        final_train_loss = last_value(data[\"losses\"][\"train\"], \"loss\")\n        final_val_loss = last_value(data[\"losses\"][\"val\"], \"loss\")\n        final_train_f1 = last_value(data[\"metrics\"][\"train\"], \"macro_f1\")\n        final_val_f1 = last_value(data[\"metrics\"][\"val\"], \"macro_f1\")\n        final_val_acc = last_value(data[\"metrics\"][\"val\"], \"RGA\")\n\n        # Print dataset header\n        print(f\"{exp_name} - {dataset_name}\")\n        # Print clear metric names\n        print(f\"train loss: {final_train_loss:.4f}\")\n        print(f\"validation loss: {final_val_loss:.4f}\")\n        print(f\"train macro F1: {final_train_f1:.4f}\")\n        print(f\"validation macro F1: {final_val_f1:.4f}\")\n        print(f\"validation accuracy: {final_val_acc:.4f}\")\n        print()  # blank line for readability\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# locate and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# iterate over experiments and print final metrics\nspr_results = experiment_data.get(\"SPR_BENCH\", {})\nfor experiment_name, data in spr_results.items():\n    print(experiment_name)  # dataset / experiment header\n\n    # ---- losses ----\n    final_train_loss = data[\"losses\"][\"train\"][-1][\"loss\"]\n    final_val_loss = data[\"losses\"][\"val\"][-1][\"loss\"]\n    print(f\"  Final train loss: {final_train_loss:.4f}\")\n    print(f\"  Final validation loss: {final_val_loss:.4f}\")\n\n    # ---- metrics ----\n    final_train_macro_f1 = data[\"metrics\"][\"train\"][-1][\"macro_f1\"]\n    final_val_macro_f1 = data[\"metrics\"][\"val\"][-1][\"macro_f1\"]\n    final_val_accuracy = data[\"metrics\"][\"val\"][-1][\"RGA\"]  # stored as accuracy\n    print(f\"  Final train macro F1 score: {final_train_macro_f1:.4f}\")\n    print(f\"  Final validation macro F1 score: {final_val_macro_f1:.4f}\")\n    print(f\"  Final validation accuracy: {final_val_accuracy:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------------\n# 0. Locate file and load data\n# --------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# --------------------------------------------------------------------------\n# 1. Traverse structure and print final metrics\n# --------------------------------------------------------------------------\nfor top_cfg_name, datasets in experiment_data.items():  # e.g., \"NoPositionalEmbedding\"\n    for dataset_name, models in datasets.items():  # e.g., \"SPR_BENCH\"\n        print(dataset_name)  # Requirement #3\n\n        for model_name, record in models.items():  # e.g., \"Baseline\", \"SymToken\"\n            # Safeguard against empty lists\n            if record[\"losses\"][\"train\"] and record[\"losses\"][\"val\"]:\n                final_train_loss = record[\"losses\"][\"train\"][-1][\"loss\"]\n                final_val_loss = record[\"losses\"][\"val\"][-1][\"loss\"]\n            else:\n                final_train_loss = final_val_loss = None\n\n            if record[\"metrics\"][\"train\"] and record[\"metrics\"][\"val\"]:\n                final_train_f1 = record[\"metrics\"][\"train\"][-1][\"macro_f1\"]\n                final_val_f1 = record[\"metrics\"][\"val\"][-1][\"macro_f1\"]\n                final_val_acc = record[\"metrics\"][\"val\"][-1][\n                    \"RGA\"\n                ]  # accuracy stored as RGA\n            else:\n                final_train_f1 = final_val_f1 = final_val_acc = None\n\n            # ------------------------------------------------------------------\n            # 2. Print metrics with explicit names (Requirement #4 & #5)\n            # ------------------------------------------------------------------\n            print(f\"  {model_name} train loss: {final_train_loss}\")\n            print(f\"  {model_name} validation loss: {final_val_loss}\")\n            print(f\"  {model_name} train macro F1: {final_train_f1}\")\n            print(f\"  {model_name} validation macro F1: {final_val_f1}\")\n            print(f\"  {model_name} validation accuracy: {final_val_acc}\")\n"], "parse_term_out": ["['Baseline', '\\n', 'train macro_f1: 0.9885', '\\n', 'validation macro_f1:\n0.6980', '\\n', 'validation accuracy: 0.6980', '\\n', 'training loss: 0.0405',\n'\\n', 'validation loss: 1.9424', '\\n', '\\n', 'SymToken', '\\n', 'train macro_f1:\n0.9850', '\\n', 'validation macro_f1: 0.6960', '\\n', 'validation accuracy:\n0.6960', '\\n', 'training loss: 0.0489', '\\n', 'validation loss: 1.5619', '\\n',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', '  Model: Baseline', '\\n', '    train loss:\n0.0405', '\\n', '    validation loss: 1.9424', '\\n', '    train macro F1 score:\n0.9885', '\\n', '    validation macro F1 score: 0.6980', '\\n', '    validation\naccuracy: 0.6980', '\\n', '  Model: SymToken', '\\n', '    train loss: 0.0489',\n'\\n', '    validation loss: 1.5619', '\\n', '    train macro F1 score: 0.9850',\n'\\n', '    validation macro F1 score: 0.6960', '\\n', '    validation accuracy:\n0.6960', '\\n', '  Model: SymToken-NoGate', '\\n', '    train loss: 0.0803', '\\n',\n'    validation loss: 1.8258', '\\n', '    train macro F1 score: 0.9735', '\\n', '\nvalidation macro F1 score: 0.6860', '\\n', '    validation accuracy: 0.6860',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Baseline - SPR_BENCH', '\\n', 'train loss: 0.0405', '\\n', 'validation loss:\n1.9424', '\\n', 'train macro F1: 0.9885', '\\n', 'validation macro F1: 0.6980',\n'\\n', 'validation accuracy: 0.6980', '\\n', '\\n', 'SymToken - SPR_BENCH', '\\n',\n'train loss: 0.0489', '\\n', 'validation loss: 1.5619', '\\n', 'train macro F1:\n0.9850', '\\n', 'validation macro F1: 0.6960', '\\n', 'validation accuracy:\n0.6960', '\\n', '\\n', 'SymToken_RandomSym - SPR_BENCH', '\\n', 'train loss:\n0.0630', '\\n', 'validation loss: 1.5903', '\\n', 'train macro F1: 0.9780', '\\n',\n'validation macro F1: 0.6940', '\\n', 'validation accuracy: 0.6940', '\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Baseline', '\\n', '  Final train loss: 0.0405', '\\n', '  Final validation loss:\n1.9424', '\\n', '  Final train macro F1 score: 0.9885', '\\n', '  Final validation\nmacro F1 score: 0.6980', '\\n', '  Final validation accuracy: 0.6980\\n', '\\n',\n'SymToken', '\\n', '  Final train loss: 0.0489', '\\n', '  Final validation loss:\n1.5619', '\\n', '  Final train macro F1 score: 0.9850', '\\n', '  Final validation\nmacro F1 score: 0.6960', '\\n', '  Final validation accuracy: 0.6960\\n', '\\n',\n'SymToken-FrozenSymProj', '\\n', '  Final train loss: 0.0464', '\\n', '  Final\nvalidation loss: 1.5682', '\\n', '  Final train macro F1 score: 0.9880', '\\n', '\nFinal validation macro F1 score: 0.7000', '\\n', '  Final validation accuracy:\n0.7000\\n', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', '  Baseline train loss: 0.05863941958546638', '\\n', '\nBaseline validation loss: 1.7082951860427857', '\\n', '  Baseline train macro F1:\n0.9839983998399839', '\\n', '  Baseline validation macro F1: 0.6839797747055811',\n'\\n', '  Baseline validation accuracy: 0.684', '\\n', '  SymToken train loss:\n0.07114528150856494', '\\n', '  SymToken validation loss: 1.6104203786849975',\n'\\n', '  SymToken train macro F1: 0.9799971195852203', '\\n', '  SymToken\nvalidation macro F1: 0.693969396939694', '\\n', '  SymToken validation accuracy:\n0.694', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']"], "parse_exc_type": [null, null, null, null, null], "parse_exc_info": [null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]}