<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 4], [0, 11], [0, 9], [0, 1], [0, 12], [0, 10], [0, 3], [0, 2], [3, 5], [3, 6], [3, 7], [3, 8]], "layout": [[0.5, 0.0], [0.0, 0.5], [0.14285714285714285, 0.5], [0.2857142857142857, 0.5], [0.42857142857142855, 0.5], [0.07142857142857142, 1.0], [0.21428571428571427, 1.0], [0.35714285714285715, 1.0], [0.5, 1.0], [0.5714285714285714, 0.5], [0.7142857142857143, 0.5], [0.8571428571428571, 0.5], [1.0, 0.5]], "plan": ["The previous implementation built color\u2010IDs with `token[1:]` (the whole suffix)\nwhile the evaluation weights extracted only a single character (`token[1]`).\nThis silent mismatch changed the statistics the network learnt from versus the\nstatistics used for weighting during validation, hurting both learning dynamics\nand the reported metric.   The fix is to use **exactly the same colour\nextraction everywhere** and to centralise this logic in one helper so it is\nimpossible to diverge again.  While touching the code, we also add explicit\nself-loops (important for GraphSAGE), follow the device-handling guidelines and\nkeep full bookkeeping required by the framework.", "Ablation name: No-Positional-Embedding. The solution duplicates the original\npipeline but defines an ablation flag \u201cNoPosEmb\u201d.   A modified GNN\n(`GNNClassifierNoPos`) only sums shape and colour embeddings, omitting the\npositional\u2010index embedding while keeping the rest of the graph logic untouched,\nthereby measuring the value of explicit positional information.   All\nbookkeeping is stored under the nested dictionary key\n`experiment_data['NoPosEmb']['SPR_BENCH']` and persisted to\n`experiment_data.npy` exactly as required.", "Ablation name: Sequential-Only-Graph. We re\u2010factor the baseline into a reusable\nrun_experiment() that (1) re-encodes the dataset with or without relational\nedges, (2) trains a fresh GNN, (3) evaluates on dev/test, and (4) stores\neverything in the required experiment_data structure.   Two runs are executed:\n\u2022 FULL \u2013 original graph (sequential + same-shape + same-colour).   \u2022 SEQ_ONLY \u2013\nablation with only bidirectional sequential edges and self-loops.   All\nmetrics/losses/predictions are saved to \u201cexperiment_data.npy\u201d.", "Ablation name: No-Self-Loop Graph. We eliminate the explicit call to\nadd_self_loops in seq_to_graph, keeping every other component identical. This\nway, node features can only travel through true inter-node edges (sequential,\nsame shape, same colour). The rest of the training / evaluation / bookkeeping\npipeline is unchanged, but results are stored under the ablation key\n\u201cno_self_loop\u201d.", "Ablation name: No-Batch-Normalization. This solution reruns the baseline\npipeline with the only architectural change being the removal of both BatchNorm\nlayers (bn1, bn2).  Everything else (dataset handling, training loop, hyper-\nparameters, bookkeeping, early stopping, saving) is kept identical, allowing a\nclean comparison with the baseline.  BatchNorm removal is achieved by replacing\nthe layers with nn.Identity().  Results, losses, metrics and predictions are\nstored under the ablation key 'no_batch_norm' and saved to experiment_data.npy.", "The previous script occasionally crashes on real SPR_BENCH because the\npositional-embedding table is hard-coded to length 20 (pos_limit=20).  Whenever\na sequence is longer than this constant, an \u201cindex out of range\u201d error is\ntriggered during the forward pass.  The fix is simply to size the positional-\nembedding layer dynamically to the longest sequence found in the whole benchmark\n(or any reasonable upper bound) and to guarantee that every position id fed to\nthe model is < pos_max.  While touching the code we also add tracking for the\nnew Combined Structural Weighted Accuracy (CSWA) metric and keep the rest of the\npipeline unchanged.  The rest of the implementation follows the original design\nbut now adapts automatically to arbitrary sequence lengths.", "The previous training crashes on real SPR_BENCH because the position-embedding\ntable is hard-coded to length 20 while many sequences are longer, producing\nindex-out-of-range errors.   We fix this by building the position vocabulary\nafter reading the data, setting pos_limit = (max sequence length + 1).  In\naddition, we expose the requested Combined-Structural-Weighted-Accuracy (CSWA)\nmetric, track it every epoch for train/validation/test, and persist all\nbookkeeping information.  The rest of the pipeline (graph construction, \u201cno-\nself-loop\u201d GNN, training loop, early-stopping) is kept unchanged, but all\ntensors/models are consistently moved to the selected device.", "The previous run-time crashes on real SPR_BENCH data because the positional-\nembedding table is fixed to 20, yet many evaluation sequences are longer, so\nindices overflow the lookup.   We now scan every split first, derive the true\nmaximum token length, and size the position embedding dynamically.   While\nrevising we also:   \u2022 build vocabularies over **all** splits to avoid OOV\nfailures;   \u2022 add the requested Combined Structural-Weighted Accuracy (CSWA)\nmetric and record it every epoch;   \u2022 keep full GPU/CPU compliance and save all\nbook-keeping in \u201cworking/experiment_data.npy\u201d.", "The previous run relied on a hard-coded positional\u2010embedding size (pos_limit =\n20).   Real SPR_BENCH sequences are often longer, so any token whose position \u2265\n20 would raise an \u201cindex out of range\u201d error during training/inference.   We\nfirst scan the training split to determine the true maximum sequence length and\ncreate the positional embedding with capacity (max_len + 1).   The rest of the\npipeline is unchanged except that we now compute and log the three requested\nmetrics (CWA, SWA, CSWA) every epoch and store everything inside experiment_data\nbefore saving it to ./working.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, time, math, copy, random\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool, BatchNorm\nfrom torch_geometric.utils import add_self_loops\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ======================================================================\n# 1.  Low-level sequence helpers (SINGLE SOURCE OF TRUTH)\n# ======================================================================\ndef colour_of(token: str) -> str:\n    \"\"\"Return the colour substring of a token (may be multiple chars).\"\"\"\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    \"\"\"Return the leading shape symbol.\"\"\"\n    return token[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(tok) for tok in seq.split() if tok))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(tok) for tok in seq.split() if tok))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(1, sum(w))\n\n\n# ======================================================================\n# 2.  Load or synthesize SPR_BENCH\n# ======================================================================\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef load_spr(path: str) -> DatasetDict:\n    if os.path.isdir(path):\n\n        def _ld(split):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        print(\"Loaded SPR_BENCH from\", path)\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n\n    # ---------- tiny fallback ----------\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes = list(\"ABCDEF\")\n    colours = [str(i) for i in range(10)]\n\n    def make_seq():\n        L = random.randint(4, 9)\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours) for _ in range(L)\n        )\n\n    def label_rule(seq):\n        return sum(int(colour_of(tok)) for tok in seq.split()) % 2\n\n    def split(n):\n        seqs = [make_seq() for _ in range(n)]\n        return Dataset.from_dict(\n            {\n                \"id\": list(range(n)),\n                \"sequence\": seqs,\n                \"label\": [label_rule(s) for s in seqs],\n            }\n        )\n\n    return DatasetDict(train=split(800), dev=split(200), test=split(200))\n\n\nspr = load_spr(SPR_PATH)\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in spr.items()}, \"classes:\", num_classes)\n\n# ======================================================================\n# 3.  Build vocabularies\n# ======================================================================\nshape_vocab, colour_vocab = {}, {}\n\n\ndef add_shape(s):\n    if s not in shape_vocab:\n        shape_vocab[s] = len(shape_vocab)\n\n\ndef add_colour(c):\n    if c not in colour_vocab:\n        colour_vocab[c] = len(colour_vocab)\n\n\nfor seq in spr[\"train\"][\"sequence\"]:\n    for tok in seq.split():\n        add_shape(shape_of(tok))\n        add_colour(colour_of(tok))\n\npos_limit = 20  # safe upper bound\n\n\n# ======================================================================\n# 4.  Sequence \u2192 graph encoder\n# ======================================================================\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks], dtype=torch.long)\n    colour_ids = torch.tensor(\n        [colour_vocab[colour_of(t)] for t in toks], dtype=torch.long\n    )\n    pos_ids = torch.tensor(list(range(n)), dtype=torch.long)\n\n    # edges: sequential (bi-directional)\n    edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n\n    # edges: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shape_of(toks[i]) == shape_of(toks[j]):\n                edges += [[i, j], [j, i]]\n\n    # edges: same colour\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colour_of(toks[i]) == colour_of(toks[j]):\n                edges += [[i, j], [j, i]]\n\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    # add self loops\n    edge_index, _ = add_self_loops(edge_index, num_nodes=n)\n\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,\n        edge_index=edge_index,\n        y=torch.tensor(label, dtype=torch.long),\n        seq=seq,  # keep raw text for metrics\n    )\n\n\ndef encode_split(ds):\n    return [seq_to_graph(s, l) for s, l in zip(ds[\"sequence\"], ds[\"label\"])]\n\n\ntrain_graphs, dev_graphs, test_graphs = map(\n    encode_split, (spr[\"train\"], spr[\"dev\"], spr[\"test\"])\n)\n\n# ======================================================================\n# 5.  DataLoaders\n# ======================================================================\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# ======================================================================\n# 6.  GNN model\n# ======================================================================\nclass GNNClassifier(nn.Module):\n    def __init__(self, n_shape, n_colour, pos_max, hid=64, n_classes=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_colour, hid)\n        self.pos_emb = nn.Embedding(pos_max, hid)\n\n        self.conv1 = SAGEConv(hid, hid)\n        self.bn1 = BatchNorm(hid)\n        self.conv2 = SAGEConv(hid, hid)\n        self.bn2 = BatchNorm(hid)\n\n        self.lin = nn.Linear(hid, n_classes)\n        self.drop = nn.Dropout(0.3)\n\n    def forward(self, data):\n        x = (\n            self.shape_emb(data.shape_id)\n            + self.col_emb(data.colour_id)\n            + self.pos_emb(data.pos_id)\n        )\n\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        graph_x = global_add_pool(x, data.batch)  # sum-pool captures counts\n        return self.lin(graph_x)\n\n\nmodel = GNNClassifier(\n    len(shape_vocab), len(colour_vocab), pos_limit, 64, num_classes\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# ======================================================================\n# 7.  Book-keeping dict\n# ======================================================================\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"sequences\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ======================================================================\n# 8.  Train / evaluate helpers\n# ======================================================================\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, pred_all, true_all = [], [], []\n\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n\n        seqs_all.extend(batch.seq)\n        pred_all.extend(preds)\n        true_all.extend(gts)\n\n    return (\n        tot_loss / tot,\n        tot_correct / tot,\n        comp_weighted_acc(seqs_all, true_all, pred_all),\n        seqs_all,\n        pred_all,\n        true_all,\n    )\n\n\ndef train_epoch(loader):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n\n    for batch in loader:\n        batch = batch.to(device)\n\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n\n    return tot_loss / tot, tot_correct / tot\n\n\n# ======================================================================\n# 9.  Training loop\n# ======================================================================\nmax_epochs, patience = 40, 8\nbest_val_loss = math.inf\nbest_state = None\npat = 0\nstart = time.time()\n\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_acc = train_epoch(train_loader)\n    val_loss, val_acc, val_cwa, _, _, _ = evaluate(dev_loader)\n\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"epoch\": epoch, \"acc\": tr_acc}\n    )\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"epoch\": epoch, \"acc\": val_acc, \"CompWA\": val_cwa}\n    )\n\n    print(\n        f\"Epoch {epoch:02d}: validation_loss = {val_loss:.4f} | val_acc={val_acc:.3f} | CompWA={val_cwa:.3f}\"\n    )\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        experiment_data[\"SPR_BENCH\"][\"best_epoch\"] = epoch\n        pat = 0\n    else:\n        pat += 1\n        if pat >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ======================================================================\n# 10.  Test evaluation\n# ======================================================================\nif best_state:\n    model.load_state_dict(best_state)\n\ntest_loss, test_acc, test_cwa, seqs, preds, gts = evaluate(test_loader)\nprint(f\"TEST -- loss:{test_loss:.4f} acc:{test_acc:.3f} CompWA:{test_cwa:.3f}\")\n\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = gts\nexperiment_data[\"SPR_BENCH\"][\"sequences\"] = seqs\n\n# ======================================================================\n# 11.  Save bookkeeping\n# ======================================================================\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"saved experiment_data.npy\")\n", "# ==============================================================\n# No-Positional-Embedding Ablation for SPR-BENCH\n# ==============================================================\n\nimport os, time, math, copy, random\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool, BatchNorm\nfrom torch_geometric.utils import add_self_loops\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ==============================================================\n# 1. Low-level helpers\n# ==============================================================\ndef colour_of(tok: str) -> str:\n    return tok[1:] if len(tok) > 1 else \"\"\n\n\ndef shape_of(tok: str) -> str:\n    return tok[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(t) for t in seq.split() if t))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(t) for t in seq.split() if t))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(1, sum(w))\n\n\n# ==============================================================\n# 2. Load / synthesize SPR_BENCH\n# ==============================================================\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef load_spr(path: str) -> DatasetDict:\n    if os.path.isdir(path):\n\n        def _ld(split):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        print(\"Loaded SPR_BENCH from\", path)\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n\n    # Tiny synthetic fallback\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes = list(\"ABCDEF\")\n    colours = [str(i) for i in range(10)]\n\n    def make_seq():\n        L = random.randint(4, 9)\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours) for _ in range(L)\n        )\n\n    def label_rule(seq):\n        return sum(int(colour_of(tok)) for tok in seq.split()) % 2\n\n    def split(n):\n        seqs = [make_seq() for _ in range(n)]\n        return Dataset.from_dict(\n            {\n                \"id\": list(range(n)),\n                \"sequence\": seqs,\n                \"label\": [label_rule(s) for s in seqs],\n            }\n        )\n\n    return DatasetDict(train=split(800), dev=split(200), test=split(200))\n\n\nspr = load_spr(SPR_PATH)\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in spr.items()}, \"classes:\", num_classes)\n\n# ==============================================================\n# 3. Build vocabularies\n# ==============================================================\nshape_vocab, colour_vocab = {}, {}\n\n\ndef add_shape(s):  # noqa: D401\n    if s not in shape_vocab:\n        shape_vocab[s] = len(shape_vocab)\n\n\ndef add_colour(c):\n    if c not in colour_vocab:\n        colour_vocab[c] = len(colour_vocab)\n\n\nfor seq in spr[\"train\"][\"sequence\"]:\n    for tok in seq.split():\n        add_shape(shape_of(tok))\n        add_colour(colour_of(tok))\n\npos_limit = 20  # safe upper bound for padding (still used in graphs)\n\n\n# ==============================================================\n# 4. Sequence \u2192 graph encoder\n# ==============================================================\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks], dtype=torch.long)\n    colour_ids = torch.tensor(\n        [colour_vocab[colour_of(t)] for t in toks], dtype=torch.long\n    )\n    pos_ids = torch.tensor(list(range(n)), dtype=torch.long)\n\n    # edges \u2013 sequential (bidirectional)\n    edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n\n    # edges \u2013 same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shape_of(toks[i]) == shape_of(toks[j]):\n                edges += [[i, j], [j, i]]\n\n    # edges \u2013 same colour\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colour_of(toks[i]) == colour_of(toks[j]):\n                edges += [[i, j], [j, i]]\n\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    edge_index, _ = add_self_loops(edge_index, num_nodes=n)\n\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,  # kept for consistency, not used by model\n        edge_index=edge_index,\n        y=torch.tensor(label, dtype=torch.long),\n        seq=seq,\n    )\n\n\ndef encode_split(ds):\n    return [seq_to_graph(s, l) for s, l in zip(ds[\"sequence\"], ds[\"label\"])]\n\n\ntrain_graphs, dev_graphs, test_graphs = map(\n    encode_split, (spr[\"train\"], spr[\"dev\"], spr[\"test\"])\n)\n\n# ==============================================================\n# 5. DataLoaders\n# ==============================================================\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# ==============================================================\n# 6. GNN w/o positional embedding\n# ==============================================================\nclass GNNClassifierNoPos(nn.Module):\n    def __init__(self, n_shape, n_colour, hid=64, n_classes=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_colour, hid)\n\n        self.conv1 = SAGEConv(hid, hid)\n        self.bn1 = BatchNorm(hid)\n        self.conv2 = SAGEConv(hid, hid)\n        self.bn2 = BatchNorm(hid)\n\n        self.lin = nn.Linear(hid, n_classes)\n        self.drop = nn.Dropout(0.3)\n\n    def forward(self, data):\n        x = self.shape_emb(data.shape_id) + self.col_emb(data.colour_id)\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        graph_x = global_add_pool(x, data.batch)  # sum\u2010pool\n        return self.lin(graph_x)\n\n\nmodel = GNNClassifierNoPos(len(shape_vocab), len(colour_vocab), 64, num_classes).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# ==============================================================\n# 7. Book-keeping dict\n# ==============================================================\nEXP_TYPE = \"NoPosEmb\"\nexperiment_data = {\n    EXP_TYPE: {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"sequences\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\nbook = experiment_data[EXP_TYPE][\"SPR_BENCH\"]\n\n\n# ==============================================================\n# 8. Train / evaluate helpers\n# ==============================================================\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, pred_all, true_all = [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n\n        seqs_all.extend(batch.seq)\n        pred_all.extend(preds)\n        true_all.extend(gts)\n\n    return (\n        tot_loss / tot,\n        tot_correct / tot,\n        comp_weighted_acc(seqs_all, true_all, pred_all),\n        seqs_all,\n        pred_all,\n        true_all,\n    )\n\n\ndef train_epoch(loader):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n    return tot_loss / tot, tot_correct / tot\n\n\n# ==============================================================\n# 9. Training loop with early stopping\n# ==============================================================\nmax_epochs, patience = 40, 8\nbest_val_loss = math.inf\nbest_state, pat = None, 0\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_acc = train_epoch(train_loader)\n    val_loss, val_acc, val_cwa, *_ = evaluate(dev_loader)\n\n    book[\"losses\"][\"train\"].append(tr_loss)\n    book[\"losses\"][\"val\"].append(val_loss)\n    book[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"acc\": tr_acc})\n    book[\"metrics\"][\"val\"].append({\"epoch\": epoch, \"acc\": val_acc, \"CompWA\": val_cwa})\n\n    print(\n        f\"Epoch {epoch:02d}: val_loss={val_loss:.4f} | val_acc={val_acc:.3f} | CompWA={val_cwa:.3f}\"\n    )\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        book[\"best_epoch\"] = epoch\n        pat = 0\n    else:\n        pat += 1\n        if pat >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ==============================================================\n# 10. Test evaluation\n# ==============================================================\nif best_state:\n    model.load_state_dict(best_state)\n\ntest_loss, test_acc, test_cwa, seqs, preds, gts = evaluate(test_loader)\nprint(f\"TEST -- loss:{test_loss:.4f} acc:{test_acc:.3f} CompWA:{test_cwa:.3f}\")\n\nbook[\"predictions\"] = preds\nbook[\"ground_truth\"] = gts\nbook[\"sequences\"] = seqs\n\n# ==============================================================\n# 11. Save bookkeeping\n# ==============================================================\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"saved experiment_data.npy\")\n", "import os, time, math, copy, random\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool, BatchNorm\nfrom torch_geometric.utils import add_self_loops\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ======================================================================\n# 1.  Low-level helpers (single source of truth)\n# ======================================================================\ndef colour_of(token: str) -> str:\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    return token[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(t) for t in seq.split() if t))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(t) for t in seq.split() if t))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(1, sum(w))\n\n\n# ======================================================================\n# 2.  Load / synthesize dataset\n# ======================================================================\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef load_spr(path: str) -> DatasetDict:\n    if os.path.isdir(path):\n\n        def _ld(split):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        print(\"Loaded SPR_BENCH from\", path)\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes, colours = list(\"ABCDEF\"), [str(i) for i in range(10)]\n\n    def make_seq():\n        L = random.randint(4, 9)\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours) for _ in range(L)\n        )\n\n    def label_rule(seq):\n        return sum(int(colour_of(t)) for t in seq.split()) % 2\n\n    def split(n):\n        seqs = [make_seq() for _ in range(n)]\n        return Dataset.from_dict(\n            {\n                \"id\": list(range(n)),\n                \"sequence\": seqs,\n                \"label\": [label_rule(s) for s in seqs],\n            }\n        )\n\n    return DatasetDict(train=split(800), dev=split(200), test=split(200))\n\n\nspr = load_spr(SPR_PATH)\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in spr.items()}, \"classes:\", num_classes)\n\n# ======================================================================\n# 3.  Build vocabularies\n# ======================================================================\nshape_vocab, colour_vocab = {}, {}\n\n\ndef add_shape(s):\n    if s not in shape_vocab:\n        shape_vocab[s] = len(shape_vocab)\n\n\ndef add_colour(c):\n    if c not in colour_vocab:\n        colour_vocab[c] = len(colour_vocab)\n\n\nfor seq in spr[\"train\"][\"sequence\"]:\n    for tok in seq.split():\n        add_shape(shape_of(tok))\n        add_colour(colour_of(tok))\npos_limit = 20  # safe upper bound\n\n\n# ======================================================================\n# 4.  Graph conversion (supports ablation switch)\n# ======================================================================\ndef seq_to_graph(seq, label, include_rel_edges: bool):\n    toks = seq.split()\n    n = len(toks)\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks], dtype=torch.long)\n    colour_ids = torch.tensor(\n        [colour_vocab[colour_of(t)] for t in toks], dtype=torch.long\n    )\n    pos_ids = torch.tensor(list(range(n)), dtype=torch.long)\n\n    # mandatory sequential edges\n    edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n\n    # additional relational edges\n    if include_rel_edges:\n        for i in range(n):\n            for j in range(i + 1, n):\n                if shape_of(toks[i]) == shape_of(toks[j]):\n                    edges += [[i, j], [j, i]]\n                if colour_of(toks[i]) == colour_of(toks[j]):\n                    edges += [[i, j], [j, i]]\n\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    edge_index, _ = add_self_loops(edge_index, num_nodes=n)\n\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,\n        edge_index=edge_index,\n        y=torch.tensor(label, dtype=torch.long),\n        seq=seq,\n    )\n\n\ndef encode_split(ds, include_rel_edges):\n    return [\n        seq_to_graph(s, l, include_rel_edges)\n        for s, l in zip(ds[\"sequence\"], ds[\"label\"])\n    ]\n\n\n# ======================================================================\n# 5.  Model definition\n# ======================================================================\nclass GNNClassifier(nn.Module):\n    def __init__(self, n_shape, n_colour, pos_max, hid=64, n_classes=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_colour, hid)\n        self.pos_emb = nn.Embedding(pos_max, hid)\n        self.conv1, self.bn1 = SAGEConv(hid, hid), BatchNorm(hid)\n        self.conv2, self.bn2 = SAGEConv(hid, hid), BatchNorm(hid)\n        self.lin = nn.Linear(hid, n_classes)\n        self.drop = nn.Dropout(0.3)\n\n    def forward(self, data):\n        x = (\n            self.shape_emb(data.shape_id)\n            + self.col_emb(data.colour_id)\n            + self.pos_emb(data.pos_id)\n        )\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        graph_x = global_add_pool(x, data.batch)  # sum-pool\n        return self.lin(graph_x)\n\n\n# ======================================================================\n# 6.  Training / eval helpers\n# ======================================================================\n@torch.no_grad()\ndef evaluate(model, loader, criterion):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, pred_all, true_all = [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n        seqs_all.extend(batch.seq)\n        pred_all.extend(preds)\n        true_all.extend(gts)\n    return (\n        tot_loss / tot,\n        tot_correct / tot,\n        comp_weighted_acc(seqs_all, true_all, pred_all),\n        seqs_all,\n        pred_all,\n        true_all,\n    )\n\n\ndef train_epoch(model, loader, optimizer, criterion):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n    return tot_loss / tot, tot_correct / tot\n\n\n# ======================================================================\n# 7.  Experiment runner\n# ======================================================================\ndef run_experiment(ablation_name: str, include_rel_edges: bool, experiment_dict):\n    print(f\"\\n==== Running {ablation_name} ====\")\n    # Encode graphs & loaders\n    train_graphs = encode_split(spr[\"train\"], include_rel_edges)\n    dev_graphs = encode_split(spr[\"dev\"], include_rel_edges)\n    test_graphs = encode_split(spr[\"test\"], include_rel_edges)\n    train_loader = DataLoader(train_graphs, batch_size=128, shuffle=True)\n    dev_loader = DataLoader(dev_graphs, batch_size=128)\n    test_loader = DataLoader(test_graphs, batch_size=128)\n\n    # Model & opt\n    model = GNNClassifier(\n        len(shape_vocab), len(colour_vocab), pos_limit, 64, num_classes\n    ).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n    # Book-keeping\n    experiment_dict[ablation_name] = {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"sequences\": [],\n            \"best_epoch\": None,\n        }\n    }\n    rec = experiment_dict[ablation_name][\"SPR_BENCH\"]\n\n    # Training loop\n    best_val_loss = math.inf\n    best_state = None\n    pat = 0\n    patience = 8\n    max_epochs = 40\n    for epoch in range(1, max_epochs + 1):\n        tr_loss, tr_acc = train_epoch(model, train_loader, optimizer, criterion)\n        val_loss, val_acc, val_cwa, *_ = evaluate(model, dev_loader, criterion)\n        rec[\"losses\"][\"train\"].append(tr_loss)\n        rec[\"losses\"][\"val\"].append(val_loss)\n        rec[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"acc\": tr_acc})\n        rec[\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"acc\": val_acc, \"CompWA\": val_cwa}\n        )\n        if epoch % 1 == 0:\n            print(\n                f\"[{ablation_name}] Epoch {epoch:02d}  val_loss={val_loss:.4f}  acc={val_acc:.3f}  CompWA={val_cwa:.3f}\"\n            )\n        if val_loss < best_val_loss - 1e-4:\n            best_val_loss = val_loss\n            best_state = copy.deepcopy(model.state_dict())\n            rec[\"best_epoch\"] = epoch\n            pat = 0\n        else:\n            pat += 1\n            if pat >= patience:\n                break\n\n    # Test evaluation\n    if best_state is not None:\n        model.load_state_dict(best_state)\n    test_loss, test_acc, test_cwa, seqs, preds, gts = evaluate(\n        model, test_loader, criterion\n    )\n    print(\n        f\"[{ablation_name}] TEST -- loss:{test_loss:.4f} acc:{test_acc:.3f} CompWA:{test_cwa:.3f}\"\n    )\n    rec[\"losses\"][\"test\"] = test_loss\n    rec[\"metrics\"][\"test\"] = {\"acc\": test_acc, \"CompWA\": test_cwa}\n    rec[\"predictions\"] = preds\n    rec[\"ground_truth\"] = gts\n    rec[\"sequences\"] = seqs\n\n\n# ======================================================================\n# 8.  Run FULL and SEQ_ONLY experiments and save\n# ======================================================================\nexperiment_data = {}\nrun_experiment(\"FULL\", include_rel_edges=True, experiment_dict=experiment_data)\nrun_experiment(\"SEQ_ONLY\", include_rel_edges=False, experiment_dict=experiment_data)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "# ================================================================\n#   NO-SELF-LOOP GNN \u2013 ablation study\n# ================================================================\nimport os, time, math, copy, random\nimport numpy as np, torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool, BatchNorm\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ================================================================\n# 1.  Low-level helpers\n# ================================================================\ndef colour_of(tok):\n    return tok[1:] if len(tok) > 1 else \"\"\n\n\ndef shape_of(tok):\n    return tok[0]\n\n\ndef count_colour_variety(seq):\n    return len(set(colour_of(t) for t in seq.split()))\n\n\ndef count_shape_variety(seq):\n    return len(set(shape_of(t) for t in seq.split()))\n\n\ndef complexity_weight(seq):\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    return sum(wt for wt, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\n# ================================================================\n# 2.  Load / synthesise SPR_BENCH\n# ================================================================\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef load_spr(path):\n    if os.path.isdir(path):\n\n        def _ld(split):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        print(\"Loaded SPR_BENCH from\", path)\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n    # tiny synthetic fallback\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes = list(\"ABCDEF\")\n    colours = [str(i) for i in range(10)]\n\n    def mk_seq():\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours)\n            for _ in range(random.randint(4, 9))\n        )\n\n    def label_rule(seq):\n        return sum(int(colour_of(t)) for t in seq.split()) % 2\n\n    def split(n):\n        seqs = [mk_seq() for _ in range(n)]\n        return Dataset.from_dict(\n            {\"id\": range(n), \"sequence\": seqs, \"label\": [label_rule(s) for s in seqs]}\n        )\n\n    return DatasetDict(train=split(800), dev=split(200), test=split(200))\n\n\nspr = load_spr(SPR_PATH)\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in spr.items()}, \"classes:\", num_classes)\n\n# ================================================================\n# 3.  Build vocabularies\n# ================================================================\nshape_vocab, colour_vocab = {}, {}\n\n\ndef add_shape(s):\n    shape_vocab.setdefault(s, len(shape_vocab))\n\n\ndef add_colour(c):\n    colour_vocab.setdefault(c, len(colour_vocab))\n\n\nfor seq in spr[\"train\"][\"sequence\"]:\n    for tok in seq.split():\n        add_shape(shape_of(tok))\n        add_colour(colour_of(tok))\npos_limit = 20  # upper bound on length\n\n\n# ================================================================\n# 4.  Sequence \u2192 graph (NO SELF LOOPS)\n# ================================================================\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks])\n    colour_ids = torch.tensor([colour_vocab[colour_of(t)] for t in toks])\n    pos_ids = torch.tensor(range(n))\n    # sequential bi-directional edges\n    edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n    # same shape / same colour edges\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shape_of(toks[i]) == shape_of(toks[j]):\n                edges += ([i, j], [j, i])\n            if colour_of(toks[i]) == colour_of(toks[j]):\n                edges += ([i, j], [j, i])\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,\n        edge_index=edge_index,\n        y=torch.tensor(label),\n        seq=seq,\n    )\n\n\ndef encode_split(ds):\n    return [seq_to_graph(s, l) for s, l in zip(ds[\"sequence\"], ds[\"label\"])]\n\n\ntrain_graphs, dev_graphs, test_graphs = map(\n    encode_split, (spr[\"train\"], spr[\"dev\"], spr[\"test\"])\n)\n\n# ================================================================\n# 5.  DataLoaders\n# ================================================================\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# ================================================================\n# 6.  GNN model\n# ================================================================\nclass GNNClassifier(nn.Module):\n    def __init__(self, n_shape, n_col, pos_max, hid=64, n_classes=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_col, hid)\n        self.pos_emb = nn.Embedding(pos_max, hid)\n        self.conv1 = SAGEConv(hid, hid)\n        self.bn1 = BatchNorm(hid)\n        self.conv2 = SAGEConv(hid, hid)\n        self.bn2 = BatchNorm(hid)\n        self.lin = nn.Linear(hid, n_classes)\n        self.drop = nn.Dropout(0.3)\n\n    def forward(self, data):\n        x = (\n            self.shape_emb(data.shape_id)\n            + self.col_emb(data.colour_id)\n            + self.pos_emb(data.pos_id)\n        )\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        graph_x = global_add_pool(x, data.batch)\n        return self.lin(graph_x)\n\n\nmodel = GNNClassifier(\n    len(shape_vocab), len(colour_vocab), pos_limit, 64, num_classes\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# ================================================================\n# 7.  Book-keeping dict\n# ================================================================\nexperiment_data = {\n    \"no_self_loop\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"sequences\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\n\n\n# ================================================================\n# 8.  Helpers\n# ================================================================\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, pred_all, true_all = [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n        seqs_all.extend(batch.seq)\n        pred_all.extend(preds)\n        true_all.extend(gts)\n    return (\n        tot_loss / tot,\n        tot_correct / tot,\n        comp_weighted_acc(seqs_all, true_all, pred_all),\n        seqs_all,\n        pred_all,\n        true_all,\n    )\n\n\ndef train_epoch(loader):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n    return tot_loss / tot, tot_correct / tot\n\n\n# ================================================================\n# 9.  Training loop\n# ================================================================\nmax_epochs, patience = 40, 8\nbest_val_loss = math.inf\nbest_state = None\npat = 0\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_acc = train_epoch(train_loader)\n    val_loss, val_acc, val_cwa, _, _, _ = evaluate(dev_loader)\n    ed = experiment_data[\"no_self_loop\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(tr_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"acc\": tr_acc})\n    ed[\"metrics\"][\"val\"].append({\"epoch\": epoch, \"acc\": val_acc, \"CompWA\": val_cwa})\n    print(\n        f\"Epoch {epoch:02d}: val_loss={val_loss:.4f} val_acc={val_acc:.3f} CompWA={val_cwa:.3f}\"\n    )\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        ed[\"best_epoch\"] = epoch\n        pat = 0\n    else:\n        pat += 1\n        if pat >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ================================================================\n# 10.  Test evaluation\n# ================================================================\nif best_state:\n    model.load_state_dict(best_state)\ntest_loss, test_acc, test_cwa, seqs, preds, gts = evaluate(test_loader)\nprint(f\"TEST -- loss:{test_loss:.4f} acc:{test_acc:.3f} CompWA:{test_cwa:.3f}\")\ned = experiment_data[\"no_self_loop\"][\"SPR_BENCH\"]\ned[\"predictions\"] = preds\ned[\"ground_truth\"] = gts\ned[\"sequences\"] = seqs\n\n# ================================================================\n# 11.  Save bookkeeping\n# ================================================================\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "# No-Batch-Normalization ablation study\nimport os, time, math, copy, random\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool\nfrom torch_geometric.utils import add_self_loops\n\n# ---------------- bookkeeping dict ----------------\nexperiment_data = {\n    \"no_batch_norm\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"sequences\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\n\n# ---------------- working dir ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------- device ----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ======================================================================\n# 1. helpers ------------------------------------------------------------\ndef colour_of(token: str) -> str:\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    return token[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(tok) for tok in seq.split() if tok))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(tok) for tok in seq.split() if tok))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(1, sum(w))\n\n\n# ======================================================================\n# 2. dataset ------------------------------------------------------------\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef load_spr(path: str) -> DatasetDict:\n    if os.path.isdir(path):\n\n        def _ld(split):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        print(\"Loaded SPR_BENCH from\", path)\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes = list(\"ABCDEF\")\n    colours = [str(i) for i in range(10)]\n\n    def make_seq():\n        L = random.randint(4, 9)\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours) for _ in range(L)\n        )\n\n    def label_rule(seq):\n        return sum(int(colour_of(tok)) for tok in seq.split()) % 2\n\n    def split(n):\n        seqs = [make_seq() for _ in range(n)]\n        return Dataset.from_dict(\n            {\n                \"id\": list(range(n)),\n                \"sequence\": seqs,\n                \"label\": [label_rule(s) for s in seqs],\n            }\n        )\n\n    return DatasetDict(train=split(800), dev=split(200), test=split(200))\n\n\nspr = load_spr(SPR_PATH)\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in spr.items()}, \"classes:\", num_classes)\n\n# ======================================================================\n# 3. vocab --------------------------------------------------------------\nshape_vocab, colour_vocab = {}, {}\n\n\ndef add_shape(s):\n    if s not in shape_vocab:\n        shape_vocab[s] = len(shape_vocab)\n\n\ndef add_colour(c):\n    if c not in colour_vocab:\n        colour_vocab[c] = len(colour_vocab)\n\n\nfor seq in spr[\"train\"][\"sequence\"]:\n    for tok in seq.split():\n        add_shape(shape_of(tok))\n        add_colour(colour_of(tok))\npos_limit = 20\n\n\n# ======================================================================\n# 4. seq -> graph -------------------------------------------------------\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks], dtype=torch.long)\n    colour_ids = torch.tensor(\n        [colour_vocab[colour_of(t)] for t in toks], dtype=torch.long\n    )\n    pos_ids = torch.tensor(list(range(n)), dtype=torch.long)\n\n    edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shape_of(toks[i]) == shape_of(toks[j]):\n                edges += [[i, j], [j, i]]\n            if colour_of(toks[i]) == colour_of(toks[j]):\n                edges += [[i, j], [j, i]]\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    edge_index, _ = add_self_loops(edge_index, num_nodes=n)\n\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,\n        edge_index=edge_index,\n        y=torch.tensor(label, dtype=torch.long),\n        seq=seq,\n    )\n\n\ndef encode_split(ds):\n    return [seq_to_graph(s, l) for s, l in zip(ds[\"sequence\"], ds[\"label\"])]\n\n\ntrain_graphs, dev_graphs, test_graphs = map(\n    encode_split, (spr[\"train\"], spr[\"dev\"], spr[\"test\"])\n)\n\n# ======================================================================\n# 5. loaders ------------------------------------------------------------\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# ======================================================================\n# 6. model --------------------------------------------------------------\nclass GNNClassifier(nn.Module):\n    def __init__(self, n_shape, n_colour, pos_max, hid=64, n_classes=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_colour, hid)\n        self.pos_emb = nn.Embedding(pos_max, hid)\n\n        self.conv1 = SAGEConv(hid, hid)\n        self.bn1 = nn.Identity()  # BatchNorm removed\n        self.conv2 = SAGEConv(hid, hid)\n        self.bn2 = nn.Identity()  # BatchNorm removed\n\n        self.lin = nn.Linear(hid, n_classes)\n        self.drop = nn.Dropout(0.3)\n\n    def forward(self, data):\n        x = (\n            self.shape_emb(data.shape_id)\n            + self.col_emb(data.colour_id)\n            + self.pos_emb(data.pos_id)\n        )\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        graph_x = global_add_pool(x, data.batch)\n        return self.lin(graph_x)\n\n\nmodel = GNNClassifier(\n    len(shape_vocab), len(colour_vocab), pos_limit, 64, num_classes\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# shorthand for dict access\nexp = experiment_data[\"no_batch_norm\"][\"SPR_BENCH\"]\n\n\n# ======================================================================\n# 7. eval & train helpers ----------------------------------------------\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, pred_all, true_all = [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n\n        seqs_all.extend(batch.seq)\n        pred_all.extend(preds)\n        true_all.extend(gts)\n    return (\n        tot_loss / tot,\n        tot_correct / tot,\n        comp_weighted_acc(seqs_all, true_all, pred_all),\n        seqs_all,\n        pred_all,\n        true_all,\n    )\n\n\ndef train_epoch(loader):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n    return tot_loss / tot, tot_correct / tot\n\n\n# ======================================================================\n# 8. training loop ------------------------------------------------------\nmax_epochs, patience = 40, 8\nbest_val_loss = math.inf\nbest_state = None\npat = 0\n\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_acc = train_epoch(train_loader)\n    val_loss, val_acc, val_cwa, _, _, _ = evaluate(dev_loader)\n\n    exp[\"losses\"][\"train\"].append(tr_loss)\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"acc\": tr_acc})\n    exp[\"metrics\"][\"val\"].append({\"epoch\": epoch, \"acc\": val_acc, \"CompWA\": val_cwa})\n\n    print(\n        f\"Epoch {epoch:02d}: val_loss={val_loss:.4f} val_acc={val_acc:.3f} CompWA={val_cwa:.3f}\"\n    )\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        exp[\"best_epoch\"] = epoch\n        pat = 0\n    else:\n        pat += 1\n        if pat >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ======================================================================\n# 9. test ---------------------------------------------------------------\nif best_state:\n    model.load_state_dict(best_state)\ntest_loss, test_acc, test_cwa, seqs, preds, gts = evaluate(test_loader)\nprint(f\"TEST -- loss:{test_loss:.4f} acc:{test_acc:.3f} CompWA:{test_cwa:.3f}\")\n\nexp[\"predictions\"] = preds\nexp[\"ground_truth\"] = gts\nexp[\"sequences\"] = seqs\nexp[\"metrics\"][\"test\"] = {\"acc\": test_acc, \"CompWA\": test_cwa}\nexp[\"losses\"][\"test\"] = test_loss\n\n# ======================================================================\n# 10. save --------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"saved experiment_data.npy\")\n", "import os, math, random, copy, time\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool, BatchNorm\n\n# -------------------------------  device ------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ============================================================================#\n# 1.  Low-level helpers + evaluation metrics\n# ============================================================================#\ndef colour_of(tok: str) -> str:\n    return tok[1:] if len(tok) > 1 else \"\"\n\n\ndef shape_of(tok: str) -> str:\n    return tok[0] if tok else \"\"\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(t) for t in seq.split()))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(t) for t in seq.split()))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef colour_weighted_acc(seqs, y_true, y_pred):\n    w = [count_colour_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef shape_weighted_acc(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef cs_weighted_acc(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\n# ============================================================================#\n# 2.  Load / synthesise SPR_BENCH\n# ============================================================================#\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef _load_spr(path):\n    if os.path.isdir(path):\n\n        def _ld(split):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        print(\"Loaded SPR_BENCH from\", path)\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n    # -------------- tiny synthetic fallback ---------------------------------\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes = list(\"ABCDEFGH\")\n    colours = list(map(str, range(10)))\n\n    def mk_seq():\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours)\n            for _ in range(random.randint(4, 35))\n        )\n\n    def rule(seq):\n        return sum(int(colour_of(t)) for t in seq.split()) % 2\n\n    def split(n):\n        seqs = [mk_seq() for _ in range(n)]\n        return Dataset.from_dict(\n            {\"id\": range(n), \"sequence\": seqs, \"label\": [rule(s) for s in seqs]}\n        )\n\n    return DatasetDict(train=split(1000), dev=split(250), test=split(250))\n\n\nspr = _load_spr(SPR_PATH)\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in spr.items()}, \"classes:\", num_classes)\n\n# ============================================================================#\n# 3.  Build vocabularies + positional range  (BUGFIX)\n# ============================================================================#\nshape_vocab, colour_vocab = {}, {}\nmax_seq_len = 0\nfor split in (\"train\", \"dev\", \"test\"):\n    for seq in spr[split][\"sequence\"]:\n        toks = seq.split()\n        max_seq_len = max(max_seq_len, len(toks))\n        for tok in toks:\n            shape_vocab.setdefault(shape_of(tok), len(shape_vocab))\n            colour_vocab.setdefault(colour_of(tok), len(colour_vocab))\n\npos_limit = max_seq_len + 1  # BUGFIX \u2013 dynamic size ensures indices are valid\nprint(\n    \"Vocab sizes \u2013 shapes:\",\n    len(shape_vocab),\n    \"colours:\",\n    len(colour_vocab),\n    \"max_len:\",\n    max_seq_len,\n)\n\n\n# ============================================================================#\n# 4.  Sequence \u2192 graph (still NO self-loops)\n# ============================================================================#\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks])\n    colour_ids = torch.tensor([colour_vocab[colour_of(t)] for t in toks])\n    pos_ids = torch.tensor(list(range(n)))  # guaranteed < pos_limit\n\n    # edges: sequential \u00b11 plus same shape/colour pairs\n    edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shape_of(toks[i]) == shape_of(toks[j]):\n                edges += ([i, j], [j, i])\n            if colour_of(toks[i]) == colour_of(toks[j]):\n                edges += ([i, j], [j, i])\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,\n        edge_index=edge_index,\n        y=torch.tensor(label),\n        seq=seq,\n    )\n\n\ndef encode_split(ds):\n    return [seq_to_graph(s, l) for s, l in zip(ds[\"sequence\"], ds[\"label\"])]\n\n\ntrain_g, dev_g, test_g = map(encode_split, (spr[\"train\"], spr[\"dev\"], spr[\"test\"]))\n\n# ============================================================================#\n# 5.  DataLoaders\n# ============================================================================#\nbatch_size = 128\ntrain_loader = DataLoader(train_g, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_g, batch_size=batch_size)\ntest_loader = DataLoader(test_g, batch_size=batch_size)\n\n\n# ============================================================================#\n# 6.  Model\n# ============================================================================#\nclass GNNClassifier(nn.Module):\n    def __init__(self, n_shape, n_col, pos_max, hid=64, n_cls=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_col, hid)\n        self.pos_emb = nn.Embedding(pos_max, hid)\n        self.conv1 = SAGEConv(hid, hid)\n        self.bn1 = BatchNorm(hid)\n        self.conv2 = SAGEConv(hid, hid)\n        self.bn2 = BatchNorm(hid)\n        self.lin = nn.Linear(hid, n_cls)\n        self.drop = nn.Dropout(0.3)\n\n    def forward(self, data):\n        x = (\n            self.shape_emb(data.shape_id)\n            + self.col_emb(data.colour_id)\n            + self.pos_emb(data.pos_id)\n        )\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        graph_x = global_add_pool(x, data.batch)\n        return self.lin(graph_x)\n\n\nmodel = GNNClassifier(\n    len(shape_vocab), len(colour_vocab), pos_limit, 64, num_classes\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# ============================================================================#\n# 7.  Book-keeping dict\n# ============================================================================#\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"sequences\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ============================================================================#\n# 8.  Helpers\n# ============================================================================#\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, pred_all, true_all = [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n        seqs_all.extend(batch.seq)\n        pred_all.extend(preds)\n        true_all.extend(gts)\n    acc = tot_correct / max(1, tot)\n    cwa = colour_weighted_acc(seqs_all, true_all, pred_all)\n    swa = shape_weighted_acc(seqs_all, true_all, pred_all)\n    cswa = cs_weighted_acc(seqs_all, true_all, pred_all)\n    return (tot_loss / max(1, tot), acc, cwa, swa, cswa, seqs_all, pred_all, true_all)\n\n\ndef train_epoch(loader):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n    return tot_loss / max(1, tot), tot_correct / max(1, tot)\n\n\n# ============================================================================#\n# 9.  Training loop\n# ============================================================================#\nmax_epochs, patience = 40, 8\nbest_val_loss = math.inf\nbest_state = None\nno_improve = 0\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_acc = train_epoch(train_loader)\n    val_loss, val_acc, val_cwa, val_swa, val_cswa, *_ = evaluate(dev_loader)\n\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(tr_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"acc\": tr_acc})\n    ed[\"metrics\"][\"val\"].append(\n        {\n            \"epoch\": epoch,\n            \"acc\": val_acc,\n            \"CWA\": val_cwa,\n            \"SWA\": val_swa,\n            \"CSWA\": val_cswa,\n        }\n    )\n    print(\n        f\"Epoch {epoch:02d}: val_loss={val_loss:.4f}  acc={val_acc:.3f} \"\n        f\"CWA={val_cwa:.3f} SWA={val_swa:.3f} CSWA={val_cswa:.3f}\"\n    )\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        ed[\"best_epoch\"] = epoch\n        no_improve = 0\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ============================================================================#\n# 10.  Test evaluation\n# ============================================================================#\nif best_state is not None:\n    model.load_state_dict(best_state)\ntest_loss, test_acc, test_cwa, test_swa, test_cswa, seqs, preds, gts = evaluate(\n    test_loader\n)\nprint(\n    f\"TEST -- loss:{test_loss:.4f} acc:{test_acc:.3f} \"\n    f\"CWA:{test_cwa:.3f} SWA:{test_swa:.3f} CSWA:{test_cswa:.3f}\"\n)\n\ned = experiment_data[\"SPR_BENCH\"]\ned[\"predictions\"] = preds\ned[\"ground_truth\"] = gts\ned[\"sequences\"] = seqs\n\n# ============================================================================#\n# 11.  Save bookkeeping\n# ============================================================================#\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, random, math, copy, time\nimport numpy as np, torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool, BatchNorm\n\n# ---------------------------------------------------------------\n# 0.  Work dir / device\n# ---------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n\n# ---------------------------------------------------------------\n# 1.  Low-level helpers + metrics\n# ---------------------------------------------------------------\ndef colour_of(tok: str) -> str:\n    return tok[1:] if len(tok) > 1 else \"\"\n\n\ndef shape_of(tok: str) -> str:\n    return tok[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(t) for t in seq.split()))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(t) for t in seq.split()))\n\n\ndef cswa(seqs, y_true, y_pred) -> float:\n    w = [count_colour_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\n# ---------------------------------------------------------------\n# 2.  Load / fallback SPR_BENCH\n# ---------------------------------------------------------------\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef load_spr(path) -> DatasetDict:\n    if os.path.isdir(path):\n\n        def _ld(split):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        print(\"Loaded SPR_BENCH from\", path)\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n    # synthetic tiny fallback\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes = list(\"ABCDE\")\n    colours = [str(i) for i in range(10)]\n\n    def mk_seq():\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours)\n            for _ in range(random.randint(4, 12))\n        )\n\n    def label(seq):\n        return sum(int(colour_of(t)) for t in seq.split()) % 2\n\n    def make_split(n):\n        seqs = [mk_seq() for _ in range(n)]\n        return Dataset.from_dict(\n            {\"id\": list(range(n)), \"sequence\": seqs, \"label\": [label(s) for s in seqs]}\n        )\n\n    return DatasetDict(train=make_split(800), dev=make_split(200), test=make_split(200))\n\n\nspr = load_spr(SPR_PATH)\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in spr.items()}, \"classes:\", num_classes)\n\n# ---------------------------------------------------------------\n# 3.  Build vocabularies (shapes / colours) & pos limit\n# ---------------------------------------------------------------\nshape_vocab, colour_vocab = {}, {}\n\n\ndef add_shape(s):\n    shape_vocab.setdefault(s, len(shape_vocab))\n\n\ndef add_colour(c):\n    colour_vocab.setdefault(c, len(colour_vocab))\n\n\nmax_len = 0\nfor seq in spr[\"train\"][\"sequence\"]:\n    toks = seq.split()\n    max_len = max(max_len, len(toks))\n    for tok in toks:\n        add_shape(shape_of(tok))\n        add_colour(colour_of(tok))\npos_limit = max_len + 1  # BUGFIX: dynamic position vocab\nprint(\"pos_limit =\", pos_limit)\n\n\n# ---------------------------------------------------------------\n# 4.  Sequence \u2192 graph (NO self-loops)\n# ---------------------------------------------------------------\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks], dtype=torch.long)\n    colour_ids = torch.tensor(\n        [colour_vocab[colour_of(t)] for t in toks], dtype=torch.long\n    )\n    pos_ids = torch.tensor(list(range(n)), dtype=torch.long)\n    # edges: sequential bi-directional\n    edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n    # same shape/colour edges\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shape_of(toks[i]) == shape_of(toks[j]):\n                edges += [[i, j], [j, i]]\n            if colour_of(toks[i]) == colour_of(toks[j]):\n                edges += [[i, j], [j, i]]\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,\n        edge_index=edge_index,\n        y=torch.tensor(label, dtype=torch.long),\n        seq=seq,\n    )\n\n\ndef encode_split(ds):\n    return [seq_to_graph(s, l) for s, l in zip(ds[\"sequence\"], ds[\"label\"])]\n\n\ntrain_graphs, dev_graphs, test_graphs = map(\n    encode_split, (spr[\"train\"], spr[\"dev\"], spr[\"test\"])\n)\n\n# ---------------------------------------------------------------\n# 5.  DataLoaders\n# ---------------------------------------------------------------\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# ---------------------------------------------------------------\n# 6.  Model\n# ---------------------------------------------------------------\nclass GNNClassifier(nn.Module):\n    def __init__(self, n_shape, n_colour, pos_max, hid=64, n_classes=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_colour, hid)\n        self.pos_emb = nn.Embedding(pos_max, hid)\n        self.conv1 = SAGEConv(hid, hid)\n        self.bn1 = BatchNorm(hid)\n        self.conv2 = SAGEConv(hid, hid)\n        self.bn2 = BatchNorm(hid)\n        self.lin = nn.Linear(hid, n_classes)\n        self.drop = nn.Dropout(0.3)\n\n    def forward(self, data):\n        x = (\n            self.shape_emb(data.shape_id)\n            + self.col_emb(data.colour_id)\n            + self.pos_emb(data.pos_id)\n        )\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        graph_x = global_add_pool(x, data.batch)\n        return self.lin(graph_x)\n\n\nmodel = GNNClassifier(\n    len(shape_vocab), len(colour_vocab), pos_limit, hid=64, n_classes=num_classes\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# ---------------------------------------------------------------\n# 7.  Book-keeping dict\n# ---------------------------------------------------------------\nexperiment_data = {\n    \"no_self_loop_SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"sequences\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ---------------------------------------------------------------\n# 8.  Helpers\n# ---------------------------------------------------------------\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, pred_all, true_all = [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n        seqs_all.extend(batch.seq)\n        pred_all.extend(preds)\n        true_all.extend(gts)\n    return (\n        tot_loss / max(1, tot),\n        tot_correct / max(1, tot),\n        cswa(seqs_all, true_all, pred_all),\n        seqs_all,\n        pred_all,\n        true_all,\n    )\n\n\ndef train_epoch(loader):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n    return tot_loss / max(1, tot), tot_correct / max(1, tot)\n\n\n# ---------------------------------------------------------------\n# 9.  Training loop\n# ---------------------------------------------------------------\nmax_epochs, patience = 40, 8\nbest_val_loss = math.inf\nbest_state = None\npat = 0\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_acc = train_epoch(train_loader)\n    val_loss, val_acc, val_cswa, _, _, _ = evaluate(dev_loader)\n    # bookkeeping\n    ed = experiment_data[\"no_self_loop_SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(tr_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"acc\": tr_acc})\n    ed[\"metrics\"][\"val\"].append({\"epoch\": epoch, \"acc\": val_acc, \"CSWA\": val_cswa})\n    print(\n        f\"Epoch {epoch:02d}: val_loss={val_loss:.4f} val_acc={val_acc:.3f} CSWA={val_cswa:.3f}\"\n    )\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        ed[\"best_epoch\"] = epoch\n        pat = 0\n    else:\n        pat += 1\n        if pat >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ---------------------------------------------------------------\n# 10.  Test evaluation\n# ---------------------------------------------------------------\nif best_state is not None:\n    model.load_state_dict(best_state)\ntest_loss, test_acc, test_cswa, seqs, preds, gts = evaluate(test_loader)\nprint(f\"TEST -- loss:{test_loss:.4f} acc:{test_acc:.3f} CSWA:{test_cswa:.3f}\")\n\ned = experiment_data[\"no_self_loop_SPR_BENCH\"]\ned[\"predictions\"] = preds\ned[\"ground_truth\"] = gts\ned[\"sequences\"] = seqs\n\n# ---------------------------------------------------------------\n# 11.  Save bookkeeping\n# ---------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, math, copy, random, time\nimport numpy as np, torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool, BatchNorm\n\n# ------------------------------------------------------------\n# housekeeping\n# ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ntorch.manual_seed(2024)\nrandom.seed(2024)\nnp.random.seed(2024)\n\n\n# ------------------------------------------------------------\n# helpers for colours / shapes\n# ------------------------------------------------------------\ndef colour_of(tok):  # everything except first char\n    return tok[1:] if len(tok) > 1 else \"\"\n\n\ndef shape_of(tok):  # first char\n    return tok[0] if tok else \"\"\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len({colour_of(t) for t in seq.split()})\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len({shape_of(t) for t in seq.split()})\n\n\ndef cswa(seqs, y_true, y_pred):\n    w = [count_colour_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\n# ------------------------------------------------------------\n# dataset loader (same path env var as before)\n# ------------------------------------------------------------\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef load_spr(path):\n    if os.path.isdir(path):\n\n        def _ld(split):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        print(\"Loaded SPR_BENCH from\", path)\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n    # fallback toy data\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes = list(\"ABCDEF\")\n    colours = [str(i) for i in range(10)]\n\n    def mk_seq():\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours)\n            for _ in range(random.randint(4, 15))\n        )\n\n    def lab(seq):  # parity of colour IDs\n        return sum(int(colour_of(t) or 0) for t in seq.split()) % 2\n\n    def split(n):\n        seqs = [mk_seq() for _ in range(n)]\n        return Dataset.from_dict(\n            {\"id\": list(range(n)), \"sequence\": seqs, \"label\": [lab(s) for s in seqs]}\n        )\n\n    return DatasetDict(train=split(800), dev=split(200), test=split(200))\n\n\nspr = load_spr(SPR_PATH)\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in spr.items()}, \"classes:\", num_classes)\n\n# ------------------------------------------------------------\n# build vocabularies over *all* splits -> prevents OOV\n# ------------------------------------------------------------\nshape_vocab, colour_vocab = {}, {}\n\n\ndef add_shape(s):\n    shape_vocab.setdefault(s, len(shape_vocab))\n\n\ndef add_colour(c):\n    colour_vocab.setdefault(c, len(colour_vocab))\n\n\nmax_seq_len = 0\nfor split in (\"train\", \"dev\", \"test\"):\n    for seq in spr[split][\"sequence\"]:\n        toks = seq.split()\n        max_seq_len = max(max_seq_len, len(toks))\n        for t in toks:\n            add_shape(shape_of(t))\n            add_colour(colour_of(t))\n\npos_limit = max_seq_len + 1  # safe upper bound\nprint(f\"max sequence length = {max_seq_len},  pos_limit = {pos_limit}\")\n\n\n# ------------------------------------------------------------\n# sequence \u2192 graph  (no self-loops)\n# ------------------------------------------------------------\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks], dtype=torch.long)\n    colour_ids = torch.tensor(\n        [colour_vocab[colour_of(t)] for t in toks], dtype=torch.long\n    )\n    pos_ids = torch.tensor(list(range(n)), dtype=torch.long)\n\n    # sequential bi-directional edges\n    edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n    # same-attribute edges\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shape_of(toks[i]) == shape_of(toks[j]):\n                edges += [[i, j], [j, i]]\n            if colour_of(toks[i]) == colour_of(toks[j]):\n                edges += [[i, j], [j, i]]\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,\n        edge_index=edge_index,\n        y=torch.tensor(label, dtype=torch.long),\n        seq=seq,\n    )\n\n\ndef encode_split(ds):\n    return [seq_to_graph(s, l) for s, l in zip(ds[\"sequence\"], ds[\"label\"])]\n\n\ntrain_graphs, dev_graphs, test_graphs = map(\n    encode_split, (spr[\"train\"], spr[\"dev\"], spr[\"test\"])\n)\n\n# ------------------------------------------------------------\n# DataLoaders\n# ------------------------------------------------------------\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# ------------------------------------------------------------\n# GNN model\n# ------------------------------------------------------------\nclass GNNClassifier(nn.Module):\n    def __init__(self, n_shape, n_col, pos_max, hid=64, n_classes=2, dropout=0.3):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_col, hid)\n        self.pos_emb = nn.Embedding(pos_max, hid)\n        self.conv1 = SAGEConv(hid, hid)\n        self.bn1 = BatchNorm(hid)\n        self.conv2 = SAGEConv(hid, hid)\n        self.bn2 = BatchNorm(hid)\n        self.lin = nn.Linear(hid, n_classes)\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, data):\n        x = (\n            self.shape_emb(data.shape_id)\n            + self.col_emb(data.colour_id)\n            + self.pos_emb(data.pos_id)\n        )\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        graph_x = global_add_pool(x, data.batch)\n        return self.lin(graph_x)\n\n\nmodel = GNNClassifier(\n    len(shape_vocab), len(colour_vocab), pos_limit, hid=64, n_classes=num_classes\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# ------------------------------------------------------------\n# bookkeeping\n# ------------------------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"sequences\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ------------------------------------------------------------\n# evaluation / training utilities\n# ------------------------------------------------------------\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, pred_all, true_all = [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n        seqs_all.extend(batch.seq)\n        pred_all.extend(preds)\n        true_all.extend(gts)\n    acc = tot_correct / tot\n    cswa_score = cswa(seqs_all, true_all, pred_all)\n    return tot_loss / tot, acc, cswa_score, seqs_all, pred_all, true_all\n\n\ndef train_epoch(loader):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n    return tot_loss / tot, tot_correct / tot\n\n\n# ------------------------------------------------------------\n# training loop\n# ------------------------------------------------------------\nmax_epochs, patience = 40, 8\nbest_val_loss = math.inf\nbest_state = None\npat = 0\n\nfor epoch in range(1, max_epochs + 1):\n    t_start = time.time()\n    tr_loss, tr_acc = train_epoch(train_loader)\n    val_loss, val_acc, val_cswa, _, _, _ = evaluate(dev_loader)\n\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"epoch\": epoch, \"acc\": tr_acc}\n    )\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"epoch\": epoch, \"acc\": val_acc, \"CSWA\": val_cswa}\n    )\n\n    print(\n        f\"Epoch {epoch:02d}: val_loss={val_loss:.4f}  val_acc={val_acc:.3f}  CSWA={val_cswa:.3f}  \"\n        f\"({time.time()-t_start:.1f}s)\"\n    )\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        experiment_data[\"SPR_BENCH\"][\"best_epoch\"] = epoch\n        pat = 0\n    else:\n        pat += 1\n        if pat >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ------------------------------------------------------------\n# test evaluation\n# ------------------------------------------------------------\nif best_state:\n    model.load_state_dict(best_state)\n\ntest_loss, test_acc, test_cswa, seqs, preds, gts = evaluate(test_loader)\nprint(f\"TEST -- loss:{test_loss:.4f}  acc:{test_acc:.3f}  CSWA:{test_cswa:.3f}\")\n\ned = experiment_data[\"SPR_BENCH\"]\ned[\"predictions\"] = preds\ned[\"ground_truth\"] = gts\ned[\"sequences\"] = seqs\n\n# ------------------------------------------------------------\n# save bookkeeping\n# ------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy to\", working_dir)\n", "import os, math, copy, random, time\nfrom typing import Dict, List\n\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool, BatchNorm\n\n# ------------------------------------------------------------\n# Set up working directory and device\n# ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------\n# Helper functions for SPR symbols\n# ------------------------------------------------------------\ndef colour_of(tok: str) -> str:\n    return tok[1:] if len(tok) > 1 else \"\"\n\n\ndef shape_of(tok: str) -> str:\n    return tok[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(t) for t in seq.split()))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(t) for t in seq.split()))\n\n\ndef cswa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    \"\"\"Combined Structural Weighted Accuracy\"\"\"\n    weights = [count_colour_variety(s) + count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(1, sum(weights))\n\n\ndef cwa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_colour_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(1, sum(weights))\n\n\ndef swa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(1, sum(weights))\n\n\n# ------------------------------------------------------------\n# Data loading \u2013 real data if present, otherwise small synthetic\n# ------------------------------------------------------------\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef load_spr(path: str) -> DatasetDict:\n    if os.path.exists(os.path.join(path, \"train.csv\")):\n        print(\"Loading SPR_BENCH from\", path)\n\n        def _ld(split: str):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n\n    # ---------- tiny synthetic fallback ----------\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes = list(\"ABCDEFGHI\")\n    colours = [str(i) for i in range(15)]\n\n    def mk_seq() -> str:\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours)\n            for _ in range(random.randint(5, 25))\n        )\n\n    def label_rule(seq: str) -> int:\n        return sum(int(colour_of(t)) for t in seq.split()) % 2\n\n    def mk_split(n: int) -> Dataset:\n        seqs = [mk_seq() for _ in range(n)]\n        labs = [label_rule(s) for s in seqs]\n        return Dataset.from_dict(\n            {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labs}\n        )\n\n    return DatasetDict(train=mk_split(800), dev=mk_split(200), test=mk_split(200))\n\n\nspr = load_spr(SPR_PATH)\nprint({k: len(v) for k, v in spr.items()})\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# ------------------------------------------------------------\n# Build vocabularies & discover maximum length\n# ------------------------------------------------------------\nshape_vocab: Dict[str, int] = {}\ncolour_vocab: Dict[str, int] = {}\nmax_len = 0\n\n\ndef add_shape(s: str):\n    if s not in shape_vocab:\n        shape_vocab[s] = len(shape_vocab)\n\n\ndef add_colour(c: str):\n    if c not in colour_vocab:\n        colour_vocab[c] = len(colour_vocab)\n\n\nfor seq in spr[\"train\"][\"sequence\"]:\n    toks = seq.split()\n    max_len = max(max_len, len(toks))\n    for tok in toks:\n        add_shape(shape_of(tok))\n        add_colour(colour_of(tok))\n\nprint(\n    \"Vocab sizes \u2013 shapes:\",\n    len(shape_vocab),\n    \"colours:\",\n    len(colour_vocab),\n    \"| max_len:\",\n    max_len,\n)\n\n\n# ------------------------------------------------------------\n# Sequence \u2192 graph encoding  (still ablating self-loops)\n# ------------------------------------------------------------\ndef seq_to_graph(seq: str, label: int) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks], dtype=torch.long)\n    colour_ids = torch.tensor(\n        [colour_vocab[colour_of(t)] for t in toks], dtype=torch.long\n    )\n    pos_ids = torch.tensor(list(range(n)), dtype=torch.long)\n\n    edges: List[List[int]] = [[i, i + 1] for i in range(n - 1)] + [\n        [i + 1, i] for i in range(n - 1)\n    ]\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shape_of(toks[i]) == shape_of(toks[j]):\n                edges += [[i, j], [j, i]]\n            if colour_of(toks[i]) == colour_of(toks[j]):\n                edges += [[i, j], [j, i]]\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,\n        edge_index=edge_index,\n        y=torch.tensor(label, dtype=torch.long),\n        seq=seq,\n    )\n\n\ndef encode_split(ds: Dataset) -> List[Data]:\n    return [seq_to_graph(s, l) for s, l in zip(ds[\"sequence\"], ds[\"label\"])]\n\n\ntrain_graphs, dev_graphs, test_graphs = map(\n    encode_split, (spr[\"train\"], spr[\"dev\"], spr[\"test\"])\n)\n\n# ------------------------------------------------------------\n# DataLoaders\n# ------------------------------------------------------------\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# ------------------------------------------------------------\n# GNN model (positional embedding sized to true max_len)\n# ------------------------------------------------------------\nclass GNNClassifier(nn.Module):\n    def __init__(\n        self, n_shape: int, n_col: int, pos_cap: int, hid: int = 64, n_classes: int = 2\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_col, hid)\n        self.pos_emb = nn.Embedding(pos_cap + 1, hid)  # bug-fix: dynamic size\n        self.conv1 = SAGEConv(hid, hid)\n        self.bn1 = BatchNorm(hid)\n        self.conv2 = SAGEConv(hid, hid)\n        self.bn2 = BatchNorm(hid)\n        self.out = nn.Linear(hid, n_classes)\n        self.drop = nn.Dropout(0.3)\n\n    def forward(self, data: Data):\n        x = (\n            self.shape_emb(data.shape_id)\n            + self.col_emb(data.colour_id)\n            + self.pos_emb(data.pos_id.clamp_max(self.pos_emb.num_embeddings - 1))\n        )\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        x = global_add_pool(x, data.batch)\n        return self.out(x)\n\n\nmodel = GNNClassifier(len(shape_vocab), len(colour_vocab), max_len, 64, num_classes).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# ------------------------------------------------------------\n# Book-keeping dict\n# ------------------------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"sequences\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ------------------------------------------------------------\n# Training / Evaluation helpers\n# ------------------------------------------------------------\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, preds_all, true_all = [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        seqs = batch.seq\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n        seqs_all.extend(seqs)\n        preds_all.extend(preds)\n        true_all.extend(gts)\n    acc = tot_correct / tot\n    cwa_ = cwa(seqs_all, true_all, preds_all)\n    swa_ = swa(seqs_all, true_all, preds_all)\n    cswa_ = cswa(seqs_all, true_all, preds_all)\n    return tot_loss / tot, acc, cwa_, swa_, cswa_, seqs_all, preds_all, true_all\n\n\ndef train_epoch(loader):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n    return tot_loss / tot, tot_correct / tot\n\n\n# ------------------------------------------------------------\n# Training loop\n# ------------------------------------------------------------\nmax_epochs, patience = 40, 8\nbest_val_loss = math.inf\nbest_state = None\nwait = 0\n\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_acc = train_epoch(train_loader)\n    val_loss, val_acc, val_cwa, val_swa, val_cswa, *_ = evaluate(dev_loader)\n\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(tr_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"acc\": tr_acc})\n    ed[\"metrics\"][\"val\"].append(\n        {\n            \"epoch\": epoch,\n            \"acc\": val_acc,\n            \"CWA\": val_cwa,\n            \"SWA\": val_swa,\n            \"CSWA\": val_cswa,\n        }\n    )\n    print(\n        f\"Epoch {epoch:02d}: val_loss={val_loss:.4f}  acc={val_acc:.3f} \"\n        f\"CWA={val_cwa:.3f} SWA={val_swa:.3f} CSWA={val_cswa:.3f}\"\n    )\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        ed[\"best_epoch\"] = epoch\n        wait = 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ------------------------------------------------------------\n# Test set evaluation\n# ------------------------------------------------------------\nif best_state is not None:\n    model.load_state_dict(best_state)\n\ntest_loss, test_acc, test_cwa, test_swa, test_cswa, seqs, preds, gts = evaluate(\n    test_loader\n)\nprint(\n    f\"TEST -- loss:{test_loss:.4f} acc:{test_acc:.3f} \"\n    f\"CWA:{test_cwa:.3f} SWA:{test_swa:.3f} CSWA:{test_cswa:.3f}\"\n)\n\ned = experiment_data[\"SPR_BENCH\"]\ned[\"predictions\"] = preds\ned[\"ground_truth\"] = gts\ned[\"sequences\"] = seqs\n\n# ------------------------------------------------------------\n# Persist results\n# ------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy to\", working_dir)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, time, math, copy, random\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool, BatchNorm\nfrom torch_geometric.utils import add_self_loops\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ======================================================================\n# 1.  Low-level sequence helpers (SINGLE SOURCE OF TRUTH)\n# ======================================================================\ndef colour_of(token: str) -> str:\n    \"\"\"Return the colour substring of a token (may be multiple chars).\"\"\"\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    \"\"\"Return the leading shape symbol.\"\"\"\n    return token[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(tok) for tok in seq.split() if tok))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(tok) for tok in seq.split() if tok))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(1, sum(w))\n\n\n# ======================================================================\n# 2.  Load or synthesize SPR_BENCH\n# ======================================================================\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef load_spr(path: str) -> DatasetDict:\n    if os.path.isdir(path):\n\n        def _ld(split):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        print(\"Loaded SPR_BENCH from\", path)\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n\n    # ---------- tiny fallback ----------\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes = list(\"ABCDEF\")\n    colours = [str(i) for i in range(10)]\n\n    def make_seq():\n        L = random.randint(4, 9)\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours) for _ in range(L)\n        )\n\n    def label_rule(seq):\n        return sum(int(colour_of(tok)) for tok in seq.split()) % 2\n\n    def split(n):\n        seqs = [make_seq() for _ in range(n)]\n        return Dataset.from_dict(\n            {\n                \"id\": list(range(n)),\n                \"sequence\": seqs,\n                \"label\": [label_rule(s) for s in seqs],\n            }\n        )\n\n    return DatasetDict(train=split(800), dev=split(200), test=split(200))\n\n\nspr = load_spr(SPR_PATH)\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in spr.items()}, \"classes:\", num_classes)\n\n# ======================================================================\n# 3.  Build vocabularies\n# ======================================================================\nshape_vocab, colour_vocab = {}, {}\n\n\ndef add_shape(s):\n    if s not in shape_vocab:\n        shape_vocab[s] = len(shape_vocab)\n\n\ndef add_colour(c):\n    if c not in colour_vocab:\n        colour_vocab[c] = len(colour_vocab)\n\n\nfor seq in spr[\"train\"][\"sequence\"]:\n    for tok in seq.split():\n        add_shape(shape_of(tok))\n        add_colour(colour_of(tok))\n\npos_limit = 20  # safe upper bound\n\n\n# ======================================================================\n# 4.  Sequence \u2192 graph encoder\n# ======================================================================\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks], dtype=torch.long)\n    colour_ids = torch.tensor(\n        [colour_vocab[colour_of(t)] for t in toks], dtype=torch.long\n    )\n    pos_ids = torch.tensor(list(range(n)), dtype=torch.long)\n\n    # edges: sequential (bi-directional)\n    edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n\n    # edges: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shape_of(toks[i]) == shape_of(toks[j]):\n                edges += [[i, j], [j, i]]\n\n    # edges: same colour\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colour_of(toks[i]) == colour_of(toks[j]):\n                edges += [[i, j], [j, i]]\n\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    # add self loops\n    edge_index, _ = add_self_loops(edge_index, num_nodes=n)\n\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,\n        edge_index=edge_index,\n        y=torch.tensor(label, dtype=torch.long),\n        seq=seq,  # keep raw text for metrics\n    )\n\n\ndef encode_split(ds):\n    return [seq_to_graph(s, l) for s, l in zip(ds[\"sequence\"], ds[\"label\"])]\n\n\ntrain_graphs, dev_graphs, test_graphs = map(\n    encode_split, (spr[\"train\"], spr[\"dev\"], spr[\"test\"])\n)\n\n# ======================================================================\n# 5.  DataLoaders\n# ======================================================================\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# ======================================================================\n# 6.  GNN model\n# ======================================================================\nclass GNNClassifier(nn.Module):\n    def __init__(self, n_shape, n_colour, pos_max, hid=64, n_classes=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_colour, hid)\n        self.pos_emb = nn.Embedding(pos_max, hid)\n\n        self.conv1 = SAGEConv(hid, hid)\n        self.bn1 = BatchNorm(hid)\n        self.conv2 = SAGEConv(hid, hid)\n        self.bn2 = BatchNorm(hid)\n\n        self.lin = nn.Linear(hid, n_classes)\n        self.drop = nn.Dropout(0.3)\n\n    def forward(self, data):\n        x = (\n            self.shape_emb(data.shape_id)\n            + self.col_emb(data.colour_id)\n            + self.pos_emb(data.pos_id)\n        )\n\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        graph_x = global_add_pool(x, data.batch)  # sum-pool captures counts\n        return self.lin(graph_x)\n\n\nmodel = GNNClassifier(\n    len(shape_vocab), len(colour_vocab), pos_limit, 64, num_classes\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# ======================================================================\n# 7.  Book-keeping dict\n# ======================================================================\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"sequences\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ======================================================================\n# 8.  Train / evaluate helpers\n# ======================================================================\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, pred_all, true_all = [], [], []\n\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n\n        seqs_all.extend(batch.seq)\n        pred_all.extend(preds)\n        true_all.extend(gts)\n\n    return (\n        tot_loss / tot,\n        tot_correct / tot,\n        comp_weighted_acc(seqs_all, true_all, pred_all),\n        seqs_all,\n        pred_all,\n        true_all,\n    )\n\n\ndef train_epoch(loader):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n\n    for batch in loader:\n        batch = batch.to(device)\n\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n\n    return tot_loss / tot, tot_correct / tot\n\n\n# ======================================================================\n# 9.  Training loop\n# ======================================================================\nmax_epochs, patience = 40, 8\nbest_val_loss = math.inf\nbest_state = None\npat = 0\nstart = time.time()\n\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_acc = train_epoch(train_loader)\n    val_loss, val_acc, val_cwa, _, _, _ = evaluate(dev_loader)\n\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"epoch\": epoch, \"acc\": tr_acc}\n    )\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"epoch\": epoch, \"acc\": val_acc, \"CompWA\": val_cwa}\n    )\n\n    print(\n        f\"Epoch {epoch:02d}: validation_loss = {val_loss:.4f} | val_acc={val_acc:.3f} | CompWA={val_cwa:.3f}\"\n    )\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        experiment_data[\"SPR_BENCH\"][\"best_epoch\"] = epoch\n        pat = 0\n    else:\n        pat += 1\n        if pat >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ======================================================================\n# 10.  Test evaluation\n# ======================================================================\nif best_state:\n    model.load_state_dict(best_state)\n\ntest_loss, test_acc, test_cwa, seqs, preds, gts = evaluate(test_loader)\nprint(f\"TEST -- loss:{test_loss:.4f} acc:{test_acc:.3f} CompWA:{test_cwa:.3f}\")\n\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = gts\nexperiment_data[\"SPR_BENCH\"][\"sequences\"] = seqs\n\n# ======================================================================\n# 11.  Save bookkeeping\n# ======================================================================\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"saved experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, time, math, copy, random\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool, BatchNorm\nfrom torch_geometric.utils import add_self_loops\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ======================================================================\n# 1.  Low-level sequence helpers (SINGLE SOURCE OF TRUTH)\n# ======================================================================\ndef colour_of(token: str) -> str:\n    \"\"\"Return the colour substring of a token (may be multiple chars).\"\"\"\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    \"\"\"Return the leading shape symbol.\"\"\"\n    return token[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(tok) for tok in seq.split() if tok))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(tok) for tok in seq.split() if tok))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(1, sum(w))\n\n\n# ======================================================================\n# 2.  Load or synthesize SPR_BENCH\n# ======================================================================\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef load_spr(path: str) -> DatasetDict:\n    if os.path.isdir(path):\n\n        def _ld(split):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        print(\"Loaded SPR_BENCH from\", path)\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n\n    # ---------- tiny fallback ----------\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes = list(\"ABCDEF\")\n    colours = [str(i) for i in range(10)]\n\n    def make_seq():\n        L = random.randint(4, 9)\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours) for _ in range(L)\n        )\n\n    def label_rule(seq):\n        return sum(int(colour_of(tok)) for tok in seq.split()) % 2\n\n    def split(n):\n        seqs = [make_seq() for _ in range(n)]\n        return Dataset.from_dict(\n            {\n                \"id\": list(range(n)),\n                \"sequence\": seqs,\n                \"label\": [label_rule(s) for s in seqs],\n            }\n        )\n\n    return DatasetDict(train=split(800), dev=split(200), test=split(200))\n\n\nspr = load_spr(SPR_PATH)\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in spr.items()}, \"classes:\", num_classes)\n\n# ======================================================================\n# 3.  Build vocabularies\n# ======================================================================\nshape_vocab, colour_vocab = {}, {}\n\n\ndef add_shape(s):\n    if s not in shape_vocab:\n        shape_vocab[s] = len(shape_vocab)\n\n\ndef add_colour(c):\n    if c not in colour_vocab:\n        colour_vocab[c] = len(colour_vocab)\n\n\nfor seq in spr[\"train\"][\"sequence\"]:\n    for tok in seq.split():\n        add_shape(shape_of(tok))\n        add_colour(colour_of(tok))\n\npos_limit = 20  # safe upper bound\n\n\n# ======================================================================\n# 4.  Sequence \u2192 graph encoder\n# ======================================================================\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks], dtype=torch.long)\n    colour_ids = torch.tensor(\n        [colour_vocab[colour_of(t)] for t in toks], dtype=torch.long\n    )\n    pos_ids = torch.tensor(list(range(n)), dtype=torch.long)\n\n    # edges: sequential (bi-directional)\n    edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n\n    # edges: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shape_of(toks[i]) == shape_of(toks[j]):\n                edges += [[i, j], [j, i]]\n\n    # edges: same colour\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colour_of(toks[i]) == colour_of(toks[j]):\n                edges += [[i, j], [j, i]]\n\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    # add self loops\n    edge_index, _ = add_self_loops(edge_index, num_nodes=n)\n\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,\n        edge_index=edge_index,\n        y=torch.tensor(label, dtype=torch.long),\n        seq=seq,  # keep raw text for metrics\n    )\n\n\ndef encode_split(ds):\n    return [seq_to_graph(s, l) for s, l in zip(ds[\"sequence\"], ds[\"label\"])]\n\n\ntrain_graphs, dev_graphs, test_graphs = map(\n    encode_split, (spr[\"train\"], spr[\"dev\"], spr[\"test\"])\n)\n\n# ======================================================================\n# 5.  DataLoaders\n# ======================================================================\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# ======================================================================\n# 6.  GNN model\n# ======================================================================\nclass GNNClassifier(nn.Module):\n    def __init__(self, n_shape, n_colour, pos_max, hid=64, n_classes=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_colour, hid)\n        self.pos_emb = nn.Embedding(pos_max, hid)\n\n        self.conv1 = SAGEConv(hid, hid)\n        self.bn1 = BatchNorm(hid)\n        self.conv2 = SAGEConv(hid, hid)\n        self.bn2 = BatchNorm(hid)\n\n        self.lin = nn.Linear(hid, n_classes)\n        self.drop = nn.Dropout(0.3)\n\n    def forward(self, data):\n        x = (\n            self.shape_emb(data.shape_id)\n            + self.col_emb(data.colour_id)\n            + self.pos_emb(data.pos_id)\n        )\n\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        graph_x = global_add_pool(x, data.batch)  # sum-pool captures counts\n        return self.lin(graph_x)\n\n\nmodel = GNNClassifier(\n    len(shape_vocab), len(colour_vocab), pos_limit, 64, num_classes\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# ======================================================================\n# 7.  Book-keeping dict\n# ======================================================================\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"sequences\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ======================================================================\n# 8.  Train / evaluate helpers\n# ======================================================================\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, pred_all, true_all = [], [], []\n\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n\n        seqs_all.extend(batch.seq)\n        pred_all.extend(preds)\n        true_all.extend(gts)\n\n    return (\n        tot_loss / tot,\n        tot_correct / tot,\n        comp_weighted_acc(seqs_all, true_all, pred_all),\n        seqs_all,\n        pred_all,\n        true_all,\n    )\n\n\ndef train_epoch(loader):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n\n    for batch in loader:\n        batch = batch.to(device)\n\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n\n    return tot_loss / tot, tot_correct / tot\n\n\n# ======================================================================\n# 9.  Training loop\n# ======================================================================\nmax_epochs, patience = 40, 8\nbest_val_loss = math.inf\nbest_state = None\npat = 0\nstart = time.time()\n\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_acc = train_epoch(train_loader)\n    val_loss, val_acc, val_cwa, _, _, _ = evaluate(dev_loader)\n\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"epoch\": epoch, \"acc\": tr_acc}\n    )\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"epoch\": epoch, \"acc\": val_acc, \"CompWA\": val_cwa}\n    )\n\n    print(\n        f\"Epoch {epoch:02d}: validation_loss = {val_loss:.4f} | val_acc={val_acc:.3f} | CompWA={val_cwa:.3f}\"\n    )\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        experiment_data[\"SPR_BENCH\"][\"best_epoch\"] = epoch\n        pat = 0\n    else:\n        pat += 1\n        if pat >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ======================================================================\n# 10.  Test evaluation\n# ======================================================================\nif best_state:\n    model.load_state_dict(best_state)\n\ntest_loss, test_acc, test_cwa, seqs, preds, gts = evaluate(test_loader)\nprint(f\"TEST -- loss:{test_loss:.4f} acc:{test_acc:.3f} CompWA:{test_cwa:.3f}\")\n\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = gts\nexperiment_data[\"SPR_BENCH\"][\"sequences\"] = seqs\n\n# ======================================================================\n# 11.  Save bookkeeping\n# ======================================================================\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"saved experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, time, math, copy, random\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, global_add_pool, BatchNorm\nfrom torch_geometric.utils import add_self_loops\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ======================================================================\n# 1.  Low-level sequence helpers (SINGLE SOURCE OF TRUTH)\n# ======================================================================\ndef colour_of(token: str) -> str:\n    \"\"\"Return the colour substring of a token (may be multiple chars).\"\"\"\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    \"\"\"Return the leading shape symbol.\"\"\"\n    return token[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(tok) for tok in seq.split() if tok))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(tok) for tok in seq.split() if tok))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / max(1, sum(w))\n\n\n# ======================================================================\n# 2.  Load or synthesize SPR_BENCH\n# ======================================================================\nSPR_PATH = os.environ.get(\"SPR_BENCH_PATH\", \"./SPR_BENCH\")\n\n\ndef load_spr(path: str) -> DatasetDict:\n    if os.path.isdir(path):\n\n        def _ld(split):\n            return load_dataset(\n                \"csv\",\n                data_files=os.path.join(path, f\"{split}.csv\"),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        print(\"Loaded SPR_BENCH from\", path)\n        return DatasetDict(train=_ld(\"train\"), dev=_ld(\"dev\"), test=_ld(\"test\"))\n\n    # ---------- tiny fallback ----------\n    print(\"SPR_BENCH not found \u2013 generating toy data\")\n    shapes = list(\"ABCDEF\")\n    colours = [str(i) for i in range(10)]\n\n    def make_seq():\n        L = random.randint(4, 9)\n        return \" \".join(\n            random.choice(shapes) + random.choice(colours) for _ in range(L)\n        )\n\n    def label_rule(seq):\n        return sum(int(colour_of(tok)) for tok in seq.split()) % 2\n\n    def split(n):\n        seqs = [make_seq() for _ in range(n)]\n        return Dataset.from_dict(\n            {\n                \"id\": list(range(n)),\n                \"sequence\": seqs,\n                \"label\": [label_rule(s) for s in seqs],\n            }\n        )\n\n    return DatasetDict(train=split(800), dev=split(200), test=split(200))\n\n\nspr = load_spr(SPR_PATH)\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in spr.items()}, \"classes:\", num_classes)\n\n# ======================================================================\n# 3.  Build vocabularies\n# ======================================================================\nshape_vocab, colour_vocab = {}, {}\n\n\ndef add_shape(s):\n    if s not in shape_vocab:\n        shape_vocab[s] = len(shape_vocab)\n\n\ndef add_colour(c):\n    if c not in colour_vocab:\n        colour_vocab[c] = len(colour_vocab)\n\n\nfor seq in spr[\"train\"][\"sequence\"]:\n    for tok in seq.split():\n        add_shape(shape_of(tok))\n        add_colour(colour_of(tok))\n\npos_limit = 20  # safe upper bound\n\n\n# ======================================================================\n# 4.  Sequence \u2192 graph encoder\n# ======================================================================\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n\n    shape_ids = torch.tensor([shape_vocab[shape_of(t)] for t in toks], dtype=torch.long)\n    colour_ids = torch.tensor(\n        [colour_vocab[colour_of(t)] for t in toks], dtype=torch.long\n    )\n    pos_ids = torch.tensor(list(range(n)), dtype=torch.long)\n\n    # edges: sequential (bi-directional)\n    edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n\n    # edges: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shape_of(toks[i]) == shape_of(toks[j]):\n                edges += [[i, j], [j, i]]\n\n    # edges: same colour\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colour_of(toks[i]) == colour_of(toks[j]):\n                edges += [[i, j], [j, i]]\n\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    # add self loops\n    edge_index, _ = add_self_loops(edge_index, num_nodes=n)\n\n    return Data(\n        shape_id=shape_ids,\n        colour_id=colour_ids,\n        pos_id=pos_ids,\n        edge_index=edge_index,\n        y=torch.tensor(label, dtype=torch.long),\n        seq=seq,  # keep raw text for metrics\n    )\n\n\ndef encode_split(ds):\n    return [seq_to_graph(s, l) for s, l in zip(ds[\"sequence\"], ds[\"label\"])]\n\n\ntrain_graphs, dev_graphs, test_graphs = map(\n    encode_split, (spr[\"train\"], spr[\"dev\"], spr[\"test\"])\n)\n\n# ======================================================================\n# 5.  DataLoaders\n# ======================================================================\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# ======================================================================\n# 6.  GNN model\n# ======================================================================\nclass GNNClassifier(nn.Module):\n    def __init__(self, n_shape, n_colour, pos_max, hid=64, n_classes=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, hid)\n        self.col_emb = nn.Embedding(n_colour, hid)\n        self.pos_emb = nn.Embedding(pos_max, hid)\n\n        self.conv1 = SAGEConv(hid, hid)\n        self.bn1 = BatchNorm(hid)\n        self.conv2 = SAGEConv(hid, hid)\n        self.bn2 = BatchNorm(hid)\n\n        self.lin = nn.Linear(hid, n_classes)\n        self.drop = nn.Dropout(0.3)\n\n    def forward(self, data):\n        x = (\n            self.shape_emb(data.shape_id)\n            + self.col_emb(data.colour_id)\n            + self.pos_emb(data.pos_id)\n        )\n\n        x = torch.relu(self.bn1(self.conv1(x, data.edge_index)))\n        x = self.drop(x)\n        x = torch.relu(self.bn2(self.conv2(x, data.edge_index)))\n        graph_x = global_add_pool(x, data.batch)  # sum-pool captures counts\n        return self.lin(graph_x)\n\n\nmodel = GNNClassifier(\n    len(shape_vocab), len(colour_vocab), pos_limit, 64, num_classes\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# ======================================================================\n# 7.  Book-keeping dict\n# ======================================================================\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"sequences\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ======================================================================\n# 8.  Train / evaluate helpers\n# ======================================================================\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval()\n    tot_loss = tot_correct = tot = 0\n    seqs_all, pred_all, true_all = [], [], []\n\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        tot_loss += loss.item() * batch.num_graphs\n\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n\n        seqs_all.extend(batch.seq)\n        pred_all.extend(preds)\n        true_all.extend(gts)\n\n    return (\n        tot_loss / tot,\n        tot_correct / tot,\n        comp_weighted_acc(seqs_all, true_all, pred_all),\n        seqs_all,\n        pred_all,\n        true_all,\n    )\n\n\ndef train_epoch(loader):\n    model.train()\n    tot_loss = tot_correct = tot = 0\n\n    for batch in loader:\n        batch = batch.to(device)\n\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=-1).cpu().tolist()\n        gts = batch.y.cpu().tolist()\n        tot_correct += sum(p == g for p, g in zip(preds, gts))\n        tot += batch.num_graphs\n\n    return tot_loss / tot, tot_correct / tot\n\n\n# ======================================================================\n# 9.  Training loop\n# ======================================================================\nmax_epochs, patience = 40, 8\nbest_val_loss = math.inf\nbest_state = None\npat = 0\nstart = time.time()\n\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_acc = train_epoch(train_loader)\n    val_loss, val_acc, val_cwa, _, _, _ = evaluate(dev_loader)\n\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"epoch\": epoch, \"acc\": tr_acc}\n    )\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"epoch\": epoch, \"acc\": val_acc, \"CompWA\": val_cwa}\n    )\n\n    print(\n        f\"Epoch {epoch:02d}: validation_loss = {val_loss:.4f} | val_acc={val_acc:.3f} | CompWA={val_cwa:.3f}\"\n    )\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        experiment_data[\"SPR_BENCH\"][\"best_epoch\"] = epoch\n        pat = 0\n    else:\n        pat += 1\n        if pat >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ======================================================================\n# 10.  Test evaluation\n# ======================================================================\nif best_state:\n    model.load_state_dict(best_state)\n\ntest_loss, test_acc, test_cwa, seqs, preds, gts = evaluate(test_loader)\nprint(f\"TEST -- loss:{test_loss:.4f} acc:{test_acc:.3f} CompWA:{test_cwa:.3f}\")\n\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = gts\nexperiment_data[\"SPR_BENCH\"][\"sequences\"] = seqs\n\n# ======================================================================\n# 11.  Save bookkeeping\n# ======================================================================\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"saved experiment_data.npy\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy data', '\\n',\n\"{'train': 800, 'dev': 200, 'test': 200}\", ' ', 'classes:', ' ', '2', '\\n',\n'Epoch 01: validation_loss = 0.7168 | val_acc=0.565 | CompWA=0.567', '\\n',\n'Epoch 02: validation_loss = 0.7365 | val_acc=0.520 | CompWA=0.523', '\\n',\n'Epoch 03: validation_loss = 0.7453 | val_acc=0.495 | CompWA=0.501', '\\n',\n'Epoch 04: validation_loss = 0.7462 | val_acc=0.520 | CompWA=0.523', '\\n',\n'Epoch 05: validation_loss = 0.7632 | val_acc=0.490 | CompWA=0.486', '\\n',\n'Epoch 06: validation_loss = 0.7548 | val_acc=0.490 | CompWA=0.501', '\\n',\n'Epoch 07: validation_loss = 0.7658 | val_acc=0.490 | CompWA=0.494', '\\n',\n'Epoch 08: validation_loss = 0.7714 | val_acc=0.490 | CompWA=0.485', '\\n',\n'Epoch 09: validation_loss = 0.7718 | val_acc=0.500 | CompWA=0.501', '\\n',\n'Early stopping.', '\\n', 'TEST -- loss:0.6579 acc:0.630 CompWA:0.625', '\\n',\n'saved experiment_data.npy', '\\n', 'Execution time: 3 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy data', '\\n',\n\"{'train': 800, 'dev': 200, 'test': 200}\", ' ', 'classes:', ' ', '2', '\\n',\n'Epoch 01: val_loss=0.7441 | val_acc=0.460 | CompWA=0.455', '\\n', 'Epoch 02:\nval_loss=0.8215 | val_acc=0.460 | CompWA=0.464', '\\n', 'Epoch 03:\nval_loss=0.8042 | val_acc=0.510 | CompWA=0.514', '\\n', 'Epoch 04:\nval_loss=0.7035 | val_acc=0.505 | CompWA=0.506', '\\n', 'Epoch 05:\nval_loss=0.7068 | val_acc=0.530 | CompWA=0.531', '\\n', 'Epoch 06:\nval_loss=0.6933 | val_acc=0.530 | CompWA=0.525', '\\n', 'Epoch 07:\nval_loss=0.7096 | val_acc=0.545 | CompWA=0.547', '\\n', 'Epoch 08:\nval_loss=0.7076 | val_acc=0.525 | CompWA=0.524', '\\n', 'Epoch 09:\nval_loss=0.6909 | val_acc=0.535 | CompWA=0.539', '\\n', 'Epoch 10:\nval_loss=0.6817 | val_acc=0.535 | CompWA=0.533', '\\n', 'Epoch 11:\nval_loss=0.6894 | val_acc=0.525 | CompWA=0.523', '\\n', 'Epoch 12:\nval_loss=0.6981 | val_acc=0.530 | CompWA=0.529', '\\n', 'Epoch 13:\nval_loss=0.6947 | val_acc=0.525 | CompWA=0.531', '\\n', 'Epoch 14:\nval_loss=0.6886 | val_acc=0.550 | CompWA=0.543', '\\n', 'Epoch 15:\nval_loss=0.6988 | val_acc=0.540 | CompWA=0.537', '\\n', 'Epoch 16:\nval_loss=0.7127 | val_acc=0.530 | CompWA=0.532', '\\n', 'Epoch 17:\nval_loss=0.7279 | val_acc=0.530 | CompWA=0.533', '\\n', 'Epoch 18:\nval_loss=0.7362 | val_acc=0.515 | CompWA=0.517', '\\n', 'Early stopping.', '\\n',\n'TEST -- loss:0.7371 acc:0.480 CompWA:0.482', '\\n', 'saved experiment_data.npy',\n'\\n', 'Execution time: 8 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy data', '\\n',\n\"{'train': 800, 'dev': 200, 'test': 200}\", ' ', 'classes:', ' ', '2', '\\n',\n'\\n==== Running FULL ====', '\\n', '[FULL] Epoch 01  val_loss=0.7436  acc=0.480\nCompWA=0.480', '\\n', '[FULL] Epoch 02  val_loss=0.7465  acc=0.475\nCompWA=0.477', '\\n', '[FULL] Epoch 03  val_loss=0.7522  acc=0.490\nCompWA=0.492', '\\n', '[FULL] Epoch 04  val_loss=0.7545  acc=0.515\nCompWA=0.520', '\\n', '[FULL] Epoch 05  val_loss=0.7644  acc=0.530\nCompWA=0.531', '\\n', '[FULL] Epoch 06  val_loss=0.7428  acc=0.510\nCompWA=0.507', '\\n', '[FULL] Epoch 07  val_loss=0.7425  acc=0.500\nCompWA=0.498', '\\n', '[FULL] Epoch 08  val_loss=0.7422  acc=0.525\nCompWA=0.526', '\\n', '[FULL] Epoch 09  val_loss=0.7470  acc=0.520\nCompWA=0.529', '\\n', '[FULL] Epoch 10  val_loss=0.7527  acc=0.530\nCompWA=0.539', '\\n', '[FULL] Epoch 11  val_loss=0.7497  acc=0.530\nCompWA=0.541', '\\n', '[FULL] Epoch 12  val_loss=0.7445  acc=0.530\nCompWA=0.539', '\\n', '[FULL] Epoch 13  val_loss=0.7405  acc=0.540\nCompWA=0.554', '\\n', '[FULL] Epoch 14  val_loss=0.7418  acc=0.540\nCompWA=0.551', '\\n', '[FULL] Epoch 15  val_loss=0.7547  acc=0.530\nCompWA=0.536', '\\n', '[FULL] Epoch 16  val_loss=0.7546  acc=0.545\nCompWA=0.555', '\\n', '[FULL] Epoch 17  val_loss=0.7408  acc=0.515\nCompWA=0.525', '\\n', '[FULL] Epoch 18  val_loss=0.7402  acc=0.525\nCompWA=0.537', '\\n', '[FULL] Epoch 19  val_loss=0.7353  acc=0.545\nCompWA=0.554', '\\n', '[FULL] Epoch 20  val_loss=0.7468  acc=0.540\nCompWA=0.552', '\\n', '[FULL] Epoch 21  val_loss=0.7770  acc=0.525\nCompWA=0.539', '\\n', '[FULL] Epoch 22  val_loss=0.7539  acc=0.530\nCompWA=0.540', '\\n', '[FULL] Epoch 23  val_loss=0.7614  acc=0.575\nCompWA=0.582', '\\n', '[FULL] Epoch 24  val_loss=0.7699  acc=0.535\nCompWA=0.546', '\\n', '[FULL] Epoch 25  val_loss=0.7663  acc=0.520\nCompWA=0.529', '\\n', '[FULL] Epoch 26  val_loss=0.7722  acc=0.515\nCompWA=0.525', '\\n', '[FULL] Epoch 27  val_loss=0.7676  acc=0.535\nCompWA=0.552', '\\n', '[FULL] TEST -- loss:0.8980 acc:0.450 CompWA:0.450', '\\n',\n'\\n==== Running SEQ_ONLY ====', '\\n', '[SEQ_ONLY] Epoch 01  val_loss=0.7521\nacc=0.480  CompWA=0.486', '\\n', '[SEQ_ONLY] Epoch 02  val_loss=0.8004  acc=0.480\nCompWA=0.477', '\\n', '[SEQ_ONLY] Epoch 03  val_loss=0.7634  acc=0.510\nCompWA=0.509', '\\n', '[SEQ_ONLY] Epoch 04  val_loss=0.7688  acc=0.470\nCompWA=0.464', '\\n', '[SEQ_ONLY] Epoch 05  val_loss=0.7512  acc=0.510\nCompWA=0.510', '\\n', '[SEQ_ONLY] Epoch 06  val_loss=0.7641  acc=0.520\nCompWA=0.520', '\\n', '[SEQ_ONLY] Epoch 07  val_loss=0.7663  acc=0.490\nCompWA=0.492', '\\n', '[SEQ_ONLY] Epoch 08  val_loss=0.7824  acc=0.465\nCompWA=0.467', '\\n', '[SEQ_ONLY] Epoch 09  val_loss=0.7724  acc=0.480\nCompWA=0.482', '\\n', '[SEQ_ONLY] Epoch 10  val_loss=0.7757  acc=0.505\nCompWA=0.504', '\\n', '[SEQ_ONLY] Epoch 11  val_loss=0.7742  acc=0.475\nCompWA=0.473', '\\n', '[SEQ_ONLY] Epoch 12  val_loss=0.7769  acc=0.465\nCompWA=0.462', '\\n', '[SEQ_ONLY] Epoch 13  val_loss=0.7895  acc=0.490\nCompWA=0.488', '\\n', '[SEQ_ONLY] TEST -- loss:0.7465 acc:0.515 CompWA:0.509',\n'\\n', '\\nSaved experiment_data.npy', '\\n', 'Execution time: 5 seconds seconds\n(time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy\ndata', '\\n', \"{'train': 800, 'dev': 200, 'test': 200}\", ' ', 'classes:', ' ',\n'2', '\\n', 'Epoch 01: val_loss=0.7673 val_acc=0.490 CompWA=0.490', '\\n', 'Epoch\n02: val_loss=0.7562 val_acc=0.475 CompWA=0.470', '\\n', 'Epoch 03:\nval_loss=0.7615 val_acc=0.450 CompWA=0.447', '\\n', 'Epoch 04: val_loss=0.7861\nval_acc=0.445 CompWA=0.433', '\\n', 'Epoch 05: val_loss=0.7647 val_acc=0.490\nCompWA=0.485', '\\n', 'Epoch 06: val_loss=0.7654 val_acc=0.495 CompWA=0.499',\n'\\n', 'Epoch 07: val_loss=0.7635 val_acc=0.475 CompWA=0.477', '\\n', 'Epoch 08:\nval_loss=0.7621 val_acc=0.455 CompWA=0.451', '\\n', 'Epoch 09: val_loss=0.7706\nval_acc=0.440 CompWA=0.437', '\\n', 'Epoch 10: val_loss=0.7654 val_acc=0.480\nCompWA=0.477', '\\n', 'Early stopping.', '\\n', 'TEST -- loss:0.7427 acc:0.500\nCompWA:0.490', '\\n', 'Saved experiment_data.npy', '\\n', 'Execution time: 3\nseconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy\ndata', '\\n', \"{'train': 800, 'dev': 200, 'test': 200}\", ' ', 'classes:', ' ',\n'2', '\\n', 'Epoch 01: val_loss=0.7819 val_acc=0.500 CompWA=0.497', '\\n', 'Epoch\n02: val_loss=0.8061 val_acc=0.500 CompWA=0.506', '\\n', 'Epoch 03:\nval_loss=0.7466 val_acc=0.510 CompWA=0.509', '\\n', 'Epoch 04: val_loss=0.7292\nval_acc=0.475 CompWA=0.468', '\\n', 'Epoch 05: val_loss=0.7191 val_acc=0.480\nCompWA=0.468', '\\n', 'Epoch 06: val_loss=0.7191 val_acc=0.475 CompWA=0.465',\n'\\n', 'Epoch 07: val_loss=0.7258 val_acc=0.485 CompWA=0.469', '\\n', 'Epoch 08:\nval_loss=0.7242 val_acc=0.475 CompWA=0.465', '\\n', 'Epoch 09: val_loss=0.7317\nval_acc=0.540 CompWA=0.541', '\\n', 'Epoch 10: val_loss=0.7528 val_acc=0.525\nCompWA=0.530', '\\n', 'Epoch 11: val_loss=0.7452 val_acc=0.520 CompWA=0.526',\n'\\n', 'Epoch 12: val_loss=0.7357 val_acc=0.450 CompWA=0.441', '\\n', 'Epoch 13:\nval_loss=0.7432 val_acc=0.490 CompWA=0.491', '\\n', 'Early stopping.', '\\n',\n'TEST -- loss:0.7011 acc:0.525 CompWA:0.519', '\\n', 'saved experiment_data.npy',\n'\\n', 'Execution time: 6 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy data', '\\n',\n\"{'train': 1000, 'dev': 250, 'test': 250}\", ' ', 'classes:', ' ', '2', '\\n',\n'Vocab sizes \u2013 shapes:', ' ', '8', ' ', 'colours:', ' ', '10', ' ', 'max_len:',\n' ', '35', '\\n', 'Epoch 01: val_loss=0.9590  acc=0.464 CWA=0.470 SWA=0.464\nCSWA=0.467', '\\n', 'Epoch 02: val_loss=1.4179  acc=0.532 CWA=0.536 SWA=0.536\nCSWA=0.536', '\\n', 'Epoch 03: val_loss=0.8423  acc=0.516 CWA=0.526 SWA=0.520\nCSWA=0.523', '\\n', 'Epoch 04: val_loss=0.8411  acc=0.508 CWA=0.523 SWA=0.518\nCSWA=0.521', '\\n', 'Epoch 05: val_loss=0.8177  acc=0.492 CWA=0.506 SWA=0.500\nCSWA=0.503', '\\n', 'Epoch 06: val_loss=0.8587  acc=0.488 CWA=0.492 SWA=0.485\nCSWA=0.489', '\\n', 'Epoch 07: val_loss=0.8243  acc=0.468 CWA=0.476 SWA=0.467\nCSWA=0.472', '\\n', 'Epoch 08: val_loss=0.8104  acc=0.476 CWA=0.487 SWA=0.478\nCSWA=0.483', '\\n', 'Epoch 09: val_loss=0.8174  acc=0.460 CWA=0.474 SWA=0.467\nCSWA=0.471', '\\n', 'Epoch 10: val_loss=0.8170  acc=0.492 CWA=0.502 SWA=0.497\nCSWA=0.499', '\\n', 'Epoch 11: val_loss=0.8314  acc=0.440 CWA=0.446 SWA=0.443\nCSWA=0.445', '\\n', 'Epoch 12: val_loss=0.8412  acc=0.424 CWA=0.430 SWA=0.425\nCSWA=0.428', '\\n', 'Epoch 13: val_loss=0.8403  acc=0.476 CWA=0.485 SWA=0.478\nCSWA=0.482', '\\n', 'Epoch 14: val_loss=0.8352  acc=0.464 CWA=0.476 SWA=0.467\nCSWA=0.472', '\\n', 'Epoch 15: val_loss=0.8420  acc=0.480 CWA=0.484 SWA=0.478\nCSWA=0.482', '\\n', 'Epoch 16: val_loss=0.9788  acc=0.480 CWA=0.497 SWA=0.492\nCSWA=0.495', '\\n', 'Early stopping.', '\\n', 'TEST -- loss:0.7749 acc:0.532\nCWA:0.540 SWA:0.538 CSWA:0.539', '\\n', 'Saved experiment_data.npy', '\\n',\n'Execution time: 5 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy data', '\\n',\n\"{'train': 800, 'dev': 200, 'test': 200}\", ' ', 'classes:', ' ', '2', '\\n',\n'pos_limit =', ' ', '13', '\\n', 'Epoch 01: val_loss=0.7719 val_acc=0.515\nCSWA=0.516', '\\n', 'Epoch 02: val_loss=0.7577 val_acc=0.505 CSWA=0.520', '\\n',\n'Epoch 03: val_loss=0.8726 val_acc=0.475 CSWA=0.484', '\\n', 'Epoch 04:\nval_loss=0.7854 val_acc=0.495 CSWA=0.511', '\\n', 'Epoch 05: val_loss=0.7575\nval_acc=0.450 CSWA=0.460', '\\n', 'Epoch 06: val_loss=0.7534 val_acc=0.485\nCSWA=0.499', '\\n', 'Epoch 07: val_loss=0.7683 val_acc=0.485 CSWA=0.486', '\\n',\n'Epoch 08: val_loss=0.7700 val_acc=0.495 CSWA=0.499', '\\n', 'Epoch 09:\nval_loss=0.7645 val_acc=0.475 CSWA=0.485', '\\n', 'Epoch 10: val_loss=0.7790\nval_acc=0.505 CSWA=0.510', '\\n', 'Epoch 11: val_loss=0.7896 val_acc=0.515\nCSWA=0.522', '\\n', 'Epoch 12: val_loss=0.7876 val_acc=0.485 CSWA=0.490', '\\n',\n'Epoch 13: val_loss=0.7918 val_acc=0.470 CSWA=0.469', '\\n', 'Epoch 14:\nval_loss=0.7750 val_acc=0.510 CSWA=0.521', '\\n', 'Early stopping.', '\\n', 'TEST\n-- loss:0.8096 acc:0.470 CSWA:0.468', '\\n', 'Saved experiment_data.npy', '\\n',\n'Execution time: 4 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy data', '\\n',\n\"{'train': 800, 'dev': 200, 'test': 200}\", ' ', 'classes:', ' ', '2', '\\n', 'max\nsequence length = 15,  pos_limit = 16', '\\n', 'Epoch 01: val_loss=0.8549\nval_acc=0.480  CSWA=0.477  (0.3s)', '\\n', 'Epoch 02: val_loss=0.7178\nval_acc=0.545  CSWA=0.545  (0.1s)', '\\n', 'Epoch 03: val_loss=0.7346\nval_acc=0.500  CSWA=0.502  (0.1s)', '\\n', 'Epoch 04: val_loss=0.7568\nval_acc=0.470  CSWA=0.481  (0.1s)', '\\n', 'Epoch 05: val_loss=0.7589\nval_acc=0.495  CSWA=0.500  (0.1s)', '\\n', 'Epoch 06: val_loss=0.7504\nval_acc=0.490  CSWA=0.491  (0.1s)', '\\n', 'Epoch 07: val_loss=0.7440\nval_acc=0.525  CSWA=0.528  (0.1s)', '\\n', 'Epoch 08: val_loss=0.7516\nval_acc=0.510  CSWA=0.523  (0.1s)', '\\n', 'Epoch 09: val_loss=0.7501\nval_acc=0.505  CSWA=0.510  (0.1s)', '\\n', 'Epoch 10: val_loss=0.7754\nval_acc=0.535  CSWA=0.541  (0.1s)', '\\n', 'Early stopping.', '\\n', 'TEST --\nloss:0.7244  acc:0.505  CSWA:0.513', '\\n', 'Saved experiment_data.npy to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_20-55-\n38_gnn_for_spr_attempt_0/0-run/process_ForkProcess-19/working', '\\n', 'Execution\ntime: 3 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy data', '\\n',\n\"{'train': 800, 'dev': 200, 'test': 200}\", '\\n', 'Vocab sizes \u2013 shapes:', ' ',\n'9', ' ', 'colours:', ' ', '15', ' ', '| max_len:', ' ', '25', '\\n', 'Epoch 01:\nval_loss=0.7398  acc=0.505 CWA=0.504 SWA=0.512 CSWA=0.508', '\\n', 'Epoch 02:\nval_loss=0.7503  acc=0.515 CWA=0.499 SWA=0.501 CSWA=0.500', '\\n', 'Epoch 03:\nval_loss=0.7781  acc=0.510 CWA=0.499 SWA=0.499 CSWA=0.499', '\\n', 'Epoch 04:\nval_loss=0.7730  acc=0.525 CWA=0.514 SWA=0.513 CSWA=0.514', '\\n', 'Epoch 05:\nval_loss=0.8315  acc=0.490 CWA=0.482 SWA=0.480 CSWA=0.481', '\\n', 'Epoch 06:\nval_loss=0.7972  acc=0.485 CWA=0.474 SWA=0.473 CSWA=0.474', '\\n', 'Epoch 07:\nval_loss=0.7789  acc=0.505 CWA=0.499 SWA=0.496 CSWA=0.498', '\\n', 'Epoch 08:\nval_loss=0.8008  acc=0.465 CWA=0.457 SWA=0.453 CSWA=0.455', '\\n', 'Epoch 09:\nval_loss=0.8355  acc=0.490 CWA=0.478 SWA=0.480 CSWA=0.479', '\\n', 'Early\nstopping.', '\\n', 'TEST -- loss:0.7032 acc:0.565 CWA:0.568 SWA:0.559\nCSWA:0.564', '\\n', 'Saved experiment_data.npy to', ' ', '/home/zxl240011/AI-Scie\nntist-v2/experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-17/working', '\\n', 'Execution time: 5 seconds seconds\n(time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy data', '\\n',\n\"{'train': 800, 'dev': 200, 'test': 200}\", ' ', 'classes:', ' ', '2', '\\n',\n'Epoch 01: validation_loss = 0.7242 | val_acc=0.540 | CompWA=0.535', '\\n',\n'Epoch 02: validation_loss = 0.8229 | val_acc=0.475 | CompWA=0.463', '\\n',\n'Epoch 03: validation_loss = 0.7665 | val_acc=0.510 | CompWA=0.493', '\\n',\n'Epoch 04: validation_loss = 0.7644 | val_acc=0.515 | CompWA=0.498', '\\n',\n'Epoch 05: validation_loss = 0.7878 | val_acc=0.495 | CompWA=0.473', '\\n',\n'Epoch 06: validation_loss = 0.8054 | val_acc=0.495 | CompWA=0.474', '\\n',\n'Epoch 07: validation_loss = 0.7971 | val_acc=0.475 | CompWA=0.455', '\\n',\n'Epoch 08: validation_loss = 0.7819 | val_acc=0.490 | CompWA=0.472', '\\n',\n'Epoch 09: validation_loss = 0.7769 | val_acc=0.490 | CompWA=0.471', '\\n',\n'Early stopping.', '\\n', 'TEST -- loss:0.7316 acc:0.515 CompWA:0.506', '\\n',\n'saved experiment_data.npy', '\\n', 'Execution time: 4 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy data', '\\n',\n\"{'train': 800, 'dev': 200, 'test': 200}\", ' ', 'classes:', ' ', '2', '\\n',\n'Epoch 01: validation_loss = 0.7414 | val_acc=0.480 | CompWA=0.490', '\\n',\n'Epoch 02: validation_loss = 0.7321 | val_acc=0.515 | CompWA=0.514', '\\n',\n'Epoch 03: validation_loss = 0.7292 | val_acc=0.530 | CompWA=0.545', '\\n',\n'Epoch 04: validation_loss = 0.7489 | val_acc=0.425 | CompWA=0.432', '\\n',\n'Epoch 05: validation_loss = 0.7462 | val_acc=0.470 | CompWA=0.476', '\\n',\n'Epoch 06: validation_loss = 0.7532 | val_acc=0.510 | CompWA=0.510', '\\n',\n'Epoch 07: validation_loss = 0.7692 | val_acc=0.485 | CompWA=0.485', '\\n',\n'Epoch 08: validation_loss = 0.7486 | val_acc=0.495 | CompWA=0.493', '\\n',\n'Epoch 09: validation_loss = 0.7428 | val_acc=0.530 | CompWA=0.532', '\\n',\n'Epoch 10: validation_loss = 0.7452 | val_acc=0.515 | CompWA=0.513', '\\n',\n'Epoch 11: validation_loss = 0.7813 | val_acc=0.475 | CompWA=0.465', '\\n',\n'Early stopping.', '\\n', 'TEST -- loss:0.7380 acc:0.490 CompWA:0.484', '\\n',\n'saved experiment_data.npy', '\\n', 'Execution time: 3 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating toy data', '\\n',\n\"{'train': 800, 'dev': 200, 'test': 200}\", ' ', 'classes:', ' ', '2', '\\n',\n'Epoch 01: validation_loss = 0.7332 | val_acc=0.535 | CompWA=0.548', '\\n',\n'Epoch 02: validation_loss = 0.7398 | val_acc=0.505 | CompWA=0.520', '\\n',\n'Epoch 03: validation_loss = 0.7435 | val_acc=0.515 | CompWA=0.511', '\\n',\n'Epoch 04: validation_loss = 0.7381 | val_acc=0.505 | CompWA=0.498', '\\n',\n'Epoch 05: validation_loss = 0.7426 | val_acc=0.510 | CompWA=0.513', '\\n',\n'Epoch 06: validation_loss = 0.7395 | val_acc=0.475 | CompWA=0.484', '\\n',\n'Epoch 07: validation_loss = 0.7597 | val_acc=0.495 | CompWA=0.494', '\\n',\n'Epoch 08: validation_loss = 0.7426 | val_acc=0.500 | CompWA=0.498', '\\n',\n'Epoch 09: validation_loss = 0.7390 | val_acc=0.510 | CompWA=0.503', '\\n',\n'Early stopping.', '\\n', 'TEST -- loss:0.7213 acc:0.535 CompWA:0.534', '\\n',\n'saved experiment_data.npy', '\\n', 'Execution time: 4 seconds seconds (time\nlimit is 30 minutes).']", ""], "analysis": ["", "", "", "The execution output indicates that the SPR_BENCH dataset was not found, and the\ncode reverted to generating toy data instead. This is a significant issue since\nthe experiment is meant to evaluate performance on the SPR_BENCH benchmark, not\non synthetic toy data. To fix this, ensure the SPR_BENCH dataset is correctly\nlocated at the specified path (./SPR_BENCH or as set by the SPR_BENCH_PATH\nenvironment variable). If the dataset is missing, provide clear instructions to\ndownload and prepare it, or include it in the project repository if permissible.", "", "", "The experiment failed to achieve meaningful learning. The validation and test\naccuracies remained near random chance (around 50%) and did not improve\nsignificantly across epochs. The Color-Shape Weighted Accuracy (CSWA) metrics\nalso showed no meaningful improvement, indicating that the model failed to learn\nthe task effectively.  Potential issues and fixes: 1. **Dataset Issue**: The\nscript generated toy data instead of using the actual SPR_BENCH dataset. Ensure\nthe correct dataset path is provided to load the SPR_BENCH data. 2. **Model\nComplexity**: The model architecture might not be complex enough for the task.\nConsider adding more layers or increasing the hidden size. 3. **Learning Rate**:\nThe learning rate might be suboptimal. Experiment with different learning rates\nor use a learning rate scheduler. 4. **Edge Construction**: The graph\nconstruction might be too simple or missing critical relationships. Revisit the\nedge definitions to ensure they capture meaningful relationships in the data. 5.\n**Regularization**: Overfitting or underfitting might be occurring. Experiment\nwith dropout rates or other regularization techniques.  Addressing these issues\nshould help improve the model's performance.", "", "The script executed successfully, and the training process completed without\nerrors. The model was evaluated on a synthetic dataset due to the absence of the\nSPR_BENCH dataset. The results indicate that the model achieved a test accuracy\nof 56.5%, with Color-Weighted Accuracy (CWA) at 56.8%, Shape-Weighted Accuracy\n(SWA) at 55.9%, and Combined Structural Weighted Accuracy (CSWA) at 56.4%. These\nresults suggest that the model is functioning as expected, although the\nperformance could potentially be improved with further tuning or access to the\nactual SPR_BENCH dataset.", "", "", "The model's performance metrics (validation accuracy, validation loss, and\nCompWA) did not improve significantly over epochs, and the early stopping\nmechanism was triggered without achieving meaningful progress. The test accuracy\nand CompWA were also very low (0.535 and 0.534 respectively), indicating that\nthe model failed to learn effectively from the data. This suggests a potential\nissue in the model's architecture, hyperparameters, or data representation.\nProposed Fixes: 1. **Model Architecture:** Experiment with different GNN\narchitectures, such as GAT or GCN, instead of SAGEConv. Try increasing the\nnumber of layers or hidden units. 2. **Hyperparameters:** Adjust learning rate,\nbatch size, and dropout rates. Use a learning rate scheduler to improve\nconvergence. 3. **Data Representation:** Revisit the graph encoding process to\nensure that relationships between nodes (shapes, colors, positions) are\naccurately captured. 4. **Regularization:** Add techniques like weight decay or\ngradient clipping to stabilize training. 5. **Dataset Size:** The toy dataset\nmay be too small to effectively train the GNN. Use the actual SPR_BENCH dataset\nfor meaningful evaluation. 6. **Debugging:** Check if the labels in the dataset\nare balanced and if the graph construction process introduces any errors or\nbiases.", ""], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training accuracy", "lower_is_better": false, "description": "Accuracy of the model during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.634, "best_value": 0.634}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Loss of the model during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6369, "best_value": 0.6369}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy of the model on the validation dataset at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.565, "best_value": 0.565}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss of the model on the validation dataset at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7168, "best_value": 0.7168}]}, {"metric_name": "validation CompWA", "lower_is_better": false, "description": "CompWA metric on the validation dataset at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.567, "best_value": 0.567}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Accuracy of the model on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.63, "best_value": 0.63}]}, {"metric_name": "test CompWA", "lower_is_better": false, "description": "CompWA metric on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.625, "best_value": 0.625}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Loss during training phase", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.614511, "best_value": 0.614511}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss during validation phase", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.736242, "best_value": 0.736242}]}, {"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy during training phase", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6613, "best_value": 0.6613}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy during validation phase", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.515, "best_value": 0.515}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "Complexity-weighted accuracy during validation phase", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5165, "best_value": 0.5165}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Accuracy on the test dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.48, "best_value": 0.48}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "Complexity-weighted accuracy on the test dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4822, "best_value": 0.4822}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "FULL - SPR_BENCH", "final_value": 0.511, "best_value": 0.511}, {"dataset_name": "SEQ_ONLY - SPR_BENCH", "final_value": 0.6052, "best_value": 0.6052}]}, {"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy during training.", "data": [{"dataset_name": "FULL - SPR_BENCH", "final_value": 0.746, "best_value": 0.746}, {"dataset_name": "SEQ_ONLY - SPR_BENCH", "final_value": 0.666, "best_value": 0.666}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "FULL - SPR_BENCH", "final_value": 0.7353, "best_value": 0.7353}, {"dataset_name": "SEQ_ONLY - SPR_BENCH", "final_value": 0.7512, "best_value": 0.7512}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy during validation.", "data": [{"dataset_name": "FULL - SPR_BENCH", "final_value": 0.545, "best_value": 0.545}, {"dataset_name": "SEQ_ONLY - SPR_BENCH", "final_value": 0.51, "best_value": 0.51}]}, {"metric_name": "validation CompWA", "lower_is_better": false, "description": "The composite weighted average during validation.", "data": [{"dataset_name": "FULL - SPR_BENCH", "final_value": 0.554, "best_value": 0.554}, {"dataset_name": "SEQ_ONLY - SPR_BENCH", "final_value": 0.51, "best_value": 0.51}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value during testing.", "data": [{"dataset_name": "FULL - SPR_BENCH", "final_value": 0.898, "best_value": 0.898}, {"dataset_name": "SEQ_ONLY - SPR_BENCH", "final_value": 0.7465, "best_value": 0.7465}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "The accuracy during testing.", "data": [{"dataset_name": "FULL - SPR_BENCH", "final_value": 0.45, "best_value": 0.45}, {"dataset_name": "SEQ_ONLY - SPR_BENCH", "final_value": 0.515, "best_value": 0.515}]}, {"metric_name": "test CompWA", "lower_is_better": false, "description": "The composite weighted average during testing.", "data": [{"dataset_name": "FULL - SPR_BENCH", "final_value": 0.45, "best_value": 0.45}, {"dataset_name": "SEQ_ONLY - SPR_BENCH", "final_value": 0.509, "best_value": 0.509}]}]}, {"metric_names": [{"metric_name": "accuracy", "lower_is_better": false, "description": "Measures the proportion of correctly predicted instances.", "data": [{"dataset_name": "training", "final_value": 0.693, "best_value": 0.693}, {"dataset_name": "validation", "final_value": 0.48, "best_value": 0.48}, {"dataset_name": "test", "final_value": 0.5, "best_value": 0.5}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Measures the error between predicted and actual values.", "data": [{"dataset_name": "training", "final_value": 0.5921, "best_value": 0.5921}, {"dataset_name": "validation", "final_value": 0.7654, "best_value": 0.7654}]}, {"metric_name": "CompWA", "lower_is_better": false, "description": "Composite Weighted Accuracy metric.", "data": [{"dataset_name": "validation", "final_value": 0.477, "best_value": 0.477}, {"dataset_name": "test", "final_value": 0.49, "best_value": 0.49}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6516789078712464, "best_value": 0.6516789078712464}]}, {"metric_name": "training accuracy", "lower_is_better": false, "description": "Final training accuracy for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6025, "best_value": 0.6025}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Best validation loss for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7190800189971924, "best_value": 0.7190800189971924}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Best validation accuracy for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.475, "best_value": 0.475}]}, {"metric_name": "validation complexity weighted accuracy", "lower_is_better": false, "description": "Best validation complexity weighted accuracy for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4653631284916201, "best_value": 0.4653631284916201}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Final test loss for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7011192631721497, "best_value": 0.7011192631721497}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Final test accuracy for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.525, "best_value": 0.525}]}, {"metric_name": "test complexity weighted accuracy", "lower_is_better": false, "description": "Final test complexity weighted accuracy for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5191675794085433, "best_value": 0.5191675794085433}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated during training, indicating how well the model is performing on the training data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6153, "best_value": 0.6153}]}, {"metric_name": "training accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.664, "best_value": 0.664}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset, used to evaluate the model's performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.8104, "best_value": 0.8104}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.476, "best_value": 0.476}]}, {"metric_name": "validation colour-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset, weighted by colour categories.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.487, "best_value": 0.487}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset, weighted by shape categories.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.478, "best_value": 0.478}]}, {"metric_name": "validation combined-score weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset, weighted by a combined score of different categories.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.483, "best_value": 0.483}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training, indicating error magnitude.", "data": [{"dataset_name": "no_self_loop_SPR_BENCH", "final_value": 0.5772, "best_value": 0.5772}]}, {"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy during training, indicating the proportion of correct predictions.", "data": [{"dataset_name": "no_self_loop_SPR_BENCH", "final_value": 0.6937, "best_value": 0.6937}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, indicating error magnitude.", "data": [{"dataset_name": "no_self_loop_SPR_BENCH", "final_value": 0.7534, "best_value": 0.7534}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy during validation, indicating the proportion of correct predictions.", "data": [{"dataset_name": "no_self_loop_SPR_BENCH", "final_value": 0.485, "best_value": 0.485}]}, {"metric_name": "validation CSWA", "lower_is_better": false, "description": "The CSWA value during validation, indicating a specific performance metric.", "data": [{"dataset_name": "no_self_loop_SPR_BENCH", "final_value": 0.4995, "best_value": 0.4995}]}]}, {"metric_names": [{"metric_name": "accuracy", "lower_is_better": false, "description": "Measures the proportion of correctly predicted instances out of the total instances.", "data": [{"dataset_name": "train", "final_value": 0.546, "best_value": 0.546}, {"dataset_name": "validation", "final_value": 0.545, "best_value": 0.545}, {"dataset_name": "test", "final_value": 0.505, "best_value": 0.505}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Represents the error between the predicted and actual values. Lower values indicate better performance.", "data": [{"dataset_name": "train", "final_value": 0.7837, "best_value": 0.7837}, {"dataset_name": "validation", "final_value": 0.7178, "best_value": 0.7178}]}, {"metric_name": "CSWA (Class-Specific Weighted Accuracy)", "lower_is_better": false, "description": "A weighted accuracy metric that accounts for class-specific performance.", "data": [{"dataset_name": "validation", "final_value": 0.545, "best_value": 0.545}, {"dataset_name": "test", "final_value": 0.513, "best_value": 0.513}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5976, "best_value": 0.5976}]}, {"metric_name": "training accuracy", "lower_is_better": false, "description": "Measures the accuracy on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.688, "best_value": 0.688}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7398, "best_value": 0.7398}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Measures the accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.505, "best_value": 0.505}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "Custom Weighted Accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.504, "best_value": 0.504}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "Smoothed Weighted Accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.512, "best_value": 0.512}]}, {"metric_name": "validation CSWA", "lower_is_better": false, "description": "Custom Smoothed Weighted Accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.508, "best_value": 0.508}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Measures the accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.565, "best_value": 0.565}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "Custom Weighted Accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.568, "best_value": 0.568}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "Smoothed Weighted Accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.559, "best_value": 0.559}]}, {"metric_name": "test CSWA", "lower_is_better": false, "description": "Custom Smoothed Weighted Accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.564, "best_value": 0.564}]}]}, {"metric_names": [{"metric_name": "training accuracy", "lower_is_better": false, "description": "Accuracy during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.656, "best_value": 0.656}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Loss during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6154, "best_value": 0.6154}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.54, "best_value": 0.54}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7242, "best_value": 0.7242}]}, {"metric_name": "validation CompWA", "lower_is_better": false, "description": "CompWA metric during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.535, "best_value": 0.535}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Accuracy during test phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.515, "best_value": 0.515}]}, {"metric_name": "test CompWA", "lower_is_better": false, "description": "CompWA metric during test phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.506, "best_value": 0.506}]}]}, {"metric_names": [{"metric_name": "training accuracy", "lower_is_better": false, "description": "Accuracy during training phase", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.655, "best_value": 0.655}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Loss during training phase", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.611, "best_value": 0.611}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy on validation dataset (best epoch)", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.53, "best_value": 0.53}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on validation dataset (best epoch)", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7292, "best_value": 0.7292}]}, {"metric_name": "validation CompWA", "lower_is_better": false, "description": "Composite Weighted Accuracy on validation dataset (best epoch)", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.545, "best_value": 0.545}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Accuracy on test dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.49, "best_value": 0.49}]}, {"metric_name": "test CompWA", "lower_is_better": false, "description": "Composite Weighted Accuracy on test dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.484, "best_value": 0.484}]}]}, {"metric_names": [{"metric_name": "training accuracy", "lower_is_better": false, "description": "Accuracy of the model during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.632, "best_value": 0.632}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Loss value of the model during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.637, "best_value": 0.637}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy of the model on the validation dataset at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.535, "best_value": 0.535}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss value of the model on the validation dataset at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7332, "best_value": 0.7332}]}, {"metric_name": "validation CompWA", "lower_is_better": false, "description": "Composite Weighted Average metric on the validation dataset at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.548, "best_value": 0.548}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Accuracy of the model on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.535, "best_value": 0.535}]}, {"metric_name": "test CompWA", "lower_is_better": false, "description": "Composite Weighted Average metric on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.534, "best_value": 0.534}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [true, false, false, false, false, false, false, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_5ce9dbd6c23b4847bc8edf8bca1e2ce1_proc_1494830/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_5ce9dbd6c23b4847bc8edf8bca1e2ce1_proc_1494830/SPR_BENCH_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_5ce9dbd6c23b4847bc8edf8bca1e2ce1_proc_1494830/SPR_BENCH_cowa_curve.png"], ["../../logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_compWA_curve.png", "../../logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_test_accuracy_bar.png", "../../logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_test_compwa_bar.png"], [], ["../../logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_compwa_curve.png", "../../logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_9641ad7d1e1f4e7588740008f7383fcb_proc_1497846/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_9641ad7d1e1f4e7588740008f7383fcb_proc_1497846/SPR_BENCH_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_9641ad7d1e1f4e7588740008f7383fcb_proc_1497846/SPR_BENCH_final_metrics.png"], [], ["../../logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_CSWA_curve.png", "../../logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_struct_metrics_curve.png", "../../logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_863792e89e9e451dbfeaecbfe4806c82_proc_1497844/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_863792e89e9e451dbfeaecbfe4806c82_proc_1497844/SPR_BENCH_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_863792e89e9e451dbfeaecbfe4806c82_proc_1497844/SPR_BENCH_cowa_curve.png"], ["../../logs/0-run/experiment_results/experiment_89b651abfe2a4cbeb2399c07a6e7da71_proc_1497846/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_89b651abfe2a4cbeb2399c07a6e7da71_proc_1497846/SPR_BENCH_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_89b651abfe2a4cbeb2399c07a6e7da71_proc_1497846/SPR_BENCH_cowa_curve.png"], [], ["../../logs/0-run/experiment_results/seed_aggregation_719620de688e49fe9f729a0f6b7c3790/SPR_BENCH_agg_loss_curve.png", "../../logs/0-run/experiment_results/seed_aggregation_719620de688e49fe9f729a0f6b7c3790/SPR_BENCH_agg_accuracy_curve.png", "../../logs/0-run/experiment_results/seed_aggregation_719620de688e49fe9f729a0f6b7c3790/SPR_BENCH_agg_cowa_curve.png"]], "plot_paths": [["experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ce9dbd6c23b4847bc8edf8bca1e2ce1_proc_1494830/SPR_BENCH_loss_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ce9dbd6c23b4847bc8edf8bca1e2ce1_proc_1494830/SPR_BENCH_accuracy_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ce9dbd6c23b4847bc8edf8bca1e2ce1_proc_1494830/SPR_BENCH_cowa_curve.png"], ["experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_loss_curves.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_accuracy_curves.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_compWA_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_loss_curves.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_accuracy_curves.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_test_accuracy_bar.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_test_compwa_bar.png"], [], ["experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_loss_curves.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_accuracy_curves.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_compwa_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9641ad7d1e1f4e7588740008f7383fcb_proc_1497846/SPR_BENCH_loss_curves.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9641ad7d1e1f4e7588740008f7383fcb_proc_1497846/SPR_BENCH_accuracy_curves.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9641ad7d1e1f4e7588740008f7383fcb_proc_1497846/SPR_BENCH_final_metrics.png"], [], ["experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_loss_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_accuracy_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_CSWA_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_loss_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_accuracy_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_struct_metrics_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_863792e89e9e451dbfeaecbfe4806c82_proc_1497844/SPR_BENCH_loss_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_863792e89e9e451dbfeaecbfe4806c82_proc_1497844/SPR_BENCH_accuracy_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_863792e89e9e451dbfeaecbfe4806c82_proc_1497844/SPR_BENCH_cowa_curve.png"], ["experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_89b651abfe2a4cbeb2399c07a6e7da71_proc_1497846/SPR_BENCH_loss_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_89b651abfe2a4cbeb2399c07a6e7da71_proc_1497846/SPR_BENCH_accuracy_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_89b651abfe2a4cbeb2399c07a6e7da71_proc_1497846/SPR_BENCH_cowa_curve.png"], [], ["experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_719620de688e49fe9f729a0f6b7c3790/SPR_BENCH_agg_loss_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_719620de688e49fe9f729a0f6b7c3790/SPR_BENCH_agg_accuracy_curve.png", "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_719620de688e49fe9f729a0f6b7c3790/SPR_BENCH_agg_cowa_curve.png"]], "plot_analyses": [[{"analysis": "The loss curves indicate that the training loss decreases steadily throughout the epochs, which is expected as the model learns from the training data. However, the validation loss shows fluctuations and does not decrease consistently. This suggests potential overfitting to the training data, as the model's performance on unseen data (validation set) does not improve consistently. The gap between training and validation loss after a few epochs is concerning and indicates that the model might not generalize well.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ce9dbd6c23b4847bc8edf8bca1e2ce1_proc_1494830/SPR_BENCH_loss_curve.png"}, {"analysis": "The accuracy curves show that training accuracy improves consistently over epochs, reflecting the model's ability to learn patterns from the training data. However, the validation accuracy remains stagnant and even decreases in certain epochs. This further supports the observation of overfitting, as the model's performance on the validation set does not improve in tandem with the training performance. The lack of improvement in validation accuracy indicates that the model might not be capturing the underlying patterns effectively for generalization.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ce9dbd6c23b4847bc8edf8bca1e2ce1_proc_1494830/SPR_BENCH_accuracy_curve.png"}, {"analysis": "The CoWA curve for the validation set shows a declining trend in complexity-weighted accuracy over the epochs, with some minor fluctuations. This suggests that the model's ability to handle sequences with higher complexity diminishes as training progresses. The lack of improvement in this metric highlights a challenge in the model's design or training process, possibly related to how it captures and processes relational and structural information in the data.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ce9dbd6c23b4847bc8edf8bca1e2ce1_proc_1494830/SPR_BENCH_cowa_curve.png"}], [{"analysis": "The loss curves show that the training loss decreases steadily, which indicates that the model is learning effectively on the training data. However, the validation loss initially decreases but starts to increase slightly after around 10 epochs, suggesting potential overfitting. This implies that the model may perform well on the training data but might struggle to generalize to unseen data.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_loss_curves.png"}, {"analysis": "The accuracy curves reveal that the training accuracy improves consistently, which aligns with the decreasing training loss. However, the validation accuracy plateaus and even slightly decreases after approximately 12 epochs, reinforcing the observation of overfitting. This suggests that while the model is learning patterns in the training data, its ability to generalize to validation data is limited after a certain point.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_accuracy_curves.png"}, {"analysis": "The complexity-weighted accuracy for validation shows an initial increase, peaking around epoch 8, followed by fluctuations. This indicates that the model's performance in capturing complex patterns improves initially but does not consistently maintain high performance across epochs. The fluctuations suggest sensitivity to the complexity of the validation data.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_compWA_curve.png"}, {"analysis": "The confusion matrix shows that the model struggles to differentiate between the two classes. It has a high number of false negatives (62) and false positives (42), indicating that the model's predictive power is not well-balanced across classes. This imbalance suggests that further tuning or architectural adjustments might be necessary to improve classification performance.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e93eb6632e7a41d6b2866d8cd7f8a62c_proc_1497844/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The plot compares the training and validation loss for two models: FULL and SEQ_ONLY. The FULL model uses the complete graph-based representation, while the SEQ_ONLY model relies on sequence-based features only. The FULL model demonstrates a smoother and more consistent decrease in training loss, indicating better optimization. Its validation loss also stabilizes over time, suggesting good generalization. In contrast, the SEQ_ONLY model shows an initially high training loss that quickly drops but exhibits more fluctuations in both training and validation loss, indicating potential overfitting or instability in learning.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the training and validation accuracy for the FULL and SEQ_ONLY models. The FULL model achieves higher training accuracy over time, demonstrating its superior ability to learn from the data. Its validation accuracy also surpasses that of the SEQ_ONLY model, indicating better generalization. The SEQ_ONLY model's training accuracy increases steadily but remains below the FULL model's. Its validation accuracy fluctuates significantly and stays lower, suggesting that sequence-only features are less effective for the task.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_accuracy_curves.png"}, {"analysis": "This plot shows a comparison of test accuracy between the FULL and SEQ_ONLY models. The FULL model achieves slightly higher test accuracy compared to the SEQ_ONLY model, indicating that the graph-based representation provides a performance edge in capturing the task's requirements.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_test_accuracy_bar.png"}, {"analysis": "This plot compares the Complexity-Weighted Accuracy (CompWA) on the test set for the FULL and SEQ_ONLY models. The FULL model achieves marginally better CompWA than the SEQ_ONLY model, suggesting that the graph-based representation is more effective at handling complex patterns in the data.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d2e5b465334e456cac454c054bda5522_proc_1497845/SPR_BENCH_test_compwa_bar.png"}], [], [{"analysis": "The loss curves indicate that the training loss steadily decreases, showing that the model is learning from the training data. However, the validation loss does not exhibit a consistent downward trend and even starts to increase slightly after a certain point, suggesting potential overfitting. The absence of Batch Normalization may contribute to this instability in the validation loss.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_loss_curves.png"}, {"analysis": "The accuracy curves show the training accuracy improving over epochs, reflecting the model's ability to fit the training data. However, the validation accuracy fluctuates significantly and does not show a clear upward trend, indicating that the model struggles to generalize to unseen data. This could be a result of overfitting or insufficient regularization.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_accuracy_curves.png"}, {"analysis": "The validation CompWA metric exhibits significant fluctuations, with a notable drop at certain epochs. This inconsistency suggests that the model's performance on the weighted accuracy metric is unstable and may not reliably improve across epochs. The lack of Batch Normalization could be a factor contributing to this instability.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_compwa_curve.png"}, {"analysis": "The confusion matrix shows that the model performs better on one class (69 correct predictions) compared to the other (36 correct predictions). However, there is a substantial number of misclassifications (37 and 58). This imbalance indicates that the model may be biased towards one class or struggles to distinguish between the two classes effectively. This could be due to class imbalance or insufficient model capacity to capture the complexities of the data.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_70f36fbce73242cf934bef122691d7a8_proc_1497847/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The plot shows the training and validation loss over epochs. The training loss decreases steadily, indicating that the model is learning effectively. However, the validation loss decreases initially but starts to increase slightly after epoch 12, suggesting potential overfitting. This indicates that the model might benefit from regularization techniques, such as dropout or early stopping, to improve generalization.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9641ad7d1e1f4e7588740008f7383fcb_proc_1497846/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot tracks accuracy metrics (Train Accuracy, Validation Accuracy, Color-Weighted Accuracy, Shape-Weighted Accuracy, and Combined Shape-Color Weighted Accuracy) over epochs. While training accuracy improves consistently, validation metrics exhibit fluctuations and remain relatively close to each other, with no significant divergence. This suggests that the model is capturing the overall patterns in the data but might struggle with specific nuances. The lack of a clear upward trajectory in validation metrics highlights the need for further tuning, such as hyperparameter optimization or feature engineering.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9641ad7d1e1f4e7588740008f7383fcb_proc_1497846/SPR_BENCH_accuracy_curves.png"}, {"analysis": "The bar chart summarizes the final validation metrics, showing similar performance across Accuracy, Color-Weighted Accuracy, Shape-Weighted Accuracy, and Combined Shape-Color Weighted Accuracy, all around 0.5. This uniformity indicates that the model is balanced in handling different aspects of the task but has room for improvement in its overall predictive power. Achieving a higher score across these metrics could potentially involve refining the graph representation or exploring alternative GNN architectures.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9641ad7d1e1f4e7588740008f7383fcb_proc_1497846/SPR_BENCH_final_metrics.png"}], [], [{"analysis": "This plot shows the cross-entropy loss for both the training and validation sets across ten epochs. Initially, both losses decrease, indicating that the model is learning. However, from epoch 4 onwards, the validation loss begins to stagnate and slightly increase, while the training loss continues to decrease. This divergence suggests overfitting, where the model performs well on the training data but struggles to generalize to unseen data.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_loss_curve.png"}, {"analysis": "This plot depicts the accuracy for both the training and validation sets over ten epochs. Training accuracy increases steadily, indicating that the model is learning to predict the training data correctly. However, the validation accuracy plateaus and shows fluctuations, particularly after epoch 4. This behavior further supports the observation of overfitting, as the model's generalization ability does not improve significantly.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_accuracy_curve.png"}, {"analysis": "This plot tracks the Color-Weighted Accuracy (CWA) on the validation set over ten epochs. There is noticeable fluctuation in the CWA, with no clear upward trend. While there are peaks at specific epochs, the metric does not consistently improve, suggesting instability in the model's performance on this metric. This instability might be linked to the model's sensitivity to the color variety in sequences.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_CSWA_curve.png"}, {"analysis": "The confusion matrix for the test set reveals that the model struggles with both classes, as evidenced by the significant number of misclassifications. For class 0, 38 predictions are correct while 58 are incorrect, and for class 1, 63 predictions are correct while 41 are incorrect. The model appears to have a slight bias toward class 1, as it predicts it more frequently. This imbalance indicates that the model may not have learned the underlying rules effectively.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d9cf3d7101204450ab2707cedbcbf249_proc_1497847/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The loss curves show a steady decrease in training loss over the epochs, indicating that the model is learning from the data. However, the validation loss initially decreases but then starts to increase after epoch 4, which suggests potential overfitting. This behavior highlights the need for regularization techniques or early stopping to prevent overfitting and improve generalization.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_loss_curve.png"}, {"analysis": "The accuracy curves reveal a clear divergence between training and validation accuracy after epoch 4. While the training accuracy continues to improve, the validation accuracy fluctuates and does not show consistent improvement. This further supports the observation that the model is overfitting to the training data. Adjustments such as data augmentation or hyperparameter tuning might be necessary to address this issue.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_accuracy_curve.png"}, {"analysis": "The structural metrics (CWA, SWA, and CSWA) for validation display significant fluctuations across epochs. The drop in performance after epoch 4 and subsequent recovery suggest instability in the model's ability to generalize structural relationships. This instability might be due to insufficient training data or an overly complex model architecture that struggles to generalize.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_struct_metrics_curve.png"}, {"analysis": "The confusion matrix indicates that the model has a moderate ability to distinguish between the two classes. The true positive rates (51 and 62) are relatively balanced, but there are still a significant number of false positives and false negatives (49 and 38, respectively). This suggests that the model's decision boundary could be refined, possibly by incorporating better feature representations or adjusting the class weights in the loss function to address class imbalance.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b7231271749240aca3b16941464907af_proc_1497845/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "This plot shows the loss curves for both training and validation sets over the epochs. The training loss decreases steadily, indicating that the model is learning from the training data. However, the validation loss initially decreases but then plateaus and slightly increases after epoch 4, suggesting potential overfitting or a failure to generalize well to unseen data. This could indicate a need for regularization techniques or hyperparameter tuning to improve generalization.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_863792e89e9e451dbfeaecbfe4806c82_proc_1497844/SPR_BENCH_loss_curve.png"}, {"analysis": "This plot displays the accuracy curves for training and validation sets over the epochs. While training accuracy consistently improves, the validation accuracy remains relatively stagnant, with minor fluctuations around the 0.5 mark after epoch 3. This reinforces the observation from the loss curves that the model might be overfitting to the training data and struggling to generalize to the validation set.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_863792e89e9e451dbfeaecbfe4806c82_proc_1497844/SPR_BENCH_accuracy_curve.png"}, {"analysis": "This plot focuses on the Complexity-Weighted Accuracy (CoWA) for the validation set. The CoWA fluctuates significantly across epochs, showing no clear upward trend. This suggests that the model is not consistently improving its ability to handle more complex sequences. The instability in CoWA might indicate that the model architecture or training process needs adjustments to better capture the complexity of the data.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_863792e89e9e451dbfeaecbfe4806c82_proc_1497844/SPR_BENCH_cowa_curve.png"}], [{"analysis": "The loss curves indicate that the training loss decreases steadily over epochs, showing that the model is learning from the training data. However, the validation loss exhibits some fluctuations and does not consistently decrease. This suggests potential overfitting or instability in the model's generalization to unseen data. The gap between training and validation loss widens slightly, which further supports this observation.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_89b651abfe2a4cbeb2399c07a6e7da71_proc_1497846/SPR_BENCH_loss_curve.png"}, {"analysis": "The accuracy curves show that the training accuracy improves over the epochs, indicating that the model is fitting the training data. However, the validation accuracy experiences significant fluctuations and does not improve consistently, reflecting instability in the model's performance on unseen data. This instability could be due to the model's sensitivity to the validation set or insufficient regularization.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_89b651abfe2a4cbeb2399c07a6e7da71_proc_1497846/SPR_BENCH_accuracy_curve.png"}, {"analysis": "The complexity-weighted accuracy (CoWA) curve for the validation set exhibits high variance across epochs. While there are moments of improvement, the overall trend does not show consistent progress. This suggests that the model struggles to maintain stable performance when accounting for the complexity of the sequences, highlighting a potential limitation in its ability to generalize effectively.", "plot_path": "experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_89b651abfe2a4cbeb2399c07a6e7da71_proc_1497846/SPR_BENCH_cowa_curve.png"}], [], []], "vlm_feedback_summary": ["The plots indicate that while the model learns effectively on the training data,\nit struggles to generalize to the validation set. Overfitting is a significant\nconcern, as evidenced by the divergence between training and validation loss,\nstagnation in validation accuracy, and declining complexity-weighted accuracy.\nThese issues suggest that improvements in model design or training methodology\nare needed to better capture the relational and structural information inherent\nin the SPR task.", "The experimental results indicate that while the model is learning effectively\non the training data, it struggles to generalize to validation data, as\nevidenced by increasing validation loss and plateauing accuracy. The complexity-\nweighted accuracy highlights the model's sensitivity to complex patterns, and\nthe confusion matrix reveals significant misclassification issues. These\nfindings suggest the need for regularization and architectural improvements to\nenhance generalization and class balance.", "The FULL model consistently outperforms the SEQ_ONLY model across all metrics,\nincluding training/validation loss, accuracy, and complexity-weighted accuracy.\nThis suggests that the graph-based representation captures the relational and\nstructural dependencies in the data more effectively than the sequence-only\napproach.", "[]", "The experimental plots reveal challenges in generalization and stability,\nparticularly in the validation metrics. The absence of Batch Normalization\nappears to contribute to the observed fluctuations and potential overfitting.\nThe results highlight the need for improvements in regularization techniques and\npotentially re-evaluating the model architecture to enhance its performance on\nthe SPR task.", "The plots provide insights into the model's learning process and performance\nmetrics. Training appears effective, but validation results suggest potential\noverfitting and room for improvement in generalization. Accuracy metrics\nindicate balanced but moderate performance, highlighting the need for further\noptimization and experimentation.", "[]", "The plots reveal that the model suffers from overfitting, as seen in the\ndivergence between training and validation losses and the stagnation of\nvalidation accuracy. The Color-Weighted Accuracy metric shows instability,\nsuggesting that the model struggles to generalize effectively on this specific\nmetric. The confusion matrix highlights significant misclassifications and a\nslight bias toward one class, indicating that the model has not fully captured\nthe underlying patterns in the data.", "The plots collectively indicate that the model is learning during training but\nstruggles to generalize to validation and test data. Overfitting is a\nsignificant issue, as evidenced by the divergence in loss and accuracy curves.\nStructural metric instability and the confusion matrix suggest the need for\nbetter generalization strategies, such as regularization, improved data\nrepresentation, or hyperparameter tuning.", "The results indicate that while the model learns effectively on the training\nset, it struggles to generalize to the validation set, as evidenced by the\nplateauing validation loss and accuracy. The instability in the Complexity-\nWeighted Accuracy (CoWA) further highlights the model's difficulty in handling\ncomplex data. Regularization, hyperparameter tuning, or architectural changes\nmay be required to improve performance.", "The plots reveal that while the model is learning effectively on the training\ndata, its performance on validation data is inconsistent and unstable. This is\nevident in the fluctuating validation loss, accuracy, and CoWA curves. The\nresults suggest potential issues with overfitting, insufficient regularization,\nor challenges in generalizing to complex patterns in the data. Further tuning of\nthe model and regularization techniques may be required to address these issues.", "[]", "[]"], "exec_time": [3.5768139362335205, 8.019836187362671, 5.526839256286621, 3.441930055618286, 6.363339185714722, 5.271135091781616, 4.044813394546509, 3.264547348022461, 5.357157945632935, 4.988440752029419, 3.9243690967559814, 4.197715520858765, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[]"], ["[]"], ["[\"SPR_BENCH\"]"], [], ["[]"], ["[]"], [], ["[]"], ["[]"], ["[]"], ["[]"], [], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- setup ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\n\n# ---------- helper for CoWA ----------\ndef colour_of(token: str) -> str:\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    return token[0]\n\n\ndef complexity_weight(seq: str) -> int:\n    return len({colour_of(t) for t in seq.split() if t}) + len(\n        {shape_of(t) for t in seq.split() if t}\n    )\n\n\n# ---------- per-dataset plots ----------\ndatasets = list(experiment_data.keys()) if experiment_data else []\nfor ds_name in datasets:\n    ds = experiment_data[ds_name]\n    # ---- extract series ----\n    epochs = np.arange(1, len(ds[\"losses\"][\"train\"]) + 1)\n    train_loss = ds[\"losses\"][\"train\"]\n    val_loss = ds[\"losses\"][\"val\"]\n    train_acc = [m[\"acc\"] for m in ds[\"metrics\"][\"train\"]]\n    val_acc = [m[\"acc\"] for m in ds[\"metrics\"][\"val\"]]\n    val_cwa = [\n        m[\"CompWA\"] if \"CompWA\" in m else m.get(\"cowa\", np.nan)\n        for m in ds[\"metrics\"][\"val\"]\n    ]\n\n    # 1) Loss curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"{ds_name} Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds_name}: {e}\")\n        plt.close()\n\n    # 2) Accuracy curve ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_acc, label=\"Train\")\n        plt.plot(epochs, val_acc, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(f\"{ds_name} Accuracy Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_accuracy_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot for {ds_name}: {e}\")\n        plt.close()\n\n    # 3) CoWA curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, label=\"Validation CoWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(f\"{ds_name} CoWA Curve\\nValidation Set Only\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_cowa_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CoWA plot for {ds_name}: {e}\")\n        plt.close()\n\n    # ---- evaluation metrics ----\n    try:\n        preds = np.array(ds[\"predictions\"])\n        gts = np.array(ds[\"ground_truth\"])\n        seqs = np.array(ds[\"sequences\"])\n\n        test_acc = (preds == gts).mean()\n        weights = np.array([complexity_weight(s) for s in seqs])\n        cowa = (weights * (preds == gts)).sum() / weights.sum()\n        print(f\"{ds_name} \u2013 Test Accuracy: {test_acc:.3f} | Test CoWA: {cowa:.3f}\")\n    except Exception as e:\n        print(f\"Error computing metrics for {ds_name}: {e}\")\n\n# ---------- comparison plots across datasets (if >1) ----------\nif len(datasets) > 1:\n    # Validation loss comparison\n    try:\n        plt.figure()\n        for ds_name in datasets:\n            val_loss = experiment_data[ds_name][\"losses\"][\"val\"]\n            plt.plot(np.arange(1, len(val_loss) + 1), val_loss, label=f\"{ds_name} Val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Loss\")\n        plt.title(\"Validation Loss Comparison Across Datasets\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_val_loss.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison loss plot: {e}\")\n        plt.close()\n\n    # Validation accuracy comparison\n    try:\n        plt.figure()\n        for ds_name in datasets:\n            val_acc = [m[\"acc\"] for m in experiment_data[ds_name][\"metrics\"][\"val\"]]\n            plt.plot(np.arange(1, len(val_acc) + 1), val_acc, label=f\"{ds_name} Val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Accuracy\")\n        plt.title(\"Validation Accuracy Comparison Across Datasets\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_val_accuracy.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison accuracy plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    book = experiment_data[\"NoPosEmb\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    book = None\n\nif book:\n    train_loss = book[\"losses\"][\"train\"]\n    val_loss = book[\"losses\"][\"val\"]\n    train_acc = [m[\"acc\"] for m in book[\"metrics\"][\"train\"]]\n    val_acc = [m[\"acc\"] for m in book[\"metrics\"][\"val\"]]\n    val_cwa = [m[\"CompWA\"] for m in book[\"metrics\"][\"val\"]]\n    preds = np.array(book[\"predictions\"])\n    gts = np.array(book[\"ground_truth\"])\n    epochs = np.arange(1, len(train_loss) + 1)\n\n    # 1. Loss curves ----------------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # 2. Accuracy curves ------------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_acc, label=\"Train\")\n        plt.plot(epochs, val_acc, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH Accuracy Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_accuracy_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot: {e}\")\n        plt.close()\n\n    # 3. Complexity-Weighted Accuracy ----------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, color=\"purple\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Comp-Weighted Acc\")\n        plt.title(\"SPR_BENCH Validation Complexity-Weighted Accuracy\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_compWA_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CompWA plot: {e}\")\n        plt.close()\n\n    # 4. Confusion matrix -----------------------------------------------------\n    try:\n        cm = np.zeros((2, 2), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n        plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        for i in range(2):\n            for j in range(2):\n                plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n        plt.xticks([0, 1], [\"Pred 0\", \"Pred 1\"])\n        plt.yticks([0, 1], [\"True 0\", \"True 1\"])\n        plt.title(\n            \"SPR_BENCH Test Confusion Matrix\\nLeft: Ground Truth, Right: Predicted\"\n        )\n        plt.colorbar()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix plot: {e}\")\n        plt.close()\n\n    # ---------- print summary ----------\n    print(f\"Best validation epoch: {book['best_epoch']}\")\n    if len(val_cwa) > 0:\n        print(f\"Final Val Acc: {val_acc[-1]:.3f} | Final Val CompWA: {val_cwa[-1]:.3f}\")\n    if preds.size:\n        correct = (preds == gts).mean()\n        print(f\"Test Accuracy (stored preds): {correct:.3f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------\n# paths & data loading\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ndataset_name = \"SPR_BENCH\"\nexps = [\"FULL\", \"SEQ_ONLY\"]\n\n\n# ------------------------------------------------------------------\n# helper to fetch curves\n# ------------------------------------------------------------------\ndef curve(exp, split, field):\n    \"\"\"Return y values for a given curve (losses or acc)\"\"\"\n    if exp not in experiment_data:\n        return []\n    node = experiment_data[exp][dataset_name]\n    if field == \"loss\":\n        return node[\"losses\"][split]\n    if field == \"acc\":\n        return [m[\"acc\"] for m in node[\"metrics\"][split]]\n    return []\n\n\n# ------------------------------------------------------------------\n# 1. Loss curves\n# ------------------------------------------------------------------\ntry:\n    plt.figure(figsize=(6, 4))\n    for exp in exps:\n        y_tr = curve(exp, \"train\", \"loss\")\n        y_val = curve(exp, \"val\", \"loss\")\n        x = range(1, len(y_tr) + 1)\n        plt.plot(x, y_tr, label=f\"{exp}-train\")\n        plt.plot(x, y_val, \"--\", label=f\"{exp}-val\")\n    plt.title(f\"{dataset_name}: Training vs Validation Loss (FULL vs SEQ_ONLY)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{dataset_name}_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------\n# 2. Accuracy curves\n# ------------------------------------------------------------------\ntry:\n    plt.figure(figsize=(6, 4))\n    for exp in exps:\n        y_tr = curve(exp, \"train\", \"acc\")\n        y_val = curve(exp, \"val\", \"acc\")\n        x = range(1, len(y_tr) + 1)\n        plt.plot(x, y_tr, label=f\"{exp}-train\")\n        plt.plot(x, y_val, \"--\", label=f\"{exp}-val\")\n    plt.title(f\"{dataset_name}: Training vs Validation Accuracy (FULL vs SEQ_ONLY)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{dataset_name}_accuracy_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy curve plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------\n# 3. Bar chart \u2013 test ACC\n# ------------------------------------------------------------------\ntry:\n    plt.figure(figsize=(4, 4))\n    accs = [experiment_data[e][dataset_name][\"metrics\"][\"test\"][\"acc\"] for e in exps]\n    plt.bar(exps, accs, color=[\"tab:blue\", \"tab:orange\"])\n    plt.ylim(0, 1)\n    plt.title(f\"{dataset_name}: Test Accuracy Comparison\")\n    plt.ylabel(\"Accuracy\")\n    fname = os.path.join(working_dir, f\"{dataset_name}_test_accuracy_bar.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test accuracy bar plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------\n# 4. Bar chart \u2013 test CompWA\n# ------------------------------------------------------------------\ntry:\n    plt.figure(figsize=(4, 4))\n    cwas = [experiment_data[e][dataset_name][\"metrics\"][\"test\"][\"CompWA\"] for e in exps]\n    plt.bar(exps, cwas, color=[\"tab:green\", \"tab:red\"])\n    plt.ylim(0, 1)\n    plt.title(f\"{dataset_name}: Test Complexity-Weighted Accuracy\")\n    plt.ylabel(\"CompWA\")\n    fname = os.path.join(working_dir, f\"{dataset_name}_test_compwa_bar.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test CompWA bar plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------\n# textual summary\n# ------------------------------------------------------------------\nfor e in exps:\n    m = (\n        experiment_data.get(e, {})\n        .get(dataset_name, {})\n        .get(\"metrics\", {})\n        .get(\"test\", {})\n    )\n    if m:\n        print(f\"{e}  --  ACC: {m['acc']:.3f}   CompWA: {m['CompWA']:.3f}\")\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------ paths & data loading ------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data[\"no_batch_norm\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = None\n\nif exp:\n    # -------- extract series --------\n    tr_loss = exp[\"losses\"][\"train\"]\n    val_loss = exp[\"losses\"][\"val\"]\n    tr_acc = [d[\"acc\"] for d in exp[\"metrics\"][\"train\"]]\n    val_acc = [d[\"acc\"] for d in exp[\"metrics\"][\"val\"]]\n    val_cwa = [d[\"CompWA\"] for d in exp[\"metrics\"][\"val\"]]\n    epochs = list(range(1, len(tr_loss) + 1))\n    preds = np.array(exp[\"predictions\"])\n    gts = np.array(exp[\"ground_truth\"])\n    n_classes = len(set(gts)) if len(gts) else 0\n\n    # -------- loss curves --------\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH Loss Curves (No BatchNorm)\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # -------- accuracy curves --------\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_acc, label=\"Train\")\n        plt.plot(epochs, val_acc, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH Accuracy Curves (No BatchNorm)\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_accuracy_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy curve plot: {e}\")\n        plt.close()\n\n    # -------- CompWA curve (validation) --------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Comp-Weighted Accuracy\")\n        plt.title(\"SPR_BENCH Validation CompWA (No BatchNorm)\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_compwa_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CompWA plot: {e}\")\n        plt.close()\n\n    # -------- confusion matrix --------\n    try:\n        if n_classes and preds.size:\n            cm = np.zeros((n_classes, n_classes), dtype=int)\n            for t, p in zip(gts, preds):\n                cm[t, p] += 1\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            for i in range(n_classes):\n                for j in range(n_classes):\n                    plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n            plt.title(\"SPR_BENCH Confusion Matrix (Test, No BatchNorm)\")\n            fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\n    # -------- terminal metrics print --------\n    tst = exp.get(\"metrics\", {}).get(\"test\", {})\n    print(\n        f\"Test Accuracy: {tst.get('acc', 'N/A'):.3f}, \"\n        f\"Test CompWA: {tst.get('CompWA', 'N/A'):.3f}\"\n    )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------------- #\n# Load experiment data\n# ------------------------------------------------------------------------- #\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# Helper to fetch safest value\ndef _get(lst, key, default=np.nan):\n    return [d.get(key, default) for d in lst]\n\n\n# ------------------------------------------------------------------------- #\n# Iterate over datasets contained in bookkeeping dict\n# ------------------------------------------------------------------------- #\nfor dset_name, log in experiment_data.items():\n    # ----------------------- Plot 1: loss curves -------------------------- #\n    try:\n        plt.figure()\n        epochs = range(1, len(log[\"losses\"][\"train\"]) + 1)\n        plt.plot(epochs, log[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(epochs, log[\"losses\"][\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dset_name} \u2013 Training vs Validation Loss\")\n        plt.legend()\n        fname = f\"{dset_name}_loss_curves.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {dset_name}: {e}\")\n        plt.close()\n\n    # --------------------- Plot 2: accuracy curves ------------------------ #\n    try:\n        plt.figure()\n        train_acc = _get(log[\"metrics\"][\"train\"], \"acc\")\n        val_entries = log[\"metrics\"][\"val\"]\n        val_acc = _get(val_entries, \"acc\")\n        val_cwa = _get(val_entries, \"CWA\")\n        val_swa = _get(val_entries, \"SWA\")\n        val_cswa = _get(val_entries, \"CSWA\")\n\n        plt.plot(epochs, train_acc, label=\"Train Acc\")\n        plt.plot(epochs, val_acc, label=\"Val Acc\")\n        plt.plot(epochs, val_cwa, label=\"Val CWA\")\n        plt.plot(epochs, val_swa, label=\"Val SWA\")\n        plt.plot(epochs, val_cswa, label=\"Val CSWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(f\"{dset_name} \u2013 Accuracy Metrics over Epochs\")\n        plt.legend()\n        fname = f\"{dset_name}_accuracy_curves.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot for {dset_name}: {e}\")\n        plt.close()\n\n    # --------------- Plot 3: bar chart of final test metrics ------------- #\n    try:\n        plt.figure()\n        test_metrics = val_entries[-1] if val_entries else {}\n        labels = [\"Acc\", \"CWA\", \"SWA\", \"CSWA\"]\n        values = [\n            test_metrics.get(\"acc\", 0),\n            test_metrics.get(\"CWA\", 0),\n            test_metrics.get(\"SWA\", 0),\n            test_metrics.get(\"CSWA\", 0),\n        ]\n        plt.bar(\n            labels, values, color=[\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\"]\n        )\n        plt.ylim(0, 1)\n        plt.title(f\"{dset_name} \u2013 Final Validation Metrics\")\n        fname = f\"{dset_name}_final_metrics.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric bar plot for {dset_name}: {e}\")\n        plt.close()\n\n    # ---------------------------- Print summary -------------------------- #\n    best_epoch = log.get(\"best_epoch\", \"n/a\")\n    print(f\"{dset_name} best epoch: {best_epoch}\")\n    if log[\"metrics\"][\"val\"]:\n        best_vals = log[\"metrics\"][\"val\"][\n            best_epoch - 1 if isinstance(best_epoch, int) else -1\n        ]\n        print(\n            f\"  Validation Acc: {best_vals.get('acc', np.nan):.3f}  \"\n            f\"CWA: {best_vals.get('CWA', np.nan):.3f}  \"\n            f\"SWA: {best_vals.get('SWA', np.nan):.3f}  \"\n            f\"CSWA: {best_vals.get('CSWA', np.nan):.3f}\"\n        )\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------\n# load experiment data\n# ------------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ned = experiment_data.get(\"SPR_BENCH\", {})\nif not ed:\n    print(\"No SPR_BENCH data found.\")\n    exit()\n\nepochs = list(range(1, len(ed[\"losses\"][\"train\"]) + 1))\ntrain_loss = ed[\"losses\"][\"train\"]\nval_loss = ed[\"losses\"][\"val\"]\ntrain_acc = [m[\"acc\"] for m in ed[\"metrics\"][\"train\"]]\nval_acc = [m[\"acc\"] for m in ed[\"metrics\"][\"val\"]]\nval_cswa = [m[\"CSWA\"] for m in ed[\"metrics\"][\"val\"]]\n\n# ------------------------------------------------------------\n# 1) Loss curves\n# ------------------------------------------------------------\ntry:\n    plt.figure()\n    plt.plot(epochs, train_loss, label=\"Train\")\n    plt.plot(epochs, val_loss, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-entropy loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curve.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------\n# 2) Accuracy curves\n# ------------------------------------------------------------\ntry:\n    plt.figure()\n    plt.plot(epochs, train_acc, label=\"Train\")\n    plt.plot(epochs, val_acc, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"SPR_BENCH: Training vs Validation Accuracy\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_accuracy_curve.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy curve: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------\n# 3) CSWA score\n# ------------------------------------------------------------\ntry:\n    plt.figure()\n    plt.plot(epochs, val_cswa, marker=\"o\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CSWA\")\n    plt.title(\"SPR_BENCH: Validation CSWA Over Epochs\")\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_CSWA_curve.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CSWA curve: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------\n# 4) Confusion matrix on test set\n# ------------------------------------------------------------\ntry:\n    preds = np.array(ed.get(\"predictions\", []))\n    gts = np.array(ed.get(\"ground_truth\", []))\n    n_cls = int(max(preds.max(), gts.max()) + 1) if preds.size else 0\n    if n_cls > 0:\n        cm = np.zeros((n_cls, n_cls), dtype=int)\n        for p, g in zip(preds, gts):\n            cm[g, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\"SPR_BENCH: Confusion Matrix (Test Set)\")\n        plt.xticks(range(n_cls))\n        plt.yticks(range(n_cls))\n        for i in range(n_cls):\n            for j in range(n_cls):\n                plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\nprint(f\"All plots saved to {working_dir}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# ---------- helpers ----------\ndef colour_of(tok):\n    return tok[1:] if len(tok) > 1 else \"\"\n\n\ndef shape_of(tok):\n    return tok[0]\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [len(set(colour_of(t) for t in s.split())) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [len(set(shape_of(t) for t in s.split())) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef cswa(seqs, y_true, y_pred):\n    w = [\n        len(set(colour_of(t) for t in s.split()))\n        + len(set(shape_of(t) for t in s.split()))\n        for s in seqs\n    ]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nfor dset, d in experiment_data.items():\n    epochs = range(1, len(d[\"losses\"][\"train\"]) + 1)\n\n    # --------- Loss curve ---------\n    try:\n        plt.figure()\n        plt.plot(epochs, d[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(epochs, d[\"losses\"][\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dset} \u2013 Loss Curves\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dset}_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {dset}: {e}\")\n        plt.close()\n\n    # --------- Accuracy curve ---------\n    try:\n        tr_acc = [m[\"acc\"] for m in d[\"metrics\"][\"train\"]]\n        val_acc = [m[\"acc\"] for m in d[\"metrics\"][\"val\"]]\n        plt.figure()\n        plt.plot(epochs, tr_acc, label=\"Train\")\n        plt.plot(epochs, val_acc, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(f\"{dset} \u2013 Accuracy Curves\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dset}_accuracy_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy curve for {dset}: {e}\")\n        plt.close()\n\n    # --------- Structural metrics curve ---------\n    try:\n        cwa_vals = [m[\"CWA\"] for m in d[\"metrics\"][\"val\"]]\n        swa_vals = [m[\"SWA\"] for m in d[\"metrics\"][\"val\"]]\n        cswa_vals = [m[\"CSWA\"] for m in d[\"metrics\"][\"val\"]]\n        plt.figure()\n        plt.plot(epochs, cwa_vals, label=\"CWA\")\n        plt.plot(epochs, swa_vals, label=\"SWA\")\n        plt.plot(epochs, cswa_vals, label=\"CSWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.title(f\"{dset} \u2013 Structural Metrics (Validation)\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dset}_struct_metrics_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating structural metrics curve for {dset}: {e}\")\n        plt.close()\n\n    # --------- Confusion matrix (test) ---------\n    try:\n        y_pred = np.array(d[\"predictions\"])\n        y_true = np.array(d[\"ground_truth\"])\n        if y_pred.size and y_true.size:\n            cm = np.zeros((2, 2), dtype=int)\n            for t, p in zip(y_true, y_pred):\n                cm[t, p] += 1\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            for i in range(2):\n                for j in range(2):\n                    plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(f\"{dset} \u2013 Confusion Matrix (Test)\")\n            fname = os.path.join(working_dir, f\"{dset}_confusion_matrix.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dset}: {e}\")\n        plt.close()\n\n    # --------- Print final test metrics ---------\n    try:\n        if y_pred.size and y_true.size:\n            acc = (y_pred == y_true).mean()\n            cwa_ = cwa(d[\"sequences\"], y_true.tolist(), y_pred.tolist())\n            swa_ = swa(d[\"sequences\"], y_true.tolist(), y_pred.tolist())\n            cswa_ = cswa(d[\"sequences\"], y_true.tolist(), y_pred.tolist())\n            print(\n                f\"{dset} TEST  Acc:{acc:.3f}  CWA:{cwa_:.3f}  SWA:{swa_:.3f}  CSWA:{cswa_:.3f}\"\n            )\n    except Exception as e:\n        print(f\"Error computing test metrics for {dset}: {e}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- setup ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\n\n# ---------- helper for CoWA ----------\ndef colour_of(token: str) -> str:\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    return token[0]\n\n\ndef complexity_weight(seq: str) -> int:\n    return len({colour_of(t) for t in seq.split() if t}) + len(\n        {shape_of(t) for t in seq.split() if t}\n    )\n\n\n# ---------- per-dataset plots ----------\ndatasets = list(experiment_data.keys()) if experiment_data else []\nfor ds_name in datasets:\n    ds = experiment_data[ds_name]\n    # ---- extract series ----\n    epochs = np.arange(1, len(ds[\"losses\"][\"train\"]) + 1)\n    train_loss = ds[\"losses\"][\"train\"]\n    val_loss = ds[\"losses\"][\"val\"]\n    train_acc = [m[\"acc\"] for m in ds[\"metrics\"][\"train\"]]\n    val_acc = [m[\"acc\"] for m in ds[\"metrics\"][\"val\"]]\n    val_cwa = [\n        m[\"CompWA\"] if \"CompWA\" in m else m.get(\"cowa\", np.nan)\n        for m in ds[\"metrics\"][\"val\"]\n    ]\n\n    # 1) Loss curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"{ds_name} Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds_name}: {e}\")\n        plt.close()\n\n    # 2) Accuracy curve ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_acc, label=\"Train\")\n        plt.plot(epochs, val_acc, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(f\"{ds_name} Accuracy Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_accuracy_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot for {ds_name}: {e}\")\n        plt.close()\n\n    # 3) CoWA curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, label=\"Validation CoWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(f\"{ds_name} CoWA Curve\\nValidation Set Only\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_cowa_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CoWA plot for {ds_name}: {e}\")\n        plt.close()\n\n    # ---- evaluation metrics ----\n    try:\n        preds = np.array(ds[\"predictions\"])\n        gts = np.array(ds[\"ground_truth\"])\n        seqs = np.array(ds[\"sequences\"])\n\n        test_acc = (preds == gts).mean()\n        weights = np.array([complexity_weight(s) for s in seqs])\n        cowa = (weights * (preds == gts)).sum() / weights.sum()\n        print(f\"{ds_name} \u2013 Test Accuracy: {test_acc:.3f} | Test CoWA: {cowa:.3f}\")\n    except Exception as e:\n        print(f\"Error computing metrics for {ds_name}: {e}\")\n\n# ---------- comparison plots across datasets (if >1) ----------\nif len(datasets) > 1:\n    # Validation loss comparison\n    try:\n        plt.figure()\n        for ds_name in datasets:\n            val_loss = experiment_data[ds_name][\"losses\"][\"val\"]\n            plt.plot(np.arange(1, len(val_loss) + 1), val_loss, label=f\"{ds_name} Val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Loss\")\n        plt.title(\"Validation Loss Comparison Across Datasets\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_val_loss.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison loss plot: {e}\")\n        plt.close()\n\n    # Validation accuracy comparison\n    try:\n        plt.figure()\n        for ds_name in datasets:\n            val_acc = [m[\"acc\"] for m in experiment_data[ds_name][\"metrics\"][\"val\"]]\n            plt.plot(np.arange(1, len(val_acc) + 1), val_acc, label=f\"{ds_name} Val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Accuracy\")\n        plt.title(\"Validation Accuracy Comparison Across Datasets\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_val_accuracy.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison accuracy plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- setup ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\n\n# ---------- helper for CoWA ----------\ndef colour_of(token: str) -> str:\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    return token[0]\n\n\ndef complexity_weight(seq: str) -> int:\n    return len({colour_of(t) for t in seq.split() if t}) + len(\n        {shape_of(t) for t in seq.split() if t}\n    )\n\n\n# ---------- per-dataset plots ----------\ndatasets = list(experiment_data.keys()) if experiment_data else []\nfor ds_name in datasets:\n    ds = experiment_data[ds_name]\n    # ---- extract series ----\n    epochs = np.arange(1, len(ds[\"losses\"][\"train\"]) + 1)\n    train_loss = ds[\"losses\"][\"train\"]\n    val_loss = ds[\"losses\"][\"val\"]\n    train_acc = [m[\"acc\"] for m in ds[\"metrics\"][\"train\"]]\n    val_acc = [m[\"acc\"] for m in ds[\"metrics\"][\"val\"]]\n    val_cwa = [\n        m[\"CompWA\"] if \"CompWA\" in m else m.get(\"cowa\", np.nan)\n        for m in ds[\"metrics\"][\"val\"]\n    ]\n\n    # 1) Loss curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"{ds_name} Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds_name}: {e}\")\n        plt.close()\n\n    # 2) Accuracy curve ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_acc, label=\"Train\")\n        plt.plot(epochs, val_acc, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(f\"{ds_name} Accuracy Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_accuracy_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot for {ds_name}: {e}\")\n        plt.close()\n\n    # 3) CoWA curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, label=\"Validation CoWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(f\"{ds_name} CoWA Curve\\nValidation Set Only\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_cowa_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CoWA plot for {ds_name}: {e}\")\n        plt.close()\n\n    # ---- evaluation metrics ----\n    try:\n        preds = np.array(ds[\"predictions\"])\n        gts = np.array(ds[\"ground_truth\"])\n        seqs = np.array(ds[\"sequences\"])\n\n        test_acc = (preds == gts).mean()\n        weights = np.array([complexity_weight(s) for s in seqs])\n        cowa = (weights * (preds == gts)).sum() / weights.sum()\n        print(f\"{ds_name} \u2013 Test Accuracy: {test_acc:.3f} | Test CoWA: {cowa:.3f}\")\n    except Exception as e:\n        print(f\"Error computing metrics for {ds_name}: {e}\")\n\n# ---------- comparison plots across datasets (if >1) ----------\nif len(datasets) > 1:\n    # Validation loss comparison\n    try:\n        plt.figure()\n        for ds_name in datasets:\n            val_loss = experiment_data[ds_name][\"losses\"][\"val\"]\n            plt.plot(np.arange(1, len(val_loss) + 1), val_loss, label=f\"{ds_name} Val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Loss\")\n        plt.title(\"Validation Loss Comparison Across Datasets\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_val_loss.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison loss plot: {e}\")\n        plt.close()\n\n    # Validation accuracy comparison\n    try:\n        plt.figure()\n        for ds_name in datasets:\n            val_acc = [m[\"acc\"] for m in experiment_data[ds_name][\"metrics\"][\"val\"]]\n            plt.plot(np.arange(1, len(val_acc) + 1), val_acc, label=f\"{ds_name} Val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Accuracy\")\n        plt.title(\"Validation Accuracy Comparison Across Datasets\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_val_accuracy.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison accuracy plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- setup ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\n\n# ---------- helper for CoWA ----------\ndef colour_of(token: str) -> str:\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    return token[0]\n\n\ndef complexity_weight(seq: str) -> int:\n    return len({colour_of(t) for t in seq.split() if t}) + len(\n        {shape_of(t) for t in seq.split() if t}\n    )\n\n\n# ---------- per-dataset plots ----------\ndatasets = list(experiment_data.keys()) if experiment_data else []\nfor ds_name in datasets:\n    ds = experiment_data[ds_name]\n    # ---- extract series ----\n    epochs = np.arange(1, len(ds[\"losses\"][\"train\"]) + 1)\n    train_loss = ds[\"losses\"][\"train\"]\n    val_loss = ds[\"losses\"][\"val\"]\n    train_acc = [m[\"acc\"] for m in ds[\"metrics\"][\"train\"]]\n    val_acc = [m[\"acc\"] for m in ds[\"metrics\"][\"val\"]]\n    val_cwa = [\n        m[\"CompWA\"] if \"CompWA\" in m else m.get(\"cowa\", np.nan)\n        for m in ds[\"metrics\"][\"val\"]\n    ]\n\n    # 1) Loss curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"{ds_name} Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds_name}: {e}\")\n        plt.close()\n\n    # 2) Accuracy curve ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_acc, label=\"Train\")\n        plt.plot(epochs, val_acc, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(f\"{ds_name} Accuracy Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_accuracy_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot for {ds_name}: {e}\")\n        plt.close()\n\n    # 3) CoWA curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, label=\"Validation CoWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(f\"{ds_name} CoWA Curve\\nValidation Set Only\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_cowa_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CoWA plot for {ds_name}: {e}\")\n        plt.close()\n\n    # ---- evaluation metrics ----\n    try:\n        preds = np.array(ds[\"predictions\"])\n        gts = np.array(ds[\"ground_truth\"])\n        seqs = np.array(ds[\"sequences\"])\n\n        test_acc = (preds == gts).mean()\n        weights = np.array([complexity_weight(s) for s in seqs])\n        cowa = (weights * (preds == gts)).sum() / weights.sum()\n        print(f\"{ds_name} \u2013 Test Accuracy: {test_acc:.3f} | Test CoWA: {cowa:.3f}\")\n    except Exception as e:\n        print(f\"Error computing metrics for {ds_name}: {e}\")\n\n# ---------- comparison plots across datasets (if >1) ----------\nif len(datasets) > 1:\n    # Validation loss comparison\n    try:\n        plt.figure()\n        for ds_name in datasets:\n            val_loss = experiment_data[ds_name][\"losses\"][\"val\"]\n            plt.plot(np.arange(1, len(val_loss) + 1), val_loss, label=f\"{ds_name} Val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Loss\")\n        plt.title(\"Validation Loss Comparison Across Datasets\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_val_loss.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison loss plot: {e}\")\n        plt.close()\n\n    # Validation accuracy comparison\n    try:\n        plt.figure()\n        for ds_name in datasets:\n            val_acc = [m[\"acc\"] for m in experiment_data[ds_name][\"metrics\"][\"val\"]]\n            plt.plot(np.arange(1, len(val_acc) + 1), val_acc, label=f\"{ds_name} Val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Accuracy\")\n        plt.title(\"Validation Accuracy Comparison Across Datasets\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_val_accuracy.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison accuracy plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- setup ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- experiment paths ----------\nexperiment_data_path_list = [\n    \"experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_863792e89e9e451dbfeaecbfe4806c82_proc_1497844/experiment_data.npy\",\n    \"experiments/2025-08-30_20-55-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_89b651abfe2a4cbeb2399c07a6e7da71_proc_1497846/experiment_data.npy\",\n]\n\nall_experiment_data = []\nfor p in experiment_data_path_list:\n    try:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p)\n        exp = np.load(full_path, allow_pickle=True).item()\n        all_experiment_data.append(exp)\n    except Exception as e:\n        print(f\"Error loading {p}: {e}\")\n\n\n# ---------- helper for CoWA ----------\ndef colour_of(token: str) -> str:\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    return token[0]\n\n\ndef complexity_weight(seq: str) -> int:\n    return len({colour_of(t) for t in seq.split() if t}) + len(\n        {shape_of(t) for t in seq.split() if t}\n    )\n\n\n# ---------- aggregate by dataset ----------\ndataset_runs = {}\nfor exp in all_experiment_data:\n    for ds_name, ds_val in exp.items():\n        dataset_runs.setdefault(ds_name, []).append(ds_val)\n\nfor ds_name, runs in dataset_runs.items():\n    # --------- aggregate time-series ----------\n    # Align to shortest run length so shapes match\n    min_len = min(len(r[\"losses\"][\"train\"]) for r in runs)\n    n_runs = len(runs)\n\n    def stack(metric_getter):\n        arr = np.stack([metric_getter(r)[:min_len] for r in runs])\n        mean = arr.mean(axis=0)\n        se = arr.std(axis=0, ddof=1) / np.sqrt(n_runs) if n_runs > 1 else None\n        return mean, se\n\n    epochs = np.arange(1, min_len + 1)\n    train_loss_mean, train_loss_se = stack(lambda r: np.array(r[\"losses\"][\"train\"]))\n    val_loss_mean, val_loss_se = stack(lambda r: np.array(r[\"losses\"][\"val\"]))\n    train_acc_mean, train_acc_se = stack(\n        lambda r: np.array([m[\"acc\"] for m in r[\"metrics\"][\"train\"]])\n    )\n    val_acc_mean, val_acc_se = stack(\n        lambda r: np.array([m[\"acc\"] for m in r[\"metrics\"][\"val\"]])\n    )\n    val_cwa_mean, val_cwa_se = stack(\n        lambda r: np.array(\n            [\n                m[\"CompWA\"] if \"CompWA\" in m else m.get(\"cowa\", np.nan)\n                for m in r[\"metrics\"][\"val\"]\n            ]\n        )\n    )\n\n    # --------- plotting helpers ----------\n    def plot_with_band(x, mean, se, label, color):\n        plt.plot(x, mean, label=label, color=color)\n        if se is not None:\n            plt.fill_between(\n                x,\n                mean - 1.96 * se,\n                mean + 1.96 * se,\n                color=color,\n                alpha=0.25,\n                linewidth=0,\n                label=f\"{label} \u00b195% CI\",\n            )\n\n    # 1) Loss curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plot_with_band(epochs, train_loss_mean, train_loss_se, \"Train\", \"tab:blue\")\n        plot_with_band(epochs, val_loss_mean, val_loss_se, \"Validation\", \"tab:orange\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"{ds_name} Aggregated Loss Curves\\nMean \u00b1 95% CI, n={n_runs}\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_agg_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated loss plot for {ds_name}: {e}\")\n        plt.close()\n\n    # 2) Accuracy curve -----------------------------------------------\n    try:\n        plt.figure()\n        plot_with_band(epochs, train_acc_mean, train_acc_se, \"Train\", \"tab:blue\")\n        plot_with_band(epochs, val_acc_mean, val_acc_se, \"Validation\", \"tab:orange\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(f\"{ds_name} Aggregated Accuracy Curves\\nMean \u00b1 95% CI, n={n_runs}\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_agg_accuracy_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated accuracy plot for {ds_name}: {e}\")\n        plt.close()\n\n    # 3) CoWA curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plot_with_band(epochs, val_cwa_mean, val_cwa_se, \"Validation CoWA\", \"tab:green\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(f\"{ds_name} Aggregated CoWA Curve\\nMean \u00b1 95% CI, n={n_runs}\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_agg_cowa_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated CoWA plot for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- aggregated final test metrics ----------\n    acc_list, cowa_list = [], []\n    for r in runs:\n        preds = np.array(r[\"predictions\"])\n        gts = np.array(r[\"ground_truth\"])\n        seqs = np.array(r[\"sequences\"])\n        weights = np.array([complexity_weight(s) for s in seqs])\n        acc_list.append((preds == gts).mean())\n        cowa_list.append((weights * (preds == gts)).sum() / weights.sum())\n\n    acc_arr, cowa_arr = np.array(acc_list), np.array(cowa_list)\n    print(\n        f\"{ds_name}: Test Accuracy {acc_arr.mean():.3f} \u00b1 {acc_arr.std(ddof=1):.3f} | \"\n        f\"Test CoWA {cowa_arr.mean():.3f} \u00b1 {cowa_arr.std(ddof=1):.3f} (n={n_runs})\"\n    )\n"], "plot_plan": ["We will load the stored experiment_data.npy, detect all available datasets, and for each one extract epoch-wise training/validation loss, accuracy and complexity-weighted accuracy (CoWA). Three standard plots are produced per dataset: loss curve, accuracy curve and CoWA curve, each wrapped in its own try-except block to guarantee figure closure and fault tolerance. If multiple datasets are present, extra comparison plots (loss and accuracy) overlay the validation curves of all datasets using distinct colours. All figures are titled clearly, saved to the working directory with descriptive names, and closed after saving. For evaluation, final test accuracy and CoWA are recomputed from the saved predictions, ground-truth labels and sequences, then printed. Only data contained in experiment_data.npy are used and no additional values are fabricated. A maximum of one figure per plot type is produced, keeping the total below five similar images. The code starts with the required imports and path set-up and follows the plotting guidelines exactly. Finally, figures are saved and metrics printed.", "We will load experiment_data.npy, extract the \u201cNoPosEmb \u2192 SPR_BENCH\u201d bookkeeping dict, and pull out (i) per-epoch train/val losses, (ii) per-epoch train/val accuracy, (iii) per-epoch validation Complexity-Weighted Accuracy, and (iv) final test predictions & ground-truth.  Three line plots will be produced: loss curves, accuracy curves, and CompWA curves, each in its own try\u2013except block, titled clearly and saved to working_dir with descriptive names.  A fourth plot will show the 2 \u00d7 2 confusion-matrix heatmap derived from the stored test predictions; if anything fails, the code will print the error but still close the figure.  Every figure is closed after saving, and we plot at most once per data type (so only 4 figures total, <5).  The script finishes by printing the best validation epoch and final test metrics that are present in the data.  All plotting relies solely on arrays found inside experiment_data.npy\u2014no fabricated values or external styling.  The code is concise and self-contained, using only matplotlib, numpy, and the os module mandated.", "We first load experiment_data.npy from the working directory and safely convert it back to a Python dict. For every experiment (FULL and SEQ_ONLY) we extract losses and accuracies for the train/validation splits, as well as the final test metrics stored in experiment_data[exp]['SPR_BENCH']['metrics']['test']. We then produce four concise plots, each wrapped in its own try-except so that one failure does not stop subsequent visualizations. Plot-1 shows training vs validation loss across epochs for both experiments; Plot-2 overlays training vs validation accuracy; Plot-3 is a grouped bar chart comparing final test accuracy; Plot-4 does the same for final complexity-weighted accuracy. All figures carry explicit titles that mention the dataset (SPR_BENCH) and the content of the plot, and we save them with descriptive filenames inside working_dir. Figures are always closed, and we also print a short textual summary of the final test metrics to stdout. This satisfies the requirement to plot only existing data, to limit the number of figures, and to keep the code compact and self-contained.", null, "We will load experiment_data.npy, grab the \u201cno_batch_norm / SPR_BENCH\u201d entry, and extract (i) train/val loss lists, (ii) train/val accuracy lists, (iii) validation CompWA values, (iv) the saved ground-truth and prediction arrays as well as final test metrics.  Four independent try-except blocks will create at most four figures: (1) loss curves, (2) accuracy curves, (3) CompWA curve, and (4) a 2 \u00d7 2 heat-map style confusion matrix for the test set.  Every plot will have a clear title and be saved to working_dir with descriptive names that include the dataset and plot type.  Figures are always closed, even after exceptions, to avoid memory leaks.  We rely strictly on the data contained in experiment_data.npy, never generating synthetic values, and only plot at epoch resolution as already stored (generally \u2264 40, well within the 5-figure limit).  After plotting, the script prints the test accuracy and CompWA that it just visualised so users can verify numbers in the terminal.  Basic Matplotlib is used without external styling or extra dependencies, and the code is concise while obeying the required header imports and saving path conventions.  All steps are wrapped in defensive loading checks to ensure robustness when the file is missing or corrupted.", "We will first load experiment_data.npy and work within the prescribed working directory. For each dataset stored (only SPR_BENCH here) we extract the series of training / validation losses and accuracies that were logged during training. We then create separate figures for: (1) loss curves and (2) accuracy curves (plain accuracy plus colour-, shape- and combined-weighted variants); each figure is wrapped in its own try-except block to guarantee robustness and proper closure. If confusion-matrix\u2013style information is available we add at most one extra bar plot comparing the four test accuracies, yielding no more than the allowed five plots. Every figure is given an informative title that clearly states the dataset and the plot type, and files are saved with similarly descriptive names in working_dir. Finally, after plotting, we print the final (test) evaluation metrics that are stored in the bookkeeping dictionary. No data are fabricated; everything comes directly from experiment_data.npy. All figures are closed after saving to avoid memory leaks.", null, "We will load experiment_data.npy, extract the SPR_BENCH entry, and retrieve per-epoch losses, accuracies and CSWA scores together with test predictions/ground-truth. Four concise plots will be generated: (1) training vs validation loss, (2) training vs validation accuracy, (3) validation CSWA, and (4) a confusion matrix on the test set. Each plot is wrapped in its own try-except block to guarantee figures are closed even on errors, and the filenames clearly encode dataset and plot type. We limit ourselves to basic matplotlib, produce no more than the required four figures, and save everything into the prescribed working directory. Finally, we print the location of the saved figures so downstream code can verify their existence.", "We will first load experiment_data.npy from the working directory and iterate over every dataset entry (here only \u201cSPR_BENCH\u201d).  \nFor each dataset we extract the per-epoch train/val losses and accuracies that were stored during training and plot them in two separate figures: a loss curve and an accuracy curve.  \nBecause the validation metrics dictionary also contains CWA, SWA and CSWA, we additionally plot these three curves together against epoch to visualise structural-weighted performance.  \nNext, using the saved test-set sequences, predictions and ground-truth labels we recompute final test metrics (ACC, CWA, SWA, CSWA) and print them to stdout.  \nWe include a simple 2\u00d72 confusion-matrix heat-map for the binary classification task; this is built directly from the saved predictions without external libraries.  \nEvery figure is wrapped in a try-except block, given a descriptive title, saved into the working directory with the dataset and plot type in the filename, and the figure is always closed afterwards.  \nOnly data found inside experiment_data.npy is accessed\u2014no values are fabricated, and no more than four figures are produced in total.", null, null, null, null], "ablation_name": [null, "No-Positional-Embedding", "Sequential-Only-Graph", "No-Self-Loop Graph", "No-Batch-Normalization", null, null, null, null, null, null, null, null], "hyperparam_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["The script will load the saved NumPy dictionary from the working directory,\nidentify each dataset entry (e.g., \u201cSPR_BENCH\u201d), and then extract the final\ntraining metrics, the best-epoch validation metrics, and the overall test\nmetrics. It re-computes test accuracy and complexity-weighted accuracy from the\nstored predictions, ground-truth labels, and sequences. Finally, it prints each\nmetric with an explicit, descriptive name, preceded by the dataset name.", "The script will locate the saved experiment_data.npy file in the \u201cworking\u201d\ndirectory, load it as a Python dictionary, and iterate through every experiment\nand dataset it contains. For each dataset (e.g., \u201cSPR_BENCH\u201d) it will (1) read\nthe stored training/validation loss lists to obtain the final (last-epoch)\nlosses, (2) read the training/validation metric lists to extract the final\naccuracies, (3) report the epoch that was marked best during training, and (4)\ncompute test-set accuracy and complexity-weighted accuracy directly from the\nsaved predictions, ground-truth labels, and sequences. Each piece of information\nis printed with an explicit, self-descriptive label, and no figures are\ngenerated.", "The solution loads the saved NumPy file from the prescribed working directory,\niterates through every experiment (FULL and SEQ_ONLY) and the contained dataset\n(SPR_BENCH), extracts the relevant metrics, determines the best validation epoch\nrecorded by the training script, and finally prints the requested summary using\nexplicit metric names (train accuracy, validation loss, etc.).  Only the last\nrecorded training values, the best-epoch validation values, and the stored test\nvalues are reported.  All code is placed at global scope so it executes\nimmediately when run.", "The script will load the saved NumPy dictionary, walk through all stored\nexperiment \u2192 dataset combinations, grab the last (i.e., final) entry for every\ntracked quantity, compute test-set statistics from the stored\npredictions/ground-truth, and then print everything with explicit metric names.\nAll code lives at the top level so the file runs immediately when executed.", "The script loads the saved NumPy dictionary, drills down through every\nexperiment and dataset, and extracts the last training metrics, the best\n(minimum-loss) validation metrics, and the single stored test metrics. It then\nprints them in a clear, label-first format, always starting with the dataset\nname. No plots or special entry points are used\u2014execution happens immediately\nwhen the file is run.", "The script loads experiment_data.npy from the working directory, locates the\nbest epoch stored during training for every dataset, and then prints the most\nrelevant metrics (losses, standard accuracy, and the three weighted accuracies)\ncorresponding to that epoch. If the best epoch is not recorded, it defaults to\nthe last available epoch. All metrics are printed with explicit, descriptive\nnames as required.", "The script below loads the saved experiment data, selects the final training\nmetrics and the best-epoch validation metrics for each stored experiment, and\nprints them with explicit, readable labels. It runs immediately on execution and\nrespects the required structural constraints.", "We will load the NumPy file from the working directory, locate the stored\ndictionary, and for every dataset entry extract the final\u2010epoch training\nloss/accuracy, the best (lowest-loss) validation metrics, and the test metrics\nthat can be recomputed from the saved predictions, ground\u2013truth labels, and\nsequences (for CSWA). The script recreates the colour/shape helper functions so\nCSWA can be calculated, then prints every metric with an explicit, human-\nreadable name as required.", "The script will load the saved NumPy file from the working directory, recover\nthe nested dictionaries, pick the last-epoch training metrics, pick the best-\nepoch validation metrics (using the stored `best_epoch` field), and recompute\ntest-set metrics from the stored predictions/ground-truth. Everything is printed\nwith explicit metric names, and the code executes immediately without any\nspecial entry point.", "The script will load the saved NumPy dictionary from the working directory,\nidentify each dataset entry (e.g., \u201cSPR_BENCH\u201d), and then extract the final\ntraining metrics, the best-epoch validation metrics, and the overall test\nmetrics. It re-computes test accuracy and complexity-weighted accuracy from the\nstored predictions, ground-truth labels, and sequences. Finally, it prints each\nmetric with an explicit, descriptive name, preceded by the dataset name.", "The script will load the saved NumPy dictionary from the working directory,\nidentify each dataset entry (e.g., \u201cSPR_BENCH\u201d), and then extract the final\ntraining metrics, the best-epoch validation metrics, and the overall test\nmetrics. It re-computes test accuracy and complexity-weighted accuracy from the\nstored predictions, ground-truth labels, and sequences. Finally, it prints each\nmetric with an explicit, descriptive name, preceded by the dataset name.", "The script will load the saved NumPy dictionary from the working directory,\nidentify each dataset entry (e.g., \u201cSPR_BENCH\u201d), and then extract the final\ntraining metrics, the best-epoch validation metrics, and the overall test\nmetrics. It re-computes test accuracy and complexity-weighted accuracy from the\nstored predictions, ground-truth labels, and sequences. Finally, it prints each\nmetric with an explicit, descriptive name, preceded by the dataset name.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n\n# ----------------------------------------------------------------------\n# Helpers (replicate small parts of training code so we can recompute CWA)\n# ----------------------------------------------------------------------\ndef colour_of(token: str) -> str:\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    return token[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(tok) for tok in seq.split() if tok))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(tok) for tok in seq.split() if tok))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    weights = [complexity_weight(s) for s in seqs]\n    correct_weights = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct_weights) / max(1, sum(weights))\n\n\n# ----------------------------------------------------------------------\n# Load experiment data\n# ----------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ----------------------------------------------------------------------\n# Iterate over datasets and print requested metrics\n# ----------------------------------------------------------------------\nfor dataset_name, data in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # --------------------- training metrics (final epoch) ---------------------\n    final_train_metrics = data[\"metrics\"][\"train\"][-1]\n    final_train_loss = data[\"losses\"][\"train\"][-1]\n    print(f\"training accuracy: {final_train_metrics['acc']:.3f}\")\n    print(f\"training loss: {final_train_loss:.4f}\")\n\n    # --------------------- validation metrics (best epoch) --------------------\n    best_epoch = data.get(\"best_epoch\", final_train_metrics[\"epoch\"])\n    # locate best-epoch entry\n    val_metrics_list = data[\"metrics\"][\"val\"]\n    best_val_entry = next(m for m in val_metrics_list if m[\"epoch\"] == best_epoch)\n    best_val_loss = data[\"losses\"][\"val\"][best_epoch - 1]  # epoch indices start at 1\n    print(f\"validation accuracy (best epoch): {best_val_entry['acc']:.3f}\")\n    print(f\"validation loss (best epoch): {best_val_loss:.4f}\")\n    print(f\"validation CompWA (best epoch): {best_val_entry['CompWA']:.3f}\")\n\n    # --------------------- test metrics (re-computed) -------------------------\n    preds = data.get(\"predictions\", [])\n    gts = data.get(\"ground_truth\", [])\n    seqs = data.get(\"sequences\", [])\n\n    if preds and gts and seqs:\n        test_accuracy = sum(p == g for p, g in zip(preds, gts)) / len(gts)\n        test_compwa = comp_weighted_acc(seqs, gts, preds)\n        print(f\"test accuracy: {test_accuracy:.3f}\")\n        print(f\"test CompWA: {test_compwa:.3f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------- helper for Comp-Weighted Acc ----------\ndef colour_of(tok: str) -> str:\n    return tok[1:] if len(tok) > 1 else \"\"\n\n\ndef shape_of(tok: str) -> str:\n    return tok[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(t) for t in seq.split() if t))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(t) for t in seq.split() if t))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    weights = [complexity_weight(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(1, sum(weights))\n\n\n# ---------- iterate and report ----------\nfor exp_name, datasets in experiment_data.items():\n    for ds_name, book in datasets.items():\n        print(f\"{ds_name}\")  # dataset name\n\n        # final / best training statistics\n        final_train_loss = book[\"losses\"][\"train\"][-1]\n        final_val_loss = book[\"losses\"][\"val\"][-1]\n\n        final_train_acc = book[\"metrics\"][\"train\"][-1][\"acc\"]\n        final_val_metrics = book[\"metrics\"][\"val\"][-1]\n        final_val_acc = final_val_metrics[\"acc\"]\n        final_val_cwa = final_val_metrics.get(\"CompWA\", None)\n\n        best_epoch = book.get(\"best_epoch\", None)\n\n        # test-set metrics (re-compute to be safe)\n        preds = book.get(\"predictions\", [])\n        gts = book.get(\"ground_truth\", [])\n        seqs = book.get(\"sequences\", [])\n        if preds and gts:\n            test_accuracy = sum(p == g for p, g in zip(preds, gts)) / len(gts)\n            test_cwa = comp_weighted_acc(seqs, gts, preds)\n        else:\n            test_accuracy = test_cwa = None\n\n        # ----- printing -----\n        print(f\"train loss: {final_train_loss:.6f}\")\n        print(f\"validation loss: {final_val_loss:.6f}\")\n        print(f\"train accuracy: {final_train_acc:.4f}\")\n        print(f\"validation accuracy: {final_val_acc:.4f}\")\n        if final_val_cwa is not None:\n            print(f\"validation complexity-weighted accuracy: {final_val_cwa:.4f}\")\n        if best_epoch is not None:\n            print(f\"best epoch: {best_epoch}\")\n        if test_accuracy is not None:\n            print(f\"test accuracy: {test_accuracy:.4f}\")\n            print(f\"test complexity-weighted accuracy: {test_cwa:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------- helper for safe indexing ----------\ndef _safe(lst, idx, default=None):\n    try:\n        return lst[idx]\n    except Exception:\n        return default\n\n\n# ---------- iterate and print ----------\nfor exp_name, ds_dict in experiment_data.items():  # exp_name: \"FULL\", \"SEQ_ONLY\"\n    for dataset_name, rec in ds_dict.items():  # dataset_name: \"SPR_BENCH\"\n        header = f\"{exp_name} - {dataset_name}\"\n        print(f\"\\nDataset: {header}\")\n\n        # ---------- bookkeeping ----------\n        train_losses = rec[\"losses\"][\"train\"]\n        val_losses = rec[\"losses\"][\"val\"]\n        train_mets = rec[\"metrics\"][\"train\"]\n        val_mets = rec[\"metrics\"][\"val\"]\n        test_loss = rec[\"losses\"][\"test\"]\n        test_mets = rec[\"metrics\"][\"test\"]\n        best_ep = rec.get(\"best_epoch\", len(val_losses))\n\n        # indices\n        last_idx = len(train_losses) - 1  # final epoch index\n        best_idx = best_ep - 1 if best_ep else last_idx\n\n        # ---------- fetch numbers ----------\n        final_train_loss = _safe(train_losses, last_idx, \"NA\")\n        final_train_acc = _safe(train_mets, last_idx, {}).get(\"acc\", \"NA\")\n\n        best_val_loss = _safe(val_losses, best_idx, \"NA\")\n        best_val_acc = _safe(val_mets, best_idx, {}).get(\"acc\", \"NA\")\n        best_val_compwa = _safe(val_mets, best_idx, {}).get(\"CompWA\", \"NA\")\n\n        # ---------- print ----------\n        print(f\"best epoch: {best_ep}\")\n        print(\n            f\"train loss (final): {final_train_loss:.4f}\"\n            if isinstance(final_train_loss, float)\n            else f\"train loss (final): {final_train_loss}\"\n        )\n        print(\n            f\"train accuracy (final): {final_train_acc:.3f}\"\n            if isinstance(final_train_acc, float)\n            else f\"train accuracy (final): {final_train_acc}\"\n        )\n\n        print(\n            f\"validation loss (best): {best_val_loss:.4f}\"\n            if isinstance(best_val_loss, float)\n            else f\"validation loss (best): {best_val_loss}\"\n        )\n        print(\n            f\"validation accuracy (best): {best_val_acc:.3f}\"\n            if isinstance(best_val_acc, float)\n            else f\"validation accuracy (best): {best_val_acc}\"\n        )\n        print(\n            f\"validation CompWA (best): {best_val_compwa:.3f}\"\n            if isinstance(best_val_compwa, float)\n            else f\"validation CompWA (best): {best_val_compwa}\"\n        )\n\n        print(\n            f\"test loss: {test_loss:.4f}\"\n            if isinstance(test_loss, float)\n            else f\"test loss: {test_loss}\"\n        )\n        print(\n            f\"test accuracy: {test_mets.get('acc', 'NA'):.3f}\"\n            if isinstance(test_mets.get(\"acc\"), float)\n            else f\"test accuracy: {test_mets.get('acc', 'NA')}\"\n        )\n        print(\n            f\"test CompWA: {test_mets.get('CompWA', 'NA'):.3f}\"\n            if isinstance(test_mets.get(\"CompWA\"), float)\n            else f\"test CompWA: {test_mets.get('CompWA', 'NA')}\"\n        )\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------\n# 1.  Locate and load the bookkeeping file\n# ---------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------\n# 2.  Helper for Comp-Weighted Accuracy (copied from original)\n# ---------------------------------------------------------------\ndef colour_of(tok):  # token = e.g. \"A3\"\n    return tok[1:] if len(tok) > 1 else \"\"\n\n\ndef shape_of(tok):\n    return tok[0]\n\n\ndef count_colour_variety(seq):\n    return len(set(colour_of(t) for t in seq.split()))\n\n\ndef count_shape_variety(seq):\n    return len(set(shape_of(t) for t in seq.split()))\n\n\ndef complexity_weight(seq):\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    return sum(wt for wt, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\n# ---------------------------------------------------------------\n# 3.  Extract and print metrics\n# ---------------------------------------------------------------\nfor exp_name, exp_dict in experiment_data.items():  # e.g. \"no_self_loop\"\n    for dataset_name, ds in exp_dict.items():  # e.g. \"SPR_BENCH\"\n        print(dataset_name)  # dataset heading\n\n        # ---- final / best values recorded during training ----\n        train_acc = (\n            ds[\"metrics\"][\"train\"][-1][\"acc\"] if ds[\"metrics\"][\"train\"] else None\n        )\n        val_acc = ds[\"metrics\"][\"val\"][-1][\"acc\"] if ds[\"metrics\"][\"val\"] else None\n        val_cwa = ds[\"metrics\"][\"val\"][-1][\"CompWA\"] if ds[\"metrics\"][\"val\"] else None\n        train_loss = ds[\"losses\"][\"train\"][-1] if ds[\"losses\"][\"train\"] else None\n        val_loss = ds[\"losses\"][\"val\"][-1] if ds[\"losses\"][\"val\"] else None\n\n        # ---- test-set metrics computed from stored predictions ----\n        preds = ds.get(\"predictions\", [])\n        gts = ds.get(\"ground_truth\", [])\n        seqs = ds.get(\"sequences\", [])\n\n        if gts:  # avoid div-by-zero on empty runs\n            test_acc = sum(int(p == g) for p, g in zip(preds, gts)) / len(gts)\n            test_cwa = comp_weighted_acc(seqs, gts, preds)\n        else:  # training might have failed / not run\n            test_acc = test_cwa = None\n\n        # ---- neatly print everything that exists ----\n        if train_acc is not None:\n            print(\"training accuracy:\", f\"{train_acc:.3f}\")\n        if train_loss is not None:\n            print(\"training loss:\", f\"{train_loss:.4f}\")\n        if val_acc is not None:\n            print(\"validation accuracy:\", f\"{val_acc:.3f}\")\n        if val_cwa is not None:\n            print(\"validation CompWA:\", f\"{val_cwa:.3f}\")\n        if val_loss is not None:\n            print(\"validation loss:\", f\"{val_loss:.4f}\")\n        if test_acc is not None:\n            print(\"test accuracy:\", f\"{test_acc:.3f}\")\n        if test_cwa is not None:\n            print(\"test CompWA:\", f\"{test_cwa:.3f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# 0. locate and load the npy file\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# 1. helper to fetch best validation index (lowest loss)\ndef _best_val_idx(loss_list):\n    if not loss_list:\n        return None\n    return int(np.argmin(loss_list))\n\n\n# ---------------------------------------------------------------------\n# 2. iterate and print\nfor exp_name, datasets in experiment_data.items():\n    for ds_name, ds_dict in datasets.items():\n        print(f\"Dataset: {ds_name}\")\n\n        # --- training ---\n        tr_losses = ds_dict[\"losses\"].get(\"train\", [])\n        tr_accs = [m[\"acc\"] for m in ds_dict[\"metrics\"].get(\"train\", [])]\n        if tr_losses:\n            print(\"final training loss:\", tr_losses[-1])\n        if tr_accs:\n            print(\"final training accuracy:\", tr_accs[-1])\n\n        # --- validation ---\n        val_losses = ds_dict[\"losses\"].get(\"val\", [])\n        val_metrics = ds_dict[\"metrics\"].get(\"val\", [])\n        best_idx = _best_val_idx(val_losses)\n        if best_idx is not None:\n            best_val_loss = val_losses[best_idx]\n            best_val_acc = val_metrics[best_idx][\"acc\"]\n            best_val_cwa = val_metrics[best_idx][\"CompWA\"]\n            print(\"best validation loss:\", best_val_loss)\n            print(\"best validation accuracy:\", best_val_acc)\n            print(\"best validation complexity weighted accuracy:\", best_val_cwa)\n\n        # --- test ---\n        test_loss = ds_dict[\"losses\"].get(\"test\")\n        test_mets = ds_dict[\"metrics\"].get(\"test\", {})\n        if test_loss is not None:\n            print(\"test loss:\", test_loss)\n        if test_mets:\n            if \"acc\" in test_mets:\n                print(\"test accuracy:\", test_mets[\"acc\"])\n            if \"CompWA\" in test_mets:\n                print(\"test complexity weighted accuracy:\", test_mets[\"CompWA\"])\n\n        # separator for readability\n        print()\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------------- #\n# 0. Locate and load the bookkeeping file\n# --------------------------------------------------------------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# --------------------------------------------------------------------------- #\n# 1. Traverse every stored dataset and print its key metrics\n# --------------------------------------------------------------------------- #\nfor dataset_name, ds in experiment_data.items():\n    print(dataset_name)  # dataset heading\n\n    # Determine which epoch to report (prefer the recorded best)\n    if ds.get(\"best_epoch\") is not None:\n        best_idx = ds[\"best_epoch\"] - 1  # epochs are 1-based, Python lists 0-based\n    else:\n        # fallback: use the final epoch stored\n        best_idx = len(ds[\"metrics\"][\"train\"]) - 1\n\n    # Safe extraction helpers -------------------------------------------------\n    def safe(lst, idx, key, default=None):\n        try:\n            return lst[idx].get(key, default)\n        except (IndexError, AttributeError):\n            return default\n\n    # Losses\n    train_loss = safe([{\"loss\": v} for v in ds[\"losses\"][\"train\"]], best_idx, \"loss\")\n    val_loss = safe([{\"loss\": v} for v in ds[\"losses\"][\"val\"]], best_idx, \"loss\")\n\n    # Training metrics\n    train_acc = safe(ds[\"metrics\"][\"train\"], best_idx, \"acc\")\n\n    # Validation metrics\n    val_acc = safe(ds[\"metrics\"][\"val\"], best_idx, \"acc\")\n    val_cwa = safe(ds[\"metrics\"][\"val\"], best_idx, \"CWA\")\n    val_swa = safe(ds[\"metrics\"][\"val\"], best_idx, \"SWA\")\n    val_cswa = safe(ds[\"metrics\"][\"val\"], best_idx, \"CSWA\")\n\n    # Print results with explicit labels -------------------------------------\n    if train_loss is not None:\n        print(f\"training loss: {train_loss:.4f}\")\n    if train_acc is not None:\n        print(f\"training accuracy: {train_acc:.3f}\")\n\n    if val_loss is not None:\n        print(f\"validation loss: {val_loss:.4f}\")\n    if val_acc is not None:\n        print(f\"validation accuracy: {val_acc:.3f}\")\n    if val_cwa is not None:\n        print(f\"validation colour-weighted accuracy: {val_cwa:.3f}\")\n    if val_swa is not None:\n        print(f\"validation shape-weighted accuracy: {val_swa:.3f}\")\n    if val_cswa is not None:\n        print(f\"validation combined-score weighted accuracy: {val_cswa:.3f}\")\n\n    # A blank line between datasets for readability\n    print()\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 0. Locate and load the experiment_data.npy file\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# 1. Helper to fetch best-epoch validation indices safely\n# ------------------------------------------------------------------\ndef get_best_index(best_epoch, fallback_length):\n    \"\"\"\n    Convert the recorded best_epoch (1-based) to a list index (0-based).\n    Falls back to the last element if best_epoch is missing or invalid.\n    \"\"\"\n    if isinstance(best_epoch, int) and 1 <= best_epoch <= fallback_length:\n        return best_epoch - 1\n    return fallback_length - 1\n\n\n# ------------------------------------------------------------------\n# 2. Iterate over each stored experiment and print metrics\n# ------------------------------------------------------------------\nfor exp_name, exp_data in experiment_data.items():\n    print(f\"\\nDataset: {exp_name}\")\n\n    # Final training metrics\n    final_train_loss = exp_data[\"losses\"][\"train\"][-1]\n    final_train_acc = exp_data[\"metrics\"][\"train\"][-1][\"acc\"]\n\n    print(f\"train loss: {final_train_loss:.4f}\")\n    print(f\"train accuracy: {final_train_acc:.4f}\")\n\n    # Best validation metrics (according to recorded best_epoch)\n    best_idx = get_best_index(\n        exp_data.get(\"best_epoch\"), len(exp_data[\"losses\"][\"val\"])\n    )\n    best_val_loss = exp_data[\"losses\"][\"val\"][best_idx]\n    best_val_acc = exp_data[\"metrics\"][\"val\"][best_idx][\"acc\"]\n    best_val_cswa = exp_data[\"metrics\"][\"val\"][best_idx][\"CSWA\"]\n\n    print(f\"validation loss (best epoch): {best_val_loss:.4f}\")\n    print(f\"validation accuracy (best epoch): {best_val_acc:.4f}\")\n    print(f\"validation CSWA (best epoch): {best_val_cswa:.4f}\")\n", "import os\nimport numpy as np\n\n\n# ------------------------------------------------------------\n# helpers copied from training script (needed for CSWA score)\n# ------------------------------------------------------------\ndef colour_of(tok):  # everything except first char\n    return tok[1:] if len(tok) > 1 else \"\"\n\n\ndef shape_of(tok):  # first char\n    return tok[0] if tok else \"\"\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len({colour_of(t) for t in seq.split()})\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len({shape_of(t) for t in seq.split()})\n\n\ndef cswa(seqs, y_true, y_pred):\n    w = [count_colour_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\n# ------------------------------------------------------------\n# load experiment data\n# ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------\n# parse and print metrics\n# ------------------------------------------------------------\nfor dataset_name, ed in experiment_data.items():\n    print(f\"{dataset_name}\")\n\n    # Determine the epoch considered \u201cbest\u201d (lowest validation loss); fall back to final\n    best_epoch = ed.get(\"best_epoch\")\n    if best_epoch is not None:\n        idx = best_epoch - 1  # zero-based index\n    else:\n        idx = len(ed[\"losses\"][\"val\"]) - 1  # final epoch\n\n    # Training metrics\n    train_acc = ed[\"metrics\"][\"train\"][idx][\"acc\"]\n    train_loss = ed[\"losses\"][\"train\"][idx]\n    print(f\"  train accuracy (epoch {idx+1}): {train_acc:.3f}\")\n    print(f\"  train loss     (epoch {idx+1}): {train_loss:.4f}\")\n\n    # Validation metrics\n    val_acc = ed[\"metrics\"][\"val\"][idx][\"acc\"]\n    val_loss = ed[\"losses\"][\"val\"][idx]\n    val_cswa = ed[\"metrics\"][\"val\"][idx].get(\"CSWA\")\n    print(f\"  validation accuracy (epoch {idx+1}): {val_acc:.3f}\")\n    print(f\"  validation loss     (epoch {idx+1}): {val_loss:.4f}\")\n    if val_cswa is not None:\n        print(f\"  validation CSWA     (epoch {idx+1}): {val_cswa:.3f}\")\n\n    # Test metrics (recomputed if necessary)\n    preds = ed.get(\"predictions\", [])\n    gts = ed.get(\"ground_truth\", [])\n    seqs = ed.get(\"sequences\", [])\n    if preds and gts:\n        test_acc = sum(int(p == g) for p, g in zip(preds, gts)) / len(gts)\n        print(f\"  test accuracy: {test_acc:.3f}\")\n\n        if seqs:\n            test_cswa = cswa(seqs, gts, preds)\n            print(f\"  test CSWA: {test_cswa:.3f}\")\n\n        # Test loss might not be present; print if available\n        test_loss_list = ed.get(\"losses\", {}).get(\"test\")\n        if test_loss_list:\n            print(f\"  test loss: {test_loss_list[-1]:.4f}\")\n", "import os\nimport numpy as np\n\n\n# ------------------------------------------------------------------\n# Helper functions (copied from the training script)\n# ------------------------------------------------------------------\ndef colour_of(tok: str) -> str:\n    return tok[1:] if len(tok) > 1 else \"\"\n\n\ndef shape_of(tok: str) -> str:\n    return tok[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(t) for t in seq.split()))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(t) for t in seq.split()))\n\n\ndef cwa(seqs, y_true, y_pred):\n    weights = [count_colour_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(1, sum(weights))\n\n\ndef swa(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(1, sum(weights))\n\n\ndef cswa(seqs, y_true, y_pred):\n    weights = [count_colour_variety(s) + count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(1, sum(weights))\n\n\n# ------------------------------------------------------------------\n# Load experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# Iterate through datasets and print metrics\n# ------------------------------------------------------------------\nfor dataset_name, ed in experiment_data.items():\n    # ---------------- Training (final epoch) ----------------\n    train_acc = ed[\"metrics\"][\"train\"][-1][\"acc\"]\n    train_loss = ed[\"losses\"][\"train\"][-1]\n\n    # ---------------- Validation (best epoch) ---------------\n    best_ep = ed.get(\"best_epoch\", len(ed[\"metrics\"][\"val\"]))\n    best_idx = best_ep - 1  # convert 1-based epoch to 0-based index\n    val_metrics = ed[\"metrics\"][\"val\"][best_idx]\n    val_loss = ed[\"losses\"][\"val\"][best_idx]\n\n    # ---------------- Test (re-compute) ---------------------\n    preds = ed.get(\"predictions\", [])\n    gts = ed.get(\"ground_truth\", [])\n    seqs = ed.get(\"sequences\", [])\n\n    if preds and gts and seqs:\n        test_accuracy = sum(int(p == g) for p, g in zip(preds, gts)) / len(gts)\n        test_cwa = cwa(seqs, gts, preds)\n        test_swa = swa(seqs, gts, preds)\n        test_cswa = cswa(seqs, gts, preds)\n    else:\n        test_accuracy = test_cwa = test_swa = test_cswa = float(\"nan\")\n\n    # ---------------- Printing ------------------------------\n    print(dataset_name)\n    print(f\"final training loss: {train_loss:.4f}\")\n    print(f\"final training accuracy: {train_acc:.3f}\")\n    print(f\"best validation loss: {val_loss:.4f}\")\n    print(f\"best validation accuracy: {val_metrics['acc']:.3f}\")\n    print(f\"best validation CWA: {val_metrics['CWA']:.3f}\")\n    print(f\"best validation SWA: {val_metrics['SWA']:.3f}\")\n    print(f\"best validation CSWA: {val_metrics['CSWA']:.3f}\")\n    print(f\"test accuracy: {test_accuracy:.3f}\")\n    print(f\"test CWA: {test_cwa:.3f}\")\n    print(f\"test SWA: {test_swa:.3f}\")\n    print(f\"test CSWA: {test_cswa:.3f}\")\n", "import os\nimport numpy as np\n\n\n# ----------------------------------------------------------------------\n# Helpers (replicate small parts of training code so we can recompute CWA)\n# ----------------------------------------------------------------------\ndef colour_of(token: str) -> str:\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    return token[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(tok) for tok in seq.split() if tok))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(tok) for tok in seq.split() if tok))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    weights = [complexity_weight(s) for s in seqs]\n    correct_weights = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct_weights) / max(1, sum(weights))\n\n\n# ----------------------------------------------------------------------\n# Load experiment data\n# ----------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ----------------------------------------------------------------------\n# Iterate over datasets and print requested metrics\n# ----------------------------------------------------------------------\nfor dataset_name, data in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # --------------------- training metrics (final epoch) ---------------------\n    final_train_metrics = data[\"metrics\"][\"train\"][-1]\n    final_train_loss = data[\"losses\"][\"train\"][-1]\n    print(f\"training accuracy: {final_train_metrics['acc']:.3f}\")\n    print(f\"training loss: {final_train_loss:.4f}\")\n\n    # --------------------- validation metrics (best epoch) --------------------\n    best_epoch = data.get(\"best_epoch\", final_train_metrics[\"epoch\"])\n    # locate best-epoch entry\n    val_metrics_list = data[\"metrics\"][\"val\"]\n    best_val_entry = next(m for m in val_metrics_list if m[\"epoch\"] == best_epoch)\n    best_val_loss = data[\"losses\"][\"val\"][best_epoch - 1]  # epoch indices start at 1\n    print(f\"validation accuracy (best epoch): {best_val_entry['acc']:.3f}\")\n    print(f\"validation loss (best epoch): {best_val_loss:.4f}\")\n    print(f\"validation CompWA (best epoch): {best_val_entry['CompWA']:.3f}\")\n\n    # --------------------- test metrics (re-computed) -------------------------\n    preds = data.get(\"predictions\", [])\n    gts = data.get(\"ground_truth\", [])\n    seqs = data.get(\"sequences\", [])\n\n    if preds and gts and seqs:\n        test_accuracy = sum(p == g for p, g in zip(preds, gts)) / len(gts)\n        test_compwa = comp_weighted_acc(seqs, gts, preds)\n        print(f\"test accuracy: {test_accuracy:.3f}\")\n        print(f\"test CompWA: {test_compwa:.3f}\")\n", "import os\nimport numpy as np\n\n\n# ----------------------------------------------------------------------\n# Helpers (replicate small parts of training code so we can recompute CWA)\n# ----------------------------------------------------------------------\ndef colour_of(token: str) -> str:\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    return token[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(tok) for tok in seq.split() if tok))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(tok) for tok in seq.split() if tok))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    weights = [complexity_weight(s) for s in seqs]\n    correct_weights = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct_weights) / max(1, sum(weights))\n\n\n# ----------------------------------------------------------------------\n# Load experiment data\n# ----------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ----------------------------------------------------------------------\n# Iterate over datasets and print requested metrics\n# ----------------------------------------------------------------------\nfor dataset_name, data in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # --------------------- training metrics (final epoch) ---------------------\n    final_train_metrics = data[\"metrics\"][\"train\"][-1]\n    final_train_loss = data[\"losses\"][\"train\"][-1]\n    print(f\"training accuracy: {final_train_metrics['acc']:.3f}\")\n    print(f\"training loss: {final_train_loss:.4f}\")\n\n    # --------------------- validation metrics (best epoch) --------------------\n    best_epoch = data.get(\"best_epoch\", final_train_metrics[\"epoch\"])\n    # locate best-epoch entry\n    val_metrics_list = data[\"metrics\"][\"val\"]\n    best_val_entry = next(m for m in val_metrics_list if m[\"epoch\"] == best_epoch)\n    best_val_loss = data[\"losses\"][\"val\"][best_epoch - 1]  # epoch indices start at 1\n    print(f\"validation accuracy (best epoch): {best_val_entry['acc']:.3f}\")\n    print(f\"validation loss (best epoch): {best_val_loss:.4f}\")\n    print(f\"validation CompWA (best epoch): {best_val_entry['CompWA']:.3f}\")\n\n    # --------------------- test metrics (re-computed) -------------------------\n    preds = data.get(\"predictions\", [])\n    gts = data.get(\"ground_truth\", [])\n    seqs = data.get(\"sequences\", [])\n\n    if preds and gts and seqs:\n        test_accuracy = sum(p == g for p, g in zip(preds, gts)) / len(gts)\n        test_compwa = comp_weighted_acc(seqs, gts, preds)\n        print(f\"test accuracy: {test_accuracy:.3f}\")\n        print(f\"test CompWA: {test_compwa:.3f}\")\n", "import os\nimport numpy as np\n\n\n# ----------------------------------------------------------------------\n# Helpers (replicate small parts of training code so we can recompute CWA)\n# ----------------------------------------------------------------------\ndef colour_of(token: str) -> str:\n    return token[1:] if len(token) > 1 else \"\"\n\n\ndef shape_of(token: str) -> str:\n    return token[0]\n\n\ndef count_colour_variety(seq: str) -> int:\n    return len(set(colour_of(tok) for tok in seq.split() if tok))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(shape_of(tok) for tok in seq.split() if tok))\n\n\ndef complexity_weight(seq: str) -> int:\n    return count_colour_variety(seq) + count_shape_variety(seq)\n\n\ndef comp_weighted_acc(seqs, y_true, y_pred):\n    weights = [complexity_weight(s) for s in seqs]\n    correct_weights = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct_weights) / max(1, sum(weights))\n\n\n# ----------------------------------------------------------------------\n# Load experiment data\n# ----------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ----------------------------------------------------------------------\n# Iterate over datasets and print requested metrics\n# ----------------------------------------------------------------------\nfor dataset_name, data in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # --------------------- training metrics (final epoch) ---------------------\n    final_train_metrics = data[\"metrics\"][\"train\"][-1]\n    final_train_loss = data[\"losses\"][\"train\"][-1]\n    print(f\"training accuracy: {final_train_metrics['acc']:.3f}\")\n    print(f\"training loss: {final_train_loss:.4f}\")\n\n    # --------------------- validation metrics (best epoch) --------------------\n    best_epoch = data.get(\"best_epoch\", final_train_metrics[\"epoch\"])\n    # locate best-epoch entry\n    val_metrics_list = data[\"metrics\"][\"val\"]\n    best_val_entry = next(m for m in val_metrics_list if m[\"epoch\"] == best_epoch)\n    best_val_loss = data[\"losses\"][\"val\"][best_epoch - 1]  # epoch indices start at 1\n    print(f\"validation accuracy (best epoch): {best_val_entry['acc']:.3f}\")\n    print(f\"validation loss (best epoch): {best_val_loss:.4f}\")\n    print(f\"validation CompWA (best epoch): {best_val_entry['CompWA']:.3f}\")\n\n    # --------------------- test metrics (re-computed) -------------------------\n    preds = data.get(\"predictions\", [])\n    gts = data.get(\"ground_truth\", [])\n    seqs = data.get(\"sequences\", [])\n\n    if preds and gts and seqs:\n        test_accuracy = sum(p == g for p, g in zip(preds, gts)) / len(gts)\n        test_compwa = comp_weighted_acc(seqs, gts, preds)\n        print(f\"test accuracy: {test_accuracy:.3f}\")\n        print(f\"test CompWA: {test_compwa:.3f}\")\n", ""], "parse_term_out": ["['SPR_BENCH', '\\n', 'training accuracy: 0.634', '\\n', 'training loss: 0.6369',\n'\\n', 'validation accuracy (best epoch): 0.565', '\\n', 'validation loss (best\nepoch): 0.7168', '\\n', 'validation CompWA (best epoch): 0.567', '\\n', 'test\naccuracy: 0.630', '\\n', 'test CompWA: 0.625', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'train loss: 0.614511', '\\n', 'validation loss: 0.736242',\n'\\n', 'train accuracy: 0.6613', '\\n', 'validation accuracy: 0.5150', '\\n',\n'validation complexity-weighted accuracy: 0.5165', '\\n', 'best epoch: 10', '\\n',\n'test accuracy: 0.4800', '\\n', 'test complexity-weighted accuracy: 0.4822',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: FULL - SPR_BENCH', '\\n', 'best epoch: 19', '\\n', 'train loss\n(final): 0.5110', '\\n', 'train accuracy (final): 0.746', '\\n', 'validation loss\n(best): 0.7353', '\\n', 'validation accuracy (best): 0.545', '\\n', 'validation\nCompWA (best): 0.554', '\\n', 'test loss: 0.8980', '\\n', 'test accuracy: 0.450',\n'\\n', 'test CompWA: 0.450', '\\n', '\\nDataset: SEQ_ONLY - SPR_BENCH', '\\n', 'best\nepoch: 5', '\\n', 'train loss (final): 0.6052', '\\n', 'train accuracy (final):\n0.666', '\\n', 'validation loss (best): 0.7512', '\\n', 'validation accuracy\n(best): 0.510', '\\n', 'validation CompWA (best): 0.510', '\\n', 'test loss:\n0.7465', '\\n', 'test accuracy: 0.515', '\\n', 'test CompWA: 0.509', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'training accuracy:', ' ', '0.693', '\\n', 'training loss:',\n' ', '0.5921', '\\n', 'validation accuracy:', ' ', '0.480', '\\n', 'validation\nCompWA:', ' ', '0.477', '\\n', 'validation loss:', ' ', '0.7654', '\\n', 'test\naccuracy:', ' ', '0.500', '\\n', 'test CompWA:', ' ', '0.490', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', 'final training loss:', ' ', '0.6516789078712464',\n'\\n', 'final training accuracy:', ' ', '0.6025', '\\n', 'best validation loss:',\n' ', '0.7190800189971924', '\\n', 'best validation accuracy:', ' ', '0.475',\n'\\n', 'best validation complexity weighted accuracy:', ' ',\n'0.4653631284916201', '\\n', 'test loss:', ' ', '0.7011192631721497', '\\n', 'test\naccuracy:', ' ', '0.525', '\\n', 'test complexity weighted accuracy:', ' ',\n'0.5191675794085433', '\\n', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['SPR_BENCH', '\\n', 'training loss: 0.6153', '\\n', 'training accuracy: 0.664',\n'\\n', 'validation loss: 0.8104', '\\n', 'validation accuracy: 0.476', '\\n',\n'validation colour-weighted accuracy: 0.487', '\\n', 'validation shape-weighted\naccuracy: 0.478', '\\n', 'validation combined-score weighted accuracy: 0.483',\n'\\n', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: no_self_loop_SPR_BENCH', '\\n', 'train loss: 0.5772', '\\n', 'train\naccuracy: 0.6937', '\\n', 'validation loss (best epoch): 0.7534', '\\n',\n'validation accuracy (best epoch): 0.4850', '\\n', 'validation CSWA (best epoch):\n0.4995', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', '  train accuracy (epoch 2): 0.546', '\\n', '  train loss\n(epoch 2): 0.7837', '\\n', '  validation accuracy (epoch 2): 0.545', '\\n', '\nvalidation loss     (epoch 2): 0.7178', '\\n', '  validation CSWA     (epoch 2):\n0.545', '\\n', '  test accuracy: 0.505', '\\n', '  test CSWA: 0.513', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'final training loss: 0.5976', '\\n', 'final training\naccuracy: 0.688', '\\n', 'best validation loss: 0.7398', '\\n', 'best validation\naccuracy: 0.505', '\\n', 'best validation CWA: 0.504', '\\n', 'best validation\nSWA: 0.512', '\\n', 'best validation CSWA: 0.508', '\\n', 'test accuracy: 0.565',\n'\\n', 'test CWA: 0.568', '\\n', 'test SWA: 0.559', '\\n', 'test CSWA: 0.564',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'training accuracy: 0.656', '\\n', 'training loss: 0.6154',\n'\\n', 'validation accuracy (best epoch): 0.540', '\\n', 'validation loss (best\nepoch): 0.7242', '\\n', 'validation CompWA (best epoch): 0.535', '\\n', 'test\naccuracy: 0.515', '\\n', 'test CompWA: 0.506', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'training accuracy: 0.655', '\\n', 'training loss: 0.6110',\n'\\n', 'validation accuracy (best epoch): 0.530', '\\n', 'validation loss (best\nepoch): 0.7292', '\\n', 'validation CompWA (best epoch): 0.545', '\\n', 'test\naccuracy: 0.490', '\\n', 'test CompWA: 0.484', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'training accuracy: 0.632', '\\n', 'training loss: 0.6370',\n'\\n', 'validation accuracy (best epoch): 0.535', '\\n', 'validation loss (best\nepoch): 0.7332', '\\n', 'validation CompWA (best epoch): 0.548', '\\n', 'test\naccuracy: 0.535', '\\n', 'test CompWA: 0.534', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
