
% The paper 'Inductive Representation Learning on Large Graphs' introduces GraphSAGE, a specific variant of Graph Neural Networks designed for inductive learning on large graphs. This paper is relevant to the baseline method in the research, which utilizes GraphSAGE as the backbone architecture for relational and structural data modeling. It should be cited when describing the GNN-based model architecture and methodology.
@article{hamilton2017inductiverl,
 author = {William L. Hamilton and Z. Ying and J. Leskovec},
 booktitle = {Neural Information Processing Systems},
 journal = {ArXiv},
 title = {Inductive Representation Learning on Large Graphs},
 volume = {abs/1706.02216},
 year = {2017}
}

% The paper 'Attention is All You Need' introduces the Transformer architecture, which has become a foundational model for sequence-based tasks. It is relevant to summarizing current approaches to sequence modeling and highlighting their focus on sequential information, contrasting with the structural and relational modeling capabilities of GNNs. This paper should be cited when discussing existing sequence-based models and their limitations in the context of the SPR task.
@article{vaswani2017attentionia,
 author = {Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and I. Polosukhin},
 booktitle = {Neural Information Processing Systems},
 pages = {5998-6008},
 title = {Attention is All you Need},
 year = {2017}
}

% The seminal paper 'Long Short-Term Memory' by Hochreiter and Schmidhuber (1997), which introduced LSTMs as a solution to the vanishing gradient problem in sequence modeling. This paper is relevant for summarizing existing sequence-based approaches and comparing their limitations to the structural modeling capabilities of GNNs in the context of the SPR task.
@article{hochreiter1997longsm,
 author = {Sepp Hochreiter and J. Schmidhuber},
 booktitle = {Neural Computation},
 journal = {Neural Computation},
 pages = {1735-1780},
 title = {Long Short-Term Memory},
 volume = {9},
 year = {1997}
}

% The paper 'DeepMCGCN: Multi-channel Deep Graph Neural Networks' discusses the capabilities of GNNs in modeling and representing graph structural data, with a focus on leveraging multi-relational features for improved performance. This is relevant to the hypothesis that GNNs can better capture relational and structural dependencies in the SPR task and should be cited when discussing the theoretical advantages of GNNs in relational data modeling.
@article{meng2024deepmcgcnmd,
 author = {Lei Meng and Zhonglin Ye and Yanlin Yang and Haixing Zhao},
 booktitle = {International Journal of Computational Intelligence Systems},
 journal = {Int. J. Comput. Intell. Syst.},
 pages = {41},
 title = {DeepMCGCN: Multi-channel Deep Graph Neural Networks},
 volume = {17},
 year = {2024}
}

% The paper 'Systematic Relational Reasoning With Epistemic Graph Neural Networks' introduces benchmarks for reasoning tasks requiring relational and structural understanding. This is relevant to contextualizing the SPR_BENCH dataset, which also focuses on relational reasoning tasks, and should be cited when discussing the dataset and its role in evaluating GNN-based methods for systematic reasoning.
@article{khalid2024systematicrr,
 author = {Irtaza Khalid and S. Schockaert},
 booktitle = {International Conference on Learning Representations},
 title = {Systematic Relational Reasoning With Epistemic Graph Neural Networks},
 year = {2024}
}

% The paper 'V-PROM: A Benchmark for Visual Reasoning Using Visual Progressive Matrices' introduces a benchmark to evaluate abstract reasoning over visual data, focusing on operations such as logical comparisons and generalization. This is relevant for contextualizing the SPR_BENCH dataset as part of a broader effort to design benchmarks for reasoning tasks. It should be cited when discussing the role of benchmarks in advancing relational reasoning research and the unique contributions of SPR_BENCH.
@article{teney2019vpromab,
 author = {Damien Teney and Peng Wang and Jiewei Cao and Lingqiao Liu and Chunhua Shen and A. Hengel},
 booktitle = {AAAI Conference on Artificial Intelligence},
 pages = {12071-12078},
 title = {V-PROM: A Benchmark for Visual Reasoning Using Visual Progressive Matrices},
 year = {2019}
}
