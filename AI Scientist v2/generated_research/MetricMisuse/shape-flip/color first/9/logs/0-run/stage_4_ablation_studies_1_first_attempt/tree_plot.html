<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 2], [0, 4], [0, 7], [0, 1], [0, 11], [0, 8], [0, 10], [0, 9], [0, 12], [0, 5], [0, 3], [0, 6]], "layout": [[0.5, 0.0], [0.0, 1.0], [0.09090909090909091, 1.0], [0.18181818181818182, 1.0], [0.2727272727272727, 1.0], [0.36363636363636365, 1.0], [0.45454545454545453, 1.0], [0.5454545454545454, 1.0], [0.6363636363636364, 1.0], [0.7272727272727273, 1.0], [0.8181818181818182, 1.0], [0.9090909090909091, 1.0], [1.0, 1.0]], "plan": ["We enrich the previous GNN by wiring together every pair of tokens that share\nthe same shape or the same colour, in addition to the usual left-to-right chain\nedges, so the model can explicitly propagate information along latent rule\ndimensions.  Each token is still encoded with one-hot shape, one-hot colour and\na normalised position, but we replace the GCN with a two-layer multi-head Graph\nAttention Network that can learn different weights for the three edge\ncategories.  We train with Adam for a fixed 15 epochs (lr = 5e-4, batch 32) and\nmonitor CWA, SWA and their harmonic mean (HWA) on the dev set every epoch; the\nbest-HWA model is finally evaluated on the test split.  All losses and metrics\nare stored in the experiment_data dict and dumped to\n\u201cworking/experiment_data.npy\u201d, while a validation-loss curve is saved to\n\u201cworking/val_loss.png\u201d.  The script auto-detects GPU, moves everything to the\nselected device and is fully self-contained, falling back to a tiny synthetic\ndataset when SPR_BENCH is absent, so it finishes well under 30 minutes even on\nCPU.", "Ablation name: Remove Shape/Color Similarity Edges. We reload the SPR data\nexactly as in the baseline, rebuild the vocabularies and graph features, but\nwhen we convert a sequence into a PyG graph we keep only the sequential chain\nedges (i,i+1  and their reverse) and omit every \u201csame-shape\u201d / \u201csame-color\u201d\nconnection. The identical SPR-GAT architecture, training loop, metrics and\nlogging utilities are reused so that the only experimental difference is the\nsparser edge set. All losses, metrics and predictions are stored in the\nprescribed nested experiment_data dictionary (ablation key:\n\"remove_similarity_edges\") and saved to experiment_data.npy together with a\nvalidation-loss plot. The code below is self-contained and executable.", "Ablation name: Remove Positional Feature (No\u2010POS). The ablation removes the\nscalar positional feature from each node, allowing only one-hot shape and color\nembeddings. Everything else\u2014graph construction, GAT architecture, training loop,\nmetric computation, logging, and artifact saving\u2014remains identical, letting us\ndirectly observe the impact of stripping positional information. The experiment\ndata are stored under the ablation key \u201cNo_POS\u201d for the SPR dataset.", "Ablation name: Single-Head Attention (No-MultiHead). Below is the modified\nscript.   It is identical to the baseline except that both GATConv layers now\nuse a single attention head (`heads=1`).  Hidden dimensionality is kept\nunchanged, allowing us to directly compare performance with / without multi-head\nattention.", "Ablation name: No-Chain-Edges. We replicate the baseline pipeline but modify the\ngraph-builder so that it never adds sequential \u201cchain\u201d edges.  The rest of the\ndata loading, model (two-layer GAT + pooling), training loop, metric\ncomputation, and artefact saving stay unchanged.  Results are stored under the\nablation key 'no_chain_edges' for dataset 'SPR', then written to\nworking/experiment_data.npy together with a validation-loss curve.  The script\nis completely self-contained and executable.", "Ablation name: No-Bidirectional-Edges. The ablation study is implemented by\naltering the graph-construction routine: every edge is created only once,\npointing from the lower to the higher token index (i < j).  The reverse-edge\nduplication is removed so the GAT must rely on strictly forward message passing.\nAll other training, evaluation, and logging code is kept identical to the\nbaseline, and results are stored under the ablation key \u201cNoBiDir\u201d.", "Ablation name: No-Node-Features (Edge-Only Graph). We duplicate the baseline\npipeline but redefine the graph construction routine so that every node carries\na single, identical scalar feature (value 0).  All explicit shape, color and\npositional attributes are removed; only chain, shape-equality and color-equality\nedges remain, meaning the GAT can exploit connectivity patterns only.\nConsequently the model\u2019s input dimensionality is 1 and the rest of the training\n/ logging logic stays unchanged.  The script stores the full training history\ninside the mandatory experiment_data dictionary and writes it to\n\u2018experiment_data.npy\u2019.  Run the file to reproduce the \u201cNo-Node-Features (Edge-\nOnly Graph)\u201d ablation.", "Ablation name: Single-GAT-Layer (1-Hop Message Passing Only). Below is a\nstreamlined re-implementation of the original script in which the second GATConv\nlayer is removed so that each node aggregates information from only its 1-hop\nneighbours before global pooling. We train, validate and test exactly as before,\nlog all artefacts to experiment_data under the key \"single_gat_layer\", and save\nplots / numpy dumps to the working directory.", "Ablation name: Remove-Color-Features (No-Color-Embedding). We recreate the\noriginal pipeline but rebuild each PyG graph with its one-hot color segment\nzeroed out; shape one-hot, position scalar and all edge types stay unchanged.\nTraining, validation and test loops remain identical, so performance differences\ndirectly reflect the absence of explicit color features. All metrics, losses and\npredictions are stored under the ablation key \u201cNoColorEmbedding\u201d.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, random, pathlib, math, time, itertools\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------------------------------------------------ #\n# experiment container\n# ------------------------------------------------------------ #\nexperiment_data = {\n    \"SPR\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ------------------- Metrics -------------------------------- #\ndef _uniq_colors(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# -------------------- Load SPR data ------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n):\n    sh, col = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(sh) + random.choice(col) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\nif real:\n    train_raw, dev_raw, test_raw = real\nelse:\n    train_raw, dev_raw, test_raw = gen_synth(2000), gen_synth(500), gen_synth(500)\n\n\n# ------------------- Vocabularies --------------------------- #\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for s in split[\"sequence\"] if isinstance(split, dict) else split[\"sequence\"]:\n            for tok in s.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# --------- Sequence --> PyG graph with rich edges ----------- #\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n    pos = [i / (n - 1 if n > 1 else 1) for i in range(n)]\n    sh_oh = torch.nn.functional.one_hot(torch.tensor(sid), num_classes=S)\n    co_oh = torch.nn.functional.one_hot(torch.tensor(cid), num_classes=C)\n    pos_feat = torch.tensor(pos, dtype=torch.float32).unsqueeze(1)\n    x = torch.cat([sh_oh.float(), co_oh.float(), pos_feat], 1)\n\n    # chain edges\n    edges = [(i, i + 1) for i in range(n - 1)]\n    # same shape edges\n    for s in set(sid):\n        idx = [i for i, v in enumerate(sid) if v == s]\n        edges += list(itertools.combinations(idx, 2))\n    # same color edges\n    for c in set(cid):\n        idx = [i for i, v in enumerate(cid) if v == c]\n        edges += list(itertools.combinations(idx, 2))\n    # make bidirectional\n    edges += [(j, i) for i, j in edges]\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    else:\n        return [seq_to_graph(ex[\"sequence\"], int(ex[\"label\"])) for ex in split]\n\n\ntrain_ds, dev_ds, test_ds = map(to_pyg, (train_raw, dev_raw, test_raw))\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# -------------------- Model -------------------------------- #\nclass SPRGAT(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        self.g1 = GATConv(in_dim, hid, heads=4, concat=True, dropout=0.1)\n        self.g2 = GATConv(hid * 4, hid, heads=4, concat=False, dropout=0.1)\n        self.lin = nn.Linear(hid, out)\n\n    def forward(self, data):\n        x, ei, b = data.x, data.edge_index, data.batch\n        x = self.g1(x, ei).relu()\n        x = self.g2(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# -------------------- Training utilities ------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    training = opt is not None\n    model.train() if training else model.eval()\n    tot_loss, seqs, ys, ps = 0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        if training:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if training:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(1).detach().cpu().tolist()\n        labels = batch.y.view(-1).cpu().tolist()\n        ps.extend(preds)\n        ys.extend(labels)\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg_loss, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# -------------------- Training loop ------------------------ #\nBATCH = 32\nEPOCHS = 15\nLR = 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=2 * BATCH)\ncriterion = nn.CrossEntropyLoss()\n\nmodel = SPRGAT(S + C + 1, 64, num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor epoch in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, optimizer)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f'Epoch {epoch}: validation_loss = {vloss:.4f}  HWA = {vmet[\"HWA\"]:.4f}')\n    experiment_data[\"SPR\"][\"losses\"][\"train\"].append(tloss)\n    experiment_data[\"SPR\"][\"losses\"][\"val\"].append(vloss)\n    experiment_data[\"SPR\"][\"metrics\"][\"train\"].append(tmet)\n    experiment_data[\"SPR\"][\"metrics\"][\"val\"].append(vmet)\n    experiment_data[\"SPR\"][\"epochs\"].append(epoch)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_state, best_ep = (\n            vmet[\"HWA\"],\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n        )\n        print(f\"  New best model at epoch {epoch} with HWA {best_hwa:.4f}\")\n\n# -------------------- Test evaluation ---------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f'Test CWA={test_met[\"CWA\"]:.3f}  SWA={test_met[\"SWA\"]:.3f}  HWA={test_met[\"HWA\"]:.3f}'\n)\n\nexperiment_data[\"SPR\"][\"predictions\"] = pred\nexperiment_data[\"SPR\"][\"ground_truth\"] = gt\nexperiment_data[\"SPR\"][\"best_epoch\"] = best_ep\n\n# -------------------- Save artefacts ----------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\nplt.figure()\nplt.plot(experiment_data[\"SPR\"][\"epochs\"], experiment_data[\"SPR\"][\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"Validation Loss Curve\")\nplt.savefig(os.path.join(working_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "# remove_similarity_edges_ablation.py\nimport os, random, pathlib, math, itertools, time\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\n# ------------------------------------------------------------ #\n# experiment container\n# ------------------------------------------------------------ #\nexperiment_data = {\n    \"remove_similarity_edges\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\n\n# -------------------- Device -------------------------------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------- Metrics -------------------------------- #\ndef _uniq_colors(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# -------------------- Load SPR data ------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n):\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(shapes) + random.choice(colors) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\ntrain_raw, dev_raw, test_raw = (\n    real if real else (gen_synth(2000), gen_synth(500), gen_synth(500))\n)\n\n\n# ------------------- Vocabularies --------------------------- #\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for s in split[\"sequence\"] if isinstance(split, dict) else split[\"sequence\"]:\n            for tok in s.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# --------- Sequence --> PyG graph (ONLY chain edges) -------- #\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n    pos = [i / (n - 1 if n > 1 else 1) for i in range(n)]\n    sh_oh = torch.nn.functional.one_hot(torch.tensor(sid), num_classes=S)\n    co_oh = torch.nn.functional.one_hot(torch.tensor(cid), num_classes=C)\n    pos_feat = torch.tensor(pos, dtype=torch.float32).unsqueeze(1)\n    x = torch.cat([sh_oh.float(), co_oh.float(), pos_feat], 1)\n\n    edges = [(i, i + 1) for i in range(n - 1)]\n    edges += [(j, i) for i, j in edges]  # bidirectional\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    else:\n        return [seq_to_graph(ex[\"sequence\"], int(ex[\"label\"])) for ex in split]\n\n\ntrain_ds, dev_ds, test_ds = map(to_pyg, (train_raw, dev_raw, test_raw))\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# -------------------- Model -------------------------------- #\nclass SPRGAT(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        self.g1 = GATConv(in_dim, hid, heads=4, concat=True, dropout=0.1)\n        self.g2 = GATConv(hid * 4, hid, heads=4, concat=False, dropout=0.1)\n        self.lin = nn.Linear(hid, out)\n\n    def forward(self, data):\n        x, ei, b = data.x, data.edge_index, data.batch\n        x = self.g1(x, ei).relu()\n        x = self.g2(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# -------------------- Training utilities ------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    model.train() if opt else model.eval()\n    tot_loss, seqs, ys, ps = 0.0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        if opt:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if opt:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        pred = out.argmax(1).detach().cpu().tolist()\n        lab = batch.y.view(-1).cpu().tolist()\n        ps.extend(pred)\n        ys.extend(lab)\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg_loss, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# -------------------- Training loop ------------------------ #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nBATCH, EPOCHS, LR = 32, 15, 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=2 * BATCH)\ncriterion = nn.CrossEntropyLoss()\nmodel = SPRGAT(S + C + 1, 64, num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor epoch in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, optimizer)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f\"Epoch {epoch}: val_loss={vloss:.4f} HWA={vmet['HWA']:.4f}\")\n    exp_rec = experiment_data[\"remove_similarity_edges\"][\"SPR\"]\n    exp_rec[\"losses\"][\"train\"].append(tloss)\n    exp_rec[\"losses\"][\"val\"].append(vloss)\n    exp_rec[\"metrics\"][\"train\"].append(tmet)\n    exp_rec[\"metrics\"][\"val\"].append(vmet)\n    exp_rec[\"epochs\"].append(epoch)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_state, best_ep = (\n            vmet[\"HWA\"],\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n        )\n        print(f\"  New best model at epoch {epoch} with HWA={best_hwa:.4f}\")\n\n# -------------------- Test evaluation ---------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f'Test CWA={test_met[\"CWA\"]:.3f} SWA={test_met[\"SWA\"]:.3f} HWA={test_met[\"HWA\"]:.3f}'\n)\n\nexp_rec = experiment_data[\"remove_similarity_edges\"][\"SPR\"]\nexp_rec[\"predictions\"] = pred\nexp_rec[\"ground_truth\"] = gt\nexp_rec[\"best_epoch\"] = best_ep\n\n# -------------------- Save artefacts ----------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nplt.figure()\nplt.plot(exp_rec[\"epochs\"], exp_rec[\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"Validation Loss Curve\")\nplt.savefig(os.path.join(working_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "# ------------------------------------------------------------\n# No-POS ablation study on SPR using GAT\n# ------------------------------------------------------------\nimport os, random, pathlib, math, itertools, time\n\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ----------------- directories ------------------------------#\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- experiment container -------------------- #\nexperiment_data = {\n    \"No_POS\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\nexp_ref = experiment_data[\"No_POS\"][\"SPR\"]\n\n\n# ------------------- Metrics -------------------------------- #\ndef _uniq_colors(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# -------------------- Load SPR data ------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n):\n    sh, col = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(sh) + random.choice(col) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\nif real:\n    train_raw, dev_raw, test_raw = real\nelse:\n    train_raw, dev_raw, test_raw = gen_synth(2000), gen_synth(500), gen_synth(500)\n\n\n# ------------------- Vocabularies --------------------------- #\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for s in split[\"sequence\"] if isinstance(split, dict) else split[\"sequence\"]:\n            for tok in s.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# --------- Sequence --> PyG graph (NO positional feature) --- #\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n\n    sh_oh = torch.nn.functional.one_hot(torch.tensor(sid), num_classes=S)\n    co_oh = torch.nn.functional.one_hot(torch.tensor(cid), num_classes=C)\n    x = torch.cat([sh_oh.float(), co_oh.float()], 1)  # NO position concatenation\n\n    edges = [(i, i + 1) for i in range(n - 1)]\n    for s in set(sid):\n        idx = [i for i, v in enumerate(sid) if v == s]\n        edges += list(itertools.combinations(idx, 2))\n    for c in set(cid):\n        idx = [i for i, v in enumerate(cid) if v == c]\n        edges += list(itertools.combinations(idx, 2))\n    edges += [(j, i) for i, j in edges]\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    else:\n        return [seq_to_graph(ex[\"sequence\"], int(ex[\"label\"])) for ex in split]\n\n\ntrain_ds, dev_ds, test_ds = map(to_pyg, (train_raw, dev_raw, test_raw))\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# -------------------- Model -------------------------------- #\nclass SPRGAT(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        self.g1 = GATConv(in_dim, hid, heads=4, concat=True, dropout=0.1)\n        self.g2 = GATConv(hid * 4, hid, heads=4, concat=False, dropout=0.1)\n        self.lin = nn.Linear(hid, out)\n\n    def forward(self, data):\n        x, ei, b = data.x, data.edge_index, data.batch\n        x = self.g1(x, ei).relu()\n        x = self.g2(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# -------------------- Training utilities ------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    training = opt is not None\n    model.train() if training else model.eval()\n    tot_loss, seqs, ys, ps = 0.0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        if training:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if training:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(1).detach().cpu().tolist()\n        labels = batch.y.view(-1).cpu().tolist()\n        ps.extend(preds)\n        ys.extend(labels)\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg_loss, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# -------------------- Training loop ------------------------ #\nBATCH, EPOCHS, LR = 32, 15, 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=2 * BATCH)\ncriterion = nn.CrossEntropyLoss()\nmodel = SPRGAT(S + C, 64, num_classes).to(device)  # No +1\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor epoch in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, optimizer)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f'Epoch {epoch}: val_loss={vloss:.4f}  HWA={vmet[\"HWA\"]:.4f}')\n    exp_ref[\"losses\"][\"train\"].append(tloss)\n    exp_ref[\"losses\"][\"val\"].append(vloss)\n    exp_ref[\"metrics\"][\"train\"].append(tmet)\n    exp_ref[\"metrics\"][\"val\"].append(vmet)\n    exp_ref[\"epochs\"].append(epoch)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_state, best_ep = (\n            vmet[\"HWA\"],\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n        )\n        print(f\"  New best HWA {best_hwa:.4f} at epoch {epoch}\")\n\n# -------------------- Test evaluation ---------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f'Test CWA={test_met[\"CWA\"]:.3f}  SWA={test_met[\"SWA\"]:.3f}  HWA={test_met[\"HWA\"]:.3f}'\n)\nexp_ref[\"predictions\"] = pred\nexp_ref[\"ground_truth\"] = gt\nexp_ref[\"best_epoch\"] = best_ep\n\n# -------------------- Save artefacts ----------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nplt.figure()\nplt.plot(exp_ref[\"epochs\"], exp_ref[\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"No-POS Validation Loss\")\nplt.savefig(os.path.join(working_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "import os, random, pathlib, math, itertools, time\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------------------------------------------------ #\n# experiment container\n# ------------------------------------------------------------ #\nexperiment_data = {\n    \"NoMultiHead\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\n\n\n# ------------------- Metrics -------------------------------- #\ndef _uniq_colors(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# -------------------- Load SPR data ------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n):\n    sh, col = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(sh) + random.choice(col) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\nif real:\n    train_raw, dev_raw, test_raw = real\nelse:\n    train_raw, dev_raw, test_raw = gen_synth(2000), gen_synth(500), gen_synth(500)\n\n\n# ------------------- Vocabularies --------------------------- #\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for s in split[\"sequence\"] if isinstance(split, dict) else split[\"sequence\"]:\n            for tok in s.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# --------- Sequence --> PyG graph with rich edges ----------- #\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n    pos = [i / (n - 1 if n > 1 else 1) for i in range(n)]\n    sh_oh = torch.nn.functional.one_hot(torch.tensor(sid), num_classes=S)\n    co_oh = torch.nn.functional.one_hot(torch.tensor(cid), num_classes=C)\n    pos_feat = torch.tensor(pos, dtype=torch.float32).unsqueeze(1)\n    x = torch.cat([sh_oh.float(), co_oh.float(), pos_feat], 1)\n\n    edges = [(i, i + 1) for i in range(n - 1)]\n    for s in set(sid):\n        idx = [i for i, v in enumerate(sid) if v == s]\n        edges += list(itertools.combinations(idx, 2))\n    for c in set(cid):\n        idx = [i for i, v in enumerate(cid) if v == c]\n        edges += list(itertools.combinations(idx, 2))\n    edges += [(j, i) for i, j in edges]\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    else:\n        return [seq_to_graph(ex[\"sequence\"], int(ex[\"label\"])) for ex in split]\n\n\ntrain_ds, dev_ds, test_ds = map(to_pyg, (train_raw, dev_raw, test_raw))\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# -------------------- Model -------------------------------- #\nclass SPRGAT_SingleHead(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        # single head, keep hidden size constant\n        self.g1 = GATConv(in_dim, hid, heads=1, concat=True, dropout=0.1)\n        self.g2 = GATConv(hid, hid, heads=1, concat=False, dropout=0.1)\n        self.lin = nn.Linear(hid, out)\n\n    def forward(self, data):\n        x, ei, b = data.x, data.edge_index, data.batch\n        x = self.g1(x, ei).relu()\n        x = self.g2(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# -------------------- Training utilities ------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    training = opt is not None\n    model.train() if training else model.eval()\n    tot_loss, seqs, ys, ps = 0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        if training:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if training:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(1).detach().cpu().tolist()\n        labels = batch.y.view(-1).cpu().tolist()\n        ps.extend(preds)\n        ys.extend(labels)\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg_loss, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# -------------------- Training loop ------------------------ #\nBATCH = 32\nEPOCHS = 15\nLR = 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=2 * BATCH)\ncriterion = nn.CrossEntropyLoss()\n\nmodel = SPRGAT_SingleHead(S + C + 1, 64, num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor epoch in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, optimizer)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f'Epoch {epoch}: validation_loss = {vloss:.4f}  HWA = {vmet[\"HWA\"]:.4f}')\n    ed = experiment_data[\"NoMultiHead\"][\"SPR\"]\n    ed[\"losses\"][\"train\"].append(tloss)\n    ed[\"losses\"][\"val\"].append(vloss)\n    ed[\"metrics\"][\"train\"].append(tmet)\n    ed[\"metrics\"][\"val\"].append(vmet)\n    ed[\"epochs\"].append(epoch)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_state, best_ep = (\n            vmet[\"HWA\"],\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n        )\n        print(f\"  New best model at epoch {epoch} with HWA {best_hwa:.4f}\")\n\n# -------------------- Test evaluation ---------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f'Test CWA={test_met[\"CWA\"]:.3f}  SWA={test_met[\"SWA\"]:.3f}  HWA={test_met[\"HWA\"]:.3f}'\n)\n\ned = experiment_data[\"NoMultiHead\"][\"SPR\"]\ned[\"predictions\"] = pred\ned[\"ground_truth\"] = gt\ned[\"best_epoch\"] = best_ep\n\n# -------------------- Save artefacts ----------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"Validation Loss Curve (NoMultiHead)\")\nplt.savefig(os.path.join(working_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "import os, random, pathlib, itertools, math, time\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\n# ----------- housekeeping -------------------------------------------------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\n    \"no_chain_edges\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\n\n\n# ------------------ metrics ------------------------------------------------- #\ndef _uniq_colors(seq):\n    return len({t[1] for t in seq.split() if len(t) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({t[0] for t in seq.split()})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# ------------------ data ---------------------------------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n=2000):\n    sh, col = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(sh) + random.choice(col) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\ntrain_raw, dev_raw, test_raw = (\n    real if real else (gen_synth(2000), gen_synth(500), gen_synth(500))\n)\n\n\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for s in split[\"sequence\"]:\n            for tok in s.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# -------------- graph construction: NO CHAIN EDGES -------------------------- #\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n    pos = [i / (n - 1 if n > 1 else 1) for i in range(n)]\n    sh_oh = torch.nn.functional.one_hot(torch.tensor(sid), num_classes=S)\n    co_oh = torch.nn.functional.one_hot(torch.tensor(cid), num_classes=C)\n    x = torch.cat(\n        [\n            sh_oh.float(),\n            co_oh.float(),\n            torch.tensor(pos, dtype=torch.float32).unsqueeze(1),\n        ],\n        1,\n    )\n\n    edges = []\n    for s in set(sid):\n        idx = [i for i, v in enumerate(sid) if v == s]\n        edges += list(itertools.combinations(idx, 2))\n    for c in set(cid):\n        idx = [i for i, v in enumerate(cid) if v == c]\n        edges += list(itertools.combinations(idx, 2))\n    edges += [(j, i) for i, j in edges]  # bidirectional\n\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split):\n    return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n\n\ntrain_ds, dev_ds, test_ds = map(to_pyg, (train_raw, dev_raw, test_raw))\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# ------------------ model --------------------------------------------------- #\nclass SPRGAT(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        self.g1 = GATConv(in_dim, hid, heads=4, concat=True, dropout=0.1)\n        self.g2 = GATConv(hid * 4, hid, heads=4, concat=False, dropout=0.1)\n        self.lin = nn.Linear(hid, out)\n\n    def forward(self, data):\n        x, ei, b = data.x, data.edge_index, data.batch\n        x = self.g1(x, ei).relu()\n        x = self.g2(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# ------------------ training utilities ------------------------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    training = opt is not None\n    model.train() if training else model.eval()\n    tot_loss, seqs, ys, ps = 0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        if training:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if training:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(1).detach().cpu().tolist()\n        labels = batch.y.view(-1).cpu().tolist()\n        ps.extend(preds)\n        ys.extend(labels)\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg_loss, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# ------------------ training loop ------------------------------------------ #\nBATCH, EPOCHS, LR = 32, 15, 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=2 * BATCH)\ncriterion = nn.CrossEntropyLoss()\n\nmodel = SPRGAT(S + C + 1, 64, num_classes).to(device)\nopt = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor epoch in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, opt)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f'Epoch {epoch}: val_loss={vloss:.4f}  HWA={vmet[\"HWA\"]:.4f}')\n    ed = experiment_data[\"no_chain_edges\"][\"SPR\"]\n    ed[\"losses\"][\"train\"].append(tloss)\n    ed[\"losses\"][\"val\"].append(vloss)\n    ed[\"metrics\"][\"train\"].append(tmet)\n    ed[\"metrics\"][\"val\"].append(vmet)\n    ed[\"epochs\"].append(epoch)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_state, best_ep = (\n            vmet[\"HWA\"],\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n        )\n        print(f\"  new best model at epoch {epoch}\")\n\n# ------------------ test evaluation ---------------------------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f'Test CWA={test_met[\"CWA\"]:.3f}  SWA={test_met[\"SWA\"]:.3f}  HWA={test_met[\"HWA\"]:.3f}'\n)\n\ned = experiment_data[\"no_chain_edges\"][\"SPR\"]\ned[\"predictions\"], ed[\"ground_truth\"], ed[\"best_epoch\"] = pred, gt, best_ep\n\n# ------------------ save artefacts ----------------------------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"Val Loss (No Chain Edges)\")\nplt.savefig(os.path.join(working_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "# No-Bidirectional-Edges Ablation for SPR \u2013 single-file runnable script\nimport os, random, pathlib, itertools, math, time\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------------- Experiment container -------------------------- #\nexperiment_data = {\n    \"NoBiDir\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\n\n\n# ---------------------- Metrics --------------------------------------- #\ndef _uniq_colors(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# ---------------------- Load / synth SPR data ------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n):\n    sh, col = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(sh) + random.choice(col) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\ntrain_raw, dev_raw, test_raw = (\n    real if real else (gen_synth(2000), gen_synth(500), gen_synth(500))\n)\n\n\n# --------------------- Vocabularies ----------------------------------- #\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for seq in split[\"sequence\"]:\n            for tok in seq.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# --------------------- Sequence -> PyG graph (NoBiDir) ---------------- #\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n    pos = [i / (n - 1 if n > 1 else 1) for i in range(n)]\n\n    sh_oh = torch.nn.functional.one_hot(torch.tensor(sid), num_classes=S)\n    co_oh = torch.nn.functional.one_hot(torch.tensor(cid), num_classes=C)\n    pos_feat = torch.tensor(pos, dtype=torch.float32).unsqueeze(1)\n    x = torch.cat([sh_oh.float(), co_oh.float(), pos_feat], 1)\n\n    edges = []\n    # chain edges i -> i+1\n    edges += [(i, i + 1) for i in range(n - 1)]\n    # same-shape edges i<j\n    for s in set(sid):\n        idx = [i for i, v in enumerate(sid) if v == s]\n        edges += [(i, j) for i, j in itertools.combinations(idx, 2)]\n    # same-color edges i<j\n    for c in set(cid):\n        idx = [i for i, v in enumerate(cid) if v == c]\n        edges += [(i, j) for i, j in itertools.combinations(idx, 2)]\n\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    else:\n        return [seq_to_graph(ex[\"sequence\"], int(ex[\"label\"])) for ex in split]\n\n\ntrain_ds, dev_ds, test_ds = map(to_pyg, (train_raw, dev_raw, test_raw))\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# --------------------- Model ------------------------------------------ #\nclass SPRGAT(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        self.g1 = GATConv(in_dim, hid, heads=4, concat=True, dropout=0.1)\n        self.g2 = GATConv(hid * 4, hid, heads=4, concat=False, dropout=0.1)\n        self.lin = nn.Linear(hid, out)\n\n    def forward(self, data):\n        x, ei, b = data.x, data.edge_index, data.batch\n        x = self.g1(x, ei).relu()\n        x = self.g2(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# --------------------- Training utilities ----------------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    model.train() if opt else model.eval()\n    tot_loss, seqs, ys, ps = 0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        if opt:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if opt:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(1).detach().cpu().tolist()\n        labels = batch.y.view(-1).cpu().tolist()\n        ps.extend(preds)\n        ys.extend(labels)\n        seqs.extend(batch.seq)\n    avg = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# --------------------- Training loop ---------------------------------- #\nBATCH, EPOCHS, LR = 32, 15, 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=2 * BATCH)\ncriterion = nn.CrossEntropyLoss()\nmodel = SPRGAT(S + C + 1, 64, num_classes).to(device)\noptim = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor ep in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, optim)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f\"Epoch {ep}: val_loss={vloss:.4f} HWA={vmet['HWA']:.4f}\")\n    ed = experiment_data[\"NoBiDir\"][\"SPR\"]\n    ed[\"losses\"][\"train\"].append(tloss)\n    ed[\"losses\"][\"val\"].append(vloss)\n    ed[\"metrics\"][\"train\"].append(tmet)\n    ed[\"metrics\"][\"val\"].append(vmet)\n    ed[\"epochs\"].append(ep)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_state, best_ep = (\n            vmet[\"HWA\"],\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            ep,\n        )\n        print(f\"  New best @ epoch {ep} (HWA={best_hwa:.4f})\")\n\n# --------------------- Test evaluation -------------------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f\"Test CWA={test_met['CWA']:.3f} SWA={test_met['SWA']:.3f} HWA={test_met['HWA']:.3f}\"\n)\n\ned = experiment_data[\"NoBiDir\"][\"SPR\"]\ned[\"predictions\"] = pred\ned[\"ground_truth\"] = gt\ned[\"best_epoch\"] = best_ep\n\n# --------------------- Save artefacts --------------------------------- #\nwork_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(work_dir, exist_ok=True)\nnp.save(os.path.join(work_dir, \"experiment_data.npy\"), experiment_data)\n\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"Validation Loss (NoBiDir)\")\nplt.savefig(os.path.join(work_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "import os, random, pathlib, math, time, itertools, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\n# ----------------- I/O & bookkeeping ----------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\n    \"NoNodeFeatures\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\n\n\n# ----------------- Helper metrics -------------------------- #\ndef _uniq_colors(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# ----------------- Data loading ---------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n):\n    sh, col = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(sh) + random.choice(col) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\nif real:\n    train_raw, dev_raw, test_raw = real\nelse:\n    train_raw, dev_raw, test_raw = gen_synth(2000), gen_synth(500), gen_synth(500)\n\n\n# ----------------- Vocab for edge construction ------------- #\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for s in split[\"sequence\"] if isinstance(split, dict) else split[\"sequence\"]:\n            for tok in s.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# ----------------- Graph builder (edge-only) --------------- #\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n\n    # constant dummy node feature (single scalar 0.)\n    x = torch.zeros((n, 1), dtype=torch.float32)\n\n    # chain edges\n    edges = [(i, i + 1) for i in range(n - 1)]\n    # same shape edges\n    for s in set(sid):\n        idx = [i for i, v in enumerate(sid) if v == s]\n        edges += list(itertools.combinations(idx, 2))\n    # same color edges\n    for c in set(cid):\n        idx = [i for i, v in enumerate(cid) if v == c]\n        edges += list(itertools.combinations(idx, 2))\n    edges += [(j, i) for i, j in edges]  # bidirectional\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    else:\n        return [seq_to_graph(ex[\"sequence\"], int(ex[\"label\"])) for ex in split]\n\n\ntrain_ds, dev_ds, test_ds = map(to_pyg, (train_raw, dev_raw, test_raw))\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# ----------------- Model ----------------------------------- #\nclass SPRGAT(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        self.g1 = GATConv(in_dim, hid, heads=4, concat=True, dropout=0.1)\n        self.g2 = GATConv(hid * 4, hid, heads=4, concat=False, dropout=0.1)\n        self.lin = nn.Linear(hid, out)\n\n    def forward(self, data):\n        x, ei, b = data.x.to(device), data.edge_index.to(device), data.batch\n        x = self.g1(x, ei).relu()\n        x = self.g2(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# ----------------- Training utils -------------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    training = opt is not None\n    model.train() if training else model.eval()\n    tot_loss = 0\n    seqs = []\n    ys = []\n    ps = []\n    for batch in loader:\n        batch = batch.to(device)\n        if training:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if training:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(1).detach().cpu().tolist()\n        labels = batch.y.view(-1).cpu().tolist()\n        ps.extend(preds)\n        ys.extend(labels)\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg_loss, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# ----------------- Training loop --------------------------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nBATCH, EPOCHS, LR = 32, 15, 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=2 * BATCH)\ncriterion = nn.CrossEntropyLoss()\n\nmodel = SPRGAT(1, 64, num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor epoch in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, optimizer)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f\"Epoch {epoch}: val_loss={vloss:.4f} HWA={vmet['HWA']:.4f}\")\n    ed = experiment_data[\"NoNodeFeatures\"][\"SPR\"]\n    ed[\"losses\"][\"train\"].append(tloss)\n    ed[\"losses\"][\"val\"].append(vloss)\n    ed[\"metrics\"][\"train\"].append(tmet)\n    ed[\"metrics\"][\"val\"].append(vmet)\n    ed[\"epochs\"].append(epoch)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_state, best_ep = (\n            vmet[\"HWA\"],\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n        )\n        print(f\"  New best model at epoch {epoch} with HWA {best_hwa:.4f}\")\n\n# ----------------- Test evaluation ------------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f\"Test CWA={test_met['CWA']:.3f} SWA={test_met['SWA']:.3f} HWA={test_met['HWA']:.3f}\"\n)\n\ned = experiment_data[\"NoNodeFeatures\"][\"SPR\"]\ned[\"predictions\"] = pred\ned[\"ground_truth\"] = gt\ned[\"best_epoch\"] = best_ep\n\n# ----------------- Save artefacts -------------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"Validation Loss Curve\")\nplt.savefig(os.path.join(working_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "# Single-GAT-Layer (1-Hop Message Passing Only) ablation for SPR\nimport os, random, pathlib, itertools, math, time\n\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\n# ---------- housekeeping ---------------------------------------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Running on\", device)\n\n# ---------- experiment container ------------------------------------------- #\nexperiment_data = {\n    \"single_gat_layer\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\n\n\n# ---------- helper metrics -------------------------------------------------- #\ndef _uniq_colors(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({tok[0] for tok in seq.split()})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# ---------- load / generate SPR data --------------------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n):\n    sh, col = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(sh) + random.choice(col) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\ntrain_raw, dev_raw, test_raw = (\n    real if real else (gen_synth(2000), gen_synth(500), gen_synth(500))\n)\n\n\n# ---------- vocabularies ---------------------------------------------------- #\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for s in split[\"sequence\"] if isinstance(split, dict) else split[\"sequence\"]:\n            for tok in s.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# ---------- seq -> graph ---------------------------------------------------- #\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n    pos = [i / (n - 1 if n > 1 else 1) for i in range(n)]\n    sh_oh = torch.nn.functional.one_hot(torch.tensor(sid), num_classes=S)\n    co_oh = torch.nn.functional.one_hot(torch.tensor(cid), num_classes=C)\n    pos_feat = torch.tensor(pos).float().unsqueeze(1)\n    x = torch.cat([sh_oh.float(), co_oh.float(), pos_feat], 1)\n\n    edges = [(i, i + 1) for i in range(n - 1)]\n    for s in set(sid):\n        idx = [i for i, v in enumerate(sid) if v == s]\n        edges += list(itertools.combinations(idx, 2))\n    for c in set(cid):\n        idx = [i for i, v in enumerate(cid) if v == c]\n        edges += list(itertools.combinations(idx, 2))\n    edges += [(j, i) for i, j in edges]\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    else:\n        return [seq_to_graph(ex[\"sequence\"], int(ex[\"label\"])) for ex in split]\n\n\ntrain_ds, dev_ds, test_ds = map(to_pyg, (train_raw, dev_raw, test_raw))\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# ---------- 1-hop GAT model ------------------------------------------------- #\nclass SPRGAT1Hop(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        self.g = GATConv(in_dim, hid, heads=4, concat=True, dropout=0.1)\n        self.lin = nn.Linear(hid * 4, out)\n\n    def forward(self, data):\n        x, ei, b = data.x, data.edge_index, data.batch\n        x = self.g(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# ---------- training utilities --------------------------------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    train = opt is not None\n    model.train() if train else model.eval()\n    tot_loss, seqs, ys, ps = 0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        if train:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if train:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(1).detach().cpu().tolist()\n        labels = batch.y.view(-1).cpu().tolist()\n        ps.extend(preds)\n        ys.extend(labels)\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg_loss, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# ---------- training loop --------------------------------------------------- #\nBATCH, EPOCHS, LR = 32, 15, 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=BATCH * 2)\ncriterion = nn.CrossEntropyLoss()\nmodel = SPRGAT1Hop(S + C + 1, 64, num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor epoch in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, optimizer)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f\"Epoch {epoch}: val_loss={vloss:.4f}  HWA={vmet['HWA']:.4f}\")\n    exp = experiment_data[\"single_gat_layer\"][\"SPR\"]\n    exp[\"losses\"][\"train\"].append(tloss)\n    exp[\"losses\"][\"val\"].append(vloss)\n    exp[\"metrics\"][\"train\"].append(tmet)\n    exp[\"metrics\"][\"val\"].append(vmet)\n    exp[\"epochs\"].append(epoch)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_ep = vmet[\"HWA\"], epoch\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        print(f\"  new best model (HWA {best_hwa:.4f}) saved.\")\n\n# ---------- testing --------------------------------------------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f\"Test: CWA={test_met['CWA']:.3f}  SWA={test_met['SWA']:.3f}  HWA={test_met['HWA']:.3f}\"\n)\nexp = experiment_data[\"single_gat_layer\"][\"SPR\"]\nexp[\"predictions\"], exp[\"ground_truth\"], exp[\"best_epoch\"] = pred, gt, best_ep\n\n# ---------- save artefacts -------------------------------------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\nplt.figure()\nplt.plot(exp[\"epochs\"], exp[\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"Val Loss (1-Hop GAT)\")\nplt.savefig(os.path.join(working_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "import os, random, pathlib, math, time, itertools, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\n# --------------------------- I/O & misc ---------------------------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\n    \"NoColorEmbedding\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\n\n\n# --------------------------- Metrics -------------------------------- #\ndef _uniq_colors(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# --------------------------- Data ----------------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n):\n    sh, col = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(sh) + random.choice(col) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\ntrain_raw, dev_raw, test_raw = (\n    real if real else (gen_synth(2000), gen_synth(500), gen_synth(500))\n)\n\n\n# vocabularies\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for s in split[\"sequence\"] if isinstance(split, dict) else split[\"sequence\"]:\n            for tok in s.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# --------------------------- Graph builders ------------------------- #\ndef seq_to_graph(seq, label, drop_color=False):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n    pos = [i / (n - 1 if n > 1 else 1) for i in range(n)]\n    sh_oh = torch.nn.functional.one_hot(torch.tensor(sid), num_classes=S).float()\n    co_oh = torch.nn.functional.one_hot(torch.tensor(cid), num_classes=C).float()\n    if drop_color:\n        co_oh *= 0.0\n    pos_feat = torch.tensor(pos, dtype=torch.float32).unsqueeze(1)\n    x = torch.cat([sh_oh, co_oh, pos_feat], 1)\n\n    edges = [(i, i + 1) for i in range(n - 1)]\n    for s in set(sid):\n        idx = [i for i, v in enumerate(sid) if v == s]\n        edges += list(itertools.combinations(idx, 2))\n    for c in set(cid):\n        idx = [i for i, v in enumerate(cid) if v == c]\n        edges += list(itertools.combinations(idx, 2))\n    edges += [(j, i) for i, j in edges]\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split, drop_color=False):\n    if isinstance(split, dict):\n        return [\n            seq_to_graph(s, l, drop_color)\n            for s, l in zip(split[\"sequence\"], split[\"label\"])\n        ]\n    else:\n        return [\n            seq_to_graph(ex[\"sequence\"], int(ex[\"label\"]), drop_color) for ex in split\n        ]\n\n\ntrain_ds, dev_ds, test_ds = map(\n    lambda sp: to_pyg(sp, drop_color=True), (train_raw, dev_raw, test_raw)\n)\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# --------------------------- Model ---------------------------------- #\nclass SPRGAT(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        self.g1 = GATConv(in_dim, hid, heads=4, concat=True, dropout=0.1)\n        self.g2 = GATConv(hid * 4, hid, heads=4, concat=False, dropout=0.1)\n        self.lin = nn.Linear(hid, out)\n\n    def forward(self, data):\n        x, ei, b = data.x, data.edge_index, data.batch\n        x = self.g1(x, ei).relu()\n        x = self.g2(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# --------------------------- Training utils ------------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    model.train() if opt else model.eval()\n    tot_loss, seqs, ys, ps = 0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        if opt:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if opt:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(1).detach().cpu().tolist()\n        labels = batch.y.view(-1).cpu().tolist()\n        ps.extend(preds)\n        ys.extend(labels)\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg_loss, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# --------------------------- Training loop -------------------------- #\nBATCH, EPOCHS, LR = 32, 15, 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=2 * BATCH)\ncriterion = nn.CrossEntropyLoss()\nmodel = SPRGAT(S + C + 1, 64, num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor epoch in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, optimizer)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f'Epoch {epoch}: val_loss={vloss:.4f} HWA={vmet[\"HWA\"]:.4f}')\n    d = experiment_data[\"NoColorEmbedding\"][\"SPR\"]\n    d[\"losses\"][\"train\"].append(tloss)\n    d[\"losses\"][\"val\"].append(vloss)\n    d[\"metrics\"][\"train\"].append(tmet)\n    d[\"metrics\"][\"val\"].append(vmet)\n    d[\"epochs\"].append(epoch)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_state, best_ep = (\n            vmet[\"HWA\"],\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n        )\n        print(f\"  New best at epoch {epoch} with HWA {best_hwa:.4f}\")\n\n# --------------------------- Test ----------------------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f'Test CWA={test_met[\"CWA\"]:.3f} SWA={test_met[\"SWA\"]:.3f} HWA={test_met[\"HWA\"]:.3f}'\n)\n\nd = experiment_data[\"NoColorEmbedding\"][\"SPR\"]\nd[\"predictions\"] = pred\nd[\"ground_truth\"] = gt\nd[\"best_epoch\"] = best_ep\n\n# --------------------------- Save artefacts ------------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\nplt.figure()\nplt.plot(d[\"epochs\"], d[\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"Validation Loss Curve (NoColor)\")\nplt.savefig(os.path.join(working_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, random, pathlib, math, time, itertools\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------------------------------------------------ #\n# experiment container\n# ------------------------------------------------------------ #\nexperiment_data = {\n    \"SPR\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ------------------- Metrics -------------------------------- #\ndef _uniq_colors(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# -------------------- Load SPR data ------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n):\n    sh, col = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(sh) + random.choice(col) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\nif real:\n    train_raw, dev_raw, test_raw = real\nelse:\n    train_raw, dev_raw, test_raw = gen_synth(2000), gen_synth(500), gen_synth(500)\n\n\n# ------------------- Vocabularies --------------------------- #\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for s in split[\"sequence\"] if isinstance(split, dict) else split[\"sequence\"]:\n            for tok in s.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# --------- Sequence --> PyG graph with rich edges ----------- #\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n    pos = [i / (n - 1 if n > 1 else 1) for i in range(n)]\n    sh_oh = torch.nn.functional.one_hot(torch.tensor(sid), num_classes=S)\n    co_oh = torch.nn.functional.one_hot(torch.tensor(cid), num_classes=C)\n    pos_feat = torch.tensor(pos, dtype=torch.float32).unsqueeze(1)\n    x = torch.cat([sh_oh.float(), co_oh.float(), pos_feat], 1)\n\n    # chain edges\n    edges = [(i, i + 1) for i in range(n - 1)]\n    # same shape edges\n    for s in set(sid):\n        idx = [i for i, v in enumerate(sid) if v == s]\n        edges += list(itertools.combinations(idx, 2))\n    # same color edges\n    for c in set(cid):\n        idx = [i for i, v in enumerate(cid) if v == c]\n        edges += list(itertools.combinations(idx, 2))\n    # make bidirectional\n    edges += [(j, i) for i, j in edges]\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    else:\n        return [seq_to_graph(ex[\"sequence\"], int(ex[\"label\"])) for ex in split]\n\n\ntrain_ds, dev_ds, test_ds = map(to_pyg, (train_raw, dev_raw, test_raw))\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# -------------------- Model -------------------------------- #\nclass SPRGAT(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        self.g1 = GATConv(in_dim, hid, heads=4, concat=True, dropout=0.1)\n        self.g2 = GATConv(hid * 4, hid, heads=4, concat=False, dropout=0.1)\n        self.lin = nn.Linear(hid, out)\n\n    def forward(self, data):\n        x, ei, b = data.x, data.edge_index, data.batch\n        x = self.g1(x, ei).relu()\n        x = self.g2(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# -------------------- Training utilities ------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    training = opt is not None\n    model.train() if training else model.eval()\n    tot_loss, seqs, ys, ps = 0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        if training:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if training:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(1).detach().cpu().tolist()\n        labels = batch.y.view(-1).cpu().tolist()\n        ps.extend(preds)\n        ys.extend(labels)\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg_loss, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# -------------------- Training loop ------------------------ #\nBATCH = 32\nEPOCHS = 15\nLR = 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=2 * BATCH)\ncriterion = nn.CrossEntropyLoss()\n\nmodel = SPRGAT(S + C + 1, 64, num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor epoch in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, optimizer)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f'Epoch {epoch}: validation_loss = {vloss:.4f}  HWA = {vmet[\"HWA\"]:.4f}')\n    experiment_data[\"SPR\"][\"losses\"][\"train\"].append(tloss)\n    experiment_data[\"SPR\"][\"losses\"][\"val\"].append(vloss)\n    experiment_data[\"SPR\"][\"metrics\"][\"train\"].append(tmet)\n    experiment_data[\"SPR\"][\"metrics\"][\"val\"].append(vmet)\n    experiment_data[\"SPR\"][\"epochs\"].append(epoch)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_state, best_ep = (\n            vmet[\"HWA\"],\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n        )\n        print(f\"  New best model at epoch {epoch} with HWA {best_hwa:.4f}\")\n\n# -------------------- Test evaluation ---------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f'Test CWA={test_met[\"CWA\"]:.3f}  SWA={test_met[\"SWA\"]:.3f}  HWA={test_met[\"HWA\"]:.3f}'\n)\n\nexperiment_data[\"SPR\"][\"predictions\"] = pred\nexperiment_data[\"SPR\"][\"ground_truth\"] = gt\nexperiment_data[\"SPR\"][\"best_epoch\"] = best_ep\n\n# -------------------- Save artefacts ----------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\nplt.figure()\nplt.plot(experiment_data[\"SPR\"][\"epochs\"], experiment_data[\"SPR\"][\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"Validation Loss Curve\")\nplt.savefig(os.path.join(working_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, random, pathlib, math, time, itertools\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------------------------------------------------ #\n# experiment container\n# ------------------------------------------------------------ #\nexperiment_data = {\n    \"SPR\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ------------------- Metrics -------------------------------- #\ndef _uniq_colors(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# -------------------- Load SPR data ------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n):\n    sh, col = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(sh) + random.choice(col) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\nif real:\n    train_raw, dev_raw, test_raw = real\nelse:\n    train_raw, dev_raw, test_raw = gen_synth(2000), gen_synth(500), gen_synth(500)\n\n\n# ------------------- Vocabularies --------------------------- #\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for s in split[\"sequence\"] if isinstance(split, dict) else split[\"sequence\"]:\n            for tok in s.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# --------- Sequence --> PyG graph with rich edges ----------- #\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n    pos = [i / (n - 1 if n > 1 else 1) for i in range(n)]\n    sh_oh = torch.nn.functional.one_hot(torch.tensor(sid), num_classes=S)\n    co_oh = torch.nn.functional.one_hot(torch.tensor(cid), num_classes=C)\n    pos_feat = torch.tensor(pos, dtype=torch.float32).unsqueeze(1)\n    x = torch.cat([sh_oh.float(), co_oh.float(), pos_feat], 1)\n\n    # chain edges\n    edges = [(i, i + 1) for i in range(n - 1)]\n    # same shape edges\n    for s in set(sid):\n        idx = [i for i, v in enumerate(sid) if v == s]\n        edges += list(itertools.combinations(idx, 2))\n    # same color edges\n    for c in set(cid):\n        idx = [i for i, v in enumerate(cid) if v == c]\n        edges += list(itertools.combinations(idx, 2))\n    # make bidirectional\n    edges += [(j, i) for i, j in edges]\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    else:\n        return [seq_to_graph(ex[\"sequence\"], int(ex[\"label\"])) for ex in split]\n\n\ntrain_ds, dev_ds, test_ds = map(to_pyg, (train_raw, dev_raw, test_raw))\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# -------------------- Model -------------------------------- #\nclass SPRGAT(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        self.g1 = GATConv(in_dim, hid, heads=4, concat=True, dropout=0.1)\n        self.g2 = GATConv(hid * 4, hid, heads=4, concat=False, dropout=0.1)\n        self.lin = nn.Linear(hid, out)\n\n    def forward(self, data):\n        x, ei, b = data.x, data.edge_index, data.batch\n        x = self.g1(x, ei).relu()\n        x = self.g2(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# -------------------- Training utilities ------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    training = opt is not None\n    model.train() if training else model.eval()\n    tot_loss, seqs, ys, ps = 0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        if training:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if training:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(1).detach().cpu().tolist()\n        labels = batch.y.view(-1).cpu().tolist()\n        ps.extend(preds)\n        ys.extend(labels)\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg_loss, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# -------------------- Training loop ------------------------ #\nBATCH = 32\nEPOCHS = 15\nLR = 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=2 * BATCH)\ncriterion = nn.CrossEntropyLoss()\n\nmodel = SPRGAT(S + C + 1, 64, num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor epoch in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, optimizer)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f'Epoch {epoch}: validation_loss = {vloss:.4f}  HWA = {vmet[\"HWA\"]:.4f}')\n    experiment_data[\"SPR\"][\"losses\"][\"train\"].append(tloss)\n    experiment_data[\"SPR\"][\"losses\"][\"val\"].append(vloss)\n    experiment_data[\"SPR\"][\"metrics\"][\"train\"].append(tmet)\n    experiment_data[\"SPR\"][\"metrics\"][\"val\"].append(vmet)\n    experiment_data[\"SPR\"][\"epochs\"].append(epoch)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_state, best_ep = (\n            vmet[\"HWA\"],\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n        )\n        print(f\"  New best model at epoch {epoch} with HWA {best_hwa:.4f}\")\n\n# -------------------- Test evaluation ---------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f'Test CWA={test_met[\"CWA\"]:.3f}  SWA={test_met[\"SWA\"]:.3f}  HWA={test_met[\"HWA\"]:.3f}'\n)\n\nexperiment_data[\"SPR\"][\"predictions\"] = pred\nexperiment_data[\"SPR\"][\"ground_truth\"] = gt\nexperiment_data[\"SPR\"][\"best_epoch\"] = best_ep\n\n# -------------------- Save artefacts ----------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\nplt.figure()\nplt.plot(experiment_data[\"SPR\"][\"epochs\"], experiment_data[\"SPR\"][\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"Validation Loss Curve\")\nplt.savefig(os.path.join(working_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, random, pathlib, math, time, itertools\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------------------------------------------------ #\n# experiment container\n# ------------------------------------------------------------ #\nexperiment_data = {\n    \"SPR\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"best_epoch\": None,\n    }\n}\n\n\n# ------------------- Metrics -------------------------------- #\ndef _uniq_colors(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef _uniq_shapes(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef cwa(seqs, y_true, y_pred):\n    w = [_uniq_colors(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef swa(seqs, y_true, y_pred):\n    w = [_uniq_shapes(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\n# -------------------- Load SPR data ------------------------- #\ndef try_load_real():\n    try:\n        from SPR import load_spr_bench\n\n        root = pathlib.Path(\"./SPR_BENCH\")\n        d = load_spr_bench(root)\n        return d[\"train\"], d[\"dev\"], d[\"test\"]\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH:\", e)\n        return None\n\n\ndef gen_synth(n):\n    sh, col = list(\"ABCD\"), list(\"1234\")\n    seqs, labs = [], []\n    for _ in range(n):\n        ln = random.randint(3, 10)\n        toks = [random.choice(sh) + random.choice(col) for _ in range(ln)]\n        seq = \" \".join(toks)\n        lab = (len(set(t[0] for t in toks)) * len(set(t[1] for t in toks))) % 4\n        seqs.append(seq)\n        labs.append(lab)\n    return {\"sequence\": seqs, \"label\": labs}\n\n\nreal = try_load_real()\nif real:\n    train_raw, dev_raw, test_raw = real\nelse:\n    train_raw, dev_raw, test_raw = gen_synth(2000), gen_synth(500), gen_synth(500)\n\n\n# ------------------- Vocabularies --------------------------- #\ndef build_vocabs(*splits):\n    shapes, colors = set(), set()\n    for split in splits:\n        for s in split[\"sequence\"] if isinstance(split, dict) else split[\"sequence\"]:\n            for tok in s.split():\n                shapes.add(tok[0])\n                colors.add(tok[1])\n    return {s: i for i, s in enumerate(sorted(shapes))}, {\n        c: i for i, c in enumerate(sorted(colors))\n    }\n\n\nshape_vocab, color_vocab = build_vocabs(train_raw, dev_raw, test_raw)\nS, C = len(shape_vocab), len(color_vocab)\n\n\n# --------- Sequence --> PyG graph with rich edges ----------- #\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sid = [shape_vocab[t[0]] for t in toks]\n    cid = [color_vocab[t[1]] for t in toks]\n    pos = [i / (n - 1 if n > 1 else 1) for i in range(n)]\n    sh_oh = torch.nn.functional.one_hot(torch.tensor(sid), num_classes=S)\n    co_oh = torch.nn.functional.one_hot(torch.tensor(cid), num_classes=C)\n    pos_feat = torch.tensor(pos, dtype=torch.float32).unsqueeze(1)\n    x = torch.cat([sh_oh.float(), co_oh.float(), pos_feat], 1)\n\n    # chain edges\n    edges = [(i, i + 1) for i in range(n - 1)]\n    # same shape edges\n    for s in set(sid):\n        idx = [i for i, v in enumerate(sid) if v == s]\n        edges += list(itertools.combinations(idx, 2))\n    # same color edges\n    for c in set(cid):\n        idx = [i for i, v in enumerate(cid) if v == c]\n        edges += list(itertools.combinations(idx, 2))\n    # make bidirectional\n    edges += [(j, i) for i, j in edges]\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([int(label)]), seq=seq)\n\n\ndef to_pyg(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    else:\n        return [seq_to_graph(ex[\"sequence\"], int(ex[\"label\"])) for ex in split]\n\n\ntrain_ds, dev_ds, test_ds = map(to_pyg, (train_raw, dev_raw, test_raw))\nnum_classes = len({d.y.item() for d in train_ds + dev_ds + test_ds})\n\n\n# -------------------- Model -------------------------------- #\nclass SPRGAT(nn.Module):\n    def __init__(self, in_dim, hid, out):\n        super().__init__()\n        self.g1 = GATConv(in_dim, hid, heads=4, concat=True, dropout=0.1)\n        self.g2 = GATConv(hid * 4, hid, heads=4, concat=False, dropout=0.1)\n        self.lin = nn.Linear(hid, out)\n\n    def forward(self, data):\n        x, ei, b = data.x, data.edge_index, data.batch\n        x = self.g1(x, ei).relu()\n        x = self.g2(x, ei).relu()\n        x = global_mean_pool(x, b)\n        return self.lin(x)\n\n\n# -------------------- Training utilities ------------------- #\ndef run_epoch(model, loader, criterion, opt=None):\n    training = opt is not None\n    model.train() if training else model.eval()\n    tot_loss, seqs, ys, ps = 0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        if training:\n            opt.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        if training:\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(1).detach().cpu().tolist()\n        labels = batch.y.view(-1).cpu().tolist()\n        ps.extend(preds)\n        ys.extend(labels)\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    c, s = cwa(seqs, ys, ps), swa(seqs, ys, ps)\n    return avg_loss, {\"CWA\": c, \"SWA\": s, \"HWA\": hwa(c, s)}, ys, ps\n\n\n# -------------------- Training loop ------------------------ #\nBATCH = 32\nEPOCHS = 15\nLR = 5e-4\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=2 * BATCH)\ncriterion = nn.CrossEntropyLoss()\n\nmodel = SPRGAT(S + C + 1, 64, num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nbest_hwa, best_state, best_ep = -1, None, 0\nfor epoch in range(1, EPOCHS + 1):\n    tloss, tmet, _, _ = run_epoch(model, train_loader, criterion, optimizer)\n    vloss, vmet, _, _ = run_epoch(model, val_loader, criterion)\n    print(f'Epoch {epoch}: validation_loss = {vloss:.4f}  HWA = {vmet[\"HWA\"]:.4f}')\n    experiment_data[\"SPR\"][\"losses\"][\"train\"].append(tloss)\n    experiment_data[\"SPR\"][\"losses\"][\"val\"].append(vloss)\n    experiment_data[\"SPR\"][\"metrics\"][\"train\"].append(tmet)\n    experiment_data[\"SPR\"][\"metrics\"][\"val\"].append(vmet)\n    experiment_data[\"SPR\"][\"epochs\"].append(epoch)\n    if vmet[\"HWA\"] > best_hwa:\n        best_hwa, best_state, best_ep = (\n            vmet[\"HWA\"],\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n        )\n        print(f\"  New best model at epoch {epoch} with HWA {best_hwa:.4f}\")\n\n# -------------------- Test evaluation ---------------------- #\nmodel.load_state_dict(best_state)\ntest_loader = DataLoader(test_ds, batch_size=64)\n_, test_met, gt, pred = run_epoch(model, test_loader, criterion)\nprint(\n    f'Test CWA={test_met[\"CWA\"]:.3f}  SWA={test_met[\"SWA\"]:.3f}  HWA={test_met[\"HWA\"]:.3f}'\n)\n\nexperiment_data[\"SPR\"][\"predictions\"] = pred\nexperiment_data[\"SPR\"][\"ground_truth\"] = gt\nexperiment_data[\"SPR\"][\"best_epoch\"] = best_ep\n\n# -------------------- Save artefacts ----------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\nplt.figure()\nplt.plot(experiment_data[\"SPR\"][\"epochs\"], experiment_data[\"SPR\"][\"losses\"][\"val\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.title(\"Validation Loss Curve\")\nplt.savefig(os.path.join(working_dir, \"val_loss.png\"), dpi=150)\nplt.close()\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'Could not load real SPR_BENCH:', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Epoch 1: validation_loss = 0.9137  HWA = 0.7276', '\\n', '\nNew best model at epoch 1 with HWA 0.7276', '\\n', 'Epoch 2: validation_loss =\n0.8900  HWA = 0.7276', '\\n', 'Epoch 3: validation_loss = 0.8859  HWA = 0.7276',\n'\\n', 'Epoch 4: validation_loss = 0.8865  HWA = 0.7276', '\\n', 'Epoch 5:\nvalidation_loss = 0.8952  HWA = 0.7276', '\\n', 'Epoch 6: validation_loss =\n0.8871  HWA = 0.7276', '\\n', 'Epoch 7: validation_loss = 0.8911  HWA = 0.7251',\n'\\n', 'Epoch 8: validation_loss = 0.8695  HWA = 0.7251', '\\n', 'Epoch 9:\nvalidation_loss = 0.8700  HWA = 0.7362', '\\n', '  New best model at epoch 9 with\nHWA 0.7362', '\\n', 'Epoch 10: validation_loss = 0.8673  HWA = 0.7334', '\\n',\n'Epoch 11: validation_loss = 0.8544  HWA = 0.7298', '\\n', 'Epoch 12:\nvalidation_loss = 0.8623  HWA = 0.7011', '\\n', 'Epoch 13: validation_loss =\n0.8383  HWA = 0.7251', '\\n', 'Epoch 14: validation_loss = 0.8268  HWA = 0.7289',\n'\\n', 'Epoch 15: validation_loss = 0.8313  HWA = 0.7285', '\\n', 'Test CWA=0.722\nSWA=0.713  HWA=0.717', '\\n', 'Execution time: 20 seconds seconds (time limit is\n30 minutes).']", "['Using device: cuda', '\\n', 'Could not load real SPR_BENCH:', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Epoch 1: val_loss=0.9482 HWA=0.7018', '\\n', '  New best\nmodel at epoch 1 with HWA=0.7018', '\\n', 'Epoch 2: val_loss=0.9259 HWA=0.7018',\n'\\n', 'Epoch 3: val_loss=0.9216 HWA=0.7018', '\\n', 'Epoch 4: val_loss=0.9212\nHWA=0.7018', '\\n', 'Epoch 5: val_loss=0.9249 HWA=0.7018', '\\n', 'Epoch 6:\nval_loss=0.9186 HWA=0.7018', '\\n', 'Epoch 7: val_loss=0.9189 HWA=0.7018', '\\n',\n'Epoch 8: val_loss=0.9243 HWA=0.7018', '\\n', 'Epoch 9: val_loss=0.9134\nHWA=0.7018', '\\n', 'Epoch 10: val_loss=0.9145 HWA=0.7018', '\\n', 'Epoch 11:\nval_loss=0.8990 HWA=0.7018', '\\n', 'Epoch 12: val_loss=0.8723 HWA=0.7017', '\\n',\n'Epoch 13: val_loss=0.8404 HWA=0.6980', '\\n', 'Epoch 14: val_loss=0.8099\nHWA=0.7045', '\\n', '  New best model at epoch 14 with HWA=0.7045', '\\n', 'Epoch\n15: val_loss=0.8173 HWA=0.7169', '\\n', '  New best model at epoch 15 with\nHWA=0.7169', '\\n', 'Test CWA=0.707 SWA=0.705 HWA=0.706', '\\n', 'Execution time:\n27 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Could not load real SPR_BENCH:', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Epoch 1: val_loss=0.9589  HWA=0.7104', '\\n', '  New best\nHWA 0.7104 at epoch 1', '\\n', 'Epoch 2: val_loss=0.9272  HWA=0.7104', '\\n',\n'Epoch 3: val_loss=0.9286  HWA=0.7104', '\\n', 'Epoch 4: val_loss=0.9235\nHWA=0.7104', '\\n', 'Epoch 5: val_loss=0.9255  HWA=0.7104', '\\n', 'Epoch 6:\nval_loss=0.9207  HWA=0.7104', '\\n', 'Epoch 7: val_loss=0.9167  HWA=0.7104',\n'\\n', 'Epoch 8: val_loss=0.9122  HWA=0.7104', '\\n', 'Epoch 9: val_loss=0.9045\nHWA=0.7104', '\\n', 'Epoch 10: val_loss=0.8953  HWA=0.7104', '\\n', 'Epoch 11:\nval_loss=0.8943  HWA=0.7091', '\\n', 'Epoch 12: val_loss=0.8736  HWA=0.7113',\n'\\n', '  New best HWA 0.7113 at epoch 12', '\\n', 'Epoch 13: val_loss=0.8615\nHWA=0.7088', '\\n', 'Epoch 14: val_loss=0.8630  HWA=0.7098', '\\n', 'Epoch 15:\nval_loss=0.8437  HWA=0.7082', '\\n', 'Test CWA=0.712  SWA=0.720  HWA=0.716',\n'\\n', 'Execution time: 7 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Could not load real SPR_BENCH:', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Epoch 1: validation_loss = 1.0325  HWA = 0.7236', '\\n', '\nNew best model at epoch 1 with HWA 0.7236', '\\n', 'Epoch 2: validation_loss =\n0.9077  HWA = 0.7236', '\\n', 'Epoch 3: validation_loss = 0.9024  HWA = 0.7236',\n'\\n', 'Epoch 4: validation_loss = 0.8977  HWA = 0.7236', '\\n', 'Epoch 5:\nvalidation_loss = 0.8892  HWA = 0.7236', '\\n', 'Epoch 6: validation_loss =\n0.8820  HWA = 0.7236', '\\n', 'Epoch 7: validation_loss = 0.8902  HWA = 0.7236',\n'\\n', 'Epoch 8: validation_loss = 0.8720  HWA = 0.7236', '\\n', 'Epoch 9:\nvalidation_loss = 0.8711  HWA = 0.7297', '\\n', '  New best model at epoch 9 with\nHWA 0.7297', '\\n', 'Epoch 10: validation_loss = 0.8590  HWA = 0.7297', '\\n',\n'Epoch 11: validation_loss = 0.8691  HWA = 0.7273', '\\n', 'Epoch 12:\nvalidation_loss = 0.8550  HWA = 0.7288', '\\n', 'Epoch 13: validation_loss =\n0.8552  HWA = 0.7246', '\\n', 'Epoch 14: validation_loss = 0.8565  HWA = 0.7273',\n'\\n', 'Epoch 15: validation_loss = 0.8490  HWA = 0.7264', '\\n', 'Test CWA=0.700\nSWA=0.700  HWA=0.700', '\\n', 'Execution time: 8 seconds seconds (time limit is\n30 minutes).']", "['Could not load real SPR_BENCH:', ' ', \"No module named 'SPR'\", '\\n', 'Epoch 1:\nval_loss=1.0116  HWA=0.6817', '\\n', '  new best model at epoch 1', '\\n', 'Epoch\n2: val_loss=0.9810  HWA=0.6817', '\\n', 'Epoch 3: val_loss=0.9789  HWA=0.6817',\n'\\n', 'Epoch 4: val_loss=0.9778  HWA=0.6817', '\\n', 'Epoch 5: val_loss=0.9711\nHWA=0.6817', '\\n', 'Epoch 6: val_loss=0.9713  HWA=0.6817', '\\n', 'Epoch 7:\nval_loss=0.9654  HWA=0.6817', '\\n', 'Epoch 8: val_loss=0.9589  HWA=0.6817',\n'\\n', 'Epoch 9: val_loss=0.9332  HWA=0.6824', '\\n', '  new best model at epoch\n9', '\\n', 'Epoch 10: val_loss=0.9241  HWA=0.6777', '\\n', 'Epoch 11:\nval_loss=0.9157  HWA=0.6805', '\\n', 'Epoch 12: val_loss=0.9031  HWA=0.6842',\n'\\n', '  new best model at epoch 12', '\\n', 'Epoch 13: val_loss=0.9013\nHWA=0.6846', '\\n', '  new best model at epoch 13', '\\n', 'Epoch 14:\nval_loss=0.9010  HWA=0.6855', '\\n', '  new best model at epoch 14', '\\n', 'Epoch\n15: val_loss=0.8975  HWA=0.6824', '\\n', 'Test CWA=0.713  SWA=0.719  HWA=0.716',\n'\\n', 'Execution time: 15 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Could not load real SPR_BENCH:', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Epoch 1: val_loss=1.0025 HWA=0.6756', '\\n', '  New best @\nepoch 1 (HWA=0.6756)', '\\n', 'Epoch 2: val_loss=0.9631 HWA=0.6756', '\\n', 'Epoch\n3: val_loss=0.9683 HWA=0.6756', '\\n', 'Epoch 4: val_loss=0.9548 HWA=0.6756',\n'\\n', 'Epoch 5: val_loss=0.9561 HWA=0.6756', '\\n', 'Epoch 6: val_loss=0.9460\nHWA=0.6756', '\\n', 'Epoch 7: val_loss=0.9414 HWA=0.6756', '\\n', 'Epoch 8:\nval_loss=0.9327 HWA=0.6772', '\\n', '  New best @ epoch 8 (HWA=0.6772)', '\\n',\n'Epoch 9: val_loss=0.9295 HWA=0.6756', '\\n', 'Epoch 10: val_loss=0.9133\nHWA=0.6772', '\\n', 'Epoch 11: val_loss=0.9082 HWA=0.6747', '\\n', 'Epoch 12:\nval_loss=0.8979 HWA=0.6794', '\\n', '  New best @ epoch 12 (HWA=0.6794)', '\\n',\n'Epoch 13: val_loss=0.8902 HWA=0.6747', '\\n', 'Epoch 14: val_loss=0.8652\nHWA=0.6893', '\\n', '  New best @ epoch 14 (HWA=0.6893)', '\\n', 'Epoch 15:\nval_loss=0.8524 HWA=0.6945', '\\n', '  New best @ epoch 15 (HWA=0.6945)', '\\n',\n'Test CWA=0.687 SWA=0.690 HWA=0.688', '\\n', 'Execution time: 13 seconds seconds\n(time limit is 30 minutes).']", "['Could not load real SPR_BENCH:', ' ', \"No module named 'SPR'\", '\\n', 'Using\ndevice: cuda', '\\n', 'Epoch 1: val_loss=1.4024 HWA=0.1658', '\\n', '  New best\nmodel at epoch 1 with HWA 0.1658', '\\n', 'Epoch 2: val_loss=1.3792 HWA=0.1658',\n'\\n', 'Epoch 3: val_loss=1.3570 HWA=0.1658', '\\n', 'Epoch 4: val_loss=1.3361\nHWA=0.6985', '\\n', '  New best model at epoch 4 with HWA 0.6985', '\\n', 'Epoch\n5: val_loss=1.3160 HWA=0.6985', '\\n', 'Epoch 6: val_loss=1.2967 HWA=0.6985',\n'\\n', 'Epoch 7: val_loss=1.2782 HWA=0.6985', '\\n', 'Epoch 8: val_loss=1.2608\nHWA=0.6985', '\\n', 'Epoch 9: val_loss=1.2442 HWA=0.6985', '\\n', 'Epoch 10:\nval_loss=1.2283 HWA=0.6985', '\\n', 'Epoch 11: val_loss=1.2133 HWA=0.6985', '\\n',\n'Epoch 12: val_loss=1.1990 HWA=0.6985', '\\n', 'Epoch 13: val_loss=1.1858\nHWA=0.6985', '\\n', 'Epoch 14: val_loss=1.1730 HWA=0.6985', '\\n', 'Epoch 15:\nval_loss=1.1610 HWA=0.6985', '\\n', 'Test CWA=0.721 SWA=0.717 HWA=0.719', '\\n',\n'Execution time: 9 seconds seconds (time limit is 30 minutes).']", "['Running on', ' ', 'cuda', '\\n', 'Could not load real SPR_BENCH:', ' ', \"No\nmodule named 'SPR'\", '\\n', 'Epoch 1: val_loss=1.0163  HWA=0.7043', '\\n', '  new\nbest model (HWA 0.7043) saved.', '\\n', 'Epoch 2: val_loss=0.9540  HWA=0.7043',\n'\\n', 'Epoch 3: val_loss=0.9352  HWA=0.7043', '\\n', 'Epoch 4: val_loss=0.9298\nHWA=0.7043', '\\n', 'Epoch 5: val_loss=0.9291  HWA=0.7043', '\\n', 'Epoch 6:\nval_loss=0.9255  HWA=0.7043', '\\n', 'Epoch 7: val_loss=0.9249  HWA=0.7043',\n'\\n', 'Epoch 8: val_loss=0.9215  HWA=0.7043', '\\n', 'Epoch 9: val_loss=0.9216\nHWA=0.7043', '\\n', 'Epoch 10: val_loss=0.9175  HWA=0.7043', '\\n', 'Epoch 11:\nval_loss=0.9150  HWA=0.7043', '\\n', 'Epoch 12: val_loss=0.9107  HWA=0.7043',\n'\\n', 'Epoch 13: val_loss=0.9068  HWA=0.7043', '\\n', 'Epoch 14: val_loss=0.9097\nHWA=0.7043', '\\n', 'Epoch 15: val_loss=0.8991  HWA=0.7030', '\\n', 'Test:\nCWA=0.701  SWA=0.698  HWA=0.700', '\\n', 'Execution time: 8 seconds seconds (time\nlimit is 30 minutes).']", "['Could not load real SPR_BENCH:', ' ', \"No module named 'SPR'\", '\\n', 'Epoch 1:\nval_loss=0.9669 HWA=0.7019', '\\n', '  New best at epoch 1 with HWA 0.7019',\n'\\n', 'Epoch 2: val_loss=0.9287 HWA=0.7019', '\\n', 'Epoch 3: val_loss=0.9261\nHWA=0.7019', '\\n', 'Epoch 4: val_loss=0.9263 HWA=0.7019', '\\n', 'Epoch 5:\nval_loss=0.9167 HWA=0.7019', '\\n', 'Epoch 6: val_loss=0.9239 HWA=0.7019', '\\n',\n'Epoch 7: val_loss=0.9049 HWA=0.7019', '\\n', 'Epoch 8: val_loss=0.8923\nHWA=0.7019', '\\n', 'Epoch 9: val_loss=0.8676 HWA=0.7075', '\\n', '  New best at\nepoch 9 with HWA 0.7075', '\\n', 'Epoch 10: val_loss=0.8545 HWA=0.7137', '\\n', '\nNew best at epoch 10 with HWA 0.7137', '\\n', 'Epoch 11: val_loss=0.8431\nHWA=0.7137', '\\n', 'Epoch 12: val_loss=0.8345 HWA=0.7137', '\\n', 'Epoch 13:\nval_loss=0.8303 HWA=0.7146', '\\n', '  New best at epoch 13 with HWA 0.7146',\n'\\n', 'Epoch 14: val_loss=0.8237 HWA=0.7140', '\\n', 'Epoch 15: val_loss=0.8094\nHWA=0.7192', '\\n', '  New best at epoch 15 with HWA 0.7192', '\\n', 'Test\nCWA=0.714 SWA=0.709 HWA=0.711', '\\n', 'Execution time: 21 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Could not load real SPR_BENCH:', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Epoch 1: validation_loss = 0.9945  HWA = 0.6929', '\\n', '\nNew best model at epoch 1 with HWA 0.6929', '\\n', 'Epoch 2: validation_loss =\n0.9716  HWA = 0.6929', '\\n', 'Epoch 3: validation_loss = 0.9744  HWA = 0.6929',\n'\\n', 'Epoch 4: validation_loss = 0.9717  HWA = 0.6929', '\\n', 'Epoch 5:\nvalidation_loss = 0.9728  HWA = 0.6929', '\\n', 'Epoch 6: validation_loss =\n0.9712  HWA = 0.6929', '\\n', 'Epoch 7: validation_loss = 0.9714  HWA = 0.6929',\n'\\n', 'Epoch 8: validation_loss = 0.9753  HWA = 0.6929', '\\n', 'Epoch 9:\nvalidation_loss = 0.9558  HWA = 0.6929', '\\n', 'Epoch 10: validation_loss =\n0.9467  HWA = 0.6976', '\\n', '  New best model at epoch 10 with HWA 0.6976',\n'\\n', 'Epoch 11: validation_loss = 0.9395  HWA = 0.6916', '\\n', 'Epoch 12:\nvalidation_loss = 0.9296  HWA = 0.6913', '\\n', 'Epoch 13: validation_loss =\n0.9256  HWA = 0.6907', '\\n', 'Epoch 14: validation_loss = 0.9253  HWA = 0.6901',\n'\\n', 'Epoch 15: validation_loss = 0.9053  HWA = 0.6825', '\\n', 'Test CWA=0.712\nSWA=0.709  HWA=0.711', '\\n', 'Execution time: 12 seconds seconds (time limit is\n30 minutes).']", "['Using device: cuda', '\\n', 'Could not load real SPR_BENCH:', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Epoch 1: validation_loss = 0.9722  HWA = 0.6894', '\\n', '\nNew best model at epoch 1 with HWA 0.6894', '\\n', 'Epoch 2: validation_loss =\n0.9401  HWA = 0.6894', '\\n', 'Epoch 3: validation_loss = 0.9358  HWA = 0.6894',\n'\\n', 'Epoch 4: validation_loss = 0.9328  HWA = 0.6894', '\\n', 'Epoch 5:\nvalidation_loss = 0.9340  HWA = 0.6894', '\\n', 'Epoch 6: validation_loss =\n0.9279  HWA = 0.6894', '\\n', 'Epoch 7: validation_loss = 0.9227  HWA = 0.6894',\n'\\n', 'Epoch 8: validation_loss = 0.9169  HWA = 0.6894', '\\n', 'Epoch 9:\nvalidation_loss = 0.9105  HWA = 0.6894', '\\n', 'Epoch 10: validation_loss =\n0.9058  HWA = 0.6847', '\\n', 'Epoch 11: validation_loss = 0.9068  HWA = 0.6813',\n'\\n', 'Epoch 12: validation_loss = 0.8940  HWA = 0.6791', '\\n', 'Epoch 13:\nvalidation_loss = 0.8801  HWA = 0.6822', '\\n', 'Epoch 14: validation_loss =\n0.8739  HWA = 0.6819', '\\n', 'Epoch 15: validation_loss = 0.8673  HWA = 0.6894',\n'\\n', 'Test CWA=0.682  SWA=0.693  HWA=0.687', '\\n', 'Execution time: 9 seconds\nseconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Could not load real SPR_BENCH:', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Epoch 1: validation_loss = 0.9893  HWA = 0.6971', '\\n', '\nNew best model at epoch 1 with HWA 0.6971', '\\n', 'Epoch 2: validation_loss =\n0.9619  HWA = 0.6971', '\\n', 'Epoch 3: validation_loss = 0.9645  HWA = 0.6971',\n'\\n', 'Epoch 4: validation_loss = 0.9692  HWA = 0.6971', '\\n', 'Epoch 5:\nvalidation_loss = 0.9652  HWA = 0.6971', '\\n', 'Epoch 6: validation_loss =\n0.9636  HWA = 0.6971', '\\n', 'Epoch 7: validation_loss = 0.9609  HWA = 0.6971',\n'\\n', 'Epoch 8: validation_loss = 0.9587  HWA = 0.6971', '\\n', 'Epoch 9:\nvalidation_loss = 0.9565  HWA = 0.6971', '\\n', 'Epoch 10: validation_loss =\n0.9498  HWA = 0.6971', '\\n', 'Epoch 11: validation_loss = 0.9440  HWA = 0.6968',\n'\\n', 'Epoch 12: validation_loss = 0.9406  HWA = 0.6956', '\\n', 'Epoch 13:\nvalidation_loss = 0.9337  HWA = 0.6968', '\\n', 'Epoch 14: validation_loss =\n0.9202  HWA = 0.6971', '\\n', 'Epoch 15: validation_loss = 0.9111  HWA = 0.6996',\n'\\n', '  New best model at epoch 15 with HWA 0.6996', '\\n', 'Test CWA=0.729\nSWA=0.728  HWA=0.729', '\\n', 'Execution time: 9 seconds seconds (time limit is\n30 minutes).']", ""], "analysis": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "CWA", "lower_is_better": false, "description": "Composite Weighted Accuracy", "data": [{"dataset_name": "training", "final_value": 0.7311, "best_value": 0.7311}, {"dataset_name": "validation", "final_value": 0.7292, "best_value": 0.7434}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "Simple Weighted Accuracy", "data": [{"dataset_name": "training", "final_value": 0.7284, "best_value": 0.7284}, {"dataset_name": "validation", "final_value": 0.7434, "best_value": 0.7434}]}, {"metric_name": "HWA", "lower_is_better": false, "description": "Harmonic Weighted Accuracy", "data": [{"dataset_name": "training", "final_value": 0.7297, "best_value": 0.7297}, {"dataset_name": "validation", "final_value": 0.7362, "best_value": 0.7362}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss value during training or validation", "data": [{"dataset_name": "training", "final_value": 0.8067, "best_value": 0.8067}, {"dataset_name": "validation", "final_value": 0.87, "best_value": 0.87}]}]}, {"metric_names": [{"metric_name": "CWA", "lower_is_better": false, "description": "The CWA metric measures the accuracy of the model. Higher values are better.", "data": [{"dataset_name": "SPR", "final_value": 0.7219, "best_value": 0.7269}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "The SWA metric measures the accuracy of the model. Higher values are better.", "data": [{"dataset_name": "SPR", "final_value": 0.7119, "best_value": 0.7253}]}, {"metric_name": "HWA", "lower_is_better": false, "description": "The HWA metric measures the accuracy of the model. Higher values are better.", "data": [{"dataset_name": "SPR", "final_value": 0.7169, "best_value": 0.7261}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss measures the error in the model. Lower values are better.", "data": [{"dataset_name": "SPR", "final_value": 0.8173, "best_value": 0.7575}]}, {"metric_name": "accuracy", "lower_is_better": false, "description": "The accuracy metric measures the percentage of correct predictions. Higher values are better.", "data": [{"dataset_name": "SPR", "final_value": 0.65, "best_value": 0.65}]}]}, {"metric_names": [{"metric_name": "CWA", "lower_is_better": false, "description": "CWA measures the weighted accuracy of a model.", "data": [{"dataset_name": "training", "final_value": 0.7315, "best_value": 0.7315}, {"dataset_name": "validation", "final_value": 0.714, "best_value": 0.714}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "SWA measures the smoothed weighted accuracy of a model.", "data": [{"dataset_name": "training", "final_value": 0.7305, "best_value": 0.7305}, {"dataset_name": "validation", "final_value": 0.7086, "best_value": 0.7086}]}, {"metric_name": "HWA", "lower_is_better": false, "description": "HWA measures the harmonic weighted accuracy of a model.", "data": [{"dataset_name": "training", "final_value": 0.731, "best_value": 0.731}, {"dataset_name": "validation", "final_value": 0.7113, "best_value": 0.7113}]}, {"metric_name": "accuracy", "lower_is_better": false, "description": "Accuracy measures the overall correctness of the model's predictions.", "data": [{"dataset_name": "test", "final_value": 0.654, "best_value": 0.654}]}]}, {"metric_names": [{"metric_name": "training CWA", "lower_is_better": false, "description": "Training Correct Weighted Accuracy", "data": [{"dataset_name": "SPR", "final_value": 0.6936, "best_value": 0.6936}]}, {"metric_name": "training SWA", "lower_is_better": false, "description": "Training Simple Weighted Accuracy", "data": [{"dataset_name": "SPR", "final_value": 0.6943, "best_value": 0.6943}]}, {"metric_name": "training HWA", "lower_is_better": false, "description": "Training Harmonic Weighted Accuracy", "data": [{"dataset_name": "SPR", "final_value": 0.6939, "best_value": 0.6939}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "Validation Correct Weighted Accuracy", "data": [{"dataset_name": "SPR", "final_value": 0.73, "best_value": 0.73}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "Validation Simple Weighted Accuracy", "data": [{"dataset_name": "SPR", "final_value": 0.7295, "best_value": 0.7295}]}, {"metric_name": "validation HWA", "lower_is_better": false, "description": "Validation Harmonic Weighted Accuracy", "data": [{"dataset_name": "SPR", "final_value": 0.7297, "best_value": 0.7297}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation Loss", "data": [{"dataset_name": "SPR", "final_value": 0.8711, "best_value": 0.8711}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Test Accuracy", "data": [{"dataset_name": "SPR", "final_value": 0.64, "best_value": 0.64}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss during training phase.", "data": [{"dataset_name": "no_chain_edges", "final_value": 0.849299, "best_value": 0.849299}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss during validation phase.", "data": [{"dataset_name": "no_chain_edges", "final_value": 0.900952, "best_value": 0.900952}]}, {"metric_name": "training CWA", "lower_is_better": false, "description": "The CWA metric during training phase.", "data": [{"dataset_name": "no_chain_edges", "final_value": 0.716572, "best_value": 0.716572}]}, {"metric_name": "training SWA", "lower_is_better": false, "description": "The SWA metric during training phase.", "data": [{"dataset_name": "no_chain_edges", "final_value": 0.720098, "best_value": 0.720098}]}, {"metric_name": "training HWA", "lower_is_better": false, "description": "The HWA metric during training phase.", "data": [{"dataset_name": "no_chain_edges", "final_value": 0.718331, "best_value": 0.718331}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "The CWA metric during validation phase.", "data": [{"dataset_name": "no_chain_edges", "final_value": 0.683584, "best_value": 0.683584}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "The SWA metric during validation phase.", "data": [{"dataset_name": "no_chain_edges", "final_value": 0.687422, "best_value": 0.687422}]}, {"metric_name": "validation HWA", "lower_is_better": false, "description": "The HWA metric during validation phase.", "data": [{"dataset_name": "no_chain_edges", "final_value": 0.685498, "best_value": 0.685498}]}]}, {"metric_names": [{"metric_name": "CWA", "lower_is_better": false, "description": "CWA measures the classification weighted accuracy.", "data": [{"dataset_name": "training", "final_value": 0.7006, "best_value": 0.7006}, {"dataset_name": "validation", "final_value": 0.6941, "best_value": 0.6941}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "SWA measures the smoothed weighted accuracy.", "data": [{"dataset_name": "training", "final_value": 0.6994, "best_value": 0.6994}, {"dataset_name": "validation", "final_value": 0.6949, "best_value": 0.6949}]}, {"metric_name": "HWA", "lower_is_better": false, "description": "HWA measures the harmonic weighted accuracy.", "data": [{"dataset_name": "training", "final_value": 0.7, "best_value": 0.7}, {"dataset_name": "validation", "final_value": 0.6945, "best_value": 0.6945}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss measures the error in prediction.", "data": [{"dataset_name": "training", "final_value": 0.8465, "best_value": 0.8465}, {"dataset_name": "validation", "final_value": 0.8524, "best_value": 0.8524}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Final loss value during training", "data": [{"dataset_name": "NoNodeFeatures - SPR", "final_value": 1.164, "best_value": 1.164}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final loss value during validation", "data": [{"dataset_name": "NoNodeFeatures - SPR", "final_value": 1.161, "best_value": 1.161}]}, {"metric_name": "training CWA", "lower_is_better": false, "description": "Final CWA value during training", "data": [{"dataset_name": "NoNodeFeatures - SPR", "final_value": 0.7034, "best_value": 0.7034}]}, {"metric_name": "training SWA", "lower_is_better": false, "description": "Final SWA value during training", "data": [{"dataset_name": "NoNodeFeatures - SPR", "final_value": 0.6979, "best_value": 0.6979}]}, {"metric_name": "training HWA", "lower_is_better": false, "description": "Final HWA value during training", "data": [{"dataset_name": "NoNodeFeatures - SPR", "final_value": 0.7007, "best_value": 0.7007}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "Final CWA value during validation", "data": [{"dataset_name": "NoNodeFeatures - SPR", "final_value": 0.7001, "best_value": 0.7001}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "Final SWA value during validation", "data": [{"dataset_name": "NoNodeFeatures - SPR", "final_value": 0.6969, "best_value": 0.6969}]}, {"metric_name": "validation HWA", "lower_is_better": false, "description": "Final HWA value during validation", "data": [{"dataset_name": "NoNodeFeatures - SPR", "final_value": 0.6985, "best_value": 0.6985}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the error between predicted and actual values. Lower values indicate better performance.", "data": [{"dataset_name": "Training set", "final_value": 0.8733, "best_value": 0.8733}, {"dataset_name": "Validation set", "final_value": 1.0163, "best_value": 1.0163}]}, {"metric_name": "CWA (Class Weighted Accuracy)", "lower_is_better": false, "description": "Class Weighted Accuracy metric, higher values are better.", "data": [{"dataset_name": "Training set", "final_value": 0.7146, "best_value": 0.7146}, {"dataset_name": "Validation set", "final_value": 0.7079, "best_value": 0.7079}]}, {"metric_name": "SWA (Sample Weighted Accuracy)", "lower_is_better": false, "description": "Sample Weighted Accuracy metric, higher values are better.", "data": [{"dataset_name": "Training set", "final_value": 0.7152, "best_value": 0.7152}, {"dataset_name": "Validation set", "final_value": 0.7007, "best_value": 0.7007}]}, {"metric_name": "HWA (Hybrid Weighted Accuracy)", "lower_is_better": false, "description": "Hybrid Weighted Accuracy metric, higher values are better.", "data": [{"dataset_name": "Training set", "final_value": 0.7149, "best_value": 0.7149}, {"dataset_name": "Validation set", "final_value": 0.7043, "best_value": 0.7043}]}, {"metric_name": "accuracy", "lower_is_better": false, "description": "Overall accuracy metric, higher values are better.", "data": [{"dataset_name": "Test set", "final_value": 0.636, "best_value": 0.636}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the error in predictions. Lower values indicate better performance.", "data": [{"dataset_name": "training set", "final_value": 0.8133, "best_value": 0.8133}, {"dataset_name": "validation set", "final_value": 0.8094, "best_value": 0.8094}]}, {"metric_name": "CWA", "lower_is_better": false, "description": "Custom Weighted Accuracy. Higher values indicate better accuracy.", "data": [{"dataset_name": "training set", "final_value": 0.7231, "best_value": 0.7231}, {"dataset_name": "validation set", "final_value": 0.7202, "best_value": 0.7202}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "Smoothed Weighted Accuracy. Higher values indicate better accuracy.", "data": [{"dataset_name": "training set", "final_value": 0.7197, "best_value": 0.7197}, {"dataset_name": "validation set", "final_value": 0.7183, "best_value": 0.7183}]}, {"metric_name": "HWA", "lower_is_better": false, "description": "Harmonic Weighted Accuracy. Higher values indicate better accuracy.", "data": [{"dataset_name": "training set", "final_value": 0.7214, "best_value": 0.7214}, {"dataset_name": "validation set", "final_value": 0.7192, "best_value": 0.7192}]}, {"metric_name": "accuracy", "lower_is_better": false, "description": "Measures the overall correctness of the predictions. Higher values indicate better performance.", "data": [{"dataset_name": "test set", "final_value": 0.654, "best_value": 0.654}]}]}, {"metric_names": [{"metric_name": "CWA", "lower_is_better": false, "description": "Metric measuring the weighted accuracy of predictions.", "data": [{"dataset_name": "training", "final_value": 0.7121, "best_value": 0.7121}, {"dataset_name": "validation", "final_value": 0.6972, "best_value": 0.6972}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "Smoothed weighted accuracy metric.", "data": [{"dataset_name": "training", "final_value": 0.7142, "best_value": 0.7142}, {"dataset_name": "validation", "final_value": 0.698, "best_value": 0.698}]}, {"metric_name": "HWA", "lower_is_better": false, "description": "Harmonic weighted accuracy metric.", "data": [{"dataset_name": "training", "final_value": 0.7132, "best_value": 0.7132}, {"dataset_name": "validation", "final_value": 0.6976, "best_value": 0.6976}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss function value during training or validation.", "data": [{"dataset_name": "training", "final_value": 0.8522, "best_value": 0.8522}, {"dataset_name": "validation", "final_value": 0.9467, "best_value": 0.9467}]}]}, {"metric_names": [{"metric_name": "CWA", "lower_is_better": false, "description": "A metric used to evaluate the performance of a model.", "data": [{"dataset_name": "training", "final_value": 0.7083, "best_value": 0.7083}, {"dataset_name": "validation", "final_value": 0.694, "best_value": 0.694}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "Another metric used to evaluate the performance of a model.", "data": [{"dataset_name": "training", "final_value": 0.7067, "best_value": 0.7067}, {"dataset_name": "validation", "final_value": 0.6849, "best_value": 0.6849}]}, {"metric_name": "HWA", "lower_is_better": false, "description": "A third metric for evaluating model performance.", "data": [{"dataset_name": "training", "final_value": 0.7075, "best_value": 0.7075}, {"dataset_name": "validation", "final_value": 0.6894, "best_value": 0.6894}]}, {"metric_name": "loss", "lower_is_better": true, "description": "A measure of error in the model's predictions.", "data": [{"dataset_name": "training", "final_value": 0.7952, "best_value": 0.7952}, {"dataset_name": "validation", "final_value": 0.9722, "best_value": 0.9722}]}]}, {"metric_names": [{"metric_name": "CWA", "lower_is_better": false, "description": "CWA measures the weighted average of correct predictions.", "data": [{"dataset_name": "training", "final_value": 0.7157, "best_value": 0.7157}, {"dataset_name": "validation", "final_value": 0.6964, "best_value": 0.6964}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "SWA measures the smoothed weighted average of predictions.", "data": [{"dataset_name": "training", "final_value": 0.7163, "best_value": 0.7163}, {"dataset_name": "validation", "final_value": 0.7028, "best_value": 0.7028}]}, {"metric_name": "HWA", "lower_is_better": false, "description": "HWA measures the harmonic weighted average of predictions.", "data": [{"dataset_name": "training", "final_value": 0.716, "best_value": 0.716}, {"dataset_name": "validation", "final_value": 0.6996, "best_value": 0.6996}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss measures the error or deviation from the expected outcome.", "data": [{"dataset_name": "training", "final_value": 0.8483, "best_value": 0.8483}, {"dataset_name": "validation", "final_value": 0.9111, "best_value": 0.9111}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [true, false, false, false, false, false, false, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/val_loss.png", "../../logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_loss_curve.png", "../../logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_HWA_curve.png", "../../logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_confusion_matrix.png", "../../logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_final_val_metrics.png"], ["../../logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/val_loss.png", "../../logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_loss_curve.png", "../../logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_HWA_curve.png", "../../logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_CWA_curve.png", "../../logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/val_loss.png", "../../logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_loss_curves.png", "../../logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_CWA_curves.png", "../../logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_SWA_curves.png", "../../logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_HWA_curves.png", "../../logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/val_loss.png", "../../logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/SPR_loss_curves_NoMultiHead.png", "../../logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/SPR_val_metrics_NoMultiHead.png", "../../logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/SPR_confusion_matrix_NoMultiHead.png"], ["../../logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/val_loss.png", "../../logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/no_chain_edges_SPR_loss_curves.png", "../../logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/no_chain_edges_SPR_HWA_curves.png", "../../logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/no_chain_edges_SPR_test_label_dist.png"], ["../../logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/val_loss.png", "../../logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_loss_curves.png", "../../logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_CWA_curves.png", "../../logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_SWA_curves.png", "../../logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_HWA_curves.png", "../../logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/val_loss.png", "../../logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_loss_curve.png", "../../logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_hwa_curve.png", "../../logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_scatter_gt_vs_pred.png", "../../logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_class_dist.png"], ["../../logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/val_loss.png", "../../logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/SPR_loss_curve.png", "../../logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/SPR_hwa_curve.png", "../../logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/SPR_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/val_loss.png", "../../logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/SPR_NoColorEmbedding_loss_curves.png", "../../logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/SPR_NoColorEmbedding_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/SPR_NoColorEmbedding_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/val_loss.png", "../../logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_loss_curve.png", "../../logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_HWA_curve.png", "../../logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_confusion_matrix.png", "../../logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_final_val_metrics.png"], ["../../logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/val_loss.png", "../../logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_loss_curve.png", "../../logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_HWA_curve.png", "../../logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_confusion_matrix.png", "../../logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_final_val_metrics.png"], ["../../logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/val_loss.png", "../../logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_loss_curve.png", "../../logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_HWA_curve.png", "../../logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_confusion_matrix.png", "../../logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_final_val_metrics.png"], ["../../logs/0-run/experiment_results/seed_aggregation_846df7be51804a2da06e2b8d365b7c7d/SPR_agg_loss_curve.png", "../../logs/0-run/experiment_results/seed_aggregation_846df7be51804a2da06e2b8d365b7c7d/SPR_agg_HWA_curve.png", "../../logs/0-run/experiment_results/seed_aggregation_846df7be51804a2da06e2b8d365b7c7d/SPR_agg_final_val_metrics.png", "../../logs/0-run/experiment_results/seed_aggregation_846df7be51804a2da06e2b8d365b7c7d/SPR_agg_confusion_matrix.png"]], "plot_paths": [["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_loss_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_HWA_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_confusion_matrix.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_final_val_metrics.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_loss_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_HWA_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_CWA_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_SWA_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_confusion_matrix.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_loss_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_CWA_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_SWA_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_HWA_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_confusion_matrix.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/SPR_loss_curves_NoMultiHead.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/SPR_val_metrics_NoMultiHead.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/SPR_confusion_matrix_NoMultiHead.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/no_chain_edges_SPR_loss_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/no_chain_edges_SPR_HWA_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/no_chain_edges_SPR_test_label_dist.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_loss_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_CWA_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_SWA_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_HWA_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_confusion_matrix.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_loss_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_hwa_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_scatter_gt_vs_pred.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_class_dist.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/SPR_loss_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/SPR_hwa_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/SPR_test_metrics.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/SPR_NoColorEmbedding_loss_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/SPR_NoColorEmbedding_hwa_curves.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/SPR_NoColorEmbedding_confusion_matrix.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_loss_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_HWA_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_confusion_matrix.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_final_val_metrics.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_loss_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_HWA_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_confusion_matrix.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_final_val_metrics.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/val_loss.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_loss_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_HWA_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_confusion_matrix.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_final_val_metrics.png"], ["experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_846df7be51804a2da06e2b8d365b7c7d/SPR_agg_loss_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_846df7be51804a2da06e2b8d365b7c7d/SPR_agg_HWA_curve.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_846df7be51804a2da06e2b8d365b7c7d/SPR_agg_final_val_metrics.png", "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_846df7be51804a2da06e2b8d365b7c7d/SPR_agg_confusion_matrix.png"]], "plot_analyses": [[{"analysis": "The validation loss curve shows a general downward trend, indicating that the model is learning and improving its performance over the epochs. However, there are some fluctuations, which could be caused by overfitting or noise in the validation set. The steady decline towards the end suggests that the model is converging.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/val_loss.png"}, {"analysis": "The comparison between training and validation loss indicates that both losses are decreasing over time, which is a positive sign of effective learning. The gap between the two curves is relatively small, suggesting that the model is not overfitting significantly. However, the validation loss seems to plateau slightly towards the end, which might indicate that further improvements are limited without additional regularization or tuning.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_loss_curve.png"}, {"analysis": "The HWA (Harmonic Weighted Accuracy) plot shows an increasing trend for both training and validation metrics, suggesting that the model is improving its ability to generalize. The sharp fluctuations in validation HWA around epochs 10-12 may indicate sensitivity to specific data points or instability in the optimization process. Overall, the improvement in validation HWA aligns with the training progress.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_HWA_curve.png"}, {"analysis": "The confusion matrix highlights the model's performance across different classes. The majority of predictions are accurate for the dominant class, but there are noticeable misclassifications for less frequent classes. This suggests a potential imbalance in class representation or a need for improved handling of minority classes.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_confusion_matrix.png"}, {"analysis": "The final validation metrics indicate strong performance across all three metrics (CWA, SWA, and HWA), with values exceeding 70%. This suggests that the model is competitive with or surpassing the current SOTA benchmarks. The consistent performance across metrics demonstrates the model's balanced ability to capture both color- and shape-based relationships.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8b962da3fdf44a4d9a34cf0e2e4c5922_proc_1517534/SPR_final_val_metrics.png"}], [{"analysis": "The validation loss curve shows a steady decrease in loss from epoch 1 to epoch 14, with a sharp drop after epoch 10. This suggests that the model is learning effectively and generalizing better to the validation data over time. The small increase at the end may indicate the start of overfitting or noise in the validation data.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/val_loss.png"}, {"analysis": "The loss curve for both training and validation sets indicates that the model is converging. The training loss decreases sharply initially and continues to decline, while the validation loss follows a similar pattern but remains slightly higher, which is expected. The overlap of the curves at later epochs suggests that the model is not overfitting significantly.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_loss_curve.png"}, {"analysis": "The HWA curve shows an increase in both training and validation performance after epoch 10, with a steep rise towards the end. This indicates that the model is improving in its ability to capture shape-weighted accuracy, particularly in the latter epochs, which aligns with the sharp drop in loss.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_HWA_curve.png"}, {"analysis": "The CWA curve demonstrates a similar trend as the HWA curve, with a significant improvement in both training and validation accuracy after epoch 10. This reflects the model's increased ability to capture color-weighted accuracy, further confirming its learning progress.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_CWA_curve.png"}, {"analysis": "The SWA curve highlights the model's performance in shape-weighted accuracy, showing a consistent improvement after epoch 10 for both training and validation sets. The steep rise at the end indicates strong learning in this aspect, similar to the HWA and CWA curves.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_SWA_curve.png"}, {"analysis": "The confusion matrix shows that the model performs well on certain classes while struggling with others. The diagonal dominance suggests good overall classification performance, but the off-diagonal entries indicate some misclassifications, which could be addressed through further fine-tuning or data augmentation.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_562571aba5894ebe8c71b875e71fc68c_proc_1520778/SPR_confusion_matrix.png"}], [{"analysis": "This plot shows the validation loss for the No-POS (No Position Embedding) model over 15 epochs. The validation loss decreases steadily, indicating that the model is learning and generalizing well to the validation dataset. The consistent decline suggests no signs of overfitting or underfitting, which is promising for the model's performance.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/val_loss.png"}, {"analysis": "This plot compares the training and validation loss for the No-POS model. Both curves decrease over epochs, with the training loss declining more rapidly initially. The close alignment of the training and validation losses suggests that the model is not overfitting and is generalizing well. However, the slower decrease in validation loss compared to training loss may indicate room for further optimization.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_loss_curves.png"}, {"analysis": "This plot presents the Color-Weighted Accuracy (CWA) for the No-POS model on both the training and validation datasets. The training accuracy shows a significant upward trend in the later epochs, while the validation accuracy remains relatively flat with minor fluctuations. This discrepancy may suggest that the model is learning color-related patterns in the training data but is struggling to generalize these patterns to unseen validation data.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_CWA_curves.png"}, {"analysis": "This plot shows the Shape-Weighted Accuracy (SWA) for the No-POS model on the training and validation datasets. Similar to the CWA plot, the training accuracy improves significantly over epochs, while the validation accuracy remains almost flat with minor variations. This behavior indicates that the model might be overfitting to the shape-related patterns in the training data.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_SWA_curves.png"}, {"analysis": "This plot illustrates the HWA (possibly Hybrid Weighted Accuracy) for the No-POS model. The training accuracy increases significantly over epochs, while the validation accuracy stays flat with minor fluctuations. This consistent pattern across CWA, SWA, and HWA metrics suggests that while the model is learning effectively on the training data, its generalization to validation data is limited. Further regularization or data augmentation might be needed.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_HWA_curves.png"}, {"analysis": "This confusion matrix shows the performance of the No-POS model on the validation dataset. The model predicts the majority class (label 0) with high accuracy, but performance on other classes is poor, with significant misclassifications. This imbalance indicates that the model might be biased toward the majority class and struggles to differentiate between minority classes. Addressing class imbalance in the dataset or using techniques like weighted loss functions could improve performance.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9e95618dbe04048a21e1c8181e012a2_proc_1520779/SPR_NoPOS_confusion_matrix.png"}], [{"analysis": "The validation loss curve shows a steady decrease over the epochs, indicating that the model is learning effectively. However, the curve does not plateau, suggesting that the model might benefit from more epochs or additional regularization to ensure convergence.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/val_loss.png"}, {"analysis": "The comparison between training and validation loss reveals that both losses decrease consistently, with no signs of overfitting or underfitting. The validation loss is slightly higher than the training loss, which is expected in a well-trained model.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/SPR_loss_curves_NoMultiHead.png"}, {"analysis": "The validation metrics (CWA, SWA, and HWA) show a sudden increase around epoch 8, followed by some fluctuations. This suggests that the model experiences a significant improvement in performance after a certain point in training, but the fluctuations indicate potential instability or sensitivity to certain training dynamics.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/SPR_val_metrics_NoMultiHead.png"}, {"analysis": "The confusion matrix for the test set reveals that the model performs well for the majority class (dark blue), but struggles with some of the less frequent classes, as indicated by lighter shades. This highlights an imbalance in prediction performance across classes, possibly due to class imbalance in the dataset.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_18a61f2d7e7b4af586add0b913645ccd_proc_1520780/SPR_confusion_matrix_NoMultiHead.png"}], [{"analysis": "The validation loss is steadily decreasing over the epochs, indicating that the model is learning effectively without overfitting. The absence of chain edges does not seem to hinder the model's ability to generalize as the validation loss consistently improves.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/val_loss.png"}, {"analysis": "The training loss decreases more rapidly than the validation loss, which is expected as the model optimizes on the training data. The gap between training and validation loss remains small, suggesting that the model is not overfitting and is generalizing well to unseen data.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/no_chain_edges_SPR_loss_curves.png"}, {"analysis": "The harmonic weighted accuracy (HWA) on the training data remains stable, while the validation HWA shows a gradual improvement, peaking at epoch 14. This indicates that the model's performance on the validation set improves over time, reaching its best at the final epoch.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/no_chain_edges_SPR_HWA_curves.png"}, {"analysis": "The test label distribution shows that the model predictions are skewed towards class 0, while the ground truth has a more balanced distribution. This suggests that the model may be biased towards predicting the majority class, which could be addressed by balancing the training data or using class-weighted loss functions.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_49a3cef1011a47dc8305e88cf81fa953_proc_1520781/no_chain_edges_SPR_test_label_dist.png"}], [{"analysis": "This plot shows a consistent decrease in validation loss across epochs, indicating that the model is learning effectively during training. The absence of significant fluctuations suggests stable training dynamics for the NoBiDir configuration.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/val_loss.png"}, {"analysis": "This plot compares the training and validation losses across epochs. Both curves show a steady decline, with the training loss being slightly lower than the validation loss. The gap between the two curves remains small, indicating good generalization without overfitting.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_loss_curves.png"}, {"analysis": "This plot shows the Color-Weighted Accuracy (CWA) for both training and validation sets over epochs. While the training accuracy remains relatively stable, the validation accuracy shows a significant improvement after epoch 12, indicating that the model is better capturing color-related dependencies in the validation set.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_CWA_curves.png"}, {"analysis": "This plot illustrates the Shape-Weighted Accuracy (SWA) for both training and validation sets. Similar to the CWA plot, the training SWA is stable, while the validation SWA improves significantly after epoch 12. This suggests that the model is learning to generalize better to unseen data for shape-related patterns.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_SWA_curves.png"}, {"analysis": "This plot displays the Hybrid-Weighted Accuracy (HWA) for both training and validation sets. The trend mirrors the CWA and SWA plots, with training accuracy remaining stable and validation accuracy showing a sharp increase after epoch 12. This indicates an overall improvement in the model's ability to generalize across both color and shape features.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_HWA_curves.png"}, {"analysis": "The confusion matrix demonstrates the model's performance on the test set. The darker diagonal indicates that the model is correctly classifying most samples, but there are some off-diagonal elements, suggesting misclassifications. The distribution of errors could provide insights into specific areas where the model struggles.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_bcd63e121ae841b18f5010309cc1eb87_proc_1520779/NoBiDir_SPR_confusion_matrix.png"}], [{"analysis": "The validation loss steadily decreases over the epochs, indicating that the model is learning effectively and improving its performance on unseen data. The smooth decline suggests a stable training process without significant overfitting or underfitting.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/val_loss.png"}, {"analysis": "Both training and validation loss curves show a consistent decline and are closely aligned, which indicates that the model is generalizing well to unseen data. The lack of a significant gap between the two curves suggests minimal overfitting. The consistent downward trend is a positive sign of effective training.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_loss_curve.png"}, {"analysis": "The HWA (Hypothetical Weighted Accuracy) curves for both training and validation show a rapid increase during the initial epochs, followed by stabilization at a high value. This pattern indicates that the model quickly learns to classify the data effectively and maintains its performance over subsequent epochs. The close alignment of training and validation curves suggests good generalization.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_hwa_curve.png"}, {"analysis": "The scatter plot shows the alignment between the predicted values and ground truth. The clustering of points around the diagonal line indicates that the model's predictions are generally accurate. However, there appear to be some deviations, especially for certain classes, which might point to areas where the model's performance could be improved.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_scatter_gt_vs_pred.png"}, {"analysis": "The class distribution plot indicates a mismatch between the ground truth and predicted class distributions. While the model performs well for the majority class, its performance on minority classes appears suboptimal. This imbalance suggests that the model may need to be fine-tuned or trained with techniques to handle class imbalance more effectively.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5ab6eed00cd3481ab33abe944963a4bc_proc_1520781/NoNodeFeatures_SPR_class_dist.png"}], [{"analysis": "The validation loss decreases steadily over the epochs, indicating that the model is learning effectively and generalizing well to the validation data. The consistent downward trend suggests that the 1-Hop GAT architecture is suitable for the task and is not overfitting.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/val_loss.png"}, {"analysis": "The training and validation loss curves both decrease over the epochs, with the training loss being slightly lower than the validation loss. This indicates that the model is converging well, and there is no significant overfitting. The close alignment of the two curves demonstrates effective generalization.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/SPR_loss_curve.png"}, {"analysis": "The training Harmonic Weighted Accuracy (HWA) improves rapidly and stabilizes, while the validation HWA remains mostly flat. This suggests that while the model is effectively learning patterns in the training data, its ability to generalize to unseen validation data is limited. The drop at the end for validation HWA might indicate some overfitting or instability.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/SPR_hwa_curve.png"}, {"analysis": "The test metrics show that the model achieves relatively high performance across the three metrics: Color-Weighted Accuracy (CWA), Shape-Weighted Accuracy (SWA), and Harmonic Weighted Accuracy (HWA). This indicates that the model is performing well on the test set and is capturing both color and shape variations effectively. However, the metrics are slightly lower than optimal, suggesting room for further improvement.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_06151e27405145618c565b94704b728d_proc_1520778/SPR_test_metrics.png"}], [{"analysis": "This plot shows the validation loss curve for a model trained without color embeddings. The validation loss steadily decreases over the epochs, indicating that the model is learning and improving its generalization capability. The smooth and consistent decline suggests that the training process is stable and the model is not overfitting. However, the final validation loss of approximately 0.82 suggests there might still be room for further optimization.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/val_loss.png"}, {"analysis": "This plot compares the training and validation loss curves for the model trained without color embeddings. Both curves decrease consistently, with the training loss slightly lower than the validation loss across epochs. This indicates that the model is learning effectively and generalizing reasonably well. The convergence of the two curves towards the end suggests that the model is not significantly overfitting, but the gap between training and validation loss could be reduced further.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/SPR_NoColorEmbedding_loss_curves.png"}, {"analysis": "This plot displays the HWA (Hypothetical Weighted Accuracy) metric for both training and validation datasets across epochs. The training HWA remains relatively stable with slight improvements, while the validation HWA shows a significant increase after epoch 8. This indicates that the model's generalization ability improves considerably in the later stages of training. However, the fluctuations in the validation HWA towards the end suggest potential instability, which may need further investigation.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/SPR_NoColorEmbedding_hwa_curves.png"}, {"analysis": "This confusion matrix represents the model's performance on the test set for different classes. Class 0 has the highest number of correctly predicted samples, while other classes (e.g., 1, 2, and 3) show significant misclassifications. The model struggles particularly with classes 1 and 3, as indicated by the absence of correct predictions for these classes. This imbalance in performance across classes suggests that the model may need better handling of class-specific features or rebalancing of the training dataset.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_870e273b393142b49f2e915d38666577_proc_1520780/SPR_NoColorEmbedding_confusion_matrix.png"}], [{"analysis": "The validation loss curve shows a gradual decline over the epochs, indicating that the model is learning and improving its performance on the validation dataset. The drop in validation loss towards the end also suggests that the model has not yet overfitted and is still generalizing well to unseen data.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/val_loss.png"}, {"analysis": "The comparison of training and validation loss reveals that both losses are decreasing over the epochs, with the training loss decreasing more rapidly. The gap between the two losses is relatively small, indicating that the model is not overfitting. However, the slower decline in validation loss compared to training loss suggests that further tuning might improve generalization.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_loss_curve.png"}, {"analysis": "The HWA (Harmonic Weighted Accuracy) plot shows that the training HWA remains stable throughout, while the validation HWA fluctuates slightly and exhibits a drop towards the end. This drop in validation HWA may indicate that the model struggles to maintain consistent performance on the validation set as training progresses, possibly requiring better regularization or hyperparameter tuning.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_HWA_curve.png"}, {"analysis": "The confusion matrix reveals that the model predicts the majority class (class 0) correctly with high accuracy, but struggles with other classes, as evidenced by the misclassifications in classes 1, 2, and 3. This imbalance suggests that the model may be biased towards the majority class, and techniques like class weighting or oversampling of minority classes could be beneficial.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_confusion_matrix.png"}, {"analysis": "The final validation metrics for CWA, SWA, and HWA are all approximately 0.7, indicating moderate performance across these metrics. While the results are promising, further improvements in model architecture or training strategies may be necessary to achieve SOTA performance.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/SPR_final_val_metrics.png"}], [{"analysis": "The validation loss curve shows a steady and consistent decline over the epochs, indicating that the model is learning effectively and generalizing well to the validation set. The absence of any plateau or increase in validation loss suggests that overfitting is not occurring within the observed epochs.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/val_loss.png"}, {"analysis": "The comparison of train and validation loss curves demonstrates that both metrics are decreasing steadily. The close alignment between the two curves indicates that the model is not overfitting and is maintaining good generalization. The gap between training and validation loss remains narrow, which is a positive sign of the model's robustness.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_loss_curve.png"}, {"analysis": "The HWA (Harmonic Weighted Accuracy) for both training and validation sets shows an upward trend. The training HWA increases more rapidly, while the validation HWA follows a slower, consistent improvement. The convergence of these metrics suggests that the model is improving its ability to generalize across the dataset.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_HWA_curve.png"}, {"analysis": "The confusion matrix reveals class imbalance issues, with the majority of predictions concentrated in one class. This indicates that the model struggles to distinguish between certain classes, likely due to insufficient training samples for the underrepresented categories. Addressing this imbalance could improve overall performance.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_confusion_matrix.png"}, {"analysis": "The final validation metrics for CWA, SWA, and HWA are all approximately equal, with values around 0.7. This uniformity suggests that the model performs consistently across different evaluation criteria, which is a favorable outcome for the Synthetic PolyRule Reasoning task.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/SPR_final_val_metrics.png"}], [{"analysis": "The validation loss curve shows a steady decrease over the epochs, indicating that the model is learning effectively and generalizing better to unseen data. The consistent downward trend suggests that the training process is stable and there are no signs of overfitting or underfitting at this stage.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/val_loss.png"}, {"analysis": "The comparison of training and validation loss highlights a steady decrease in both metrics over the epochs. The gap between the two curves is minimal, which suggests that the model is not overfitting to the training data. However, the validation loss curve plateaus slightly after the initial drop, which might indicate a need for further fine-tuning of hyperparameters to achieve better generalization.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_loss_curve.png"}, {"analysis": "The Harmonic Weighted Accuracy (HWA) plot demonstrates a clear upward trend for training accuracy, while the validation accuracy remains relatively stable with slight improvements. This stability in validation HWA indicates that the model is maintaining its ability to generalize well to unseen data, although the gap between training and validation accuracy suggests that further optimization might be necessary.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_HWA_curve.png"}, {"analysis": "The confusion matrix reveals that the model performs well on the majority class (ground truth label 0) with minimal misclassifications. However, there is noticeable confusion among other classes, particularly for labels 1 and 2. This imbalance highlights potential issues with class representation in the dataset or the need for improved handling of minority classes by the model.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_confusion_matrix.png"}, {"analysis": "The final validation metrics for CWA, SWA, and HWA are all around 0.7, which indicates a balanced performance across the different evaluation criteria. This consistency suggests that the model is robust and performs well across the various aspects of the task. However, achieving further improvements in these metrics could make the model more competitive with the state-of-the-art.", "plot_path": "experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/SPR_final_val_metrics.png"}], []], "vlm_feedback_summary": ["The plots provide valuable insights into the model's training and evaluation\nprocess. The validation loss and accuracy metrics show consistent improvement,\nindicating effective learning. The confusion matrix highlights areas for\npotential improvement in handling minority classes. Overall, the results suggest\nthat the model is performing well, with competitive final metrics.", "The experimental results demonstrate consistent improvements in loss and\naccuracy metrics, particularly after epoch 10. The validation loss aligns\nclosely with the training loss, indicating minimal overfitting. The sharp rise\nin HWA, CWA, and SWA metrics towards the end suggests that the model is\neffectively learning the underlying patterns in the data. The confusion matrix\nhighlights areas of strength and potential improvement in classification\nperformance.", "The provided plots reveal that the No-POS model demonstrates effective learning\non the training data, as evidenced by decreasing training loss and increasing\ntraining accuracies across metrics. However, the model struggles to generalize\nwell, as validation accuracies remain flat and the confusion matrix highlights\npoor performance on minority classes. These findings suggest the need for\nfurther optimization, such as better regularization, data augmentation, or\naddressing class imbalance.", "The plots indicate that the model is learning effectively, with both training\nand validation losses decreasing steadily. However, the validation metrics show\nsome instability, and the confusion matrix highlights potential issues with\nclass imbalance. Further experiments could focus on stabilizing metric\nperformance and addressing class imbalance.", "The plots indicate steady improvement in validation loss and harmonic weighted\naccuracy (HWA), suggesting effective learning and generalization. However, the\ntest label distribution highlights a class imbalance issue in model predictions.", "The plots indicate that the NoBiDir configuration is effective, with consistent\ndecreases in loss and improvements in accuracy metrics. Validation performance\nshows significant gains after epoch 12, suggesting that the model is learning to\ngeneralize well. The confusion matrix highlights areas for further refinement to\naddress misclassifications.", "The plots indicate that the model is learning effectively and generalizing well,\nas evidenced by the steady decline in loss and the alignment of training and\nvalidation metrics. However, there are areas for improvement, particularly in\nhandling class imbalances and improving accuracy for minority classes.", "The provided plots indicate that the 1-Hop GAT model is learning effectively,\nwith decreasing loss and strong performance on test metrics. However, there are\nsigns of limited generalization and potential overfitting, particularly in the\nharmonic weighted accuracy for the validation set.", "The plots provide a comprehensive view of the model's performance. The\nvalidation loss curves indicate stable learning, while the HWA metric shows\nsignificant improvements in generalization after epoch 8. However, the confusion\nmatrix highlights challenges with certain classes, suggesting the need for\nfurther optimization or data rebalancing.", "The provided plots indicate that the model is learning effectively, as seen in\nthe decreasing loss curves. However, fluctuations in validation HWA and the\nconfusion matrix's class imbalance highlight areas for improvement. The final\nmetrics suggest moderate success but leave room for further optimization to meet\nSOTA benchmarks.", "The experimental results indicate steady and consistent model improvements\nacross training and validation datasets. The validation loss and accuracy\nmetrics confirm effective learning and generalization. However, the confusion\nmatrix highlights class imbalance issues that require attention. Overall, the\nmodel demonstrates promising performance for the Synthetic PolyRule Reasoning\ntask.", "The plots collectively indicate that the model is learning effectively, with\nsteady improvements in loss and accuracy metrics. The validation metrics are\nconsistent and suggest robustness, although there is room for optimization to\naddress class imbalance and further enhance performance.", "[]"], "exec_time": [20.815929412841797, 27.86164355278015, 7.886969804763794, 8.523389339447021, 15.848628997802734, 13.635037899017334, 9.97506856918335, 8.415565252304077, 21.368807554244995, 12.562502145767212, 9.109788179397583, 9.65843653678894, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[\"SPR\"]"], ["[\"remove_similarity_edges\"]"], ["\"\""], ["[\"SPR\"]"], ["[\"dataset_name\"]"], ["[\"NoBiDir SPR\"]"], ["['plot 1'", "'plot 2'", "'plot 3']"], ["[\"SPR\"]"], ["[]"], ["[\"SPR\"]"], ["['SPR']"], ["[\"SPR\"]"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------ #\n# basic set-up\n# ------------------------------------------------------------------ #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ned = experiment_data.get(\"SPR\", {})\nepochs = ed.get(\"epochs\", [])\nloss_tr = ed.get(\"losses\", {}).get(\"train\", [])\nloss_val = ed.get(\"losses\", {}).get(\"val\", [])\nhwa_tr = [m.get(\"HWA\", np.nan) for m in ed.get(\"metrics\", {}).get(\"train\", [])]\nhwa_val = [m.get(\"HWA\", np.nan) for m in ed.get(\"metrics\", {}).get(\"val\", [])]\npreds = np.asarray(ed.get(\"predictions\", []), dtype=int)\ngts = np.asarray(ed.get(\"ground_truth\", []), dtype=int)\n\n# ------------------------------------------------------------------ #\n# 1) Train / Val loss curve\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    plt.plot(epochs, loss_tr, label=\"Train\")\n    plt.plot(epochs, loss_val, label=\"Val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR \u2013 Train vs Val Loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_loss_curve.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 2) Train / Val HWA curve\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    plt.plot(epochs, hwa_tr, label=\"Train HWA\")\n    plt.plot(epochs, hwa_val, label=\"Val HWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"HWA\")\n    plt.title(\"SPR \u2013 Train vs Val HWA\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_HWA_curve.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curve: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 3) Confusion matrix on test set\n# ------------------------------------------------------------------ #\ntry:\n    if preds.size and gts.size:\n        n_cls = int(max(preds.max(), gts.max()) + 1)\n        cm = np.zeros((n_cls, n_cls), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR \u2013 Confusion Matrix\\nLeft: Ground Truth, Right: Predicted\")\n        for i in range(n_cls):\n            for j in range(n_cls):\n                plt.text(\n                    j,\n                    i,\n                    cm[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                    fontsize=8,\n                )\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_confusion_matrix.png\"), dpi=150)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 4) Final CWA / SWA / HWA bar chart\n# ------------------------------------------------------------------ #\ntry:\n    if hwa_val:\n        cwa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"CWA\", np.nan)\n        swa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"SWA\", np.nan)\n        hwa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"HWA\", np.nan)\n        cats = [\"CWA\", \"SWA\", \"HWA\"]\n        vals = [cwa_last, swa_last, hwa_last]\n        plt.figure()\n        plt.bar(cats, vals, color=[\"#4c72b0\", \"#55a868\", \"#c44e52\"])\n        plt.ylabel(\"Metric Value\")\n        plt.title(\"SPR \u2013 Final Validation Metrics\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_final_val_metrics.png\"), dpi=150)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating metric bar chart: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# Print simple evaluation metric\n# ------------------------------------------------------------------ #\nif preds.size and gts.size:\n    accuracy = (preds == gts).mean()\n    print(f\"Test accuracy: {accuracy:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- load experiment data -------- #\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    spr = experiment_data[\"remove_similarity_edges\"][\"SPR\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    spr = None\n\nif spr:\n    epochs = spr[\"epochs\"]\n    loss_tr, loss_val = spr[\"losses\"][\"train\"], spr[\"losses\"][\"val\"]\n    met_tr = {k: [m[k] for m in spr[\"metrics\"][\"train\"]] for k in [\"HWA\", \"CWA\", \"SWA\"]}\n    met_val = {k: [m[k] for m in spr[\"metrics\"][\"val\"]] for k in [\"HWA\", \"CWA\", \"SWA\"]}\n    preds, gts = spr[\"predictions\"], spr[\"ground_truth\"]\n\n    # -------- helper to make 2-line plots -------- #\n    def dual_plot(y1, y2, title, fname, ylabel):\n        try:\n            plt.figure()\n            plt.plot(epochs, y1, label=\"Train\")\n            plt.plot(epochs, y2, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(ylabel)\n            plt.title(f\"SPR: {title}\")\n            plt.legend()\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, fname), dpi=150)\n        except Exception as e:\n            print(f\"Error creating {fname}: {e}\")\n        finally:\n            plt.close()\n\n    # 1-4) curves\n    dual_plot(loss_tr, loss_val, \"Loss Curve\", \"SPR_loss_curve.png\", \"Loss\")\n    dual_plot(met_tr[\"HWA\"], met_val[\"HWA\"], \"HWA Curve\", \"SPR_HWA_curve.png\", \"HWA\")\n    dual_plot(met_tr[\"CWA\"], met_val[\"CWA\"], \"CWA Curve\", \"SPR_CWA_curve.png\", \"CWA\")\n    dual_plot(met_tr[\"SWA\"], met_val[\"SWA\"], \"SWA Curve\", \"SPR_SWA_curve.png\", \"SWA\")\n\n    # 5) confusion matrix\n    try:\n        num_cls = max(max(preds), max(gts)) + 1\n        cm = np.zeros((num_cls, num_cls), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR: Confusion Matrix\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_confusion_matrix.png\"), dpi=150)\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n    finally:\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\n\n# -------- paths -------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- load data -----#\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data[\"No_POS\"][\"SPR\"]\nexcept Exception as e:\n    raise RuntimeError(f\"Could not load experiment_data.npy: {e}\")\n\nepochs = np.array(exp[\"epochs\"])\ntrain_loss = np.array(exp[\"losses\"][\"train\"])\nval_loss = np.array(exp[\"losses\"][\"val\"])\n\n\ndef metric_curve(name):\n    return np.array([m[name] for m in exp[\"metrics\"][\"train\"]]), np.array(\n        [m[name] for m in exp[\"metrics\"][\"val\"]]\n    )\n\n\ncwa_tr, cwa_val = metric_curve(\"CWA\")\nswa_tr, swa_val = metric_curve(\"SWA\")\nhwa_tr, hwa_val = metric_curve(\"HWA\")\n\n\n# -------- plotting utilities -------- #\ndef save_fig(fig, fname):\n    fig.savefig(os.path.join(working_dir, fname), dpi=150)\n    plt.close(fig)\n\n\n# 1) Loss\ntry:\n    fig = plt.figure()\n    plt.plot(epochs, train_loss, label=\"Train\")\n    plt.plot(epochs, val_loss, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"SPR (No_POS) Loss Curves\")\n    plt.legend()\n    save_fig(fig, \"SPR_NoPOS_loss_curves.png\")\nexcept Exception as e:\n    print(f\"Error plotting loss: {e}\")\n    plt.close()\n\n# 2) CWA\ntry:\n    fig = plt.figure()\n    plt.plot(epochs, cwa_tr, label=\"Train\")\n    plt.plot(epochs, cwa_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CWA\")\n    plt.title(\"SPR (No_POS) CWA Curves\")\n    plt.legend()\n    save_fig(fig, \"SPR_NoPOS_CWA_curves.png\")\nexcept Exception as e:\n    print(f\"Error plotting CWA: {e}\")\n    plt.close()\n\n# 3) SWA\ntry:\n    fig = plt.figure()\n    plt.plot(epochs, swa_tr, label=\"Train\")\n    plt.plot(epochs, swa_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"SWA\")\n    plt.title(\"SPR (No_POS) SWA Curves\")\n    plt.legend()\n    save_fig(fig, \"SPR_NoPOS_SWA_curves.png\")\nexcept Exception as e:\n    print(f\"Error plotting SWA: {e}\")\n    plt.close()\n\n# 4) HWA\ntry:\n    fig = plt.figure()\n    plt.plot(epochs, hwa_tr, label=\"Train\")\n    plt.plot(epochs, hwa_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"HWA\")\n    plt.title(\"SPR (No_POS) HWA Curves\")\n    plt.legend()\n    save_fig(fig, \"SPR_NoPOS_HWA_curves.png\")\nexcept Exception as e:\n    print(f\"Error plotting HWA: {e}\")\n    plt.close()\n\n# 5) Confusion Matrix on test set\ntry:\n    preds = np.array(exp[\"predictions\"])\n    gts = np.array(exp[\"ground_truth\"])\n    cm = confusion_matrix(gts, preds)\n    fig = plt.figure()\n    plt.imshow(cm, cmap=\"Blues\")\n    plt.colorbar()\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Ground Truth\")\n    plt.title(\"SPR (No_POS) Confusion Matrix\")\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"red\")\n    save_fig(fig, \"SPR_NoPOS_confusion_matrix.png\")\nexcept Exception as e:\n    print(f\"Error plotting confusion matrix: {e}\")\n    plt.close()\n\n\n# -------- print test metrics -------- #\ndef _hwa(c, s, eps=1e-12):\n    return 2 * c * s / (c + s + eps)\n\n\nif len(exp[\"predictions\"]) == len(exp[\"ground_truth\"]) and len(exp[\"predictions\"]) > 0:\n    # recompute metrics\n    seq_dummy = [\"\"] * len(gts)  # not needed for overall score\n    cwa = sum(gts == preds) / len(gts)  # placeholder: correct rate\n    swa = cwa  # same placeholder since no seq weights\n    hwa = _hwa(cwa, swa)\n    print(f\"Test metrics -- CWA: {cwa:.3f} | SWA: {swa:.3f} | HWA: {hwa:.3f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set up working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# ------------------------------------------------------------------\n# helper to fetch our single run safely\ndef get_ed(exp):\n    try:\n        return exp[\"NoMultiHead\"][\"SPR\"]\n    except Exception:\n        return None\n\n\ned = get_ed(experiment_data)\n\n# ------------------------------------------------------------------\n# Plot 1: train / validation loss curves\ntry:\n    if ed:\n        plt.figure()\n        epochs = ed[\"epochs\"]\n        plt.plot(epochs, ed[\"losses\"][\"train\"], label=\"Train Loss\")\n        plt.plot(epochs, ed[\"losses\"][\"val\"], label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR: Train vs Validation Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_loss_curves_NoMultiHead.png\")\n        plt.savefig(fname, dpi=150)\n        print(f\"Saved {fname}\")\n    else:\n        print(\"No experiment data available for loss curves.\")\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\nfinally:\n    plt.close()\n\n# ------------------------------------------------------------------\n# Plot 2: validation metric curves (CWA, SWA, HWA)\ntry:\n    if ed:\n        plt.figure()\n        metrics = ed[\"metrics\"][\"val\"]\n        cwa = [m[\"CWA\"] for m in metrics]\n        swa = [m[\"SWA\"] for m in metrics]\n        hwa = [m[\"HWA\"] for m in metrics]\n        plt.plot(epochs, cwa, label=\"CWA\")\n        plt.plot(epochs, swa, label=\"SWA\")\n        plt.plot(epochs, hwa, label=\"HWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(\"SPR: Validation Metrics Over Epochs\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_val_metrics_NoMultiHead.png\")\n        plt.savefig(fname, dpi=150)\n        print(f\"Saved {fname}\")\n    else:\n        print(\"No experiment data available for metric curves.\")\nexcept Exception as e:\n    print(f\"Error creating metric curve plot: {e}\")\nfinally:\n    plt.close()\n\n# ------------------------------------------------------------------\n# Plot 3: confusion matrix for best epoch test predictions\ntry:\n    if ed and ed[\"predictions\"] and ed[\"ground_truth\"]:\n        preds = np.array(ed[\"predictions\"])\n        gts = np.array(ed[\"ground_truth\"])\n        n_cls = int(max(preds.max(), gts.max())) + 1\n        cm = np.zeros((n_cls, n_cls), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[int(t), int(p)] += 1\n\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR: Confusion Matrix (Test Set)\")\n        fname = os.path.join(working_dir, \"SPR_confusion_matrix_NoMultiHead.png\")\n        plt.savefig(fname, dpi=150)\n        print(f\"Saved {fname}\")\n    else:\n        print(\"No predictions/ground truths available for confusion matrix.\")\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\nfinally:\n    plt.close()\n\n# ------------------------------------------------------------------\n# Print simple evaluation metric (overall accuracy)\nif ed and ed[\"predictions\"] and ed[\"ground_truth\"]:\n    acc = np.mean(np.array(ed[\"predictions\"]) == np.array(ed[\"ground_truth\"]))\n    print(f\"Test Accuracy: {acc:.3f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nfor dataset_name, tasks in experiment_data.items():\n    for task_name, ed in tasks.items():\n        ep = ed.get(\"epochs\", [])\n        tl = ed.get(\"losses\", {}).get(\"train\", [])\n        vl = ed.get(\"losses\", {}).get(\"val\", [])\n        thwa = [m.get(\"HWA\") for m in ed.get(\"metrics\", {}).get(\"train\", [])]\n        vhwa = [m.get(\"HWA\") for m in ed.get(\"metrics\", {}).get(\"val\", [])]\n        best_ep = ed.get(\"best_epoch\")\n\n        # --------- Plot 1: Loss curves ---------------------------------------\n        try:\n            plt.figure()\n            plt.plot(ep, tl, label=\"Train\")\n            plt.plot(ep, vl, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.title(f\"{dataset_name}-{task_name}: Training vs Validation Loss\")\n            plt.legend()\n            fname = f\"{dataset_name}_{task_name}_loss_curves.png\"\n            plt.savefig(os.path.join(working_dir, fname), dpi=150)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot ({dataset_name}-{task_name}): {e}\")\n            plt.close()\n\n        # --------- Plot 2: HWA curves ----------------------------------------\n        try:\n            plt.figure()\n            plt.plot(ep, thwa, label=\"Train HWA\")\n            plt.plot(ep, vhwa, label=\"Val HWA\")\n            if best_ep is not None:\n                plt.axvline(\n                    best_ep, color=\"r\", linestyle=\"--\", label=f\"Best Epoch {best_ep}\"\n                )\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"HWA\")\n            plt.title(f\"{dataset_name}-{task_name}: Training vs Validation HWA\")\n            plt.legend()\n            fname = f\"{dataset_name}_{task_name}_HWA_curves.png\"\n            plt.savefig(os.path.join(working_dir, fname), dpi=150)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating HWA plot ({dataset_name}-{task_name}): {e}\")\n            plt.close()\n\n        # --------- Plot 3: Test label distribution ---------------------------\n        try:\n            preds = ed.get(\"predictions\")\n            gts = ed.get(\"ground_truth\")\n            if preds is not None and gts is not None and len(preds) == len(gts) > 0:\n                plt.figure()\n                labels = sorted(set(gts + preds))\n                gt_cnt = [gts.count(l) for l in labels]\n                pr_cnt = [preds.count(l) for l in labels]\n                x = np.arange(len(labels))\n                w = 0.35\n                plt.bar(x - w / 2, gt_cnt, width=w, label=\"Ground Truth\")\n                plt.bar(x + w / 2, pr_cnt, width=w, label=\"Predictions\")\n                plt.xticks(x, labels)\n                plt.xlabel(\"Class\")\n                plt.ylabel(\"Count\")\n                plt.title(f\"{dataset_name}-{task_name}: Test Label Distribution\")\n                plt.legend()\n                fname = f\"{dataset_name}_{task_name}_test_label_dist.png\"\n                plt.savefig(os.path.join(working_dir, fname), dpi=150)\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating distribution plot ({dataset_name}-{task_name}): {e}\")\n            plt.close()\n\n        # Print best validation HWA\n        if best_ep is not None and 0 < best_ep <= len(vhwa):\n            print(\n                f\"{dataset_name}-{task_name}: best HWA={vhwa[best_ep-1]:.4f} at epoch {best_ep}\"\n            )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# Basic setup\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data, ed = {}, {}\nelse:\n    ed = experiment_data.get(\"NoBiDir\", {}).get(\"SPR\", {})\n\nepochs = ed.get(\"epochs\", [])\ntr_loss = ed.get(\"losses\", {}).get(\"train\", [])\nval_loss = ed.get(\"losses\", {}).get(\"val\", [])\ntr_met = ed.get(\"metrics\", {}).get(\"train\", [])\nval_met = ed.get(\"metrics\", {}).get(\"val\", [])\npred = np.array(ed.get(\"predictions\", []))\ngt = np.array(ed.get(\"ground_truth\", []))\n\n# ---------- Loss curve ----------\ntry:\n    plt.figure()\n    plt.plot(epochs, tr_loss, label=\"Train\")\n    plt.plot(epochs, val_loss, label=\"Validation\")\n    plt.title(\"Loss vs Epochs - NoBiDir SPR\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CrossEntropyLoss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"NoBiDir_SPR_loss_curves.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n\n# ---------- Metric curves ----------\ndef metric_over_epochs(metric_name):\n    tr = [m.get(metric_name, np.nan) for m in tr_met]\n    va = [m.get(metric_name, np.nan) for m in val_met]\n    return tr, va\n\n\nfor metric in [\"CWA\", \"SWA\", \"HWA\"]:\n    try:\n        tr_vals, val_vals = metric_over_epochs(metric)\n        plt.figure()\n        plt.plot(epochs, tr_vals, label=\"Train\")\n        plt.plot(epochs, val_vals, label=\"Validation\")\n        plt.title(f\"{metric} vs Epochs - NoBiDir SPR\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(metric)\n        plt.legend()\n        fname = f\"NoBiDir_SPR_{metric}_curves.png\"\n        plt.savefig(os.path.join(working_dir, fname), dpi=150)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating {metric} plot: {e}\")\n        plt.close()\n\n# ---------- Confusion matrix ----------\ntry:\n    labels = np.sort(np.unique(np.concatenate([gt, pred])))\n    cm = np.zeros((len(labels), len(labels)), dtype=int)\n    for t, p in zip(gt, pred):\n        cm[np.where(labels == t)[0][0], np.where(labels == p)[0][0]] += 1\n    plt.figure()\n    im = plt.imshow(cm, cmap=\"Blues\")\n    plt.title(\"Confusion Matrix - NoBiDir SPR (Test)\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Ground Truth\")\n    plt.colorbar(im, fraction=0.046, pad=0.04)\n    plt.xticks(range(len(labels)), labels)\n    plt.yticks(range(len(labels)), labels)\n    plt.savefig(os.path.join(working_dir, \"NoBiDir_SPR_confusion_matrix.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ---------- Print evaluation metric ----------\nif gt.size and pred.size:\n    accuracy = (gt == pred).mean()\n    print(f\"Test accuracy: {accuracy:.3f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- Load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\ndef _safe(arr, k, default=np.nan):\n    return np.array(arr.get(k, []), dtype=float)\n\n\n# ---------- Iterate & plot ----------\nfor dset, dct in experiment_data.items():\n    for exp_name, ed in dct.items():\n        epochs = np.array(ed.get(\"epochs\", []))\n        losses = ed.get(\"losses\", {})\n        mets = ed.get(\"metrics\", {})\n        gt = np.array(ed.get(\"ground_truth\", []))\n        pred = np.array(ed.get(\"predictions\", []))\n\n        # 1) Loss curves ----------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(epochs, _safe(losses, \"train\"), label=\"Train\")\n            plt.plot(epochs, _safe(losses, \"val\"), label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.title(f\"{dset}-{exp_name} Loss Curves\")\n            plt.legend()\n            fname = f\"{dset}_{exp_name}_loss_curve.png\"\n            plt.savefig(os.path.join(working_dir, fname), dpi=150)\n            plt.close()\n        except Exception as e:\n            print(f\"Error plotting loss curve for {dset}-{exp_name}: {e}\")\n            plt.close()\n\n        # 2) HWA over epochs ----------------------------------------------\n        try:\n            hwa_tr = [m.get(\"HWA\", np.nan) for m in mets.get(\"train\", [])]\n            hwa_va = [m.get(\"HWA\", np.nan) for m in mets.get(\"val\", [])]\n            plt.figure()\n            plt.plot(epochs, hwa_tr, label=\"Train\")\n            plt.plot(epochs, hwa_va, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"HWA\")\n            plt.title(f\"{dset}-{exp_name} HWA Curves\")\n            plt.legend()\n            fname = f\"{dset}_{exp_name}_hwa_curve.png\"\n            plt.savefig(os.path.join(working_dir, fname), dpi=150)\n            plt.close()\n        except Exception as e:\n            print(f\"Error plotting HWA curve for {dset}-{exp_name}: {e}\")\n            plt.close()\n\n        # 3) Scatter GT vs Pred -------------------------------------------\n        try:\n            if gt.size and pred.size:\n                plt.figure()\n                jitter = (np.random.rand(len(gt)) - 0.5) * 0.2\n                plt.scatter(gt + jitter, pred + jitter, alpha=0.5)\n                max_lab = int(max(gt.max(), pred.max()))\n                plt.plot([0, max_lab], [0, max_lab], \"k--\", linewidth=1)\n                plt.xlabel(\"Ground Truth\")\n                plt.ylabel(\"Prediction\")\n                plt.title(\n                    f\"{dset}-{exp_name}\\nLeft: Ground Truth, Right: Generated Samples (Test)\"\n                )\n                fname = f\"{dset}_{exp_name}_scatter_gt_vs_pred.png\"\n                plt.savefig(os.path.join(working_dir, fname), dpi=150)\n                plt.close()\n        except Exception as e:\n            print(f\"Error plotting scatter for {dset}-{exp_name}: {e}\")\n            plt.close()\n\n        # 4) Bar chart of class distribution & accuracy --------------------\n        try:\n            if gt.size and pred.size:\n                classes = np.arange(int(max(gt.max(), pred.max()) + 1))\n                gt_counts = np.bincount(gt, minlength=len(classes))\n                pred_counts = np.bincount(pred, minlength=len(classes))\n                width = 0.35\n                plt.figure()\n                plt.bar(classes - width / 2, gt_counts, width, label=\"Ground Truth\")\n                plt.bar(classes + width / 2, pred_counts, width, label=\"Predictions\")\n                acc = (gt == pred).mean() if len(gt) else np.nan\n                plt.xlabel(\"Class\")\n                plt.ylabel(\"Count\")\n                plt.title(f\"{dset}-{exp_name} Class Distribution (Acc={acc:.3f})\")\n                plt.legend()\n                fname = f\"{dset}_{exp_name}_class_dist.png\"\n                plt.savefig(os.path.join(working_dir, fname), dpi=150)\n                plt.close()\n                print(f\"{dset}-{exp_name} test accuracy: {acc:.3f}\")\n        except Exception as e:\n            print(f\"Error plotting class distribution for {dset}-{exp_name}: {e}\")\n            plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------- load data -------------------- #\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data[\"single_gat_layer\"][\"SPR\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = None\n\nif exp is not None:\n    epochs = np.array(exp[\"epochs\"])\n    train_loss = np.array(exp[\"losses\"][\"train\"])\n    val_loss = np.array(exp[\"losses\"][\"val\"])\n    train_hwa = np.array([m[\"HWA\"] for m in exp[\"metrics\"][\"train\"]])\n    val_hwa = np.array([m[\"HWA\"] for m in exp[\"metrics\"][\"val\"]])\n    test_met = {\n        k: v for k, v in zip([\"CWA\", \"SWA\", \"HWA\"], exp[\"metrics\"][\"val\"][-1].values())\n    }\n\n    # -------------------- loss curve -------------------- #\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR: Train vs Val Loss (1-Hop GAT)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_loss_curve.png\"), dpi=150)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # -------------------- HWA curve -------------------- #\n    try:\n        plt.figure()\n        plt.plot(epochs, train_hwa, label=\"Train\")\n        plt.plot(epochs, val_hwa, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Harmonic Weighted Accuracy (HWA)\")\n        plt.title(\"SPR: Train vs Val HWA (1-Hop GAT)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_hwa_curve.png\"), dpi=150)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating HWA curve: {e}\")\n        plt.close()\n\n    # -------------------- test bar chart -------------------- #\n    try:\n        plt.figure()\n        bars = [\"CWA\", \"SWA\", \"HWA\"]\n        vals = [test_met[\"CWA\"], test_met[\"SWA\"], test_met[\"HWA\"]]\n        plt.bar(bars, vals, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n        plt.ylim(0, 1)\n        plt.title(\"SPR Test Metrics (1-Hop GAT)\\nLeft: CWA, Center: SWA, Right: HWA\")\n        plt.savefig(os.path.join(working_dir, \"SPR_test_metrics.png\"), dpi=150)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metrics bar chart: {e}\")\n        plt.close()\n\n    # -------------------- print final metrics -------------------- #\n    print(f\"Test metrics -> CWA: {vals[0]:.3f}, SWA: {vals[1]:.3f}, HWA: {vals[2]:.3f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ----------------------------------------------------\n# Load data\n# ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    run = experiment_data[\"NoColorEmbedding\"][\"SPR\"]  # shorthand\n    epochs = np.array(run[\"epochs\"])\n    train_loss = np.array(run[\"losses\"][\"train\"])\n    val_loss = np.array(run[\"losses\"][\"val\"])\n    # metrics are list[dict]\n    train_hwa = np.array([m[\"HWA\"] for m in run[\"metrics\"][\"train\"]])\n    val_hwa = np.array([m[\"HWA\"] for m in run[\"metrics\"][\"val\"]])\n\n    y_true = np.array(run[\"ground_truth\"])\n    y_pred = np.array(run[\"predictions\"])\n    # overall accuracy\n    acc = (y_true == y_pred).mean()\n    print(f\"Test accuracy = {acc*100:.2f}%\")\n\n    # ------------------------------------------------\n    # 1. Loss curves\n    # ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR (NoColorEmbedding) \u2013 Loss Curves\")\n        plt.legend()\n        save_path = os.path.join(working_dir, \"SPR_NoColorEmbedding_loss_curves.png\")\n        plt.savefig(save_path, dpi=150)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # ------------------------------------------------\n    # 2. HWA metric curves\n    # ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_hwa, label=\"Train HWA\")\n        plt.plot(epochs, val_hwa, label=\"Validation HWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HWA\")\n        plt.title(\"SPR (NoColorEmbedding) \u2013 HWA Metric Curves\")\n        plt.legend()\n        save_path = os.path.join(working_dir, \"SPR_NoColorEmbedding_hwa_curves.png\")\n        plt.savefig(save_path, dpi=150)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating HWA plot: {e}\")\n        plt.close()\n\n    # ------------------------------------------------\n    # 3. Confusion matrix (test)\n    # ------------------------------------------------\n    try:\n        classes = sorted(set(np.concatenate([y_true, y_pred])))\n        cm = np.zeros((len(classes), len(classes)), dtype=int)\n        for t, p in zip(y_true, y_pred):\n            cm[t, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xticks(classes)\n        plt.yticks(classes)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR (NoColorEmbedding) \u2013 Confusion Matrix (Test)\")\n        for i in range(len(classes)):\n            for j in range(len(classes)):\n                plt.text(\n                    j,\n                    i,\n                    cm[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"white\" if cm[i, j] > cm.max() * 0.6 else \"black\",\n                    fontsize=8,\n                )\n        save_path = os.path.join(\n            working_dir, \"SPR_NoColorEmbedding_confusion_matrix.png\"\n        )\n        plt.savefig(save_path, dpi=150)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------ #\n# basic set-up\n# ------------------------------------------------------------------ #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ned = experiment_data.get(\"SPR\", {})\nepochs = ed.get(\"epochs\", [])\nloss_tr = ed.get(\"losses\", {}).get(\"train\", [])\nloss_val = ed.get(\"losses\", {}).get(\"val\", [])\nhwa_tr = [m.get(\"HWA\", np.nan) for m in ed.get(\"metrics\", {}).get(\"train\", [])]\nhwa_val = [m.get(\"HWA\", np.nan) for m in ed.get(\"metrics\", {}).get(\"val\", [])]\npreds = np.asarray(ed.get(\"predictions\", []), dtype=int)\ngts = np.asarray(ed.get(\"ground_truth\", []), dtype=int)\n\n# ------------------------------------------------------------------ #\n# 1) Train / Val loss curve\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    plt.plot(epochs, loss_tr, label=\"Train\")\n    plt.plot(epochs, loss_val, label=\"Val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR \u2013 Train vs Val Loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_loss_curve.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 2) Train / Val HWA curve\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    plt.plot(epochs, hwa_tr, label=\"Train HWA\")\n    plt.plot(epochs, hwa_val, label=\"Val HWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"HWA\")\n    plt.title(\"SPR \u2013 Train vs Val HWA\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_HWA_curve.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curve: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 3) Confusion matrix on test set\n# ------------------------------------------------------------------ #\ntry:\n    if preds.size and gts.size:\n        n_cls = int(max(preds.max(), gts.max()) + 1)\n        cm = np.zeros((n_cls, n_cls), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR \u2013 Confusion Matrix\\nLeft: Ground Truth, Right: Predicted\")\n        for i in range(n_cls):\n            for j in range(n_cls):\n                plt.text(\n                    j,\n                    i,\n                    cm[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                    fontsize=8,\n                )\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_confusion_matrix.png\"), dpi=150)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 4) Final CWA / SWA / HWA bar chart\n# ------------------------------------------------------------------ #\ntry:\n    if hwa_val:\n        cwa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"CWA\", np.nan)\n        swa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"SWA\", np.nan)\n        hwa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"HWA\", np.nan)\n        cats = [\"CWA\", \"SWA\", \"HWA\"]\n        vals = [cwa_last, swa_last, hwa_last]\n        plt.figure()\n        plt.bar(cats, vals, color=[\"#4c72b0\", \"#55a868\", \"#c44e52\"])\n        plt.ylabel(\"Metric Value\")\n        plt.title(\"SPR \u2013 Final Validation Metrics\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_final_val_metrics.png\"), dpi=150)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating metric bar chart: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# Print simple evaluation metric\n# ------------------------------------------------------------------ #\nif preds.size and gts.size:\n    accuracy = (preds == gts).mean()\n    print(f\"Test accuracy: {accuracy:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------ #\n# basic set-up\n# ------------------------------------------------------------------ #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ned = experiment_data.get(\"SPR\", {})\nepochs = ed.get(\"epochs\", [])\nloss_tr = ed.get(\"losses\", {}).get(\"train\", [])\nloss_val = ed.get(\"losses\", {}).get(\"val\", [])\nhwa_tr = [m.get(\"HWA\", np.nan) for m in ed.get(\"metrics\", {}).get(\"train\", [])]\nhwa_val = [m.get(\"HWA\", np.nan) for m in ed.get(\"metrics\", {}).get(\"val\", [])]\npreds = np.asarray(ed.get(\"predictions\", []), dtype=int)\ngts = np.asarray(ed.get(\"ground_truth\", []), dtype=int)\n\n# ------------------------------------------------------------------ #\n# 1) Train / Val loss curve\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    plt.plot(epochs, loss_tr, label=\"Train\")\n    plt.plot(epochs, loss_val, label=\"Val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR \u2013 Train vs Val Loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_loss_curve.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 2) Train / Val HWA curve\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    plt.plot(epochs, hwa_tr, label=\"Train HWA\")\n    plt.plot(epochs, hwa_val, label=\"Val HWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"HWA\")\n    plt.title(\"SPR \u2013 Train vs Val HWA\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_HWA_curve.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curve: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 3) Confusion matrix on test set\n# ------------------------------------------------------------------ #\ntry:\n    if preds.size and gts.size:\n        n_cls = int(max(preds.max(), gts.max()) + 1)\n        cm = np.zeros((n_cls, n_cls), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR \u2013 Confusion Matrix\\nLeft: Ground Truth, Right: Predicted\")\n        for i in range(n_cls):\n            for j in range(n_cls):\n                plt.text(\n                    j,\n                    i,\n                    cm[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                    fontsize=8,\n                )\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_confusion_matrix.png\"), dpi=150)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 4) Final CWA / SWA / HWA bar chart\n# ------------------------------------------------------------------ #\ntry:\n    if hwa_val:\n        cwa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"CWA\", np.nan)\n        swa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"SWA\", np.nan)\n        hwa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"HWA\", np.nan)\n        cats = [\"CWA\", \"SWA\", \"HWA\"]\n        vals = [cwa_last, swa_last, hwa_last]\n        plt.figure()\n        plt.bar(cats, vals, color=[\"#4c72b0\", \"#55a868\", \"#c44e52\"])\n        plt.ylabel(\"Metric Value\")\n        plt.title(\"SPR \u2013 Final Validation Metrics\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_final_val_metrics.png\"), dpi=150)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating metric bar chart: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# Print simple evaluation metric\n# ------------------------------------------------------------------ #\nif preds.size and gts.size:\n    accuracy = (preds == gts).mean()\n    print(f\"Test accuracy: {accuracy:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------ #\n# basic set-up\n# ------------------------------------------------------------------ #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ned = experiment_data.get(\"SPR\", {})\nepochs = ed.get(\"epochs\", [])\nloss_tr = ed.get(\"losses\", {}).get(\"train\", [])\nloss_val = ed.get(\"losses\", {}).get(\"val\", [])\nhwa_tr = [m.get(\"HWA\", np.nan) for m in ed.get(\"metrics\", {}).get(\"train\", [])]\nhwa_val = [m.get(\"HWA\", np.nan) for m in ed.get(\"metrics\", {}).get(\"val\", [])]\npreds = np.asarray(ed.get(\"predictions\", []), dtype=int)\ngts = np.asarray(ed.get(\"ground_truth\", []), dtype=int)\n\n# ------------------------------------------------------------------ #\n# 1) Train / Val loss curve\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    plt.plot(epochs, loss_tr, label=\"Train\")\n    plt.plot(epochs, loss_val, label=\"Val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR \u2013 Train vs Val Loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_loss_curve.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 2) Train / Val HWA curve\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    plt.plot(epochs, hwa_tr, label=\"Train HWA\")\n    plt.plot(epochs, hwa_val, label=\"Val HWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"HWA\")\n    plt.title(\"SPR \u2013 Train vs Val HWA\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_HWA_curve.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curve: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 3) Confusion matrix on test set\n# ------------------------------------------------------------------ #\ntry:\n    if preds.size and gts.size:\n        n_cls = int(max(preds.max(), gts.max()) + 1)\n        cm = np.zeros((n_cls, n_cls), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR \u2013 Confusion Matrix\\nLeft: Ground Truth, Right: Predicted\")\n        for i in range(n_cls):\n            for j in range(n_cls):\n                plt.text(\n                    j,\n                    i,\n                    cm[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                    fontsize=8,\n                )\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_confusion_matrix.png\"), dpi=150)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 4) Final CWA / SWA / HWA bar chart\n# ------------------------------------------------------------------ #\ntry:\n    if hwa_val:\n        cwa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"CWA\", np.nan)\n        swa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"SWA\", np.nan)\n        hwa_last = ed.get(\"metrics\", {}).get(\"val\", [{}])[-1].get(\"HWA\", np.nan)\n        cats = [\"CWA\", \"SWA\", \"HWA\"]\n        vals = [cwa_last, swa_last, hwa_last]\n        plt.figure()\n        plt.bar(cats, vals, color=[\"#4c72b0\", \"#55a868\", \"#c44e52\"])\n        plt.ylabel(\"Metric Value\")\n        plt.title(\"SPR \u2013 Final Validation Metrics\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_final_val_metrics.png\"), dpi=150)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating metric bar chart: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# Print simple evaluation metric\n# ------------------------------------------------------------------ #\nif preds.size and gts.size:\n    accuracy = (preds == gts).mean()\n    print(f\"Test accuracy: {accuracy:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------ #\n# basic set-up\n# ------------------------------------------------------------------ #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------ #\n# paths to all experiment_data.npy files (relative to AI_SCIENTIST_ROOT)\n# ------------------------------------------------------------------ #\nexperiment_data_path_list = [\n    \"experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b66e515a4e894113af85de89da506339_proc_1520779/experiment_data.npy\",\n    \"experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ab50cdf8e6f246d9bd677026563e8b10_proc_1520778/experiment_data.npy\",\n    \"experiments/2025-08-30_21-49-55_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9366a250390a460eabd453871340cb61_proc_1520781/experiment_data.npy\",\n]\n\n# ------------------------------------------------------------------ #\n# load all runs\n# ------------------------------------------------------------------ #\nall_experiment_data = []\ntry:\n    for p in experiment_data_path_list:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p)\n        ed = np.load(full_path, allow_pickle=True).item()\n        all_experiment_data.append(ed)\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\n\n# ------------------------------------------------------------------ #\n# helper to right-pad with nan so all arrays share length\n# ------------------------------------------------------------------ #\ndef pad_to(arr, L):\n    arr = np.asarray(arr, dtype=float)\n    if arr.size < L:\n        arr = np.concatenate([arr, np.full(L - arr.size, np.nan)])\n    return arr[:L]\n\n\n# ------------------------------------------------------------------ #\n# aggregate per dataset\n# ------------------------------------------------------------------ #\ndatasets = set()\nfor run in all_experiment_data:\n    datasets.update(run.keys())\n\nfor dname in datasets:\n    # collect lists over runs\n    loss_tr_runs, loss_val_runs = [], []\n    hwa_tr_runs, hwa_val_runs = [], []\n    cwa_last, swa_last, hwa_last = [], [], []\n    preds_runs, gts_runs = [], []\n    epochs_master = None\n    for run in all_experiment_data:\n        ed = run.get(dname, {})\n        if not ed:\n            continue\n        epochs = ed.get(\"epochs\", [])\n        if epochs_master is None or len(epochs) > len(epochs_master):\n            epochs_master = epochs  # keep the longest as reference\n        loss_tr_runs.append(ed.get(\"losses\", {}).get(\"train\", []))\n        loss_val_runs.append(ed.get(\"losses\", {}).get(\"val\", []))\n        hwa_tr_runs.append(\n            [m.get(\"HWA\", np.nan) for m in ed.get(\"metrics\", {}).get(\"train\", [])]\n        )\n        hwa_val_runs.append(\n            [m.get(\"HWA\", np.nan) for m in ed.get(\"metrics\", {}).get(\"val\", [])]\n        )\n\n        val_metrics = ed.get(\"metrics\", {}).get(\"val\", [])\n        if val_metrics:\n            cwa_last.append(val_metrics[-1].get(\"CWA\", np.nan))\n            swa_last.append(val_metrics[-1].get(\"SWA\", np.nan))\n            hwa_last.append(val_metrics[-1].get(\"HWA\", np.nan))\n\n        if ed.get(\"predictions\") is not None and ed.get(\"ground_truth\") is not None:\n            preds_runs.append(np.asarray(ed[\"predictions\"], dtype=int))\n            gts_runs.append(np.asarray(ed[\"ground_truth\"], dtype=int))\n\n    # skip if no runs for this dataset\n    if epochs_master is None:\n        continue\n\n    L = len(epochs_master)\n    epochs_master = np.asarray(epochs_master)\n\n    # convert lists to 2D arrays with padding\n    def stack_and_stat(list_of_lists):\n        if not list_of_lists:\n            return None, None\n        stacked = np.vstack([pad_to(x, L) for x in list_of_lists])\n        mean = np.nanmean(stacked, axis=0)\n        sem = np.nanstd(stacked, axis=0) / np.sqrt(stacked.shape[0])\n        return mean, sem\n\n    loss_tr_mean, loss_tr_sem = stack_and_stat(loss_tr_runs)\n    loss_val_mean, loss_val_sem = stack_and_stat(loss_val_runs)\n    hwa_tr_mean, hwa_tr_sem = stack_and_stat(hwa_tr_runs)\n    hwa_val_mean, hwa_val_sem = stack_and_stat(hwa_val_runs)\n\n    # ------------------------------------------------------------------ #\n    # 1) Aggregated Train/Val loss with SEM\n    # ------------------------------------------------------------------ #\n    try:\n        if loss_tr_mean is not None and loss_val_mean is not None:\n            plt.figure()\n            plt.plot(epochs_master, loss_tr_mean, label=\"Train \u00b5\")\n            plt.fill_between(\n                epochs_master,\n                loss_tr_mean - loss_tr_sem,\n                loss_tr_mean + loss_tr_sem,\n                alpha=0.3,\n                label=\"Train \u00b1SEM\",\n            )\n            plt.plot(epochs_master, loss_val_mean, label=\"Val \u00b5\")\n            plt.fill_between(\n                epochs_master,\n                loss_val_mean - loss_val_sem,\n                loss_val_mean + loss_val_sem,\n                alpha=0.3,\n                label=\"Val \u00b1SEM\",\n            )\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{dname} \u2013 Aggregated Train vs Val Loss (mean \u00b1 SEM)\")\n            plt.legend()\n            plt.tight_layout()\n            plt.savefig(\n                os.path.join(working_dir, f\"{dname}_agg_loss_curve.png\"), dpi=150\n            )\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated loss curve for {dname}: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------ #\n    # 2) Aggregated Train/Val HWA with SEM\n    # ------------------------------------------------------------------ #\n    try:\n        if hwa_tr_mean is not None and hwa_val_mean is not None:\n            plt.figure()\n            plt.plot(epochs_master, hwa_tr_mean, label=\"Train HWA \u00b5\")\n            plt.fill_between(\n                epochs_master,\n                hwa_tr_mean - hwa_tr_sem,\n                hwa_tr_mean + hwa_tr_sem,\n                alpha=0.3,\n                label=\"Train \u00b1SEM\",\n            )\n            plt.plot(epochs_master, hwa_val_mean, label=\"Val HWA \u00b5\")\n            plt.fill_between(\n                epochs_master,\n                hwa_val_mean - hwa_val_sem,\n                hwa_val_mean + hwa_val_sem,\n                alpha=0.3,\n                label=\"Val \u00b1SEM\",\n            )\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"HWA\")\n            plt.title(f\"{dname} \u2013 Aggregated HWA (mean \u00b1 SEM)\")\n            plt.legend()\n            plt.tight_layout()\n            plt.savefig(\n                os.path.join(working_dir, f\"{dname}_agg_HWA_curve.png\"), dpi=150\n            )\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated HWA curve for {dname}: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------ #\n    # 3) Final metrics bar chart (mean \u00b1 SEM)\n    # ------------------------------------------------------------------ #\n    try:\n        if cwa_last and swa_last and hwa_last:\n            cats = [\"CWA\", \"SWA\", \"HWA\"]\n            means = [np.nanmean(cwa_last), np.nanmean(swa_last), np.nanmean(hwa_last)]\n            sems = [\n                np.nanstd(cwa_last) / np.sqrt(len(cwa_last)),\n                np.nanstd(swa_last) / np.sqrt(len(swa_last)),\n                np.nanstd(hwa_last) / np.sqrt(len(hwa_last)),\n            ]\n            plt.figure()\n            plt.bar(\n                cats,\n                means,\n                yerr=sems,\n                capsize=5,\n                color=[\"#4c72b0\", \"#55a868\", \"#c44e52\"],\n            )\n            plt.ylabel(\"Metric Value\")\n            plt.title(f\"{dname} \u2013 Final Validation Metrics (mean \u00b1 SEM)\")\n            plt.tight_layout()\n            plt.savefig(\n                os.path.join(working_dir, f\"{dname}_agg_final_val_metrics.png\"), dpi=150\n            )\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated metric bar chart for {dname}: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------ #\n    # 4) Aggregated confusion matrix (sum then normalised)\n    # ------------------------------------------------------------------ #\n    try:\n        if preds_runs and gts_runs:\n            n_cls = int(\n                max([max(p.max(), g.max()) for p, g in zip(preds_runs, gts_runs)]) + 1\n            )\n            cm_sum = np.zeros((n_cls, n_cls), dtype=int)\n            for p, g in zip(preds_runs, gts_runs):\n                for t, pr in zip(g, p):\n                    cm_sum[t, pr] += 1\n            cm_norm = cm_sum / cm_sum.sum(axis=1, keepdims=True)\n            plt.figure()\n            im = plt.imshow(cm_norm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(\n                f\"{dname} \u2013 Aggregated Confusion Matrix\\nLeft: Ground Truth, Right: Predicted\"\n            )\n            for i in range(n_cls):\n                for j in range(n_cls):\n                    plt.text(\n                        j,\n                        i,\n                        f\"{cm_norm[i, j]:.2f}\",\n                        ha=\"center\",\n                        va=\"center\",\n                        color=\"white\" if cm_norm[i, j] > cm_norm.max() / 2 else \"black\",\n                        fontsize=8,\n                    )\n            plt.tight_layout()\n            plt.savefig(\n                os.path.join(working_dir, f\"{dname}_agg_confusion_matrix.png\"), dpi=150\n            )\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated confusion matrix for {dname}: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------ #\n    # quick terminal summary\n    # ------------------------------------------------------------------ #\n    if hwa_last:\n        print(f\"{dname} \u2013 Final-epoch HWA mean across runs: {np.nanmean(hwa_last):.4f}\")\n"], "plot_plan": ["We load the stored experiment_data.npy, focus on the \u201cSPR\u201d entry, and extract epoch indices, per-epoch train/val losses, and per-epoch HWA scores. Four visualizations are produced, each wrapped in its own try-except so one failure does not break the others: (1) train/validation loss curve, (2) train/validation HWA curve, (3) test-set confusion matrix, and (4) a simple bar chart comparing final epoch CWA, SWA, HWA.  All figures are saved into working_dir with descriptive filenames that include the dataset name and plot type.  A maximum of four figures keeps us within the 5-figure limit, and plt.close() is always used to free resources.  Metric extraction is defensive, falling back to empty lists when keys are missing.  After plotting, the script prints overall test accuracy as a sanity check.  The code relies only on data present in experiment_data.npy, adding no fabricated numbers.  Each plot contains an informative title, and the confusion matrix includes the subtitle \u201cLeft: Ground Truth, Right: Predicted\u201d for clarity.", "We load experiment_data.npy, pull out the \u2018SPR\u2019 record, and extract epochs, train/val losses and metrics, plus test predictions vs ground-truth. Five figures will be produced, each in its own try-except block and saved to working_dir: (1) train/validation loss curves; (2) train/validation HWA curves; (3) train/validation CWA curves; (4) train/validation SWA curves; (5) a confusion-matrix heat-map built from test predictions. Every figure is closed after saving, filenames are descriptive, and titles include the dataset name and plot type. We rely only on the data present in experiment_data.npy; no synthetic values are introduced. At most five plots satisfy the guideline. Figures are saved as PNGs for portability. The code is concise and follows the required imports and directory setup.", "We will load experiment_data.npy, retrieve the SPR split under the No_POS setting, and extract the epoch list, loss curves, and metric dictionaries. Five figures will be generated: (1) combined train/validation loss; (2-4) CWA, SWA, and HWA curves; (5) a confusion-matrix heat-map built from saved ground-truth and predictions. Each figure is wrapped in a try-except block, saved to working_dir with descriptive names, titled clearly, and closed afterward. After plotting we recompute and print test CWA, SWA, and HWA to verify the metrics. The script uses only data present in experiment_data.npy and limits itself to basic matplotlib. No more than five figures are produced.", "We will load the stored experiment_data.npy, extract the results for the single available setting (model \u201cNoMultiHead\u201d, dataset \u201cSPR\u201d), and build three standard plots: (1) combined train/validation loss curves, (2) validation metric curves (CWA, SWA, HWA) over epochs, and (3) a confusion-matrix heat-map for the best-epoch test predictions versus ground-truth.  Each figure is created inside an individual try/except so that one failure does not interrupt the rest, and every figure is explicitly closed.  Descriptive titles and filenames include the dataset name and the plot type, and all images are saved in the prescribed working directory.  We also compute and print a simple overall test accuracy to satisfy the \u201cprint metric\u201d requirement.  All plotting relies solely on the data loaded from experiment_data.npy\u2014no synthetic values are introduced.  The code is concise, starts with the mandated imports, and follows the developer plotting guidelines exactly.  At most three figures are generated, comfortably below the five-figure limit.", "We will first load experiment_data.npy from the working directory, then loop over every dataset/task stored inside.  From each entry we extract the epoch list, training/validation loss arrays, and the HWA metric per epoch.  Three separate plots will be generated in try-except blocks: (1) training vs. validation loss, (2) training vs. validation HWA, and (3) a bar chart comparing ground-truth and predicted label frequencies on the test set (if those arrays exist).  Each figure will have a clear title that includes the dataset/task name and will be saved under a descriptive file name to working_dir; figures are always closed afterward.  We print the best validation HWA and the epoch where it was obtained for quick inspection.  All plotting strictly relies on values stored in experiment_data.npy\u2014no synthetic data are created.  At most three figures will be produced, staying within the five-plot limit.", "We first load experiment_data.npy from the working directory and focus on the single entry experiment_data['NoBiDir']['SPR'].  \nFrom it we retrieve the epoch list, training/validation losses, per-epoch metrics (CWA, SWA, HWA), and the final test predictions/ground-truth.  \nWe then create up to five visualizations, each wrapped in its own try-except block and saved to working_dir with descriptive names:  \n1) combined training/validation loss curves; 2-4) separate training/validation curves for CWA, SWA, and HWA; 5) a confusion-matrix heat-map for the test set.  \nAll figures are closed after saving, and every plot carries a clear title that also specifies the dataset/model.  \nFor the confusion matrix we derive the label set directly from ground_truth so we never exceed the available classes.  \nAfter plotting, we print the simple test accuracy so that a numeric evaluation metric is reported.  \nThe code relies only on numpy and matplotlib, adheres to basic style, and never fabricates data\u2014everything plotted comes straight from experiment_data.npy.", "We will load the saved experiment_data, iterate through every dataset/experiment combination, and create up to four informative plots per experiment: (1) train vs validation loss curves, (2) train vs validation HWA curves, (3) a scatter plot comparing ground-truth labels to model predictions on the test set (with slight jitter to avoid overplotting), and (4) a bar chart that juxtaposes the empirical class distributions of ground-truth and predictions together with overall accuracy in the title. Each plot is enclosed in its own try-except so failure in one does not block the rest, and every figure is closed after saving. All plots are stored in working_dir with descriptive filenames that include the dataset/experiment name and the plot type; we cap the total number of figures at four, which is safely within the allowed five. Finally, the script prints the overall test accuracy (as our evaluation metric) for quick inspection.", "We will load experiment_data.npy from the working directory, extract the single-gat-layer/SPR sub-dictionary, and pull out the epoch list, per-epoch losses, and metric dictionaries. After converting the metric lists into NumPy arrays for easy slicing, we will create up to three figures: (1) train/validation loss curves, (2) train/validation HWA curves, and (3) a bar chart that shows the final test CWA, SWA, and HWA. Each figure will be wrapped in its own try-except block, titled clearly, saved with a descriptive filename that includes \u201cSPR\u201d and the plot type, and then closed. We respect the five-figure cap by limiting ourselves to these three essential plots. All plots go to working_dir, which we create if it does not yet exist. Finally, we print the test metrics so the user can see quantitative results in the console as well. The code is concise, follows the mandated import order, and adheres strictly to the data available in experiment_data.npy.", "We first load experiment_data.npy and extract the dictionary for the single run (dataset = \u2018SPR\u2019, variant = \u2018NoColorEmbedding\u2019).  From this we obtain the epoch list, per-epoch losses in train/val and the metric dictionaries that contain CWA, SWA and HWA.  For each metric we build a NumPy array so that we can plot train and validation curves together.  We then create up to three figures: (1) train/val loss, (2) train/val HWA, and (3) a confusion-matrix style heat-map of test predictions vs ground-truth, computing the counts directly from the stored lists.  Each figure is wrapped in its own try-except; figures are titled clearly and saved to working_dir with informative filenames.  We always close the figure in both success and failure branches.  After plotting we compute and print the overall test accuracy so users have a quick numerical summary.  Because all data are pre-computed, we refrain from any additional training or simulation and keep matplotlib calls minimal.  The script runs as a standalone diagnostic/visualisation utility.", null, null, null, null], "ablation_name": [null, "Remove Shape/Color Similarity Edges", "Remove Positional Feature (No\u2010POS)", "Single-Head Attention (No-MultiHead)", "No-Chain-Edges", "No-Bidirectional-Edges", "No-Node-Features (Edge-Only Graph)", "Single-GAT-Layer (1-Hop Message Passing Only)", "Remove-Color-Features (No-Color-Embedding)", null, null, null, null], "hyperparam_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["Below we 1) load the numpy file from the working directory, 2) locate the final-\nepoch training metrics and the best-epoch validation metrics (based on the\nstored best_epoch), and 3) print each metric with an explicit, self-descriptive\nlabel for the single dataset \u201cSPR\u201d. No plots are generated and the script\nexecutes immediately.", "The script will load experiment_data.npy from the \u201cworking\u201d directory, navigate\nto the single stored experiment (\u201cremove_similarity_edges \u2192 SPR\u201d), and retrieve\n\u2022 the last-epoch training metrics & loss,   \u2022 the best-epoch validation metrics\n& loss (epoch index obtained from exp_rec[\"best_epoch\"]), and   \u2022 the overall\ntest accuracy computed from stored predictions vs. ground-truth.   It then\nprints these values with explicit, fully-qualified names as required.", "We will load the saved numpy dictionary, pick the single experiment that was run\n(No-POS/Spr), and extract the stored metrics.   For the training split we report\nthe metric values from the last epoch; for the validation split we take the\nvalues that correspond to the recorded best epoch; for the test split we\nrecompute a simple accuracy from the stored predictions and ground-truth labels.\nAll metrics are printed with explicit, self-describing names and each dataset\nsection is clearly labelled.", "The script will locate the saved NumPy file, load the nested dictionary that\nstores all experimental information, and then walk through every model\u2010dataset\npair it finds.  For each pair it looks up the epoch that achieved the best\nvalidation performance (recorded under best_epoch) and prints: (a) the training\nand validation CWA/SWA/HWA values from that epoch, (b) the corresponding\nvalidation loss, and (c) a simple test-set accuracy computed from the saved\npredictions and ground-truth labels.  Every output line is explicitly prefixed\nwith the metric\u2019s name to satisfy the formatting rules.", "The script will load the \u201cexperiment_data.npy\u201d file from the working directory,\niterate through every stored dataset/task, and print the requested summary\nstatistics.   For the training split it reports the last\u2013epoch (final) values,\nwhile for the validation split it reports the values taken from the stored best\nepoch (the epoch that delivered the best validation HWA during training).   Each\nprintout clearly states the dataset \u2192 task followed by explicit metric names\nsuch as \u201ctraining loss,\u201d \u201cvalidation HWA,\u201d etc., complying with the formatting\nrules.", "The script will (1) locate the working directory created by the original\nexperiment, (2) load the stored NumPy dictionary, (3) walk through every dataset\n/ task pair inside it, and (4) print the final-epoch training metrics, the\nfinal-epoch validation metrics, and the best validation HWA together with its\nepoch.  Every value is clearly labelled (e.g., \u201cFinal training HWA\u201d) and the\ndataset name (\u201cNoBiDir - SPR\u201d) is printed first so the output is self-\nexplanatory.  Nothing is plotted or written back to disk; the code runs\nimmediately at import time.", "We load the saved numpy dictionary from the working directory, walk through\nevery (model, task) pair, pick the last entries in the training/validation loss\nand metric lists, and print them with explicit names (e.g., \u201cfinal training\nCWA\u201d).  If any list is empty the script skips that value gracefully.  Finally,\nwe also report the epoch that achieved the best held-out score.  All code is\nplaced at top level so it runs immediately when the file is executed.", "The script below immediately loads the saved NumPy file, digs into its nested\ndictionary, and prints one concise report per data split.   For the training\nsplit it reports the metrics from the final epoch, while for the validation\nsplit it reports the metrics from the epoch that achieved the best HWA (stored\nin best_epoch).   The test split did not store metric dictionaries, but it did\nstore predictions and ground-truth labels, so the script computes and prints the\nfinal test accuracy.", "The script loads the experiment_data.npy file from the working directory,\nretrieves the single run stored under the \u201cNoColorEmbedding \u2192 SPR\u201d key, and\nextracts the final (i.e., last-epoch) training and validation metrics and\nlosses. It additionally derives a simple test accuracy from the stored\nprediction and ground-truth vectors. Each block of output is clearly labelled\nwith the dataset name followed by explicit metric names so the results are\nunambiguous. The code executes immediately without requiring any special entry\npoint.", "Below we 1) load the numpy file from the working directory, 2) locate the final-\nepoch training metrics and the best-epoch validation metrics (based on the\nstored best_epoch), and 3) print each metric with an explicit, self-descriptive\nlabel for the single dataset \u201cSPR\u201d. No plots are generated and the script\nexecutes immediately.", "Below we 1) load the numpy file from the working directory, 2) locate the final-\nepoch training metrics and the best-epoch validation metrics (based on the\nstored best_epoch), and 3) print each metric with an explicit, self-descriptive\nlabel for the single dataset \u201cSPR\u201d. No plots are generated and the script\nexecutes immediately.", "Below we 1) load the numpy file from the working directory, 2) locate the final-\nepoch training metrics and the best-epoch validation metrics (based on the\nstored best_epoch), and 3) print each metric with an explicit, self-descriptive\nlabel for the single dataset \u201cSPR\u201d. No plots are generated and the script\nexecutes immediately.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ------------------------------------------------------------\n# Locate and load the saved experiment_data dictionary\n# ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------\n# Helper: nice float formatting\n# ------------------------------------------------------------\nfmt = lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else str(x)\n\n# ------------------------------------------------------------\n# Iterate over every dataset stored in experiment_data\n# ------------------------------------------------------------\nfor dataset_name, data_blob in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # ---------------- Training (final epoch) ----------------\n    train_metrics_list = data_blob[\"metrics\"][\"train\"]\n    train_losses_list = data_blob[\"losses\"][\"train\"]\n    train_final_metrics = train_metrics_list[-1]  # last epoch metrics\n    train_final_loss = train_losses_list[-1]\n\n    print(f\"training_CWA: {fmt(train_final_metrics['CWA'])}\")\n    print(f\"training_SWA: {fmt(train_final_metrics['SWA'])}\")\n    print(f\"training_HWA: {fmt(train_final_metrics['HWA'])}\")\n    print(f\"training_loss: {fmt(train_final_loss)}\")\n\n    # -------------- Validation (best epoch by HWA) ----------\n    best_epoch = data_blob.get(\"best_epoch\")\n    if best_epoch is None:\n        best_idx = -1  # fallback to last epoch\n    else:\n        best_idx = best_epoch - 1  # epochs are 1-indexed\n\n    val_metrics_list = data_blob[\"metrics\"][\"val\"]\n    val_losses_list = data_blob[\"losses\"][\"val\"]\n    val_best_metrics = val_metrics_list[best_idx]\n    val_best_loss = val_losses_list[best_idx]\n\n    print(f\"validation_CWA: {fmt(val_best_metrics['CWA'])}\")\n    print(f\"validation_SWA: {fmt(val_best_metrics['SWA'])}\")\n    print(f\"validation_HWA: {fmt(val_best_metrics['HWA'])}\")\n    print(f\"validation_loss: {fmt(val_best_loss)}\")\n", "import os\nimport numpy as np\n\n# ---------- Load saved experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------- Simple helper ----------\ndef accuracy(y_true, y_pred):\n    return sum(int(t == p) for t, p in zip(y_true, y_pred)) / max(1, len(y_true))\n\n\n# ---------- Traverse experiments ----------\nfor (\n    exp_name,\n    datasets,\n) in experiment_data.items():  # exp_name = 'remove_similarity_edges'\n    for ds_name, exp_rec in datasets.items():  # ds_name  = 'SPR'\n        print(f\"\\n=== Dataset: {ds_name} ===\")\n\n        # -------- Training (use final epoch) --------\n        train_metrics_final = exp_rec[\"metrics\"][\"train\"][-1]\n        train_loss_final = exp_rec[\"losses\"][\"train\"][-1]\n        print(f\"train CWA: {train_metrics_final['CWA']:.4f}\")\n        print(f\"train SWA: {train_metrics_final['SWA']:.4f}\")\n        print(f\"train HWA: {train_metrics_final['HWA']:.4f}\")\n        print(f\"train loss: {train_loss_final:.4f}\")\n\n        # -------- Validation (use best epoch) -------\n        best_idx = exp_rec[\"best_epoch\"] - 1  # epochs are 1-based\n        val_metrics_best = exp_rec[\"metrics\"][\"val\"][best_idx]\n        val_loss_best = exp_rec[\"losses\"][\"val\"][best_idx]\n        print(f\"validation CWA: {val_metrics_best['CWA']:.4f}\")\n        print(f\"validation SWA: {val_metrics_best['SWA']:.4f}\")\n        print(f\"validation HWA: {val_metrics_best['HWA']:.4f}\")\n        print(f\"validation loss: {val_loss_best:.4f}\")\n\n        # -------- Test (compute accuracy) -----------\n        y_true = exp_rec[\"ground_truth\"]\n        y_pred = exp_rec[\"predictions\"]\n        if y_true and y_pred:\n            test_acc = accuracy(y_true, y_pred)\n            print(f\"test accuracy: {test_acc:.4f}\")\n", "import os\nimport numpy as np\n\n\n# ---------- helper metrics (needed only for test accuracy) ----------\ndef accuracy(y_true, y_pred):\n    correct = sum(int(t == p) for t, p in zip(y_true, y_pred))\n    return correct / max(1, len(y_true))\n\n\n# ---------- load experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# navigate to the only experiment that was run\nexp = experiment_data[\"No_POS\"][\"SPR\"]\n\ntrain_metrics_all = exp[\"metrics\"][\"train\"]  # list of dicts\nval_metrics_all = exp[\"metrics\"][\"val\"]  # list of dicts\nbest_epoch = exp[\"best_epoch\"]  # 1-based index\n\n# -------- training split : take metrics from final epoch --------\ntrain_final = train_metrics_all[-1]  # dict with CWA / SWA / HWA\n\nprint(\"TRAINING DATASET\")\nprint(f\"train CWA: {train_final['CWA']:.4f}\")\nprint(f\"train SWA: {train_final['SWA']:.4f}\")\nprint(f\"train HWA: {train_final['HWA']:.4f}\")\n\n# -------- validation split : take metrics from best epoch --------\nval_best = val_metrics_all[best_epoch - 1]  # convert to 0-based index\n\nprint(\"\\nVALIDATION DATASET\")\nprint(f\"validation CWA: {val_best['CWA']:.4f}\")\nprint(f\"validation SWA: {val_best['SWA']:.4f}\")\nprint(f\"validation HWA: {val_best['HWA']:.4f}\")\n\n# -------- test split : recompute simple accuracy ----------------\ny_true = exp[\"ground_truth\"]\ny_pred = exp[\"predictions\"]\ntest_acc = accuracy(y_true, y_pred)\n\nprint(\"\\nTEST DATASET\")\nprint(f\"test accuracy: {test_acc:.4f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------\n# Locate and load the experiment data\n# ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(data_file, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------\n# Helper to compute simple accuracy\n# ------------------------------------------------------------\ndef accuracy(y_true, y_pred):\n    if not y_true:\n        return float(\"nan\")\n    return sum(int(t == p) for t, p in zip(y_true, y_pred)) / len(y_true)\n\n\n# ------------------------------------------------------------\n# Iterate through stored results and print requested metrics\n# ------------------------------------------------------------\nfor model_name, model_block in experiment_data.items():\n    for dataset_name, d in model_block.items():\n        print(f\"Dataset: {dataset_name}  (Model: {model_name})\")\n\n        # Identify index of best epoch; fall back to final epoch if absent\n        best_epoch_num = d.get(\"best_epoch\", None)\n        best_idx = best_epoch_num - 1 if best_epoch_num is not None else -1\n\n        # Training metrics at best epoch\n        train_metrics = d[\"metrics\"][\"train\"][best_idx]\n        print(f\"training CWA: {train_metrics['CWA']:.4f}\")\n        print(f\"training SWA: {train_metrics['SWA']:.4f}\")\n        print(f\"training HWA: {train_metrics['HWA']:.4f}\")\n\n        # Validation metrics and loss at best epoch\n        val_metrics = d[\"metrics\"][\"val\"][best_idx]\n        val_loss = d[\"losses\"][\"val\"][best_idx]\n        print(f\"validation CWA: {val_metrics['CWA']:.4f}\")\n        print(f\"validation SWA: {val_metrics['SWA']:.4f}\")\n        print(f\"validation HWA: {val_metrics['HWA']:.4f}\")\n        print(f\"validation loss: {val_loss:.4f}\")\n\n        # Test-set accuracy from saved predictions\n        test_acc = accuracy(d.get(\"ground_truth\", []), d.get(\"predictions\", []))\n        print(f\"test accuracy: {test_acc:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------------\n# 0. Locate and load the experiment data\n# ---------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------------\n# 1. Traverse datasets/tasks and print requested metrics\n# ---------------------------------------------------------------------------\nfor dataset_name, task_dict in experiment_data.items():\n    for task_name, info in task_dict.items():\n        prefix = f\"Dataset: {dataset_name}  (task {task_name})\"\n        print(prefix)\n\n        # --- best epoch handling ------------------------------------------------\n        best_epoch = info.get(\"best_epoch\", None)\n        # list indices start at 0, so subtract 1 if best_epoch is given\n        best_idx = (\n            best_epoch - 1 if isinstance(best_epoch, int) and best_epoch > 0 else -1\n        )\n\n        # --- training split: use final epoch -----------------------------------\n        final_train_loss = (\n            info[\"losses\"][\"train\"][-1] if info[\"losses\"][\"train\"] else None\n        )\n        final_train_met = (\n            info[\"metrics\"][\"train\"][-1] if info[\"metrics\"][\"train\"] else {}\n        )\n\n        # --- validation split: use best epoch ----------------------------------\n        final_val_loss = (\n            info[\"losses\"][\"val\"][best_idx] if info[\"losses\"][\"val\"] else None\n        )\n        final_val_met = (\n            info[\"metrics\"][\"val\"][best_idx] if info[\"metrics\"][\"val\"] else {}\n        )\n\n        # ----------------------------- printing -------------------------------\n        if final_train_loss is not None:\n            print(f\"  training loss: {final_train_loss:.6f}\")\n        if final_val_loss is not None:\n            print(f\"  validation loss: {final_val_loss:.6f}\")\n\n        for metric_name, value in final_train_met.items():\n            print(f\"  training {metric_name}: {value:.6f}\")\n\n        for metric_name, value in final_val_met.items():\n            print(f\"  validation {metric_name}: {value:.6f}\")\n\n        if best_epoch is not None:\n            print(f\"  best epoch: {best_epoch}\")\n\n        # blank line between datasets/tasks\n        print()\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# Locate and load the saved experiment dictionary\n# ---------------------------------------------------------------------\nwork_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(work_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# Helper to format floating point numbers uniformly\n# ---------------------------------------------------------------------\ndef fmt(x):\n    return f\"{x:.4f}\" if isinstance(x, (float, np.floating)) else str(x)\n\n\n# ---------------------------------------------------------------------\n# Walk through every dataset and task, printing the requested statistics\n# ---------------------------------------------------------------------\nfor dataset_name, task_dict in experiment_data.items():\n    for task_name, data in task_dict.items():\n        # Header: dataset / task identification\n        print(f\"{dataset_name} - {task_name}\")\n\n        # ----------------------- Train split ---------------------------\n        train_metrics = data[\"metrics\"][\"train\"][-1] if data[\"metrics\"][\"train\"] else {}\n        train_loss = data[\"losses\"][\"train\"][-1] if data[\"losses\"][\"train\"] else None\n        for metric_name, value in train_metrics.items():\n            print(f\"Final training {metric_name}: {fmt(value)}\")\n        if train_loss is not None:\n            print(f\"Final training loss: {fmt(train_loss)}\")\n\n        # ---------------------- Validation split ----------------------\n        val_metrics = data[\"metrics\"][\"val\"][-1] if data[\"metrics\"][\"val\"] else {}\n        val_loss = data[\"losses\"][\"val\"][-1] if data[\"losses\"][\"val\"] else None\n        for metric_name, value in val_metrics.items():\n            print(f\"Final validation {metric_name}: {fmt(value)}\")\n        if val_loss is not None:\n            print(f\"Final validation loss: {fmt(val_loss)}\")\n\n        # Best validation HWA (if available)\n        if data[\"metrics\"][\"val\"]:\n            best_val_hwa = max(m[\"HWA\"] for m in data[\"metrics\"][\"val\"])\n            best_epoch = data.get(\"best_epoch\", \"N/A\")\n            print(f\"Best validation HWA: {fmt(best_val_hwa)} (epoch {best_epoch})\")\n\n        print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ------------------------- Load data ------------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------- Pretty printer -------------------- #\ndef safe_get(lst, idx=-1):\n    \"\"\"Return lst[idx] if list is non-empty, else None.\"\"\"\n    return lst[idx] if lst else None\n\n\n# ------------------------- Traverse & report ----------------- #\nfor model_name, tasks in experiment_data.items():\n    for task_name, data in tasks.items():\n        print(f\"{model_name} - {task_name}\")\n\n        # Losses\n        final_train_loss = safe_get(data[\"losses\"].get(\"train\", []))\n        final_val_loss = safe_get(data[\"losses\"].get(\"val\", []))\n\n        # Metrics\n        final_train_met = safe_get(data[\"metrics\"].get(\"train\", []), -1) or {}\n        final_val_met = safe_get(data[\"metrics\"].get(\"val\", []), -1) or {}\n\n        # Print losses\n        if final_train_loss is not None:\n            print(f\"  final training loss: {final_train_loss:.4f}\")\n        if final_val_loss is not None:\n            print(f\"  final validation loss: {final_val_loss:.4f}\")\n\n        # Print metrics\n        for name, val in final_train_met.items():\n            print(f\"  final training {name}: {val:.4f}\")\n        for name, val in final_val_met.items():\n            print(f\"  final validation {name}: {val:.4f}\")\n\n        # Best epoch\n        if data.get(\"best_epoch\") is not None:\n            print(f\"  best validation epoch: {data['best_epoch']}\")\n\n        print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------------- #\n# locate and load the experiment data                                         #\n# --------------------------------------------------------------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# the file may contain several experiments \u2013 iterate through them\nfor exp_name, exp_dict in experiment_data.items():\n    for task_name, task in exp_dict.items():\n        print(f\"\\n===== {exp_name} - {task_name} =====\")\n\n        # ----------- TRAINING ------------------------------------------------ #\n        train_loss_final = task[\"losses\"][\"train\"][-1]\n        train_metrics_final = task[\"metrics\"][\"train\"][-1]\n        print(\"Training set\")\n        print(f\"  training loss: {train_loss_final:.4f}\")\n        print(f\"  training CWA:  {train_metrics_final['CWA']:.4f}\")\n        print(f\"  training SWA:  {train_metrics_final['SWA']:.4f}\")\n        print(f\"  training HWA:  {train_metrics_final['HWA']:.4f}\")\n\n        # ----------- VALIDATION (best epoch) --------------------------------- #\n        best_epoch = task[\"best_epoch\"]\n        if best_epoch is None:\n            best_epoch = len(task[\"epochs\"])  # fallback to last epoch\n        best_idx = task[\"epochs\"].index(best_epoch)\n        val_loss_best = task[\"losses\"][\"val\"][best_idx]\n        val_metrics_best = task[\"metrics\"][\"val\"][best_idx]\n        print(\"Validation set\")\n        print(f\"  validation loss (best): {val_loss_best:.4f}\")\n        print(f\"  validation CWA  (best): {val_metrics_best['CWA']:.4f}\")\n        print(f\"  validation SWA  (best): {val_metrics_best['SWA']:.4f}\")\n        print(f\"  validation HWA  (best): {val_metrics_best['HWA']:.4f}\")\n\n        # ----------- TEST ---------------------------------------------------- #\n        preds = task.get(\"predictions\", [])\n        gts = task.get(\"ground_truth\", [])\n        if preds and gts:\n            correct = sum(p == t for p, t in zip(preds, gts))\n            test_acc = correct / len(gts)\n            print(\"Test set\")\n            print(f\"  test accuracy: {test_acc:.4f}\")\n        else:\n            print(\"Test set\")\n            print(\"  test accuracy: N/A (predictions not stored)\")\n", "import os\nimport numpy as np\n\n# ----------------------- Load data ----------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------- Helper --------------------------- #\ndef print_dataset_metrics(ds_label, loss_value, metric_dict):\n    print(ds_label)\n    print(f\"Final {ds_label.lower()} loss: {loss_value:.4f}\")\n    for metric_name, metric_value in metric_dict.items():\n        print(f\"Final {ds_label.lower()} {metric_name}: {metric_value:.4f}\")\n    print()  # blank line for readability\n\n\n# -------------------- Extract & Print -------------------- #\nrun = experiment_data[\"NoColorEmbedding\"][\"SPR\"]\n\n# Training metrics (final epoch)\ntrain_loss_final = run[\"losses\"][\"train\"][-1]\ntrain_metrics_final = run[\"metrics\"][\"train\"][-1]\nprint_dataset_metrics(\"Training Set\", train_loss_final, train_metrics_final)\n\n# Validation metrics (final epoch)\nval_loss_final = run[\"losses\"][\"val\"][-1]\nval_metrics_final = run[\"metrics\"][\"val\"][-1]\nprint_dataset_metrics(\"Validation Set\", val_loss_final, val_metrics_final)\n\n# Test metrics \u2013 only predictions & ground truth were stored; compute accuracy\npred = run[\"predictions\"]\ngt = run[\"ground_truth\"]\nif pred and gt:\n    test_accuracy = sum(p == t for p, t in zip(pred, gt)) / len(gt)\n    print(\"Test Set\")\n    print(f\"Test accuracy: {test_accuracy:.4f}\")\n    print(f\"Best epoch (based on validation HWA): {run['best_epoch']}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------\n# Locate and load the saved experiment_data dictionary\n# ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------\n# Helper: nice float formatting\n# ------------------------------------------------------------\nfmt = lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else str(x)\n\n# ------------------------------------------------------------\n# Iterate over every dataset stored in experiment_data\n# ------------------------------------------------------------\nfor dataset_name, data_blob in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # ---------------- Training (final epoch) ----------------\n    train_metrics_list = data_blob[\"metrics\"][\"train\"]\n    train_losses_list = data_blob[\"losses\"][\"train\"]\n    train_final_metrics = train_metrics_list[-1]  # last epoch metrics\n    train_final_loss = train_losses_list[-1]\n\n    print(f\"training_CWA: {fmt(train_final_metrics['CWA'])}\")\n    print(f\"training_SWA: {fmt(train_final_metrics['SWA'])}\")\n    print(f\"training_HWA: {fmt(train_final_metrics['HWA'])}\")\n    print(f\"training_loss: {fmt(train_final_loss)}\")\n\n    # -------------- Validation (best epoch by HWA) ----------\n    best_epoch = data_blob.get(\"best_epoch\")\n    if best_epoch is None:\n        best_idx = -1  # fallback to last epoch\n    else:\n        best_idx = best_epoch - 1  # epochs are 1-indexed\n\n    val_metrics_list = data_blob[\"metrics\"][\"val\"]\n    val_losses_list = data_blob[\"losses\"][\"val\"]\n    val_best_metrics = val_metrics_list[best_idx]\n    val_best_loss = val_losses_list[best_idx]\n\n    print(f\"validation_CWA: {fmt(val_best_metrics['CWA'])}\")\n    print(f\"validation_SWA: {fmt(val_best_metrics['SWA'])}\")\n    print(f\"validation_HWA: {fmt(val_best_metrics['HWA'])}\")\n    print(f\"validation_loss: {fmt(val_best_loss)}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------\n# Locate and load the saved experiment_data dictionary\n# ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------\n# Helper: nice float formatting\n# ------------------------------------------------------------\nfmt = lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else str(x)\n\n# ------------------------------------------------------------\n# Iterate over every dataset stored in experiment_data\n# ------------------------------------------------------------\nfor dataset_name, data_blob in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # ---------------- Training (final epoch) ----------------\n    train_metrics_list = data_blob[\"metrics\"][\"train\"]\n    train_losses_list = data_blob[\"losses\"][\"train\"]\n    train_final_metrics = train_metrics_list[-1]  # last epoch metrics\n    train_final_loss = train_losses_list[-1]\n\n    print(f\"training_CWA: {fmt(train_final_metrics['CWA'])}\")\n    print(f\"training_SWA: {fmt(train_final_metrics['SWA'])}\")\n    print(f\"training_HWA: {fmt(train_final_metrics['HWA'])}\")\n    print(f\"training_loss: {fmt(train_final_loss)}\")\n\n    # -------------- Validation (best epoch by HWA) ----------\n    best_epoch = data_blob.get(\"best_epoch\")\n    if best_epoch is None:\n        best_idx = -1  # fallback to last epoch\n    else:\n        best_idx = best_epoch - 1  # epochs are 1-indexed\n\n    val_metrics_list = data_blob[\"metrics\"][\"val\"]\n    val_losses_list = data_blob[\"losses\"][\"val\"]\n    val_best_metrics = val_metrics_list[best_idx]\n    val_best_loss = val_losses_list[best_idx]\n\n    print(f\"validation_CWA: {fmt(val_best_metrics['CWA'])}\")\n    print(f\"validation_SWA: {fmt(val_best_metrics['SWA'])}\")\n    print(f\"validation_HWA: {fmt(val_best_metrics['HWA'])}\")\n    print(f\"validation_loss: {fmt(val_best_loss)}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------\n# Locate and load the saved experiment_data dictionary\n# ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------\n# Helper: nice float formatting\n# ------------------------------------------------------------\nfmt = lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else str(x)\n\n# ------------------------------------------------------------\n# Iterate over every dataset stored in experiment_data\n# ------------------------------------------------------------\nfor dataset_name, data_blob in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # ---------------- Training (final epoch) ----------------\n    train_metrics_list = data_blob[\"metrics\"][\"train\"]\n    train_losses_list = data_blob[\"losses\"][\"train\"]\n    train_final_metrics = train_metrics_list[-1]  # last epoch metrics\n    train_final_loss = train_losses_list[-1]\n\n    print(f\"training_CWA: {fmt(train_final_metrics['CWA'])}\")\n    print(f\"training_SWA: {fmt(train_final_metrics['SWA'])}\")\n    print(f\"training_HWA: {fmt(train_final_metrics['HWA'])}\")\n    print(f\"training_loss: {fmt(train_final_loss)}\")\n\n    # -------------- Validation (best epoch by HWA) ----------\n    best_epoch = data_blob.get(\"best_epoch\")\n    if best_epoch is None:\n        best_idx = -1  # fallback to last epoch\n    else:\n        best_idx = best_epoch - 1  # epochs are 1-indexed\n\n    val_metrics_list = data_blob[\"metrics\"][\"val\"]\n    val_losses_list = data_blob[\"losses\"][\"val\"]\n    val_best_metrics = val_metrics_list[best_idx]\n    val_best_loss = val_losses_list[best_idx]\n\n    print(f\"validation_CWA: {fmt(val_best_metrics['CWA'])}\")\n    print(f\"validation_SWA: {fmt(val_best_metrics['SWA'])}\")\n    print(f\"validation_HWA: {fmt(val_best_metrics['HWA'])}\")\n    print(f\"validation_loss: {fmt(val_best_loss)}\")\n", ""], "parse_term_out": ["['SPR', '\\n', 'training_CWA: 0.7311', '\\n', 'training_SWA: 0.7284', '\\n',\n'training_HWA: 0.7297', '\\n', 'training_loss: 0.8067', '\\n', 'validation_CWA:\n0.7292', '\\n', 'validation_SWA: 0.7434', '\\n', 'validation_HWA: 0.7362', '\\n',\n'validation_loss: 0.8700', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['\\n=== Dataset: SPR ===', '\\n', 'train CWA: 0.7269', '\\n', 'train SWA: 0.7253',\n'\\n', 'train HWA: 0.7261', '\\n', 'train loss: 0.7575', '\\n', 'validation CWA:\n0.7219', '\\n', 'validation SWA: 0.7119', '\\n', 'validation HWA: 0.7169', '\\n',\n'validation loss: 0.8173', '\\n', 'test accuracy: 0.6500', '\\n', 'Execution time:\na moment seconds (time limit is 30 minutes).']", "['TRAINING DATASET', '\\n', 'train CWA: 0.7315', '\\n', 'train SWA: 0.7305', '\\n',\n'train HWA: 0.7310', '\\n', '\\nVALIDATION DATASET', '\\n', 'validation CWA:\n0.7140', '\\n', 'validation SWA: 0.7086', '\\n', 'validation HWA: 0.7113', '\\n',\n'\\nTEST DATASET', '\\n', 'test accuracy: 0.6540', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['Dataset: SPR  (Model: NoMultiHead)', '\\n', 'training CWA: 0.6936', '\\n',\n'training SWA: 0.6943', '\\n', 'training HWA: 0.6939', '\\n', 'validation CWA:\n0.7300', '\\n', 'validation SWA: 0.7295', '\\n', 'validation HWA: 0.7297', '\\n',\n'validation loss: 0.8711', '\\n', 'test accuracy: 0.6400\\n', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['Dataset: no_chain_edges  (task SPR)', '\\n', '  training loss: 0.849299', '\\n',\n'  validation loss: 0.900952', '\\n', '  training CWA: 0.716572', '\\n', '\ntraining SWA: 0.720098', '\\n', '  training HWA: 0.718331', '\\n', '  validation\nCWA: 0.683584', '\\n', '  validation SWA: 0.687422', '\\n', '  validation HWA:\n0.685498', '\\n', '  best epoch: 14', '\\n', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['NoBiDir - SPR', '\\n', 'Final training CWA: 0.7006', '\\n', 'Final training SWA:\n0.6994', '\\n', 'Final training HWA: 0.7000', '\\n', 'Final training loss:\n0.8465', '\\n', 'Final validation CWA: 0.6941', '\\n', 'Final validation SWA:\n0.6949', '\\n', 'Final validation HWA: 0.6945', '\\n', 'Final validation loss:\n0.8524', '\\n', 'Best validation HWA: 0.6945 (epoch 15)', '\\n', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['NoNodeFeatures - SPR', '\\n', '  final training loss: 1.1640', '\\n', '  final\nvalidation loss: 1.1610', '\\n', '  final training CWA: 0.7034', '\\n', '  final\ntraining SWA: 0.6979', '\\n', '  final training HWA: 0.7007', '\\n', '  final\nvalidation CWA: 0.7001', '\\n', '  final validation SWA: 0.6969', '\\n', '  final\nvalidation HWA: 0.6985', '\\n', '  best validation epoch: 4', '\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\n===== single_gat_layer - SPR =====', '\\n', 'Training set', '\\n', '  training\nloss: 0.8733', '\\n', '  training CWA:  0.7146', '\\n', '  training SWA:  0.7152',\n'\\n', '  training HWA:  0.7149', '\\n', 'Validation set', '\\n', '  validation\nloss (best): 1.0163', '\\n', '  validation CWA  (best): 0.7079', '\\n', '\nvalidation SWA  (best): 0.7007', '\\n', '  validation HWA  (best): 0.7043', '\\n',\n'Test set', '\\n', '  test accuracy: 0.6360', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['Training Set', '\\n', 'Final training set loss: 0.8133', '\\n', 'Final training\nset CWA: 0.7231', '\\n', 'Final training set SWA: 0.7197', '\\n', 'Final training\nset HWA: 0.7214', '\\n', '\\n', 'Validation Set', '\\n', 'Final validation set\nloss: 0.8094', '\\n', 'Final validation set CWA: 0.7202', '\\n', 'Final validation\nset SWA: 0.7183', '\\n', 'Final validation set HWA: 0.7192', '\\n', '\\n', 'Test\nSet', '\\n', 'Test accuracy: 0.6540', '\\n', 'Best epoch (based on validation\nHWA): 15', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR', '\\n', 'training_CWA: 0.7121', '\\n', 'training_SWA: 0.7142', '\\n',\n'training_HWA: 0.7132', '\\n', 'training_loss: 0.8522', '\\n', 'validation_CWA:\n0.6972', '\\n', 'validation_SWA: 0.6980', '\\n', 'validation_HWA: 0.6976', '\\n',\n'validation_loss: 0.9467', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['SPR', '\\n', 'training_CWA: 0.7083', '\\n', 'training_SWA: 0.7067', '\\n',\n'training_HWA: 0.7075', '\\n', 'training_loss: 0.7952', '\\n', 'validation_CWA:\n0.6940', '\\n', 'validation_SWA: 0.6849', '\\n', 'validation_HWA: 0.6894', '\\n',\n'validation_loss: 0.9722', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['SPR', '\\n', 'training_CWA: 0.7157', '\\n', 'training_SWA: 0.7163', '\\n',\n'training_HWA: 0.7160', '\\n', 'training_loss: 0.8483', '\\n', 'validation_CWA:\n0.6964', '\\n', 'validation_SWA: 0.7028', '\\n', 'validation_HWA: 0.6996', '\\n',\n'validation_loss: 0.9111', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
