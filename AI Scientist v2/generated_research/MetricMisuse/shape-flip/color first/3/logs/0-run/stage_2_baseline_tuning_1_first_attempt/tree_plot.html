<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 2], [0, 1], [0, 3], [0, 4]], "layout": [[0.5, 0.0], [0.0, 1.0], [0.3333333333333333, 1.0], [0.6666666666666666, 1.0], [1.0, 1.0]], "plan": ["The crash occurred because the script looked for the SPR_BENCH folder only in\nthe current working directory while the real data live elsewhere.   I add a\nsmall helper that automatically searches several likely locations (current dir,\nparent dir, an absolute fallback path, or the path stored in the environment\nvariable SPR_DATA_PATH).   If the data are still not found a clear error is\nraised that tells the user how to fix things.   Nothing else in the pipeline has\nto change, so training / evaluation logic remains untouched but now runs\nsuccessfully as soon as the data are detected.", "Hyperparam tuning name: num_epochs. The solution simply extends training to a\nlarger maximum epoch budget (30) and introduces an early-stopping mechanism that\nmonitors the dev BWA.  Training halts if BWA has not improved for five\nconsecutive epochs, preventing unnecessary over-training.  All metrics, losses\nand timestamps are logged under the hyperparameter-tuning key \u200b\"num_epochs\" in\nthe experiment_data dictionary and saved to \u201cexperiment_data.npy\u201d; the learning\npipeline, dataset construction and evaluation logic remain identical to the\nbaseline.", "Hyperparam tuning name: learning_rate. We perform a small grid-search over Adam\nlearning rates {3e-4, 5e-4, 1e-3, 2e-3}.   For each rate we re-initialize the\nGCN, train for 5 epochs, track train/dev losses and BWA, and finally evaluate on\nthe test set.   All results are stored in a hierarchical experiment_data dict\nunder the key \u201clearning_rate\u201d, with one sub-dictionary per lr value.   After the\nloop we identify and report the lr that achieves the highest dev-set BWA; all\nmetrics/arrays are saved to experiment_data.npy and a comparison plot is written\nto disk.", "Hyperparam tuning name: batch_size. We iterate over a list of candidate batch\nsizes (16, 32, 64, 128).   For every batch size we rebuild the DataLoaders, re-\ninitialise the GCN model, and train for a small, fixed number of epochs while\nlogging per-epoch losses and BWAs.   All results are stored in a nested\nexperiment_data dict under the outer key \"batch_size\", then saved to\nexperiment_data.npy; a BWA curve is also saved for each batch size.", "Hyperparam tuning name: dropout_rate. Proposed solution: add a command-line\u2013free\ngrid\u2013search that trains the model 5 epochs for every dropout probability in a\nsmall list (0.0\u20130.4).   For each value we (1) build a fresh model with that\ndropout, (2) train, (3) record per-epoch train/dev BWA and losses, and (4)\nremember the model that achieves the best dev BWA.   After the sweep we run a\nfinal test evaluation with the best-performing checkpoint, store/plot the\ncorresponding curves, and save every metric in the required\n`experiment_data.npy` file under the top-level key `dropout_rate`."], "code": ["import os, pathlib, time, numpy as np, torch, torch.nn as nn, matplotlib.pyplot as plt\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom typing import List\nfrom datasets import DatasetDict, load_dataset\n\n# ---------------------------------------------------------------------\n# mandatory working dir\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# mandatory device handling\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# ---------- Helper to locate the dataset -----------------------------\ndef locate_spr_bench() -> pathlib.Path:\n    \"\"\"\n    Try a list of plausible locations or an environment variable.\n    \"\"\"\n    candidates = [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"../SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n        pathlib.Path(os.getenv(\"SPR_DATA_PATH\", \"\")),\n    ]\n    for p in candidates:\n        if p and (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p.resolve()}\")\n            return p.resolve()\n    raise FileNotFoundError(\n        \"SPR_BENCH dataset not found. Place the folder in the current or parent \"\n        \"directory or set the environment variable SPR_DATA_PATH to its location.\"\n    )\n\n\n# ---------------------------------------------------------------------\n# ---------- Provided helpers (unchanged aside from path logic) -------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(t[1] for t in sequence.strip().split() if len(t) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(t[0] for t in sequence.strip().split() if t))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / (sum(w) if sum(w) > 0 else 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / (sum(w) if sum(w) > 0 else 1)\n\n\n# ---------------------------------------------------------------------\n# ---------- Load dataset ---------------------------------------------\nDATA_PATH = locate_spr_bench()\nspr = load_spr_bench(DATA_PATH)\n\n\n# ---------------------------------------------------------------------\n# ---------- Build vocabularies ---------------------------------------\ndef extract_tokens(seq: str) -> List[str]:\n    return seq.strip().split()\n\n\ntoken_set, label_set = set(), set()\nfor ex in spr[\"train\"]:\n    token_set.update(extract_tokens(ex[\"sequence\"]))\n    label_set.add(ex[\"label\"])\n\ntoken2idx = {tok: i + 1 for i, tok in enumerate(sorted(token_set))}\nlabel2idx = {lab: i for i, lab in enumerate(sorted(label_set))}\nidx2label = {i: lab for lab, i in label2idx.items()}\n\n\n# ---------------------------------------------------------------------\n# ---------- Graph construction ---------------------------------------\ndef seq_to_data(example):\n    seq = example[\"sequence\"]\n    tokens = extract_tokens(seq)\n    node_indices = [token2idx.get(tok, 0) for tok in tokens]\n    x = torch.tensor(node_indices, dtype=torch.long).unsqueeze(-1)\n\n    if len(tokens) > 1:\n        src = torch.arange(0, len(tokens) - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n\n    y = torch.tensor([label2idx[example[\"label\"]]], dtype=torch.long)\n    data = Data(x=x, edge_index=edge_index, y=y)\n    data.seq = seq  # keep original for metrics\n    return data\n\n\ntrain_graphs = [seq_to_data(ex) for ex in spr[\"train\"]]\ndev_graphs = [seq_to_data(ex) for ex in spr[\"dev\"]]\ntest_graphs = [seq_to_data(ex) for ex in spr[\"test\"]]\n\nbatch_size = 64\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n\n\n# ---------------------------------------------------------------------\n# ---------- Model -----------------------------------------------------\nclass SPR_GCN(nn.Module):\n    def __init__(self, vocab_size: int, embed_dim: int, num_classes: int):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size + 1, embed_dim, padding_idx=0)\n        self.gcn1 = GCNConv(embed_dim, 64)\n        self.gcn2 = GCNConv(64, 64)\n        self.lin = nn.Linear(64, num_classes)\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x, edge_index, batch):\n        x = self.embed(x.squeeze(-1))\n        x = self.gcn1(x, edge_index).relu()\n        x = self.gcn2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        x = self.dropout(x)\n        return self.lin(x)\n\n\nmodel = SPR_GCN(len(token2idx), 32, len(label2idx)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------------------------------------------------------------------\n# ---------- Experiment data dict -------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\n# ---------------------------------------------------------------------\n# ---------- Evaluation function --------------------------------------\ndef evaluate(loader):\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    total_loss = 0.0\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = criterion(out, batch.y.view(-1))\n            total_loss += loss.item() * batch.num_graphs\n            preds = out.argmax(dim=-1).cpu().tolist()\n            labels = batch.y.view(-1).cpu().tolist()\n            seqs = batch.seq\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n            all_seqs.extend(seqs)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    bwa = (cwa + swa) / 2.0\n    avg_loss = total_loss / len(loader.dataset)\n    return avg_loss, bwa, cwa, swa, all_preds, all_labels\n\n\n# ---------------------------------------------------------------------\n# ---------- Training loop --------------------------------------------\nnum_epochs = 5\nfor epoch in range(1, num_epochs + 1):\n    model.train()\n    epoch_loss = 0.0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch.x, batch.edge_index, batch.batch)\n        loss = criterion(out, batch.y.view(-1))\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item() * batch.num_graphs\n    train_loss = epoch_loss / len(train_loader.dataset)\n\n    val_loss, val_bwa, val_cwa, val_swa, _, _ = evaluate(dev_loader)\n    _, train_bwa, _, _, _, _ = evaluate(train_loader)\n\n    # log\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(train_bwa)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(val_bwa)\n    experiment_data[\"SPR_BENCH\"][\"timestamps\"].append(time.time())\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f}  \"\n        f\"val_loss={val_loss:.4f}  BWA={val_bwa:.4f} \"\n        f\"(CWA={val_cwa:.4f}, SWA={val_swa:.4f})\"\n    )\n\n# ---------------------------------------------------------------------\n# ---------- Save metrics ---------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# ---------------------------------------------------------------------\n# ---------- Plotting --------------------------------------------------\nepochs = np.arange(1, num_epochs + 1)\nplt.figure()\nplt.plot(epochs, experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"], label=\"Train BWA\")\nplt.plot(epochs, experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"], label=\"Dev BWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"BWA\")\nplt.title(\"BWA over epochs\")\nplt.legend()\nplt.tight_layout()\nplot_path = os.path.join(working_dir, \"bwa_curve_spr.png\")\nplt.savefig(plot_path)\nprint(f\"Curve saved to {plot_path}\")\n\n# ---------------------------------------------------------------------\n# ---------- Final test evaluation ------------------------------------\ntest_loss, test_bwa, test_cwa, test_swa, test_preds, test_labels = evaluate(test_loader)\nprint(\n    f\"Final Test -> loss: {test_loss:.4f}  BWA: {test_bwa:.4f}  \"\n    f\"CWA: {test_cwa:.4f}  SWA: {test_swa:.4f}\"\n)\n\n# Store predictions for further analysis\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = test_preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = test_labels\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, time, numpy as np, torch, torch.nn as nn, matplotlib.pyplot as plt\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom typing import List\nfrom datasets import DatasetDict, load_dataset\n\n# ------------------------------------------------------------\n# mandatory working dir\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------\ndef locate_spr_bench() -> pathlib.Path:\n    candidates = [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"../SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n        pathlib.Path(os.getenv(\"SPR_DATA_PATH\", \"\")),\n    ]\n    for p in candidates:\n        if p and (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p.resolve()}\")\n            return p.resolve()\n    raise FileNotFoundError(\"SPR_BENCH dataset not found.\")\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(f):  # helper\n        return load_dataset(\n            \"csv\", data_files=str(root / f), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(t[1] for t in sequence.strip().split() if len(t) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(t[0] for t in sequence.strip().split() if t))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / (sum(w) if sum(w) > 0 else 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / (sum(w) if sum(w) > 0 else 1)\n\n\n# ------------------------------------------------------------\nDATA_PATH = locate_spr_bench()\nspr = load_spr_bench(DATA_PATH)\n\n\ndef extract_tokens(seq: str) -> List[str]:\n    return seq.strip().split()\n\n\ntoken_set, label_set = set(), set()\nfor ex in spr[\"train\"]:\n    token_set.update(extract_tokens(ex[\"sequence\"]))\n    label_set.add(ex[\"label\"])\ntoken2idx = {tok: i + 1 for i, tok in enumerate(sorted(token_set))}\nlabel2idx = {lab: i for i, lab in enumerate(sorted(label_set))}\nidx2label = {i: lab for lab, i in label2idx.items()}\n\n\ndef seq_to_data(example):\n    seq = example[\"sequence\"]\n    tokens = extract_tokens(seq)\n    node_indices = [token2idx.get(tok, 0) for tok in tokens]\n    x = torch.tensor(node_indices, dtype=torch.long).unsqueeze(-1)\n    if len(tokens) > 1:\n        src = torch.arange(0, len(tokens) - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[example[\"label\"]]], dtype=torch.long)\n    data = Data(x=x, edge_index=edge_index, y=y)\n    data.seq = seq\n    return data\n\n\ntrain_graphs = [seq_to_data(ex) for ex in spr[\"train\"]]\ndev_graphs = [seq_to_data(ex) for ex in spr[\"dev\"]]\ntest_graphs = [seq_to_data(ex) for ex in spr[\"test\"]]\n\nbatch_size = 64\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n\n\n# ------------------------------------------------------------\nclass SPR_GCN(nn.Module):\n    def __init__(self, vocab_size: int, embed_dim: int, num_classes: int):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size + 1, embed_dim, padding_idx=0)\n        self.gcn1 = GCNConv(embed_dim, 64)\n        self.gcn2 = GCNConv(64, 64)\n        self.lin = nn.Linear(64, num_classes)\n        self.drop = nn.Dropout(0.2)\n\n    def forward(self, x, edge_index, batch):\n        x = self.embed(x.squeeze(-1))\n        x = self.gcn1(x, edge_index).relu()\n        x = self.gcn2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        x = self.drop(x)\n        return self.lin(x)\n\n\nmodel = SPR_GCN(len(token2idx), 32, len(label2idx)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ------------------------------------------------------------\nexperiment_data = {\n    \"num_epochs\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n\n# ------------------------------------------------------------\ndef evaluate(loader):\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    total_loss = 0.0\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            logits = model(batch.x, batch.edge_index, batch.batch)\n            loss = criterion(logits, batch.y.view(-1))\n            total_loss += loss.item() * batch.num_graphs\n            preds = logits.argmax(-1).cpu().tolist()\n            labels = batch.y.view(-1).cpu().tolist()\n            seqs = batch.seq\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n            all_seqs.extend(seqs)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    bwa = (cwa + swa) / 2.0\n    return total_loss / len(loader.dataset), bwa, cwa, swa, all_preds, all_labels\n\n\n# ------------------------------------------------------------\nmax_epochs = 30  # increased budget\npatience = 5  # early stopping patience\nbest_val_bwa = -1.0\nepochs_no_improve = 0\nactual_epochs_run = 0\n\nfor epoch in range(1, max_epochs + 1):\n    actual_epochs_run += 1\n    model.train()\n    accum_loss = 0.0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        logits = model(batch.x, batch.edge_index, batch.batch)\n        loss = criterion(logits, batch.y.view(-1))\n        loss.backward()\n        optimizer.step()\n        accum_loss += loss.item() * batch.num_graphs\n    train_loss = accum_loss / len(train_loader.dataset)\n\n    val_loss, val_bwa, val_cwa, val_swa, _, _ = evaluate(dev_loader)\n    _, train_bwa, _, _, _, _ = evaluate(train_loader)\n\n    # logging\n    edict = experiment_data[\"num_epochs\"][\"SPR_BENCH\"]\n    edict[\"losses\"][\"train\"].append(train_loss)\n    edict[\"losses\"][\"val\"].append(val_loss)\n    edict[\"metrics\"][\"train\"].append(train_bwa)\n    edict[\"metrics\"][\"val\"].append(val_bwa)\n    edict[\"timestamps\"].append(time.time())\n\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n        f\"BWA={val_bwa:.4f} (CWA={val_cwa:.4f}, SWA={val_swa:.4f})\"\n    )\n\n    # early stopping logic\n    if val_bwa > best_val_bwa + 1e-6:\n        best_val_bwa = val_bwa\n        epochs_no_improve = 0\n        best_state = model.state_dict()\n    else:\n        epochs_no_improve += 1\n        if epochs_no_improve >= patience:\n            print(\n                f\"No improvement for {patience} epochs; early stopping at epoch {epoch}.\"\n            )\n            break\n\n# ------------------------------------------------------------\nprint(\n    f\"Training finished after {actual_epochs_run} epochs; best dev BWA = {best_val_bwa:.4f}\"\n)\n# Load best weights before final test evaluation\nmodel.load_state_dict(best_state)\n\nepochs = np.arange(\n    1, len(experiment_data[\"num_epochs\"][\"SPR_BENCH\"][\"metrics\"][\"val\"]) + 1\n)\nplt.figure()\nplt.plot(\n    epochs,\n    experiment_data[\"num_epochs\"][\"SPR_BENCH\"][\"metrics\"][\"train\"],\n    label=\"Train BWA\",\n)\nplt.plot(\n    epochs,\n    experiment_data[\"num_epochs\"][\"SPR_BENCH\"][\"metrics\"][\"val\"],\n    label=\"Dev BWA\",\n)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"BWA\")\nplt.title(\"BWA over epochs (tuned num_epochs)\")\nplt.legend()\nplt.tight_layout()\nplot_path = os.path.join(working_dir, \"bwa_curve_spr.png\")\nplt.savefig(plot_path)\nprint(f\"Curve saved to {plot_path}\")\n\n# ------------------------------------------------------------\ntest_loss, test_bwa, test_cwa, test_swa, test_preds, test_labels = evaluate(test_loader)\nprint(\n    f\"Final Test -> loss: {test_loss:.4f}  BWA: {test_bwa:.4f}  \"\n    f\"CWA: {test_cwa:.4f}  SWA: {test_swa:.4f}\"\n)\n\n# store predictions\nedict = experiment_data[\"num_epochs\"][\"SPR_BENCH\"]\nedict[\"predictions\"] = test_preds\nedict[\"ground_truth\"] = test_labels\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, time, numpy as np, torch, torch.nn as nn, matplotlib.pyplot as plt\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom typing import List\nfrom datasets import DatasetDict, load_dataset\n\n# --------------------------- working dir ----------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --------------------------- device ---------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# --------------------------- locate dataset -------------------------------\ndef locate_spr_bench() -> pathlib.Path:\n    candidates = [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"../SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n        pathlib.Path(os.getenv(\"SPR_DATA_PATH\", \"\")),\n    ]\n    for p in candidates:\n        if p and (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p.resolve()}\")\n            return p.resolve()\n    raise FileNotFoundError(\n        \"SPR_BENCH dataset not found. Place it appropriately or \"\n        \"set SPR_DATA_PATH env var.\"\n    )\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(t[1] for t in sequence.strip().split() if len(t) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(t[0] for t in sequence.strip().split() if t))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / (sum(w) if sum(w) > 0 else 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / (sum(w) if sum(w) > 0 else 1)\n\n\n# --------------------------- load -----------------------------------------\nDATA_PATH = locate_spr_bench()\nspr = load_spr_bench(DATA_PATH)\n\n\n# --------------------------- vocab ----------------------------------------\ndef extract_tokens(seq: str) -> List[str]:\n    return seq.strip().split()\n\n\ntoken_set, label_set = set(), set()\nfor ex in spr[\"train\"]:\n    token_set.update(extract_tokens(ex[\"sequence\"]))\n    label_set.add(ex[\"label\"])\ntoken2idx = {tok: i + 1 for i, tok in enumerate(sorted(token_set))}\nlabel2idx = {lab: i for i, lab in enumerate(sorted(label_set))}\nidx2label = {i: lab for lab, i in label2idx.items()}\n\n\n# --------------------------- graphs ---------------------------------------\ndef seq_to_data(example):\n    seq = example[\"sequence\"]\n    tokens = extract_tokens(seq)\n    node_indices = [token2idx.get(tok, 0) for tok in tokens]\n    x = torch.tensor(node_indices, dtype=torch.long).unsqueeze(-1)\n    if len(tokens) > 1:\n        src = torch.arange(0, len(tokens) - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[example[\"label\"]]], dtype=torch.long)\n    data = Data(x=x, edge_index=edge_index, y=y)\n    data.seq = seq\n    return data\n\n\ntrain_graphs = [seq_to_data(ex) for ex in spr[\"train\"]]\ndev_graphs = [seq_to_data(ex) for ex in spr[\"dev\"]]\ntest_graphs = [seq_to_data(ex) for ex in spr[\"test\"]]\n\nbatch_size = 64\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n\n\n# --------------------------- model ----------------------------------------\nclass SPR_GCN(nn.Module):\n    def __init__(self, vocab_size: int, embed_dim: int, num_classes: int):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size + 1, embed_dim, padding_idx=0)\n        self.gcn1 = GCNConv(embed_dim, 64)\n        self.gcn2 = GCNConv(64, 64)\n        self.lin = nn.Linear(64, num_classes)\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x, edge_index, batch):\n        x = self.embed(x.squeeze(-1))\n        x = self.gcn1(x, edge_index).relu()\n        x = self.gcn2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        x = self.dropout(x)\n        return self.lin(x)\n\n\n# --------------------------- evaluation -----------------------------------\ndef evaluate(model, loader, criterion):\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    total_loss = 0.0\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = criterion(out, batch.y.view(-1))\n            total_loss += loss.item() * batch.num_graphs\n            preds = out.argmax(dim=-1).cpu().tolist()\n            labels = batch.y.view(-1).cpu().tolist()\n            seqs = batch.seq\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n            all_seqs.extend(seqs)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    bwa = (cwa + swa) / 2.0\n    avg_loss = total_loss / len(loader.dataset)\n    return avg_loss, bwa, cwa, swa, all_preds, all_labels\n\n\n# --------------------------- experiment dict ------------------------------\nexperiment_data = {\"learning_rate\": {}}\n\n# --------------------------- hyperparameter grid --------------------------\ngrid_lrs = [3e-4, 5e-4, 1e-3, 2e-3]\nnum_epochs = 5\nbest_lr, best_bwa = None, -1\n\nfor lr in grid_lrs:\n    print(f\"\\n=== Training with learning_rate = {lr} ===\")\n    torch.manual_seed(42)\n    np.random.seed(42)\n    model = SPR_GCN(len(token2idx), 32, len(label2idx)).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    exp_key = f\"lr_{lr}\"\n    experiment_data[\"learning_rate\"].setdefault(\"SPR_BENCH\", {})[exp_key] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        epoch_loss = 0.0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = criterion(out, batch.y.view(-1))\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item() * batch.num_graphs\n        train_loss = epoch_loss / len(train_loader.dataset)\n\n        val_loss, val_bwa, val_cwa, val_swa, _, _ = evaluate(\n            model, dev_loader, criterion\n        )\n        _, train_bwa, _, _, _, _ = evaluate(model, train_loader, criterion)\n\n        # log\n        exp_rec = experiment_data[\"learning_rate\"][\"SPR_BENCH\"][exp_key]\n        exp_rec[\"losses\"][\"train\"].append(train_loss)\n        exp_rec[\"losses\"][\"val\"].append(val_loss)\n        exp_rec[\"metrics\"][\"train\"].append(train_bwa)\n        exp_rec[\"metrics\"][\"val\"].append(val_bwa)\n        exp_rec[\"timestamps\"].append(time.time())\n\n        print(\n            f\"Epoch {epoch} | train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"BWA={val_bwa:.4f} (CWA={val_cwa:.4f}, SWA={val_swa:.4f})\"\n        )\n\n    # final test evaluation for this lr\n    test_loss, test_bwa, test_cwa, test_swa, test_preds, test_labels = evaluate(\n        model, test_loader, criterion\n    )\n    exp_rec[\"predictions\"] = test_preds\n    exp_rec[\"ground_truth\"] = test_labels\n    exp_rec[\"test_loss\"] = test_loss\n    exp_rec[\"test_bwa\"] = test_bwa\n\n    print(\n        f\"Test -> loss: {test_loss:.4f}  BWA: {test_bwa:.4f} \"\n        f\"CWA: {test_cwa:.4f} SWA: {test_swa:.4f}\"\n    )\n\n    if val_bwa > best_bwa:\n        best_bwa, best_lr = val_bwa, lr\n\n    # house-keeping\n    del model\n    torch.cuda.empty_cache()\n\n# --------------------------- summary --------------------------------------\nprint(f\"\\nBest learning_rate based on dev BWA: {best_lr} (BWA={best_bwa:.4f})\")\n\n# --------------------------- plotting -------------------------------------\nplt.figure()\nfor lr in grid_lrs:\n    exp_key = f\"lr_{lr}\"\n    val_bwa_hist = experiment_data[\"learning_rate\"][\"SPR_BENCH\"][exp_key][\"metrics\"][\n        \"val\"\n    ]\n    plt.plot(range(1, num_epochs + 1), val_bwa_hist, label=f\"lr={lr}\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Dev BWA\")\nplt.title(\"Learning-rate tuning on SPR_BENCH\")\nplt.legend()\nplt.tight_layout()\nplot_path = os.path.join(working_dir, \"lr_tuning_bwa_curve.png\")\nplt.savefig(plot_path)\nprint(f\"Curve saved to {plot_path}\")\n\n# --------------------------- save results ---------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All experiment data saved.\")\n", "import os, pathlib, time, numpy as np, torch, torch.nn as nn, matplotlib.pyplot as plt\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom typing import List\nfrom datasets import DatasetDict, load_dataset\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\ndef locate_spr_bench() -> pathlib.Path:\n    candidates = [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"../SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n        pathlib.Path(os.getenv(\"SPR_DATA_PATH\", \"\")),\n    ]\n    for p in candidates:\n        if p and (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p.resolve()}\")\n            return p.resolve()\n    raise FileNotFoundError(\"SPR_BENCH dataset not found. Set SPR_DATA_PATH env var.\")\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):  # helper\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split()))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / (sum(w) if sum(w) > 0 else 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / (sum(w) if sum(w) > 0 else 1)\n\n\n# ---------------------------------------------------------------------\nDATA_PATH = locate_spr_bench()\nspr = load_spr_bench(DATA_PATH)\n\n\ndef extract_tokens(seq: str) -> List[str]:\n    return seq.strip().split()\n\n\ntoken_set, label_set = set(), set()\nfor ex in spr[\"train\"]:\n    token_set.update(extract_tokens(ex[\"sequence\"]))\n    label_set.add(ex[\"label\"])\n\ntoken2idx = {tok: i + 1 for i, tok in enumerate(sorted(token_set))}\nlabel2idx = {lab: i for i, lab in enumerate(sorted(label_set))}\nidx2label = {i: lab for lab, i in label2idx.items()}\n\n\ndef seq_to_data(example):\n    seq = example[\"sequence\"]\n    tokens = extract_tokens(seq)\n    node_idx = [token2idx.get(t, 0) for t in tokens]\n    x = torch.tensor(node_idx, dtype=torch.long).unsqueeze(-1)\n    if len(tokens) > 1:\n        src = torch.arange(len(tokens) - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], 0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[example[\"label\"]]], dtype=torch.long)\n    data = Data(x=x, edge_index=edge_index, y=y)\n    data.seq = seq\n    return data\n\n\ntrain_graphs = [seq_to_data(ex) for ex in spr[\"train\"]]\ndev_graphs = [seq_to_data(ex) for ex in spr[\"dev\"]]\ntest_graphs = [seq_to_data(ex) for ex in spr[\"test\"]]\n\n\n# ---------------------------------------------------------------------\nclass SPR_GCN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size + 1, embed_dim, padding_idx=0)\n        self.g1 = GCNConv(embed_dim, 64)\n        self.g2 = GCNConv(64, 64)\n        self.lin = nn.Linear(64, num_classes)\n        self.drop = nn.Dropout(0.2)\n\n    def forward(self, x, edge_index, batch):\n        x = self.embed(x.squeeze(-1))\n        x = self.g1(x, edge_index).relu()\n        x = self.g2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        x = self.drop(x)\n        return self.lin(x)\n\n\ncriterion = nn.CrossEntropyLoss()\n\n\n# ---------------------------------------------------------------------\ndef evaluate(model, loader):\n    model.eval()\n    preds, labels, seqs = [], [], []\n    total_loss = 0.0\n    with torch.no_grad():\n        for b in loader:\n            b = b.to(device)\n            out = model(b.x, b.edge_index, b.batch)\n            loss = criterion(out, b.y.view(-1))\n            total_loss += loss.item() * b.num_graphs\n            preds.extend(out.argmax(-1).cpu().tolist())\n            labels.extend(b.y.view(-1).cpu().tolist())\n            seqs.extend(b.seq)\n    cwa = color_weighted_accuracy(seqs, labels, preds)\n    swa = shape_weighted_accuracy(seqs, labels, preds)\n    bwa = (cwa + swa) / 2\n    return total_loss / len(loader.dataset), bwa, cwa, swa, preds, labels\n\n\n# ---------------------------------------------------------------------\nexperiment_data = {\"batch_size\": {\"SPR_BENCH\": {}}}\nbatch_sizes = [16, 32, 64, 128]\nnum_epochs = 5\n\nfor bs in batch_sizes:\n    print(f\"\\n=== Training with batch_size={bs} ===\")\n    # loaders\n    train_loader = DataLoader(train_graphs, batch_size=bs, shuffle=True)\n    dev_loader = DataLoader(dev_graphs, batch_size=bs)\n    test_loader = DataLoader(test_graphs, batch_size=bs)\n    # model/optim\n    model = SPR_GCN(len(token2idx), 32, len(label2idx)).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    run_data = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        epoch_loss = 0.0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = criterion(out, batch.y.view(-1))\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item() * batch.num_graphs\n        train_loss = epoch_loss / len(train_loader.dataset)\n\n        val_loss, val_bwa, val_cwa, val_swa, _, _ = evaluate(model, dev_loader)\n        _, train_bwa, *_ = evaluate(model, train_loader)\n\n        run_data[\"losses\"][\"train\"].append(train_loss)\n        run_data[\"losses\"][\"val\"].append(val_loss)\n        run_data[\"metrics\"][\"train\"].append(train_bwa)\n        run_data[\"metrics\"][\"val\"].append(val_bwa)\n        run_data[\"timestamps\"].append(time.time())\n\n        print(\n            f\"Epoch {epoch}/{num_epochs}  \"\n            f\"train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"BWA={val_bwa:.4f} (CWA={val_cwa:.4f}, SWA={val_swa:.4f})\"\n        )\n\n    # final test\n    test_loss, test_bwa, test_cwa, test_swa, test_preds, test_labels = evaluate(\n        model, test_loader\n    )\n    print(\n        f\"Test -> loss={test_loss:.4f} BWA={test_bwa:.4f} \"\n        f\"CWA={test_cwa:.4f} SWA={test_swa:.4f}\"\n    )\n\n    run_data[\"predictions\"] = test_preds\n    run_data[\"ground_truth\"] = test_labels\n\n    # store run data\n    experiment_data[\"batch_size\"][\"SPR_BENCH\"][str(bs)] = run_data\n\n    # plot\n    epochs = np.arange(1, num_epochs + 1)\n    plt.figure()\n    plt.plot(epochs, run_data[\"metrics\"][\"train\"], label=\"Train BWA\")\n    plt.plot(epochs, run_data[\"metrics\"][\"val\"], label=\"Dev BWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"BWA\")\n    plt.title(f\"BWA over epochs (bs={bs})\")\n    plt.legend()\n    plt.tight_layout()\n    p = os.path.join(working_dir, f\"bwa_curve_bs_{bs}.png\")\n    plt.savefig(p)\n    plt.close()\n    print(f\"Curve saved to {p}\")\n\n# ---------------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All experiment data saved.\")\n", "import os, pathlib, time, numpy as np, torch, torch.nn as nn, matplotlib.pyplot as plt\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom typing import List\nfrom datasets import DatasetDict, load_dataset\n\n# ---------------------------------------------------------------------\n# mandatory working dir\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# mandatory device handling\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# ---------- Helper to locate the dataset -----------------------------\ndef locate_spr_bench() -> pathlib.Path:\n    candidates = [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"../SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n        pathlib.Path(os.getenv(\"SPR_DATA_PATH\", \"\")),\n    ]\n    for p in candidates:\n        if p and (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p.resolve()}\")\n            return p.resolve()\n    raise FileNotFoundError(\n        \"SPR_BENCH dataset not found. Place the folder in the current or parent \"\n        \"directory or set the environment variable SPR_DATA_PATH to its location.\"\n    )\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(t[1] for t in sequence.strip().split() if len(t) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(t[0] for t in sequence.strip().split() if t))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / (sum(w) if sum(w) > 0 else 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if yt == yp else 0 for wt, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / (sum(w) if sum(w) > 0 else 1)\n\n\n# ---------------------------------------------------------------------\n# ---------- Load dataset ---------------------------------------------\nDATA_PATH = locate_spr_bench()\nspr = load_spr_bench(DATA_PATH)\n\n\n# ---------------------------------------------------------------------\n# ---------- Build vocabularies ---------------------------------------\ndef extract_tokens(seq: str) -> List[str]:\n    return seq.strip().split()\n\n\ntoken_set, label_set = set(), set()\nfor ex in spr[\"train\"]:\n    token_set.update(extract_tokens(ex[\"sequence\"]))\n    label_set.add(ex[\"label\"])\n\ntoken2idx = {tok: i + 1 for i, tok in enumerate(sorted(token_set))}\nlabel2idx = {lab: i for i, lab in enumerate(sorted(label_set))}\nidx2label = {i: lab for lab, i in label2idx.items()}\n\n\n# ---------------------------------------------------------------------\n# ---------- Graph construction ---------------------------------------\ndef seq_to_data(example):\n    seq = example[\"sequence\"]\n    tokens = extract_tokens(seq)\n    node_indices = [token2idx.get(tok, 0) for tok in tokens]\n    x = torch.tensor(node_indices, dtype=torch.long).unsqueeze(-1)\n\n    if len(tokens) > 1:\n        src = torch.arange(0, len(tokens) - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n\n    y = torch.tensor([label2idx[example[\"label\"]]], dtype=torch.long)\n    data = Data(x=x, edge_index=edge_index, y=y)\n    data.seq = seq\n    return data\n\n\ntrain_graphs = [seq_to_data(ex) for ex in spr[\"train\"]]\ndev_graphs = [seq_to_data(ex) for ex in spr[\"dev\"]]\ntest_graphs = [seq_to_data(ex) for ex in spr[\"test\"]]\n\nbatch_size = 64\ntrain_loader_full = DataLoader(train_graphs, batch_size=batch_size, shuffle=False)\ndev_loader = DataLoader(dev_graphs, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n\n\n# ---------------------------------------------------------------------\n# ---------- Model -----------------------------------------------------\nclass SPR_GCN(nn.Module):\n    def __init__(\n        self, vocab_size: int, embed_dim: int, num_classes: int, dropout_rate: float\n    ):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size + 1, embed_dim, padding_idx=0)\n        self.gcn1 = GCNConv(embed_dim, 64)\n        self.gcn2 = GCNConv(64, 64)\n        self.lin = nn.Linear(64, num_classes)\n        self.dropout = nn.Dropout(dropout_rate)\n\n    def forward(self, x, edge_index, batch):\n        x = self.embed(x.squeeze(-1))\n        x = self.gcn1(x, edge_index).relu()\n        x = self.gcn2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        x = self.dropout(x)\n        return self.lin(x)\n\n\n# ---------------------------------------------------------------------\n# ---------- Evaluation function --------------------------------------\ndef evaluate(model, loader, criterion):\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    total_loss = 0.0\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = criterion(out, batch.y.view(-1))\n            total_loss += loss.item() * batch.num_graphs\n            preds = out.argmax(dim=-1).cpu().tolist()\n            labels = batch.y.view(-1).cpu().tolist()\n            seqs = batch.seq\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n            all_seqs.extend(seqs)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    bwa = (cwa + swa) / 2.0\n    avg_loss = total_loss / len(loader.dataset)\n    return avg_loss, bwa, cwa, swa, all_preds, all_labels\n\n\n# ---------------------------------------------------------------------\n# ---------- Hyperparameter tuning over dropout -----------------------\nexperiment_data = {\"dropout_rate\": {\"SPR_BENCH\": {}}}\ndropout_grid = [0.0, 0.1, 0.2, 0.3, 0.4]\nnum_epochs = 5\nbest_dev_bwa, best_rate, best_state = -1.0, None, None\n\nfor dr in dropout_grid:\n    print(f\"\\n=== Training with dropout={dr:.2f} ===\")\n    model = SPR_GCN(len(token2idx), 32, len(label2idx), dropout_rate=dr).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n\n    rate_dict = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        epoch_loss = 0.0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = criterion(out, batch.y.view(-1))\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item() * batch.num_graphs\n        train_loss = epoch_loss / len(train_loader.dataset)\n\n        val_loss, val_bwa, val_cwa, val_swa, _, _ = evaluate(\n            model, dev_loader, criterion\n        )\n        _, train_bwa, _, _, _, _ = evaluate(model, train_loader_full, criterion)\n\n        rate_dict[\"losses\"][\"train\"].append(train_loss)\n        rate_dict[\"losses\"][\"val\"].append(val_loss)\n        rate_dict[\"metrics\"][\"train\"].append(train_bwa)\n        rate_dict[\"metrics\"][\"val\"].append(val_bwa)\n        rate_dict[\"timestamps\"].append(time.time())\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n            f\"BWA={val_bwa:.4f} (CWA={val_cwa:.4f}, SWA={val_swa:.4f})\"\n        )\n\n    # keep best model w.r.t dev BWA\n    if val_bwa > best_dev_bwa:\n        best_dev_bwa = val_bwa\n        best_rate = dr\n        best_state = model.state_dict()\n\n    experiment_data[\"dropout_rate\"][\"SPR_BENCH\"][f\"dr_{dr:.2f}\"] = rate_dict\n    # free cuda mem before next run\n    del model\n    torch.cuda.empty_cache()\n\nprint(f\"\\nBest dev BWA {best_dev_bwa:.4f} achieved with dropout={best_rate:.2f}\")\n\n# ---------------------------------------------------------------------\n# ---------- Final test evaluation with best model --------------------\nbest_model = SPR_GCN(len(token2idx), 32, len(label2idx), dropout_rate=best_rate).to(\n    device\n)\nbest_model.load_state_dict(best_state)\ncriterion = nn.CrossEntropyLoss()\ntest_loss, test_bwa, test_cwa, test_swa, test_preds, test_labels = evaluate(\n    best_model, test_loader, criterion\n)\nprint(\n    f\"Test -> loss: {test_loss:.4f}  BWA: {test_bwa:.4f}  CWA: {test_cwa:.4f}  SWA: {test_swa:.4f}\"\n)\n\n# store final test results\nexperiment_data[\"dropout_rate\"][\"SPR_BENCH\"][\"best_rate\"] = best_rate\nexperiment_data[\"dropout_rate\"][\"SPR_BENCH\"][\"test\"] = {\n    \"loss\": test_loss,\n    \"BWA\": test_bwa,\n    \"CWA\": test_cwa,\n    \"SWA\": test_swa,\n    \"predictions\": test_preds,\n    \"ground_truth\": test_labels,\n}\n\n# ---------------------------------------------------------------------\n# ---------- Plotting best run ----------------------------------------\nepochs = np.arange(1, num_epochs + 1)\nbest_dict = experiment_data[\"dropout_rate\"][\"SPR_BENCH\"][f\"dr_{best_rate:.2f}\"]\nplt.figure()\nplt.plot(epochs, best_dict[\"metrics\"][\"train\"], label=\"Train BWA\")\nplt.plot(epochs, best_dict[\"metrics\"][\"val\"], label=\"Dev BWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"BWA\")\nplt.title(f\"BWA over epochs (dropout={best_rate:.2f})\")\nplt.legend()\nplt.tight_layout()\nplot_path = os.path.join(working_dir, f\"bwa_curve_spr_dropout_{best_rate:.2f}.png\")\nplt.savefig(plot_path)\nprint(f\"Curve saved to {plot_path}\")\n\n# ---------------------------------------------------------------------\n# ---------- Save metrics ---------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n"], "term_out": ["['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 529216.33\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 688674.64\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 814997.67\nexamples/s]', '\\n', 'Epoch 1: train_loss=0.5353  val_loss=0.4737  BWA=0.7952\n(CWA=0.7930, SWA=0.7973)', '\\n', 'Epoch 2: train_loss=0.4391  val_loss=0.4123\nBWA=0.8247 (CWA=0.8248, SWA=0.8246)', '\\n', 'Epoch 3: train_loss=0.3927\nval_loss=0.3755  BWA=0.8545 (CWA=0.8541, SWA=0.8548)', '\\n', 'Epoch 4:\ntrain_loss=0.3677  val_loss=0.3569  BWA=0.8686 (CWA=0.8688, SWA=0.8684)', '\\n',\n'Epoch 5: train_loss=0.3501  val_loss=0.3512  BWA=0.8601 (CWA=0.8611,\nSWA=0.8590)', '\\n', 'Curve saved to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-3/working/bwa_curve_spr.png', '\\n', 'Final Test -> loss:\n0.8514  BWA: 0.6389  CWA: 0.6577  SWA: 0.6201', '\\n', 'Execution time: 21\nseconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 553466.04\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 637529.11\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 719978.03\nexamples/s]', '\\n', 'Epoch 01: train_loss=0.5352  val_loss=0.4733  BWA=0.7975\n(CWA=0.7951, SWA=0.7998)', '\\n', 'Epoch 02: train_loss=0.4386  val_loss=0.4091\nBWA=0.8238 (CWA=0.8243, SWA=0.8232)', '\\n', 'Epoch 03: train_loss=0.3907\nval_loss=0.3726  BWA=0.8501 (CWA=0.8503, SWA=0.8498)', '\\n', 'Epoch 04:\ntrain_loss=0.3660  val_loss=0.3543  BWA=0.8678 (CWA=0.8676, SWA=0.8680)', '\\n',\n'Epoch 05: train_loss=0.3502  val_loss=0.3504  BWA=0.8577 (CWA=0.8589,\nSWA=0.8564)', '\\n', 'Epoch 06: train_loss=0.3337  val_loss=0.3251  BWA=0.8852\n(CWA=0.8851, SWA=0.8853)', '\\n', 'Epoch 07: train_loss=0.3216  val_loss=0.3089\nBWA=0.8933 (CWA=0.8931, SWA=0.8936)', '\\n', 'Epoch 08: train_loss=0.3111\nval_loss=0.3020  BWA=0.8994 (CWA=0.8998, SWA=0.8990)', '\\n', 'Epoch 09:\ntrain_loss=0.3018  val_loss=0.2956  BWA=0.9072 (CWA=0.9065, SWA=0.9078)', '\\n',\n'Epoch 10: train_loss=0.2929  val_loss=0.2832  BWA=0.9017 (CWA=0.9018,\nSWA=0.9016)', '\\n', 'Epoch 11: train_loss=0.2849  val_loss=0.2803  BWA=0.9128\n(CWA=0.9125, SWA=0.9131)', '\\n', 'Epoch 12: train_loss=0.2774  val_loss=0.2690\nBWA=0.9201 (CWA=0.9198, SWA=0.9205)', '\\n', 'Epoch 13: train_loss=0.2748\nval_loss=0.2599  BWA=0.9239 (CWA=0.9233, SWA=0.9245)', '\\n', 'Epoch 14:\ntrain_loss=0.2637  val_loss=0.2594  BWA=0.9138 (CWA=0.9139, SWA=0.9136)', '\\n',\n'Epoch 15: train_loss=0.2601  val_loss=0.2519  BWA=0.9225 (CWA=0.9224,\nSWA=0.9226)', '\\n', 'Epoch 16: train_loss=0.2522  val_loss=0.2455  BWA=0.9274\n(CWA=0.9273, SWA=0.9275)', '\\n', 'Epoch 17: train_loss=0.2523  val_loss=0.2499\nBWA=0.9241 (CWA=0.9234, SWA=0.9248)', '\\n', 'Epoch 18: train_loss=0.2471\nval_loss=0.2376  BWA=0.9316 (CWA=0.9310, SWA=0.9323)', '\\n', 'Epoch 19:\ntrain_loss=0.2402  val_loss=0.2409  BWA=0.9265 (CWA=0.9273, SWA=0.9256)', '\\n',\n'Epoch 20: train_loss=0.2372  val_loss=0.2257  BWA=0.9347 (CWA=0.9342,\nSWA=0.9352)', '\\n', 'Epoch 21: train_loss=0.2302  val_loss=0.2277  BWA=0.9294\n(CWA=0.9295, SWA=0.9293)', '\\n', 'Epoch 22: train_loss=0.2298  val_loss=0.2203\nBWA=0.9327 (CWA=0.9328, SWA=0.9326)', '\\n', 'Epoch 23: train_loss=0.2253\nval_loss=0.2165  BWA=0.9382 (CWA=0.9376, SWA=0.9388)', '\\n', 'Epoch 24:\ntrain_loss=0.2231  val_loss=0.2139  BWA=0.9343 (CWA=0.9350, SWA=0.9335)', '\\n',\n'Epoch 25: train_loss=0.2205  val_loss=0.2185  BWA=0.9392 (CWA=0.9389,\nSWA=0.9396)', '\\n', 'Epoch 26: train_loss=0.2179  val_loss=0.2072  BWA=0.9430\n(CWA=0.9429, SWA=0.9431)', '\\n', 'Epoch 27: train_loss=0.2193  val_loss=0.2024\nBWA=0.9453 (CWA=0.9452, SWA=0.9455)', '\\n', 'Epoch 28: train_loss=0.2153\nval_loss=0.2090  BWA=0.9415 (CWA=0.9411, SWA=0.9419)', '\\n', 'Epoch 29:\ntrain_loss=0.2097  val_loss=0.2086  BWA=0.9381 (CWA=0.9391, SWA=0.9371)', '\\n',\n'Epoch 30: train_loss=0.2114  val_loss=0.2026  BWA=0.9439 (CWA=0.9441,\nSWA=0.9438)', '\\n', 'Training finished after 30 epochs; best dev BWA = 0.9453',\n'\\n', 'Curve saved to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_17-\n49-45_gnn_for_spr_attempt_0/0-run/process_ForkProcess-\n6/working/bwa_curve_spr.png', '\\n', 'Final Test -> loss: 1.2339  BWA: 0.6528\nCWA: 0.6746  SWA: 0.6310', '\\n', 'Execution time: 3 minutes seconds (time limit\nis 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 553188.65\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 609725.83\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 853211.82\nexamples/s]', '\\n', '\\n=== Training with learning_rate = 0.0003 ===', '\\n',\n'Epoch 1 | train_loss=0.5949 val_loss=0.5150 BWA=0.7547 (CWA=0.7536,\nSWA=0.7558)', '\\n', 'Epoch 2 | train_loss=0.4965 val_loss=0.4764 BWA=0.7936\n(CWA=0.7912, SWA=0.7961)', '\\n', 'Epoch 3 | train_loss=0.4620 val_loss=0.4432\nBWA=0.7946 (CWA=0.7942, SWA=0.7951)', '\\n', 'Epoch 4 | train_loss=0.4399\nval_loss=0.4229 BWA=0.8120 (CWA=0.8119, SWA=0.8122)', '\\n', 'Epoch 5 |\ntrain_loss=0.4245 val_loss=0.4118 BWA=0.8212 (CWA=0.8215, SWA=0.8209)', '\\n',\n'Test -> loss: 0.7307  BWA: 0.6259 CWA: 0.6430 SWA: 0.6089', '\\n', '\\n===\nTraining with learning_rate = 0.0005 ===', '\\n', 'Epoch 1 | train_loss=0.5610\nval_loss=0.4855 BWA=0.7759 (CWA=0.7748, SWA=0.7771)', '\\n', 'Epoch 2 |\ntrain_loss=0.4659 val_loss=0.4478 BWA=0.8099 (CWA=0.8080, SWA=0.8117)', '\\n',\n'Epoch 3 | train_loss=0.4328 val_loss=0.4134 BWA=0.8217 (CWA=0.8217,\nSWA=0.8217)', '\\n', 'Epoch 4 | train_loss=0.4147 val_loss=0.3998 BWA=0.8335\n(CWA=0.8342, SWA=0.8328)', '\\n', 'Epoch 5 | train_loss=0.4023 val_loss=0.3907\nBWA=0.8420 (CWA=0.8423, SWA=0.8416)', '\\n', 'Test -> loss: 0.7515  BWA: 0.6287\nCWA: 0.6465 SWA: 0.6108', '\\n', '\\n=== Training with learning_rate = 0.001 ===',\n'\\n', 'Epoch 1 | train_loss=0.5210 val_loss=0.4412 BWA=0.8009 (CWA=0.8002,\nSWA=0.8017)', '\\n', 'Epoch 2 | train_loss=0.4284 val_loss=0.4162 BWA=0.8344\n(CWA=0.8333, SWA=0.8355)', '\\n', 'Epoch 3 | train_loss=0.4003 val_loss=0.3813\nBWA=0.8534 (CWA=0.8533, SWA=0.8534)', '\\n', 'Epoch 4 | train_loss=0.3794\nval_loss=0.3643 BWA=0.8681 (CWA=0.8677, SWA=0.8685)', '\\n', 'Epoch 5 |\ntrain_loss=0.3615 val_loss=0.3481 BWA=0.8741 (CWA=0.8742, SWA=0.8741)', '\\n',\n'Test -> loss: 0.7967  BWA: 0.6347 CWA: 0.6536 SWA: 0.6159', '\\n', '\\n===\nTraining with learning_rate = 0.002 ===', '\\n', 'Epoch 1 | train_loss=0.4857\nval_loss=0.4079 BWA=0.8316 (CWA=0.8316, SWA=0.8316)', '\\n', 'Epoch 2 |\ntrain_loss=0.4018 val_loss=0.3875 BWA=0.8558 (CWA=0.8550, SWA=0.8566)', '\\n',\n'Epoch 3 | train_loss=0.3659 val_loss=0.3477 BWA=0.8751 (CWA=0.8741,\nSWA=0.8760)', '\\n', 'Epoch 4 | train_loss=0.3353 val_loss=0.3390 BWA=0.8836\n(CWA=0.8830, SWA=0.8842)', '\\n', 'Epoch 5 | train_loss=0.3148 val_loss=0.2986\nBWA=0.9008 (CWA=0.9009, SWA=0.9007)', '\\n', 'Test -> loss: 0.8965  BWA: 0.6459\nCWA: 0.6661 SWA: 0.6257', '\\n', '\\nBest learning_rate based on dev BWA: 0.002\n(BWA=0.9008)', '\\n', 'Curve saved to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-7/working/lr_tuning_bwa_curve.png', '\\n', 'All\nexperiment data saved.', '\\n', 'Execution time: a minute seconds (time limit is\n30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 520595.03\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 407166.54\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 696230.93\nexamples/s]', '\\n', '\\n=== Training with batch_size=16 ===', '\\n', 'Epoch 1/5\ntrain_loss=0.4881 val_loss=0.4132 BWA=0.8184 (CWA=0.8183, SWA=0.8186)', '\\n',\n'Epoch 2/5  train_loss=0.3861 val_loss=0.3580 BWA=0.8686 (CWA=0.8687,\nSWA=0.8685)', '\\n', 'Epoch 3/5  train_loss=0.3503 val_loss=0.3335 BWA=0.8812\n(CWA=0.8810, SWA=0.8815)', '\\n', 'Epoch 4/5  train_loss=0.3260 val_loss=0.3110\nBWA=0.8951 (CWA=0.8959, SWA=0.8944)', '\\n', 'Epoch 5/5  train_loss=0.3050\nval_loss=0.2941 BWA=0.8972 (CWA=0.8976, SWA=0.8968)', '\\n', 'Test -> loss=0.9278\nBWA=0.6456 CWA=0.6657 SWA=0.6254', '\\n', 'Curve saved to /home/zxl240011/AI-Scie\nntist-v2/experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-8/working/bwa_curve_bs_16.png', '\\n', '\\n=== Training\nwith batch_size=32 ===', '\\n', 'Epoch 1/5  train_loss=0.5121 val_loss=0.4464\nBWA=0.7987 (CWA=0.7978, SWA=0.7996)', '\\n', 'Epoch 2/5  train_loss=0.4218\nval_loss=0.3963 BWA=0.8301 (CWA=0.8312, SWA=0.8291)', '\\n', 'Epoch 3/5\ntrain_loss=0.3869 val_loss=0.3803 BWA=0.8420 (CWA=0.8424, SWA=0.8416)', '\\n',\n'Epoch 4/5  train_loss=0.3631 val_loss=0.3494 BWA=0.8733 (CWA=0.8734,\nSWA=0.8731)', '\\n', 'Epoch 5/5  train_loss=0.3457 val_loss=0.3344 BWA=0.8777\n(CWA=0.8778, SWA=0.8776)', '\\n', 'Test -> loss=0.8647 BWA=0.6348 CWA=0.6540\nSWA=0.6156', '\\n', 'Curve saved to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-8/working/bwa_curve_bs_32.png', '\\n', '\\n=== Training\nwith batch_size=64 ===', '\\n', 'Epoch 1/5  train_loss=0.5362 val_loss=0.4466\nBWA=0.8006 (CWA=0.8001, SWA=0.8012)', '\\n', 'Epoch 2/5  train_loss=0.4251\nval_loss=0.4059 BWA=0.8235 (CWA=0.8243, SWA=0.8227)', '\\n', 'Epoch 3/5\ntrain_loss=0.3901 val_loss=0.3780 BWA=0.8520 (CWA=0.8518, SWA=0.8523)', '\\n',\n'Epoch 4/5  train_loss=0.3683 val_loss=0.3586 BWA=0.8536 (CWA=0.8544,\nSWA=0.8528)', '\\n', 'Epoch 5/5  train_loss=0.3489 val_loss=0.3351 BWA=0.8819\n(CWA=0.8819, SWA=0.8818)', '\\n', 'Test -> loss=0.8472 BWA=0.6353 CWA=0.6546\nSWA=0.6161', '\\n', 'Curve saved to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-8/working/bwa_curve_bs_64.png', '\\n', '\\n=== Training\nwith batch_size=128 ===', '\\n', 'Epoch 1/5  train_loss=0.5555 val_loss=0.4765\nBWA=0.7933 (CWA=0.7915, SWA=0.7951)', '\\n', 'Epoch 2/5  train_loss=0.4468\nval_loss=0.4152 BWA=0.8219 (CWA=0.8211, SWA=0.8228)', '\\n', 'Epoch 3/5\ntrain_loss=0.4108 val_loss=0.3943 BWA=0.8316 (CWA=0.8321, SWA=0.8311)', '\\n',\n'Epoch 4/5  train_loss=0.3927 val_loss=0.3811 BWA=0.8508 (CWA=0.8502,\nSWA=0.8514)', '\\n', 'Epoch 5/5  train_loss=0.3797 val_loss=0.3803 BWA=0.8356\n(CWA=0.8372, SWA=0.8341)', '\\n', 'Test -> loss=0.7552 BWA=0.6407 CWA=0.6586\nSWA=0.6228', '\\n', 'Curve saved to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-8/working/bwa_curve_bs_128.png', '\\n', 'All experiment\ndata saved.', '\\n', 'Execution time: a minute seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 527801.18\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 569955.70\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 716534.10\nexamples/s]', '\\n', '\\n=== Training with dropout=0.00 ===', '\\n', 'Epoch 1:\ntrain_loss=0.5266  val_loss=0.4661  BWA=0.8011 (CWA=0.7986, SWA=0.8035)', '\\n',\n'Epoch 2: train_loss=0.4217  val_loss=0.3939  BWA=0.8447 (CWA=0.8446,\nSWA=0.8448)', '\\n', 'Epoch 3: train_loss=0.3742  val_loss=0.3636  BWA=0.8573\n(CWA=0.8572, SWA=0.8573)', '\\n', 'Epoch 4: train_loss=0.3450  val_loss=0.3342\nBWA=0.8768 (CWA=0.8769, SWA=0.8768)', '\\n', 'Epoch 5: train_loss=0.3226\nval_loss=0.3162  BWA=0.8835 (CWA=0.8837, SWA=0.8832)', '\\n', '\\n=== Training\nwith dropout=0.10 ===', '\\n', 'Epoch 1: train_loss=0.5269  val_loss=0.4563\nBWA=0.7961 (CWA=0.7937, SWA=0.7985)', '\\n', 'Epoch 2: train_loss=0.4322\nval_loss=0.4061  BWA=0.8303 (CWA=0.8302, SWA=0.8304)', '\\n', 'Epoch 3:\ntrain_loss=0.3921  val_loss=0.3781  BWA=0.8463 (CWA=0.8463, SWA=0.8462)', '\\n',\n'Epoch 4: train_loss=0.3685  val_loss=0.3534  BWA=0.8636 (CWA=0.8641,\nSWA=0.8631)', '\\n', 'Epoch 5: train_loss=0.3460  val_loss=0.3372  BWA=0.8745\n(CWA=0.8751, SWA=0.8740)', '\\n', '\\n=== Training with dropout=0.20 ===', '\\n',\n'Epoch 1: train_loss=0.5152  val_loss=0.4453  BWA=0.8071 (CWA=0.8058,\nSWA=0.8083)', '\\n', 'Epoch 2: train_loss=0.4264  val_loss=0.4124  BWA=0.8298\n(CWA=0.8291, SWA=0.8304)', '\\n', 'Epoch 3: train_loss=0.3971  val_loss=0.3836\nBWA=0.8490 (CWA=0.8490, SWA=0.8489)', '\\n', 'Epoch 4: train_loss=0.3741\nval_loss=0.3645  BWA=0.8601 (CWA=0.8605, SWA=0.8597)', '\\n', 'Epoch 5:\ntrain_loss=0.3584  val_loss=0.3557  BWA=0.8597 (CWA=0.8602, SWA=0.8592)', '\\n',\n'\\n=== Training with dropout=0.30 ===', '\\n', 'Epoch 1: train_loss=0.5187\nval_loss=0.4352  BWA=0.8059 (CWA=0.8053, SWA=0.8065)', '\\n', 'Epoch 2:\ntrain_loss=0.4244  val_loss=0.4018  BWA=0.8347 (CWA=0.8344, SWA=0.8350)', '\\n',\n'Epoch 3: train_loss=0.3956  val_loss=0.3812  BWA=0.8476 (CWA=0.8477,\nSWA=0.8475)', '\\n', 'Epoch 4: train_loss=0.3780  val_loss=0.3759  BWA=0.8509\n(CWA=0.8516, SWA=0.8502)', '\\n', 'Epoch 5: train_loss=0.3625  val_loss=0.3702\nBWA=0.8611 (CWA=0.8604, SWA=0.8618)', '\\n', '\\n=== Training with dropout=0.40\n===', '\\n', 'Epoch 1: train_loss=0.5358  val_loss=0.4549  BWA=0.7952\n(CWA=0.7947, SWA=0.7957)', '\\n', 'Epoch 2: train_loss=0.4424  val_loss=0.4086\nBWA=0.8288 (CWA=0.8285, SWA=0.8291)', '\\n', 'Epoch 3: train_loss=0.4042\nval_loss=0.3829  BWA=0.8477 (CWA=0.8475, SWA=0.8479)', '\\n', 'Epoch 4:\ntrain_loss=0.3879  val_loss=0.3710  BWA=0.8527 (CWA=0.8533, SWA=0.8521)', '\\n',\n'Epoch 5: train_loss=0.3700  val_loss=0.3551  BWA=0.8619 (CWA=0.8621,\nSWA=0.8618)', '\\n', '\\nBest dev BWA 0.8835 achieved with dropout=0.00', '\\n',\n'Test -> loss: 0.8647  BWA: 0.6394  CWA: 0.6586  SWA: 0.6201', '\\n', 'Curve\nsaved to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_17-49-\n45_gnn_for_spr_attempt_0/0-run/process_ForkProcess-\n9/working/bwa_curve_spr_dropout_0.00.png', '\\n', 'Execution time: 2 minutes\nseconds (time limit is 30 minutes).']"], "analysis": ["", "", "", "", ""], "exc_type": [null, null, null, null, null], "exc_info": [null, null, null, null, null], "exc_stack": [null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "balanced weighted accuracy", "lower_is_better": false, "description": "Measures the balanced weighted accuracy of the model.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.8595, "best_value": 0.8686}]}, {"metric_name": "cross-entropy loss", "lower_is_better": true, "description": "Measures the cross-entropy loss of the model.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.3501, "best_value": 0.3512}]}]}, {"metric_names": [{"metric_name": "BWA accuracy", "lower_is_better": false, "description": "Accuracy metric using the BWA method.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9495, "best_value": 0.9453}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss value indicating the error rate.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.2114, "best_value": 0.2024}]}, {"metric_name": "accuracy", "lower_is_better": false, "description": "Overall test accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6732, "best_value": 0.6732}]}]}, {"metric_names": [{"metric_name": "train BWA", "lower_is_better": false, "description": "Training Balanced Weighted Accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.8999, "best_value": 0.8999}]}, {"metric_name": "validation BWA", "lower_is_better": false, "description": "Validation Balanced Weighted Accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9008, "best_value": 0.9008}]}, {"metric_name": "test BWA", "lower_is_better": false, "description": "Testing Balanced Weighted Accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6459, "best_value": 0.6459}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "Training loss.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.3148, "best_value": 0.3148}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.2986, "best_value": 0.2986}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Testing loss.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.8965, "best_value": 0.8965}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.8371, "best_value": 0.9018}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.8356, "best_value": 0.8972}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.3797, "best_value": 0.305}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.3803, "best_value": 0.2941}]}]}, {"metric_names": [{"metric_name": "balanced weighted accuracy", "lower_is_better": false, "description": "Balanced weighted accuracy measures the model's performance in handling imbalanced datasets.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6394, "best_value": 0.6394}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "Weighted accuracy specifically for the color attribute.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6586, "best_value": 0.6586}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "Weighted accuracy specifically for the shape attribute.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6201, "best_value": 0.6201}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss measures the error or deviation in predictions compared to actual values.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.8647, "best_value": 0.8647}]}]}], "is_best_node": [true, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/bwa_curve_spr.png", "../../logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/SPR_BENCH_bwa_curve.png", "../../logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/bwa_curve_spr.png", "../../logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/SPR_BENCH_bwa_curve.png", "../../logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/lr_tuning_bwa_curve.png", "../../logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_bwa_curves.png", "../../logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_best_lr_bwa.png", "../../logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_test_bwa_bar.png", "../../logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_label_distribution.png"], ["../../logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_16.png", "../../logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_32.png", "../../logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_64.png", "../../logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_128.png", "../../logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs16_loss_bwa_curves.png", "../../logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs32_loss_bwa_curves.png", "../../logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs64_loss_bwa_curves.png", "../../logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs128_loss_bwa_curves.png", "../../logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_final_bwa_vs_batch_size.png"], ["../../logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/bwa_curve_spr_dropout_0.00.png", "../../logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_bwa_curve_best_dr_0.00.png", "../../logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_loss_curve_best_dr_0.00.png", "../../logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_dev_bwa_by_dropout.png", "../../logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_test_metrics_best_dropout.png"]], "plot_paths": [["experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/bwa_curve_spr.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/SPR_BENCH_loss_curve.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/SPR_BENCH_bwa_curve.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/bwa_curve_spr.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/SPR_BENCH_bwa_curve.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/SPR_BENCH_loss_curve.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/lr_tuning_bwa_curve.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_bwa_curves.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_loss_curves.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_best_lr_bwa.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_test_bwa_bar.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_label_distribution.png"], ["experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_16.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_32.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_64.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_128.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs16_loss_bwa_curves.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs32_loss_bwa_curves.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs64_loss_bwa_curves.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs128_loss_bwa_curves.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_final_bwa_vs_batch_size.png"], ["experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/bwa_curve_spr_dropout_0.00.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_bwa_curve_best_dr_0.00.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_loss_curve_best_dr_0.00.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_dev_bwa_by_dropout.png", "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_test_metrics_best_dropout.png"]], "plot_analyses": [[{"analysis": "The plot shows a consistent improvement in Balanced Weighted Accuracy (BWA) for both the training and development datasets over the epochs. This indicates that the model is learning effectively and generalizing well. The slight convergence and plateauing at the later epochs suggest that the model is approaching its optimal performance.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/bwa_curve_spr.png"}, {"analysis": "The loss curve demonstrates a steady decrease in both training and validation loss over the epochs. This indicates that the model is effectively minimizing the error during training and generalizing well to unseen data. The absence of divergence between the two curves suggests that overfitting has not occurred.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/SPR_BENCH_loss_curve.png"}, {"analysis": "This plot is similar to the first one and confirms the trend of increasing BWA over epochs for both training and validation data. The close alignment between the two curves further supports the observation that the model is generalizing well and learning effectively.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/SPR_BENCH_bwa_curve.png"}, {"analysis": "The confusion matrix indicates the number of correct and incorrect predictions made by the model. The darker diagonal elements suggest that the model has achieved good classification accuracy, while the lighter off-diagonal elements indicate relatively fewer misclassifications. The balance between the true positive and true negative rates appears reasonable.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0892781bfb4b47e493387b157c561d3a_proc_1437200/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The plot shows the Balanced Weighted Accuracy (BWA) over epochs for both the training and development datasets. Both curves exhibit a steady improvement in accuracy as the number of epochs increases, indicating successful learning. The training and development curves are closely aligned, suggesting that the model generalizes well without significant overfitting. The slight upward trend at the end suggests that further training may yield marginal improvements, but the model seems to be nearing convergence.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/bwa_curve_spr.png"}, {"analysis": "This plot again depicts the Balanced Weighted Accuracy (BWA) over epochs, but with a slightly different presentation. The trends for both training and validation datasets are consistent with the previous plot, showing steady improvement and close alignment. This reinforces the conclusion that the model is learning effectively and generalizing well. The stability of the curves toward the later epochs suggests that the selected hyperparameters are appropriate for this stage of training.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/SPR_BENCH_bwa_curve.png"}, {"analysis": "The plot shows the cross-entropy loss over epochs for both training and validation datasets. Both curves exhibit a consistent downward trend, with the training loss slightly lower than the validation loss throughout. This indicates that the model is learning effectively while maintaining generalization. The convergence of the two curves toward the later epochs suggests a well-optimized model with no significant overfitting or underfitting. The decrease in loss aligns with the improvement in accuracy observed in the other plots.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/SPR_BENCH_loss_curve.png"}, {"analysis": "The confusion matrix for the test set provides insights into the model's performance in terms of true and predicted labels. The high values along the diagonal indicate a strong ability to correctly classify instances. The relatively low off-diagonal values suggest that misclassifications are minimal. This confirms the model's effectiveness in capturing the underlying patterns of the data, as reflected in the high accuracy metrics observed in the previous plots.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f5662eb74b4a44749b67414c5878833c_proc_1442552/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The graph demonstrates that increasing the learning rate generally improves the performance on the Dev BWA metric. The learning rate of 0.002 achieves the highest performance, with a steady increase across epochs. Lower learning rates (e.g., 0.0003) show slower improvement, indicating suboptimal training dynamics at lower learning rates.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/lr_tuning_bwa_curve.png"}, {"analysis": "This plot compares the learning rate impact on Dev BWA performance. It confirms that the learning rate of 0.002 consistently outperforms others across all epochs. The trend shows that higher learning rates lead to faster and better convergence, emphasizing the importance of tuning this hyperparameter.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_bwa_curves.png"}, {"analysis": "The plot shows the Cross-Entropy Loss for both training and validation sets across different learning rates. The learning rate of 0.002 achieves the lowest loss on both sets, indicating effective learning and minimal overfitting. The loss curves for lower learning rates (e.g., 0.0003) converge more slowly, reflecting their inefficiency in capturing the data patterns effectively.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_loss_curves.png"}, {"analysis": "This plot compares the Train and Dev BWA for the best learning rate (0.002). The curves are closely aligned, showcasing minimal overfitting and consistent learning behavior. The steady improvement across epochs highlights the effectiveness of the chosen learning rate in optimizing the model.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_best_lr_bwa.png"}, {"analysis": "The bar chart shows the final Test BWA for different learning rates. While all learning rates achieve similar performance, the learning rate of 0.002 slightly outperforms others. This indicates that higher learning rates are beneficial for this task without causing significant degradation in generalization.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_test_bwa_bar.png"}, {"analysis": "This plot compares the label distribution of the ground truth and predictions for the best learning rate (0.002). The predictions closely match the ground truth distribution, demonstrating that the model successfully learns and generalizes the label patterns. However, slight discrepancies suggest room for further refinement.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6ed1f047037e4427a578ce96de0537dc_proc_1442553/spr_bench_label_distribution.png"}], [{"analysis": "This plot shows the Balanced Weighted Accuracy (BWA) for the training and development datasets over epochs with a batch size of 16. The BWA steadily increases for both datasets, indicating consistent learning. The gap between training and development BWA is minimal, suggesting that the model is not overfitting. The BWA plateaus slightly after epoch 4, hinting at a potential convergence.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_16.png"}, {"analysis": "This plot depicts the BWA for training and development datasets with a batch size of 32. Similar to the previous plot, BWA increases steadily and shows convergence after epoch 4. The training and development curves are closely aligned, reflecting good generalization and minimal overfitting.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_32.png"}, {"analysis": "This plot illustrates the BWA for training and development datasets with a batch size of 64. The BWA increases consistently for both datasets and converges after epoch 4. The alignment of the training and development curves indicates that the model generalizes well without significant overfitting.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_64.png"}, {"analysis": "This plot shows the BWA for training and development datasets with a batch size of 128. While the BWA increases initially, it starts to decline slightly for the development dataset after epoch 4. This suggests potential overfitting or instability at larger batch sizes.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/bwa_curve_bs_128.png"}, {"analysis": "This plot combines the loss (left axis) and BWA (right axis) for the training and development datasets with a batch size of 16. As the loss decreases steadily, the BWA increases, demonstrating effective learning. The alignment of the training and development curves for both metrics indicates good generalization.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs16_loss_bwa_curves.png"}, {"analysis": "This plot presents the loss and BWA for a batch size of 32. The loss decreases steadily while the BWA increases, reflecting effective learning. The training and development curves are closely aligned, indicating minimal overfitting and good generalization.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs32_loss_bwa_curves.png"}, {"analysis": "This plot shows the loss and BWA for a batch size of 64. The loss decreases consistently, and the BWA increases, showing effective learning. The alignment of the curves suggests good generalization, although the batch size may be nearing the optimal limit for stability.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs64_loss_bwa_curves.png"}, {"analysis": "This plot displays the loss and BWA for a batch size of 128. While the loss decreases, the BWA shows a decline after epoch 4, particularly for the development dataset. This suggests that the larger batch size may lead to overfitting or instability.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_bs128_loss_bwa_curves.png"}, {"analysis": "This bar chart summarizes the final development BWA for different batch sizes. Batch sizes of 16, 32, and 64 achieve similar final BWA, while a batch size of 128 shows a slight decline. This indicates that smaller batch sizes may provide better generalization and stability.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9e786e2c86974615bc13351761c5a082_proc_1442554/SPR_BENCH_final_bwa_vs_batch_size.png"}], [{"analysis": "The plot demonstrates the Balanced Weighted Accuracy (BWA) across epochs for both the training and development datasets with a dropout rate of 0.00. Both curves exhibit consistent improvement over epochs, converging near the same value of ~0.88 at epoch 5. This indicates effective model training without significant overfitting or underfitting, as the training and development accuracies are closely aligned.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/bwa_curve_spr_dropout_0.00.png"}, {"analysis": "This plot also shows Balanced Weighted Accuracy (BWA) for training and development datasets over epochs at the best dropout rate of 0.00. The results are consistent with the previous plot, confirming that the model is learning effectively and maintaining a balance between training and development performance. The close alignment of the curves further supports the absence of overfitting.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_bwa_curve_best_dr_0.00.png"}, {"analysis": "This plot depicts the cross-entropy loss for training and development datasets over epochs with the best dropout rate of 0.00. The steady decrease in both training and development loss suggests that the model is learning effectively. The slightly lower development loss compared to training loss indicates a robust generalization capability of the model.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_loss_curve_best_dr_0.00.png"}, {"analysis": "This plot illustrates the effect of varying dropout rates on the final Balanced Weighted Accuracy (BWA) for the development dataset. The results suggest that dropout has minimal impact on the final performance, as all dropout rates yield nearly identical BWA values. This indicates that the model is not sensitive to dropout regularization under the current setup.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_dev_bwa_by_dropout.png"}, {"analysis": "This plot presents the test performance of the model on the SPR_BENCH dataset across three metrics: Balanced Weighted Accuracy (BWA), Color-Weighted Accuracy (CWA), and Shape-Weighted Accuracy (SWA). The BWA score (~0.65) is slightly higher than the CWA (~0.62) and SWA (~0.58), suggesting that the model performs better overall compared to its performance on color- and shape-weighted metrics. The lower SWA score may indicate that the model struggles more with shape-related reasoning compared to color-related reasoning.", "plot_path": "experiments/2025-08-30_17-49-45_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff65def095ac441697be600d82d9f3f8_proc_1442555/spr_test_metrics_best_dropout.png"}]], "vlm_feedback_summary": ["The plots collectively indicate that the model is learning effectively and\ngeneralizing well to unseen data. The steady improvement in both accuracy and\nloss metrics, along with a well-balanced confusion matrix, supports the\nhypothesis that the GNN-based approach is suitable for the SPR task.", "The plots collectively demonstrate effective training and generalization of the\nmodel. The steady improvement in accuracy and reduction in loss over epochs,\nalong with the well-aligned training and validation curves, indicate that the\nhyperparameter tuning has been successful. The confusion matrix further supports\nthese observations, showcasing minimal misclassifications and strong predictive\nperformance on the test set.", "The plots provide clear insights into the impact of learning rate on model\nperformance. Higher learning rates, particularly 0.002, lead to better and\nfaster convergence. The evaluation metrics indicate effective learning with\nminimal overfitting. The label distribution plot shows good alignment between\npredictions and ground truth, validating the model's ability to generalize\neffectively.", "The plots reveal the impact of different batch sizes on the model's learning and\ngeneralization. Smaller batch sizes (16, 32, and 64) show consistent\nimprovements in BWA and good alignment between training and development\ndatasets, indicating effective learning and minimal overfitting. However, a\nbatch size of 128 leads to a slight decline in development BWA, suggesting\npotential overfitting or instability. The combination of loss and BWA plots\nfurther supports these observations, highlighting the trade-off between batch\nsize and model performance.", "The plots collectively indicate that the model is effectively learning and\ngeneralizing on the SPR_BENCH dataset. The training and development accuracies\nand losses show consistent improvement, with minimal signs of overfitting.\nDropout regularization has little effect on performance, and the test results\nhighlight that the model performs better on overall accuracy compared to the\ncolor- and shape-weighted metrics, with shape-weighted accuracy being the most\nchallenging."], "exec_time": [21.64319634437561, 229.01460433006287, 60.093480348587036, 87.45934128761292, 165.40662050247192], "exec_time_feedback": ["", "", "", "", ""], "datasets_successfully_tested": [["<all_datasets_in_experiment_data>"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH_bs16'", "'SPR_BENCH_bs32'", "'SPR_BENCH_bs64']"], ["['SPR_BENCH']"]], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# mandatory working dir\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------------------------------------------------------------------\n# iterate over datasets\nfor dset, logs in experiment_data.items():\n    epochs = np.arange(1, len(logs.get(\"losses\", {}).get(\"train\", [])) + 1)\n\n    # 1) Loss curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, logs[\"losses\"][\"train\"], label=\"Train Loss\")\n        plt.plot(epochs, logs[\"losses\"][\"val\"], label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"{dset} Loss Curve\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dset}_loss_curve.png\")\n        plt.tight_layout()\n        plt.savefig(fname)\n        print(f\"Saved: {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {dset}: {e}\")\n        plt.close()\n\n    # 2) Metric curve --------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, logs[\"metrics\"][\"train\"], label=\"Train BWA\")\n        plt.plot(epochs, logs[\"metrics\"][\"val\"], label=\"Val BWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"BWA\")\n        plt.title(f\"{dset} Balanced Weighted Accuracy (BWA)\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dset}_bwa_curve.png\")\n        plt.tight_layout()\n        plt.savefig(fname)\n        print(f\"Saved: {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating BWA curve for {dset}: {e}\")\n        plt.close()\n\n    # 3) Confusion matrix ---------------------------------------------\n    try:\n        preds = np.array(logs.get(\"predictions\", []))\n        gts = np.array(logs.get(\"ground_truth\", []))\n        if preds.size and gts.size:\n            num_classes = max(preds.max(), gts.max()) + 1\n            cm = np.zeros((num_classes, num_classes), dtype=int)\n            for t, p in zip(gts, preds):\n                cm[t, p] += 1\n\n            plt.figure(figsize=(4, 4))\n            im = plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n            plt.colorbar(im, fraction=0.046, pad=0.04)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(f\"{dset} Confusion Matrix\")\n            plt.tight_layout()\n            fname = os.path.join(working_dir, f\"{dset}_confusion_matrix.png\")\n            plt.savefig(fname)\n            print(f\"Saved: {fname}\")\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dset}: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# mandatory working dir\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# ------------------------------------------------------------------\ndef safe_get(dct, *keys):\n    cur = dct\n    for k in keys:\n        if cur is None or k not in cur:\n            return None\n        cur = cur[k]\n    return cur\n\n\n# iterate over datasets (usually just SPR_BENCH)\nfor dset_name, dset_dict in experiment_data.get(\"num_epochs\", {}).items():\n    # ------------------------------------------------------------------\n    # 1) BWA curve\n    try:\n        train_bwa = safe_get(dset_dict, \"metrics\", \"train\")\n        val_bwa = safe_get(dset_dict, \"metrics\", \"val\")\n        if train_bwa and val_bwa:\n            epochs = np.arange(1, len(train_bwa) + 1)\n            plt.figure()\n            plt.plot(epochs, train_bwa, label=\"Train BWA\")\n            plt.plot(epochs, val_bwa, label=\"Validation BWA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Balanced Weighted Accuracy (BWA)\")\n            plt.title(f\"{dset_name}: BWA over Epochs\")\n            plt.legend()\n            plt.tight_layout()\n            fname = os.path.join(working_dir, f\"{dset_name}_bwa_curve.png\")\n            plt.savefig(fname)\n            print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating BWA curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # 2) Loss curve\n    try:\n        train_loss = safe_get(dset_dict, \"losses\", \"train\")\n        val_loss = safe_get(dset_dict, \"losses\", \"val\")\n        if train_loss and val_loss:\n            epochs = np.arange(1, len(train_loss) + 1)\n            plt.figure()\n            plt.plot(epochs, train_loss, label=\"Train Loss\")\n            plt.plot(epochs, val_loss, label=\"Validation Loss\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{dset_name}: Loss over Epochs\")\n            plt.legend()\n            plt.tight_layout()\n            fname = os.path.join(working_dir, f\"{dset_name}_loss_curve.png\")\n            plt.savefig(fname)\n            print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------------------------------------------------------------\n    # 3) Confusion matrix on test predictions\n    try:\n        preds = dset_dict.get(\"predictions\", [])\n        gts = dset_dict.get(\"ground_truth\", [])\n        if preds and gts:\n            preds = np.asarray(preds)\n            gts = np.asarray(gts)\n            num_classes = max(preds.max(), gts.max()) + 1\n            cm = np.zeros((num_classes, num_classes), dtype=int)\n            for gt, pr in zip(gts, preds):\n                cm[gt, pr] += 1\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im, fraction=0.046, pad=0.04)\n            plt.xlabel(\"Predicted Label\")\n            plt.ylabel(\"True Label\")\n            plt.title(f\"{dset_name}: Confusion Matrix (Test Set)\")\n            plt.tight_layout()\n            fname = os.path.join(working_dir, f\"{dset_name}_confusion_matrix.png\")\n            plt.savefig(fname)\n            print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dset_name}: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------\ntry:\n    exp = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = exp[\"learning_rate\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp, grid_keys = {}, []\nelse:\n    grid_keys = list(exp.keys())\n\n\n# ---------------------- helper utilities -----------------------\ndef best_lr_key(exp_dict):\n    best_key, best_val = None, -1\n    for k, rec in exp_dict.items():\n        val_hist = rec[\"metrics\"][\"val\"]\n        if val_hist and val_hist[-1] > best_val:\n            best_val = val_hist[-1]\n            best_key = k\n    return best_key\n\n\nbest_key = best_lr_key(exp)\n\n# ---------------------------- FIG 1 -----------------------------\ntry:\n    plt.figure()\n    for k in grid_keys[:]:\n        epochs = range(1, len(exp[k][\"metrics\"][\"val\"]) + 1)\n        plt.plot(epochs, exp[k][\"metrics\"][\"val\"], label=k.replace(\"lr_\", \"lr=\"))\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Dev BWA\")\n    plt.title(\n        \"Learning-rate comparison on SPR_BENCH\\nLeft: Ground Truth, Right: Generated Samples\"\n    )\n    plt.legend()\n    path = os.path.join(working_dir, \"spr_bench_bwa_curves.png\")\n    plt.savefig(path)\n    print(f\"Saved {path}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot1: {e}\")\n    plt.close()\n\n# ---------------------------- FIG 2 -----------------------------\ntry:\n    plt.figure()\n    for k in grid_keys[:]:\n        ep = range(1, len(exp[k][\"losses\"][\"train\"]) + 1)\n        plt.plot(ep, exp[k][\"losses\"][\"train\"], linestyle=\"-\", label=f\"{k}_train\")\n        plt.plot(ep, exp[k][\"losses\"][\"val\"], linestyle=\"--\", label=f\"{k}_val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"Train/Val Loss for each learning-rate (SPR_BENCH)\")\n    plt.legend(fontsize=6)\n    path = os.path.join(working_dir, \"spr_bench_loss_curves.png\")\n    plt.savefig(path)\n    print(f\"Saved {path}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot2: {e}\")\n    plt.close()\n\n# ---------------------------- FIG 3 -----------------------------\ntry:\n    if best_key:\n        plt.figure()\n        ep = range(1, len(exp[best_key][\"metrics\"][\"train\"]) + 1)\n        plt.plot(ep, exp[best_key][\"metrics\"][\"train\"], label=\"Train BWA\")\n        plt.plot(ep, exp[best_key][\"metrics\"][\"val\"], label=\"Dev BWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"BWA\")\n        plt.title(f\"Best lr ({best_key.replace('lr_','')}) \u2013 Train vs Dev BWA\")\n        plt.legend()\n        path = os.path.join(working_dir, f\"spr_bench_best_lr_bwa.png\")\n        plt.savefig(path)\n        print(f\"Saved {path}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot3: {e}\")\n    plt.close()\n\n# ---------------------------- FIG 4 -----------------------------\ntry:\n    plt.figure()\n    final_bwa = [exp[k][\"test_bwa\"] for k in grid_keys]\n    lrs = [k.replace(\"lr_\", \"\") for k in grid_keys]\n    plt.bar(lrs, final_bwa, color=\"skyblue\")\n    plt.xlabel(\"Learning Rate\")\n    plt.ylabel(\"Test BWA\")\n    plt.title(\"Final Test BWA per Learning-Rate (SPR_BENCH)\")\n    path = os.path.join(working_dir, \"spr_bench_test_bwa_bar.png\")\n    plt.savefig(path)\n    print(f\"Saved {path}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot4: {e}\")\n    plt.close()\n\n# ---------------------------- FIG 5 -----------------------------\ntry:\n    if best_key:\n        preds = np.array(exp[best_key][\"predictions\"])\n        gts = np.array(exp[best_key][\"ground_truth\"])\n        unique_labels = np.unique(np.concatenate([preds, gts]))[:20]  # at most 20\n        pred_counts = [np.sum(preds == l) for l in unique_labels]\n        gt_counts = [np.sum(gts == l) for l in unique_labels]\n        x = np.arange(len(unique_labels))\n        width = 0.35\n        plt.figure(figsize=(8, 4))\n        plt.bar(x - width / 2, gt_counts, width=width, label=\"Ground Truth\")\n        plt.bar(x + width / 2, pred_counts, width=width, label=\"Predictions\")\n        plt.xlabel(\"Label Index\")\n        plt.ylabel(\"Count\")\n        plt.title(f\"Label Distribution \u2013 Best lr ({best_key.replace('lr_','')})\")\n        plt.legend()\n        path = os.path.join(working_dir, \"spr_bench_label_distribution.png\")\n        plt.savefig(path)\n        print(f\"Saved {path}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot5: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ------------------------------------------------------------------\nspr_runs = experiment_data.get(\"batch_size\", {}).get(\"SPR_BENCH\", {})\nbatch_sizes = sorted(spr_runs.keys(), key=lambda x: int(x))[:4]  # ensure only 4\nfig_count = 0\n\nfor bs in batch_sizes:\n    try:\n        run = spr_runs[bs]\n        epochs = np.arange(1, len(run[\"metrics\"][\"train\"]) + 1)\n        fig, ax1 = plt.subplots()\n        ax2 = ax1.twinx()\n\n        # Loss curves (left y-axis)\n        ax1.plot(epochs, run[\"losses\"][\"train\"], \"r--\", label=\"Train Loss\")\n        ax1.plot(epochs, run[\"losses\"][\"val\"], \"r-\", label=\"Val Loss\")\n        ax1.set_xlabel(\"Epoch\")\n        ax1.set_ylabel(\"Cross-Entropy Loss\", color=\"r\")\n        ax1.tick_params(axis=\"y\", labelcolor=\"r\")\n\n        # BWA curves (right y-axis)\n        ax2.plot(epochs, run[\"metrics\"][\"train\"], \"b--\", label=\"Train BWA\")\n        ax2.plot(epochs, run[\"metrics\"][\"val\"], \"b-\", label=\"Val BWA\")\n        ax2.set_ylabel(\"Balanced Weighted Accuracy\", color=\"b\")\n        ax2.tick_params(axis=\"y\", labelcolor=\"b\")\n\n        plt.title(f\"SPR_BENCH (bs={bs})\\nLeft: Loss, Right: BWA \u2013 SPR_BENCH\")\n        fig.tight_layout()\n        name = f\"SPR_BENCH_bs{bs}_loss_bwa_curves.png\"\n        path = os.path.join(working_dir, name)\n        plt.savefig(path)\n        print(f\"Saved {path}\")\n        plt.close()\n        fig_count += 1\n    except Exception as e:\n        print(f\"Error creating curves for bs={bs}: {e}\")\n        plt.close()\n\n# ------------------------------------------------------------------\n# Summary bar chart of final test BWA across batch sizes\ntry:\n    final_bwa = [spr_runs[bs][\"metrics\"][\"val\"][-1] for bs in batch_sizes]\n    x = np.arange(len(batch_sizes))\n    plt.figure()\n    plt.bar(x, final_bwa, color=\"skyblue\")\n    plt.xticks(x, batch_sizes)\n    plt.ylabel(\"Final Dev BWA\")\n    plt.title(\"SPR_BENCH \u2013 Final Balanced Weighted Accuracy by Batch Size\")\n    plt.tight_layout()\n    name = \"SPR_BENCH_final_bwa_vs_batch_size.png\"\n    path = os.path.join(working_dir, name)\n    plt.savefig(path)\n    print(f\"Saved {path}\")\n    plt.close()\n    fig_count += 1\nexcept Exception as e:\n    print(f\"Error creating summary bar chart: {e}\")\n    plt.close()\n\nprint(f\"Total figures created: {fig_count}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# mandatory working dir\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    spr_exp = experiment_data[\"dropout_rate\"][\"SPR_BENCH\"]\n    best_rate = spr_exp[\"best_rate\"]\n    best_dict = spr_exp[f\"dr_{best_rate:.2f}\"]\n    epochs = np.arange(1, len(best_dict[\"metrics\"][\"train\"]) + 1)\n\n    # ---------------------------------------------------------------\n    # 1. BWA curve for best model\n    try:\n        plt.figure()\n        plt.plot(epochs, best_dict[\"metrics\"][\"train\"], label=\"Train BWA\")\n        plt.plot(epochs, best_dict[\"metrics\"][\"val\"], label=\"Dev BWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Balanced Weighted Accuracy\")\n        plt.title(f\"SPR_BENCH BWA vs Epochs (Best Dropout={best_rate:.2f})\")\n        plt.legend()\n        path = os.path.join(working_dir, f\"spr_bwa_curve_best_dr_{best_rate:.2f}.png\")\n        plt.tight_layout()\n        plt.savefig(path)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating BWA curve: {e}\")\n        plt.close()\n\n    # ---------------------------------------------------------------\n    # 2. Loss curve for best model\n    try:\n        plt.figure()\n        plt.plot(epochs, best_dict[\"losses\"][\"train\"], label=\"Train Loss\")\n        plt.plot(epochs, best_dict[\"losses\"][\"val\"], label=\"Dev Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"SPR_BENCH Loss vs Epochs (Best Dropout={best_rate:.2f})\")\n        plt.legend()\n        path = os.path.join(working_dir, f\"spr_loss_curve_best_dr_{best_rate:.2f}.png\")\n        plt.tight_layout()\n        plt.savefig(path)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating Loss curve: {e}\")\n        plt.close()\n\n    # ---------------------------------------------------------------\n    # 3. Dev BWA across dropout rates\n    try:\n        rates, val_bwa = [], []\n        for k, v in spr_exp.items():\n            if k.startswith(\"dr_\"):\n                rates.append(float(k.split(\"_\")[1]))\n                val_bwa.append(v[\"metrics\"][\"val\"][-1])  # last epoch val BWA\n        order = np.argsort(rates)\n        rates = np.array(rates)[order]\n        val_bwa = np.array(val_bwa)[order]\n\n        plt.figure()\n        plt.bar([f\"{r:.2f}\" for r in rates], val_bwa, color=\"skyblue\")\n        plt.xlabel(\"Dropout Rate\")\n        plt.ylabel(\"Final Dev BWA\")\n        plt.title(\"SPR_BENCH Dev BWA by Dropout Rate\")\n        path = os.path.join(working_dir, \"spr_dev_bwa_by_dropout.png\")\n        plt.tight_layout()\n        plt.savefig(path)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating dropout comparison plot: {e}\")\n        plt.close()\n\n    # ---------------------------------------------------------------\n    # 4. Test metrics bar chart\n    try:\n        test_res = spr_exp[\"test\"]\n        metrics = [\"BWA\", \"CWA\", \"SWA\"]\n        values = [test_res[\"BWA\"], test_res[\"CWA\"], test_res[\"SWA\"]]\n        plt.figure()\n        plt.bar(metrics, values, color=[\"green\", \"orange\", \"purple\"])\n        plt.ylim(0, 1)\n        plt.ylabel(\"Score\")\n        plt.title(\"SPR_BENCH Test Metrics (Best Dropout)\")\n        path = os.path.join(working_dir, \"spr_test_metrics_best_dropout.png\")\n        plt.tight_layout()\n        plt.savefig(path)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metrics plot: {e}\")\n        plt.close()\n"], "plot_plan": ["We first load the saved experiment_data.npy, detect which dataset keys are present, and then create up to three standard plots for each dataset: (1) training/validation loss over epochs, (2) training/validation BWA (or generic \u201cmetric\u201d) curves, and (3) a confusion-matrix heat-map on the test set if predictions and ground-truth arrays are available.  Each plot is produced inside its own try\u2013except block to avoid interrupting the workflow if a particular field is missing.  Figures are titled clearly and saved into the mandatory working directory with descriptive filenames that include the dataset name and plot type.  Epoch indices are inferred from the length of the stored loss arrays, and only actual data in experiment_data is visualized\u2014no synthetic values are generated.  We also ensure that no more than five figures per dataset are produced, automatically closing every figure whether or not an exception occurs.  Finally, the script prints the paths of all successfully saved plots so users can verify output.", "We will first load the saved experiment_data.npy from the working directory and verify its integrity.  \nUsing only the arrays contained in this dict, we will create up to three standard plots for the SPR_BENCH experiment: (1) BWA training vs validation curve, (2) loss training vs validation curve, and (3) a confusion-matrix style heat-map comparing ground-truth labels to test predictions.  \nEach visualization is wrapped inside its own try-except block so that a failure in one plot does not halt the others; in all cases figures are explicitly closed.  \nFilenames include the dataset name and plot type for easy identification, and all files are saved to working_dir.  \nAxis labels, legends and clear titles are provided, with subtitles when helpful.  \nIf any expected key is missing or empty (e.g., predictions), that plot is skipped gracefully.  \nThe code uses only basic matplotlib and numpy, follows the interval rule (only one time-series plot per metric), and respects the provided plotting guidelines.", "We will load the saved experiment_data.npy, isolate the SPR_BENCH records for every learning-rate experiment, and collect per-epoch losses and BWA metrics.  \nFigure 1 compares dev-set BWA curves for all four learning-rates.  \nFigure 2 tracks train/val loss curves for every learning-rate (two solid/dashed lines per lr).  \nFigure 3 shows train vs val BWA for only the best learning-rate, emphasising its convergence.  \nFigure 4 is a bar plot of final test BWA obtained by each learning-rate, providing an immediate hyper-parameter comparison.  \nFigure 5 contrasts class-wise counts of ground-truth vs predictions for the best model, helping spot label bias; we truncate to at most the first 20 labels to keep it legible.  \nEach figure is created in an independent try-except block, saved into working_dir with descriptive filenames, and explicitly closed.  \nAll operations rely solely on values present in experiment_data.npy\u2014no synthetic data are introduced.  \nFinally, the script prints the path of every saved figure so the user can locate them easily.", "We first load the saved numpy dictionary and pull out the per\u2013batch-size entries stored under experiment_data['batch_size']['SPR_BENCH']. For each of the four batch sizes we read the recorded epoch-wise arrays of losses and balanced weighted accuracy (BWA). In four separate try-blocks we draw a single figure per batch size that overlays the train/validation BWA curves and the corresponding loss curves on a shared x-axis; the subtitle clearly states \u201cLeft: Loss, Right: BWA \u2013 SPR_BENCH\u201d. After finishing those four plots we create one additional bar chart that compares the final test-set BWA obtained with each batch size, giving a quick summary of the hyper-parameter sweep. All figures are saved in working_dir using descriptive filenames that include the dataset name and the plot type, and every figure is closed immediately after saving. We respect the five-figure ceiling and never invent data\u2014the code only accesses keys that exist in experiment_data.npy. Each plotting block is wrapped in try\u2013except so that errors in one figure do not stop the rest. Finally, the script prints the path of every successfully saved image, allowing quick verification. Everything is contained in a concise, self-contained Python snippet that starts with the mandated imports.", "We first load experiment_data.npy from the working directory, retrieve the best dropout rate and the dictionary that stores epoch-wise losses/metrics for that run, and gather the final validation BWA for every tried dropout value. We then create up to four visualizations: (1) training vs. validation BWA over epochs for the best model, (2) training vs. validation loss over epochs for the same model, (3) a bar chart comparing the final validation BWA of all dropout settings, and (4) a bar chart of final test set metrics (BWA, CWA, SWA). Each plot is built inside its own try-except block, saved with a descriptive filename that includes the dataset name and plot type, and the figure is always closed afterward. We respect the five-figure limit and only use the data contained in experiment_data.npy\u2014no synthetic values are generated. Every plot includes an explicit title that mentions \u201cSPR_BENCH\u201d and clarifies what is being shown. All figures are written to working_dir so they can be inspected later. The code below follows these steps in a concise, self-contained manner."], "ablation_name": [null, null, null, null, null], "hyperparam_name": [null, "num_epochs", "learning_rate", "batch_size", "dropout_rate"], "is_seed_node": [false, false, false, false, false], "is_seed_agg_node": [false, false, false, false, false], "parse_metrics_plan": ["The script will locate the working directory, load the stored numpy dictionary,\nand iterate over each dataset key (e.g., \"SPR_BENCH\").   For every dataset it\nwill compute:   \u2022 the final train balanced-weighted accuracy (last element of\nmetrics[\"train\"])   \u2022 the best validation balanced-weighted accuracy (maximum of\nmetrics[\"val\"])   \u2022 the final train cross-entropy loss (last element of\nlosses[\"train\"])   \u2022 the best validation cross-entropy loss (minimum of\nlosses[\"val\"])   It then prints the dataset name followed by these clearly\nlabelled metrics. No plots or extra output are produced.", "The script will load the saved NumPy file from the working directory, unpack the\nnested dictionary, and then compute the final train metrics, the best validation\nmetrics, and the overall test accuracy for every dataset it finds (only\n\u201cSPR_BENCH\u201d in this case). After computing these values, it prints the dataset\nname followed by clearly-labeled metric/value pairs\u2014no figures or extra text are\nproduced.", "The script will load the NPY file from the working directory, iterate through\nevery learning-rate setting stored for each dataset, and print the final (last-\nepoch) training BWA, validation BWA, test BWA, last-epoch training loss, last-\nepoch validation loss, and test loss. Each value is clearly labelled, and the\ndataset name is printed once before its block of metrics.", "The script will load experiment_data.npy from the \u201cworking\u201d directory, iterate\nthrough every dataset (only \u201cSPR_BENCH\u201d here), and then through every batch-size\nrun that was stored.   For each run it fetches the lists of training/validation\nlosses and accuracies and prints their final (last-epoch) values, clearly\nlabelling each metric (e.g., \u201ctrain accuracy,\u201d \u201cvalidation loss\u201d).   The code\nexecutes immediately at import time, contains no special entry-point guard, and\nproduces no plots.", "The script will 1) locate the working directory, 2) load experiment_data.npy, 3)\nidentify the best dropout run stored in the file, and 4) print clearly-labelled\nfinal metrics (train/validation losses and balanced weighted accuracies from the\nbest run, plus the test metrics) for every dataset found in the file. No plots\nare produced and everything executes at top level."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# Locate working directory and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# Helper to safely fetch final / best values\ndef get_final(lst):\n    return lst[-1] if lst else None\n\n\ndef get_best_val(lst, mode=\"max\"):\n    if not lst:\n        return None\n    return max(lst) if mode == \"max\" else min(lst)\n\n\n# ---------------------------------------------------------------------\n# Iterate over datasets and print metrics\nfor dataset_name, content in experiment_data.items():\n    metrics = content.get(\"metrics\", {})\n    losses = content.get(\"losses\", {})\n\n    final_train_bwa = get_final(metrics.get(\"train\", []))\n    best_val_bwa = get_best_val(metrics.get(\"val\", []), mode=\"max\")\n\n    final_train_loss = get_final(losses.get(\"train\", []))\n    best_val_loss = get_best_val(losses.get(\"val\", []), mode=\"min\")\n\n    print(f\"{dataset_name}:\")\n    if final_train_bwa is not None:\n        print(f\"  final train balanced weighted accuracy: {final_train_bwa:.4f}\")\n    if best_val_bwa is not None:\n        print(f\"  best validation balanced weighted accuracy: {best_val_bwa:.4f}\")\n    if final_train_loss is not None:\n        print(f\"  final train cross-entropy loss: {final_train_loss:.4f}\")\n    if best_val_loss is not None:\n        print(f\"  best validation cross-entropy loss: {best_val_loss:.4f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------\n# Locate and load the stored experiment results\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------\ndef print_metrics(ds_name: str, ds_dict: dict):\n    \"\"\"\n    Print required metrics for a single dataset contained in ds_dict.\n    \"\"\"\n    # Convenience handles\n    met_train = ds_dict[\"metrics\"][\"train\"]  # list of train BWA values\n    met_val = ds_dict[\"metrics\"][\"val\"]  # list of validation BWA values\n    loss_train = ds_dict[\"losses\"][\"train\"]  # list of train losses\n    loss_val = ds_dict[\"losses\"][\"val\"]  # list of validation losses\n\n    # Final and best values\n    final_train_bwa = met_train[-1] if met_train else float(\"nan\")\n    best_validation_bwa = max(met_val) if met_val else float(\"nan\")\n    final_train_loss = loss_train[-1] if loss_train else float(\"nan\")\n    best_validation_loss = min(loss_val) if loss_val else float(\"nan\")\n\n    # Test accuracy (simple correctness ratio on stored predictions)\n    preds = ds_dict.get(\"predictions\", [])\n    gts = ds_dict.get(\"ground_truth\", [])\n    if preds and gts:\n        test_accuracy = sum(int(p == g) for p, g in zip(preds, gts)) / len(gts)\n    else:\n        test_accuracy = float(\"nan\")\n\n    # ----------------- Printing -----------------\n    print(f\"Dataset: {ds_name}\")\n    print(f\"Final train BWA accuracy: {final_train_bwa:.4f}\")\n    print(f\"Best validation BWA accuracy: {best_validation_bwa:.4f}\")\n    print(f\"Final train loss: {final_train_loss:.4f}\")\n    print(f\"Best validation loss: {best_validation_loss:.4f}\")\n    print(f\"Test accuracy: {test_accuracy:.4f}\")\n    print(\"-\" * 40)\n\n\n# ------------------------------------------------------------\n# Iterate through datasets contained in experiment_data\nfor outer_key in experiment_data:  # e.g. 'num_epochs'\n    for dataset_name, dataset_dict in experiment_data[outer_key].items():\n        print_metrics(dataset_name, dataset_dict)\n", "import os\nimport numpy as np\n\n# --------------------- locate and load experiment data --------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# --------------------- iterate and report metrics -------------------------\nfor dataset_name, lr_dict in experiment_data.get(\"learning_rate\", {}).items():\n    # Print dataset header\n    print(f\"Dataset: {dataset_name}\")\n\n    for lr_key, record in lr_dict.items():\n        # Extract learning-rate value from the key \"lr_<value>\"\n        lr_value = lr_key.split(\"_\", 1)[1]\n\n        # Retrieve final (last-epoch) metrics\n        final_train_bwa = (\n            record[\"metrics\"][\"train\"][-1] if record[\"metrics\"][\"train\"] else None\n        )\n        final_val_bwa = (\n            record[\"metrics\"][\"val\"][-1] if record[\"metrics\"][\"val\"] else None\n        )\n        final_train_loss = (\n            record[\"losses\"][\"train\"][-1] if record[\"losses\"][\"train\"] else None\n        )\n        final_val_loss = (\n            record[\"losses\"][\"val\"][-1] if record[\"losses\"][\"val\"] else None\n        )\n\n        # Retrieve test metrics\n        test_bwa = record.get(\"test_bwa\", None)\n        test_loss = record.get(\"test_loss\", None)\n\n        # Print metrics with clear labels\n        print(f\"  Learning rate: {lr_value}\")\n        if final_train_bwa is not None:\n            print(f\"    train BWA: {final_train_bwa:.4f}\")\n        if final_val_bwa is not None:\n            print(f\"    validation BWA: {final_val_bwa:.4f}\")\n        if test_bwa is not None:\n            print(f\"    test BWA: {test_bwa:.4f}\")\n        if final_train_loss is not None:\n            print(f\"    train loss: {final_train_loss:.4f}\")\n        if final_val_loss is not None:\n            print(f\"    validation loss: {final_val_loss:.4f}\")\n        if test_loss is not None:\n            print(f\"    test loss: {test_loss:.4f}\")\n        print()  # blank line between learning-rate settings\n", "import os\nimport numpy as np\n\n# ----------------------------------------------------------------------\n# Locate the saved NumPy file\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\n# Load the dictionary (allow_pickle=True is required to load objects)\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ----------------------------------------------------------------------\n# Iterate over datasets and batch-size runs, printing final metrics\nfor dataset_name, runs in experiment_data.get(\"batch_size\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n    for bs_str, run_data in runs.items():\n        # Retrieve metric/loss histories\n        train_acc_history = run_data[\"metrics\"][\"train\"]  # BWA used as accuracy\n        val_acc_history = run_data[\"metrics\"][\"val\"]\n        train_loss_hist = run_data[\"losses\"][\"train\"]\n        val_loss_hist = run_data[\"losses\"][\"val\"]\n\n        # Final (last-epoch) values\n        final_train_acc = train_acc_history[-1] if train_acc_history else None\n        final_val_acc = val_acc_history[-1] if val_acc_history else None\n        final_train_loss = train_loss_hist[-1] if train_loss_hist else None\n        final_val_loss = val_loss_hist[-1] if val_loss_hist else None\n\n        # Print metrics with clear labels\n        print(f\" batch size: {bs_str}\")\n        if final_train_acc is not None:\n            print(f\"  train accuracy: {final_train_acc:.4f}\")\n        if final_val_acc is not None:\n            print(f\"  validation accuracy: {final_val_acc:.4f}\")\n        if final_train_loss is not None:\n            print(f\"  train loss: {final_train_loss:.4f}\")\n        if final_val_loss is not None:\n            print(f\"  validation loss: {final_val_loss:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# Locate and load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\ndef print_metrics_for_dataset(dataset_name: str, data: dict):\n    # Retrieve the best dropout rate\n    best_rate = data.get(\"best_rate\", None)\n    if best_rate is None:\n        print(f\"{dataset_name}: best dropout rate not recorded.\\n\")\n        return\n\n    best_key = f\"dr_{best_rate:.2f}\"\n    if best_key not in data:\n        print(f\"{dataset_name}: metrics for best dropout rate ({best_key}) missing.\\n\")\n        return\n\n    best_dict = data[best_key]\n    # Final epoch metrics from the best run\n    train_bwa_final = best_dict[\"metrics\"][\"train\"][-1]\n    val_bwa_final = best_dict[\"metrics\"][\"val\"][-1]\n    train_loss_final = best_dict[\"losses\"][\"train\"][-1]\n    val_loss_final = best_dict[\"losses\"][\"val\"][-1]\n\n    test_dict = data.get(\"test\", {})\n    test_bwa = test_dict.get(\"BWA\", None)\n    test_cwa = test_dict.get(\"CWA\", None)\n    test_swa = test_dict.get(\"SWA\", None)\n    test_loss = test_dict.get(\"loss\", None)\n\n    # ------------------ Printing ------------------\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"best dropout rate: {best_rate:.2f}\")\n    print(f\"train balanced weighted accuracy: {train_bwa_final:.4f}\")\n    print(f\"validation balanced weighted accuracy: {val_bwa_final:.4f}\")\n    print(f\"train loss: {train_loss_final:.4f}\")\n    print(f\"validation loss: {val_loss_final:.4f}\")\n    if test_bwa is not None:\n        print(f\"test balanced weighted accuracy: {test_bwa:.4f}\")\n    if test_cwa is not None:\n        print(f\"test color weighted accuracy: {test_cwa:.4f}\")\n    if test_swa is not None:\n        print(f\"test shape weighted accuracy: {test_swa:.4f}\")\n    if test_loss is not None:\n        print(f\"test loss: {test_loss:.4f}\")\n    print()  # blank line for readability\n\n\n# ---------------------------------------------------------------------\n# Iterate over every dataset stored in experiment_data\nfor hyperparam_group in experiment_data.values():  # e.g., \"dropout_rate\"\n    for dataset_name, dataset_data in hyperparam_group.items():  # e.g., \"SPR_BENCH\"\n        if isinstance(dataset_data, dict):\n            print_metrics_for_dataset(dataset_name, dataset_data)\n"], "parse_term_out": ["['SPR_BENCH:', '\\n', '  final train balanced weighted accuracy: 0.8595', '\\n', '\nbest validation balanced weighted accuracy: 0.8686', '\\n', '  final train cross-\nentropy loss: 0.3501', '\\n', '  best validation cross-entropy loss: 0.3512',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', 'Final train BWA accuracy: 0.9495', '\\n', 'Best\nvalidation BWA accuracy: 0.9453', '\\n', 'Final train loss: 0.2114', '\\n', 'Best\nvalidation loss: 0.2024', '\\n', 'Test accuracy: 0.6732', '\\n',\n'----------------------------------------', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', '  Learning rate: 0.0003', '\\n', '    train BWA:\n0.8201', '\\n', '    validation BWA: 0.8212', '\\n', '    test BWA: 0.6259', '\\n',\n'    train loss: 0.4245', '\\n', '    validation loss: 0.4118', '\\n', '    test\nloss: 0.7307', '\\n', '\\n', '  Learning rate: 0.0005', '\\n', '    train BWA:\n0.8377', '\\n', '    validation BWA: 0.8420', '\\n', '    test BWA: 0.6287', '\\n',\n'    train loss: 0.4023', '\\n', '    validation loss: 0.3907', '\\n', '    test\nloss: 0.7515', '\\n', '\\n', '  Learning rate: 0.001', '\\n', '    train BWA:\n0.8729', '\\n', '    validation BWA: 0.8741', '\\n', '    test BWA: 0.6347', '\\n',\n'    train loss: 0.3615', '\\n', '    validation loss: 0.3481', '\\n', '    test\nloss: 0.7967', '\\n', '\\n', '  Learning rate: 0.002', '\\n', '    train BWA:\n0.8999', '\\n', '    validation BWA: 0.9008', '\\n', '    test BWA: 0.6459', '\\n',\n'    train loss: 0.3148', '\\n', '    validation loss: 0.2986', '\\n', '    test\nloss: 0.8965', '\\n', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Dataset: SPR_BENCH', '\\n', ' batch size: 16', '\\n', '  train accuracy:\n0.9018', '\\n', '  validation accuracy: 0.8972', '\\n', '  train loss: 0.3050',\n'\\n', '  validation loss: 0.2941', '\\n', ' batch size: 32', '\\n', '  train\naccuracy: 0.8754', '\\n', '  validation accuracy: 0.8777', '\\n', '  train loss:\n0.3457', '\\n', '  validation loss: 0.3344', '\\n', ' batch size: 64', '\\n', '\ntrain accuracy: 0.8833', '\\n', '  validation accuracy: 0.8819', '\\n', '  train\nloss: 0.3489', '\\n', '  validation loss: 0.3351', '\\n', ' batch size: 128',\n'\\n', '  train accuracy: 0.8371', '\\n', '  validation accuracy: 0.8356', '\\n', '\ntrain loss: 0.3797', '\\n', '  validation loss: 0.3803', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', 'best dropout rate: 0.00', '\\n', 'train balanced\nweighted accuracy: 0.8852', '\\n', 'validation balanced weighted accuracy:\n0.8835', '\\n', 'train loss: 0.3226', '\\n', 'validation loss: 0.3162', '\\n',\n'test balanced weighted accuracy: 0.6394', '\\n', 'test color weighted accuracy:\n0.6586', '\\n', 'test shape weighted accuracy: 0.6201', '\\n', 'test loss:\n0.8647', '\\n', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']"], "parse_exc_type": [null, null, null, null, null], "parse_exc_info": [null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
