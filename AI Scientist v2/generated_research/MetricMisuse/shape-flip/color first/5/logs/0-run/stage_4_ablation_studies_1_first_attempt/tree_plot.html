<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 5], [0, 8], [0, 3], [0, 6], [0, 2], [0, 4], [0, 1], [0, 7], [6, 9], [6, 12], [6, 11], [6, 10]], "layout": [[0.5, 0.0], [0.0, 0.5], [0.14285714285714285, 0.5], [0.2857142857142857, 0.5], [0.42857142857142855, 0.5], [0.5714285714285714, 0.5], [0.7142857142857143, 0.5], [0.8571428571428571, 0.5], [1.0, 0.5], [0.5, 1.0], [0.6428571428571429, 1.0], [0.7857142857142857, 1.0], [0.9285714285714286, 1.0]], "plan": ["We replace the plain GCN with a relational GNN that explicitly models three\ndifferent relations between tokens: (i) immediate-order, (ii) same-shape, and\n(iii) same-color.  Each SPR sequence is converted into a heterogeneous graph\nwhose edge_type encodes these relations, allowing the model to reason jointly\nover positional, shape-based and color-based connections.  The network uses two\nRGCNConv layers followed by attention-style mean pooling to obtain a graph\nembedding, which is classified with a linear head.  We keep the previous early-\nstopping and metric bookkeeping logic, but now track Color-Weighted, Shape-\nWeighted and the requested Complexity-Weighted accuracies at every epoch.  All\nmetrics, losses, predictions and ground-truth labels are stored in the\nexperiment_data dictionary and dumped to the ./working directory so they can be\nreused for later analysis or plots.  If the real SPR_BENCH folder is\nunavailable, the script falls back to a tiny synthetic dataset so that it always\nruns.  Hyper-parameters are kept modest (embed=64, hidden=64, epochs\u226440,\npatience=7) to ensure execution within 30 minutes on CPU or GPU.  The code is\nself-contained, executes on import, and respects the required device handling\nconventions.", "Ablation name: Single-Relation Graph (No Relation Types). The following program\nreuses the original data/utility pipeline but (1) collapses every edge into a\nsingle, un-typed relation, and (2) swaps the two RGCNConv layers for ordinary\nGCNConv layers.  This ablation keeps all other hyper-parameters, training loops,\nmetrics and early-stopping identical to the baseline so that the drop in\nperformance can be attributed solely to the loss of explicit edge semantics.", "Ablation name: No-Sequential-Edge Graphs. The ablation keeps the entire training\npipeline, model, and hyper-parameters identical to the baseline, but rewrites\nthe graph-construction routine so that it ONLY adds \u201csame-shape\u201d (relation 1)\nand \u201csame-color\u201d (relation 2) edges; all sequential (relation 0) links are\nomitted.  The relation-ID space is preserved (num_rel=3) so the RGCN\narchitecture remains unchanged, yet relation 0 is never instantiated.\nEverything else\u2014data loading, training loop, metrics collection, early stopping,\nand saving the `experiment_data.npy` file\u2014remains intact.", "Ablation name: No-Color-Edge Graphs. The ablation replaces the original graph\nconstruction with one that completely omits relation-type 2 (\u201csame-color\u201d\nedges), keeping only sequential (0) and same-shape (1) connections. All other\npipeline stages\u2014dataset loading (real or synthetic), model, training loop,\nmetric computation and result logging\u2014remain identical so that any performance\nchange can be attributed solely to the removed color edges. We track losses and\nCWA/SWA/Complexity-WA for both train and validation splits, perform early\nstopping, evaluate on the held-out test set, and finally persist the full\nexperiment dictionary as experiment_data.npy inside the working directory.", "Ablation name: Constant-Node-Features (Token-Blind Graph). The solution builds\nthe same RGCN architecture but removes all token-identity information: every\nnode now receives the same single learnable embedding (index 0), so the model\nmust rely solely on the relational edges. A separate graph-construction function\ncreates these \u201ctoken-blind\u201d graphs, and a dedicated model class ignores the\noriginal token indices. Training/validation/testing, early stopping, metric\nlogging, and saving `experiment_data.npy` mirror the baseline so results are\ndirectly comparable.", "Ablation name: Shallow-GNN (1-hop) Ablation. The solution re-uses the baseline\npipeline (dataset handling, graph construction, training utilities, etc.) but\ndefines a new Shallow_GNN model that contains only one RGCNConv layer, thereby\nrestricting message passing to 1-hop neighbors.  Everything else (embeddings,\noptimizer, training loop, evaluation, metric logging, and saving to\nexperiment_data.npy) remains unchanged so we can directly compare results with\nthe 2-layer baseline.  Results for this ablation are stored under the key\n'Shallow_GNN_1hop'.", "Ablation name: Undirected-Edge Graphs. We keep the original directed-edge\npipeline unchanged and add a second pipeline that rebuilds every graph with only\none undirected edge per relational pair.  All node features, relation ids\n(0-sequence,1-shape,2-color) and the RGCN architecture are preserved; only\nedge_index/edge_type differ.  Both variants are trained with identical hyper-\nparameters and early stopping so that the performance gap isolates the effect of\nedge directionality.  The script records losses and weighted accuracies for\ntrain/val/test splits for each variant inside a single experiment_data\ndictionary and stores everything as working/experiment_data.npy.", "Ablation name: One-Hot Node Features (Frozen Vocabulary Encoding). Below we keep\nall data\u2010handling and training utilities from the baseline, but swap the\nlearnable embedding for a frozen one-hot representation held in a buffer (or\ngenerated on-the-fly).  This guarantees that node features carry full token\nidentity yet cannot adapt, allowing us to isolate the effect of embedding\nlearning.  We train the new model with the same loop/early-stopping regime, log\nidentical metrics, and finally store everything in the required\nexperiment_data.npy file.  The script is completely self-contained and will fall\nback to the synthetic dataset if SPR-BENCH is unavailable.", "Ablation name: Multi-Synthetic Dataset Generalization Ablation. Below is an\noutline of the solution followed by the full executable code.   We first\nsynthesise three independent SPR-style corpora (Dataset-A,B,C) with different\nrandom seeds.   We construct a shared vocabulary/label map over the union of all\nthree datasets, convert every sequence to a relational graph and reuse the\nbaseline R-GCN model/training loop.   Two experiments are run: (1) train on A,\nvalidate on B, test on C; (2) train on A+B, validate on B, test on C.   All\nlosses, weighted accuracies, predictions and ground-truths are saved in the\nrequired experiment_data.npy file.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, random, time, copy, numpy as np, torch\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport torch.nn as nn\n\n# -------------------------------------------------------------------------\n# required working dir & device boiler-plate\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n# -------------------------------------------------------------------------\n\n\n# try to import official SPR utilities ------------------------------------------------\ndef try_load_real_dataset() -> Tuple[List[dict], List[dict], List[dict]]:\n    try:\n        import SPR\n\n        DATA_PATH = pathlib.Path(os.environ.get(\"SPR_DATA_PATH\", \"./SPR_BENCH\"))\n        dset = SPR.load_spr_bench(DATA_PATH)\n        return dset[\"train\"], dset[\"dev\"], dset[\"test\"]\n    except Exception as e:\n        raise IOError from e\n\n\n# synthetic fallback ------------------------------------------------------------------\ndef build_synthetic_dataset(n_train=600, n_val=150, n_test=150):\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        L = random.randint(4, 10)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    def make_split(n):\n        return [\n            {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n            for i in range(n)\n        ]\n\n    def tag(lst):\n        for i, r in enumerate(lst):\n            r[\"id\"] = i\n        return lst\n\n    return tag(make_split(n_train)), tag(make_split(n_val)), tag(make_split(n_test))\n\n\ntry:\n    train_rows, dev_rows, test_rows = try_load_real_dataset()\n    print(\"Loaded real SPR_BENCH.\")\nexcept IOError:\n    print(\"Using synthetic data (real dataset not found).\")\n    train_rows, dev_rows, test_rows = build_synthetic_dataset()\n\n\n# -------------------------------------------------------------------------\n# vocab & label maps ------------------------------------------------------\ndef all_tokens(rows):\n    for r in rows:\n        for tok in r[\"sequence\"].split():\n            yield tok\n\n\ntoken2idx = {\"<PAD>\": 0}\nfor tok in all_tokens(train_rows + dev_rows + test_rows):\n    token2idx.setdefault(tok, len(token2idx))\nlabel2idx = {}\nfor r in train_rows + dev_rows + test_rows:\n    label2idx.setdefault(r[\"label\"], len(label2idx))\nnum_classes = len(label2idx)\nprint(f\"Vocab={len(token2idx)}, Labels={num_classes}\")\n\n\n# -------------------------------------------------------------------------\n# helper metrics ----------------------------------------------------------\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\n# -------------------------------------------------------------------------\n# graph construction with relation types ---------------------------------\ndef seq_to_graph(seq: str, label: str) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    colors = [t[1] if len(t) > 1 else \"_\" for t in toks]\n    node_feats = torch.tensor([token2idx[t] for t in toks], dtype=torch.long)\n    src, dst, etype = [], [], []\n    # relation 0: next/previous (order)\n    for i in range(n - 1):\n        src.extend([i, i + 1])\n        dst.extend([i + 1, i])\n        etype.extend([0, 0])\n    # relation 1: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n                etype.extend([1, 1])\n    # relation 2: same color\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colors[i] == colors[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n                etype.extend([2, 2])\n    if len(src) == 0:  # fallback self loop\n        src = [0]\n        dst = [0]\n        etype = [0]\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    return Data(\n        x=node_feats,\n        edge_index=edge_index,\n        edge_type=edge_type,\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\ntrain_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in train_rows]\nval_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dev_rows]\ntest_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in test_rows]\n\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# -------------------------------------------------------------------------\n# model -------------------------------------------------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self, vocab_size, embed_dim=64, hidden_dim=64, num_rel=3, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.conv1 = RGCNConv(embed_dim, hidden_dim, num_relations=num_rel)\n        self.conv2 = RGCNConv(hidden_dim, hidden_dim, num_relations=num_rel)\n        self.lin = nn.Linear(hidden_dim, num_cls)\n\n    def forward(self, x, edge_index, edge_type, batch):\n        x = self.embed(x)\n        x = torch.relu(self.conv1(x, edge_index, edge_type))\n        x = torch.relu(self.conv2(x, edge_index, edge_type))\n        g_emb = global_mean_pool(x, batch)\n        return self.lin(g_emb)\n\n\n# -------------------------------------------------------------------------\n# training utilities ------------------------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train = optimizer is not None\n    model.train() if train else model.eval()\n    tot_loss, seqs, y_true, y_pred = 0.0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n        loss = criterion(out, batch.y.squeeze())\n        if train:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        y_pred.extend(preds)\n        y_true.extend(batch.y.squeeze().cpu().tolist())\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, y_true, y_pred)\n    swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n    cpx = complexity_weighted_accuracy(seqs, y_true, y_pred)\n    return avg_loss, cwa, swa, cpx, y_pred, y_true, seqs\n\n\n# -------------------------------------------------------------------------\n# experiment tracking dict ------------------------------------------------\nexperiment_data = {\n    \"SPR_RGCN\": {\n        \"metrics\": {\n            \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n        },\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# -------------------------------------------------------------------------\n# training loop -----------------------------------------------------------\nmax_epochs = 40\npatience = 7\nmodel = SPR_RGCN(len(token2idx), num_cls=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_val = float(\"inf\")\nbest_state = None\nwait = 0\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_cwa, tr_swa, tr_cpx, _, _, _ = run_epoch(\n        model, train_loader, criterion, optimizer\n    )\n    val_loss, val_cwa, val_swa, val_cpx, _, _, _ = run_epoch(\n        model, val_loader, criterion\n    )\n    experiment_data[\"SPR_RGCN\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_RGCN\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_RGCN\"][\"metrics\"][\"train\"][\"CWA\"].append(tr_cwa)\n    experiment_data[\"SPR_RGCN\"][\"metrics\"][\"train\"][\"SWA\"].append(tr_swa)\n    experiment_data[\"SPR_RGCN\"][\"metrics\"][\"train\"][\"CmpWA\"].append(tr_cpx)\n    experiment_data[\"SPR_RGCN\"][\"metrics\"][\"val\"][\"CWA\"].append(val_cwa)\n    experiment_data[\"SPR_RGCN\"][\"metrics\"][\"val\"][\"SWA\"].append(val_swa)\n    experiment_data[\"SPR_RGCN\"][\"metrics\"][\"val\"][\"CmpWA\"].append(val_cpx)\n    experiment_data[\"SPR_RGCN\"][\"epochs\"].append(epoch)\n    print(\n        f\"Epoch {epoch:02d}: \"\n        f\"train_loss={tr_loss:.4f} val_loss={val_loss:.4f} \"\n        f\"val_CmpWA={val_cpx:.4f}\"\n    )\n    if val_loss < best_val - 1e-4:\n        best_val = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        wait = 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping.\")\n            break\n\n# -------------------------------------------------------------------------\n# load best & final test --------------------------------------------------\nif best_state is not None:\n    model.load_state_dict(best_state)\ntest_loss, test_cwa, test_swa, test_cpx, test_pred, test_true, _ = run_epoch(\n    model, test_loader, criterion\n)\nprint(\n    f\"TEST: loss={test_loss:.4f} CWA={test_cwa:.4f} \"\n    f\"SWA={test_swa:.4f} CmpWA={test_cpx:.4f}\"\n)\n\nexperiment_data[\"SPR_RGCN\"][\"predictions\"] = test_pred\nexperiment_data[\"SPR_RGCN\"][\"ground_truth\"] = test_true\nexperiment_data[\"SPR_RGCN\"][\"test_metrics\"] = {\n    \"loss\": test_loss,\n    \"CWA\": test_cwa,\n    \"SWA\": test_swa,\n    \"CmpWA\": test_cpx,\n}\n\n# -------------------------------------------------------------------------\n# save experiment data ----------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "import os, pathlib, random, copy, time, numpy as np, torch\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool  # <<<\u2014 GCN\nimport torch.nn as nn\n\n# -------------------------------------------------------------------------\n# working dir / device ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# -------------------------------------------------------------------------\n# try to load real SPR_BENCH ----------------------------------------------\ndef try_load_real_dataset() -> Tuple[List[dict], List[dict], List[dict]]:\n    try:\n        import SPR\n\n        DATA_PATH = pathlib.Path(os.environ.get(\"SPR_DATA_PATH\", \"./SPR_BENCH\"))\n        dset = SPR.load_spr_bench(DATA_PATH)\n        return dset[\"train\"], dset[\"dev\"], dset[\"test\"]\n    except Exception as e:\n        raise IOError from e\n\n\n# synthetic fallback ------------------------------------------------------\ndef build_synthetic_dataset(n_train=600, n_val=150, n_test=150):\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        L = random.randint(4, 10)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    def make_split(n):\n        return [\n            {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n            for i in range(n)\n        ]\n\n    def tag(lst):\n        for i, r in enumerate(lst):\n            r[\"id\"] = i\n        return lst\n\n    return tag(make_split(n_train)), tag(make_split(n_val)), tag(make_split(n_test))\n\n\ntry:\n    train_rows, dev_rows, test_rows = try_load_real_dataset()\n    dataset_name = \"SPR_BENCH\"\n    print(\"Loaded real SPR_BENCH dataset.\")\nexcept IOError:\n    train_rows, dev_rows, test_rows = build_synthetic_dataset()\n    dataset_name = \"synthetic\"\n    print(\"Using synthetic dataset (real dataset not found).\")\n\n\n# -------------------------------------------------------------------------\n# vocab / label maps ------------------------------------------------------\ndef all_tokens(rows):\n    for r in rows:\n        for tok in r[\"sequence\"].split():\n            yield tok\n\n\ntoken2idx = {\"<PAD>\": 0}\nfor tok in all_tokens(train_rows + dev_rows + test_rows):\n    token2idx.setdefault(tok, len(token2idx))\n\nlabel2idx = {}\nfor r in train_rows + dev_rows + test_rows:\n    label2idx.setdefault(r[\"label\"], len(label2idx))\nnum_classes = len(label2idx)\nprint(f\"Vocab size = {len(token2idx)} | #labels = {num_classes}\")\n\n\n# -------------------------------------------------------------------------\n# metrics helpers ---------------------------------------------------------\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef weighted_acc(weights, y_true, y_pred):\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / (sum(weights) if weights else 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc([count_color_variety(s) for s in seqs], y_true, y_pred)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc([count_shape_variety(s) for s in seqs], y_true, y_pred)\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(\n        [count_color_variety(s) + count_shape_variety(s) for s in seqs], y_true, y_pred\n    )\n\n\n# -------------------------------------------------------------------------\n# graph construction (all edges collapsed to ONE relation) ----------------\ndef seq_to_single_rel_graph(seq: str, label: str) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    colors = [t[1] if len(t) > 1 else \"_\" for t in toks]\n    node_feats = torch.tensor([token2idx[t] for t in toks], dtype=torch.long)\n\n    src, dst = [], []\n    # original relation 0: next / previous\n    for i in range(n - 1):\n        src.extend([i, i + 1])\n        dst.extend([i + 1, i])\n    # original relation 1: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n    # original relation 2: same color\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colors[i] == colors[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n\n    if len(src) == 0:  # self loop fallback\n        src, dst = [0], [0]\n\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    edge_type = torch.zeros(\n        edge_index.size(1), dtype=torch.long\n    )  # single relation id 0\n    return Data(\n        x=node_feats,\n        edge_index=edge_index,\n        edge_type=edge_type,\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\ntrain_graphs = [seq_to_single_rel_graph(r[\"sequence\"], r[\"label\"]) for r in train_rows]\nval_graphs = [seq_to_single_rel_graph(r[\"sequence\"], r[\"label\"]) for r in dev_rows]\ntest_graphs = [seq_to_single_rel_graph(r[\"sequence\"], r[\"label\"]) for r in test_rows]\n\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# -------------------------------------------------------------------------\n# Ablation model: Two-layer GCN -------------------------------------------\nclass SPR_GCN(nn.Module):\n    def __init__(self, vocab, embed_dim=64, hidden_dim=64, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.conv1 = GCNConv(embed_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.lin = nn.Linear(hidden_dim, num_cls)\n\n    def forward(self, x, edge_index, edge_type, batch):  # edge_type ignored\n        x = self.embed(x)\n        x = torch.relu(self.conv1(x, edge_index))\n        x = torch.relu(self.conv2(x, edge_index))\n        g = global_mean_pool(x, batch)\n        return self.lin(g)\n\n\n# -------------------------------------------------------------------------\n# training / eval loop ----------------------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train_flag = optimizer is not None\n    model.train() if train_flag else model.eval()\n    tot_loss, seqs, y_true, y_pred = 0.0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n        loss = criterion(out, batch.y.squeeze())\n        if train_flag:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        y_pred.extend(preds)\n        y_true.extend(batch.y.squeeze().cpu().tolist())\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    return (\n        avg_loss,\n        color_weighted_accuracy(seqs, y_true, y_pred),\n        shape_weighted_accuracy(seqs, y_true, y_pred),\n        complexity_weighted_accuracy(seqs, y_true, y_pred),\n        y_pred,\n        y_true,\n        seqs,\n    )\n\n\ndef train_model(\n    model, train_loader, val_loader, test_loader, max_epochs=40, patience=7, lr=1e-3\n):\n    model = model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optim = torch.optim.Adam(model.parameters(), lr=lr)\n    history = {\n        \"loss_tr\": [],\n        \"loss_val\": [],\n        \"CWA_tr\": [],\n        \"CWA_val\": [],\n        \"SWA_tr\": [],\n        \"SWA_val\": [],\n        \"CmpWA_tr\": [],\n        \"CmpWA_val\": [],\n    }\n    best_val, best_state, wait = float(\"inf\"), None, 0\n\n    for epoch in range(1, max_epochs + 1):\n        tr = run_epoch(model, train_loader, criterion, optim)\n        va = run_epoch(model, val_loader, criterion)\n        history[\"loss_tr\"].append(tr[0])\n        history[\"loss_val\"].append(va[0])\n        history[\"CWA_tr\"].append(tr[1])\n        history[\"CWA_val\"].append(va[1])\n        history[\"SWA_tr\"].append(tr[2])\n        history[\"SWA_val\"].append(va[2])\n        history[\"CmpWA_tr\"].append(tr[3])\n        history[\"CmpWA_val\"].append(va[3])\n        print(\n            f\"Epoch {epoch:02d}: train_loss={tr[0]:.4f} val_loss={va[0]:.4f} \"\n            f\"val_CmpWA={va[3]:.4f}\"\n        )\n        if va[0] < best_val - 1e-4:\n            best_val, best_state, wait = va[0], copy.deepcopy(model.state_dict()), 0\n        else:\n            wait += 1\n            if wait >= patience:\n                print(\"Early stopping.\")\n                break\n    # load best and test\n    if best_state is not None:\n        model.load_state_dict(best_state)\n    te = run_epoch(model, test_loader, criterion)\n    print(f\"TEST: loss={te[0]:.4f} CWA={te[1]:.4f} SWA={te[2]:.4f} CmpWA={te[3]:.4f}\")\n    return history, te\n\n\n# -------------------------------------------------------------------------\n# run ablation ------------------------------------------------------------\nmodel_gcn = SPR_GCN(len(token2idx), num_cls=num_classes)\nhist, test_stats = train_model(model_gcn, train_loader, val_loader, test_loader)\n\n# -------------------------------------------------------------------------\n# save experiment data ----------------------------------------------------\nexperiment_data = {\n    \"SingleRelation_GCN\": {\n        dataset_name: {\n            \"metrics\": {\n                \"train\": {\n                    \"CWA\": hist[\"CWA_tr\"],\n                    \"SWA\": hist[\"SWA_tr\"],\n                    \"CmpWA\": hist[\"CmpWA_tr\"],\n                },\n                \"val\": {\n                    \"CWA\": hist[\"CWA_val\"],\n                    \"SWA\": hist[\"SWA_val\"],\n                    \"CmpWA\": hist[\"CmpWA_val\"],\n                },\n            },\n            \"losses\": {\"train\": hist[\"loss_tr\"], \"val\": hist[\"loss_val\"]},\n            \"predictions\": test_stats[4],\n            \"ground_truth\": test_stats[5],\n            \"test_metrics\": {\n                \"loss\": test_stats[0],\n                \"CWA\": test_stats[1],\n                \"SWA\": test_stats[2],\n                \"CmpWA\": test_stats[3],\n            },\n        }\n    }\n}\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved all metrics to:\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, copy, numpy as np, torch\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport torch.nn as nn\n\n# --------------------------------------------------------\n# experiment-tracking dict (guideline-compliant structure)\n# --------------------------------------------------------\nexperiment_data = {\n    \"NoSeqEdges\": {\n        \"dataset\": {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# --------------------------------------------------------\n# env / device\n# --------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# --------------------------------------------------------\n# try to load real dataset (SPR_BENCH); otherwise synthetic\n# --------------------------------------------------------\ndef try_load_real_dataset() -> Tuple[List[dict], List[dict], List[dict]]:\n    try:\n        import SPR\n\n        DATA_PATH = pathlib.Path(os.environ.get(\"SPR_DATA_PATH\", \"./SPR_BENCH\"))\n        dset = SPR.load_spr_bench(DATA_PATH)\n        return dset[\"train\"], dset[\"dev\"], dset[\"test\"]\n    except Exception:\n        raise IOError\n\n\ndef build_synthetic_dataset(n_train=600, n_val=150, n_test=150):\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        L = random.randint(4, 10)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    def make_split(n):\n        return [\n            {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n            for i in range(n)\n        ]\n\n    def tag(lst):\n        for i, r in enumerate(lst):\n            r[\"id\"] = i\n        return lst\n\n    return tag(make_split(n_train)), tag(make_split(n_val)), tag(make_split(n_test))\n\n\ntry:\n    train_rows, dev_rows, test_rows = try_load_real_dataset()\n    dataset_name = \"SPR\"\n    print(\"Loaded real SPR_BENCH.\")\nexcept IOError:\n    print(\"Using synthetic data.\")\n    train_rows, dev_rows, test_rows = build_synthetic_dataset()\n    dataset_name = \"Synthetic\"\n\n\n# --------------------------------------------------------\n# vocab / label maps\n# --------------------------------------------------------\ndef all_tokens(rows):\n    for r in rows:\n        for tok in r[\"sequence\"].split():\n            yield tok\n\n\ntoken2idx = {\"<PAD>\": 0}\nfor tok in all_tokens(train_rows + dev_rows + test_rows):\n    token2idx.setdefault(tok, len(token2idx))\n\nlabel2idx = {}\nfor r in train_rows + dev_rows + test_rows:\n    label2idx.setdefault(r[\"label\"], len(label2idx))\nnum_classes = len(label2idx)\nprint(f\"Vocab size={len(token2idx)}, num_classes={num_classes}\")\n\n\n# --------------------------------------------------------\n# metric helpers\n# --------------------------------------------------------\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\n# --------------------------------------------------------\n# NO-SEQUENTIAL-EDGE graph construction\n# keeps only relations 1 (same shape) & 2 (same color)\n# --------------------------------------------------------\ndef seq_to_graph(seq: str, label: str) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    colors = [t[1] if len(t) > 1 else \"_\" for t in toks]\n    node_feats = torch.tensor([token2idx[t] for t in toks], dtype=torch.long)\n\n    src, dst, etype = [], [], []\n    # relation 1: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n                etype.extend([1, 1])\n    # relation 2: same color\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colors[i] == colors[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n                etype.extend([2, 2])\n\n    # ensure at least one edge (self-loop, use dummy relation 1)\n    if not src:\n        src, dst, etype = [0], [0], [1]\n\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    return Data(\n        x=node_feats,\n        edge_index=edge_index,\n        edge_type=edge_type,\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\ntrain_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in train_rows]\nval_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dev_rows]\ntest_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in test_rows]\n\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# --------------------------------------------------------\n# RGCN model (unchanged, num_rel=3)\n# --------------------------------------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self, vocab, embed_dim=64, hidden_dim=64, num_rel=3, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.conv1 = RGCNConv(embed_dim, hidden_dim, num_relations=num_rel)\n        self.conv2 = RGCNConv(hidden_dim, hidden_dim, num_relations=num_rel)\n        self.lin = nn.Linear(hidden_dim, num_cls)\n\n    def forward(self, x, edge_index, edge_type, batch):\n        h = self.embed(x)\n        h = torch.relu(self.conv1(h, edge_index, edge_type))\n        h = torch.relu(self.conv2(h, edge_index, edge_type))\n        g = global_mean_pool(h, batch)\n        return self.lin(g)\n\n\n# --------------------------------------------------------\n# train / eval routines\n# --------------------------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train = optimizer is not None\n    model.train() if train else model.eval()\n    tot_loss, seqs, y_true, y_pred = 0.0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n        loss = criterion(out, batch.y.squeeze())\n        if train:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        y_pred.extend(preds)\n        y_true.extend(batch.y.squeeze().cpu().tolist())\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    return (\n        avg_loss,\n        color_weighted_accuracy(seqs, y_true, y_pred),\n        shape_weighted_accuracy(seqs, y_true, y_pred),\n        complexity_weighted_accuracy(seqs, y_true, y_pred),\n        y_pred,\n        y_true,\n        seqs,\n    )\n\n\n# --------------------------------------------------------\n# training loop\n# --------------------------------------------------------\nmax_epochs, patience = 40, 7\nmodel = SPR_RGCN(len(token2idx), num_cls=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_val, best_state, wait = float(\"inf\"), None, 0\nfor epoch in range(1, max_epochs + 1):\n    tr = run_epoch(model, train_loader, criterion, optimizer)\n    vl = run_epoch(model, val_loader, criterion)\n    # log\n    experiment_data[\"NoSeqEdges\"][\"dataset\"][\"losses\"][\"train\"].append(tr[0])\n    experiment_data[\"NoSeqEdges\"][\"dataset\"][\"losses\"][\"val\"].append(vl[0])\n    for k, idx in zip((\"CWA\", \"SWA\", \"CmpWA\"), (1, 2, 3)):\n        experiment_data[\"NoSeqEdges\"][\"dataset\"][\"metrics\"][\"train\"][k].append(tr[idx])\n        experiment_data[\"NoSeqEdges\"][\"dataset\"][\"metrics\"][\"val\"][k].append(vl[idx])\n    experiment_data[\"NoSeqEdges\"][\"dataset\"][\"epochs\"].append(epoch)\n    print(\n        f\"Epoch {epoch:02d} | train_loss={tr[0]:.4f} val_loss={vl[0]:.4f} val_CmpWA={vl[3]:.4f}\"\n    )\n\n    if vl[0] < best_val - 1e-4:\n        best_val, best_state, wait = vl[0], copy.deepcopy(model.state_dict()), 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping.\")\n            break\n\n# --------------------------------------------------------\n# evaluate on test set\n# --------------------------------------------------------\nif best_state is not None:\n    model.load_state_dict(best_state)\ntest = run_epoch(model, test_loader, criterion)\nprint(\n    f\"TEST | loss={test[0]:.4f} CWA={test[1]:.4f} SWA={test[2]:.4f} CmpWA={test[3]:.4f}\"\n)\n\nexperiment_data[\"NoSeqEdges\"][\"dataset\"][\"predictions\"] = test[4]\nexperiment_data[\"NoSeqEdges\"][\"dataset\"][\"ground_truth\"] = test[5]\nexperiment_data[\"NoSeqEdges\"][\"dataset\"][\"test_metrics\"] = {\n    \"loss\": test[0],\n    \"CWA\": test[1],\n    \"SWA\": test[2],\n    \"CmpWA\": test[3],\n}\n\n# --------------------------------------------------------\n# save results\n# --------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "import os, pathlib, random, copy, numpy as np, torch, time\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport torch.nn as nn\n\n# ---------------------------------------------------------------------#\n# working dir & device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------#\n# dataset loading (real SPR or synthetic fallback)\ndef try_load_real_dataset() -> Tuple[List[dict], List[dict], List[dict]]:\n    try:\n        import SPR\n\n        DATA_PATH = pathlib.Path(os.environ.get(\"SPR_DATA_PATH\", \"./SPR_BENCH\"))\n        dset = SPR.load_spr_bench(DATA_PATH)\n        return dset[\"train\"], dset[\"dev\"], dset[\"test\"]\n    except Exception as e:\n        raise IOError from e\n\n\ndef build_synthetic_dataset(n_train=600, n_val=150, n_test=150):\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        L = random.randint(4, 10)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    def make_split(n):\n        return [\n            {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n            for i in range(n)\n        ]\n\n    def tag(lst):\n        for i, r in enumerate(lst):\n            r[\"id\"] = i\n        return lst\n\n    return tag(make_split(n_train)), tag(make_split(n_val)), tag(make_split(n_test))\n\n\ntry:\n    train_rows, dev_rows, test_rows = try_load_real_dataset()\n    print(\"Loaded real SPR_BENCH dataset.\")\nexcept IOError:\n    print(\"Using synthetic data (real dataset not found).\")\n    train_rows, dev_rows, test_rows = build_synthetic_dataset()\n\n\n# ---------------------------------------------------------------------#\n# vocabulary & label mapping\ndef all_tokens(rows):\n    for r in rows:\n        for tok in r[\"sequence\"].split():\n            yield tok\n\n\ntoken2idx = {\"<PAD>\": 0}\nfor tok in all_tokens(train_rows + dev_rows + test_rows):\n    token2idx.setdefault(tok, len(token2idx))\n\nlabel2idx = {}\nfor r in train_rows + dev_rows + test_rows:\n    label2idx.setdefault(r[\"label\"], len(label2idx))\n\nnum_classes = len(label2idx)\nprint(f\"Vocab size: {len(token2idx)}, #Labels: {num_classes}\")\n\n\n# ---------------------------------------------------------------------#\n# metric helpers\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\n# ---------------------------------------------------------------------#\n# Ablation: graph construction WITHOUT same-color edges\ndef seq_to_graph_no_color(seq: str, label: str) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    node_feats = torch.tensor([token2idx[t] for t in toks], dtype=torch.long)\n\n    src, dst, etype = [], [], []\n    # relation 0: sequential edges\n    for i in range(n - 1):\n        src.extend([i, i + 1])\n        dst.extend([i + 1, i])\n        etype.extend([0, 0])\n    # relation 1: same shape edges\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n                etype.extend([1, 1])\n\n    if not src:  # self-loop safeguard\n        src = [0]\n        dst = [0]\n        etype = [0]\n\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    return Data(\n        x=node_feats,\n        edge_index=edge_index,\n        edge_type=edge_type,\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\ntrain_graphs = [seq_to_graph_no_color(r[\"sequence\"], r[\"label\"]) for r in train_rows]\nval_graphs = [seq_to_graph_no_color(r[\"sequence\"], r[\"label\"]) for r in dev_rows]\ntest_graphs = [seq_to_graph_no_color(r[\"sequence\"], r[\"label\"]) for r in test_rows]\n\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# ---------------------------------------------------------------------#\n# model definition (only 2 relations now)\nclass SPR_RGCN(nn.Module):\n    def __init__(self, vocab, embed_dim=64, hidden_dim=64, num_rel=2, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab, embed_dim, padding_idx=0)\n        self.conv1 = RGCNConv(embed_dim, hidden_dim, num_relations=num_rel)\n        self.conv2 = RGCNConv(hidden_dim, hidden_dim, num_relations=num_rel)\n        self.lin = nn.Linear(hidden_dim, num_cls)\n\n    def forward(self, x, edge_index, edge_type, batch):\n        x = self.embed(x)\n        x = torch.relu(self.conv1(x, edge_index, edge_type))\n        x = torch.relu(self.conv2(x, edge_index, edge_type))\n        g_emb = global_mean_pool(x, batch)\n        return self.lin(g_emb)\n\n\n# ---------------------------------------------------------------------#\n# epoch runner\ndef run_epoch(model, loader, criterion, opt=None):\n    train_mode = opt is not None\n    model.train() if train_mode else model.eval()\n    tot_loss, seqs, y_true, y_pred = 0.0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n        loss = criterion(out, batch.y.squeeze())\n        if train_mode:\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        y_pred.extend(preds)\n        y_true.extend(batch.y.squeeze().cpu().tolist())\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, y_true, y_pred)\n    swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n    cpx = complexity_weighted_accuracy(seqs, y_true, y_pred)\n    return avg_loss, cwa, swa, cpx, y_pred, y_true\n\n\n# ---------------------------------------------------------------------#\n# experiment tracking dict\nexperiment_data = {\n    \"no_color_edge\": {\n        \"SPR_RGCN\": {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------------------------------------------------------------------#\n# training loop\nmax_epochs, patience = 40, 7\nmodel = SPR_RGCN(len(token2idx), num_cls=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_val, best_state, wait = float(\"inf\"), None, 0\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_cwa, tr_swa, tr_cpx, _, _ = run_epoch(\n        model, train_loader, criterion, optimizer\n    )\n    val_loss, val_cwa, val_swa, val_cpx, _, _ = run_epoch(model, val_loader, criterion)\n\n    exp = experiment_data[\"no_color_edge\"][\"SPR_RGCN\"]\n    exp[\"losses\"][\"train\"].append(tr_loss)\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"train\"][\"CWA\"].append(tr_cwa)\n    exp[\"metrics\"][\"train\"][\"SWA\"].append(tr_swa)\n    exp[\"metrics\"][\"train\"][\"CmpWA\"].append(tr_cpx)\n    exp[\"metrics\"][\"val\"][\"CWA\"].append(val_cwa)\n    exp[\"metrics\"][\"val\"][\"SWA\"].append(val_swa)\n    exp[\"metrics\"][\"val\"][\"CmpWA\"].append(val_cpx)\n    exp[\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch:02d} | \"\n        f\"train_loss {tr_loss:.4f} val_loss {val_loss:.4f} \"\n        f\"val CWA {val_cwa:.4f} SWA {val_swa:.4f} CmpWA {val_cpx:.4f}\"\n    )\n\n    if val_loss < best_val - 1e-4:\n        best_val, best_state, wait = val_loss, copy.deepcopy(model.state_dict()), 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n# ---------------------------------------------------------------------#\n# evaluation on test split\nif best_state is not None:\n    model.load_state_dict(best_state)\n\ntest_loss, test_cwa, test_swa, test_cpx, test_pred, test_true = run_epoch(\n    model, test_loader, criterion\n)\nprint(\n    f\"TEST: loss={test_loss:.4f} CWA={test_cwa:.4f} \"\n    f\"SWA={test_swa:.4f} CmpWA={test_cpx:.4f}\"\n)\n\nexp = experiment_data[\"no_color_edge\"][\"SPR_RGCN\"]\nexp[\"predictions\"] = test_pred\nexp[\"ground_truth\"] = test_true\nexp[\"test_metrics\"] = {\n    \"loss\": test_loss,\n    \"CWA\": test_cwa,\n    \"SWA\": test_swa,\n    \"CmpWA\": test_cpx,\n}\n\n# ---------------------------------------------------------------------#\n# save all experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to working/experiment_data.npy\")\n", "# constant_node_feature_ablation.py\nimport os, pathlib, random, copy, numpy as np, torch, time\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport torch.nn as nn\n\n# -------------------------------------------------------------------------\n# working dir & torch device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n# -------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------\n# load real SPR or fall back to synthetic ---------------------------------\ndef try_load_real_dataset() -> Tuple[List[dict], List[dict], List[dict]]:\n    try:\n        import SPR\n\n        DATA_PATH = pathlib.Path(os.environ.get(\"SPR_DATA_PATH\", \"./SPR_BENCH\"))\n        dset = SPR.load_spr_bench(DATA_PATH)\n        return dset[\"train\"], dset[\"dev\"], dset[\"test\"]\n    except Exception:\n        raise IOError\n\n\ndef build_synthetic_dataset(n_train=600, n_val=150, n_test=150):\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        L = random.randint(4, 10)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    def make_split(n):\n        return [\n            {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n            for i in range(n)\n        ]\n\n    def tag(lst):\n        for i, r in enumerate(lst):\n            r[\"id\"] = i\n        return lst\n\n    return tag(make_split(n_train)), tag(make_split(n_val)), tag(make_split(n_test))\n\n\ntry:\n    train_rows, dev_rows, test_rows = try_load_real_dataset()\n    print(\"Loaded real SPR_BENCH dataset.\")\nexcept IOError:\n    print(\"Using synthetic dataset (real dataset not found).\")\n    train_rows, dev_rows, test_rows = build_synthetic_dataset()\n# -------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------\n# metrics helpers ---------------------------------------------------------\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\n# -------------------------------------------------------------------------\n# graph construction (TOKEN-BLIND) ----------------------------------------\ndef seq_to_graph_tokenblind(seq: str, label: str) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    colors = [t[1] if len(t) > 1 else \"_\" for t in toks]\n\n    # every node gets identical index 0 -> same learnable vector\n    node_feats = torch.zeros(n, dtype=torch.long)  # all zeros\n\n    src, dst, etype = [], [], []\n    # relation 0: sequential neighbours\n    for i in range(n - 1):\n        src.extend([i, i + 1])\n        dst.extend([i + 1, i])\n        etype.extend([0, 0])\n    # relation 1: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n                etype.extend([1, 1])\n    # relation 2: same color\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colors[i] == colors[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n                etype.extend([2, 2])\n    if len(src) == 0:\n        src, dst, etype = [0], [0], [0]\n\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    return Data(\n        x=node_feats,\n        edge_index=edge_index,\n        edge_type=edge_type,\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\n# -------------------------------------------------------------------------\n# label map (need only labels, token vocab not used here) -----------------\nlabel2idx = {}\nfor r in train_rows + dev_rows + test_rows:\n    label2idx.setdefault(r[\"label\"], len(label2idx))\nnum_classes = len(label2idx)\nprint(f\"Num classes = {num_classes}\")\n# -------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------\n# build graphs & loaders --------------------------------------------------\ntrain_graphs = [seq_to_graph_tokenblind(r[\"sequence\"], r[\"label\"]) for r in train_rows]\nval_graphs = [seq_to_graph_tokenblind(r[\"sequence\"], r[\"label\"]) for r in dev_rows]\ntest_graphs = [seq_to_graph_tokenblind(r[\"sequence\"], r[\"label\"]) for r in test_rows]\n\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n# -------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------\n# TOKEN-BLIND RGCN model --------------------------------------------------\nclass SPR_RGCN_TokenBlind(nn.Module):\n    def __init__(self, embed_dim=64, hidden_dim=64, num_rel=3, num_cls=2):\n        super().__init__()\n        # single learnable vector shared by all nodes\n        self.embed = nn.Embedding(1, embed_dim)\n        self.conv1 = RGCNConv(embed_dim, hidden_dim, num_relations=num_rel)\n        self.conv2 = RGCNConv(hidden_dim, hidden_dim, num_relations=num_rel)\n        self.lin = nn.Linear(hidden_dim, num_cls)\n\n    def forward(self, x, edge_index, edge_type, batch):\n        x = self.embed(x)  # x values are all 0, so returns shared vector\n        x = torch.relu(self.conv1(x, edge_index, edge_type))\n        x = torch.relu(self.conv2(x, edge_index, edge_type))\n        g_emb = global_mean_pool(x, batch)\n        return self.lin(g_emb)\n\n\n# -------------------------------------------------------------------------\n# training utilities ------------------------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train_mode = optimizer is not None\n    model.train() if train_mode else model.eval()\n    total_loss, seqs, y_true, y_pred = 0.0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n        loss = criterion(out, batch.y.squeeze())\n        if train_mode:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        total_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        y_pred.extend(preds)\n        y_true.extend(batch.y.squeeze().cpu().tolist())\n        seqs.extend(batch.seq)\n    avg_loss = total_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, y_true, y_pred)\n    swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n    cpx = complexity_weighted_accuracy(seqs, y_true, y_pred)\n    return avg_loss, cwa, swa, cpx, y_pred, y_true, seqs\n\n\n# -------------------------------------------------------------------------\n# experiment tracking dict -----------------------------------------------\nexperiment_data = {\n    \"ConstantNodeFeatures\": {\n        \"SPR\": {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n# -------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------\n# training loop -----------------------------------------------------------\nmax_epochs, patience = 40, 7\nmodel = SPR_RGCN_TokenBlind(num_cls=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nbest_val, best_state, wait = float(\"inf\"), None, 0\n\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_cwa, tr_swa, tr_cpx, _, _, _ = run_epoch(\n        model, train_loader, criterion, optimizer\n    )\n    val_loss, val_cwa, val_swa, val_cpx, _, _, _ = run_epoch(\n        model, val_loader, criterion\n    )\n    ex = experiment_data[\"ConstantNodeFeatures\"][\"SPR\"]\n    ex[\"losses\"][\"train\"].append(tr_loss)\n    ex[\"losses\"][\"val\"].append(val_loss)\n    ex[\"metrics\"][\"train\"][\"CWA\"].append(tr_cwa)\n    ex[\"metrics\"][\"train\"][\"SWA\"].append(tr_swa)\n    ex[\"metrics\"][\"train\"][\"CmpWA\"].append(tr_cpx)\n    ex[\"metrics\"][\"val\"][\"CWA\"].append(val_cwa)\n    ex[\"metrics\"][\"val\"][\"SWA\"].append(val_swa)\n    ex[\"metrics\"][\"val\"][\"CmpWA\"].append(val_cpx)\n    ex[\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch:02d}: train_loss={tr_loss:.4f} \"\n        f\"val_loss={val_loss:.4f} val_CmpWA={val_cpx:.4f}\"\n    )\n    if val_loss < best_val - 1e-4:\n        best_val, best_state, wait = val_loss, copy.deepcopy(model.state_dict()), 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping.\")\n            break\n\n# -------------------------------------------------------------------------\n# evaluation on test set --------------------------------------------------\nif best_state is not None:\n    model.load_state_dict(best_state)\ntest_loss, test_cwa, test_swa, test_cpx, test_pred, test_true, _ = run_epoch(\n    model, test_loader, criterion\n)\nprint(\n    f\"TEST: loss={test_loss:.4f} CWA={test_cwa:.4f} \"\n    f\"SWA={test_swa:.4f} CmpWA={test_cpx:.4f}\"\n)\nexp = experiment_data[\"ConstantNodeFeatures\"][\"SPR\"]\nexp[\"predictions\"] = test_pred\nexp[\"ground_truth\"] = test_true\nexp[\"test_metrics\"] = {\n    \"loss\": test_loss,\n    \"CWA\": test_cwa,\n    \"SWA\": test_swa,\n    \"CmpWA\": test_cpx,\n}\n# -------------------------------------------------------------------------\n# save experiment data ----------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "# Shallow-GNN (1-hop) ablation study \u2013 self-contained runnable script\nimport os, pathlib, random, copy, numpy as np, torch, time\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport torch.nn as nn\n\n# -------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# -------------------------------------------------------------------------\n# dataset loading (real SPR_BENCH if available, else synthetic fallback)\ndef try_load_real_dataset() -> Tuple[List[dict], List[dict], List[dict]]:\n    try:\n        import SPR\n\n        DATA_PATH = pathlib.Path(os.environ.get(\"SPR_DATA_PATH\", \"./SPR_BENCH\"))\n        ds = SPR.load_spr_bench(DATA_PATH)\n        return ds[\"train\"], ds[\"dev\"], ds[\"test\"]\n    except Exception:\n        raise IOError\n\n\ndef build_synthetic_dataset(n_train=600, n_val=150, n_test=150):\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        return \" \".join(\n            random.choice(shapes) + random.choice(colors)\n            for _ in range(random.randint(4, 10))\n        )\n\n    def make_split(n):\n        lst = [\n            {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n            for i in range(n)\n        ]\n        for i, r in enumerate(lst):\n            r[\"id\"] = i\n        return lst\n\n    return make_split(n_train), make_split(n_val), make_split(n_test)\n\n\ntry:\n    train_rows, dev_rows, test_rows = try_load_real_dataset()\n    dataset_name = \"SPR_BENCH\"\n    print(\"Loaded real SPR_BENCH.\")\nexcept IOError:\n    train_rows, dev_rows, test_rows = build_synthetic_dataset()\n    dataset_name = \"synthetic\"\n    print(\"Using synthetic dataset.\")\n\n\n# -------------------------------------------------------------------------\n# vocab / label maps\ndef all_tokens(rows):\n    for r in rows:\n        for t in r[\"sequence\"].split():\n            yield t\n\n\ntoken2idx = {\"<PAD>\": 0}\nfor tok in all_tokens(train_rows + dev_rows + test_rows):\n    token2idx.setdefault(tok, len(token2idx))\n\nlabel2idx = {}\nfor r in train_rows + dev_rows + test_rows:\n    label2idx.setdefault(r[\"label\"], len(label2idx))\nnum_classes = len(label2idx)\nprint(f\"Vocab={len(token2idx)}  Labels={num_classes}\")\n\n\n# -------------------------------------------------------------------------\n# metrics\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split() if len(t) > 1})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split() if t})\n\n\ndef _w_acc(seqs, y_t, y_p, func):\n    w = [func(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_t, y_p)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(a, b, c):\n    return _w_acc(a, b, c, count_color_variety)\n\n\ndef shape_weighted_accuracy(a, b, c):\n    return _w_acc(a, b, c, count_shape_variety)\n\n\ndef complexity_weighted_accuracy(a, b, c):\n    return _w_acc(a, b, c, lambda s: count_color_variety(s) + count_shape_variety(s))\n\n\n# -------------------------------------------------------------------------\n# sequence \u2192 heterogeneous graph\ndef seq_to_graph(seq, label) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    colors = [t[1] if len(t) > 1 else \"_\" for t in toks]\n    node_feats = torch.tensor([token2idx[t] for t in toks], dtype=torch.long)\n    src, dst, etype = [], [], []\n    # relation 0: order\n    for i in range(n - 1):\n        src.extend([i, i + 1])\n        dst.extend([i + 1, i])\n        etype.extend([0, 0])\n    # relation 1: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n                etype.extend([1, 1])\n    # relation 2: same color\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colors[i] == colors[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n                etype.extend([2, 2])\n    if not src:\n        src, dst, etype = [0], [0], [0]  # self-loop fallback\n    return Data(\n        x=node_feats,\n        edge_index=torch.tensor([src, dst], dtype=torch.long),\n        edge_type=torch.tensor(etype, dtype=torch.long),\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\ntrain_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in train_rows]\nval_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dev_rows]\ntest_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in test_rows]\n\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n\n\n# -------------------------------------------------------------------------\n# Shallow 1-hop RGCN model\nclass Shallow_RGCN(nn.Module):\n    def __init__(self, vocab_size, embed_dim=64, hidden_dim=64, num_rel=3, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.conv1 = RGCNConv(embed_dim, hidden_dim, num_relations=num_rel)\n        self.lin = nn.Linear(hidden_dim, num_cls)\n\n    def forward(self, x, edge_index, edge_type, batch):\n        x = self.embed(x)\n        x = torch.relu(self.conv1(x, edge_index, edge_type))\n        g_emb = global_mean_pool(x, batch)\n        return self.lin(g_emb)\n\n\n# -------------------------------------------------------------------------\n# training utilities\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train_flag = optimizer is not None\n    model.train() if train_flag else model.eval()\n    tot_loss, seqs, y_t, y_p = 0.0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n        loss = criterion(out, batch.y.squeeze())\n        if train_flag:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        pred = out.argmax(-1).cpu().tolist()\n        y_p.extend(pred)\n        y_t.extend(batch.y.squeeze().cpu().tolist())\n        seqs.extend(batch.seq)\n    N = len(loader.dataset)\n    return (\n        tot_loss / N,\n        color_weighted_accuracy(seqs, y_t, y_p),\n        shape_weighted_accuracy(seqs, y_t, y_p),\n        complexity_weighted_accuracy(seqs, y_t, y_p),\n        y_p,\n        y_t,\n        seqs,\n    )\n\n\n# -------------------------------------------------------------------------\n# experiment tracking dict\nexperiment_data = {\n    \"Shallow_GNN_1hop\": {\n        dataset_name: {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"test_metrics\": {},\n        }\n    }\n}\n\n# -------------------------------------------------------------------------\n# training loop\nmax_epochs = 40\npatience = 7\nmodel = Shallow_RGCN(len(token2idx), num_cls=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_val = float(\"inf\")\nbest_state = None\nwait = 0\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_cwa, tr_swa, tr_cpx, _, _, _ = run_epoch(\n        model, train_loader, criterion, optimizer\n    )\n    vl_loss, vl_cwa, vl_swa, vl_cpx, _, _, _ = run_epoch(model, val_loader, criterion)\n    ed = experiment_data[\"Shallow_GNN_1hop\"][dataset_name]\n    ed[\"losses\"][\"train\"].append(tr_loss)\n    ed[\"losses\"][\"val\"].append(vl_loss)\n    ed[\"metrics\"][\"train\"][\"CWA\"].append(tr_cwa)\n    ed[\"metrics\"][\"train\"][\"SWA\"].append(tr_swa)\n    ed[\"metrics\"][\"train\"][\"CmpWA\"].append(tr_cpx)\n    ed[\"metrics\"][\"val\"][\"CWA\"].append(vl_cwa)\n    ed[\"metrics\"][\"val\"][\"SWA\"].append(vl_swa)\n    ed[\"metrics\"][\"val\"][\"CmpWA\"].append(vl_cpx)\n    ed[\"epochs\"].append(epoch)\n    print(\n        f\"Epoch {epoch:02d}  train_loss={tr_loss:.4f}  val_loss={vl_loss:.4f}  val_CmpWA={vl_cpx:.4f}\"\n    )\n    if vl_loss < best_val - 1e-4:\n        best_val = vl_loss\n        best_state = copy.deepcopy(model.state_dict())\n        wait = 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping.\")\n            break\n\n# -------------------------------------------------------------------------\n# evaluation on test\nif best_state is not None:\n    model.load_state_dict(best_state)\nts_loss, ts_cwa, ts_swa, ts_cpx, ts_pred, ts_true, _ = run_epoch(\n    model, test_loader, criterion\n)\nprint(\n    f\"TEST  loss={ts_loss:.4f}  CWA={ts_cwa:.4f}  SWA={ts_swa:.4f}  CmpWA={ts_cpx:.4f}\"\n)\n\ned = experiment_data[\"Shallow_GNN_1hop\"][dataset_name]\ned[\"predictions\"] = ts_pred\ned[\"ground_truth\"] = ts_true\ned[\"test_metrics\"] = {\"loss\": ts_loss, \"CWA\": ts_cwa, \"SWA\": ts_swa, \"CmpWA\": ts_cpx}\n\n# -------------------------------------------------------------------------\n# save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "#!/usr/bin/env python\nimport os, pathlib, random, time, copy, numpy as np, torch\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport torch.nn as nn\n\n# -------------------------------------------------------------------------\n# basic setup -------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------------------------------------------------------------------\n# load SPR or synthetic ---------------------------------------------------\ndef try_load_real_dataset() -> Tuple[List[dict], List[dict], List[dict]]:\n    try:\n        import SPR\n\n        DATA_PATH = pathlib.Path(os.environ.get(\"SPR_DATA_PATH\", \"./SPR_BENCH\"))\n        dset = SPR.load_spr_bench(DATA_PATH)\n        return dset[\"train\"], dset[\"dev\"], dset[\"test\"]\n    except Exception as e:\n        raise IOError from e\n\n\ndef build_synthetic_dataset(n_train=600, n_val=150, n_test=150):\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        L = random.randint(4, 10)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    def mk(n):\n        return [\n            {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n            for i in range(n)\n        ]\n\n    return mk(n_train), mk(n_val), mk(n_test)\n\n\ntry:\n    train_rows, dev_rows, test_rows = try_load_real_dataset()\n    dataset_name = \"SPR_BENCH\"\n    print(\"Loaded real SPR_BENCH.\")\nexcept IOError:\n    print(\"Using synthetic data (real dataset not found).\")\n    train_rows, dev_rows, test_rows = build_synthetic_dataset()\n    dataset_name = \"synthetic\"\n\n# -------------------------------------------------------------------------\n# vocab & label maps ------------------------------------------------------\ntoken2idx = {\"<PAD>\": 0}\nfor split in train_rows + dev_rows + test_rows:\n    for tok in split[\"sequence\"].split():\n        if tok not in token2idx:\n            token2idx[tok] = len(token2idx)\n\nlabel2idx = {}\nfor r in train_rows + dev_rows + test_rows:\n    if r[\"label\"] not in label2idx:\n        label2idx[r[\"label\"]] = len(label2idx)\n\nnum_classes = len(label2idx)\nprint(f\"Vocab={len(token2idx)}, Labels={num_classes}\")\n\n\n# -------------------------------------------------------------------------\n# metrics -----------------------------------------------------------------\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split()})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split()})\n\n\ndef weighted_acc(seqs, y_true, y_pred, weight_fn):\n    w = [weight_fn(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(seqs, y_true, y_pred, count_color_variety)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(seqs, y_true, y_pred, count_shape_variety)\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(\n        seqs, y_true, y_pred, lambda s: count_color_variety(s) + count_shape_variety(s)\n    )\n\n\n# -------------------------------------------------------------------------\n# graph builders ----------------------------------------------------------\ndef seq_to_graph(seq: str, label: str, directed: bool = True) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    colors = [t[1] for t in toks]\n    node_feats = torch.tensor([token2idx[t] for t in toks], dtype=torch.long)\n    src, dst, etype = [], [], []\n\n    def add_edge(i, j, rel):\n        src.append(i)\n        dst.append(j)\n        etype.append(rel)\n\n    # relation 0: neighbour in sequence\n    for i in range(n - 1):\n        add_edge(i, i + 1, 0)\n        if directed:\n            add_edge(i + 1, i, 0)\n\n    # relation 1: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                add_edge(i, j, 1)\n                if directed:\n                    add_edge(j, i, 1)\n\n    # relation 2: same color\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colors[i] == colors[j]:\n                add_edge(i, j, 2)\n                if directed:\n                    add_edge(j, i, 2)\n\n    if not src:  # rare fallback\n        add_edge(0, 0, 0)\n\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    return Data(\n        x=node_feats,\n        edge_index=edge_index,\n        edge_type=edge_type,\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\n# -------------------------------------------------------------------------\n# dataloaders builder -----------------------------------------------------\ndef build_dataloaders(directed: bool, batch_size: int = 128):\n    train_graphs = [\n        seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in train_rows\n    ]\n    val_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in dev_rows]\n    test_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in test_rows]\n    return (\n        DataLoader(train_graphs, batch_size=batch_size, shuffle=True),\n        DataLoader(val_graphs, batch_size=batch_size),\n        DataLoader(test_graphs, batch_size=batch_size),\n    )\n\n\n# -------------------------------------------------------------------------\n# model -------------------------------------------------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self, vocab, emb=64, hid=64, rels=3, classes=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab, emb, padding_idx=0)\n        self.conv1 = RGCNConv(emb, hid, num_relations=rels)\n        self.conv2 = RGCNConv(hid, hid, num_relations=rels)\n        self.lin = nn.Linear(hid, classes)\n\n    def forward(self, x, edge_index, edge_type, batch):\n        h = torch.relu(self.conv1(self.embed(x), edge_index, edge_type))\n        h = torch.relu(self.conv2(h, edge_index, edge_type))\n        g = global_mean_pool(h, batch)\n        return self.lin(g)\n\n\n# -------------------------------------------------------------------------\n# training utilities ------------------------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train_mode = optimizer is not None\n    model.train() if train_mode else model.eval()\n    tot_loss, seqs, yt, yp = 0.0, [], [], []\n    with torch.set_grad_enabled(train_mode):\n        for batch in loader:\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n            loss = criterion(out, batch.y.squeeze())\n            if train_mode:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            tot_loss += loss.item() * batch.num_graphs\n            preds = out.argmax(-1).cpu().tolist()\n            yp.extend(preds)\n            yt.extend(batch.y.squeeze().cpu().tolist())\n            seqs.extend(batch.seq)\n    n = len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, yt, yp)\n    swa = shape_weighted_accuracy(seqs, yt, yp)\n    cpx = complexity_weighted_accuracy(seqs, yt, yp)\n    return tot_loss / n, cwa, swa, cpx, yp, yt, seqs\n\n\n# -------------------------------------------------------------------------\n# experiment dict ---------------------------------------------------------\nexperiment_data = {\n    \"edge_direction\": {\n        \"directed\": {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"undirected\": {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    }\n}\n\n\n# -------------------------------------------------------------------------\n# training loop per variant ----------------------------------------------\ndef train_variant(name: str, directed: bool):\n    print(f\"\\n--- Training variant: {name} (directed={directed}) ---\")\n    train_loader, val_loader, test_loader = build_dataloaders(directed)\n    model = SPR_RGCN(len(token2idx), classes=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    best_val, best_state, wait, patience = float(\"inf\"), None, 0, 7\n    for epoch in range(1, 41):\n        tr_loss, tr_cwa, tr_swa, tr_cpx, *_ = run_epoch(\n            model, train_loader, criterion, opt\n        )\n        vl_loss, vl_cwa, vl_swa, vl_cpx, *_ = run_epoch(model, val_loader, criterion)\n\n        exp_branch = experiment_data[\"edge_direction\"][name]\n        exp_branch[\"losses\"][\"train\"].append(tr_loss)\n        exp_branch[\"losses\"][\"val\"].append(vl_loss)\n        for k, v in zip([\"CWA\", \"SWA\", \"CmpWA\"], [tr_cwa, tr_swa, tr_cpx]):\n            exp_branch[\"metrics\"][\"train\"][k].append(v)\n        for k, v in zip([\"CWA\", \"SWA\", \"CmpWA\"], [vl_cwa, vl_swa, vl_cpx]):\n            exp_branch[\"metrics\"][\"val\"][k].append(v)\n\n        print(\n            f\"Epoch {epoch:02d} | tr_loss {tr_loss:.3f} vl_loss {vl_loss:.3f} vl_CmpWA {vl_cpx:.3f}\"\n        )\n        if vl_loss < best_val - 1e-4:\n            best_val, best_state, wait = vl_loss, copy.deepcopy(model.state_dict()), 0\n        else:\n            wait += 1\n            if wait >= patience:\n                print(\"Early stopping.\")\n                break\n    # load best, evaluate test\n    if best_state is not None:\n        model.load_state_dict(best_state)\n    ts_loss, ts_cwa, ts_swa, ts_cpx, ts_pred, ts_true, _ = run_epoch(\n        model, test_loader, criterion\n    )\n    exp_branch[\"predictions\"] = ts_pred\n    exp_branch[\"ground_truth\"] = ts_true\n    exp_branch[\"test_metrics\"] = {\n        \"loss\": ts_loss,\n        \"CWA\": ts_cwa,\n        \"SWA\": ts_swa,\n        \"CmpWA\": ts_cpx,\n    }\n    print(\n        f\"TEST ({name}): loss={ts_loss:.3f} CWA={ts_cwa:.3f} SWA={ts_swa:.3f} CmpWA={ts_cpx:.3f}\"\n    )\n    del model\n    torch.cuda.empty_cache()\n\n\n# -------------------------------------------------------------------------\n# run both variants -------------------------------------------------------\ntrain_variant(\"directed\", directed=True)\ntrain_variant(\"undirected\", directed=False)\n\n# -------------------------------------------------------------------------\n# save experiment data ----------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved all metrics to working/experiment_data.npy\")\n", "import os, pathlib, random, copy, numpy as np, torch, time\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# -------------------------------------------------------------------------\n# working dir & device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n# -------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------\n# try to load official SPR dataset, otherwise build synthetic -------------\ndef try_load_real_dataset() -> Tuple[List[dict], List[dict], List[dict]]:\n    try:\n        import SPR\n\n        DATA_PATH = pathlib.Path(os.environ.get(\"SPR_DATA_PATH\", \"./SPR_BENCH\"))\n        dset = SPR.load_spr_bench(DATA_PATH)\n        return dset[\"train\"], dset[\"dev\"], dset[\"test\"]\n    except Exception:\n        raise IOError\n\n\ndef build_synthetic_dataset(n_train=600, n_val=150, n_test=150):\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        L = random.randint(4, 10)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    def make_split(n):\n        return [\n            {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n            for i in range(n)\n        ]\n\n    def tag(lst):\n        for i, r in enumerate(lst):\n            r[\"id\"] = i\n        return lst\n\n    return tag(make_split(n_train)), tag(make_split(n_val)), tag(make_split(n_test))\n\n\ntry:\n    train_rows, dev_rows, test_rows = try_load_real_dataset()\n    dataset_name = \"SPR-BENCH\"\n    print(\"Loaded SPR-BENCH.\")\nexcept IOError:\n    print(\"Using synthetic data.\")\n    train_rows, dev_rows, test_rows = build_synthetic_dataset()\n    dataset_name = \"synthetic\"\n# -------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------\n# vocab & label maps\ndef all_tokens(rows):\n    for r in rows:\n        for tok in r[\"sequence\"].split():\n            yield tok\n\n\ntoken2idx = {\"<PAD>\": 0}\nfor tok in all_tokens(train_rows + dev_rows + test_rows):\n    token2idx.setdefault(tok, len(token2idx))\nlabel2idx = {}\nfor r in train_rows + dev_rows + test_rows:\n    label2idx.setdefault(r[\"label\"], len(label2idx))\nnum_classes = len(label2idx)\nvocab_size = len(token2idx)\nprint(f\"Vocab={vocab_size}, Labels={num_classes}\")\n# -------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------\n# metrics\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split() if len(t) > 1})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split() if t})\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\n# -------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------\n# graph construction\ndef seq_to_graph(seq: str, label: str) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    colors = [t[1] if len(t) > 1 else \"_\" for t in toks]\n    node_feats = torch.tensor([token2idx[t] for t in toks], dtype=torch.long)\n    src, dst, etype = [], [], []\n    # relation 0: order\n    for i in range(n - 1):\n        src.extend([i, i + 1])\n        dst.extend([i + 1, i])\n        etype.extend([0, 0])\n    # relation 1: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n                etype.extend([1, 1])\n    # relation 2: same color\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colors[i] == colors[j]:\n                src.extend([i, j])\n                dst.extend([j, i])\n                etype.extend([2, 2])\n    if len(src) == 0:\n        src = [0]\n        dst = [0]\n        etype = [0]\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    return Data(\n        x=node_feats,\n        edge_index=edge_index,\n        edge_type=edge_type,\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\ntrain_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in train_rows]\nval_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dev_rows]\ntest_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in test_rows]\n\nbatch_size = 128\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_graphs, batch_size=batch_size)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size)\n# -------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------\n# Model with frozen one-hot node features\nclass SPR_RGCN_OneHot(nn.Module):\n    def __init__(self, vocab, hidden_dim=64, num_rel=3, num_cls=2):\n        super().__init__()\n        # first conv consumes one-hot directly\n        self.conv1 = RGCNConv(vocab, hidden_dim, num_relations=num_rel)\n        self.conv2 = RGCNConv(hidden_dim, hidden_dim, num_relations=num_rel)\n        self.lin = nn.Linear(hidden_dim, num_cls)\n        self.vocab = vocab  # saved for one_hot\n\n    def forward(self, x, edge_index, edge_type, batch):\n        # convert indices to one-hot (non-learnable)\n        x = F.one_hot(x, num_classes=self.vocab).float()\n        x = torch.relu(self.conv1(x, edge_index, edge_type))\n        x = torch.relu(self.conv2(x, edge_index, edge_type))\n        g_emb = global_mean_pool(x, batch)\n        return self.lin(g_emb)\n\n\n# -------------------------------------------------------------------------\n\n\n# -------------------------------------------------------------------------\n# training utilities\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train = optimizer is not None\n    model.train() if train else model.eval()\n    tot_loss, seqs, y_true, y_pred = 0.0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n        loss = criterion(out, batch.y.squeeze())\n        if train:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        y_pred.extend(preds)\n        y_true.extend(batch.y.squeeze().cpu().tolist())\n        seqs.extend(batch.seq)\n    avg_loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, y_true, y_pred)\n    swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n    cpx = complexity_weighted_accuracy(seqs, y_true, y_pred)\n    return avg_loss, cwa, swa, cpx, y_pred, y_true, seqs\n\n\n# -------------------------------------------------------------------------\n\n# -------------------------------------------------------------------------\n# experiment tracking dict\nexperiment_data = {\n    \"onehot_frozen\": {\n        dataset_name: {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"epochs\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\nstore = experiment_data[\"onehot_frozen\"][dataset_name]\n# -------------------------------------------------------------------------\n\n# -------------------------------------------------------------------------\n# train loop\nmax_epochs, patience = 40, 7\nmodel = SPR_RGCN_OneHot(vocab_size, num_cls=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_val = float(\"inf\")\nbest_state = None\nwait = 0\nfor epoch in range(1, max_epochs + 1):\n    tr_loss, tr_cwa, tr_swa, tr_cpx, _, _, _ = run_epoch(\n        model, train_loader, criterion, optimizer\n    )\n    val_loss, val_cwa, val_swa, val_cpx, _, _, _ = run_epoch(\n        model, val_loader, criterion\n    )\n    # log\n    store[\"losses\"][\"train\"].append(tr_loss)\n    store[\"losses\"][\"val\"].append(val_loss)\n    store[\"metrics\"][\"train\"][\"CWA\"].append(tr_cwa)\n    store[\"metrics\"][\"train\"][\"SWA\"].append(tr_swa)\n    store[\"metrics\"][\"train\"][\"CmpWA\"].append(tr_cpx)\n    store[\"metrics\"][\"val\"][\"CWA\"].append(val_cwa)\n    store[\"metrics\"][\"val\"][\"SWA\"].append(val_swa)\n    store[\"metrics\"][\"val\"][\"CmpWA\"].append(val_cpx)\n    store[\"epochs\"].append(epoch)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={tr_loss:.4f} val_loss={val_loss:.4f} val_CmpWA={val_cpx:.4f}\"\n    )\n    # early stopping\n    if val_loss < best_val - 1e-4:\n        best_val = val_loss\n        best_state = copy.deepcopy(model.state_dict())\n        wait = 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping.\")\n            break\n# -------------------------------------------------------------------------\n\n# -------------------------------------------------------------------------\n# evaluate on test set\nif best_state is not None:\n    model.load_state_dict(best_state)\ntest_loss, test_cwa, test_swa, test_cpx, test_pred, test_true, _ = run_epoch(\n    model, test_loader, criterion\n)\nprint(\n    f\"TEST: loss={test_loss:.4f} CWA={test_cwa:.4f} SWA={test_swa:.4f} CmpWA={test_cpx:.4f}\"\n)\n\nstore[\"predictions\"] = test_pred\nstore[\"ground_truth\"] = test_true\nstore[\"test_metrics\"] = {\n    \"loss\": test_loss,\n    \"CWA\": test_cwa,\n    \"SWA\": test_swa,\n    \"CmpWA\": test_cpx,\n}\n# -------------------------------------------------------------------------\n\n# -------------------------------------------------------------------------\n# save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to working/experiment_data.npy\")\n", "# Multi-Synthetic Dataset Generalisation Ablation \u2013 single-file script\nimport os, random, copy, numpy as np, torch, pathlib\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport torch.nn as nn\n\n# -------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n\n# -------------------------------------------------------------------------\n# Synthetic corpus builder ------------------------------------------------\ndef build_synthetic_dataset(n_items: int = 900) -> List[dict]:\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        L = random.randint(4, 10)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    rows = [\n        {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n        for i in range(n_items)\n    ]\n    return rows\n\n\n# Fix seeds and create datasets A,B,C ------------------------------------\ndataset_A = build_synthetic_dataset()\nrandom.seed(1)\ndataset_B = build_synthetic_dataset()\nrandom.seed(2)\ndataset_C = build_synthetic_dataset()\n\n\n# -------------------------------------------------------------------------\n# Vocabulary and label mapping over union of all three datasets ----------\ndef all_tokens(rows):\n    for r in rows:\n        for tok in r[\"sequence\"].split():\n            yield tok\n\n\ntoken2idx = {\"<PAD>\": 0}\nfor tok in all_tokens(dataset_A + dataset_B + dataset_C):\n    token2idx.setdefault(tok, len(token2idx))\nlabel2idx = {}\nfor r in dataset_A + dataset_B + dataset_C:\n    label2idx.setdefault(r[\"label\"], len(label2idx))\nnum_classes = len(label2idx)\nprint(f\"Vocab={len(token2idx)}, Labels={num_classes}\")\n\n\n# -------------------------------------------------------------------------\n# Graph construction ------------------------------------------------------\ndef seq_to_graph(seq: str, label: str) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    colors = [t[1] for t in toks]\n    node_feats = torch.tensor([token2idx[t] for t in toks], dtype=torch.long)\n    src, dst, etype = [], [], []\n    # relation 0 \u2013 order\n    for i in range(n - 1):\n        src += [i, i + 1]\n        dst += [i + 1, i]\n        etype += [0, 0]\n    # relation 1 \u2013 same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                src += [i, j]\n                dst += [j, i]\n                etype += [1, 1]\n    # relation 2 \u2013 same colour\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colors[i] == colors[j]:\n                src += [i, j]\n                dst += [j, i]\n                etype += [2, 2]\n    if not src:\n        src, dst, etype = [0], [0], [0]\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    return Data(\n        x=node_feats,\n        edge_index=edge_index,\n        edge_type=torch.tensor(etype, dtype=torch.long),\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\n# -------------------------------------------------------------------------\n# Weighted-accuracy helpers ----------------------------------------------\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split()})\n\n\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split()})\n\n\ndef weighted_acc(seqs, y_true, y_pred, w_fn):\n    w = [w_fn(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\n# -------------------------------------------------------------------------\n# Data loaders ------------------------------------------------------------\ndef rows_to_loader(rows, batch_size=128, shuffle=False):\n    graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in rows]\n    return DataLoader(graphs, batch_size=batch_size, shuffle=shuffle)\n\n\n# -------------------------------------------------------------------------\n# R-GCN Model -------------------------------------------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self, vocab, embed=64, hid=64, rel=3, cls=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed, padding_idx=0)\n        self.c1 = RGCNConv(embed, hid, num_relations=rel)\n        self.c2 = RGCNConv(hid, hid, num_relations=rel)\n        self.lin = nn.Linear(hid, cls)\n\n    def forward(self, x, edge_index, edge_type, batch):\n        x = self.emb(x)\n        x = torch.relu(self.c1(x, edge_index, edge_type))\n        x = torch.relu(self.c2(x, edge_index, edge_type))\n        return self.lin(global_mean_pool(x, batch))\n\n\n# -------------------------------------------------------------------------\n# One epoch ---------------------------------------------------------------\ndef run_epoch(model, loader, criterion, opt=None):\n    train = opt is not None\n    model.train() if train else model.eval()\n    total, seqs, y_true, y_pred = 0.0, [], [], []\n    for batch in loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n        loss = criterion(out, batch.y.squeeze())\n        if train:\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n        total += loss.item() * batch.num_graphs\n        preds = out.argmax(-1).cpu().tolist()\n        y_pred += preds\n        y_true += batch.y.squeeze().cpu().tolist()\n        seqs += batch.seq\n    avg = total / len(loader.dataset)\n    cwa = weighted_acc(seqs, y_true, y_pred, count_color_variety)\n    swa = weighted_acc(seqs, y_true, y_pred, count_shape_variety)\n    cmp = weighted_acc(\n        seqs, y_true, y_pred, lambda s: count_color_variety(s) + count_shape_variety(s)\n    )\n    return avg, cwa, swa, cmp, y_pred, y_true, seqs\n\n\n# -------------------------------------------------------------------------\n# Training routine --------------------------------------------------------\ndef train_model(train_rows, val_rows, test_rows, max_epochs=40, patience=7):\n    loaders = {\n        \"train\": rows_to_loader(train_rows, shuffle=True),\n        \"val\": rows_to_loader(val_rows),\n        \"test\": rows_to_loader(test_rows),\n    }\n    model = SPR_RGCN(len(token2idx), cls=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    best, wait, best_state = float(\"inf\"), 0, None\n    logs = {\"losses\": {\"train\": [], \"val\": []}, \"metrics\": {\"train\": [], \"val\": []}}\n    for epoch in range(1, max_epochs + 1):\n        tr = run_epoch(model, loaders[\"train\"], criterion, opt)\n        vl = run_epoch(model, loaders[\"val\"], criterion)\n        logs[\"losses\"][\"train\"].append(tr[0])\n        logs[\"losses\"][\"val\"].append(vl[0])\n        logs[\"metrics\"][\"train\"].append(tr[3])\n        logs[\"metrics\"][\"val\"].append(vl[3])\n        # early stop\n        if vl[0] < best - 1e-4:\n            best, best_state, wait = vl[0], copy.deepcopy(model.state_dict()), 0\n        else:\n            wait += 1\n        if wait >= patience:\n            break\n    model.load_state_dict(best_state)\n    ts = run_epoch(model, loaders[\"test\"], criterion)\n    return logs, ts\n\n\n# -------------------------------------------------------------------------\n# Run Ablation experiments ------------------------------------------------\nexperiment_data = {\"MultiSyntheticGeneralization\": {}}\n\n# 1) Train A / Val B / Test C --------------------------------------------\nprint(\"\\n=== Experiment: Train A | Val B | Test C ===\")\nlogs1, test1 = train_model(dataset_A, dataset_B, dataset_C)\nexperiment_data[\"MultiSyntheticGeneralization\"][\"A_train_B_val_C_test\"] = {\n    \"losses\": logs1[\"losses\"],\n    \"CmpWA_train\": logs1[\"metrics\"][\"train\"],\n    \"CmpWA_val\": logs1[\"metrics\"][\"val\"],\n    \"predictions\": test1[4],\n    \"ground_truth\": test1[5],\n    \"test_metrics\": {\n        \"loss\": test1[0],\n        \"CWA\": test1[1],\n        \"SWA\": test1[2],\n        \"CmpWA\": test1[3],\n    },\n}\n\n# 2) Train (A+B) / Val B / Test C ----------------------------------------\nprint(\"\\n=== Experiment: Train A+B | Val B | Test C ===\")\nlogs2, test2 = train_model(dataset_A + dataset_B, dataset_B, dataset_C)\nexperiment_data[\"MultiSyntheticGeneralization\"][\"AB_train_C_test\"] = {\n    \"losses\": logs2[\"losses\"],\n    \"CmpWA_train\": logs2[\"metrics\"][\"train\"],\n    \"CmpWA_val\": logs2[\"metrics\"][\"val\"],\n    \"predictions\": test2[4],\n    \"ground_truth\": test2[5],\n    \"test_metrics\": {\n        \"loss\": test2[0],\n        \"CWA\": test2[1],\n        \"SWA\": test2[2],\n        \"CmpWA\": test2[3],\n    },\n}\n\n# -------------------------------------------------------------------------\n# Save --------------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved results to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n#!/usr/bin/env python\nimport os, pathlib, random, time, copy, numpy as np, torch\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport torch.nn as nn\n\n# -------------------------------------------------------------------------\n# basic setup -------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------------------------------------------------------------------\n# load SPR or synthetic ---------------------------------------------------\ndef try_load_real_dataset() -> Tuple[List[dict], List[dict], List[dict]]:\n    try:\n        import SPR\n\n        DATA_PATH = pathlib.Path(os.environ.get(\"SPR_DATA_PATH\", \"./SPR_BENCH\"))\n        dset = SPR.load_spr_bench(DATA_PATH)\n        return dset[\"train\"], dset[\"dev\"], dset[\"test\"]\n    except Exception as e:\n        raise IOError from e\n\n\ndef build_synthetic_dataset(n_train=600, n_val=150, n_test=150):\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        L = random.randint(4, 10)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    def mk(n):\n        return [\n            {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n            for i in range(n)\n        ]\n\n    return mk(n_train), mk(n_val), mk(n_test)\n\n\ntry:\n    train_rows, dev_rows, test_rows = try_load_real_dataset()\n    dataset_name = \"SPR_BENCH\"\n    print(\"Loaded real SPR_BENCH.\")\nexcept IOError:\n    print(\"Using synthetic data (real dataset not found).\")\n    train_rows, dev_rows, test_rows = build_synthetic_dataset()\n    dataset_name = \"synthetic\"\n\n# -------------------------------------------------------------------------\n# vocab & label maps ------------------------------------------------------\ntoken2idx = {\"<PAD>\": 0}\nfor split in train_rows + dev_rows + test_rows:\n    for tok in split[\"sequence\"].split():\n        if tok not in token2idx:\n            token2idx[tok] = len(token2idx)\n\nlabel2idx = {}\nfor r in train_rows + dev_rows + test_rows:\n    if r[\"label\"] not in label2idx:\n        label2idx[r[\"label\"]] = len(label2idx)\n\nnum_classes = len(label2idx)\nprint(f\"Vocab={len(token2idx)}, Labels={num_classes}\")\n\n\n# -------------------------------------------------------------------------\n# metrics -----------------------------------------------------------------\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split()})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split()})\n\n\ndef weighted_acc(seqs, y_true, y_pred, weight_fn):\n    w = [weight_fn(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(seqs, y_true, y_pred, count_color_variety)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(seqs, y_true, y_pred, count_shape_variety)\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(\n        seqs, y_true, y_pred, lambda s: count_color_variety(s) + count_shape_variety(s)\n    )\n\n\n# -------------------------------------------------------------------------\n# graph builders ----------------------------------------------------------\ndef seq_to_graph(seq: str, label: str, directed: bool = True) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    colors = [t[1] for t in toks]\n    node_feats = torch.tensor([token2idx[t] for t in toks], dtype=torch.long)\n    src, dst, etype = [], [], []\n\n    def add_edge(i, j, rel):\n        src.append(i)\n        dst.append(j)\n        etype.append(rel)\n\n    # relation 0: neighbour in sequence\n    for i in range(n - 1):\n        add_edge(i, i + 1, 0)\n        if directed:\n            add_edge(i + 1, i, 0)\n\n    # relation 1: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                add_edge(i, j, 1)\n                if directed:\n                    add_edge(j, i, 1)\n\n    # relation 2: same color\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colors[i] == colors[j]:\n                add_edge(i, j, 2)\n                if directed:\n                    add_edge(j, i, 2)\n\n    if not src:  # rare fallback\n        add_edge(0, 0, 0)\n\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    return Data(\n        x=node_feats,\n        edge_index=edge_index,\n        edge_type=edge_type,\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\n# -------------------------------------------------------------------------\n# dataloaders builder -----------------------------------------------------\ndef build_dataloaders(directed: bool, batch_size: int = 128):\n    train_graphs = [\n        seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in train_rows\n    ]\n    val_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in dev_rows]\n    test_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in test_rows]\n    return (\n        DataLoader(train_graphs, batch_size=batch_size, shuffle=True),\n        DataLoader(val_graphs, batch_size=batch_size),\n        DataLoader(test_graphs, batch_size=batch_size),\n    )\n\n\n# -------------------------------------------------------------------------\n# model -------------------------------------------------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self, vocab, emb=64, hid=64, rels=3, classes=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab, emb, padding_idx=0)\n        self.conv1 = RGCNConv(emb, hid, num_relations=rels)\n        self.conv2 = RGCNConv(hid, hid, num_relations=rels)\n        self.lin = nn.Linear(hid, classes)\n\n    def forward(self, x, edge_index, edge_type, batch):\n        h = torch.relu(self.conv1(self.embed(x), edge_index, edge_type))\n        h = torch.relu(self.conv2(h, edge_index, edge_type))\n        g = global_mean_pool(h, batch)\n        return self.lin(g)\n\n\n# -------------------------------------------------------------------------\n# training utilities ------------------------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train_mode = optimizer is not None\n    model.train() if train_mode else model.eval()\n    tot_loss, seqs, yt, yp = 0.0, [], [], []\n    with torch.set_grad_enabled(train_mode):\n        for batch in loader:\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n            loss = criterion(out, batch.y.squeeze())\n            if train_mode:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            tot_loss += loss.item() * batch.num_graphs\n            preds = out.argmax(-1).cpu().tolist()\n            yp.extend(preds)\n            yt.extend(batch.y.squeeze().cpu().tolist())\n            seqs.extend(batch.seq)\n    n = len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, yt, yp)\n    swa = shape_weighted_accuracy(seqs, yt, yp)\n    cpx = complexity_weighted_accuracy(seqs, yt, yp)\n    return tot_loss / n, cwa, swa, cpx, yp, yt, seqs\n\n\n# -------------------------------------------------------------------------\n# experiment dict ---------------------------------------------------------\nexperiment_data = {\n    \"edge_direction\": {\n        \"directed\": {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"undirected\": {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    }\n}\n\n\n# -------------------------------------------------------------------------\n# training loop per variant ----------------------------------------------\ndef train_variant(name: str, directed: bool):\n    print(f\"\\n--- Training variant: {name} (directed={directed}) ---\")\n    train_loader, val_loader, test_loader = build_dataloaders(directed)\n    model = SPR_RGCN(len(token2idx), classes=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    best_val, best_state, wait, patience = float(\"inf\"), None, 0, 7\n    for epoch in range(1, 41):\n        tr_loss, tr_cwa, tr_swa, tr_cpx, *_ = run_epoch(\n            model, train_loader, criterion, opt\n        )\n        vl_loss, vl_cwa, vl_swa, vl_cpx, *_ = run_epoch(model, val_loader, criterion)\n\n        exp_branch = experiment_data[\"edge_direction\"][name]\n        exp_branch[\"losses\"][\"train\"].append(tr_loss)\n        exp_branch[\"losses\"][\"val\"].append(vl_loss)\n        for k, v in zip([\"CWA\", \"SWA\", \"CmpWA\"], [tr_cwa, tr_swa, tr_cpx]):\n            exp_branch[\"metrics\"][\"train\"][k].append(v)\n        for k, v in zip([\"CWA\", \"SWA\", \"CmpWA\"], [vl_cwa, vl_swa, vl_cpx]):\n            exp_branch[\"metrics\"][\"val\"][k].append(v)\n\n        print(\n            f\"Epoch {epoch:02d} | tr_loss {tr_loss:.3f} vl_loss {vl_loss:.3f} vl_CmpWA {vl_cpx:.3f}\"\n        )\n        if vl_loss < best_val - 1e-4:\n            best_val, best_state, wait = vl_loss, copy.deepcopy(model.state_dict()), 0\n        else:\n            wait += 1\n            if wait >= patience:\n                print(\"Early stopping.\")\n                break\n    # load best, evaluate test\n    if best_state is not None:\n        model.load_state_dict(best_state)\n    ts_loss, ts_cwa, ts_swa, ts_cpx, ts_pred, ts_true, _ = run_epoch(\n        model, test_loader, criterion\n    )\n    exp_branch[\"predictions\"] = ts_pred\n    exp_branch[\"ground_truth\"] = ts_true\n    exp_branch[\"test_metrics\"] = {\n        \"loss\": ts_loss,\n        \"CWA\": ts_cwa,\n        \"SWA\": ts_swa,\n        \"CmpWA\": ts_cpx,\n    }\n    print(\n        f\"TEST ({name}): loss={ts_loss:.3f} CWA={ts_cwa:.3f} SWA={ts_swa:.3f} CmpWA={ts_cpx:.3f}\"\n    )\n    del model\n    torch.cuda.empty_cache()\n\n\n# -------------------------------------------------------------------------\n# run both variants -------------------------------------------------------\ntrain_variant(\"directed\", directed=True)\ntrain_variant(\"undirected\", directed=False)\n\n# -------------------------------------------------------------------------\n# save experiment data ----------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved all metrics to working/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n#!/usr/bin/env python\nimport os, pathlib, random, time, copy, numpy as np, torch\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport torch.nn as nn\n\n# -------------------------------------------------------------------------\n# basic setup -------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------------------------------------------------------------------\n# load SPR or synthetic ---------------------------------------------------\ndef try_load_real_dataset() -> Tuple[List[dict], List[dict], List[dict]]:\n    try:\n        import SPR\n\n        DATA_PATH = pathlib.Path(os.environ.get(\"SPR_DATA_PATH\", \"./SPR_BENCH\"))\n        dset = SPR.load_spr_bench(DATA_PATH)\n        return dset[\"train\"], dset[\"dev\"], dset[\"test\"]\n    except Exception as e:\n        raise IOError from e\n\n\ndef build_synthetic_dataset(n_train=600, n_val=150, n_test=150):\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        L = random.randint(4, 10)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    def mk(n):\n        return [\n            {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n            for i in range(n)\n        ]\n\n    return mk(n_train), mk(n_val), mk(n_test)\n\n\ntry:\n    train_rows, dev_rows, test_rows = try_load_real_dataset()\n    dataset_name = \"SPR_BENCH\"\n    print(\"Loaded real SPR_BENCH.\")\nexcept IOError:\n    print(\"Using synthetic data (real dataset not found).\")\n    train_rows, dev_rows, test_rows = build_synthetic_dataset()\n    dataset_name = \"synthetic\"\n\n# -------------------------------------------------------------------------\n# vocab & label maps ------------------------------------------------------\ntoken2idx = {\"<PAD>\": 0}\nfor split in train_rows + dev_rows + test_rows:\n    for tok in split[\"sequence\"].split():\n        if tok not in token2idx:\n            token2idx[tok] = len(token2idx)\n\nlabel2idx = {}\nfor r in train_rows + dev_rows + test_rows:\n    if r[\"label\"] not in label2idx:\n        label2idx[r[\"label\"]] = len(label2idx)\n\nnum_classes = len(label2idx)\nprint(f\"Vocab={len(token2idx)}, Labels={num_classes}\")\n\n\n# -------------------------------------------------------------------------\n# metrics -----------------------------------------------------------------\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split()})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split()})\n\n\ndef weighted_acc(seqs, y_true, y_pred, weight_fn):\n    w = [weight_fn(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(seqs, y_true, y_pred, count_color_variety)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(seqs, y_true, y_pred, count_shape_variety)\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(\n        seqs, y_true, y_pred, lambda s: count_color_variety(s) + count_shape_variety(s)\n    )\n\n\n# -------------------------------------------------------------------------\n# graph builders ----------------------------------------------------------\ndef seq_to_graph(seq: str, label: str, directed: bool = True) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    colors = [t[1] for t in toks]\n    node_feats = torch.tensor([token2idx[t] for t in toks], dtype=torch.long)\n    src, dst, etype = [], [], []\n\n    def add_edge(i, j, rel):\n        src.append(i)\n        dst.append(j)\n        etype.append(rel)\n\n    # relation 0: neighbour in sequence\n    for i in range(n - 1):\n        add_edge(i, i + 1, 0)\n        if directed:\n            add_edge(i + 1, i, 0)\n\n    # relation 1: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                add_edge(i, j, 1)\n                if directed:\n                    add_edge(j, i, 1)\n\n    # relation 2: same color\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colors[i] == colors[j]:\n                add_edge(i, j, 2)\n                if directed:\n                    add_edge(j, i, 2)\n\n    if not src:  # rare fallback\n        add_edge(0, 0, 0)\n\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    return Data(\n        x=node_feats,\n        edge_index=edge_index,\n        edge_type=edge_type,\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\n# -------------------------------------------------------------------------\n# dataloaders builder -----------------------------------------------------\ndef build_dataloaders(directed: bool, batch_size: int = 128):\n    train_graphs = [\n        seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in train_rows\n    ]\n    val_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in dev_rows]\n    test_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in test_rows]\n    return (\n        DataLoader(train_graphs, batch_size=batch_size, shuffle=True),\n        DataLoader(val_graphs, batch_size=batch_size),\n        DataLoader(test_graphs, batch_size=batch_size),\n    )\n\n\n# -------------------------------------------------------------------------\n# model -------------------------------------------------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self, vocab, emb=64, hid=64, rels=3, classes=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab, emb, padding_idx=0)\n        self.conv1 = RGCNConv(emb, hid, num_relations=rels)\n        self.conv2 = RGCNConv(hid, hid, num_relations=rels)\n        self.lin = nn.Linear(hid, classes)\n\n    def forward(self, x, edge_index, edge_type, batch):\n        h = torch.relu(self.conv1(self.embed(x), edge_index, edge_type))\n        h = torch.relu(self.conv2(h, edge_index, edge_type))\n        g = global_mean_pool(h, batch)\n        return self.lin(g)\n\n\n# -------------------------------------------------------------------------\n# training utilities ------------------------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train_mode = optimizer is not None\n    model.train() if train_mode else model.eval()\n    tot_loss, seqs, yt, yp = 0.0, [], [], []\n    with torch.set_grad_enabled(train_mode):\n        for batch in loader:\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n            loss = criterion(out, batch.y.squeeze())\n            if train_mode:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            tot_loss += loss.item() * batch.num_graphs\n            preds = out.argmax(-1).cpu().tolist()\n            yp.extend(preds)\n            yt.extend(batch.y.squeeze().cpu().tolist())\n            seqs.extend(batch.seq)\n    n = len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, yt, yp)\n    swa = shape_weighted_accuracy(seqs, yt, yp)\n    cpx = complexity_weighted_accuracy(seqs, yt, yp)\n    return tot_loss / n, cwa, swa, cpx, yp, yt, seqs\n\n\n# -------------------------------------------------------------------------\n# experiment dict ---------------------------------------------------------\nexperiment_data = {\n    \"edge_direction\": {\n        \"directed\": {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"undirected\": {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    }\n}\n\n\n# -------------------------------------------------------------------------\n# training loop per variant ----------------------------------------------\ndef train_variant(name: str, directed: bool):\n    print(f\"\\n--- Training variant: {name} (directed={directed}) ---\")\n    train_loader, val_loader, test_loader = build_dataloaders(directed)\n    model = SPR_RGCN(len(token2idx), classes=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    best_val, best_state, wait, patience = float(\"inf\"), None, 0, 7\n    for epoch in range(1, 41):\n        tr_loss, tr_cwa, tr_swa, tr_cpx, *_ = run_epoch(\n            model, train_loader, criterion, opt\n        )\n        vl_loss, vl_cwa, vl_swa, vl_cpx, *_ = run_epoch(model, val_loader, criterion)\n\n        exp_branch = experiment_data[\"edge_direction\"][name]\n        exp_branch[\"losses\"][\"train\"].append(tr_loss)\n        exp_branch[\"losses\"][\"val\"].append(vl_loss)\n        for k, v in zip([\"CWA\", \"SWA\", \"CmpWA\"], [tr_cwa, tr_swa, tr_cpx]):\n            exp_branch[\"metrics\"][\"train\"][k].append(v)\n        for k, v in zip([\"CWA\", \"SWA\", \"CmpWA\"], [vl_cwa, vl_swa, vl_cpx]):\n            exp_branch[\"metrics\"][\"val\"][k].append(v)\n\n        print(\n            f\"Epoch {epoch:02d} | tr_loss {tr_loss:.3f} vl_loss {vl_loss:.3f} vl_CmpWA {vl_cpx:.3f}\"\n        )\n        if vl_loss < best_val - 1e-4:\n            best_val, best_state, wait = vl_loss, copy.deepcopy(model.state_dict()), 0\n        else:\n            wait += 1\n            if wait >= patience:\n                print(\"Early stopping.\")\n                break\n    # load best, evaluate test\n    if best_state is not None:\n        model.load_state_dict(best_state)\n    ts_loss, ts_cwa, ts_swa, ts_cpx, ts_pred, ts_true, _ = run_epoch(\n        model, test_loader, criterion\n    )\n    exp_branch[\"predictions\"] = ts_pred\n    exp_branch[\"ground_truth\"] = ts_true\n    exp_branch[\"test_metrics\"] = {\n        \"loss\": ts_loss,\n        \"CWA\": ts_cwa,\n        \"SWA\": ts_swa,\n        \"CmpWA\": ts_cpx,\n    }\n    print(\n        f\"TEST ({name}): loss={ts_loss:.3f} CWA={ts_cwa:.3f} SWA={ts_swa:.3f} CmpWA={ts_cpx:.3f}\"\n    )\n    del model\n    torch.cuda.empty_cache()\n\n\n# -------------------------------------------------------------------------\n# run both variants -------------------------------------------------------\ntrain_variant(\"directed\", directed=True)\ntrain_variant(\"undirected\", directed=False)\n\n# -------------------------------------------------------------------------\n# save experiment data ----------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved all metrics to working/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n#!/usr/bin/env python\nimport os, pathlib, random, time, copy, numpy as np, torch\nfrom typing import List, Tuple\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport torch.nn as nn\n\n# -------------------------------------------------------------------------\n# basic setup -------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------------------------------------------------------------------\n# load SPR or synthetic ---------------------------------------------------\ndef try_load_real_dataset() -> Tuple[List[dict], List[dict], List[dict]]:\n    try:\n        import SPR\n\n        DATA_PATH = pathlib.Path(os.environ.get(\"SPR_DATA_PATH\", \"./SPR_BENCH\"))\n        dset = SPR.load_spr_bench(DATA_PATH)\n        return dset[\"train\"], dset[\"dev\"], dset[\"test\"]\n    except Exception as e:\n        raise IOError from e\n\n\ndef build_synthetic_dataset(n_train=600, n_val=150, n_test=150):\n    shapes, colors, labels = [\"C\", \"S\", \"T\"], [\"r\", \"g\", \"b\", \"y\"], [\"rule1\", \"rule2\"]\n\n    def make_seq():\n        L = random.randint(4, 10)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    def mk(n):\n        return [\n            {\"id\": i, \"sequence\": make_seq(), \"label\": random.choice(labels)}\n            for i in range(n)\n        ]\n\n    return mk(n_train), mk(n_val), mk(n_test)\n\n\ntry:\n    train_rows, dev_rows, test_rows = try_load_real_dataset()\n    dataset_name = \"SPR_BENCH\"\n    print(\"Loaded real SPR_BENCH.\")\nexcept IOError:\n    print(\"Using synthetic data (real dataset not found).\")\n    train_rows, dev_rows, test_rows = build_synthetic_dataset()\n    dataset_name = \"synthetic\"\n\n# -------------------------------------------------------------------------\n# vocab & label maps ------------------------------------------------------\ntoken2idx = {\"<PAD>\": 0}\nfor split in train_rows + dev_rows + test_rows:\n    for tok in split[\"sequence\"].split():\n        if tok not in token2idx:\n            token2idx[tok] = len(token2idx)\n\nlabel2idx = {}\nfor r in train_rows + dev_rows + test_rows:\n    if r[\"label\"] not in label2idx:\n        label2idx[r[\"label\"]] = len(label2idx)\n\nnum_classes = len(label2idx)\nprint(f\"Vocab={len(token2idx)}, Labels={num_classes}\")\n\n\n# -------------------------------------------------------------------------\n# metrics -----------------------------------------------------------------\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split()})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split()})\n\n\ndef weighted_acc(seqs, y_true, y_pred, weight_fn):\n    w = [weight_fn(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(seqs, y_true, y_pred, count_color_variety)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(seqs, y_true, y_pred, count_shape_variety)\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    return weighted_acc(\n        seqs, y_true, y_pred, lambda s: count_color_variety(s) + count_shape_variety(s)\n    )\n\n\n# -------------------------------------------------------------------------\n# graph builders ----------------------------------------------------------\ndef seq_to_graph(seq: str, label: str, directed: bool = True) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    shapes = [t[0] for t in toks]\n    colors = [t[1] for t in toks]\n    node_feats = torch.tensor([token2idx[t] for t in toks], dtype=torch.long)\n    src, dst, etype = [], [], []\n\n    def add_edge(i, j, rel):\n        src.append(i)\n        dst.append(j)\n        etype.append(rel)\n\n    # relation 0: neighbour in sequence\n    for i in range(n - 1):\n        add_edge(i, i + 1, 0)\n        if directed:\n            add_edge(i + 1, i, 0)\n\n    # relation 1: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if shapes[i] == shapes[j]:\n                add_edge(i, j, 1)\n                if directed:\n                    add_edge(j, i, 1)\n\n    # relation 2: same color\n    for i in range(n):\n        for j in range(i + 1, n):\n            if colors[i] == colors[j]:\n                add_edge(i, j, 2)\n                if directed:\n                    add_edge(j, i, 2)\n\n    if not src:  # rare fallback\n        add_edge(0, 0, 0)\n\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    return Data(\n        x=node_feats,\n        edge_index=edge_index,\n        edge_type=edge_type,\n        y=torch.tensor([label2idx[label]], dtype=torch.long),\n        seq=seq,\n    )\n\n\n# -------------------------------------------------------------------------\n# dataloaders builder -----------------------------------------------------\ndef build_dataloaders(directed: bool, batch_size: int = 128):\n    train_graphs = [\n        seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in train_rows\n    ]\n    val_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in dev_rows]\n    test_graphs = [seq_to_graph(r[\"sequence\"], r[\"label\"], directed) for r in test_rows]\n    return (\n        DataLoader(train_graphs, batch_size=batch_size, shuffle=True),\n        DataLoader(val_graphs, batch_size=batch_size),\n        DataLoader(test_graphs, batch_size=batch_size),\n    )\n\n\n# -------------------------------------------------------------------------\n# model -------------------------------------------------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self, vocab, emb=64, hid=64, rels=3, classes=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab, emb, padding_idx=0)\n        self.conv1 = RGCNConv(emb, hid, num_relations=rels)\n        self.conv2 = RGCNConv(hid, hid, num_relations=rels)\n        self.lin = nn.Linear(hid, classes)\n\n    def forward(self, x, edge_index, edge_type, batch):\n        h = torch.relu(self.conv1(self.embed(x), edge_index, edge_type))\n        h = torch.relu(self.conv2(h, edge_index, edge_type))\n        g = global_mean_pool(h, batch)\n        return self.lin(g)\n\n\n# -------------------------------------------------------------------------\n# training utilities ------------------------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train_mode = optimizer is not None\n    model.train() if train_mode else model.eval()\n    tot_loss, seqs, yt, yp = 0.0, [], [], []\n    with torch.set_grad_enabled(train_mode):\n        for batch in loader:\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.edge_type, batch.batch)\n            loss = criterion(out, batch.y.squeeze())\n            if train_mode:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            tot_loss += loss.item() * batch.num_graphs\n            preds = out.argmax(-1).cpu().tolist()\n            yp.extend(preds)\n            yt.extend(batch.y.squeeze().cpu().tolist())\n            seqs.extend(batch.seq)\n    n = len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, yt, yp)\n    swa = shape_weighted_accuracy(seqs, yt, yp)\n    cpx = complexity_weighted_accuracy(seqs, yt, yp)\n    return tot_loss / n, cwa, swa, cpx, yp, yt, seqs\n\n\n# -------------------------------------------------------------------------\n# experiment dict ---------------------------------------------------------\nexperiment_data = {\n    \"edge_direction\": {\n        \"directed\": {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"undirected\": {\n            \"metrics\": {\n                \"train\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n                \"val\": {\"CWA\": [], \"SWA\": [], \"CmpWA\": []},\n            },\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    }\n}\n\n\n# -------------------------------------------------------------------------\n# training loop per variant ----------------------------------------------\ndef train_variant(name: str, directed: bool):\n    print(f\"\\n--- Training variant: {name} (directed={directed}) ---\")\n    train_loader, val_loader, test_loader = build_dataloaders(directed)\n    model = SPR_RGCN(len(token2idx), classes=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    best_val, best_state, wait, patience = float(\"inf\"), None, 0, 7\n    for epoch in range(1, 41):\n        tr_loss, tr_cwa, tr_swa, tr_cpx, *_ = run_epoch(\n            model, train_loader, criterion, opt\n        )\n        vl_loss, vl_cwa, vl_swa, vl_cpx, *_ = run_epoch(model, val_loader, criterion)\n\n        exp_branch = experiment_data[\"edge_direction\"][name]\n        exp_branch[\"losses\"][\"train\"].append(tr_loss)\n        exp_branch[\"losses\"][\"val\"].append(vl_loss)\n        for k, v in zip([\"CWA\", \"SWA\", \"CmpWA\"], [tr_cwa, tr_swa, tr_cpx]):\n            exp_branch[\"metrics\"][\"train\"][k].append(v)\n        for k, v in zip([\"CWA\", \"SWA\", \"CmpWA\"], [vl_cwa, vl_swa, vl_cpx]):\n            exp_branch[\"metrics\"][\"val\"][k].append(v)\n\n        print(\n            f\"Epoch {epoch:02d} | tr_loss {tr_loss:.3f} vl_loss {vl_loss:.3f} vl_CmpWA {vl_cpx:.3f}\"\n        )\n        if vl_loss < best_val - 1e-4:\n            best_val, best_state, wait = vl_loss, copy.deepcopy(model.state_dict()), 0\n        else:\n            wait += 1\n            if wait >= patience:\n                print(\"Early stopping.\")\n                break\n    # load best, evaluate test\n    if best_state is not None:\n        model.load_state_dict(best_state)\n    ts_loss, ts_cwa, ts_swa, ts_cpx, ts_pred, ts_true, _ = run_epoch(\n        model, test_loader, criterion\n    )\n    exp_branch[\"predictions\"] = ts_pred\n    exp_branch[\"ground_truth\"] = ts_true\n    exp_branch[\"test_metrics\"] = {\n        \"loss\": ts_loss,\n        \"CWA\": ts_cwa,\n        \"SWA\": ts_swa,\n        \"CmpWA\": ts_cpx,\n    }\n    print(\n        f\"TEST ({name}): loss={ts_loss:.3f} CWA={ts_cwa:.3f} SWA={ts_swa:.3f} CmpWA={ts_cpx:.3f}\"\n    )\n    del model\n    torch.cuda.empty_cache()\n\n\n# -------------------------------------------------------------------------\n# run both variants -------------------------------------------------------\ntrain_variant(\"directed\", directed=True)\ntrain_variant(\"undirected\", directed=False)\n\n# -------------------------------------------------------------------------\n# save experiment data ----------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved all metrics to working/experiment_data.npy\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'Using synthetic data (real dataset not found).',\n'\\n', 'Vocab=13, Labels=2', '\\n', 'Epoch 01: train_loss=0.6976 val_loss=0.7009\nval_CmpWA=0.5212', '\\n', 'Epoch 02: train_loss=0.6716 val_loss=0.6811\nval_CmpWA=0.5885', '\\n', 'Epoch 03: train_loss=0.6520 val_loss=0.6949\nval_CmpWA=0.6048', '\\n', 'Epoch 04: train_loss=0.6358 val_loss=0.6904\nval_CmpWA=0.5863', '\\n', 'Epoch 05: train_loss=0.6252 val_loss=0.6931\nval_CmpWA=0.5679', '\\n', 'Epoch 06: train_loss=0.6166 val_loss=0.6922\nval_CmpWA=0.5603', '\\n', 'Epoch 07: train_loss=0.6034 val_loss=0.6980\nval_CmpWA=0.5505', '\\n', 'Epoch 08: train_loss=0.5923 val_loss=0.6914\nval_CmpWA=0.5407', '\\n', 'Epoch 09: train_loss=0.5801 val_loss=0.7070\nval_CmpWA=0.5320', '\\n', 'Early stopping.', '\\n', 'TEST: loss=0.6945 CWA=0.5906\nSWA=0.5623 CmpWA=0.5778', '\\n', 'Saved metrics to working/experiment_data.npy',\n'\\n', 'Execution time: 5 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Using synthetic dataset (real dataset not\nfound).', '\\n', 'Vocab size = 13 | #labels = 2', '\\n', 'Epoch 01:\ntrain_loss=0.6951 val_loss=0.6882 val_CmpWA=0.5289', '\\n', 'Epoch 02:\ntrain_loss=0.6900 val_loss=0.6880 val_CmpWA=0.5171', '\\n', 'Epoch 03:\ntrain_loss=0.6863 val_loss=0.6860 val_CmpWA=0.5171', '\\n', 'Epoch 04:\ntrain_loss=0.6838 val_loss=0.6852 val_CmpWA=0.5289', '\\n', 'Epoch 05:\ntrain_loss=0.6829 val_loss=0.6851 val_CmpWA=0.5343', '\\n', 'Epoch 06:\ntrain_loss=0.6811 val_loss=0.6862 val_CmpWA=0.5128', '\\n', 'Epoch 07:\ntrain_loss=0.6782 val_loss=0.6860 val_CmpWA=0.5107', '\\n', 'Epoch 08:\ntrain_loss=0.6764 val_loss=0.6849 val_CmpWA=0.5278', '\\n', 'Epoch 09:\ntrain_loss=0.6758 val_loss=0.6841 val_CmpWA=0.5310', '\\n', 'Epoch 10:\ntrain_loss=0.6733 val_loss=0.6859 val_CmpWA=0.5396', '\\n', 'Epoch 11:\ntrain_loss=0.6711 val_loss=0.6870 val_CmpWA=0.5278', '\\n', 'Epoch 12:\ntrain_loss=0.6691 val_loss=0.6879 val_CmpWA=0.5332', '\\n', 'Epoch 13:\ntrain_loss=0.6675 val_loss=0.6886 val_CmpWA=0.5396', '\\n', 'Epoch 14:\ntrain_loss=0.6658 val_loss=0.6893 val_CmpWA=0.5343', '\\n', 'Epoch 15:\ntrain_loss=0.6640 val_loss=0.6895 val_CmpWA=0.5161', '\\n', 'Epoch 16:\ntrain_loss=0.6616 val_loss=0.6934 val_CmpWA=0.5075', '\\n', 'Early stopping.',\n'\\n', 'TEST: loss=0.7019 CWA=0.4462 SWA=0.4523 CmpWA=0.4489', '\\n', 'Saved all\nmetrics to:', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_20-\n55-31_gnn_for_spr_attempt_0/0-run/process_ForkProcess-\n16/working/experiment_data.npy', '\\n', 'Execution time: 5 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Using synthetic data.', '\\n', 'Vocab\nsize=13, num_classes=2', '\\n', 'Epoch 01 | train_loss=0.6978 val_loss=0.7538\nval_CmpWA=0.3937', '\\n', 'Epoch 02 | train_loss=0.6839 val_loss=0.7262\nval_CmpWA=0.5496', '\\n', 'Epoch 03 | train_loss=0.6677 val_loss=0.7282\nval_CmpWA=0.4678', '\\n', 'Epoch 04 | train_loss=0.6563 val_loss=0.7298\nval_CmpWA=0.4700', '\\n', 'Epoch 05 | train_loss=0.6475 val_loss=0.7341\nval_CmpWA=0.4995', '\\n', 'Epoch 06 | train_loss=0.6424 val_loss=0.7402\nval_CmpWA=0.4449', '\\n', 'Epoch 07 | train_loss=0.6371 val_loss=0.7471\nval_CmpWA=0.4755', '\\n', 'Epoch 08 | train_loss=0.6321 val_loss=0.7475\nval_CmpWA=0.5082', '\\n', 'Epoch 09 | train_loss=0.6266 val_loss=0.7532\nval_CmpWA=0.4482', '\\n', 'Early stopping.', '\\n', 'TEST | loss=0.7287 CWA=0.4822\nSWA=0.4880 CmpWA=0.4848', '\\n', 'Saved metrics to working/experiment_data.npy',\n'\\n', 'Execution time: 2 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Using synthetic data (real dataset not found).',\n'\\n', 'Vocab size: 13, #Labels: 2', '\\n', 'Epoch 01 | train_loss 0.7104 val_loss\n0.7288 val CWA 0.4588 SWA 0.4557 CmpWA 0.4574', '\\n', 'Epoch 02 | train_loss\n0.6950 val_loss 0.7068 val CWA 0.5431 SWA 0.5296 CmpWA 0.5371', '\\n', 'Epoch 03\n| train_loss 0.6715 val_loss 0.7118 val CWA 0.5588 SWA 0.5616 CmpWA 0.5600',\n'\\n', 'Epoch 04 | train_loss 0.6532 val_loss 0.7190 val CWA 0.5078 SWA 0.4926\nCmpWA 0.5011', '\\n', 'Epoch 05 | train_loss 0.6615 val_loss 0.7226 val CWA\n0.5118 SWA 0.4901 CmpWA 0.5022', '\\n', 'Epoch 06 | train_loss 0.6402 val_loss\n0.7222 val CWA 0.5667 SWA 0.5616 CmpWA 0.5644', '\\n', 'Epoch 07 | train_loss\n0.6440 val_loss 0.7220 val CWA 0.5255 SWA 0.5222 CmpWA 0.5240', '\\n', 'Epoch 08\n| train_loss 0.6354 val_loss 0.7308 val CWA 0.5000 SWA 0.4901 CmpWA 0.4956',\n'\\n', 'Epoch 09 | train_loss 0.6305 val_loss 0.7233 val CWA 0.5235 SWA 0.5123\nCmpWA 0.5186', '\\n', 'Early stopping triggered.', '\\n', 'TEST: loss=0.7073\nCWA=0.5222 SWA=0.5179 CmpWA=0.5203', '\\n', 'Saved experiment data to\nworking/experiment_data.npy', '\\n', 'Execution time: 2 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Using synthetic dataset (real dataset not\nfound).', '\\n', 'Num classes = 2', '\\n', 'Epoch 01: train_loss=0.7785\nval_loss=0.7012 val_CmpWA=0.5151', '\\n', 'Epoch 02: train_loss=0.7105\nval_loss=0.6953 val_CmpWA=0.4925', '\\n', 'Epoch 03: train_loss=0.6946\nval_loss=0.6976 val_CmpWA=0.5162', '\\n', 'Epoch 04: train_loss=0.6992\nval_loss=0.6927 val_CmpWA=0.5496', '\\n', 'Epoch 05: train_loss=0.6922\nval_loss=0.6945 val_CmpWA=0.5162', '\\n', 'Epoch 06: train_loss=0.6928\nval_loss=0.6934 val_CmpWA=0.4860', '\\n', 'Epoch 07: train_loss=0.7008\nval_loss=0.6952 val_CmpWA=0.5162', '\\n', 'Epoch 08: train_loss=0.6974\nval_loss=0.6938 val_CmpWA=0.4828', '\\n', 'Epoch 09: train_loss=0.6932\nval_loss=0.6934 val_CmpWA=0.5162', '\\n', 'Epoch 10: train_loss=0.6955\nval_loss=0.6934 val_CmpWA=0.5032', '\\n', 'Epoch 11: train_loss=0.7029\nval_loss=0.6952 val_CmpWA=0.5162', '\\n', 'Early stopping.', '\\n', 'TEST:\nloss=0.6915 CWA=0.5060 SWA=0.5202 CmpWA=0.5125', '\\n', 'Saved metrics to\nworking/experiment_data.npy', '\\n', 'Execution time: 5 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Using synthetic dataset.', '\\n', 'Vocab=13\nLabels=2', '\\n', 'Epoch 01  train_loss=0.7242  val_loss=0.6890\nval_CmpWA=0.5613', '\\n', 'Epoch 02  train_loss=0.7129  val_loss=0.6896\nval_CmpWA=0.5689', '\\n', 'Epoch 03  train_loss=0.6866  val_loss=0.7013\nval_CmpWA=0.5288', '\\n', 'Epoch 04  train_loss=0.6801  val_loss=0.7210\nval_CmpWA=0.4962', '\\n', 'Epoch 05  train_loss=0.6778  val_loss=0.7043\nval_CmpWA=0.5244', '\\n', 'Epoch 06  train_loss=0.6696  val_loss=0.6956\nval_CmpWA=0.5863', '\\n', 'Epoch 07  train_loss=0.6661  val_loss=0.6990\nval_CmpWA=0.5472', '\\n', 'Epoch 08  train_loss=0.6602  val_loss=0.7044\nval_CmpWA=0.5396', '\\n', 'Early stopping.', '\\n', 'TEST  loss=0.7243  CWA=0.5020\nSWA=0.4976  CmpWA=0.5000', '\\n', 'Saved metrics to working/experiment_data.npy',\n'\\n', 'Execution time: 4 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Using synthetic data (real dataset not found).',\n'\\n', 'Vocab=13, Labels=2', '\\n', '\\n--- Training variant: directed\n(directed=True) ---', '\\n', 'Epoch 01 | tr_loss 0.722 vl_loss 0.684 vl_CmpWA\n0.555', '\\n', 'Epoch 02 | tr_loss 0.677 vl_loss 0.683 vl_CmpWA 0.546', '\\n',\n'Epoch 03 | tr_loss 0.660 vl_loss 0.684 vl_CmpWA 0.557', '\\n', 'Epoch 04 |\ntr_loss 0.648 vl_loss 0.682 vl_CmpWA 0.568', '\\n', 'Epoch 05 | tr_loss 0.637\nvl_loss 0.681 vl_CmpWA 0.564', '\\n', 'Epoch 06 | tr_loss 0.622 vl_loss 0.686\nvl_CmpWA 0.543', '\\n', 'Epoch 07 | tr_loss 0.614 vl_loss 0.682 vl_CmpWA 0.569',\n'\\n', 'Epoch 08 | tr_loss 0.603 vl_loss 0.687 vl_CmpWA 0.566', '\\n', 'Epoch 09 |\ntr_loss 0.589 vl_loss 0.699 vl_CmpWA 0.529', '\\n', 'Epoch 10 | tr_loss 0.580\nvl_loss 0.701 vl_CmpWA 0.515', '\\n', 'Epoch 11 | tr_loss 0.565 vl_loss 0.712\nvl_CmpWA 0.504', '\\n', 'Epoch 12 | tr_loss 0.554 vl_loss 0.712 vl_CmpWA 0.517',\n'\\n', 'Early stopping.', '\\n', 'TEST (directed): loss=0.685 CWA=0.545 SWA=0.550\nCmpWA=0.547', '\\n', '\\n--- Training variant: undirected (directed=False) ---',\n'\\n', 'Epoch 01 | tr_loss 0.725 vl_loss 0.681 vl_CmpWA 0.563', '\\n', 'Epoch 02 |\ntr_loss 0.703 vl_loss 0.672 vl_CmpWA 0.624', '\\n', 'Epoch 03 | tr_loss 0.670\nvl_loss 0.683 vl_CmpWA 0.551', '\\n', 'Epoch 04 | tr_loss 0.663 vl_loss 0.682\nvl_CmpWA 0.551', '\\n', 'Epoch 05 | tr_loss 0.652 vl_loss 0.670 vl_CmpWA 0.572',\n'\\n', 'Epoch 06 | tr_loss 0.643 vl_loss 0.669 vl_CmpWA 0.578', '\\n', 'Epoch 07 |\ntr_loss 0.635 vl_loss 0.671 vl_CmpWA 0.602', '\\n', 'Epoch 08 | tr_loss 0.626\nvl_loss 0.679 vl_CmpWA 0.540', '\\n', 'Epoch 09 | tr_loss 0.615 vl_loss 0.671\nvl_CmpWA 0.610', '\\n', 'Epoch 10 | tr_loss 0.605 vl_loss 0.669 vl_CmpWA 0.610',\n'\\n', 'Epoch 11 | tr_loss 0.594 vl_loss 0.681 vl_CmpWA 0.560', '\\n', 'Epoch 12 |\ntr_loss 0.588 vl_loss 0.685 vl_CmpWA 0.550', '\\n', 'Epoch 13 | tr_loss 0.575\nvl_loss 0.675 vl_CmpWA 0.622', '\\n', 'Epoch 14 | tr_loss 0.561 vl_loss 0.696\nvl_CmpWA 0.523', '\\n', 'Epoch 15 | tr_loss 0.548 vl_loss 0.683 vl_CmpWA 0.571',\n'\\n', 'Epoch 16 | tr_loss 0.538 vl_loss 0.689 vl_CmpWA 0.558', '\\n', 'Epoch 17 |\ntr_loss 0.520 vl_loss 0.711 vl_CmpWA 0.529', '\\n', 'Early stopping.', '\\n',\n'TEST (undirected): loss=0.684 CWA=0.588 SWA=0.580 CmpWA=0.584', '\\n', 'Saved\nall metrics to working/experiment_data.npy', '\\n', 'Execution time: 4 seconds\nseconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Using synthetic data.', '\\n', 'Vocab=13,\nLabels=2', '\\n', 'Epoch 01: train_loss=0.6941 val_loss=0.6982 val_CmpWA=0.4081',\n'\\n', 'Epoch 02: train_loss=0.6898 val_loss=0.6970 val_CmpWA=0.4191', '\\n',\n'Epoch 03: train_loss=0.6870 val_loss=0.7010 val_CmpWA=0.4125', '\\n', 'Epoch 04:\ntrain_loss=0.6843 val_loss=0.6977 val_CmpWA=0.4147', '\\n', 'Epoch 05:\ntrain_loss=0.6818 val_loss=0.6998 val_CmpWA=0.4477', '\\n', 'Epoch 06:\ntrain_loss=0.6788 val_loss=0.6967 val_CmpWA=0.4521', '\\n', 'Epoch 07:\ntrain_loss=0.6766 val_loss=0.6965 val_CmpWA=0.4521', '\\n', 'Epoch 08:\ntrain_loss=0.6733 val_loss=0.6979 val_CmpWA=0.4609', '\\n', 'Epoch 09:\ntrain_loss=0.6704 val_loss=0.7011 val_CmpWA=0.4510', '\\n', 'Epoch 10:\ntrain_loss=0.6676 val_loss=0.7000 val_CmpWA=0.4609', '\\n', 'Epoch 11:\ntrain_loss=0.6640 val_loss=0.6997 val_CmpWA=0.4686', '\\n', 'Epoch 12:\ntrain_loss=0.6596 val_loss=0.7031 val_CmpWA=0.4554', '\\n', 'Epoch 13:\ntrain_loss=0.6552 val_loss=0.7012 val_CmpWA=0.4752', '\\n', 'Epoch 14:\ntrain_loss=0.6506 val_loss=0.6996 val_CmpWA=0.4675', '\\n', 'Early stopping.',\n'\\n', 'TEST: loss=0.6934 CWA=0.4863 SWA=0.4976 CmpWA=0.4914', '\\n', 'Saved\nmetrics to working/experiment_data.npy', '\\n', 'Execution time: 3 seconds\nseconds (time limit is 30 minutes).']", "['Device:', ' ', 'cuda', '\\n', 'Vocab=13, Labels=2', '\\n', '\\n=== Experiment:\nTrain A | Val B | Test C ===', '\\n', '\\n=== Experiment: Train A+B | Val B | Test\nC ===', '\\n', 'Saved results to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-19/working/experiment_data.npy', '\\n', 'Execution time:\n28 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Using synthetic data (real dataset not found).',\n'\\n', 'Vocab=13, Labels=2', '\\n', '\\n--- Training variant: directed\n(directed=True) ---', '\\n', 'Epoch 01 | tr_loss 0.737 vl_loss 0.704 vl_CmpWA\n0.504', '\\n', 'Epoch 02 | tr_loss 0.696 vl_loss 0.702 vl_CmpWA 0.591', '\\n',\n'Epoch 03 | tr_loss 0.675 vl_loss 0.705 vl_CmpWA 0.577', '\\n', 'Epoch 04 |\ntr_loss 0.662 vl_loss 0.702 vl_CmpWA 0.499', '\\n', 'Epoch 05 | tr_loss 0.652\nvl_loss 0.700 vl_CmpWA 0.537', '\\n', 'Epoch 06 | tr_loss 0.640 vl_loss 0.701\nvl_CmpWA 0.544', '\\n', 'Epoch 07 | tr_loss 0.628 vl_loss 0.699 vl_CmpWA 0.567',\n'\\n', 'Epoch 08 | tr_loss 0.629 vl_loss 0.699 vl_CmpWA 0.561', '\\n', 'Epoch 09 |\ntr_loss 0.611 vl_loss 0.710 vl_CmpWA 0.529', '\\n', 'Epoch 10 | tr_loss 0.603\nvl_loss 0.707 vl_CmpWA 0.566', '\\n', 'Epoch 11 | tr_loss 0.588 vl_loss 0.711\nvl_CmpWA 0.527', '\\n', 'Epoch 12 | tr_loss 0.577 vl_loss 0.706 vl_CmpWA 0.554',\n'\\n', 'Epoch 13 | tr_loss 0.565 vl_loss 0.711 vl_CmpWA 0.521', '\\n', 'Epoch 14 |\ntr_loss 0.554 vl_loss 0.720 vl_CmpWA 0.523', '\\n', 'Early stopping.', '\\n',\n'TEST (directed): loss=0.728 CWA=0.509 SWA=0.500 CmpWA=0.505', '\\n', '\\n---\nTraining variant: undirected (directed=False) ---', '\\n', 'Epoch 01 | tr_loss\n0.702 vl_loss 0.683 vl_CmpWA 0.553', '\\n', 'Epoch 02 | tr_loss 0.684 vl_loss\n0.685 vl_CmpWA 0.569', '\\n', 'Epoch 03 | tr_loss 0.669 vl_loss 0.672 vl_CmpWA\n0.576', '\\n', 'Epoch 04 | tr_loss 0.658 vl_loss 0.670 vl_CmpWA 0.597', '\\n',\n'Epoch 05 | tr_loss 0.649 vl_loss 0.670 vl_CmpWA 0.584', '\\n', 'Epoch 06 |\ntr_loss 0.640 vl_loss 0.666 vl_CmpWA 0.574', '\\n', 'Epoch 07 | tr_loss 0.633\nvl_loss 0.665 vl_CmpWA 0.604', '\\n', 'Epoch 08 | tr_loss 0.622 vl_loss 0.674\nvl_CmpWA 0.628', '\\n', 'Epoch 09 | tr_loss 0.614 vl_loss 0.664 vl_CmpWA 0.598',\n'\\n', 'Epoch 10 | tr_loss 0.603 vl_loss 0.664 vl_CmpWA 0.581', '\\n', 'Epoch 11 |\ntr_loss 0.600 vl_loss 0.670 vl_CmpWA 0.612', '\\n', 'Epoch 12 | tr_loss 0.583\nvl_loss 0.663 vl_CmpWA 0.597', '\\n', 'Epoch 13 | tr_loss 0.570 vl_loss 0.671\nvl_CmpWA 0.617', '\\n', 'Epoch 14 | tr_loss 0.558 vl_loss 0.667 vl_CmpWA 0.584',\n'\\n', 'Epoch 15 | tr_loss 0.546 vl_loss 0.669 vl_CmpWA 0.603', '\\n', 'Epoch 16 |\ntr_loss 0.531 vl_loss 0.674 vl_CmpWA 0.623', '\\n', 'Epoch 17 | tr_loss 0.518\nvl_loss 0.670 vl_CmpWA 0.603', '\\n', 'Epoch 18 | tr_loss 0.509 vl_loss 0.674\nvl_CmpWA 0.624', '\\n', 'Epoch 19 | tr_loss 0.489 vl_loss 0.677 vl_CmpWA 0.588',\n'\\n', 'Early stopping.', '\\n', 'TEST (undirected): loss=0.686 CWA=0.561\nSWA=0.564 CmpWA=0.562', '\\n', 'Saved all metrics to\nworking/experiment_data.npy', '\\n', 'Execution time: 11 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Using synthetic data (real dataset not found).',\n'\\n', 'Vocab=13, Labels=2', '\\n', '\\n--- Training variant: directed\n(directed=True) ---', '\\n', 'Epoch 01 | tr_loss 0.847 vl_loss 0.747 vl_CmpWA\n0.519', '\\n', 'Epoch 02 | tr_loss 0.733 vl_loss 0.712 vl_CmpWA 0.509', '\\n',\n'Epoch 03 | tr_loss 0.694 vl_loss 0.738 vl_CmpWA 0.467', '\\n', 'Epoch 04 |\ntr_loss 0.677 vl_loss 0.701 vl_CmpWA 0.509', '\\n', 'Epoch 05 | tr_loss 0.664\nvl_loss 0.703 vl_CmpWA 0.537', '\\n', 'Epoch 06 | tr_loss 0.650 vl_loss 0.711\nvl_CmpWA 0.473', '\\n', 'Epoch 07 | tr_loss 0.641 vl_loss 0.715 vl_CmpWA 0.459',\n'\\n', 'Epoch 08 | tr_loss 0.631 vl_loss 0.715 vl_CmpWA 0.488', '\\n', 'Epoch 09 |\ntr_loss 0.624 vl_loss 0.716 vl_CmpWA 0.494', '\\n', 'Epoch 10 | tr_loss 0.616\nvl_loss 0.725 vl_CmpWA 0.483', '\\n', 'Epoch 11 | tr_loss 0.607 vl_loss 0.725\nvl_CmpWA 0.481', '\\n', 'Early stopping.', '\\n', 'TEST (directed): loss=0.694\nCWA=0.502 SWA=0.507 CmpWA=0.504', '\\n', '\\n--- Training variant: undirected\n(directed=False) ---', '\\n', 'Epoch 01 | tr_loss 0.730 vl_loss 0.706 vl_CmpWA\n0.533', '\\n', 'Epoch 02 | tr_loss 0.690 vl_loss 0.724 vl_CmpWA 0.481', '\\n',\n'Epoch 03 | tr_loss 0.671 vl_loss 0.706 vl_CmpWA 0.495', '\\n', 'Epoch 04 |\ntr_loss 0.653 vl_loss 0.701 vl_CmpWA 0.498', '\\n', 'Epoch 05 | tr_loss 0.641\nvl_loss 0.708 vl_CmpWA 0.516', '\\n', 'Epoch 06 | tr_loss 0.629 vl_loss 0.709\nvl_CmpWA 0.516', '\\n', 'Epoch 07 | tr_loss 0.618 vl_loss 0.704 vl_CmpWA 0.549',\n'\\n', 'Epoch 08 | tr_loss 0.607 vl_loss 0.707 vl_CmpWA 0.555', '\\n', 'Epoch 09 |\ntr_loss 0.594 vl_loss 0.707 vl_CmpWA 0.571', '\\n', 'Epoch 10 | tr_loss 0.581\nvl_loss 0.710 vl_CmpWA 0.544', '\\n', 'Epoch 11 | tr_loss 0.569 vl_loss 0.713\nvl_CmpWA 0.549', '\\n', 'Early stopping.', '\\n', 'TEST (undirected): loss=0.705\nCWA=0.528 SWA=0.535 CmpWA=0.531', '\\n', 'Saved all metrics to\nworking/experiment_data.npy', '\\n', 'Execution time: 5 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Using synthetic data (real dataset not found).',\n'\\n', 'Vocab=13, Labels=2', '\\n', '\\n--- Training variant: directed\n(directed=True) ---', '\\n', 'Epoch 01 | tr_loss 0.735 vl_loss 0.725 vl_CmpWA\n0.467', '\\n', 'Epoch 02 | tr_loss 0.697 vl_loss 0.742 vl_CmpWA 0.460', '\\n',\n'Epoch 03 | tr_loss 0.684 vl_loss 0.750 vl_CmpWA 0.438', '\\n', 'Epoch 04 |\ntr_loss 0.653 vl_loss 0.755 vl_CmpWA 0.412', '\\n', 'Epoch 05 | tr_loss 0.651\nvl_loss 0.758 vl_CmpWA 0.386', '\\n', 'Epoch 06 | tr_loss 0.633 vl_loss 0.761\nvl_CmpWA 0.420', '\\n', 'Epoch 07 | tr_loss 0.622 vl_loss 0.761 vl_CmpWA 0.346',\n'\\n', 'Epoch 08 | tr_loss 0.611 vl_loss 0.766 vl_CmpWA 0.381', '\\n', 'Early\nstopping.', '\\n', 'TEST (directed): loss=0.701 CWA=0.513 SWA=0.498 CmpWA=0.506',\n'\\n', '\\n--- Training variant: undirected (directed=False) ---', '\\n', 'Epoch 01\n| tr_loss 0.773 vl_loss 0.728 vl_CmpWA 0.485', '\\n', 'Epoch 02 | tr_loss 0.728\nvl_loss 0.695 vl_CmpWA 0.521', '\\n', 'Epoch 03 | tr_loss 0.683 vl_loss 0.694\nvl_CmpWA 0.550', '\\n', 'Epoch 04 | tr_loss 0.682 vl_loss 0.695 vl_CmpWA 0.504',\n'\\n', 'Epoch 05 | tr_loss 0.663 vl_loss 0.694 vl_CmpWA 0.477', '\\n', 'Epoch 06 |\ntr_loss 0.657 vl_loss 0.700 vl_CmpWA 0.469', '\\n', 'Epoch 07 | tr_loss 0.644\nvl_loss 0.699 vl_CmpWA 0.532', '\\n', 'Epoch 08 | tr_loss 0.639 vl_loss 0.704\nvl_CmpWA 0.501', '\\n', 'Epoch 09 | tr_loss 0.630 vl_loss 0.705 vl_CmpWA 0.509',\n'\\n', 'Epoch 10 | tr_loss 0.619 vl_loss 0.708 vl_CmpWA 0.517', '\\n', 'Early\nstopping.', '\\n', 'TEST (undirected): loss=0.711 CWA=0.479 SWA=0.475\nCmpWA=0.477', '\\n', 'Saved all metrics to working/experiment_data.npy', '\\n',\n'Execution time: 4 seconds seconds (time limit is 30 minutes).']", ""], "analysis": ["", "", "", "The execution of the training script completed successfully without any errors\nor bugs. The synthetic dataset was used due to the absence of the real dataset.\nThe model trained and validated properly, with early stopping triggered after\nthe validation loss did not improve. The test metrics were calculated and saved\nsuccessfully. No issues were detected.", "", "", "The execution of the training script completed without any errors or bugs. Two\nvariants of the model (directed and undirected) were trained and evaluated\nsuccessfully. Metrics such as loss, Color-Weighted Accuracy (CWA), Shape-\nWeighted Accuracy (SWA), and Complexity-Weighted Accuracy (CmpWA) were computed\nand saved. Early stopping was applied appropriately when validation loss stopped\nimproving, and the results were consistent with the expected behavior of the\nscript.", "", "", "", "", "The execution output indicates that the training script successfully executed\nwithout any errors or bugs. The model was trained on synthetic data (as the real\ndataset was not found) for two variants: directed and undirected edge\ndirections. Both variants were evaluated, with early stopping implemented during\ntraining. Metrics such as Color-Weighted Accuracy (CWA), Shape-Weighted Accuracy\n(SWA), and Complexity-Weighted Accuracy (CmpWA) were reported for both training\nand testing phases. Results were saved successfully to 'experiment_data.npy'.\nThe script performed as expected, and no issues were detected.", ""], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the error or difference between predicted and actual values.", "data": [{"dataset_name": "Training", "final_value": 0.5801, "best_value": 0.5801}, {"dataset_name": "Validation", "final_value": 0.6811, "best_value": 0.6811}, {"dataset_name": "Test", "final_value": 0.6945, "best_value": 0.6945}]}, {"metric_name": "CWA", "lower_is_better": false, "description": "Custom Weighted Accuracy, a metric for classification performance.", "data": [{"dataset_name": "Training", "final_value": 0.7286, "best_value": 0.7286}, {"dataset_name": "Validation", "final_value": 0.5953, "best_value": 0.5953}, {"dataset_name": "Test", "final_value": 0.5906, "best_value": 0.5906}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "Smoothed Weighted Accuracy, another metric for classification performance.", "data": [{"dataset_name": "Training", "final_value": 0.7305, "best_value": 0.7305}, {"dataset_name": "Validation", "final_value": 0.5799, "best_value": 0.5799}, {"dataset_name": "Test", "final_value": 0.5623, "best_value": 0.5623}]}, {"metric_name": "CmpWA", "lower_is_better": false, "description": "Composite Weighted Accuracy, a combined metric for classification performance.", "data": [{"dataset_name": "Training", "final_value": 0.7295, "best_value": 0.7295}, {"dataset_name": "Validation", "final_value": 0.5885, "best_value": 0.5885}, {"dataset_name": "Test", "final_value": 0.5778, "best_value": 0.5778}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.6616, "best_value": 0.6616}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final validation loss for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.6934, "best_value": 0.6934}]}, {"metric_name": "training color weighted accuracy", "lower_is_better": false, "description": "Final training color weighted accuracy for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.6161, "best_value": 0.6161}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "Final validation color weighted accuracy for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.5107, "best_value": 0.5107}]}, {"metric_name": "training shape weighted accuracy", "lower_is_better": false, "description": "Final training shape weighted accuracy for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.6213, "best_value": 0.6213}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "Final validation shape weighted accuracy for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.5036, "best_value": 0.5036}]}, {"metric_name": "training complexity weighted accuracy", "lower_is_better": false, "description": "Final training complexity weighted accuracy for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.6185, "best_value": 0.6185}]}, {"metric_name": "validation complexity weighted accuracy", "lower_is_better": false, "description": "Final validation complexity weighted accuracy for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.5075, "best_value": 0.5075}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Test loss for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.7019, "best_value": 0.7019}]}, {"metric_name": "test color weighted accuracy", "lower_is_better": false, "description": "Test color weighted accuracy for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.4462, "best_value": 0.4462}]}, {"metric_name": "test shape weighted accuracy", "lower_is_better": false, "description": "Test shape weighted accuracy for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.4523, "best_value": 0.4523}]}, {"metric_name": "test complexity weighted accuracy", "lower_is_better": false, "description": "Test complexity weighted accuracy for the dataset.", "data": [{"dataset_name": "synthetic", "final_value": 0.4489, "best_value": 0.4489}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "NoSeqEdges", "final_value": 0.6266386373837789, "best_value": 0.6266386373837789}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "NoSeqEdges", "final_value": 0.7531723546981811, "best_value": 0.7531723546981811}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value during testing.", "data": [{"dataset_name": "NoSeqEdges", "final_value": 0.7287301111221314, "best_value": 0.7287301111221314}]}, {"metric_name": "train complexity weighted accuracy (CWA)", "lower_is_better": false, "description": "The complexity weighted accuracy during training.", "data": [{"dataset_name": "NoSeqEdges", "final_value": 0.670152855993564, "best_value": 0.670152855993564}]}, {"metric_name": "validation complexity weighted accuracy (CWA)", "lower_is_better": false, "description": "The complexity weighted accuracy during validation.", "data": [{"dataset_name": "NoSeqEdges", "final_value": 0.44820065430752454, "best_value": 0.44820065430752454}]}, {"metric_name": "test complexity weighted accuracy (CWA)", "lower_is_better": false, "description": "The complexity weighted accuracy during testing.", "data": [{"dataset_name": "NoSeqEdges", "final_value": 0.4848156182212581, "best_value": 0.4848156182212581}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the error in predictions. Lower values indicate better performance.", "data": [{"dataset_name": "train", "final_value": 0.6305, "best_value": 0.6305}, {"dataset_name": "validation", "final_value": 0.7233, "best_value": 0.7233}, {"dataset_name": "test", "final_value": 0.7073, "best_value": 0.7073}]}, {"metric_name": "CWA", "lower_is_better": false, "description": "CWA stands for Class-Wise Accuracy. Higher values indicate better performance.", "data": [{"dataset_name": "train", "final_value": 0.6489, "best_value": 0.6489}, {"dataset_name": "validation", "final_value": 0.5235, "best_value": 0.5235}, {"dataset_name": "test", "final_value": 0.5222, "best_value": 0.5222}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "SWA stands for Sample-Wise Accuracy. Higher values indicate better performance.", "data": [{"dataset_name": "train", "final_value": 0.6551, "best_value": 0.6551}, {"dataset_name": "validation", "final_value": 0.5123, "best_value": 0.5123}, {"dataset_name": "test", "final_value": 0.5179, "best_value": 0.5179}]}, {"metric_name": "CmpWA", "lower_is_better": false, "description": "CmpWA stands for Comparison-Wise Accuracy. Higher values indicate better performance.", "data": [{"dataset_name": "train", "final_value": 0.6517, "best_value": 0.6517}, {"dataset_name": "validation", "final_value": 0.5186, "best_value": 0.5186}, {"dataset_name": "test", "final_value": 0.5203, "best_value": 0.5203}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the error of the model's predictions compared to the actual values.", "data": [{"dataset_name": "Training", "final_value": 0.7029, "best_value": 0.7029}, {"dataset_name": "Validation", "final_value": 0.6927, "best_value": 0.6927}, {"dataset_name": "Test", "final_value": 0.6915, "best_value": 0.6915}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "Accuracy of the model with weights applied based on color.", "data": [{"dataset_name": "Training", "final_value": 0.4951, "best_value": 0.4951}, {"dataset_name": "Validation", "final_value": 0.5506, "best_value": 0.5506}, {"dataset_name": "Test", "final_value": 0.506, "best_value": 0.506}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy of the model with weights applied based on shape.", "data": [{"dataset_name": "Training", "final_value": 0.4824, "best_value": 0.4824}, {"dataset_name": "Validation", "final_value": 0.5483, "best_value": 0.5483}, {"dataset_name": "Test", "final_value": 0.5202, "best_value": 0.5202}]}, {"metric_name": "complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy of the model with weights applied based on complexity.", "data": [{"dataset_name": "Training", "final_value": 0.4894, "best_value": 0.4894}, {"dataset_name": "Validation", "final_value": 0.5496, "best_value": 0.5496}, {"dataset_name": "Test", "final_value": 0.5125, "best_value": 0.5125}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the model's error during training, validation, and testing.", "data": [{"dataset_name": "synthetic", "final_value": 0.6602, "best_value": 0.6602}, {"dataset_name": "synthetic", "final_value": 0.7243, "best_value": 0.689}, {"dataset_name": "synthetic", "final_value": 0.7243, "best_value": 0.689}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions weighted by color-related factors.", "data": [{"dataset_name": "synthetic", "final_value": 0.6088, "best_value": 0.6088}, {"dataset_name": "synthetic", "final_value": 0.502, "best_value": 0.5621}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions weighted by shape-related factors.", "data": [{"dataset_name": "synthetic", "final_value": 0.6058, "best_value": 0.6058}, {"dataset_name": "synthetic", "final_value": 0.4976, "best_value": 0.5604}]}, {"metric_name": "complexity-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions weighted by complexity-related factors.", "data": [{"dataset_name": "synthetic", "final_value": 0.6075, "best_value": 0.6075}, {"dataset_name": "synthetic", "final_value": 0.5, "best_value": 0.5613}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Loss during training phase", "data": [{"dataset_name": "directed", "final_value": 0.5536, "best_value": 0.5536}, {"dataset_name": "undirected", "final_value": 0.5199, "best_value": 0.5199}]}, {"metric_name": "train color-weighted accuracy", "lower_is_better": false, "description": "Color-weighted accuracy during training phase", "data": [{"dataset_name": "directed", "final_value": 0.7662, "best_value": 0.7662}, {"dataset_name": "undirected", "final_value": 0.7963, "best_value": 0.7963}]}, {"metric_name": "train shape-weighted accuracy", "lower_is_better": false, "description": "Shape-weighted accuracy during training phase", "data": [{"dataset_name": "directed", "final_value": 0.766, "best_value": 0.766}, {"dataset_name": "undirected", "final_value": 0.7938, "best_value": 0.7938}]}, {"metric_name": "train complexity-weighted accuracy", "lower_is_better": false, "description": "Complexity-weighted accuracy during training phase", "data": [{"dataset_name": "directed", "final_value": 0.7661, "best_value": 0.7661}, {"dataset_name": "undirected", "final_value": 0.7952, "best_value": 0.7952}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss during validation phase", "data": [{"dataset_name": "directed", "final_value": 0.6809, "best_value": 0.6809}, {"dataset_name": "undirected", "final_value": 0.6691, "best_value": 0.6691}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "Color-weighted accuracy during validation phase", "data": [{"dataset_name": "directed", "final_value": 0.5618, "best_value": 0.5618}, {"dataset_name": "undirected", "final_value": 0.6056, "best_value": 0.6056}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Shape-weighted accuracy during validation phase", "data": [{"dataset_name": "directed", "final_value": 0.5676, "best_value": 0.5676}, {"dataset_name": "undirected", "final_value": 0.6159, "best_value": 0.6159}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "Complexity-weighted accuracy during validation phase", "data": [{"dataset_name": "directed", "final_value": 0.5644, "best_value": 0.5644}, {"dataset_name": "undirected", "final_value": 0.6103, "best_value": 0.6103}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Loss during testing phase", "data": [{"dataset_name": "directed", "final_value": 0.6852, "best_value": 0.6852}, {"dataset_name": "undirected", "final_value": 0.6836, "best_value": 0.6836}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "Color-weighted accuracy during testing phase", "data": [{"dataset_name": "directed", "final_value": 0.5451, "best_value": 0.5451}, {"dataset_name": "undirected", "final_value": 0.5882, "best_value": 0.5882}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "Shape-weighted accuracy during testing phase", "data": [{"dataset_name": "directed", "final_value": 0.5498, "best_value": 0.5498}, {"dataset_name": "undirected", "final_value": 0.5796, "best_value": 0.5796}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "Complexity-weighted accuracy during testing phase", "data": [{"dataset_name": "directed", "final_value": 0.5471, "best_value": 0.5471}, {"dataset_name": "undirected", "final_value": 0.5844, "best_value": 0.5844}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "synthetic", "final_value": 0.6506, "best_value": 0.6506}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "synthetic", "final_value": 0.6996, "best_value": 0.6996}]}, {"metric_name": "train color-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by color during training.", "data": [{"dataset_name": "synthetic", "final_value": 0.6647, "best_value": 0.6647}]}, {"metric_name": "train shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by shape during training.", "data": [{"dataset_name": "synthetic", "final_value": 0.6652, "best_value": 0.6652}]}, {"metric_name": "train complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by complexity during training.", "data": [{"dataset_name": "synthetic", "final_value": 0.6649, "best_value": 0.6649}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by color during validation.", "data": [{"dataset_name": "synthetic", "final_value": 0.4629, "best_value": 0.4629}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by shape during validation.", "data": [{"dataset_name": "synthetic", "final_value": 0.4732, "best_value": 0.4732}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by complexity during validation.", "data": [{"dataset_name": "synthetic", "final_value": 0.4675, "best_value": 0.4675}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value during testing.", "data": [{"dataset_name": "synthetic", "final_value": 0.6934, "best_value": 0.6934}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by color during testing.", "data": [{"dataset_name": "synthetic", "final_value": 0.4863, "best_value": 0.4863}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by shape during testing.", "data": [{"dataset_name": "synthetic", "final_value": 0.4976, "best_value": 0.4976}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by complexity during testing.", "data": [{"dataset_name": "synthetic", "final_value": 0.4914, "best_value": 0.4914}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is learning.", "data": [{"dataset_name": "A_train_B_val_C_test", "final_value": 0.6261, "best_value": 0.6261}, {"dataset_name": "AB_train_C_test", "final_value": 0.338, "best_value": 0.338}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, used for model tuning.", "data": [{"dataset_name": "A_train_B_val_C_test", "final_value": 0.7037, "best_value": 0.7037}, {"dataset_name": "AB_train_C_test", "final_value": 0.3001, "best_value": 0.3001}]}, {"metric_name": "training composite weighted accuracy", "lower_is_better": false, "description": "The composite weighted accuracy during training, measuring the model's performance.", "data": [{"dataset_name": "A_train_B_val_C_test", "final_value": 0.6354, "best_value": 0.6354}, {"dataset_name": "AB_train_C_test", "final_value": 0.886, "best_value": 0.886}]}, {"metric_name": "validation composite weighted accuracy", "lower_is_better": false, "description": "The composite weighted accuracy during validation, used for model tuning.", "data": [{"dataset_name": "A_train_B_val_C_test", "final_value": 0.5248, "best_value": 0.5248}, {"dataset_name": "AB_train_C_test", "final_value": 0.9195, "best_value": 0.9195}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value on the test dataset, indicating final model performance.", "data": [{"dataset_name": "A_train_B_val_C_test", "final_value": 0.7091, "best_value": 0.7091}, {"dataset_name": "AB_train_C_test", "final_value": 0.9208, "best_value": 0.9208}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy on the test dataset.", "data": [{"dataset_name": "A_train_B_val_C_test", "final_value": 0.5027, "best_value": 0.5027}, {"dataset_name": "AB_train_C_test", "final_value": 0.501, "best_value": 0.501}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy on the test dataset.", "data": [{"dataset_name": "A_train_B_val_C_test", "final_value": 0.502, "best_value": 0.502}, {"dataset_name": "AB_train_C_test", "final_value": 0.498, "best_value": 0.498}]}, {"metric_name": "test composite weighted accuracy", "lower_is_better": false, "description": "The composite weighted accuracy on the test dataset, measuring overall performance.", "data": [{"dataset_name": "A_train_B_val_C_test", "final_value": 0.5024, "best_value": 0.5024}, {"dataset_name": "AB_train_C_test", "final_value": 0.4996, "best_value": 0.4996}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Represents the error in prediction. Lower values indicate better performance.", "data": [{"dataset_name": "directed", "final_value": 0.7275, "best_value": 0.6988}, {"dataset_name": "undirected", "final_value": 0.6864, "best_value": 0.6631}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions weighted by color.", "data": [{"dataset_name": "directed", "final_value": 0.5088, "best_value": 0.5709}, {"dataset_name": "undirected", "final_value": 0.5614, "best_value": 0.5948}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions weighted by shape.", "data": [{"dataset_name": "directed", "final_value": 0.5, "best_value": 0.5628}, {"dataset_name": "undirected", "final_value": 0.5637, "best_value": 0.599}]}, {"metric_name": "complexity-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions weighted by complexity.", "data": [{"dataset_name": "directed", "final_value": 0.5048, "best_value": 0.5672}, {"dataset_name": "undirected", "final_value": 0.5624, "best_value": 0.5967}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Loss during training phase", "data": [{"dataset_name": "directed", "final_value": 0.6066, "best_value": 0.6066}, {"dataset_name": "undirected", "final_value": 0.5691, "best_value": 0.5691}]}, {"metric_name": "train color-weighted accuracy", "lower_is_better": false, "description": "Color-weighted accuracy during training phase", "data": [{"dataset_name": "directed", "final_value": 0.6952, "best_value": 0.6952}, {"dataset_name": "undirected", "final_value": 0.7494, "best_value": 0.7494}]}, {"metric_name": "train shape-weighted accuracy", "lower_is_better": false, "description": "Shape-weighted accuracy during training phase", "data": [{"dataset_name": "directed", "final_value": 0.6915, "best_value": 0.6915}, {"dataset_name": "undirected", "final_value": 0.7477, "best_value": 0.7477}]}, {"metric_name": "train complexity-weighted accuracy", "lower_is_better": false, "description": "Complexity-weighted accuracy during training phase", "data": [{"dataset_name": "directed", "final_value": 0.6935, "best_value": 0.6935}, {"dataset_name": "undirected", "final_value": 0.7486, "best_value": 0.7486}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss during validation phase", "data": [{"dataset_name": "directed", "final_value": 0.7014, "best_value": 0.7014}, {"dataset_name": "undirected", "final_value": 0.7008, "best_value": 0.7008}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "Color-weighted accuracy during validation phase", "data": [{"dataset_name": "directed", "final_value": 0.5101, "best_value": 0.5101}, {"dataset_name": "undirected", "final_value": 0.496, "best_value": 0.496}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Shape-weighted accuracy during validation phase", "data": [{"dataset_name": "directed", "final_value": 0.5084, "best_value": 0.5084}, {"dataset_name": "undirected", "final_value": 0.5012, "best_value": 0.5012}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "Complexity-weighted accuracy during validation phase", "data": [{"dataset_name": "directed", "final_value": 0.5093, "best_value": 0.5093}, {"dataset_name": "undirected", "final_value": 0.4984, "best_value": 0.4984}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Loss during testing phase", "data": [{"dataset_name": "directed", "final_value": 0.6941, "best_value": 0.6941}, {"dataset_name": "undirected", "final_value": 0.7048, "best_value": 0.7048}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "Color-weighted accuracy during testing phase", "data": [{"dataset_name": "directed", "final_value": 0.502, "best_value": 0.502}, {"dataset_name": "undirected", "final_value": 0.5279, "best_value": 0.5279}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "Shape-weighted accuracy during testing phase", "data": [{"dataset_name": "directed", "final_value": 0.5075, "best_value": 0.5075}, {"dataset_name": "undirected", "final_value": 0.5348, "best_value": 0.5348}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "Complexity-weighted accuracy during testing phase", "data": [{"dataset_name": "directed", "final_value": 0.5044, "best_value": 0.5044}, {"dataset_name": "undirected", "final_value": 0.531, "best_value": 0.531}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "directed", "final_value": 0.6107, "best_value": 0.6107}, {"dataset_name": "undirected", "final_value": 0.6189, "best_value": 0.6189}]}, {"metric_name": "train color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during training.", "data": [{"dataset_name": "directed", "final_value": 0.7105, "best_value": 0.7105}, {"dataset_name": "undirected", "final_value": 0.6857, "best_value": 0.6857}]}, {"metric_name": "train shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during training.", "data": [{"dataset_name": "directed", "final_value": 0.7104, "best_value": 0.7104}, {"dataset_name": "undirected", "final_value": 0.6888, "best_value": 0.6888}]}, {"metric_name": "train complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during training.", "data": [{"dataset_name": "directed", "final_value": 0.7104, "best_value": 0.7104}, {"dataset_name": "undirected", "final_value": 0.6871, "best_value": 0.6871}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "directed", "final_value": 0.7252, "best_value": 0.7252}, {"dataset_name": "undirected", "final_value": 0.6937, "best_value": 0.6937}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during validation.", "data": [{"dataset_name": "directed", "final_value": 0.4691, "best_value": 0.4691}, {"dataset_name": "undirected", "final_value": 0.5529, "best_value": 0.5529}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during validation.", "data": [{"dataset_name": "directed", "final_value": 0.4652, "best_value": 0.4652}, {"dataset_name": "undirected", "final_value": 0.5468, "best_value": 0.5468}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during validation.", "data": [{"dataset_name": "directed", "final_value": 0.4673, "best_value": 0.4673}, {"dataset_name": "undirected", "final_value": 0.5501, "best_value": 0.5501}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value during testing.", "data": [{"dataset_name": "directed", "final_value": 0.7015, "best_value": 0.7015}, {"dataset_name": "undirected", "final_value": 0.7113, "best_value": 0.7113}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during testing.", "data": [{"dataset_name": "directed", "final_value": 0.5129, "best_value": 0.5129}, {"dataset_name": "undirected", "final_value": 0.4791, "best_value": 0.4791}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during testing.", "data": [{"dataset_name": "directed", "final_value": 0.4975, "best_value": 0.4975}, {"dataset_name": "undirected", "final_value": 0.4754, "best_value": 0.4754}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during testing.", "data": [{"dataset_name": "directed", "final_value": 0.5061, "best_value": 0.5061}, {"dataset_name": "undirected", "final_value": 0.4774, "best_value": 0.4774}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, false, false, true, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_loss_curve.png", "../../logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_CWA_curve.png", "../../logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_CmpWA_curve.png", "../../logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_test_summary.png"], ["../../logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_loss_curve.png", "../../logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_CWA_curve.png", "../../logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_CmpWA_curve.png", "../../logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_loss_curve.png", "../../logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_CWA_curve.png", "../../logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_CmpWA_curve.png", "../../logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_loss.png", "../../logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_CWA.png", "../../logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_SWA.png", "../../logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_CmpWA.png", "../../logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_confusion_matrix.png"], [], ["../../logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_loss_curve.png", "../../logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_cmpWA_curve.png", "../../logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_CWA_curve.png", "../../logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_e87d461daa8e4d95853808a7c8f4269c_proc_1497854/loss_curves_synthetic_or_SPR.png", "../../logs/0-run/experiment_results/experiment_e87d461daa8e4d95853808a7c8f4269c_proc_1497854/CmpWA_curves_synthetic_or_SPR.png", "../../logs/0-run/experiment_results/experiment_e87d461daa8e4d95853808a7c8f4269c_proc_1497854/test_metrics_comparison_synthetic_or_SPR.png"], ["../../logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_loss_curve.png", "../../logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_CmpWA_curve.png", "../../logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_CWA_curve.png", "../../logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_f77b4bc2f1fa400b933187f41812e33c_proc_1497857/MultiSyntheticGeneralization_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f77b4bc2f1fa400b933187f41812e33c_proc_1497857/MultiSyntheticGeneralization_CmpWA_curves.png", "../../logs/0-run/experiment_results/experiment_f77b4bc2f1fa400b933187f41812e33c_proc_1497857/MultiSyntheticGeneralization_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_4bb6a8bc04f348989d102ec490b4e9cf_proc_1497855/loss_curves_synthetic_or_SPR.png", "../../logs/0-run/experiment_results/experiment_4bb6a8bc04f348989d102ec490b4e9cf_proc_1497855/CmpWA_curves_synthetic_or_SPR.png", "../../logs/0-run/experiment_results/experiment_4bb6a8bc04f348989d102ec490b4e9cf_proc_1497855/test_metrics_comparison_synthetic_or_SPR.png"], ["../../logs/0-run/experiment_results/experiment_613dadca68994d989063e7b4ab2110df_proc_1497854/loss_curves_synthetic_or_SPR.png", "../../logs/0-run/experiment_results/experiment_613dadca68994d989063e7b4ab2110df_proc_1497854/CmpWA_curves_synthetic_or_SPR.png", "../../logs/0-run/experiment_results/experiment_613dadca68994d989063e7b4ab2110df_proc_1497854/test_metrics_comparison_synthetic_or_SPR.png"], ["../../logs/0-run/experiment_results/experiment_f36f779507014ac1a13a55f7a65d8911_proc_1497856/loss_curves_synthetic_or_SPR.png", "../../logs/0-run/experiment_results/experiment_f36f779507014ac1a13a55f7a65d8911_proc_1497856/CmpWA_curves_synthetic_or_SPR.png", "../../logs/0-run/experiment_results/experiment_f36f779507014ac1a13a55f7a65d8911_proc_1497856/test_metrics_comparison_synthetic_or_SPR.png"], ["../../logs/0-run/experiment_results/seed_aggregation_2957f1769f6c4d889668f7ee02091dfc/agg_loss_curves_synthetic_or_SPR.png", "../../logs/0-run/experiment_results/seed_aggregation_2957f1769f6c4d889668f7ee02091dfc/agg_CmpWA_curves_synthetic_or_SPR.png", "../../logs/0-run/experiment_results/seed_aggregation_2957f1769f6c4d889668f7ee02091dfc/agg_test_metrics_synthetic_or_SPR.png"]], "plot_paths": [["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_loss_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_CWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_SWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_CmpWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_test_summary.png"], ["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_loss_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_CWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_SWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_CmpWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_test_metrics.png"], ["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_loss_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_CWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_SWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_CmpWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_confusion_matrix.png"], ["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_loss.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_CWA.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_SWA.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_CmpWA.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_confusion_matrix.png"], [], ["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_loss_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_cmpWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_CWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_SWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_confusion_matrix.png"], ["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e87d461daa8e4d95853808a7c8f4269c_proc_1497854/loss_curves_synthetic_or_SPR.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e87d461daa8e4d95853808a7c8f4269c_proc_1497854/CmpWA_curves_synthetic_or_SPR.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e87d461daa8e4d95853808a7c8f4269c_proc_1497854/test_metrics_comparison_synthetic_or_SPR.png"], ["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_loss_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_CmpWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_CWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_SWA_curve.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_confusion_matrix.png"], ["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f77b4bc2f1fa400b933187f41812e33c_proc_1497857/MultiSyntheticGeneralization_loss_curves.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f77b4bc2f1fa400b933187f41812e33c_proc_1497857/MultiSyntheticGeneralization_CmpWA_curves.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f77b4bc2f1fa400b933187f41812e33c_proc_1497857/MultiSyntheticGeneralization_test_metrics.png"], ["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4bb6a8bc04f348989d102ec490b4e9cf_proc_1497855/loss_curves_synthetic_or_SPR.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4bb6a8bc04f348989d102ec490b4e9cf_proc_1497855/CmpWA_curves_synthetic_or_SPR.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4bb6a8bc04f348989d102ec490b4e9cf_proc_1497855/test_metrics_comparison_synthetic_or_SPR.png"], ["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_613dadca68994d989063e7b4ab2110df_proc_1497854/loss_curves_synthetic_or_SPR.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_613dadca68994d989063e7b4ab2110df_proc_1497854/CmpWA_curves_synthetic_or_SPR.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_613dadca68994d989063e7b4ab2110df_proc_1497854/test_metrics_comparison_synthetic_or_SPR.png"], ["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f36f779507014ac1a13a55f7a65d8911_proc_1497856/loss_curves_synthetic_or_SPR.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f36f779507014ac1a13a55f7a65d8911_proc_1497856/CmpWA_curves_synthetic_or_SPR.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f36f779507014ac1a13a55f7a65d8911_proc_1497856/test_metrics_comparison_synthetic_or_SPR.png"], ["experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_2957f1769f6c4d889668f7ee02091dfc/agg_loss_curves_synthetic_or_SPR.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_2957f1769f6c4d889668f7ee02091dfc/agg_CmpWA_curves_synthetic_or_SPR.png", "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_2957f1769f6c4d889668f7ee02091dfc/agg_test_metrics_synthetic_or_SPR.png"]], "plot_analyses": [[{"analysis": "The training loss decreases steadily, indicating that the model is learning effectively on the training data. However, the validation loss remains relatively flat and even increases slightly, suggesting overfitting. The model may not generalize well to unseen data, and regularization techniques or additional hyperparameter tuning might be necessary.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_loss_curve.png"}, {"analysis": "The Color-Weighted Accuracy (CWA) for the training set improves consistently over epochs, showing that the model is capturing color-based relationships in the training data. However, the validation CWA peaks early and then declines, further indicating overfitting and poor generalization to the validation set.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_CWA_curve.png"}, {"analysis": "Similar to the CWA, the Shape-Weighted Accuracy (SWA) for the training set increases steadily, reflecting the model's ability to learn shape-based dependencies in the training data. The validation SWA, however, follows a declining trend after an initial peak, again pointing to overfitting.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_SWA_curve.png"}, {"analysis": "The Combined Weighted Accuracy (CmpWA) shows the same trends as the CWA and SWA metrics. The training accuracy improves consistently, but the validation accuracy declines after an initial increase, reinforcing the observation of overfitting.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_CmpWA_curve.png"}, {"analysis": "The test set performance metrics reveal that the model achieves a loss of 0.695, which is relatively high, and the CWA (0.591), SWA (0.562), and CmpWA (0.578) are below the SOTA benchmarks (CWA: 65.0%, SWA: 70.0%). This indicates that the model fails to achieve the desired performance and suggests that further optimization or architectural changes are needed.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_b17edab791f14c288925c03b997cd4d7_proc_1494370/SPR_RGCN_test_summary.png"}], [{"analysis": "The training loss decreases steadily over the epochs, indicating that the model is learning from the training data. However, the validation loss initially decreases slightly but then increases from around epoch 6 onwards, suggesting overfitting. This implies that the model is failing to generalize well to unseen data, and regularization techniques or early stopping might be needed to mitigate this issue.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_loss_curve.png"}, {"analysis": "The Color-Weighted Accuracy (CWA) on the training set improves consistently over the epochs, demonstrating that the model is learning to classify based on color-related features in the training data. However, the validation CWA remains stagnant and even slightly decreases after epoch 6, indicating poor generalization to unseen validation data. This could be attributed to overfitting or insufficient representation of color-related patterns in the validation set.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_CWA_curve.png"}, {"analysis": "The Shape-Weighted Accuracy (SWA) on the training set shows a similar trend to the CWA, with consistent improvement over the epochs. However, the validation SWA follows a declining trend, further emphasizing the overfitting issue and the model's inability to generalize well to shape-related features in the validation data.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_SWA_curve.png"}, {"analysis": "The Complexity-Weighted Accuracy (CmpWA) on the training set improves steadily, indicating that the model is learning to handle more complex relationships in the data. However, the validation CmpWA shows a declining trend similar to the CWA and SWA, reinforcing the observation that the model struggles to generalize to unseen data and handle complexity effectively in the validation set.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_CmpWA_curve.png"}, {"analysis": "The bar chart shows that the test set performances for CWA, SWA, and CmpWA are all at 0.45, which is relatively low and consistent across the metrics. This suggests that the model's performance on the test set is not satisfactory and highlights the need for further tuning, better regularization, or alternative approaches to improve generalization and overall accuracy.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3e6d9b87af2e4c8db558ab9323163637_proc_1497854/synthetic_SingleRelation_GCN_test_metrics.png"}], [{"analysis": "The plot shows the training and validation loss over epochs for the NoSeqEdges setup. The training loss decreases steadily, indicating that the model is learning from the data. However, the validation loss initially decreases but starts to plateau and slightly increase after epoch 6. This suggests potential overfitting, as the model's performance on unseen data does not improve despite further training.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_loss_curve.png"}, {"analysis": "The plot displays the Color-Weighted Accuracy (CWA) for training and validation sets over epochs. The training accuracy improves consistently, but the validation accuracy fluctuates significantly and does not show a clear upward trend. This indicates that the model might struggle to generalize the learned patterns to the validation set.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_CWA_curve.png"}, {"analysis": "The plot shows the Shape-Weighted Accuracy (SWA) for training and validation sets over epochs. Similar to CWA, the training accuracy improves steadily, but the validation accuracy exhibits high variability and lacks a consistent upward trend. This further supports the observation of generalization issues.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_SWA_curve.png"}, {"analysis": "The plot illustrates the Composite Weighted Accuracy (CmpWA) for training and validation sets over epochs. The training accuracy improves steadily, but the validation accuracy follows a fluctuating pattern, similar to the CWA and SWA plots. This reinforces the hypothesis that the model's generalization capabilities need improvement.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_CmpWA_curve.png"}, {"analysis": "The confusion matrix indicates that the model struggles with classifying certain classes. There is a significant number of misclassifications, particularly for one of the classes, which suggests an imbalance in the model's ability to distinguish between different categories. This could be due to insufficient training data for certain classes or inherent biases in the model.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_874f6ec47c324ba2b684b2ccf2de3978_proc_1497855/NoSeqEdges_confusion_matrix.png"}], [{"analysis": "The first plot shows the training and validation loss curves over epochs. The training loss decreases steadily, indicating that the model is learning from the data. However, the validation loss remains relatively flat and even increases slightly towards the end, suggesting potential overfitting or insufficient generalization to the validation set. The gap between training and validation losses also widens over epochs, which further supports this observation.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_loss.png"}, {"analysis": "The second plot displays the Color-Weighted Accuracy (CWA) for training and validation datasets over epochs. While the training accuracy improves consistently, the validation accuracy exhibits fluctuations, indicating instability in the model's performance on the validation set. The gap between training and validation CWA widens, suggesting overfitting to the training data.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_CWA.png"}, {"analysis": "The third plot depicts Shape-Weighted Accuracy (SWA) for training and validation datasets. Similar to the CWA plot, the training SWA improves steadily, while the validation SWA fluctuates and does not show consistent improvement. This behavior further supports the hypothesis of overfitting and challenges in generalizing to the validation set.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_SWA.png"}, {"analysis": "The fourth plot shows Complexity-Weighted Accuracy (CmpWA) for training and validation datasets. The training CmpWA improves steadily, but the validation CmpWA fluctuates significantly. The instability in validation performance indicates that the model struggles to generalize to unseen data, particularly for more complex sequences.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_CmpWA.png"}, {"analysis": "The confusion matrix provides insight into the model's classification performance. The model shows a bias towards certain classes, as evidenced by the imbalance in correct predictions across classes. The relatively high number of misclassifications (off-diagonal elements) indicates room for improvement in the model's ability to distinguish between different classes.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ea82a1e8919b4a78945a6d4121683b36_proc_1497856/no_color_edge_SPR_RGCN_confusion_matrix.png"}], [], [{"analysis": "The plot shows the training and validation loss over 8 epochs. The training loss decreases steadily, indicating that the model is learning from the training data. However, the validation loss does not follow the same trend; it fluctuates and even increases after epoch 6. This suggests potential overfitting, as the model performs well on training data but struggles to generalize to validation data.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_loss_curve.png"}, {"analysis": "This plot illustrates the Complexity-Weighted Accuracy (CWA) for training and validation datasets. While the training accuracy improves steadily, the validation accuracy shows significant fluctuations, particularly dropping sharply around epoch 4 before recovering. This behavior indicates instability in generalization and suggests that the model may not be robust to variations in the validation set.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_cmpWA_curve.png"}, {"analysis": "The Color-Weighted Accuracy (CWA) plot shows similar trends to the Complexity-Weighted Accuracy plot. The training accuracy improves consistently, while the validation accuracy fluctuates significantly. This further supports the observation of overfitting, as the model captures patterns in the training data but fails to generalize consistently to the validation set.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_CWA_curve.png"}, {"analysis": "The Shape-Weighted Accuracy (SWA) plot aligns with the patterns observed in the previous accuracy metrics. Training accuracy shows steady improvement, but validation accuracy experiences sharp drops and recoveries. This reinforces the need for better regularization techniques or architectural adjustments to improve generalization.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_SWA_curve.png"}, {"analysis": "The confusion matrix for the test set reveals that the model struggles with one of the classes. While it predicts one class reasonably well (69 correct predictions vs. 11 incorrect), it performs poorly on the other class (65 incorrect predictions vs. 5 correct). This class imbalance or model bias could be a significant factor limiting overall performance and should be addressed.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6c25bd281098419b922c16cf95221e6e_proc_1497855/synthetic_confusion_matrix.png"}], [{"analysis": "This plot shows the loss curves for directed and undirected graph variants on the synthetic_or_SPR dataset. The directed graph variant exhibits a consistent decrease in training loss, indicating effective learning. However, the validation loss for the directed variant remains relatively stable, with slight fluctuations, suggesting potential overfitting. The undirected graph variant also shows a steady decrease in training loss, but its validation loss fluctuates more significantly, indicating less stable generalization.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e87d461daa8e4d95853808a7c8f4269c_proc_1497854/loss_curves_synthetic_or_SPR.png"}, {"analysis": "This plot presents the Complexity-weighted Accuracy (CmpWA) curves for directed and undirected graph variants. The directed graph variant achieves higher CmpWA on the training set compared to the undirected variant, demonstrating better learning of complex relationships. However, the validation accuracy for both variants is inconsistent, with the undirected variant performing slightly worse overall. This suggests that both models struggle with generalization, with the directed variant showing a marginal advantage.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e87d461daa8e4d95853808a7c8f4269c_proc_1497854/CmpWA_curves_synthetic_or_SPR.png"}, {"analysis": "This bar chart compares test metrics (loss, CWA, SWA, and CmpWA) for directed and undirected graph variants. The directed variant achieves slightly lower test loss, indicating better overall optimization. For CWA and SWA, the undirected variant outperforms the directed variant, suggesting better performance on color- and shape-weighted evaluations. In contrast, the directed variant achieves higher CmpWA, indicating stronger performance on complexity-weighted tasks. This highlights a trade-off between different evaluation metrics depending on the graph variant used.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e87d461daa8e4d95853808a7c8f4269c_proc_1497854/test_metrics_comparison_synthetic_or_SPR.png"}], [{"analysis": "This plot shows the training and validation loss over 14 epochs. The training loss decreases consistently, indicating that the model is learning from the training data. However, the validation loss remains relatively flat and higher than the training loss, suggesting potential overfitting or insufficient generalization to the validation set.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_loss_curve.png"}, {"analysis": "This plot shows the Complexity-Weighted Accuracy (CmpWA) for both training and validation sets over 14 epochs. The training accuracy improves steadily, reflecting the model's increasing ability to learn the task. However, the validation accuracy increases more slowly and plateaus, indicating limited generalization to unseen data.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_CmpWA_curve.png"}, {"analysis": "This plot depicts the Color-Weighted Accuracy (CWA) for both training and validation sets over 14 epochs. The training accuracy improves significantly, showing the model's capability to learn color-based rules. The validation accuracy improves slightly but remains substantially lower than the training accuracy, suggesting challenges in generalizing color-based rule learning.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_CWA_curve.png"}, {"analysis": "This plot illustrates the Shape-Weighted Accuracy (SWA) for both training and validation sets over 14 epochs. The training accuracy increases steadily, showing the model's ability to learn shape-based rules. The validation accuracy shows slight improvement but remains significantly lower than the training accuracy, highlighting potential overfitting or difficulty in generalizing shape-based rule learning.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_SWA_curve.png"}, {"analysis": "This confusion matrix provides a breakdown of the model's predictions versus the true labels. The diagonal elements represent correct predictions, while off-diagonal elements indicate misclassifications. The model shows moderate performance, with a noticeable number of misclassifications in both classes. This suggests room for improvement in the model's ability to distinguish between the classes.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7fdd5ed9a76248eb935ae841065e0340_proc_1497856/synthetic_confusion_matrix.png"}], [{"analysis": "This plot shows the cross-entropy loss for training and validation data across epochs. Both configurations, A_train_B_val_C_test and AB_train_C_test, display a consistent decrease in loss over the epochs, indicating effective learning. However, the validation loss for A_train_B_val_C_test exhibits more fluctuations compared to AB_train_C_test, suggesting potential overfitting or instability in the former configuration. AB_train_C_test demonstrates smoother loss curves, implying better generalization and stability.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f77b4bc2f1fa400b933187f41812e33c_proc_1497857/MultiSyntheticGeneralization_loss_curves.png"}, {"analysis": "This plot illustrates the Composite Weighted Accuracy (CmpWA) across epochs for training and validation data. The AB_train_C_test configuration consistently achieves higher accuracy compared to A_train_B_val_C_test, especially in validation, which shows a steady upward trend. The A_train_B_val_C_test validation accuracy curve fluctuates significantly, suggesting less stable performance. Overall, AB_train_C_test appears to generalize better and achieve higher accuracy.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f77b4bc2f1fa400b933187f41812e33c_proc_1497857/MultiSyntheticGeneralization_CmpWA_curves.png"}, {"analysis": "This bar chart compares the final test scores of Color-Weighted Accuracy (CWA), Shape-Weighted Accuracy (SWA), and Composite Weighted Accuracy (CmpWA) for two configurations: A_train_B_val_C_test and AB_train_C_test. Both configurations achieve similar scores across all metrics, indicating comparable performance. However, the slight edge in stability and generalization observed in the AB_train_C_test configuration in earlier plots might make it a more reliable choice for deployment.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f77b4bc2f1fa400b933187f41812e33c_proc_1497857/MultiSyntheticGeneralization_test_metrics.png"}], [{"analysis": "This plot compares the training and validation loss for directed and undirected graph representations over epochs. Both directed and undirected training losses decrease steadily, with the undirected variant achieving slightly lower loss values. However, validation losses for both variants remain relatively constant, with the directed variant showing slightly higher loss. This indicates potential overfitting, especially for the undirected variant, as the training loss decreases significantly without corresponding improvements in validation loss.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4bb6a8bc04f348989d102ec490b4e9cf_proc_1497855/loss_curves_synthetic_or_SPR.png"}, {"analysis": "This plot illustrates the Complexity-Weighted Accuracy (CmpWA) for training and validation sets over epochs. Training accuracy increases steadily for both directed and undirected variants, with the undirected variant achieving higher values. However, validation accuracy remains relatively flat for both variants, with slight oscillations. This suggests that while the models learn well on the training data, their generalization capability to unseen validation data is limited. The undirected variant's higher training accuracy aligns with its lower training loss but does not translate to better validation performance.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4bb6a8bc04f348989d102ec490b4e9cf_proc_1497855/CmpWA_curves_synthetic_or_SPR.png"}, {"analysis": "This plot compares test performance metrics, including loss, Color-Weighted Accuracy (CWA), Shape-Weighted Accuracy (SWA), and Complexity-Weighted Accuracy (CmpWA), for directed and undirected graph representations. The directed variant achieves lower test loss than the undirected variant, indicating better fit to the test data. However, the undirected variant outperforms the directed variant on all accuracy metrics (CWA, SWA, and CmpWA). This suggests that while the directed variant minimizes loss more effectively, the undirected variant captures the task's structural complexity better, leading to higher accuracy scores.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4bb6a8bc04f348989d102ec490b4e9cf_proc_1497855/test_metrics_comparison_synthetic_or_SPR.png"}], [{"analysis": "This plot shows the cross-entropy loss for two variants of the model: 'directed' and 'undirected'. The training loss for both variants decreases steadily, indicating successful learning. However, the validation loss behaves differently. For the 'undirected' variant, validation loss initially decreases but then plateaus and slightly increases, suggesting potential overfitting. The 'directed' variant shows a less pronounced increase in validation loss, indicating better generalization compared to the 'undirected' variant.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_613dadca68994d989063e7b4ab2110df_proc_1497854/loss_curves_synthetic_or_SPR.png"}, {"analysis": "This plot tracks Complexity-Weighted Accuracy (CmpWA) across training epochs for the two model variants. Both 'directed' and 'undirected' variants show improvements in training accuracy, with the 'undirected' variant achieving the highest training accuracy. However, validation accuracy for both variants is much lower, with the 'directed' variant showing slightly better performance. The gap between training and validation accuracy suggests overfitting, particularly for the 'undirected' variant.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_613dadca68994d989063e7b4ab2110df_proc_1497854/CmpWA_curves_synthetic_or_SPR.png"}, {"analysis": "This bar chart compares the test performance metrics for the 'directed' and 'undirected' model variants. Both variants achieve similar loss values. For CWA and SWA metrics, the 'undirected' variant slightly outperforms the 'directed' variant, while the CmpWA scores are nearly identical. These results suggest that while the 'undirected' variant may capture some nuances better, the overall performance difference is minimal.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_613dadca68994d989063e7b4ab2110df_proc_1497854/test_metrics_comparison_synthetic_or_SPR.png"}], [{"analysis": "The loss curves show that the directed variant achieves faster and more consistent convergence on the training set compared to the undirected variant. However, the validation loss for the directed variant increases slightly after an initial decrease, suggesting some degree of overfitting. The undirected variant exhibits a slower decrease in training loss and a more stable validation loss, indicating better generalization but slower learning.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f36f779507014ac1a13a55f7a65d8911_proc_1497856/loss_curves_synthetic_or_SPR.png"}, {"analysis": "The complexity-weighted accuracy (CmpWA) curves reveal that the directed variant achieves higher accuracy on the training set throughout the epochs compared to the undirected variant. However, the validation accuracy for the directed variant fluctuates significantly, again indicating potential overfitting. The undirected variant shows a more stable but lower validation accuracy, suggesting better generalization with less overfitting.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f36f779507014ac1a13a55f7a65d8911_proc_1497856/CmpWA_curves_synthetic_or_SPR.png"}, {"analysis": "The test metrics comparison indicates that the directed variant outperforms the undirected variant on Color-Weighted Accuracy (CWA), Shape-Weighted Accuracy (SWA), and Complexity-Weighted Accuracy (CmpWA). However, the loss values for both variants are nearly identical, indicating that the directed variant's superior performance on weighted accuracy metrics is not reflected in the overall loss. This suggests that the directed variant may be better at capturing the nuanced relationships in the data, but further investigation into the loss function's alignment with the evaluation metrics is warranted.", "plot_path": "experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f36f779507014ac1a13a55f7a65d8911_proc_1497856/test_metrics_comparison_synthetic_or_SPR.png"}], []], "vlm_feedback_summary": ["The experimental results indicate that while the model learns effectively on the\ntraining data, it suffers from significant overfitting, as evidenced by the\ndivergence between training and validation metrics. Additionally, the test set\nperformance falls short of the SOTA benchmarks, highlighting the need for\nfurther optimization and potential redesign of the model architecture or\ntraining strategy.", "The plots indicate significant overfitting, as evidenced by the divergence\nbetween training and validation metrics across loss, CWA, SWA, and CmpWA. While\nthe model learns effectively on the training set, it fails to generalize to\nvalidation and test sets. This highlights the need for better regularization,\nearly stopping, or alternative model architectures to improve generalization and\nperformance on unseen data.", "The plots reveal that while the model learns effectively on the training set, it\nstruggles to generalize to the validation set, as evidenced by fluctuating\nvalidation metrics and a slight increase in validation loss after a few epochs.\nThe confusion matrix highlights a potential issue with class imbalance or\ndifficulty in distinguishing between classes. These observations suggest that\nfurther efforts are needed to enhance the model's generalization capabilities\nand address class-specific performance issues.", "The plots reveal that while the model learns effectively on the training data,\nits performance on the validation set is unstable and suggests overfitting. The\nwidening gaps between training and validation metrics (loss and accuracy)\nindicate insufficient generalization. The confusion matrix highlights\nclassification biases and significant misclassification rates, emphasizing the\nneed for further optimization and regularization.", "[]", "The results indicate steady learning on the training set across all metrics but\nhighlight significant generalization issues on the validation set. Validation\nmetrics fluctuate and do not consistently improve, pointing to overfitting. The\nconfusion matrix suggests class imbalance or bias, further impacting\nperformance. Regularization, architectural adjustments, or addressing class\nimbalance may improve generalization and overall performance.", "The plots reveal that the directed graph variant generally performs better in\nterms of optimization and complexity-weighted accuracy (CmpWA), while the\nundirected variant excels in color- and shape-weighted accuracy (CWA and SWA).\nHowever, both variants face challenges with validation stability and\ngeneralization.", "The experimental plots indicate that the model is learning effectively on the\ntraining data but struggles to generalize to the validation set. This is evident\nfrom the divergence between training and validation metrics across all loss and\naccuracy plots. The confusion matrix further highlights the model's moderate\nperformance, with significant misclassification rates. These results suggest the\nneed for strategies to improve generalization, such as regularization, data\naugmentation, or architectural adjustments.", "The analysis highlights that the AB_train_C_test configuration demonstrates\nbetter generalization and stability compared to A_train_B_val_C_test. This is\nevident from the smoother loss curves and higher validation accuracy. While\nfinal test scores are similar, AB_train_C_test appears to be a more robust\nchoice.", "The plots provide insights into the performance of directed and undirected graph\nrepresentations in the SPR task. Training loss and accuracy improve steadily,\nbut validation metrics remain relatively flat, indicating limited\ngeneralization. The undirected variant shows better accuracy across metrics\ndespite higher loss, suggesting it captures structural relationships more\neffectively, while the directed variant minimizes loss more efficiently.", "The plots reveal key insights about the performance of the 'directed' and\n'undirected' model variants. The 'directed' variant demonstrates better\ngeneralization and slightly lower overfitting, while the 'undirected' variant\nachieves higher training accuracy but shows signs of overfitting. The test\nmetrics comparison indicates marginal differences between the two variants, with\nthe 'undirected' variant slightly outperforming in some metrics.", "The directed variant demonstrates faster learning and better performance on\nweighted accuracy metrics but shows signs of overfitting, while the undirected\nvariant exhibits better generalization but slower learning. Further optimization\nand regularization are needed to balance these trade-offs.", "[]"], "exec_time": [5.721504211425781, 5.99726414680481, 2.9732000827789307, 2.978341817855835, 5.754414796829224, 4.052672863006592, 4.094498157501221, 3.8131206035614014, 28.22548794746399, 11.366606950759888, 5.167499542236328, 4.984937429428101, null], "exec_time_feedback": ["Implementation works but runs too quickly (0.10 minutes).We have up to 60\nminutes available for each experiment.Make sure to scale up the experiment by\nincreasing the number of epochs, using a larger model, or working with bigger\ndatasets.Given that the current execution time is {exec_time_minutes:.2f}\nminutes, think about how changing the number of epochs to run, or using a larger\nmodel, or working with bigger datasets to runwill affect the execution time, and\nmake sure to scale up the experiment accordingly.", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[]"], ["[]"], ["[]"], ["[]"], [], ["[]"], ["[\"synthetic_or_SPR\"]"], ["[]"], ["['AB_train_C_test']"], ["[\"synthetic_or_SPR\"]"], ["['synthetic_or_SPR']"], ["[\"synthetic_or_SPR\"]"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- setup ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    run = experiment_data.get(\"SPR_RGCN\", {})\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    run = {}\n\n\n# helper\ndef save_close(fig_name):\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, fig_name))\n    plt.close()\n\n\n# ---------- 1) loss curve ----------\ntry:\n    plt.figure()\n    ep = run[\"epochs\"]\n    plt.plot(ep, run[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(ep, run[\"losses\"][\"val\"], \"--\", label=\"val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_RGCN \u2013 Training vs Validation Loss\")\n    plt.legend()\n    save_close(\"SPR_RGCN_loss_curve.png\")\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# ---------- 2-4) metric curves ----------\nfor metric in [\"CWA\", \"SWA\", \"CmpWA\"]:\n    try:\n        plt.figure()\n        ep = run[\"epochs\"]\n        plt.plot(ep, run[\"metrics\"][\"train\"][metric], label=\"train\")\n        plt.plot(ep, run[\"metrics\"][\"val\"][metric], \"--\", label=\"val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(metric)\n        plt.title(f\"SPR_RGCN \u2013 Training vs Validation {metric}\")\n        plt.legend()\n        save_close(f\"SPR_RGCN_{metric}_curve.png\")\n    except Exception as e:\n        print(f\"Error creating {metric} curve: {e}\")\n        plt.close()\n\n# ---------- 5) test metrics summary ----------\ntry:\n    plt.figure()\n    names = [\"Loss\", \"CWA\", \"SWA\", \"CmpWA\"]\n    values = [run[\"test_metrics\"][k] for k in [\"loss\", \"CWA\", \"SWA\", \"CmpWA\"]]\n    bars = plt.bar(names, values, color=\"skyblue\")\n    for b, v in zip(bars, values):\n        plt.text(\n            b.get_x() + b.get_width() / 2,\n            b.get_height(),\n            f\"{v:.3f}\",\n            ha=\"center\",\n            va=\"bottom\",\n        )\n    plt.title(\"SPR_RGCN \u2013 Test Set Performance\")\n    save_close(\"SPR_RGCN_test_summary.png\")\nexcept Exception as e:\n    print(f\"Error creating test summary plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ------------------------------------------------------------\nfor model_name, model_dict in experiment_data.items():\n    for dataset_name, d in model_dict.items():\n        losses = d[\"losses\"]\n        metrics = d[\"metrics\"]\n        test_metrics = d[\"test_metrics\"]\n\n        # 1) Loss curve ----------------------------------------------------\n        try:\n            plt.figure()\n            epochs = range(1, len(losses[\"train\"]) + 1)\n            plt.plot(epochs, losses[\"train\"], label=\"train\")\n            plt.plot(epochs, losses[\"val\"], label=\"val\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.title(f\"{dataset_name} | {model_name} - Training vs Validation Loss\")\n            plt.legend()\n            fname = f\"{dataset_name}_{model_name}_loss_curve.png\"\n            plt.savefig(os.path.join(working_dir, fname), dpi=150)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss curve: {e}\")\n            plt.close()\n\n        # Helper to plot metric histories ---------------------------------\n        def plot_metric(metric_key, full_name):\n            try:\n                plt.figure()\n                plt.plot(epochs, metrics[\"train\"][metric_key], label=\"train\")\n                plt.plot(epochs, metrics[\"val\"][metric_key], label=\"val\")\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(full_name)\n                plt.title(f\"{dataset_name} | {model_name} - {full_name} over Epochs\")\n                plt.legend()\n                fname = f\"{dataset_name}_{model_name}_{metric_key}_curve.png\"\n                plt.savefig(os.path.join(working_dir, fname), dpi=150)\n                plt.close()\n            except Exception as e_inner:\n                print(f\"Error creating {metric_key} curve: {e_inner}\")\n                plt.close()\n\n        # 2) CWA curve\n        plot_metric(\"CWA\", \"Color-Weighted Accuracy\")\n        # 3) SWA curve\n        plot_metric(\"SWA\", \"Shape-Weighted Accuracy\")\n        # 4) CmpWA curve\n        plot_metric(\"CmpWA\", \"Complexity-Weighted Accuracy\")\n\n        # 5) Test metrics bar chart ---------------------------------------\n        try:\n            plt.figure()\n            bars = [\"CWA\", \"SWA\", \"CmpWA\"]\n            values = [test_metrics[\"CWA\"], test_metrics[\"SWA\"], test_metrics[\"CmpWA\"]]\n            plt.bar(bars, values, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n            plt.ylim(0, 1)\n            plt.title(f\"{dataset_name} | {model_name} - Test Weighted Accuracies\")\n            for i, v in enumerate(values):\n                plt.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n            fname = f\"{dataset_name}_{model_name}_test_metrics.png\"\n            plt.savefig(os.path.join(working_dir, fname), dpi=150)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating test metrics bar chart: {e}\")\n            plt.close()\n\n        # Print final test metrics ----------------------------------------\n        print(\n            f\"{dataset_name} | {model_name} TEST -> \"\n            f'Loss: {test_metrics[\"loss\"]:.4f}, '\n            f'CWA: {test_metrics[\"CWA\"]:.4f}, '\n            f'SWA: {test_metrics[\"SWA\"]:.4f}, '\n            f'CmpWA: {test_metrics[\"CmpWA\"]:.4f}'\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set up working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# assume only one dataset entry (per provided code)\ndataset_key = next(iter(experiment_data.keys()), None)\nif dataset_key is None:\n    print(\"No experiment data found.\")\n    exit()\n\ndset = experiment_data[dataset_key][\"dataset\"]\nepochs = dset[\"epochs\"]\nloss_train, loss_val = dset[\"losses\"][\"train\"], dset[\"losses\"][\"val\"]\nmetrics = dset[\"metrics\"]\npreds, gts = np.array(dset.get(\"predictions\", [])), np.array(\n    dset.get(\"ground_truth\", [])\n)\n\n# 1. Loss curves\ntry:\n    plt.figure()\n    plt.plot(epochs, loss_train, label=\"Train\")\n    plt.plot(epochs, loss_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(f\"{dataset_key}: Training vs Validation Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{dataset_key}_loss_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n\n# helper to plot each metric curve\ndef plot_metric(metric_name):\n    try:\n        plt.figure()\n        plt.plot(epochs, metrics[\"train\"][metric_name], label=\"Train\")\n        plt.plot(epochs, metrics[\"val\"][metric_name], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(metric_name)\n        plt.title(f\"{dataset_key}: {metric_name} over Epochs\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_{metric_name}_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating {metric_name} curve: {e}\")\n        plt.close()\n\n\n# 2-4. Metric curves\nfor m in [\"CWA\", \"SWA\", \"CmpWA\"]:\n    plot_metric(m)\n\n# 5. Confusion matrix (if predictions exist)\ntry:\n    if preds.size and gts.size:\n        classes = sorted(set(gts) | set(preds))\n        cm = np.zeros((len(classes), len(classes)), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(f\"{dataset_key}: Confusion Matrix\")\n        for i in range(len(classes)):\n            for j in range(len(classes)):\n                plt.text(\n                    j,\n                    i,\n                    cm[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"red\" if cm[i, j] else \"black\",\n                )\n        fname = os.path.join(working_dir, f\"{dataset_key}_confusion_matrix.png\")\n        plt.savefig(fname)\n        plt.close()\n    else:\n        print(\"Predictions / ground truth not found \u2013 skipping confusion matrix.\")\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# print stored test metrics\ntest_metrics = experiment_data[dataset_key][\"dataset\"].get(\"test_metrics\", {})\nprint(\"Test metrics:\", test_metrics)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# working directory for plots\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------ #\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment_data.npy: {e}\")\n    exit(0)\n\n\n# ------------------------------------------------------------------ #\n# helper to fetch nested dict safely\ndef get(d, *keys, default=None):\n    for k in keys:\n        d = d.get(k, {})\n    return d if d else default\n\n\nds_name = \"no_color_edge\"\nmodel_name = \"SPR_RGCN\"\nexp = get(experiment_data, ds_name, model_name, default={})\nepochs = exp.get(\"epochs\", [])\nloss_tr = get(exp, \"losses\", \"train\", default=[])\nloss_val = get(exp, \"losses\", \"val\", default=[])\ncwa_tr = get(exp, \"metrics\", \"train\", \"CWA\", default=[])\ncwa_val = get(exp, \"metrics\", \"val\", \"CWA\", default=[])\nswa_tr = get(exp, \"metrics\", \"train\", \"SWA\", default=[])\nswa_val = get(exp, \"metrics\", \"val\", \"SWA\", default=[])\ncpx_tr = get(exp, \"metrics\", \"train\", \"CmpWA\", default=[])\ncpx_val = get(exp, \"metrics\", \"val\", \"CmpWA\", default=[])\ny_true = exp.get(\"ground_truth\", [])\ny_pred = exp.get(\"predictions\", [])\n\n# ------------------------------------------------------------------ #\n# 1. Loss curve\ntry:\n    plt.figure()\n    plt.plot(epochs, loss_tr, label=\"Train\")\n    plt.plot(epochs, loss_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(f\"{ds_name}: {model_name} Loss Curves\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{ds_name}_{model_name}_loss.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# 2. CWA curve\ntry:\n    plt.figure()\n    plt.plot(epochs, cwa_tr, label=\"Train\")\n    plt.plot(epochs, cwa_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Color-Weighted Accuracy\")\n    plt.title(f\"{ds_name}: {model_name} CWA Curves\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"{ds_name}_{model_name}_CWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CWA plot: {e}\")\n    plt.close()\n\n# 3. SWA curve\ntry:\n    plt.figure()\n    plt.plot(epochs, swa_tr, label=\"Train\")\n    plt.plot(epochs, swa_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Shape-Weighted Accuracy\")\n    plt.title(f\"{ds_name}: {model_name} SWA Curves\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"{ds_name}_{model_name}_SWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA plot: {e}\")\n    plt.close()\n\n# 4. Complexity-Weighted Accuracy curve\ntry:\n    plt.figure()\n    plt.plot(epochs, cpx_tr, label=\"Train\")\n    plt.plot(epochs, cpx_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Complexity-Weighted Accuracy\")\n    plt.title(f\"{ds_name}: {model_name} CmpWA Curves\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"{ds_name}_{model_name}_CmpWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CmpWA plot: {e}\")\n    plt.close()\n\n# 5. Confusion matrix heat-map (max 5 plots total)\ntry:\n    import itertools\n\n    num_cls = max(max(y_true, default=0), max(y_pred, default=0)) + 1\n    cm = np.zeros((num_cls, num_cls), dtype=int)\n    for t, p in zip(y_true, y_pred):\n        cm[t, p] += 1\n    plt.figure()\n    plt.imshow(cm, cmap=\"Blues\")\n    plt.colorbar()\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(f\"{ds_name}: {model_name} Confusion Matrix\")\n    for i, j in itertools.product(range(num_cls), range(num_cls)):\n        plt.text(\n            j,\n            i,\n            cm[i, j],\n            ha=\"center\",\n            va=\"center\",\n            color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n            fontsize=8,\n        )\n    plt.savefig(\n        os.path.join(working_dir, f\"{ds_name}_{model_name}_confusion_matrix.png\")\n    )\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# print test metrics\ntest_metrics = exp.get(\"test_metrics\", {})\nprint(\"Test Metrics:\")\nfor k, v in test_metrics.items():\n    print(f\"  {k}: {v:.4f}\" if isinstance(v, float) else f\"  {k}: {v}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\n\nWe will load the stored experiment_data, pick the ConstantNodeFeatures\u2013SPR entry, and extract epochs, train/val losses, and the three weighted accuracies. For each of the four quantities (loss, CWA, SWA, CmpWA) we generate one line plot that overlays training and validation curves (where applicable), use clear titles and save into working_dir with descriptive filenames. All plotting is wrapped in individual try-except blocks, figures are always closed, and we print the test-set metrics after plotting. Only data present in the .npy file are accessed; if a key is missing the corresponding plot is skipped gracefully. This yields at most four figures, satisfying the \u201c\u22645\u201d constraint, and gives a concise visual summary of the experiment.", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load metrics\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nif experiment_data:\n    model_key = next(iter(experiment_data))  # 'Shallow_GNN_1hop'\n    dataset_key = next(iter(experiment_data[model_key]))  # 'synthetic' or real\n    ed = experiment_data[model_key][dataset_key]\n\n    epochs = ed[\"epochs\"]\n    tr_loss = ed[\"losses\"][\"train\"]\n    vl_loss = ed[\"losses\"][\"val\"]\n    tr_cwa = ed[\"metrics\"][\"train\"][\"CWA\"]\n    vl_cwa = ed[\"metrics\"][\"val\"][\"CWA\"]\n    tr_swa = ed[\"metrics\"][\"train\"][\"SWA\"]\n    vl_swa = ed[\"metrics\"][\"val\"][\"SWA\"]\n    tr_cmp = ed[\"metrics\"][\"train\"][\"CmpWA\"]\n    vl_cmp = ed[\"metrics\"][\"val\"][\"CmpWA\"]\n    preds = np.array(ed[\"predictions\"])\n    gtruth = np.array(ed[\"ground_truth\"])\n    n_cls = len(np.unique(gtruth))\n\n    # 1) loss curves\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_loss, label=\"Train\")\n        plt.plot(epochs, vl_loss, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dataset_key}: Training vs Validation Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # 2) complexity weighted accuracy\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_cmp, label=\"Train\")\n        plt.plot(epochs, vl_cmp, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cmp-Weighted Accuracy\")\n        plt.title(f\"{dataset_key}: Complexity-Weighted Accuracy (Train vs Validation)\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_cmpWA_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating cmpWA plot: {e}\")\n        plt.close()\n\n    # 3) color weighted accuracy\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_cwa, label=\"Train\")\n        plt.plot(epochs, vl_cwa, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Color-Weighted Accuracy\")\n        plt.title(f\"{dataset_key}: Color-Weighted Accuracy (Train vs Validation)\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_CWA_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CWA plot: {e}\")\n        plt.close()\n\n    # 4) shape weighted accuracy\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_swa, label=\"Train\")\n        plt.plot(epochs, vl_swa, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(f\"{dataset_key}: Shape-Weighted Accuracy (Train vs Validation)\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_SWA_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot: {e}\")\n        plt.close()\n\n    # 5) confusion matrix (optional, keeps total \u22645)\n    if n_cls <= 10:\n        try:\n            cm = np.zeros((n_cls, n_cls), dtype=int)\n            for t, p in zip(gtruth, preds):\n                cm[t, p] += 1\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(f\"{dataset_key}: Confusion Matrix (Test)\")\n            for i in range(n_cls):\n                for j in range(n_cls):\n                    plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n            fname = os.path.join(working_dir, f\"{dataset_key}_confusion_matrix.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating confusion matrix plot: {e}\")\n            plt.close()\n\n    # print final test metrics\n    print(\"Test metrics:\", ed.get(\"test_metrics\", {}))\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    variants = [\"directed\", \"undirected\"]\n    # ---------- FIGURE 1: loss curves ----------\n    try:\n        plt.figure()\n        for v in variants:\n            losses_tr = experiment_data[\"edge_direction\"][v][\"losses\"][\"train\"]\n            losses_vl = experiment_data[\"edge_direction\"][v][\"losses\"][\"val\"]\n            epochs = np.arange(1, len(losses_tr) + 1)\n            plt.plot(epochs, losses_tr, label=f\"{v}-train\")\n            plt.plot(epochs, losses_vl, linestyle=\"--\", label=f\"{v}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"Loss Curves per Variant (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"loss_curves_synthetic_or_SPR.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ---------- FIGURE 2: CmpWA curves ----------\n    try:\n        plt.figure()\n        for v in variants:\n            cpx_tr = experiment_data[\"edge_direction\"][v][\"metrics\"][\"train\"][\"CmpWA\"]\n            cpx_vl = experiment_data[\"edge_direction\"][v][\"metrics\"][\"val\"][\"CmpWA\"]\n            epochs = np.arange(1, len(cpx_tr) + 1)\n            plt.plot(epochs, cpx_tr, label=f\"{v}-train\")\n            plt.plot(epochs, cpx_vl, linestyle=\"--\", label=f\"{v}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(\"CmpWA Curves per Variant (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"CmpWA_curves_synthetic_or_SPR.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CmpWA plot: {e}\")\n        plt.close()\n\n    # ---------- FIGURE 3: test metrics bar ----------\n    try:\n        metrics_names = [\"loss\", \"CWA\", \"SWA\", \"CmpWA\"]\n        x = np.arange(len(metrics_names))\n        width = 0.35\n        plt.figure()\n        for idx, v in enumerate(variants):\n            tm = [\n                experiment_data[\"edge_direction\"][v][\"test_metrics\"][m]\n                for m in metrics_names\n            ]\n            plt.bar(x + idx * width, tm, width=width, label=v)\n        plt.xticks(x + width / 2, metrics_names)\n        plt.ylabel(\"Score\")\n        plt.title(\"Test Metrics Comparison (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, \"test_metrics_comparison_synthetic_or_SPR.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar plot: {e}\")\n        plt.close()\n\n    # ---------- print test metrics ----------\n    for v in variants:\n        print(\n            f\"Test metrics for {v}: {experiment_data['edge_direction'][v]['test_metrics']}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ------------------------------------------------------------------------\n# Identify model key and dataset key automatically\nif experiment_data:\n    model_key = next(iter(experiment_data))\n    dataset_key = next(iter(experiment_data[model_key]))\n    store = experiment_data[model_key][dataset_key]\nelse:\n    store = None\n\nif store is None:\n    print(\"No experiment data found \u2014 nothing to plot.\")\nelse:\n    epochs = store.get(\"epochs\", [])\n    losses_tr = store[\"losses\"].get(\"train\", [])\n    losses_val = store[\"losses\"].get(\"val\", [])\n    metrics = store[\"metrics\"]\n    test_metrics = store.get(\"test_metrics\", {})\n    y_pred = np.array(store.get(\"predictions\", []))\n    y_true = np.array(store.get(\"ground_truth\", []))\n\n    # 1) Loss curve -------------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, losses_tr, label=\"Train\")\n        plt.plot(epochs, losses_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dataset_key}: Training vs Validation Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset_key}_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # Helper to plot any metric ------------------------------------------\n    def plot_metric(metric_name, ylabel):\n        try:\n            plt.figure()\n            plt.plot(epochs, metrics[\"train\"][metric_name], label=\"Train\")\n            plt.plot(epochs, metrics[\"val\"][metric_name], label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(ylabel)\n            plt.title(f\"{dataset_key}: {metric_name} over Epochs\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dataset_key}_{metric_name}_curve.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating {metric_name} curve: {e}\")\n            plt.close()\n\n    # 2) CmpWA curve\n    plot_metric(\"CmpWA\", \"Complexity-Weighted Accuracy\")\n\n    # 3) CWA curve\n    plot_metric(\"CWA\", \"Color-Weighted Accuracy\")\n\n    # 4) SWA curve\n    plot_metric(\"SWA\", \"Shape-Weighted Accuracy\")\n\n    # 5) Confusion Matrix -------------------------------------------------\n    try:\n        if y_pred.size and y_true.size:\n            num_cls = max(y_true.max(), y_pred.max()) + 1\n            cm = np.zeros((num_cls, num_cls), dtype=int)\n            for t, p in zip(y_true, y_pred):\n                cm[t, p] += 1\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(f\"{dataset_key}: Confusion Matrix\")\n            for i in range(num_cls):\n                for j in range(num_cls):\n                    plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n            fname = os.path.join(working_dir, f\"{dataset_key}_confusion_matrix.png\")\n            plt.savefig(fname)\n            plt.close()\n        else:\n            print(\"Skipped confusion matrix: no prediction data found.\")\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\n    # --------------------------------------------------------------------\n    # Print stored test metrics\n    if test_metrics:\n        print(\"Test-set metrics:\")\n        for k, v in test_metrics.items():\n            print(f\"  {k}: {v:.4f}\" if isinstance(v, float) else f\"  {k}: {v}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --------------------------------------------------------------------- #\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp_dict = experiment_data[\"MultiSyntheticGeneralization\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp_dict = {}\n\n# Prepare ordered experiment names for reproducible colors/labels\nexp_names = list(exp_dict.keys())\ncolors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\"]\n\n# --------------------------------------------------------------------- #\n# 1) Loss curves\ntry:\n    plt.figure()\n    for idx, name in enumerate(exp_names):\n        train_loss = exp_dict[name][\"losses\"][\"train\"]\n        val_loss = exp_dict[name][\"losses\"][\"val\"]\n        epochs = np.arange(1, len(train_loss) + 1)\n        plt.plot(\n            epochs,\n            train_loss,\n            color=colors[idx % len(colors)],\n            label=f\"{name}-train\",\n            linewidth=1.5,\n        )\n        plt.plot(\n            epochs,\n            val_loss,\n            color=colors[idx % len(colors)],\n            label=f\"{name}-val\",\n            linestyle=\"--\",\n            linewidth=1.5,\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"MultiSyntheticGeneralization: Loss Curves (Train vs Validation)\")\n    plt.legend(fontsize=\"small\")\n    save_path = os.path.join(\n        working_dir, \"MultiSyntheticGeneralization_loss_curves.png\"\n    )\n    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# --------------------------------------------------------------------- #\n# 2) CmpWA curves\ntry:\n    plt.figure()\n    for idx, name in enumerate(exp_names):\n        train_cmp = exp_dict[name][\"CmpWA_train\"]\n        val_cmp = exp_dict[name][\"CmpWA_val\"]\n        epochs = np.arange(1, len(train_cmp) + 1)\n        plt.plot(\n            epochs,\n            train_cmp,\n            color=colors[idx % len(colors)],\n            label=f\"{name}-train\",\n            linewidth=1.5,\n        )\n        plt.plot(\n            epochs,\n            val_cmp,\n            color=colors[idx % len(colors)],\n            label=f\"{name}-val\",\n            linestyle=\"--\",\n            linewidth=1.5,\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Composite Weighted Accuracy\")\n    plt.title(\"MultiSyntheticGeneralization: CmpWA Curves (Train vs Validation)\")\n    plt.legend(fontsize=\"small\")\n    save_path = os.path.join(\n        working_dir, \"MultiSyntheticGeneralization_CmpWA_curves.png\"\n    )\n    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CmpWA curves: {e}\")\n    plt.close()\n\n# --------------------------------------------------------------------- #\n# 3) Test weighted-accuracy bar chart\ntry:\n    metrics = [\"CWA\", \"SWA\", \"CmpWA\"]\n    x = np.arange(len(metrics))\n    width = 0.35\n    plt.figure()\n    for idx, name in enumerate(exp_names):\n        vals = [exp_dict[name][\"test_metrics\"][m] for m in metrics]\n        plt.bar(\n            x + idx * width,\n            vals,\n            width=width,\n            color=colors[idx % len(colors)],\n            label=name,\n        )\n    plt.xticks(x + width * (len(exp_names) - 1) / 2, metrics)\n    plt.ylabel(\"Score\")\n    plt.ylim(0, 1.05)\n    plt.title(\"MultiSyntheticGeneralization: Test Weighted Accuracies\")\n    plt.legend(fontsize=\"small\")\n    save_path = os.path.join(\n        working_dir, \"MultiSyntheticGeneralization_test_metrics.png\"\n    )\n    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metric bars: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    variants = [\"directed\", \"undirected\"]\n    # ---------- FIGURE 1: loss curves ----------\n    try:\n        plt.figure()\n        for v in variants:\n            losses_tr = experiment_data[\"edge_direction\"][v][\"losses\"][\"train\"]\n            losses_vl = experiment_data[\"edge_direction\"][v][\"losses\"][\"val\"]\n            epochs = np.arange(1, len(losses_tr) + 1)\n            plt.plot(epochs, losses_tr, label=f\"{v}-train\")\n            plt.plot(epochs, losses_vl, linestyle=\"--\", label=f\"{v}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"Loss Curves per Variant (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"loss_curves_synthetic_or_SPR.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ---------- FIGURE 2: CmpWA curves ----------\n    try:\n        plt.figure()\n        for v in variants:\n            cpx_tr = experiment_data[\"edge_direction\"][v][\"metrics\"][\"train\"][\"CmpWA\"]\n            cpx_vl = experiment_data[\"edge_direction\"][v][\"metrics\"][\"val\"][\"CmpWA\"]\n            epochs = np.arange(1, len(cpx_tr) + 1)\n            plt.plot(epochs, cpx_tr, label=f\"{v}-train\")\n            plt.plot(epochs, cpx_vl, linestyle=\"--\", label=f\"{v}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(\"CmpWA Curves per Variant (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"CmpWA_curves_synthetic_or_SPR.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CmpWA plot: {e}\")\n        plt.close()\n\n    # ---------- FIGURE 3: test metrics bar ----------\n    try:\n        metrics_names = [\"loss\", \"CWA\", \"SWA\", \"CmpWA\"]\n        x = np.arange(len(metrics_names))\n        width = 0.35\n        plt.figure()\n        for idx, v in enumerate(variants):\n            tm = [\n                experiment_data[\"edge_direction\"][v][\"test_metrics\"][m]\n                for m in metrics_names\n            ]\n            plt.bar(x + idx * width, tm, width=width, label=v)\n        plt.xticks(x + width / 2, metrics_names)\n        plt.ylabel(\"Score\")\n        plt.title(\"Test Metrics Comparison (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, \"test_metrics_comparison_synthetic_or_SPR.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar plot: {e}\")\n        plt.close()\n\n    # ---------- print test metrics ----------\n    for v in variants:\n        print(\n            f\"Test metrics for {v}: {experiment_data['edge_direction'][v]['test_metrics']}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    variants = [\"directed\", \"undirected\"]\n    # ---------- FIGURE 1: loss curves ----------\n    try:\n        plt.figure()\n        for v in variants:\n            losses_tr = experiment_data[\"edge_direction\"][v][\"losses\"][\"train\"]\n            losses_vl = experiment_data[\"edge_direction\"][v][\"losses\"][\"val\"]\n            epochs = np.arange(1, len(losses_tr) + 1)\n            plt.plot(epochs, losses_tr, label=f\"{v}-train\")\n            plt.plot(epochs, losses_vl, linestyle=\"--\", label=f\"{v}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"Loss Curves per Variant (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"loss_curves_synthetic_or_SPR.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ---------- FIGURE 2: CmpWA curves ----------\n    try:\n        plt.figure()\n        for v in variants:\n            cpx_tr = experiment_data[\"edge_direction\"][v][\"metrics\"][\"train\"][\"CmpWA\"]\n            cpx_vl = experiment_data[\"edge_direction\"][v][\"metrics\"][\"val\"][\"CmpWA\"]\n            epochs = np.arange(1, len(cpx_tr) + 1)\n            plt.plot(epochs, cpx_tr, label=f\"{v}-train\")\n            plt.plot(epochs, cpx_vl, linestyle=\"--\", label=f\"{v}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(\"CmpWA Curves per Variant (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"CmpWA_curves_synthetic_or_SPR.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CmpWA plot: {e}\")\n        plt.close()\n\n    # ---------- FIGURE 3: test metrics bar ----------\n    try:\n        metrics_names = [\"loss\", \"CWA\", \"SWA\", \"CmpWA\"]\n        x = np.arange(len(metrics_names))\n        width = 0.35\n        plt.figure()\n        for idx, v in enumerate(variants):\n            tm = [\n                experiment_data[\"edge_direction\"][v][\"test_metrics\"][m]\n                for m in metrics_names\n            ]\n            plt.bar(x + idx * width, tm, width=width, label=v)\n        plt.xticks(x + width / 2, metrics_names)\n        plt.ylabel(\"Score\")\n        plt.title(\"Test Metrics Comparison (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, \"test_metrics_comparison_synthetic_or_SPR.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar plot: {e}\")\n        plt.close()\n\n    # ---------- print test metrics ----------\n    for v in variants:\n        print(\n            f\"Test metrics for {v}: {experiment_data['edge_direction'][v]['test_metrics']}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    variants = [\"directed\", \"undirected\"]\n    # ---------- FIGURE 1: loss curves ----------\n    try:\n        plt.figure()\n        for v in variants:\n            losses_tr = experiment_data[\"edge_direction\"][v][\"losses\"][\"train\"]\n            losses_vl = experiment_data[\"edge_direction\"][v][\"losses\"][\"val\"]\n            epochs = np.arange(1, len(losses_tr) + 1)\n            plt.plot(epochs, losses_tr, label=f\"{v}-train\")\n            plt.plot(epochs, losses_vl, linestyle=\"--\", label=f\"{v}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"Loss Curves per Variant (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"loss_curves_synthetic_or_SPR.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ---------- FIGURE 2: CmpWA curves ----------\n    try:\n        plt.figure()\n        for v in variants:\n            cpx_tr = experiment_data[\"edge_direction\"][v][\"metrics\"][\"train\"][\"CmpWA\"]\n            cpx_vl = experiment_data[\"edge_direction\"][v][\"metrics\"][\"val\"][\"CmpWA\"]\n            epochs = np.arange(1, len(cpx_tr) + 1)\n            plt.plot(epochs, cpx_tr, label=f\"{v}-train\")\n            plt.plot(epochs, cpx_vl, linestyle=\"--\", label=f\"{v}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(\"CmpWA Curves per Variant (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"CmpWA_curves_synthetic_or_SPR.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CmpWA plot: {e}\")\n        plt.close()\n\n    # ---------- FIGURE 3: test metrics bar ----------\n    try:\n        metrics_names = [\"loss\", \"CWA\", \"SWA\", \"CmpWA\"]\n        x = np.arange(len(metrics_names))\n        width = 0.35\n        plt.figure()\n        for idx, v in enumerate(variants):\n            tm = [\n                experiment_data[\"edge_direction\"][v][\"test_metrics\"][m]\n                for m in metrics_names\n            ]\n            plt.bar(x + idx * width, tm, width=width, label=v)\n        plt.xticks(x + width / 2, metrics_names)\n        plt.ylabel(\"Score\")\n        plt.title(\"Test Metrics Comparison (synthetic_or_SPR dataset)\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, \"test_metrics_comparison_synthetic_or_SPR.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metric bar plot: {e}\")\n        plt.close()\n\n    # ---------- print test metrics ----------\n    for v in variants:\n        print(\n            f\"Test metrics for {v}: {experiment_data['edge_direction'][v]['test_metrics']}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n###############################################################################\n# --------------------------- load all experiments ----------------------------\n###############################################################################\ntry:\n    experiment_data_path_list = [\n        \"experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4bb6a8bc04f348989d102ec490b4e9cf_proc_1497855/experiment_data.npy\",\n        \"experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_613dadca68994d989063e7b4ab2110df_proc_1497854/experiment_data.npy\",\n        \"experiments/2025-08-30_20-55-31_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f36f779507014ac1a13a55f7a65d8911_proc_1497856/experiment_data.npy\",\n    ]\n    all_experiment_data = []\n    for p in experiment_data_path_list:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p)\n        exp_data = np.load(full_path, allow_pickle=True).item()\n        all_experiment_data.append(exp_data)\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    all_experiment_data = []\n\n# Abort early if nothing was loaded\nif not all_experiment_data:\n    exit()\n\n\n###############################################################################\n# -------------------------- helper: aggregate runs ---------------------------\n###############################################################################\ndef collect_curve(field_path, variant):\n    \"\"\"\n    field_path - list of nested keys e.g. ['losses', 'train']\n    returns stacked array (n_runs, n_epochs_aligned)\n    \"\"\"\n    curves = []\n    for exp in all_experiment_data:\n        data = exp[\"edge_direction\"][variant]\n        # drill-down\n        d = data\n        for k in field_path:\n            d = d[k]\n        curves.append(np.asarray(d, dtype=float))\n    min_len = min(len(c) for c in curves)\n    curves = np.stack([c[:min_len] for c in curves], axis=0)  # (n_runs, n_epochs)\n    return curves\n\n\ndef mean_sem(arr, axis=0):\n    mean = arr.mean(axis=axis)\n    sem = arr.std(axis=axis, ddof=1) / np.sqrt(arr.shape[axis])\n    return mean, sem\n\n\nvariants = [\"directed\", \"undirected\"]\n\n###############################################################################\n# ----------------------------- Figure 1: Loss --------------------------------\n###############################################################################\ntry:\n    plt.figure()\n    for v in variants:\n        tr_curve = collect_curve([\"losses\", \"train\"], v)\n        vl_curve = collect_curve([\"losses\", \"val\"], v)\n\n        mean_tr, sem_tr = mean_sem(tr_curve)\n        mean_vl, sem_vl = mean_sem(vl_curve)\n\n        epochs = np.arange(1, len(mean_tr) + 1)\n\n        plt.plot(epochs, mean_tr, label=f\"{v}-train (mean)\")\n        plt.fill_between(epochs, mean_tr - sem_tr, mean_tr + sem_tr, alpha=0.2)\n\n        plt.plot(epochs, mean_vl, linestyle=\"--\", label=f\"{v}-val (mean)\")\n        plt.fill_between(epochs, mean_vl - sem_vl, mean_vl + sem_vl, alpha=0.2)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"Aggregated Loss Curves per Variant (synthetic_or_SPR dataset)\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"agg_loss_curves_synthetic_or_SPR.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated loss curve: {e}\")\n    plt.close()\n\n###############################################################################\n# ---------------------------- Figure 2: CmpWA --------------------------------\n###############################################################################\ntry:\n    plt.figure()\n    for v in variants:\n        tr_curve = collect_curve([\"metrics\", \"train\", \"CmpWA\"], v)\n        vl_curve = collect_curve([\"metrics\", \"val\", \"CmpWA\"], v)\n\n        mean_tr, sem_tr = mean_sem(tr_curve)\n        mean_vl, sem_vl = mean_sem(vl_curve)\n\n        epochs = np.arange(1, len(mean_tr) + 1)\n\n        plt.plot(epochs, mean_tr, label=f\"{v}-train (mean)\")\n        plt.fill_between(epochs, mean_tr - sem_tr, mean_tr + sem_tr, alpha=0.2)\n\n        plt.plot(epochs, mean_vl, linestyle=\"--\", label=f\"{v}-val (mean)\")\n        plt.fill_between(epochs, mean_vl - sem_vl, mean_vl + sem_vl, alpha=0.2)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Complexity-Weighted Accuracy\")\n    plt.title(\"Aggregated CmpWA Curves per Variant (synthetic_or_SPR dataset)\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"agg_CmpWA_curves_synthetic_or_SPR.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated CmpWA curve: {e}\")\n    plt.close()\n\n###############################################################################\n# -------------------------- Figure 3: Test metrics ---------------------------\n###############################################################################\ntry:\n    metric_names = [\"loss\", \"CWA\", \"SWA\", \"CmpWA\"]\n    x = np.arange(len(metric_names))\n    width = 0.35\n\n    plt.figure()\n    for idx, v in enumerate(variants):\n        # gather per-run values for each metric\n        vals = {m: [] for m in metric_names}\n        for exp in all_experiment_data:\n            tm = exp[\"edge_direction\"][v][\"test_metrics\"]\n            for m in metric_names:\n                vals[m].append(tm[m])\n        # compute mean & sem\n        means = [np.mean(vals[m]) for m in metric_names]\n        sems = [np.std(vals[m], ddof=1) / np.sqrt(len(vals[m])) for m in metric_names]\n\n        plt.bar(x + idx * width, means, width=width, yerr=sems, capsize=4, label=v)\n\n        # print table-style output\n        printable = \", \".join(\n            [\n                f\"{m}: {mu:.4f} \u00b1 {se:.4f}\"\n                for m, mu, se in zip(metric_names, means, sems)\n            ]\n        )\n        print(f\"Aggregated test metrics for {v}: {printable}\")\n\n    plt.xticks(x + width / 2, metric_names)\n    plt.ylabel(\"Score\")\n    plt.title(\"Aggregated Test Metrics Comparison (synthetic_or_SPR dataset)\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"agg_test_metrics_synthetic_or_SPR.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated test metric bar plot: {e}\")\n    plt.close()\n"], "plot_plan": ["We load the saved experiment_data.npy, extract the single run stored under key 'SPR_RGCN', and read its recorded epochs, losses, and three weighted-accuracy curves. Four line plots are produced: one for loss and one each for CWA, SWA, and CmpWA, with training and validation curves super-imposed. A fifth bar plot summarizes the final test metrics (loss, CWA, SWA, CmpWA) to give a compact end-of-training snapshot. Each figure is generated inside its own try-except block, labelled clearly, saved to working_dir with the dataset and plot type in the filename, and the figure is closed afterwards. All plotting relies solely on the contents of experiment_data.npy\u2014no values are fabricated. The entire script starts with the required imports and working directory creation. No additional stylistic packages are used, respecting the requirement for basic matplotlib only. Finally, the script prints any loading or plotting errors so that failures do not halt subsequent plots.", "We will load experiment_data.npy, loop over each stored model and dataset, and extract losses, CWA, SWA, CmpWA histories plus the final test metrics. Five plots will be produced per dataset-model pair: (1) train-vs-validation loss, (2-4) the three weighted accuracies, and (5) a bar chart of the final test CWA, SWA, and CmpWA. Each figure is created inside its own try-except block, saved under a descriptive name containing the dataset and plot type, and immediately closed. We cap the total number of figures to these five, so no epoch subsampling is required. All plots are written to the predefined working_dir, using plain matplotlib without custom styles. After plotting, the script prints the test metrics so that the caller can quickly check performance. This satisfies all plotting guidelines and keeps the code concise and robust.", "We will load experiment_data.npy, detect the sole dataset key, and pull out the epochs, loss histories, and metric histories for both training and validation splits. We then generate up to five separate plots, each inside its own try-except block and saved to the working directory: (1) loss curves, (2-4) CWA, SWA, and CmpWA curves, and (5) a confusion-matrix heat-map comparing ground-truth vs. predictions on the test set. Every figure is given a clear title that names the dataset and the content, closed after saving, and errors are caught and reported without aborting subsequent plots. Finally, the script prints the stored test metrics so users can verify numerical performance alongside the visuals.", "We load the saved experiment_data.npy, extract training/validation losses and metric histories, and the final test metrics. Five separate figures will be produced: (1) train vs. validation loss curves, (2) Color-Weighted Accuracy curves, (3) Shape-Weighted Accuracy curves, (4) Complexity-Weighted Accuracy curves, and (5) a simple confusion-matrix heat-map of ground-truth vs. prediction on the test set. Each figure is wrapped in its own try-except block, titled clearly with dataset/model information, saved under descriptive names inside working_dir, and the figure is closed whether or not an error occurs. Only data that exists in the numpy file are used\u2014no synthetic values are generated. If experiment_data.npy is missing or malformed, the script reports the error and exits gracefully. After plotting, the script prints the recorded test loss and weighted accuracies for quick inspection. This approach gives a compact yet complete visual summary of the experiment while adhering strictly to the provided plotting guidelines.", "", "We load the saved experiment_data.npy, detect the single dataset present, and extract per-epoch arrays for training/validation losses and the three weighted-accuracy metrics.  Four figures are produced (\u22645 as required): (1) loss curves; (2) Cmp-weighted accuracy; (3) color-weighted accuracy; (4) shape-weighted accuracy\u2014each showing train and validation lines versus epoch.  Every figure is created inside its own try-except block, given a clear title that contains the dataset name and a descriptive subtitle (\u201cTrain vs Validation\u201d), saved to the working directory with a descriptive file name, and then closed.  We also build a simple confusion-matrix heat-map from test predictions vs. ground-truth, but only if number of classes \u226410, keeping the total figures \u22645.  No fabricated values are used; everything comes directly from experiment_data.  Finally, the script prints the stored test metrics so users can verify numerical performance alongside the visualizations.  All matplotlib figures are closed to free resources, and code remains concise and self-contained.", "We will load the saved experiment_data.npy, extract per-epoch losses and metrics for the two edge-direction variants, and visualise three key aspects.  \nFirst, we create a single figure that overlays training and validation loss curves for both directed and undirected runs, helping us compare convergence.  \nSecond, we plot the per-epoch Complexity-Weighted Accuracy (CmpWA) curves for train/val, again for both variants, giving insight into performance on more complex sequences.  \nThird, we build a grouped bar chart that summarises the final test\u2010set scores (Loss, CWA, SWA, CmpWA) for each variant so the best configuration is immediately clear.  \nAll plots are wrapped in individual try-except blocks, saved into the working directory with descriptive names, properly titled, and the figures are closed afterwards.  \nWe respect the five-figure limit (we only create three), use only data present in the .npy file, and rely solely on basic Matplotlib.  \nFinally, we print the test metrics dictionary so the numerical values are visible in the notebook/console alongside the saved plots.", "We will load the serialized `experiment_data.npy`, automatically detect the single (model, dataset) combination it contains, and pull out epochs, loss histories, metric histories, and test\u2010set predictions. Five plots are generated, each wrapped in its own try-except block so that any single failure will not stop the rest: (1) training/validation loss curve; (2) training/validation Complexity-Weighted Accuracy (CmpWA); (3) Color-Weighted Accuracy (CWA); (4) Shape-Weighted Accuracy (SWA); (5) a confusion-matrix heat-map built from stored test predictions vs ground-truth. Each figure is titled clearly, saved in `working_dir` with descriptive filenames that contain both the dataset name and plot type, and then closed to free resources. We only visualize values that truly exist in the loaded dictionary, and we skip a plot gracefully if a required key is missing. Finally, the code prints the test-set metrics that were stored during training so users can see them in the notebook/log without opening the images.", "We will load the stored experiment_data dictionary, extract the two runs under the \u2018MultiSyntheticGeneralization\u2019 key, and draw three standard figures: (1) train/val loss over epochs, (2) train/val composite-weighted accuracy (CmpWA) over epochs, and (3) a grouped bar chart comparing the final test CWA, SWA and CmpWA for the two runs.  Each figure is wrapped in its own try-except so one failure does not stop the rest, and every figure is saved to the working directory with an informative name that includes the dataset and plot type.  Titles explicitly mention the dataset; subtitles (legends or suptitles) distinguish train vs validation and the two experiment settings.  The code uses only matplotlib and numpy, closes every figure, and limits itself to three plots to stay within the five-figure cap.  No extra data are fabricated\u2014everything comes from experiment_data.npy.  Finally, the script ends silently after saving the PNGs.", null, null, null, null], "ablation_name": [null, "Single-Relation Graph (No Relation Types)", "No-Sequential-Edge Graphs", "No-Color-Edge Graphs", "Constant-Node-Features (Token-Blind Graph)", "Shallow-GNN (1-hop) Ablation", "Undirected-Edge Graphs", "One-Hot Node Features (Frozen Vocabulary Encoding)", "Multi-Synthetic Dataset Generalization Ablation", null, null, null, null], "hyperparam_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["The script will load the saved numpy dictionary from the working directory,\nidentify the model entry (here only \u201cSPR_RGCN\u201d), and then gather the best or\nfinal values for every recorded metric, separately for the training, validation\nand test splits.   For training we take values from the last epoch; for\nvalidation we take the epoch that achieved the lowest validation loss; the test\nmetrics are stored directly under the \u201ctest_metrics\u201d key.   The code then prints\neach dataset name followed by clearly-labeled metric/value pairs.   Everything\nis executed at top level so the file runs immediately when invoked.", "Below is a compact script that immediately loads the saved NumPy file, walks\nthrough its nested structure, and prints the final value of every stored metric\nwith explicit, self-descriptive labels for each dataset it finds.", "The script loads the saved NumPy dictionary from the working directory, iterates\nover every dataset key (e.g., \u201cNoSeqEdges\u201d), and extracts the final\ntraining/validation losses and accuracies as well as the test metrics that are\nstored separately. It then prints the dataset name once, followed by clearly-\nlabeled lines for each metric (\u201ctrain loss,\u201d \u201cvalidation CWA,\u201d \u201ctest CmpWA,\u201d\netc.), always reporting the last value recorded (which corresponds to the final\nepoch or the single test evaluation). All logic is placed at top level so the\nfile executes immediately when run, and no figures are generated.", "The script loads the saved numpy dictionary, navigates through its hierarchical\nstructure, and prints a concise summary of the final (last-epoch) train and\nvalidation metrics together with the single stored test metrics. It labels each\nblock clearly by dataset (\u201ctrain dataset\u201d, \u201cvalidation dataset\u201d, \u201ctest dataset\u201d)\nand each value by its full metric name (e.g., \u201ctrain CWA\u201d). The code executes\nimmediately when run and follows the required file-path and structural\nconstraints.", "Below is a small utility that immediately loads the stored numpy dictionary,\nfinds the required \u201cfinal\u201d or \u201cbest\u201d values for every metric, and prints them\nwith clear, explicit names for the training, validation, and test splits. The\nbest validation metrics are chosen at the epoch that achieved the lowest\nvalidation loss, while training metrics are taken from the last epoch (i.e., the\nfinal values recorded). Test metrics are stored once, so they are reported\ndirectly.", "The script loads the saved experiment_data.npy file, iterates over every dataset\nstored under the \u201cShallow_GNN_1hop\u201d experiment, and extracts (1) the final-epoch\ntraining metrics, (2) the best-epoch validation metrics (based on the smallest\nvalidation loss), and (3) the single test metrics already stored. It then prints\nthe dataset name followed by clearly-labelled lines for each metric so that\nresults are easy to read. The code executes immediately and respects all\nstructural constraints (no main-guard, no plots).", "The script first loads the saved dictionary from working/experiment_data.npy,\nwhich contains results for the \u201cdirected\u201d and \u201cundirected\u201d variants.   For every\nvariant it extracts: (1) the last-epoch training loss and accuracies, (2) the\nbest validation values determined by the epoch with the lowest validation loss,\nand (3) the stored test metrics.   It then prints the dataset (variant) name\nfollowed by clearly labelled metrics such as \u201ctrain color-weighted accuracy,\u201d\n\u201cbest validation loss,\u201d or \u201ctest complexity-weighted accuracy,\u201d showing only\nthese final / best numbers.   No plots are created and all code is at global\nscope, so the script runs immediately when executed.", "The script will load the saved NumPy file from the \u201cworking\u201d directory, walk\nthrough the nested dictionary structure (model \u2192 dataset \u2192 metrics), and extract\nthe last recorded value for every tracked metric. It prints results dataset-by-\ndataset, explicitly naming each metric (e.g., \u201ctrain color-weighted accuracy\u201d)\nto satisfy the required specificity. Only scalar values are displayed\u2014no plots\nare created and no special entry point is used, so the code runs immediately\nwhen executed.", "The script loads the saved experiment data from the working directory, loops\nover each experiment setup, derives the final or best values for the main\nmetrics, and prints them in a clear, labeled format. For losses we report the\nfinal training loss and the best (minimum) validation loss; for composite\nweighted accuracy we show the final training value and the best (maximum)\nvalidation value. Test-set metrics are printed exactly as stored. No plots are\nproduced and the code runs immediately on execution.", "The script first loads the saved dictionary from working/experiment_data.npy,\nwhich contains results for the \u201cdirected\u201d and \u201cundirected\u201d variants.   For every\nvariant it extracts: (1) the last-epoch training loss and accuracies, (2) the\nbest validation values determined by the epoch with the lowest validation loss,\nand (3) the stored test metrics.   It then prints the dataset (variant) name\nfollowed by clearly labelled metrics such as \u201ctrain color-weighted accuracy,\u201d\n\u201cbest validation loss,\u201d or \u201ctest complexity-weighted accuracy,\u201d showing only\nthese final / best numbers.   No plots are created and all code is at global\nscope, so the script runs immediately when executed.", "The script first loads the saved dictionary from working/experiment_data.npy,\nwhich contains results for the \u201cdirected\u201d and \u201cundirected\u201d variants.   For every\nvariant it extracts: (1) the last-epoch training loss and accuracies, (2) the\nbest validation values determined by the epoch with the lowest validation loss,\nand (3) the stored test metrics.   It then prints the dataset (variant) name\nfollowed by clearly labelled metrics such as \u201ctrain color-weighted accuracy,\u201d\n\u201cbest validation loss,\u201d or \u201ctest complexity-weighted accuracy,\u201d showing only\nthese final / best numbers.   No plots are created and all code is at global\nscope, so the script runs immediately when executed.", "The script first loads the saved dictionary from working/experiment_data.npy,\nwhich contains results for the \u201cdirected\u201d and \u201cundirected\u201d variants.   For every\nvariant it extracts: (1) the last-epoch training loss and accuracies, (2) the\nbest validation values determined by the epoch with the lowest validation loss,\nand (3) the stored test metrics.   It then prints the dataset (variant) name\nfollowed by clearly labelled metrics such as \u201ctrain color-weighted accuracy,\u201d\n\u201cbest validation loss,\u201d or \u201ctest complexity-weighted accuracy,\u201d showing only\nthese final / best numbers.   No plots are created and all code is at global\nscope, so the script runs immediately when executed.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# -------------------------------------------------------------------------\n# locate and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------------------------------\ndef print_metrics(model_key=\"SPR_RGCN\"):\n    if model_key not in experiment_data:\n        raise KeyError(f\"Model '{model_key}' not found in experiment data.\")\n\n    data = experiment_data[model_key]\n\n    # ----------------------- TRAIN ---------------------------------------\n    train_loss_history = data[\"losses\"][\"train\"]\n    train_cwa_history = data[\"metrics\"][\"train\"][\"CWA\"]\n    train_swa_history = data[\"metrics\"][\"train\"][\"SWA\"]\n    train_cmp_history = data[\"metrics\"][\"train\"][\"CmpWA\"]\n\n    # final epoch = last index\n    train_idx = -1\n\n    print(\"Dataset: Training\")\n    print(f\"train loss: {train_loss_history[train_idx]:.4f}\")\n    print(f\"train CWA: {train_cwa_history[train_idx]:.4f}\")\n    print(f\"train SWA: {train_swa_history[train_idx]:.4f}\")\n    print(f\"train CmpWA: {train_cmp_history[train_idx]:.4f}\\n\")\n\n    # ----------------------- VALIDATION ----------------------------------\n    val_loss_history = data[\"losses\"][\"val\"]\n    val_cwa_history = data[\"metrics\"][\"val\"][\"CWA\"]\n    val_swa_history = data[\"metrics\"][\"val\"][\"SWA\"]\n    val_cmp_history = data[\"metrics\"][\"val\"][\"CmpWA\"]\n\n    # best epoch = minimum validation loss\n    best_val_idx = int(np.argmin(val_loss_history))\n\n    print(\"Dataset: Validation\")\n    print(f\"validation loss: {val_loss_history[best_val_idx]:.4f}\")\n    print(f\"validation CWA: {val_cwa_history[best_val_idx]:.4f}\")\n    print(f\"validation SWA: {val_swa_history[best_val_idx]:.4f}\")\n    print(f\"validation CmpWA: {val_cmp_history[best_val_idx]:.4f}\\n\")\n\n    # ----------------------- TEST ----------------------------------------\n    test_metrics = data.get(\"test_metrics\", {})\n    if test_metrics:\n        print(\"Dataset: Test\")\n        print(f\"test loss: {test_metrics.get('loss', float('nan')):.4f}\")\n        print(f\"test CWA: {test_metrics.get('CWA', float('nan')):.4f}\")\n        print(f\"test SWA: {test_metrics.get('SWA', float('nan')):.4f}\")\n        print(f\"test CmpWA: {test_metrics.get('CmpWA', float('nan')):.4f}\\n\")\n    else:\n        print(\"Dataset: Test\")\n        print(\"test metrics not found.\\n\")\n\n\n# Execute immediately\nprint_metrics()\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# 0. Locate and load the saved experiment data ------------------------\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# 1. Traverse the structure and report final metrics ------------------\n# ---------------------------------------------------------------------\nfor model_name, model_blk in experiment_data.items():  # e.g., \"SingleRelation_GCN\"\n    for dataset_name, dset_blk in model_blk.items():  # e.g., \"synthetic\" or \"SPR_BENCH\"\n        print(f\"\\nDataset: {dataset_name}\")\n\n        # ---- losses -------------------------------------------------\n        train_losses = dset_blk[\"losses\"][\"train\"]\n        val_losses = dset_blk[\"losses\"][\"val\"]\n        print(f\"final training loss: {train_losses[-1]:.4f}\")\n        print(f\"final validation loss: {val_losses[-1]:.4f}\")\n\n        # ---- accuracies (train / val) -------------------------------\n        tr_metrics = dset_blk[\"metrics\"][\"train\"]\n        va_metrics = dset_blk[\"metrics\"][\"val\"]\n\n        print(f\"final training color weighted accuracy: {tr_metrics['CWA'][-1]:.4f}\")\n        print(f\"final validation color weighted accuracy: {va_metrics['CWA'][-1]:.4f}\")\n\n        print(f\"final training shape weighted accuracy: {tr_metrics['SWA'][-1]:.4f}\")\n        print(f\"final validation shape weighted accuracy: {va_metrics['SWA'][-1]:.4f}\")\n\n        print(\n            f\"final training complexity weighted accuracy: {tr_metrics['CmpWA'][-1]:.4f}\"\n        )\n        print(\n            f\"final validation complexity weighted accuracy: {va_metrics['CmpWA'][-1]:.4f}\"\n        )\n\n        # ---- test metrics ------------------------------------------\n        test_metrics = dset_blk[\"test_metrics\"]\n        print(f\"test loss: {test_metrics['loss']:.4f}\")\n        print(f\"test color weighted accuracy: {test_metrics['CWA']:.4f}\")\n        print(f\"test shape weighted accuracy: {test_metrics['SWA']:.4f}\")\n        print(f\"test complexity weighted accuracy: {test_metrics['CmpWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load the experiment results\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy at {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# Helper to fetch the final value from a list (safer if list empty)\n# ------------------------------------------------------------------\ndef last(lst, default=None):\n    return lst[-1] if lst else default\n\n\n# ------------------------------------------------------------------\n# Iterate through every recorded dataset and print metrics\n# ------------------------------------------------------------------\nfor dataset_key, container in experiment_data.items():\n    ds = container[\"dataset\"]\n\n    # Final losses\n    final_train_loss = last(ds[\"losses\"][\"train\"], default=\"N/A\")\n    final_val_loss = last(ds[\"losses\"][\"val\"], default=\"N/A\")\n    test_loss = ds.get(\"test_metrics\", {}).get(\"loss\", \"N/A\")\n\n    # Final train metrics\n    tr_metrics = ds[\"metrics\"][\"train\"]\n    final_train_CWA = last(tr_metrics[\"CWA\"], default=\"N/A\")\n    final_train_SWA = last(tr_metrics[\"SWA\"], default=\"N/A\")\n    final_train_CmpWA = last(tr_metrics[\"CmpWA\"], default=\"N/A\")\n\n    # Final validation metrics\n    val_metrics = ds[\"metrics\"][\"val\"]\n    final_val_CWA = last(val_metrics[\"CWA\"], default=\"N/A\")\n    final_val_SWA = last(val_metrics[\"SWA\"], default=\"N/A\")\n    final_val_CmpWA = last(val_metrics[\"CmpWA\"], default=\"N/A\")\n\n    # Test metrics\n    test_metrics = ds.get(\"test_metrics\", {})\n    test_CWA = test_metrics.get(\"CWA\", \"N/A\")\n    test_SWA = test_metrics.get(\"SWA\", \"N/A\")\n    test_CmpWA = test_metrics.get(\"CmpWA\", \"N/A\")\n\n    # ------------------------------------------------------------------\n    # Print results\n    # ------------------------------------------------------------------\n    print(f\"\\nDataset: {dataset_key}\")\n    # Losses\n    print(f\"train loss: {final_train_loss}\")\n    print(f\"validation loss: {final_val_loss}\")\n    print(f\"test loss: {test_loss}\")\n    # Train metrics\n    print(f\"train CWA: {final_train_CWA}\")\n    print(f\"train SWA: {final_train_SWA}\")\n    print(f\"train complexity weighted accuracy: {final_train_CmpWA}\")\n    # Validation metrics\n    print(f\"validation CWA: {final_val_CWA}\")\n    print(f\"validation SWA: {final_val_SWA}\")\n    print(f\"validation complexity weighted accuracy: {final_val_CmpWA}\")\n    # Test metrics\n    print(f\"test CWA: {test_CWA}\")\n    print(f\"test SWA: {test_SWA}\")\n    print(f\"test complexity weighted accuracy: {test_CmpWA}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------------------\n# Locate and load the saved experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------------------\n# Helper for nice float formatting\ndef fmt(v):\n    return f\"{v:.4f}\" if isinstance(v, (float, np.floating)) else str(v)\n\n\n# -------------------------------------------------------------\n# Traverse and print metrics\nfor setup_name, setup_dict in experiment_data.items():\n    for model_name, exp in setup_dict.items():\n        print(f\"{setup_name} - {model_name}\")  # experiment / model header\n        print()  # blank line for readability\n\n        # ---------- Train ----------\n        print(\"train dataset:\")\n        print(f\"train loss: {fmt(exp['losses']['train'][-1])}\")\n        print(f\"train CWA: {fmt(exp['metrics']['train']['CWA'][-1])}\")\n        print(f\"train SWA: {fmt(exp['metrics']['train']['SWA'][-1])}\")\n        print(f\"train CmpWA: {fmt(exp['metrics']['train']['CmpWA'][-1])}\")\n        print()\n\n        # ---------- Validation ----------\n        print(\"validation dataset:\")\n        print(f\"validation loss: {fmt(exp['losses']['val'][-1])}\")\n        print(f\"validation CWA: {fmt(exp['metrics']['val']['CWA'][-1])}\")\n        print(f\"validation SWA: {fmt(exp['metrics']['val']['SWA'][-1])}\")\n        print(f\"validation CmpWA: {fmt(exp['metrics']['val']['CmpWA'][-1])}\")\n        print()\n\n        # ---------- Test ----------\n        print(\"test dataset:\")\n        test_metrics = exp.get(\"test_metrics\", {})\n        if test_metrics:\n            print(f\"test loss: {fmt(test_metrics.get('loss'))}\")\n            print(f\"test CWA: {fmt(test_metrics.get('CWA'))}\")\n            print(f\"test SWA: {fmt(test_metrics.get('SWA'))}\")\n            print(f\"test CmpWA: {fmt(test_metrics.get('CmpWA'))}\")\n        else:\n            print(\"No test metrics found.\")\n        print(\"\\n\" + \"-\" * 50 + \"\\n\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------------------------------\n# Locate and load the saved experiment file\n# -------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Navigate to the block holding metrics\nexp_block = experiment_data[\"ConstantNodeFeatures\"][\"SPR\"]\n\n# Convenience handles -----------------------------------------------------\ntrain_losses = exp_block[\"losses\"][\"train\"]\nval_losses = exp_block[\"losses\"][\"val\"]\n\ntrain_cwa = exp_block[\"metrics\"][\"train\"][\"CWA\"]\ntrain_swa = exp_block[\"metrics\"][\"train\"][\"SWA\"]\ntrain_cmp = exp_block[\"metrics\"][\"train\"][\"CmpWA\"]\n\nval_cwa = exp_block[\"metrics\"][\"val\"][\"CWA\"]\nval_swa = exp_block[\"metrics\"][\"val\"][\"SWA\"]\nval_cmp = exp_block[\"metrics\"][\"val\"][\"CmpWA\"]\n\n# -------------------------------------------------------------------------\n# Select indices for \u201cfinal\u201d (training) and \u201cbest\u201d (validation) epochs\n# -------------------------------------------------------------------------\nfinal_idx_train = len(train_losses) - 1\nbest_idx_val = int(np.argmin(val_losses))\n\n# -------------------------------------------------------------------------\n# Fetch metrics\n# -------------------------------------------------------------------------\n# Training (final epoch)\ntrain_loss_final = train_losses[final_idx_train]\ntrain_cwa_final = train_cwa[final_idx_train]\ntrain_swa_final = train_swa[final_idx_train]\ntrain_cmp_final = train_cmp[final_idx_train]\n\n# Validation (epoch with lowest val loss)\nval_loss_best = val_losses[best_idx_val]\nval_cwa_best = val_cwa[best_idx_val]\nval_swa_best = val_swa[best_idx_val]\nval_cmp_best = val_cmp[best_idx_val]\n\n# Test (single evaluation)\ntest_metrics = exp_block[\"test_metrics\"]\ntest_loss = test_metrics[\"loss\"]\ntest_cwa = test_metrics[\"CWA\"]\ntest_swa = test_metrics[\"SWA\"]\ntest_cmp = test_metrics[\"CmpWA\"]\n\n# -------------------------------------------------------------------------\n# Print results with explicit labels\n# -------------------------------------------------------------------------\nprint(\"Dataset: Training\")\nprint(f\"train loss: {train_loss_final:.4f}\")\nprint(f\"train color-weighted accuracy: {train_cwa_final:.4f}\")\nprint(f\"train shape-weighted accuracy: {train_swa_final:.4f}\")\nprint(f\"train complexity-weighted accuracy: {train_cmp_final:.4f}\\n\")\n\nprint(\"Dataset: Validation\")\nprint(f\"validation loss (best): {val_loss_best:.4f}\")\nprint(f\"validation color-weighted accuracy (at best loss): {val_cwa_best:.4f}\")\nprint(f\"validation shape-weighted accuracy (at best loss): {val_swa_best:.4f}\")\nprint(f\"validation complexity-weighted accuracy (at best loss): {val_cmp_best:.4f}\\n\")\n\nprint(\"Dataset: Test\")\nprint(f\"test loss: {test_loss:.4f}\")\nprint(f\"test color-weighted accuracy: {test_cwa:.4f}\")\nprint(f\"test shape-weighted accuracy: {test_swa:.4f}\")\nprint(f\"test complexity-weighted accuracy: {test_cmp:.4f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate and load data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\nexp_key = \"Shallow_GNN_1hop\"\nfor dataset_name, data in experiment_data.get(exp_key, {}).items():\n    # helper references\n    tr_losses = data[\"losses\"][\"train\"]\n    val_losses = data[\"losses\"][\"val\"]\n    tr_metrics = data[\"metrics\"][\"train\"]\n    val_metrics = data[\"metrics\"][\"val\"]\n    tst_metrics = data[\"test_metrics\"]\n\n    # determine epochs of interest\n    final_epoch_idx = len(tr_losses) - 1\n    best_val_idx = int(np.argmin(val_losses))  # epoch with best (lowest) val loss\n\n    # fetch training (final epoch)\n    train_loss_final = tr_losses[final_epoch_idx]\n    train_cwa_final = tr_metrics[\"CWA\"][final_epoch_idx]\n    train_swa_final = tr_metrics[\"SWA\"][final_epoch_idx]\n    train_cmp_final = tr_metrics[\"CmpWA\"][final_epoch_idx]\n\n    # fetch validation (best epoch)\n    val_loss_best = val_losses[best_val_idx]\n    val_cwa_best = val_metrics[\"CWA\"][best_val_idx]\n    val_swa_best = val_metrics[\"SWA\"][best_val_idx]\n    val_cmp_best = val_metrics[\"CmpWA\"][best_val_idx]\n\n    # fetch test (single set)\n    test_loss = tst_metrics.get(\"loss\", float(\"nan\"))\n    test_cwa = tst_metrics.get(\"CWA\", float(\"nan\"))\n    test_swa = tst_metrics.get(\"SWA\", float(\"nan\"))\n    test_cmp = tst_metrics.get(\"CmpWA\", float(\"nan\"))\n\n    # ------------------------------------------------------------------\n    # printing section\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"train loss: {train_loss_final:.4f}\")\n    print(f\"train color-weighted accuracy: {train_cwa_final:.4f}\")\n    print(f\"train shape-weighted accuracy: {train_swa_final:.4f}\")\n    print(f\"train complexity-weighted accuracy: {train_cmp_final:.4f}\")\n\n    print(f\"validation loss (best): {val_loss_best:.4f}\")\n    print(f\"validation color-weighted accuracy (best): {val_cwa_best:.4f}\")\n    print(f\"validation shape-weighted accuracy (best): {val_swa_best:.4f}\")\n    print(f\"validation complexity-weighted accuracy (best): {val_cmp_best:.4f}\")\n\n    print(f\"test loss: {test_loss:.4f}\")\n    print(f\"test color-weighted accuracy: {test_cwa:.4f}\")\n    print(f\"test shape-weighted accuracy: {test_swa:.4f}\")\n    print(f\"test complexity-weighted accuracy: {test_cmp:.4f}\")\n    print(\"-\" * 40)\n", "import os\nimport numpy as np\n\n# 0. Locate file and load\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# 1. Iterate over variants (datasets)\nfor variant_name, variant_data in experiment_data[\"edge_direction\"].items():\n    print(f\"\\nDataset: {variant_name}\")\n\n    # --------------------- TRAIN (final epoch) ---------------------------\n    final_train_idx = -1  # last recorded epoch\n    train_loss_final = variant_data[\"losses\"][\"train\"][final_train_idx]\n    train_cwa_final = variant_data[\"metrics\"][\"train\"][\"CWA\"][final_train_idx]\n    train_swa_final = variant_data[\"metrics\"][\"train\"][\"SWA\"][final_train_idx]\n    train_cpx_final = variant_data[\"metrics\"][\"train\"][\"CmpWA\"][final_train_idx]\n\n    print(f\"train loss: {train_loss_final:.4f}\")\n    print(f\"train color-weighted accuracy: {train_cwa_final:.4f}\")\n    print(f\"train shape-weighted accuracy: {train_swa_final:.4f}\")\n    print(f\"train complexity-weighted accuracy: {train_cpx_final:.4f}\")\n\n    # --------------------- VALIDATION (best val loss) --------------------\n    val_losses = variant_data[\"losses\"][\"val\"]\n    best_val_idx = int(np.argmin(val_losses))\n    val_loss_best = val_losses[best_val_idx]\n    val_cwa_best = variant_data[\"metrics\"][\"val\"][\"CWA\"][best_val_idx]\n    val_swa_best = variant_data[\"metrics\"][\"val\"][\"SWA\"][best_val_idx]\n    val_cpx_best = variant_data[\"metrics\"][\"val\"][\"CmpWA\"][best_val_idx]\n\n    print(f\"best validation loss: {val_loss_best:.4f}\")\n    print(f\"best validation color-weighted accuracy: {val_cwa_best:.4f}\")\n    print(f\"best validation shape-weighted accuracy: {val_swa_best:.4f}\")\n    print(f\"best validation complexity-weighted accuracy: {val_cpx_best:.4f}\")\n\n    # --------------------- TEST (stored once) ----------------------------\n    test_metrics = variant_data[\"test_metrics\"]\n    print(f\"test loss: {test_metrics['loss']:.4f}\")\n    print(f\"test color-weighted accuracy: {test_metrics['CWA']:.4f}\")\n    print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.4f}\")\n    print(f\"test complexity-weighted accuracy: {test_metrics['CmpWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# ----------------------------------------------------------------------\n# locate and load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ----------------------------------------------------------------------\n# iterate through models and datasets\nfor model_name, model_block in experiment_data.items():\n    for dataset_name, dataset_block in model_block.items():\n        print(f\"Dataset: {dataset_name}\")\n\n        # final (last) training & validation losses\n        train_loss_final = dataset_block[\"losses\"][\"train\"][-1]\n        val_loss_final = dataset_block[\"losses\"][\"val\"][-1]\n\n        # final training metrics\n        train_cwa_final = dataset_block[\"metrics\"][\"train\"][\"CWA\"][-1]\n        train_swa_final = dataset_block[\"metrics\"][\"train\"][\"SWA\"][-1]\n        train_cmpwa_final = dataset_block[\"metrics\"][\"train\"][\"CmpWA\"][-1]\n\n        # final validation metrics\n        val_cwa_final = dataset_block[\"metrics\"][\"val\"][\"CWA\"][-1]\n        val_swa_final = dataset_block[\"metrics\"][\"val\"][\"SWA\"][-1]\n        val_cmpwa_final = dataset_block[\"metrics\"][\"val\"][\"CmpWA\"][-1]\n\n        # test metrics (single values)\n        test_metrics = dataset_block.get(\"test_metrics\", {})\n        test_loss = test_metrics.get(\"loss\")\n        test_cwa = test_metrics.get(\"CWA\")\n        test_swa = test_metrics.get(\"SWA\")\n        test_cmpwa = test_metrics.get(\"CmpWA\")\n\n        # ------------------------------------------------------------------\n        # print results with precise metric names\n        print(f\"train loss: {train_loss_final:.4f}\")\n        print(f\"validation loss: {val_loss_final:.4f}\")\n\n        print(f\"train color-weighted accuracy: {train_cwa_final:.4f}\")\n        print(f\"train shape-weighted accuracy: {train_swa_final:.4f}\")\n        print(f\"train complexity-weighted accuracy: {train_cmpwa_final:.4f}\")\n\n        print(f\"validation color-weighted accuracy: {val_cwa_final:.4f}\")\n        print(f\"validation shape-weighted accuracy: {val_swa_final:.4f}\")\n        print(f\"validation complexity-weighted accuracy: {val_cmpwa_final:.4f}\")\n\n        if test_metrics:\n            print(f\"test loss: {test_loss:.4f}\")\n            print(f\"test color-weighted accuracy: {test_cwa:.4f}\")\n            print(f\"test shape-weighted accuracy: {test_swa:.4f}\")\n            print(f\"test complexity-weighted accuracy: {test_cmpwa:.4f}\")\n\n        # spacing between datasets (optional clarity)\n        print()\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load the results file\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# Extract and print metrics\n# ------------------------------------------------------------------\nexperiments = experiment_data.get(\"MultiSyntheticGeneralization\", {})\n\nfor experiment_name, results in experiments.items():\n    print(f\"\\nDataset: {experiment_name}\")\n\n    # ----- losses -----\n    train_losses = results[\"losses\"][\"train\"]\n    val_losses = results[\"losses\"][\"val\"]\n    final_train_loss = train_losses[-1]\n    best_val_loss = min(val_losses)\n\n    # ----- composite weighted accuracies -----\n    train_cmpwa = results[\"CmpWA_train\"]\n    val_cmpwa = results[\"CmpWA_val\"]\n    final_train_cmpwa = train_cmpwa[-1]\n    best_val_cmpwa = max(val_cmpwa)\n\n    # ----- test metrics -----\n    test_metrics = results[\"test_metrics\"]\n    test_loss = test_metrics[\"loss\"]\n    test_cwa = test_metrics[\"CWA\"]\n    test_swa = test_metrics[\"SWA\"]\n    test_cmpwa = test_metrics[\"CmpWA\"]\n\n    # ----- print -----\n    print(f\"final training loss: {final_train_loss:.4f}\")\n    print(f\"best validation loss: {best_val_loss:.4f}\")\n    print(f\"final training composite weighted accuracy: {final_train_cmpwa:.4f}\")\n    print(f\"best validation composite weighted accuracy: {best_val_cmpwa:.4f}\")\n    print(f\"test loss: {test_loss:.4f}\")\n    print(f\"test color-weighted accuracy: {test_cwa:.4f}\")\n    print(f\"test shape-weighted accuracy: {test_swa:.4f}\")\n    print(f\"test composite weighted accuracy: {test_cmpwa:.4f}\")\n", "import os\nimport numpy as np\n\n# 0. Locate file and load\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# 1. Iterate over variants (datasets)\nfor variant_name, variant_data in experiment_data[\"edge_direction\"].items():\n    print(f\"\\nDataset: {variant_name}\")\n\n    # --------------------- TRAIN (final epoch) ---------------------------\n    final_train_idx = -1  # last recorded epoch\n    train_loss_final = variant_data[\"losses\"][\"train\"][final_train_idx]\n    train_cwa_final = variant_data[\"metrics\"][\"train\"][\"CWA\"][final_train_idx]\n    train_swa_final = variant_data[\"metrics\"][\"train\"][\"SWA\"][final_train_idx]\n    train_cpx_final = variant_data[\"metrics\"][\"train\"][\"CmpWA\"][final_train_idx]\n\n    print(f\"train loss: {train_loss_final:.4f}\")\n    print(f\"train color-weighted accuracy: {train_cwa_final:.4f}\")\n    print(f\"train shape-weighted accuracy: {train_swa_final:.4f}\")\n    print(f\"train complexity-weighted accuracy: {train_cpx_final:.4f}\")\n\n    # --------------------- VALIDATION (best val loss) --------------------\n    val_losses = variant_data[\"losses\"][\"val\"]\n    best_val_idx = int(np.argmin(val_losses))\n    val_loss_best = val_losses[best_val_idx]\n    val_cwa_best = variant_data[\"metrics\"][\"val\"][\"CWA\"][best_val_idx]\n    val_swa_best = variant_data[\"metrics\"][\"val\"][\"SWA\"][best_val_idx]\n    val_cpx_best = variant_data[\"metrics\"][\"val\"][\"CmpWA\"][best_val_idx]\n\n    print(f\"best validation loss: {val_loss_best:.4f}\")\n    print(f\"best validation color-weighted accuracy: {val_cwa_best:.4f}\")\n    print(f\"best validation shape-weighted accuracy: {val_swa_best:.4f}\")\n    print(f\"best validation complexity-weighted accuracy: {val_cpx_best:.4f}\")\n\n    # --------------------- TEST (stored once) ----------------------------\n    test_metrics = variant_data[\"test_metrics\"]\n    print(f\"test loss: {test_metrics['loss']:.4f}\")\n    print(f\"test color-weighted accuracy: {test_metrics['CWA']:.4f}\")\n    print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.4f}\")\n    print(f\"test complexity-weighted accuracy: {test_metrics['CmpWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# 0. Locate file and load\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# 1. Iterate over variants (datasets)\nfor variant_name, variant_data in experiment_data[\"edge_direction\"].items():\n    print(f\"\\nDataset: {variant_name}\")\n\n    # --------------------- TRAIN (final epoch) ---------------------------\n    final_train_idx = -1  # last recorded epoch\n    train_loss_final = variant_data[\"losses\"][\"train\"][final_train_idx]\n    train_cwa_final = variant_data[\"metrics\"][\"train\"][\"CWA\"][final_train_idx]\n    train_swa_final = variant_data[\"metrics\"][\"train\"][\"SWA\"][final_train_idx]\n    train_cpx_final = variant_data[\"metrics\"][\"train\"][\"CmpWA\"][final_train_idx]\n\n    print(f\"train loss: {train_loss_final:.4f}\")\n    print(f\"train color-weighted accuracy: {train_cwa_final:.4f}\")\n    print(f\"train shape-weighted accuracy: {train_swa_final:.4f}\")\n    print(f\"train complexity-weighted accuracy: {train_cpx_final:.4f}\")\n\n    # --------------------- VALIDATION (best val loss) --------------------\n    val_losses = variant_data[\"losses\"][\"val\"]\n    best_val_idx = int(np.argmin(val_losses))\n    val_loss_best = val_losses[best_val_idx]\n    val_cwa_best = variant_data[\"metrics\"][\"val\"][\"CWA\"][best_val_idx]\n    val_swa_best = variant_data[\"metrics\"][\"val\"][\"SWA\"][best_val_idx]\n    val_cpx_best = variant_data[\"metrics\"][\"val\"][\"CmpWA\"][best_val_idx]\n\n    print(f\"best validation loss: {val_loss_best:.4f}\")\n    print(f\"best validation color-weighted accuracy: {val_cwa_best:.4f}\")\n    print(f\"best validation shape-weighted accuracy: {val_swa_best:.4f}\")\n    print(f\"best validation complexity-weighted accuracy: {val_cpx_best:.4f}\")\n\n    # --------------------- TEST (stored once) ----------------------------\n    test_metrics = variant_data[\"test_metrics\"]\n    print(f\"test loss: {test_metrics['loss']:.4f}\")\n    print(f\"test color-weighted accuracy: {test_metrics['CWA']:.4f}\")\n    print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.4f}\")\n    print(f\"test complexity-weighted accuracy: {test_metrics['CmpWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# 0. Locate file and load\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# 1. Iterate over variants (datasets)\nfor variant_name, variant_data in experiment_data[\"edge_direction\"].items():\n    print(f\"\\nDataset: {variant_name}\")\n\n    # --------------------- TRAIN (final epoch) ---------------------------\n    final_train_idx = -1  # last recorded epoch\n    train_loss_final = variant_data[\"losses\"][\"train\"][final_train_idx]\n    train_cwa_final = variant_data[\"metrics\"][\"train\"][\"CWA\"][final_train_idx]\n    train_swa_final = variant_data[\"metrics\"][\"train\"][\"SWA\"][final_train_idx]\n    train_cpx_final = variant_data[\"metrics\"][\"train\"][\"CmpWA\"][final_train_idx]\n\n    print(f\"train loss: {train_loss_final:.4f}\")\n    print(f\"train color-weighted accuracy: {train_cwa_final:.4f}\")\n    print(f\"train shape-weighted accuracy: {train_swa_final:.4f}\")\n    print(f\"train complexity-weighted accuracy: {train_cpx_final:.4f}\")\n\n    # --------------------- VALIDATION (best val loss) --------------------\n    val_losses = variant_data[\"losses\"][\"val\"]\n    best_val_idx = int(np.argmin(val_losses))\n    val_loss_best = val_losses[best_val_idx]\n    val_cwa_best = variant_data[\"metrics\"][\"val\"][\"CWA\"][best_val_idx]\n    val_swa_best = variant_data[\"metrics\"][\"val\"][\"SWA\"][best_val_idx]\n    val_cpx_best = variant_data[\"metrics\"][\"val\"][\"CmpWA\"][best_val_idx]\n\n    print(f\"best validation loss: {val_loss_best:.4f}\")\n    print(f\"best validation color-weighted accuracy: {val_cwa_best:.4f}\")\n    print(f\"best validation shape-weighted accuracy: {val_swa_best:.4f}\")\n    print(f\"best validation complexity-weighted accuracy: {val_cpx_best:.4f}\")\n\n    # --------------------- TEST (stored once) ----------------------------\n    test_metrics = variant_data[\"test_metrics\"]\n    print(f\"test loss: {test_metrics['loss']:.4f}\")\n    print(f\"test color-weighted accuracy: {test_metrics['CWA']:.4f}\")\n    print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.4f}\")\n    print(f\"test complexity-weighted accuracy: {test_metrics['CmpWA']:.4f}\")\n", ""], "parse_term_out": ["['Dataset: Training', '\\n', 'train loss: 0.5801', '\\n', 'train CWA: 0.7286',\n'\\n', 'train SWA: 0.7305', '\\n', 'train CmpWA: 0.7295\\n', '\\n', 'Dataset:\nValidation', '\\n', 'validation loss: 0.6811', '\\n', 'validation CWA: 0.5953',\n'\\n', 'validation SWA: 0.5799', '\\n', 'validation CmpWA: 0.5885\\n', '\\n',\n'Dataset: Test', '\\n', 'test loss: 0.6945', '\\n', 'test CWA: 0.5906', '\\n',\n'test SWA: 0.5623', '\\n', 'test CmpWA: 0.5778\\n', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['\\nDataset: synthetic', '\\n', 'final training loss: 0.6616', '\\n', 'final\nvalidation loss: 0.6934', '\\n', 'final training color weighted accuracy:\n0.6161', '\\n', 'final validation color weighted accuracy: 0.5107', '\\n', 'final\ntraining shape weighted accuracy: 0.6213', '\\n', 'final validation shape\nweighted accuracy: 0.5036', '\\n', 'final training complexity weighted accuracy:\n0.6185', '\\n', 'final validation complexity weighted accuracy: 0.5075', '\\n',\n'test loss: 0.7019', '\\n', 'test color weighted accuracy: 0.4462', '\\n', 'test\nshape weighted accuracy: 0.4523', '\\n', 'test complexity weighted accuracy:\n0.4489', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: NoSeqEdges', '\\n', 'train loss: 0.6266386373837789', '\\n',\n'validation loss: 0.7531723546981811', '\\n', 'test loss: 0.7287301111221314',\n'\\n', 'train CWA: 0.6684596577017115', '\\n', 'train SWA: 0.672209026128266',\n'\\n', 'train complexity weighted accuracy: 0.670152855993564', '\\n', 'validation\nCWA: 0.44861660079051385', '\\n', 'validation SWA: 0.44768856447688565', '\\n',\n'validation complexity weighted accuracy: 0.44820065430752454', '\\n', 'test CWA:\n0.48221343873517786', '\\n', 'test SWA: 0.4879807692307692', '\\n', 'test\ncomplexity weighted accuracy: 0.4848156182212581', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['no_color_edge - SPR_RGCN', '\\n', '\\n', 'train dataset:', '\\n', 'train loss:\n0.6305', '\\n', 'train CWA: 0.6489', '\\n', 'train SWA: 0.6551', '\\n', 'train\nCmpWA: 0.6517', '\\n', '\\n', 'validation dataset:', '\\n', 'validation loss:\n0.7233', '\\n', 'validation CWA: 0.5235', '\\n', 'validation SWA: 0.5123', '\\n',\n'validation CmpWA: 0.5186', '\\n', '\\n', 'test dataset:', '\\n', 'test loss:\n0.7073', '\\n', 'test CWA: 0.5222', '\\n', 'test SWA: 0.5179', '\\n', 'test CmpWA:\n0.5203', '\\n', '\\n--------------------------------------------------\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: Training', '\\n', 'train loss: 0.7029', '\\n', 'train color-weighted\naccuracy: 0.4951', '\\n', 'train shape-weighted accuracy: 0.4824', '\\n', 'train\ncomplexity-weighted accuracy: 0.4894\\n', '\\n', 'Dataset: Validation', '\\n',\n'validation loss (best): 0.6927', '\\n', 'validation color-weighted accuracy (at\nbest loss): 0.5506', '\\n', 'validation shape-weighted accuracy (at best loss):\n0.5483', '\\n', 'validation complexity-weighted accuracy (at best loss):\n0.5496\\n', '\\n', 'Dataset: Test', '\\n', 'test loss: 0.6915', '\\n', 'test color-\nweighted accuracy: 0.5060', '\\n', 'test shape-weighted accuracy: 0.5202', '\\n',\n'test complexity-weighted accuracy: 0.5125', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['Dataset: synthetic', '\\n', 'train loss: 0.6602', '\\n', 'train color-weighted\naccuracy: 0.6088', '\\n', 'train shape-weighted accuracy: 0.6058', '\\n', 'train\ncomplexity-weighted accuracy: 0.6075', '\\n', 'validation loss (best): 0.6890',\n'\\n', 'validation color-weighted accuracy (best): 0.5621', '\\n', 'validation\nshape-weighted accuracy (best): 0.5604', '\\n', 'validation complexity-weighted\naccuracy (best): 0.5613', '\\n', 'test loss: 0.7243', '\\n', 'test color-weighted\naccuracy: 0.5020', '\\n', 'test shape-weighted accuracy: 0.4976', '\\n', 'test\ncomplexity-weighted accuracy: 0.5000', '\\n',\n'----------------------------------------', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['\\nDataset: directed', '\\n', 'train loss: 0.5536', '\\n', 'train color-weighted\naccuracy: 0.7662', '\\n', 'train shape-weighted accuracy: 0.7660', '\\n', 'train\ncomplexity-weighted accuracy: 0.7661', '\\n', 'best validation loss: 0.6809',\n'\\n', 'best validation color-weighted accuracy: 0.5618', '\\n', 'best validation\nshape-weighted accuracy: 0.5676', '\\n', 'best validation complexity-weighted\naccuracy: 0.5644', '\\n', 'test loss: 0.6852', '\\n', 'test color-weighted\naccuracy: 0.5451', '\\n', 'test shape-weighted accuracy: 0.5498', '\\n', 'test\ncomplexity-weighted accuracy: 0.5471', '\\n', '\\nDataset: undirected', '\\n',\n'train loss: 0.5199', '\\n', 'train color-weighted accuracy: 0.7963', '\\n',\n'train shape-weighted accuracy: 0.7938', '\\n', 'train complexity-weighted\naccuracy: 0.7952', '\\n', 'best validation loss: 0.6691', '\\n', 'best validation\ncolor-weighted accuracy: 0.6056', '\\n', 'best validation shape-weighted\naccuracy: 0.6159', '\\n', 'best validation complexity-weighted accuracy: 0.6103',\n'\\n', 'test loss: 0.6836', '\\n', 'test color-weighted accuracy: 0.5882', '\\n',\n'test shape-weighted accuracy: 0.5796', '\\n', 'test complexity-weighted\naccuracy: 0.5844', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Dataset: synthetic', '\\n', 'train loss: 0.6506', '\\n', 'validation loss:\n0.6996', '\\n', 'train color-weighted accuracy: 0.6647', '\\n', 'train shape-\nweighted accuracy: 0.6652', '\\n', 'train complexity-weighted accuracy: 0.6649',\n'\\n', 'validation color-weighted accuracy: 0.4629', '\\n', 'validation shape-\nweighted accuracy: 0.4732', '\\n', 'validation complexity-weighted accuracy:\n0.4675', '\\n', 'test loss: 0.6934', '\\n', 'test color-weighted accuracy:\n0.4863', '\\n', 'test shape-weighted accuracy: 0.4976', '\\n', 'test complexity-\nweighted accuracy: 0.4914', '\\n', '\\n', 'Execution time: a moment seconds (time\nlimit is 30 minutes).']", "['\\nDataset: A_train_B_val_C_test', '\\n', 'final training loss: 0.6261', '\\n',\n'best validation loss: 0.7037', '\\n', 'final training composite weighted\naccuracy: 0.6354', '\\n', 'best validation composite weighted accuracy: 0.5248',\n'\\n', 'test loss: 0.7091', '\\n', 'test color-weighted accuracy: 0.5027', '\\n',\n'test shape-weighted accuracy: 0.5020', '\\n', 'test composite weighted accuracy:\n0.5024', '\\n', '\\nDataset: AB_train_C_test', '\\n', 'final training loss:\n0.3380', '\\n', 'best validation loss: 0.3001', '\\n', 'final training composite\nweighted accuracy: 0.8860', '\\n', 'best validation composite weighted accuracy:\n0.9195', '\\n', 'test loss: 0.9208', '\\n', 'test color-weighted accuracy:\n0.5010', '\\n', 'test shape-weighted accuracy: 0.4980', '\\n', 'test composite\nweighted accuracy: 0.4996', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['\\nDataset: directed', '\\n', 'train loss: 0.5535', '\\n', 'train color-weighted\naccuracy: 0.7698', '\\n', 'train shape-weighted accuracy: 0.7714', '\\n', 'train\ncomplexity-weighted accuracy: 0.7705', '\\n', 'best validation loss: 0.6988',\n'\\n', 'best validation color-weighted accuracy: 0.5709', '\\n', 'best validation\nshape-weighted accuracy: 0.5628', '\\n', 'best validation complexity-weighted\naccuracy: 0.5672', '\\n', 'test loss: 0.7275', '\\n', 'test color-weighted\naccuracy: 0.5088', '\\n', 'test shape-weighted accuracy: 0.5000', '\\n', 'test\ncomplexity-weighted accuracy: 0.5048', '\\n', '\\nDataset: undirected', '\\n',\n'train loss: 0.4894', '\\n', 'train color-weighted accuracy: 0.8337', '\\n',\n'train shape-weighted accuracy: 0.8309', '\\n', 'train complexity-weighted\naccuracy: 0.8325', '\\n', 'best validation loss: 0.6631', '\\n', 'best validation\ncolor-weighted accuracy: 0.5948', '\\n', 'best validation shape-weighted\naccuracy: 0.5990', '\\n', 'best validation complexity-weighted accuracy: 0.5967',\n'\\n', 'test loss: 0.6864', '\\n', 'test color-weighted accuracy: 0.5614', '\\n',\n'test shape-weighted accuracy: 0.5637', '\\n', 'test complexity-weighted\naccuracy: 0.5624', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: directed', '\\n', 'train loss: 0.6066', '\\n', 'train color-weighted\naccuracy: 0.6952', '\\n', 'train shape-weighted accuracy: 0.6915', '\\n', 'train\ncomplexity-weighted accuracy: 0.6935', '\\n', 'best validation loss: 0.7014',\n'\\n', 'best validation color-weighted accuracy: 0.5101', '\\n', 'best validation\nshape-weighted accuracy: 0.5084', '\\n', 'best validation complexity-weighted\naccuracy: 0.5093', '\\n', 'test loss: 0.6941', '\\n', 'test color-weighted\naccuracy: 0.5020', '\\n', 'test shape-weighted accuracy: 0.5075', '\\n', 'test\ncomplexity-weighted accuracy: 0.5044', '\\n', '\\nDataset: undirected', '\\n',\n'train loss: 0.5691', '\\n', 'train color-weighted accuracy: 0.7494', '\\n',\n'train shape-weighted accuracy: 0.7477', '\\n', 'train complexity-weighted\naccuracy: 0.7486', '\\n', 'best validation loss: 0.7008', '\\n', 'best validation\ncolor-weighted accuracy: 0.4960', '\\n', 'best validation shape-weighted\naccuracy: 0.5012', '\\n', 'best validation complexity-weighted accuracy: 0.4984',\n'\\n', 'test loss: 0.7048', '\\n', 'test color-weighted accuracy: 0.5279', '\\n',\n'test shape-weighted accuracy: 0.5348', '\\n', 'test complexity-weighted\naccuracy: 0.5310', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: directed', '\\n', 'train loss: 0.6107', '\\n', 'train color-weighted\naccuracy: 0.7105', '\\n', 'train shape-weighted accuracy: 0.7104', '\\n', 'train\ncomplexity-weighted accuracy: 0.7104', '\\n', 'best validation loss: 0.7252',\n'\\n', 'best validation color-weighted accuracy: 0.4691', '\\n', 'best validation\nshape-weighted accuracy: 0.4652', '\\n', 'best validation complexity-weighted\naccuracy: 0.4673', '\\n', 'test loss: 0.7015', '\\n', 'test color-weighted\naccuracy: 0.5129', '\\n', 'test shape-weighted accuracy: 0.4975', '\\n', 'test\ncomplexity-weighted accuracy: 0.5061', '\\n', '\\nDataset: undirected', '\\n',\n'train loss: 0.6189', '\\n', 'train color-weighted accuracy: 0.6857', '\\n',\n'train shape-weighted accuracy: 0.6888', '\\n', 'train complexity-weighted\naccuracy: 0.6871', '\\n', 'best validation loss: 0.6937', '\\n', 'best validation\ncolor-weighted accuracy: 0.5529', '\\n', 'best validation shape-weighted\naccuracy: 0.5468', '\\n', 'best validation complexity-weighted accuracy: 0.5501',\n'\\n', 'test loss: 0.7113', '\\n', 'test color-weighted accuracy: 0.4791', '\\n',\n'test shape-weighted accuracy: 0.4754', '\\n', 'test complexity-weighted\naccuracy: 0.4774', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
