
% This paper provides a comprehensive overview of Graph Neural Networks (GNNs), including their foundational concepts, architectures, message-passing mechanisms, and applications. It is relevant to the theoretical foundation of this research, as GNNs are central to capturing relational and structural information in the proposed SPR task. The citation will be used in the introduction and related work sections to establish the strengths of GNNs in modeling graph-structured data.
@article{khemani2024aro,
 author = {Bharti Khemani and S. Patil and K. Kotecha and Sudeep Tanwar},
 booktitle = {Journal of Big Data},
 journal = {Journal of Big Data},
 pages = {1-43},
 title = {A review of graph neural networks: concepts, architectures, techniques, challenges, datasets, applications, and future directions},
 volume = {11},
 year = {2024}
}

% This paper provides a comprehensive survey of deep learning models, including RNNs, LSTMs, and Transformers, along with their structures, applications, and limitations. It is relevant to summarizing existing sequence-based approaches for symbolic reasoning tasks and highlighting their limitations in capturing relational and structural information. This citation will be used in the related work section to emphasize the gap that the proposed GNN-based method aims to address.
@article{shiri2023aco,
 author = {Farhad Shiri and Thinagaran Perumal and N. Mustapha and Raihani Mohamed},
 booktitle = {Journal of Artificial Intelligence},
 journal = {ArXiv},
 title = {A Comprehensive Overview and Comparative Analysis on Deep Learning Models: CNN, RNN, LSTM, GRU},
 volume = {abs/2305.17473},
 year = {2023}
}

% This paper introduces GraphSAGE, an inductive framework for generating node embeddings in large graphs by sampling and aggregating features from a node's local neighborhood. It is foundational to the methodology of this research, as GraphSAGE is employed to capture relational and structural dependencies in the proposed SPR task. This citation will be used in the methodology section to credit the architecture and explain its relevance in modeling graph-structured data.
@article{hamilton2017inductiverl,
 author = {William L. Hamilton and Z. Ying and J. Leskovec},
 booktitle = {Neural Information Processing Systems},
 journal = {ArXiv},
 title = {Inductive Representation Learning on Large Graphs},
 volume = {abs/1706.02216},
 year = {2017}
}

% This paper introduces a vectorized relational graph convolutional network (VR-GCN) for multi-relational network alignment tasks, emphasizing the use of multi-relation information in graph embeddings. It is relevant to the methodology section of the proposed research, where RGCNs are employed to model multi-relational data in symbolic reasoning tasks. The citation will provide foundational support for the choice of RGCN architecture and its ability to handle complex relational information.
@article{ye2019avr,
 author = {Rui Ye and Xin Li and Yujie Fang and Hongyu Zang and Mingzhong Wang},
 booktitle = {International Joint Conference on Artificial Intelligence},
 pages = {4135-4141},
 title = {A Vectorized Relational Graph Convolutional Network for Multi-Relational Network Alignment},
 year = {2019}
}
