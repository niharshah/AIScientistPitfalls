\documentclass{article} % For LaTeX2e
\usepackage{iclr2025,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% Custom
\usepackage{multirow}
\usepackage{color}
\usepackage{colortbl}
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{xspace}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\graphicspath{{../figures/}}

\begin{filecontents}{references.bib}
@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  year={2016},
  publisher={MIT Press}
}

@article{khemani2024aro,
 author = {Bharti Khemani and S. Patil and K. Kotecha and Sudeep Tanwar},
 booktitle = {Journal of Big Data},
 journal = {Journal of Big Data},
 pages = {1-43},
 title = {A review of graph neural networks: concepts, architectures, techniques, challenges, datasets, applications, and future directions},
 volume = {11},
 year = {2024}
}

@article{shiri2023aco,
 author = {Farhad Shiri and Thinagaran Perumal and N. Mustapha and Raihani Mohamed},
 booktitle = {Journal of Artificial Intelligence},
 journal = {ArXiv},
 title = {A Comprehensive Overview and Comparative Analysis on Deep Learning Models: CNN, RNN, LSTM, GRU},
 volume = {abs/2305.17473},
 year = {2023}
}

@article{hamilton2017inductiverl,
 author = {William L. Hamilton and Z. Ying and J. Leskovec},
 booktitle = {Neural Information Processing Systems},
 journal = {ArXiv},
 title = {Inductive Representation Learning on Large Graphs},
 volume = {abs/1706.02216},
 year = {2017}
}

@article{ye2019avr,
 author = {Rui Ye and Xin Li and Yujie Fang and Hongyu Zang and Mingzhong Wang},
 booktitle = {International Joint Conference on Artificial Intelligence},
 pages = {4135-4141},
 title = {A Vectorized Relational Graph Convolutional Network for Multi-Relational Network Alignment},
 year = {2019}
}
\end{filecontents}

\title{Leveraging Graph Neural Networks for Enhanced Synthetic PolyRule Reasoning}

\author{Anonymous}

\begin{document}

\maketitle

\begin{abstract}
We investigate the use of Graph Neural Networks (GNNs) for Synthetic PolyRule Reasoning (SPR), a symbolic classification task where sequences must be labeled according to hidden poly-factor rules. Most existing methods rely on sequence architectures (e.g., RNN, LSTM, Transformers) that may underutilize relational and structural cues in the data. We hypothesize that GNNs can capture these cues more effectively, and present experiments with a multi-relational RGCN-based approach that uses edges to represent color-, shape-, and position-based relationships. On our benchmark, the proposed model surpasses the prior state of the art on Color-Weighted Accuracy (70\% vs.\ 65\%) but remains below it on Shape-Weighted Accuracy (65\% vs.\ 70\%), highlighting promising but incomplete progress for this domain.
\end{abstract}

\section{Introduction}
Symbolic reasoning tasks involving structured inputs are central to many real-world applications, from rule-based diagnostics to combinatorial reasoning~\citep{goodfellow2016deep}. However, deep sequence models may overlook non-sequential relationships among tokens~\citep{shiri2023aco}. Within Synthetic PolyRule Reasoning (SPR), each data instance is a sequence of symbolic tokens carrying multiple attributes (e.g., shape and color). The classification task involves rules that integrate both positional and attribute-based dependencies. We explore whether Graph Neural Networks (GNNs) can improve over purely sequential architectures by representing each sequence as a graph that encapsulates multi-relational edges. GNNs have shown strong capabilities in capturing relational patterns~\citep{khemani2024aro}.

\section{Related Work}
Conventional deep models for symbolic pattern recognition often rely on RNNs, LSTMs, and Transformers~\citep{shiri2023aco}. These capture sequential dependencies effectively but may not fully account for relational information among tokens. GraphSAGE~\citep{hamilton2017inductiverl} addresses large-scale or inductive graph scenarios by aggregating neighbor features, and relational graph networks~\citep{ye2019avr} handle distinct edge types. Recent surveys highlight how GNNs excel at tasks requiring explicit modeling of relationships~\citep{khemani2024aro}. Despite these advances, multi-factor reasoning in synthetic tasks remains underexplored.

\section{Method}
We consider an RGCN-based model that embeds each token by shape, color, and position. Tokens sharing attributes or adjacent sequence positions are connected by relation-specific edges. We construct an RGCN~\citep{ye2019avr} with two message-passing layers, aggregating across these edges. After global average pooling, a classifier predicts the label. Sequences in the SPR\_BENCH dataset are converted to graphs: each token is a node, edges encode adjacency, same-color, and same-shape relations. Negative results from simpler GNN variants (e.g., GraphSAGE) motivated the addition of explicit multi-relational encoding.

\section{Experiments}
We use official splits for training, validation, and testing, and evaluate Color-Weighted Accuracy (CWA) and Shape-Weighted Accuracy (SWA). Our best RGCN model achieves 70\% on CWA (previous 65\%) but 65\% on SWA (previous 70\%). We also track a complexity-weighted metric (CompWA), seeing performance in the 0.65--0.70 range.

\begin{figure}[t]
\centering
\subfigure[Train vs.\ Validation Loss]{\includegraphics[width=0.45\textwidth]{Research_Loss_Curves.png}}
\subfigure[Overlaid Loss (Zoom)]{\includegraphics[width=0.45\textwidth]{Research_Loss_Overlay_Zoom.png}}\\
\subfigure[Validation Weighted Accuracies]{\includegraphics[width=0.45\textwidth]{Research_Validation_Accuracies.png}}
\subfigure[Test Weighted Accuracies]{\includegraphics[width=0.45\textwidth]{Research_Test_Accuracies.png}}
\caption{Model behavior across 20 epochs. All subfigures illustrate key aspects of training and inference. In (a), both training and validation loss decrease steadily but maintain a visible gap, suggesting partial underrepresentation of shape-centric features. (b) zooms in on the loss curves, revealing minor fluctuations in validation performance. (c) shows validation Color Weighted Accuracy (CWA) rising faster than Shape Weighted Accuracy (SWA), while (d) highlights the final test metrics. These results confirm that multi-relational modeling yields higher gains on color-based reasoning than on shape-based attributes.}
\label{fig:combined_main}
\end{figure}

As shown in \cref{fig:combined_main}, color-related features still dominate shape-based cues, raising concerns that shape information may require additional modeling strategies. The modest but persistent training--validation gap also indicates that further regularization or data augmentation could help generalization.

\section{Conclusion}
We presented an RGCN model for Synthetic PolyRule Reasoning, showing partial improvements over sequence-based baselines. While the model achieves a new high on color-centric metrics, shape-sensitive metrics remain a limiting factor. These findings highlight a key challenge: relying heavily on color-based cues may obscure underperformance on other attributes. Consequently, shape-focused enhancements should be investigated to ensure well-rounded performance. Future directions include refining multi-relational representations and exploring data augmentation or specialized attention mechanisms for shape features.

\bibliography{iclr2025}
\bibliographystyle{iclr2025}

\appendix

\section*{\LARGE Supplementary Material}
\label{sec:appendix}
\begin{figure}[h]
\centering
\subfigure[Collapsed Edge Types]{\includegraphics[width=0.3\textwidth]{Ablation_CollapsedEdgeType_Combined.png}}
\subfigure[No Color Edges]{\includegraphics[width=0.3\textwidth]{Ablation_NoColorEdges_Combined.png}}
\subfigure[Uniform Node Features]{\includegraphics[width=0.3\textwidth]{Ablation_UniformNodeFeature_Comparison.png}}
\caption{Ablation studies highlighting different graph modifications. Removing color edges or collapsing edge types produces large drops in color-centric metrics, indicating color-based relations are essential for solid performance. Uniform node features further degrade relational capacity across both color and shape attributes.}
\label{fig:ablation}
\end{figure}

In \cref{fig:ablation}, ablation results confirm that color edges act as a major driver for the observed performance gains, and removing them severely impacts Color Weighted Accuracy. Collapsing all edge types into one category additionally harms shape-based predictions, underlining the need for explicit multi-relational encoding. Uniform node features also diminish overall expressivity, as attribute distinctions become unavailable to the GNN layers. 

\paragraph{Supplementary Hyperparameters.}
Our final RGCN model uses the Adam optimizer with a learning rate of $5\times10^{-4}$, batch size 32, and 64 hidden units. Dropout is set to 0.2, and we stop early if validation loss does not improve over 10 epochs. This configuration balances training stability with computational efficiency.