{"edges": [[0, 10], [0, 11], [0, 1], [0, 5], [0, 2], [0, 6], [0, 9], [0, 8], [0, 7], [0, 4], [0, 12], [0, 3]], "layout": [[0.5, 0.0], [0.0, 1.0], [0.09090909090909091, 1.0], [0.18181818181818182, 1.0], [0.2727272727272727, 1.0], [0.36363636363636365, 1.0], [0.45454545454545453, 1.0], [0.5454545454545454, 1.0], [0.6363636363636364, 1.0], [0.7272727272727273, 1.0], [0.8181818181818182, 1.0], [0.9090909090909091, 1.0], [1.0, 1.0]], "plan": ["We will treat each SPR sequence as a graph whose nodes are the symbols (token-\nstrings).  Each node is described by a one-hot encoding of its \u201cshape\u201d (first\ncharacter) and \u201ccolor\u201d (remaining characters).  Undirected edges are added\nbetween consecutive tokens, giving minimal yet meaningful relational structure.\nWe pre-build dictionaries of all shapes and colours found in the training split\nso the same encodings are reused on dev/test.  Graphs are wrapped in torch-\ngeometric Data objects and fed to a tiny 2-layer GCN with global-mean pooling\nfollowed by a linear classifier.  During training we track Cross-Entropy loss,\nplain accuracy and the requested Complexity-Weighted Accuracy (CompWA = weight-\nsum(correct)/(weight-sum(all))).  All tensors and the model are moved to GPU\nwhen available.  At the end we evaluate on the dev set, plot the learning\ncurves, save metrics/predictions in \u201c./working\u201d, and print the final CompWA.", "Hyperparam tuning name: EPOCHS. We will evaluate a small set of EPOCHS values\n(10 / 20 / 40 / 60).   For every setting we (1) instanciate a fresh model, (2)\ntrain up to the given maximum while applying early-stopping on the validation\nloss (patience = 5), (3) keep per-epoch losses & accuracies, and (4) store the\nfinal dev-set predictions.   Results of every run are written into a single\nexperiment_data dictionary under the \u201cepochs_tuning\u201d key and finally saved to\n\u201cexperiment_data.npy\u201d, together with a loss-curve plot for each run.", "Hyperparam tuning name: learning_rate. The solution performs a simple grid-\nsearch over four learning-rates, re-initialising and training the GCN for each\nvalue, then logging losses, accuracies and complexity-weighted accuracy.\nResults for every rate are stored in a hierarchical experiment_data dictionary\nunder the key \u201clearning_rate\u201d and finally saved to\n\u2018working/experiment_data.npy\u2019.  The rest of the pipeline (data preparation,\nmodel definition, training loop, plotting) is kept unchanged.  The script is\ncompletely self-contained and executable.", "Hyperparam tuning name: batch_size. We keep the original pipeline but loop over\nseveral training-batch sizes (16, 32, 64, 128).   For every batch size we (1)\nbuild a new DataLoader, model and optimiser, (2) train for the same number of\nepochs, (3) evaluate on the dev split each epoch, (4) store all\ncurves/predictions in a hierarchical experiment_data dict and (5) plot the loss\ncurves for comparison.   Everything is self-contained and the results are saved\nto working/experiment_data.npy.", "Hyperparam tuning name: weight_decay. We build on the baseline by sweeping a\nsmall grid of Adam weight-decay values (0, 1e-5, 1e-4, 1e-3, 1e-2).   For every\ndecay we re-initialise the GCN, train for a few epochs, validate after each\nepoch, then record losses, accuracies, predictions and ground-truth in a nested\nexperiment_data dict under the key 'weight_decay'.   All results are saved to\nworking/experiment_data.npy and a loss-curve figure that overlays every decay\nvalue.", "Hyperparam tuning name: hidden_dim (GCN hidden layer size). The script below\nsweeps over four different hidden layer sizes (32, 64, 128 and 256).   For every\nhidden_dim it trains the same 2-layer GCN for a fixed number of epochs,\nevaluates on the dev split each epoch, keeps full loss / accuracy traces, and\nstores the final dev predictions together with the Complexity-Weighted Accuracy.\nAll results are collected in the specified experiment_data structure under the\nkey \"hidden_dim\" and saved to working/experiment_data.npy; a separate loss-curve\nplot is produced for each hidden size.", "Hyperparam tuning name: dropout_rate. The provided program is extended to sweep\nfour dropout rates (0.0, 0.1, 0.3, 0.5).   For each rate a GCN model with\n`Dropout` after every convolution (and before the final linear layer) is\ntrained, validated, and finally evaluated for Complexity-Weighted Accuracy.\nAll results are stored in the requested `experiment_data` structure (one top-\nlevel key per dropout configuration) and saved to `experiment_data.npy`;\nindividual loss curves are also saved.", "Hyperparam tuning name: num_gcn_layers. We iterate over three different depths\n(2, 3 and 4 stacked GCNConv layers).   For each depth we: build a model with the\nrequested number of GCN layers, train it for a few epochs, evaluate after every\nepoch on the dev split and finally compute Complexity-Weighted Accuracy.   All\nlosses, metrics, predictions and ground-truth labels are collected in a\nhierarchical experiment_data dictionary under the key \u201cnum_gcn_layers\u201d \u2192 depth\nvalue \u2192 \u201cSPR_BENCH\u201d.   After all runs we persist experiment_data (and a loss\ncurve for every depth) into the ./working directory as required.", "Hyperparam tuning name: edge_dropout_rate. We sweep edge_dropout_rate \u2208 {0.0,\n0.1, 0.2, 0.3}.   During each training step, DropEdge is applied by randomly\nmasking edges with probability p before passing the batch through the GCN;\nevaluation uses the full graph.   For every rate we re-initialise the model,\ntrain for 10 epochs, track losses/accuracies, compute the final complexity-\nweighted accuracy on the dev set, store everything in a nested experiment_data\ndict, and save it (plus loss curves) to the working directory.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ------------- required working dir -------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------- GPU/CPU handling -------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------- helper: load SPR_BENCH -------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # adjust if necessary\nif not DATA_PATH.exists():  # fallback tiny synthetic data\n    print(\"SPR_BENCH not found \u2013 creating tiny synthetic data.\")\n    os.makedirs(DATA_PATH, exist_ok=True)\n    for split, s in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        seqs, labels = [], []\n        shapes = [\"A\", \"B\", \"C\"]\n        colors = [\"1\", \"2\", \"3\"]\n        rng = np.random.default_rng(0)\n        for _ in range(s):\n            n = rng.integers(3, 7)\n            seq = \" \".join(rng.choice(shapes) + rng.choice(colors) for _ in range(n))\n            label = rng.choice([\"yes\", \"no\"])\n            seqs.append(seq)\n            labels.append(label)\n        import csv\n\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            w = csv.writer(f)\n            w.writerow([\"id\", \"sequence\", \"label\"])\n            for i, (seq, lbl) in enumerate(zip(seqs, labels)):\n                w.writerow([f\"{split}_{i}\", seq, lbl])\n\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ------------- preprocessing: build vocab -------------\ndef parse_token(tok):\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor row in dsets[\"train\"]:\n    for tok in row[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nprint(\"Shapes:\", shape2id)\nprint(\"Colours:\", col2id)\n\n# label mapping\nall_labels = sorted({row[\"label\"] for row in dsets[\"train\"]})\nlabel2id = {l: i for i, l in enumerate(all_labels)}\n\n\n# ------------- sequence -> graph -------------\ndef seq_to_graph(sequence, lbl):\n    tokens = sequence.split()\n    n = len(tokens)\n    x = []\n    for tok in tokens:\n        s, c = parse_token(tok)\n        vec = np.zeros(len(shape2id) + len(col2id), dtype=np.float32)\n        vec[shape2id[s]] = 1.0\n        vec[len(shape2id) + col2id[c]] = 1.0\n        x.append(vec)\n    x = torch.tensor(np.stack(x))\n    # edges between consecutive positions (undirected)\n    if n > 1:\n        src = torch.arange(0, n - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2id[lbl]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y)\n\n\ndef build_graph_dataset(split):\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[split]]\n\n\ngraph_train = build_graph_dataset(\"train\")\ngraph_dev = build_graph_dataset(\"dev\")\ngraph_test = build_graph_dataset(\"test\")\n\n# ------------- Dataloaders -------------\ntrain_loader = DataLoader(graph_train, batch_size=64, shuffle=True)\ndev_loader = DataLoader(graph_dev, batch_size=128, shuffle=False)\ntest_loader = DataLoader(graph_test, batch_size=128, shuffle=False)\n\n\n# ------------- model -------------\nclass GCN(torch.nn.Module):\n    def __init__(self, in_dim, hid=64, num_classes=len(label2id)):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hid)\n        self.conv2 = GCNConv(hid, hid)\n        self.lin = torch.nn.Linear(hid, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\nmodel = GCN(in_dim=len(shape2id) + len(col2id)).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ------------- Complexity Weighted Accuracy -------------\ndef complexity_weight(seq):\n    toks = seq.split()\n    shapes = {t[0] for t in toks}\n    cols = {t[1:] if len(t) > 1 else \"0\" for t in toks}\n    return len(shapes) + len(cols)\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n    return sum(good) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ------------- tracking dict -------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ------------- training loop -------------\nEPOCHS = 10\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    tot_loss, tot_corr, tot_ex = 0.0, 0, 0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch.x, batch.edge_index, batch.batch)\n        loss = F.cross_entropy(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        pred = out.argmax(dim=-1)\n        tot_corr += int((pred == batch.y).sum().item())\n        tot_ex += batch.num_graphs\n    tr_loss = tot_loss / tot_ex\n    tr_acc = tot_corr / tot_ex\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(tr_acc)\n\n    # ---- validation ----\n    model.eval()\n    v_loss, v_corr, v_ex = 0.0, 0, 0\n    all_pred, all_gt, all_seq = [], [], []\n    with torch.no_grad():\n        for batch, raw in zip(dev_loader, dsets[\"dev\"]):\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            v_loss += loss.item() * batch.num_graphs\n            pred = out.argmax(dim=-1).cpu()\n            v_corr += int((pred == batch.y.cpu()).sum().item())\n            v_ex += batch.num_graphs\n            all_pred.extend(pred.tolist())\n            all_gt.extend(batch.y.cpu().tolist())\n            all_seq.append(raw[\"sequence\"])\n    val_loss = v_loss / v_ex\n    val_acc = v_corr / v_ex\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(val_acc)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}\")\n\n# ------------- final evaluation on dev for CompWA -------------\nseqs = [row[\"sequence\"] for row in dsets[\"dev\"]]\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for batch in dev_loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.batch)\n        preds.extend(out.argmax(dim=-1).cpu().tolist())\ncompwa = comp_weighted_accuracy(\n    seqs, [label2id[r[\"label\"]] for r in dsets[\"dev\"]], preds\n)\nprint(f\"Complexity-Weighted Accuracy (dev): {compwa:.4f}\")\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = [\n    label2id[r[\"label\"]] for r in dsets[\"dev\"]\n]\n\n# ------------- plot and save -------------\nplt.figure()\nplt.plot(experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"], label=\"train\")\nplt.plot(experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"], label=\"val\")\nplt.title(\"Cross-Entropy loss\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Data & plot saved to ./working\")\n", "import os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- helper: load SPR_BENCH ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nif not DATA_PATH.exists():  # tiny synthetic fallback\n    print(\"SPR_BENCH not found \u2013 creating tiny synthetic data.\")\n    os.makedirs(DATA_PATH, exist_ok=True)\n    for split, size in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        rng = np.random.default_rng(0)\n        seqs, labels = [], []\n        shapes = [\"A\", \"B\", \"C\"]\n        colors = [\"1\", \"2\", \"3\"]\n        for _ in range(size):\n            n = rng.integers(3, 7)\n            seqs.append(\n                \" \".join(rng.choice(shapes) + rng.choice(colors) for _ in range(n))\n            )\n            labels.append(rng.choice([\"yes\", \"no\"]))\n        import csv\n\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            w = csv.writer(f)\n            w.writerow([\"id\", \"sequence\", \"label\"])\n            for i, (s, l) in enumerate(zip(seqs, labels)):\n                w.writerow([f\"{split}_{i}\", s, l])\n\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ---------- vocab ----------\ndef parse_token(tok):  # returns (shape, colour)\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor row in dsets[\"train\"]:\n    for tok in row[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nlabel2id = {l: i for i, l in enumerate(sorted({r[\"label\"] for r in dsets[\"train\"]}))}\n\n\n# ---------- seq -> graph ----------\ndef seq_to_graph(sequence, lbl):\n    toks = sequence.split()\n    n = len(toks)\n    x = []\n    for tok in toks:\n        s, c = parse_token(tok)\n        vec = np.zeros(len(shape2id) + len(col2id), dtype=np.float32)\n        vec[shape2id[s]] = 1.0\n        vec[len(shape2id) + col2id[c]] = 1.0\n        x.append(vec)\n    x = torch.tensor(np.stack(x))\n    if n > 1:\n        src = torch.arange(n - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], 0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2id[lbl]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y)\n\n\ndef build_graph_dataset(split):\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[split]]\n\n\ngraph_train, graph_dev, graph_test = map(build_graph_dataset, [\"train\", \"dev\", \"test\"])\ntrain_loader = DataLoader(graph_train, batch_size=64, shuffle=True)\ndev_loader = DataLoader(graph_dev, batch_size=128, shuffle=False)\ntest_loader = DataLoader(graph_test, batch_size=128, shuffle=False)\n\n\n# ---------- model ----------\nclass GCN(torch.nn.Module):\n    def __init__(self, in_dim, hid=64, num_classes=len(label2id)):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hid)\n        self.conv2 = GCNConv(hid, hid)\n        self.lin = torch.nn.Linear(hid, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\n# ---------- metrics ----------\ndef complexity_weight(seq):\n    toks = seq.split()\n    return len({t[0] for t in toks}) + len(\n        {(t[1:] if len(t) > 1 else \"0\") for t in toks}\n    )\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n    return sum(good) / sum(w) if sum(w) else 0.0\n\n\n# ---------- experiment storage ----------\nexperiment_data = {\"epochs_tuning\": {}}  # top level = hyperparam type\n\n# ---------- hyperparameter grid ----------\nEPOCH_OPTIONS = [10, 20, 40, 60]\npatience = 5\n\nfor max_epochs in EPOCH_OPTIONS:\n    run_key = f\"EPOCHS_{max_epochs}\"\n    experiment_data[\"epochs_tuning\"][run_key] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    model = GCN(in_dim=len(shape2id) + len(col2id)).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    best_val_loss, best_state, wait = float(\"inf\"), None, 0\n    for epoch in range(1, max_epochs + 1):\n        # ---- train ----\n        model.train()\n        tot_loss = tot_corr = tot_ex = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item() * batch.num_graphs\n            tot_corr += int((out.argmax(-1) == batch.y).sum().item())\n            tot_ex += batch.num_graphs\n        tr_loss = tot_loss / tot_ex\n        tr_acc = tot_corr / tot_ex\n\n        # ---- validation ----\n        model.eval()\n        v_loss = v_corr = v_ex = 0\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch.x, batch.edge_index, batch.batch)\n                loss = F.cross_entropy(out, batch.y)\n                v_loss += loss.item() * batch.num_graphs\n                v_corr += int((out.argmax(-1) == batch.y).sum().item())\n                v_ex += batch.num_graphs\n        val_loss = v_loss / v_ex\n        val_acc = v_corr / v_ex\n\n        # ---- store ----\n        ed = experiment_data[\"epochs_tuning\"][run_key]\n        ed[\"losses\"][\"train\"].append(tr_loss)\n        ed[\"losses\"][\"val\"].append(val_loss)\n        ed[\"metrics\"][\"train\"].append(tr_acc)\n        ed[\"metrics\"][\"val\"].append(val_acc)\n        print(f\"[{run_key}] Epoch {epoch}/{max_epochs}  val_loss={val_loss:.4f}\")\n\n        # ---- early stopping ----\n        if val_loss < best_val_loss:\n            best_val_loss, best_state, wait = val_loss, model.state_dict(), 0\n        else:\n            wait += 1\n            if wait >= patience:\n                print(f\"Early stopping at epoch {epoch}\")\n                break\n\n    # ---- load best model & evaluate ----\n    model.load_state_dict(best_state)\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            preds.extend(\n                model(batch.x, batch.edge_index, batch.batch).argmax(-1).cpu().tolist()\n            )\n    ground_truth = [label2id[r[\"label\"]] for r in dsets[\"dev\"]]\n    experiment_data[\"epochs_tuning\"][run_key][\"predictions\"] = preds\n    experiment_data[\"epochs_tuning\"][run_key][\"ground_truth\"] = ground_truth\n\n    # ---- plot ----\n    plt.figure()\n    plt.plot(ed[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(ed[\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"Loss curve ({run_key})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"CE loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_{run_key}.png\"))\n    plt.close()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All data saved to\", working_dir)\n", "import os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ----- working dir -----\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----- device -----\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----- helper: load SPR_BENCH -----\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nif not DATA_PATH.exists():  # tiny synthetic fallback\n    print(\"SPR_BENCH not found \u2013 creating tiny synthetic data.\")\n    os.makedirs(DATA_PATH, exist_ok=True)\n    for split, s in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        seqs, labels = [], []\n        shapes, colors = [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        rng = np.random.default_rng(0)\n        for _ in range(s):\n            n = rng.integers(3, 7)\n            seqs.append(\n                \" \".join(rng.choice(shapes) + rng.choice(colors) for _ in range(n))\n            )\n            labels.append(rng.choice([\"yes\", \"no\"]))\n        import csv\n\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            w = csv.writer(f)\n            w.writerow([\"id\", \"sequence\", \"label\"])\n            for i, (seq, lbl) in enumerate(zip(seqs, labels)):\n                w.writerow([f\"{split}_{i}\", seq, lbl])\n\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ----- vocab -----\ndef parse_token(tok):\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor row in dsets[\"train\"]:\n    for tok in row[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nlabel2id = {l: i for i, l in enumerate(sorted({r[\"label\"] for r in dsets[\"train\"]}))}\nprint(\"Shapes:\", shape2id, \"\\nColours:\", col2id)\n\n\n# ----- graph conversion -----\ndef seq_to_graph(sequence, lbl):\n    toks = sequence.split()\n    n = len(toks)\n    x = []\n    for tok in toks:\n        s, c = parse_token(tok)\n        vec = np.zeros(len(shape2id) + len(col2id), dtype=np.float32)\n        vec[shape2id[s]] = 1.0\n        vec[len(shape2id) + col2id[c]] = 1.0\n        x.append(vec)\n    x = torch.tensor(np.stack(x))\n    if n > 1:\n        src = torch.arange(0, n - 1)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])])\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2id[lbl]])\n    return Data(x=x, edge_index=edge_index, y=y)\n\n\ndef build_graph_dataset(split):\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[split]]\n\n\ngraph_train, graph_dev, graph_test = map(build_graph_dataset, [\"train\", \"dev\", \"test\"])\n\ntrain_loader = DataLoader(graph_train, batch_size=64, shuffle=True)\ndev_loader = DataLoader(graph_dev, batch_size=128, shuffle=False)\n\n\n# ----- model -----\nclass GCN(torch.nn.Module):\n    def __init__(self, in_dim, hid=64, num_classes=len(label2id)):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hid)\n        self.conv2 = GCNConv(hid, hid)\n        self.lin = torch.nn.Linear(hid, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\n# ----- Complexity-Weighted Accuracy -----\ndef complexity_weight(seq):\n    toks = seq.split()\n    shapes = {t[0] for t in toks}\n    cols = {t[1:] if len(t) > 1 else \"0\" for t in toks}\n    return len(shapes) + len(cols)\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n    return sum(good) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ----- experiment logging dict -----\nexperiment_data = {\"learning_rate\": {}}\n\n# ----- hyper-parameter grid -----\nlearning_rates = [5e-4, 1e-3, 2e-3, 5e-3]\nEPOCHS = 10\n\nfor lr in learning_rates:\n    print(f\"\\n=== Training with learning rate {lr} ===\")\n    model = GCN(in_dim=len(shape2id) + len(col2id)).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    run_log = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        # ---- train ----\n        model.train()\n        tot_loss = tot_corr = tot_ex = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item() * batch.num_graphs\n            tot_corr += int((out.argmax(-1) == batch.y).sum().item())\n            tot_ex += batch.num_graphs\n        tr_loss, tr_acc = tot_loss / tot_ex, tot_corr / tot_ex\n        run_log[\"losses\"][\"train\"].append(tr_loss)\n        run_log[\"metrics\"][\"train\"].append(tr_acc)\n\n        # ---- validation ----\n        model.eval()\n        v_loss = v_corr = v_ex = 0\n        preds = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch.x, batch.edge_index, batch.batch)\n                loss = F.cross_entropy(out, batch.y)\n                v_loss += loss.item() * batch.num_graphs\n                pred = out.argmax(-1).cpu()\n                preds.extend(pred.tolist())\n                v_corr += int((pred == batch.y.cpu()).sum().item())\n                v_ex += batch.num_graphs\n        val_loss, val_acc = v_loss / v_ex, v_corr / v_ex\n        run_log[\"losses\"][\"val\"].append(val_loss)\n        run_log[\"metrics\"][\"val\"].append(val_acc)\n        print(f\"  Epoch {epoch}: val_loss={val_loss:.4f}, val_acc={val_acc:.3f}\")\n\n    # ----- dev CompWA -----\n    seqs_dev = [r[\"sequence\"] for r in dsets[\"dev\"]]\n    gts_dev = [label2id[r[\"label\"]] for r in dsets[\"dev\"]]\n    compwa = comp_weighted_accuracy(seqs_dev, gts_dev, preds)\n    run_log[\"metrics\"][\"comp_weighted_accuracy\"] = compwa\n    run_log[\"predictions\"] = preds\n    run_log[\"ground_truth\"] = gts_dev\n    print(f\"  Complexity-Weighted Accuracy: {compwa:.4f}\")\n\n    # ----- store -----\n    experiment_data[\"learning_rate\"][str(lr)] = run_log\n\n    # quick plot for this lr\n    plt.figure()\n    plt.plot(run_log[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(run_log[\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"LR {lr} \u2013 Cross-Entropy\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_lr_{lr}.png\"))\n    plt.close()\n\n# ----- save all experiment data -----\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nAll data & plots saved to ./working\")\n", "import os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ------------ working dir ------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------ device ------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------ load SPR_BENCH ------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nif not DATA_PATH.exists():\n    print(\"SPR_BENCH not found \u2013 creating tiny synthetic data.\")\n    os.makedirs(DATA_PATH, exist_ok=True)\n    for split, s in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        seqs, labels, shapes, colors = [], [], [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        rng = np.random.default_rng(0)\n        for _ in range(s):\n            n = rng.integers(3, 7)\n            seqs.append(\n                \" \".join(rng.choice(shapes) + rng.choice(colors) for _ in range(n))\n            )\n            labels.append(rng.choice([\"yes\", \"no\"]))\n        import csv\n\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            w = csv.writer(f)\n            w.writerow([\"id\", \"sequence\", \"label\"])\n            for i, (seq, lbl) in enumerate(zip(seqs, labels)):\n                w.writerow([f\"{split}_{i}\", seq, lbl])\n\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ------------ vocab / label maps ------------\ndef parse_token(tok):  # token like 'A1' or 'B'\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor row in dsets[\"train\"]:\n    for tok in row[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nlabel2id = {l: i for i, l in enumerate(sorted({r[\"label\"] for r in dsets[\"train\"]}))}\nprint(\"Shapes:\", shape2id)\nprint(\"Colours:\", col2id)\n\n\n# ------------ seq -> graph ------------\ndef seq_to_graph(sequence, lbl):\n    toks = sequence.split()\n    n = len(toks)\n    x = []\n    for tok in toks:\n        s, c = parse_token(tok)\n        vec = np.zeros(len(shape2id) + len(col2id), dtype=np.float32)\n        vec[shape2id[s]] = 1.0\n        vec[len(shape2id) + col2id[c]] = 1.0\n        x.append(vec)\n    x = torch.tensor(np.stack(x))\n    if n > 1:\n        src = torch.arange(0, n - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], 0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2id[lbl]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y)\n\n\ndef build_graph_dataset(split):\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[split]]\n\n\ngraph_train, graph_dev, graph_test = map(build_graph_dataset, [\"train\", \"dev\", \"test\"])\n\n\n# ------------ model ------------\nclass GCN(torch.nn.Module):\n    def __init__(self, in_dim, hid=64, num_classes=len(label2id)):\n        super().__init__()\n        self.conv1, self.conv2 = GCNConv(in_dim, hid), GCNConv(hid, hid)\n        self.lin = torch.nn.Linear(hid, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\n# ------------ helper metrics ------------\ndef complexity_weight(seq):\n    toks = seq.split()\n    return len({t[0] for t in toks}) + len({t[1:] if len(t) > 1 else \"0\" for t in toks})\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n    return sum(good) / sum(w) if sum(w) else 0.0\n\n\n# ------------ experiment data dict ------------\nexperiment_data = {\"batch_size\": {}}\n\n\n# ------------ training function ------------\ndef run_experiment(batch_size, epochs=10):\n    tag = f\"batch_{batch_size}\"\n    experiment_data[\"batch_size\"][tag] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    train_loader = DataLoader(graph_train, batch_size=batch_size, shuffle=True)\n    dev_loader = DataLoader(\n        graph_dev, batch_size=128, shuffle=False\n    )  # eval with large batch\n    model = GCN(in_dim=len(shape2id) + len(col2id)).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for epoch in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        tot_loss = tot_corr = tot_ex = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item() * batch.num_graphs\n            tot_corr += int((out.argmax(-1) == batch.y).sum().item())\n            tot_ex += batch.num_graphs\n        experiment_data[\"batch_size\"][tag][\"losses\"][\"train\"].append(tot_loss / tot_ex)\n        experiment_data[\"batch_size\"][tag][\"metrics\"][\"train\"].append(tot_corr / tot_ex)\n\n        # ---- validation ----\n        model.eval()\n        v_loss = v_corr = v_ex = 0\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch.x, batch.edge_index, batch.batch)\n                v_loss += F.cross_entropy(out, batch.y).item() * batch.num_graphs\n                v_corr += int((out.argmax(-1) == batch.y).sum().item())\n                v_ex += batch.num_graphs\n        experiment_data[\"batch_size\"][tag][\"losses\"][\"val\"].append(v_loss / v_ex)\n        experiment_data[\"batch_size\"][tag][\"metrics\"][\"val\"].append(v_corr / v_ex)\n        print(\n            f\"[{tag}] Epoch {epoch}: val_loss={v_loss / v_ex:.4f}, val_acc={v_corr / v_ex:.4f}\"\n        )\n\n    # ---- final predictions & CompWA ----\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            preds.extend(\n                model(batch.x, batch.edge_index, batch.batch).argmax(-1).cpu().tolist()\n            )\n    gts = [label2id[r[\"label\"]] for r in dsets[\"dev\"]]\n    experiment_data[\"batch_size\"][tag][\"predictions\"] = preds\n    experiment_data[\"batch_size\"][tag][\"ground_truth\"] = gts\n    compwa = comp_weighted_accuracy([r[\"sequence\"] for r in dsets[\"dev\"]], gts, preds)\n    print(f\"[{tag}] Complexity-Weighted Accuracy (dev): {compwa:.4f}\")\n\n\n# ------------ run all batch sizes ------------\nfor bs in [16, 32, 64, 128]:\n    run_experiment(bs)\n\n# ------------ plot loss curves ------------\nplt.figure()\nfor tag, dat in experiment_data[\"batch_size\"].items():\n    plt.plot(dat[\"losses\"][\"val\"], label=f\"{tag}\")\nplt.title(\"Validation Cross-Entropy vs Epoch\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\n\n# ------------ save data ------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All data saved to ./working\")\n", "import os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ---------- hyper-parameter grid ----------\nWEIGHT_DECAYS = [0.0, 1e-5, 1e-4, 1e-3, 1e-2]\nEPOCHS = 10\nBATCH_TRAIN, BATCH_EVAL = 64, 128\ntorch.manual_seed(0)\nnp.random.seed(0)\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- data loading ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nif not DATA_PATH.exists():\n    print(\"SPR_BENCH not found \u2013 creating tiny synthetic data.\")\n    os.makedirs(DATA_PATH, exist_ok=True)\n    for split, size in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        rng = np.random.default_rng(0)\n        seqs, labels = [], []\n        shapes, cols = \"ABC\", \"123\"\n        for _ in range(size):\n            n = rng.integers(3, 7)\n            seq = \" \".join(\n                rng.choice(list(shapes)) + rng.choice(list(cols)) for _ in range(n)\n            )\n            labels.append(rng.choice([\"yes\", \"no\"]))\n            seqs.append(seq)\n        import csv\n\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            w = csv.writer(f)\n            w.writerow([\"id\", \"sequence\", \"label\"])\n            for i, (s, l) in enumerate(zip(seqs, labels)):\n                w.writerow([f\"{split}_{i}\", s, l])\n\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ---------- vocab ----------\ndef parse_token(tok):\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor row in dsets[\"train\"]:\n    for tok in row[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nlabel2id = {l: i for i, l in enumerate(sorted({r[\"label\"] for r in dsets[\"train\"]}))}\n\n\n# ---------- graph conversion ----------\ndef seq_to_graph(sequence, lbl):\n    toks = sequence.split()\n    n = len(toks)\n    feats = []\n    for tok in toks:\n        s, c = parse_token(tok)\n        vec = np.zeros(len(shape2id) + len(col2id), dtype=np.float32)\n        vec[shape2id[s]] = 1.0\n        vec[len(shape2id) + col2id[c]] = 1.0\n        feats.append(vec)\n    x = torch.tensor(np.stack(feats))\n    if n > 1:\n        src = torch.arange(n - 1)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])])\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2id[lbl]])\n    return Data(x=x, edge_index=edge_index, y=y)\n\n\ndef build_graph_dataset(split):\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[split]]\n\n\ngraph_train, graph_dev, graph_test = map(build_graph_dataset, [\"train\", \"dev\", \"test\"])\ntrain_loader = DataLoader(graph_train, batch_size=BATCH_TRAIN, shuffle=True)\ndev_loader = DataLoader(graph_dev, batch_size=BATCH_EVAL, shuffle=False)\n\n\n# ---------- metrics ----------\ndef complexity_weight(seq):\n    toks = seq.split()\n    sh = {t[0] for t in toks}\n    co = {t[1:] if len(t) > 1 else \"0\" for t in toks}\n    return len(sh) + len(co)\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n    return sum(good) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------- model ----------\nclass GCN(torch.nn.Module):\n    def __init__(self, in_dim, hid=64, n_cls=len(label2id)):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hid)\n        self.conv2 = GCNConv(hid, hid)\n        self.lin = torch.nn.Linear(hid, n_cls)\n\n    def forward(self, x, edge_index, batch):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\n# ---------- experiment container ----------\nexperiment_data = {\"weight_decay\": {\"SPR_BENCH\": {}}}\n\n# ---------- training + evaluation for each weight_decay ----------\nfor wd in WEIGHT_DECAYS:\n    print(f\"\\n=== Training with weight_decay={wd} ===\")\n    model = GCN(len(shape2id) + len(col2id)).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=wd)\n\n    key = f\"wd_{wd}\"\n    experiment_data[\"weight_decay\"][\"SPR_BENCH\"][key] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [label2id[r[\"label\"]] for r in dsets[\"dev\"]],\n    }\n\n    # --- epochs ---\n    for epoch in range(1, EPOCHS + 1):\n        # train\n        model.train()\n        tot_loss = tot_corr = tot_ex = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item() * batch.num_graphs\n            tot_corr += int((out.argmax(-1) == batch.y).sum().item())\n            tot_ex += batch.num_graphs\n        tr_loss = tot_loss / tot_ex\n        tr_acc = tot_corr / tot_ex\n\n        # validate\n        model.eval()\n        v_loss = v_corr = v_ex = 0\n        preds = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch.x, batch.edge_index, batch.batch)\n                loss = F.cross_entropy(out, batch.y)\n                v_loss += loss.item() * batch.num_graphs\n                v_corr += int((out.argmax(-1) == batch.y).sum().item())\n                v_ex += batch.num_graphs\n                preds.extend(out.argmax(-1).cpu().tolist())\n        val_loss = v_loss / v_ex\n        val_acc = v_corr / v_ex\n\n        # record\n        d = experiment_data[\"weight_decay\"][\"SPR_BENCH\"][key]\n        d[\"losses\"][\"train\"].append(tr_loss)\n        d[\"losses\"][\"val\"].append(val_loss)\n        d[\"metrics\"][\"train\"].append(tr_acc)\n        d[\"metrics\"][\"val\"].append(val_acc)\n\n        print(f\"Epoch {epoch}: train_loss={tr_loss:.4f} val_loss={val_loss:.4f}\")\n\n    # --- final dev predictions & CompWA ---\n    experiment_data[\"weight_decay\"][\"SPR_BENCH\"][key][\"predictions\"] = preds\n    compwa = comp_weighted_accuracy(\n        [r[\"sequence\"] for r in dsets[\"dev\"]],\n        experiment_data[\"weight_decay\"][\"SPR_BENCH\"][key][\"ground_truth\"],\n        preds,\n    )\n    print(f\"Weight decay {wd}: Complexity-Weighted Accuracy (dev) = {compwa:.4f}\")\n\n# ---------- plot ----------\nplt.figure(figsize=(6, 4))\nfor wd in WEIGHT_DECAYS:\n    k = f\"wd_{wd}\"\n    vals = experiment_data[\"weight_decay\"][\"SPR_BENCH\"][k][\"losses\"][\"val\"]\n    plt.plot(vals, label=k)\nplt.title(\"Validation Loss vs. Weight Decay\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved results to working/experiment_data.npy and loss_curve.png\")\n", "import os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ------------ dirs & device ------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------ load or create SPR_BENCH ------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nif not DATA_PATH.exists():\n    print(\"SPR_BENCH not found \u2013 creating tiny synthetic data.\")\n    os.makedirs(DATA_PATH, exist_ok=True)\n    rng = np.random.default_rng(0)\n    for split, s in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            import csv\n\n            w = csv.writer(f)\n            w.writerow([\"id\", \"sequence\", \"label\"])\n            for i in range(s):\n                n = rng.integers(3, 7)\n                seq = \" \".join(\n                    rng.choice(list(\"ABC\")) + str(rng.integers(1, 4)) for _ in range(n)\n                )\n                w.writerow([f\"{split}_{i}\", seq, rng.choice([\"yes\", \"no\"])])\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ------------ vocab building ------------\ndef parse_token(tok):\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor row in dsets[\"train\"]:\n    for tok in row[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nlabel2id = {l: i for i, l in enumerate(sorted({r[\"label\"] for r in dsets[\"train\"]}))}\nprint(\"Shapes\", shape2id, \"Colours\", col2id, \"Labels\", label2id)\n\n# ------------ seq -> graph ------------\nfrom torch_geometric.data import Data\n\n\ndef seq_to_graph(sequence, lbl):\n    toks = sequence.split()\n    x = []\n    for tok in toks:\n        s, c = parse_token(tok)\n        v = np.zeros(len(shape2id) + len(col2id), dtype=np.float32)\n        v[shape2id[s]] = 1.0\n        v[len(shape2id) + col2id[c]] = 1.0\n        x.append(v)\n    x = torch.tensor(np.stack(x))\n    n = len(toks)\n    if n > 1:\n        src = torch.arange(0, n - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], 0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([label2id[lbl]]))\n\n\ndef build(split):\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[split]]\n\n\ngraph_train, graph_dev, graph_test = map(build, [\"train\", \"dev\", \"test\"])\ntrain_loader = DataLoader(graph_train, batch_size=64, shuffle=True)\ndev_loader = DataLoader(graph_dev, batch_size=128, shuffle=False)\n\n\n# ------------ model definition ------------\nclass GCN(torch.nn.Module):\n    def __init__(self, in_dim, hid, num_classes):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hid)\n        self.conv2 = GCNConv(hid, hid)\n        self.lin = torch.nn.Linear(hid, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\n# ------------ helper metric ------------\ndef complexity_weight(seq):\n    toks = seq.split()\n    sh = {t[0] for t in toks}\n    co = {t[1:] if len(t) > 1 else \"0\" for t in toks}\n    return len(sh) + len(co)\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n    return sum(good) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ------------ experiment container ------------\nexperiment_data = {\"hidden_dim\": {\"SPR_BENCH\": {}}}\n\nhidden_dims = [32, 64, 128, 256]\nEPOCHS = 10\ninput_dim = len(shape2id) + len(col2id)\nseqs_dev = [r[\"sequence\"] for r in dsets[\"dev\"]]\ngt_dev = [label2id[r[\"label\"]] for r in dsets[\"dev\"]]\n\nfor hid in hidden_dims:\n    print(f\"\\n=== Hidden dim: {hid} ===\")\n    model = GCN(input_dim, hid, len(label2id)).to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n    tr_losses, tr_accs, val_losses, val_accs = [], [], [], []\n    for epoch in range(1, EPOCHS + 1):\n        # --- training ---\n        model.train()\n        tl, tc, tex = 0.0, 0, 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optim.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            loss.backward()\n            optim.step()\n            tl += loss.item() * batch.num_graphs\n            tc += int((out.argmax(-1) == batch.y).sum().item())\n            tex += batch.num_graphs\n        tr_losses.append(tl / tex)\n        tr_accs.append(tc / tex)\n\n        # --- validation ---\n        model.eval()\n        vl, vc, vex = 0.0, 0, 0\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch.x, batch.edge_index, batch.batch)\n                loss = F.cross_entropy(out, batch.y)\n                vl += loss.item() * batch.num_graphs\n                vc += int((out.argmax(-1) == batch.y).sum().item())\n                vex += batch.num_graphs\n        val_losses.append(vl / vex)\n        val_accs.append(vc / vex)\n        print(\n            f\"Epoch {epoch}: val_loss {val_losses[-1]:.4f}  val_acc {val_accs[-1]:.4f}\"\n        )\n\n    # --- final dev predictions & CompWA ---\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            preds.extend(\n                model(batch.x, batch.edge_index, batch.batch).argmax(-1).cpu().tolist()\n            )\n    compwa = comp_weighted_accuracy(seqs_dev, gt_dev, preds)\n    print(f\"Hidden {hid}: Comp-Weighted Acc = {compwa:.4f}\")\n\n    # --- save per-hid info ---\n    hdict = {\n        \"metrics\": {\"train\": tr_accs, \"val\": val_accs},\n        \"losses\": {\"train\": tr_losses, \"val\": val_losses},\n        \"predictions\": preds,\n        \"ground_truth\": gt_dev,\n        \"comp_weighted_acc\": compwa,\n    }\n    experiment_data[\"hidden_dim\"][\"SPR_BENCH\"][str(hid)] = hdict\n\n    # plot loss curve\n    plt.figure()\n    plt.plot(tr_losses, label=\"train\")\n    plt.plot(val_losses, label=\"val\")\n    plt.title(f\"Loss curve (hid={hid})\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_hid{hid}.png\"))\n    plt.close()\n\n# ------------ persist ------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All results saved in ./working/experiment_data.npy\")\n", "import os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ---------- misc ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- load SPR_BENCH ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    out = DatasetDict()\n    for s in [\"train\", \"dev\", \"test\"]:\n        out[s] = _load(f\"{s}.csv\")\n    return out\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nif not DATA_PATH.exists():  # tiny synthetic fallback\n    print(\"SPR_BENCH not found \u2013 creating tiny synthetic data.\")\n    DATA_PATH.mkdir(exist_ok=True)\n    rng = np.random.default_rng(0)\n    for split, nrows in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            import csv\n\n            w = csv.writer(f)\n            w.writerow([\"id\", \"sequence\", \"label\"])\n            for i in range(nrows):\n                n = rng.integers(3, 7)\n                seq = \" \".join(\n                    rng.choice(list(\"ABC\")) + rng.choice(list(\"123\")) for _ in range(n)\n                )\n                w.writerow([f\"{split}_{i}\", seq, rng.choice([\"yes\", \"no\"])])\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ---------- vocab ----------\ndef parse_token(tok):\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor row in dsets[\"train\"]:\n    for tok in row[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nlabel2id = {l: i for i, l in enumerate(sorted({r[\"label\"] for r in dsets[\"train\"]}))}\nprint(\"Shapes:\", shape2id, \"\\nColours:\", col2id, \"\\nLabels:\", label2id)\n\n\n# ---------- sequence \u279c graph ----------\ndef seq_to_graph(sequence, lbl):\n    toks = sequence.split()\n    feats = []\n    for tok in toks:\n        s, c = parse_token(tok)\n        vec = np.zeros(len(shape2id) + len(col2id), np.float32)\n        vec[shape2id[s]] = 1.0\n        vec[len(shape2id) + col2id[c]] = 1.0\n        feats.append(vec)\n    x = torch.tensor(np.stack(feats))\n    n = len(toks)\n    if n > 1:\n        src = torch.arange(n - 1)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])])\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2id[lbl]])\n    return Data(x=x, edge_index=edge_index, y=y)\n\n\ndef build_split(split):\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[split]]\n\n\ngraph_train, graph_dev, graph_test = map(build_split, [\"train\", \"dev\", \"test\"])\ntrain_loader = DataLoader(graph_train, batch_size=64, shuffle=True)\ndev_loader = DataLoader(graph_dev, batch_size=128)\n\n\n# ---------- metrics ----------\ndef complexity_weight(seq):\n    t = seq.split()\n    return len({tok[0] for tok in t}) + len(\n        {tok[1:] if len(tok) > 1 else \"0\" for tok in t}\n    )\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n    return sum(good) / sum(w) if sum(w) else 0.0\n\n\n# ---------- model ----------\nclass GCN(torch.nn.Module):\n    def __init__(self, in_dim, hid, n_classes, dropout):\n        super().__init__()\n        self.c1 = GCNConv(in_dim, hid)\n        self.c2 = GCNConv(hid, hid)\n        self.lin = torch.nn.Linear(hid, n_classes)\n        self.dropout = dropout\n\n    def forward(self, x, edge_index, batch):\n        x = F.relu(self.c1(x, edge_index))\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = F.relu(self.c2(x, edge_index))\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = global_mean_pool(x, batch)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        return self.lin(x)\n\n\n# ---------- experiment container ----------\nexperiment_data = {}\ndropout_rates = [0.0, 0.1, 0.3, 0.5]\nEPOCHS = 10\n\nfor dr in dropout_rates:\n    tag = f\"dropout_{dr}\"\n    experiment_data[tag] = {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n    model = GCN(\n        in_dim=len(shape2id) + len(col2id), hid=64, n_classes=len(label2id), dropout=dr\n    ).to(device)\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    # ---- train epochs ----\n    for ep in range(1, EPOCHS + 1):\n        model.train()\n        tot_loss = tot_cor = tot_ex = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            opt.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            loss.backward()\n            opt.step()\n            tot_loss += loss.item() * batch.num_graphs\n            tot_cor += int((out.argmax(-1) == batch.y).sum())\n            tot_ex += batch.num_graphs\n        tr_loss, tr_acc = tot_loss / tot_ex, tot_cor / tot_ex\n        experiment_data[tag][\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n        experiment_data[tag][\"SPR_BENCH\"][\"metrics\"][\"train\"].append(tr_acc)\n\n        # ---- validation ----\n        model.eval()\n        v_loss = v_cor = v_ex = 0\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch.x, batch.edge_index, batch.batch)\n                v_loss += F.cross_entropy(out, batch.y).item() * batch.num_graphs\n                v_cor += int((out.argmax(-1) == batch.y).sum())\n                v_ex += batch.num_graphs\n        val_loss, val_acc = v_loss / v_ex, v_cor / v_ex\n        experiment_data[tag][\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n        experiment_data[tag][\"SPR_BENCH\"][\"metrics\"][\"val\"].append(val_acc)\n        print(f\"[{tag}] Epoch {ep:02d}  val_loss={val_loss:.4f}\")\n\n    # ---- final dev evaluation for CompWA ----\n    seqs = [r[\"sequence\"] for r in dsets[\"dev\"]]\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            preds.extend(\n                model(batch.x, batch.edge_index, batch.batch).argmax(-1).cpu().tolist()\n            )\n    compwa = comp_weighted_accuracy(\n        seqs, [label2id[r[\"label\"]] for r in dsets[\"dev\"]], preds\n    )\n    print(f\"[{tag}] Complexity-Weighted Accuracy: {compwa:.4f}\")\n    edict = experiment_data[tag][\"SPR_BENCH\"]\n    edict[\"predictions\"] = preds\n    edict[\"ground_truth\"] = [label2id[r[\"label\"]] for r in dsets[\"dev\"]]\n    edict[\"comp_weighted_acc\"] = compwa\n\n    # ---- plot ----\n    plt.figure()\n    plt.plot(edict[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(edict[\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"Loss curve \u2013 {tag}\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_{tag}.png\"))\n    plt.close()\n\n# ---------- save all ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All data saved to ./working/experiment_data.npy\")\n", "import os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ------------ required working dir -------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------ GPU/CPU handling -------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------ helper: load SPR_BENCH -------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nif not DATA_PATH.exists():  # build tiny synthetic fallback\n    print(\"SPR_BENCH not found \u2013 creating tiny synthetic data.\")\n    os.makedirs(DATA_PATH, exist_ok=True)\n    for split, s in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        rng = np.random.default_rng(0)\n        shapes, colors = [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        seqs, labels = [], []\n        for _ in range(s):\n            n = rng.integers(3, 7)\n            seq = \" \".join(rng.choice(shapes) + rng.choice(colors) for _ in range(n))\n            labels.append(rng.choice([\"yes\", \"no\"]))\n            seqs.append(seq)\n        import csv\n\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            w = csv.writer(f)\n            w.writerow([\"id\", \"sequence\", \"label\"])\n            for i, (seq, lbl) in enumerate(zip(seqs, labels)):\n                w.writerow([f\"{split}_{i}\", seq, lbl])\n\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ------------ vocab -------------\ndef parse_token(tok):\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor row in dsets[\"train\"]:\n    for tok in row[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nlabel2id = {l: i for i, l in enumerate(sorted({r[\"label\"] for r in dsets[\"train\"]}))}\nprint(\"Shapes:\", shape2id, \"\\nColours:\", col2id)\n\n\n# ------------ sequence -> graph conversion -------------\ndef seq_to_graph(sequence, lbl):\n    toks = sequence.split()\n    n = len(toks)\n    x = []\n    for tok in toks:\n        s, c = parse_token(tok)\n        vec = np.zeros(len(shape2id) + len(col2id), dtype=np.float32)\n        vec[shape2id[s]] = 1.0\n        vec[len(shape2id) + col2id[c]] = 1.0\n        x.append(vec)\n    x = torch.tensor(np.stack(x))\n    if n > 1:\n        src = torch.arange(0, n - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2id[lbl]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y)\n\n\ndef build_graph_dataset(split):\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[split]]\n\n\ngraph_train, graph_dev, graph_test = map(build_graph_dataset, [\"train\", \"dev\", \"test\"])\ntrain_loader = DataLoader(graph_train, batch_size=64, shuffle=True)\ndev_loader = DataLoader(graph_dev, batch_size=128, shuffle=False)\ntest_loader = DataLoader(graph_test, batch_size=128, shuffle=False)\n\n\n# ------------ dynamic GCN -------------\nclass GCNStack(torch.nn.Module):\n    def __init__(self, in_dim, hid, num_layers, num_classes):\n        super().__init__()\n        self.convs = torch.nn.ModuleList()\n        if num_layers < 1:\n            raise ValueError(\"num_layers must be >=1\")\n        self.convs.append(GCNConv(in_dim, hid))\n        for _ in range(num_layers - 1):\n            self.convs.append(GCNConv(hid, hid))\n        self.lin = torch.nn.Linear(hid, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        for conv in self.convs:\n            x = conv(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\n# ------------ metric helpers -------------\ndef complexity_weight(seq):\n    toks = seq.split()\n    shapes = {t[0] for t in toks}\n    cols = {t[1:] if len(t) > 1 else \"0\" for t in toks}\n    return len(shapes) + len(cols)\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    return (\n        sum(wi if a == b else 0 for wi, a, b in zip(w, y_true, y_pred)) / sum(w)\n        if sum(w) > 0\n        else 0.0\n    )\n\n\n# ------------ experiment data container -------------\nexperiment_data = {\"num_gcn_layers\": {}}\n\nDEPTHS = [2, 3, 4]\nEPOCHS = 10\n\nfor depth in DEPTHS:\n    print(f\"\\n=== Training model with {depth} GCN layers ===\")\n    run_key = str(depth)\n    experiment_data[\"num_gcn_layers\"][run_key] = {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n    model = GCNStack(\n        len(shape2id) + len(col2id), hid=64, num_layers=depth, num_classes=len(label2id)\n    ).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    # ---- training loop ----\n    for epoch in range(1, EPOCHS + 1):\n        model.train()\n        tot_loss = tot_corr = tot_ex = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item() * batch.num_graphs\n            tot_corr += int((out.argmax(-1) == batch.y).sum().item())\n            tot_ex += batch.num_graphs\n        tr_loss, tr_acc = tot_loss / tot_ex, tot_corr / tot_ex\n        ed = experiment_data[\"num_gcn_layers\"][run_key][\"SPR_BENCH\"]\n        ed[\"losses\"][\"train\"].append(tr_loss)\n        ed[\"metrics\"][\"train\"].append(tr_acc)\n\n        # ---- validation ----\n        model.eval()\n        v_loss = v_corr = v_ex = 0\n        all_pred = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch.x, batch.edge_index, batch.batch)\n                loss = F.cross_entropy(out, batch.y)\n                v_loss += loss.item() * batch.num_graphs\n                preds = out.argmax(-1).cpu()\n                v_corr += int((preds == batch.y.cpu()).sum().item())\n                v_ex += batch.num_graphs\n                all_pred.extend(preds.tolist())\n        val_loss, val_acc = v_loss / v_ex, v_corr / v_ex\n        ed[\"losses\"][\"val\"].append(val_loss)\n        ed[\"metrics\"][\"val\"].append(val_acc)\n        print(\n            f\"Depth {depth} | Epoch {epoch} | val_loss {val_loss:.4f} | val_acc {val_acc:.3f}\"\n        )\n\n    # ---- Complexity Weighted Acc on dev ----\n    dev_seqs = [r[\"sequence\"] for r in dsets[\"dev\"]]\n    y_true = [label2id[r[\"label\"]] for r in dsets[\"dev\"]]\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            preds.extend(\n                model(batch.x, batch.edge_index, batch.batch).argmax(-1).cpu().tolist()\n            )\n    compwa = comp_weighted_accuracy(dev_seqs, y_true, preds)\n    print(f\"Depth {depth} | Complexity Weighted Accuracy (dev): {compwa:.4f}\")\n    ed[\"predictions\"] = preds\n    ed[\"ground_truth\"] = y_true\n    ed[\"compWA\"] = compwa\n\n    # ---- plot loss curve for this depth ----\n    plt.figure()\n    plt.plot(ed[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(ed[\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"Loss curve \u2013 {depth} GCN layers\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_depth_{depth}.png\"))\n    plt.close()\n\n# ------------ save experiment data -------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nAll experiments finished. Data saved to ./working/experiment_data.npy\")\n", "import os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ---------- paths / device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"device:\", device)\n\n\n# ---------- load SPR_BENCH ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")\nif not DATA_PATH.exists():\n    print(\"SPR_BENCH not found \u2013 creating synthetic tiny data.\")\n    DATA_PATH.mkdir(exist_ok=True)\n    rng = np.random.default_rng(0)\n    for split, size in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        rows = [[\"id\", \"sequence\", \"label\"]]\n        for i in range(size):\n            n = rng.integers(3, 7)\n            seq = \" \".join(\n                rng.choice(list(\"ABC\")) + rng.choice(list(\"123\")) for _ in range(n)\n            )\n            rows.append([f\"{split}_{i}\", seq, rng.choice([\"yes\", \"no\"])])\n        import csv, itertools\n\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            csv.writer(f).writerows(rows)\n\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ---------- vocab & label mapping ----------\ndef parse_token(tok):\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor r in dsets[\"train\"]:\n    for tok in r[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nlabel2id = {l: i for i, l in enumerate(sorted({r[\"label\"] for r in dsets[\"train\"]}))}\n\n\n# ---------- seq -> pyg graph ----------\ndef seq_to_graph(sequence, lbl):\n    toks = sequence.split()\n    n = len(toks)\n    x = []\n    for tok in toks:\n        s, c = parse_token(tok)\n        vec = np.zeros(len(shape2id) + len(col2id), dtype=np.float32)\n        vec[shape2id[s]] = 1.0\n        vec[len(shape2id) + col2id[c]] = 1.0\n        x.append(vec)\n    x = torch.tensor(np.stack(x))\n    if n > 1:\n        src = torch.arange(n - 1)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])])\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=torch.tensor([label2id[lbl]]))\n\n\ngraph_train = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[\"train\"]]\ngraph_dev = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[\"dev\"]]\ngraph_test = [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[\"test\"]]\n\n# ---------- data loaders ----------\ntrain_loader = DataLoader(graph_train, batch_size=64, shuffle=True)\ndev_loader = DataLoader(graph_dev, batch_size=128, shuffle=False)\n\n\n# ---------- model ----------\nclass GCN(torch.nn.Module):\n    def __init__(self, in_dim, hid=64, num_classes=len(label2id)):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hid)\n        self.conv2 = GCNConv(hid, hid)\n        self.lin = torch.nn.Linear(hid, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\n# ---------- utils ----------\ndef drop_edges(edge_index, drop_prob):\n    if drop_prob <= 0:\n        return edge_index\n    mask = torch.rand(edge_index.size(1), device=edge_index.device) > drop_prob\n    return edge_index[:, mask]\n\n\ndef complexity_weight(seq):\n    toks = seq.split()\n    return len({t[0] for t in toks}) + len(\n        {(t[1:] if len(t) > 1 else \"0\") for t in toks}\n    )\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n    return sum(good) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------- experiment data ----------\nexperiment_data = {\"edge_dropout\": {}}\n\n# ---------- sweep ----------\ndrop_rates = [0.0, 0.1, 0.2, 0.3]\nEPOCHS = 10\nin_dim = len(shape2id) + len(col2id)\n\nfor p in drop_rates:\n    tag = f\"p_{p}\"\n    experiment_data[\"edge_dropout\"][tag] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    model = GCN(in_dim).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    # ---- training ----\n    for epoch in range(1, EPOCHS + 1):\n        model.train()\n        tot_loss = tot_corr = tot_n = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            ei = drop_edges(batch.edge_index, p)\n            out = model(batch.x, ei, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item() * batch.num_graphs\n            tot_corr += (out.argmax(-1) == batch.y).sum().item()\n            tot_n += batch.num_graphs\n        tr_loss = tot_loss / tot_n\n        tr_acc = tot_corr / tot_n\n        experiment_data[\"edge_dropout\"][tag][\"losses\"][\"train\"].append(tr_loss)\n        experiment_data[\"edge_dropout\"][tag][\"metrics\"][\"train\"].append(tr_acc)\n        # ---- validation ----\n        model.eval()\n        v_loss = v_corr = v_n = 0\n        preds = []\n        gts = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch.x, batch.edge_index, batch.batch)\n                loss = F.cross_entropy(out, batch.y)\n                v_loss += loss.item() * batch.num_graphs\n                pr = out.argmax(-1)\n                preds.extend(pr.cpu().tolist())\n                gts.extend(batch.y.cpu().tolist())\n                v_corr += (pr == batch.y).sum().item()\n                v_n += batch.num_graphs\n        val_loss = v_loss / v_n\n        val_acc = v_corr / v_n\n        experiment_data[\"edge_dropout\"][tag][\"losses\"][\"val\"].append(val_loss)\n        experiment_data[\"edge_dropout\"][tag][\"metrics\"][\"val\"].append(val_acc)\n        if epoch == EPOCHS:  # store final preds\n            experiment_data[\"edge_dropout\"][tag][\"predictions\"] = preds\n            experiment_data[\"edge_dropout\"][tag][\"ground_truth\"] = gts\n        print(f\"[p={p}] epoch {epoch}: val_loss={val_loss:.4f}\")\n    # ---- Comp-Weighted Acc on dev ----\n    seqs = [r[\"sequence\"] for r in dsets[\"dev\"]]\n    cwa = comp_weighted_accuracy(seqs, gts, preds)\n    experiment_data[\"edge_dropout\"][tag][\"comp_weighted_acc\"] = cwa\n    print(f\"[p={p}] Complexity-Weighted Acc (dev): {cwa:.4f}\")\n\n# ---------- save & plot ----------\nfor tag in experiment_data[\"edge_dropout\"]:\n    plt.figure()\n    plt.plot(experiment_data[\"edge_dropout\"][tag][\"losses\"][\"train\"], label=\"train\")\n    plt.plot(experiment_data[\"edge_dropout\"][tag][\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"Loss (edge_dropout={tag})\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_{tag}.png\"))\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All results saved to ./working\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ------------- required working dir -------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------- GPU/CPU handling -------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------- helper: load SPR_BENCH -------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # adjust if necessary\nif not DATA_PATH.exists():  # fallback tiny synthetic data\n    print(\"SPR_BENCH not found \u2013 creating tiny synthetic data.\")\n    os.makedirs(DATA_PATH, exist_ok=True)\n    for split, s in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        seqs, labels = [], []\n        shapes = [\"A\", \"B\", \"C\"]\n        colors = [\"1\", \"2\", \"3\"]\n        rng = np.random.default_rng(0)\n        for _ in range(s):\n            n = rng.integers(3, 7)\n            seq = \" \".join(rng.choice(shapes) + rng.choice(colors) for _ in range(n))\n            label = rng.choice([\"yes\", \"no\"])\n            seqs.append(seq)\n            labels.append(label)\n        import csv\n\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            w = csv.writer(f)\n            w.writerow([\"id\", \"sequence\", \"label\"])\n            for i, (seq, lbl) in enumerate(zip(seqs, labels)):\n                w.writerow([f\"{split}_{i}\", seq, lbl])\n\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ------------- preprocessing: build vocab -------------\ndef parse_token(tok):\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor row in dsets[\"train\"]:\n    for tok in row[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nprint(\"Shapes:\", shape2id)\nprint(\"Colours:\", col2id)\n\n# label mapping\nall_labels = sorted({row[\"label\"] for row in dsets[\"train\"]})\nlabel2id = {l: i for i, l in enumerate(all_labels)}\n\n\n# ------------- sequence -> graph -------------\ndef seq_to_graph(sequence, lbl):\n    tokens = sequence.split()\n    n = len(tokens)\n    x = []\n    for tok in tokens:\n        s, c = parse_token(tok)\n        vec = np.zeros(len(shape2id) + len(col2id), dtype=np.float32)\n        vec[shape2id[s]] = 1.0\n        vec[len(shape2id) + col2id[c]] = 1.0\n        x.append(vec)\n    x = torch.tensor(np.stack(x))\n    # edges between consecutive positions (undirected)\n    if n > 1:\n        src = torch.arange(0, n - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2id[lbl]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y)\n\n\ndef build_graph_dataset(split):\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[split]]\n\n\ngraph_train = build_graph_dataset(\"train\")\ngraph_dev = build_graph_dataset(\"dev\")\ngraph_test = build_graph_dataset(\"test\")\n\n# ------------- Dataloaders -------------\ntrain_loader = DataLoader(graph_train, batch_size=64, shuffle=True)\ndev_loader = DataLoader(graph_dev, batch_size=128, shuffle=False)\ntest_loader = DataLoader(graph_test, batch_size=128, shuffle=False)\n\n\n# ------------- model -------------\nclass GCN(torch.nn.Module):\n    def __init__(self, in_dim, hid=64, num_classes=len(label2id)):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hid)\n        self.conv2 = GCNConv(hid, hid)\n        self.lin = torch.nn.Linear(hid, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\nmodel = GCN(in_dim=len(shape2id) + len(col2id)).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ------------- Complexity Weighted Accuracy -------------\ndef complexity_weight(seq):\n    toks = seq.split()\n    shapes = {t[0] for t in toks}\n    cols = {t[1:] if len(t) > 1 else \"0\" for t in toks}\n    return len(shapes) + len(cols)\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n    return sum(good) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ------------- tracking dict -------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ------------- training loop -------------\nEPOCHS = 10\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    tot_loss, tot_corr, tot_ex = 0.0, 0, 0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch.x, batch.edge_index, batch.batch)\n        loss = F.cross_entropy(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        pred = out.argmax(dim=-1)\n        tot_corr += int((pred == batch.y).sum().item())\n        tot_ex += batch.num_graphs\n    tr_loss = tot_loss / tot_ex\n    tr_acc = tot_corr / tot_ex\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(tr_acc)\n\n    # ---- validation ----\n    model.eval()\n    v_loss, v_corr, v_ex = 0.0, 0, 0\n    all_pred, all_gt, all_seq = [], [], []\n    with torch.no_grad():\n        for batch, raw in zip(dev_loader, dsets[\"dev\"]):\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            v_loss += loss.item() * batch.num_graphs\n            pred = out.argmax(dim=-1).cpu()\n            v_corr += int((pred == batch.y.cpu()).sum().item())\n            v_ex += batch.num_graphs\n            all_pred.extend(pred.tolist())\n            all_gt.extend(batch.y.cpu().tolist())\n            all_seq.append(raw[\"sequence\"])\n    val_loss = v_loss / v_ex\n    val_acc = v_corr / v_ex\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(val_acc)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}\")\n\n# ------------- final evaluation on dev for CompWA -------------\nseqs = [row[\"sequence\"] for row in dsets[\"dev\"]]\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for batch in dev_loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.batch)\n        preds.extend(out.argmax(dim=-1).cpu().tolist())\ncompwa = comp_weighted_accuracy(\n    seqs, [label2id[r[\"label\"]] for r in dsets[\"dev\"]], preds\n)\nprint(f\"Complexity-Weighted Accuracy (dev): {compwa:.4f}\")\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = [\n    label2id[r[\"label\"]] for r in dsets[\"dev\"]\n]\n\n# ------------- plot and save -------------\nplt.figure()\nplt.plot(experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"], label=\"train\")\nplt.plot(experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"], label=\"val\")\nplt.title(\"Cross-Entropy loss\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Data & plot saved to ./working\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ------------- required working dir -------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------- GPU/CPU handling -------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------- helper: load SPR_BENCH -------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # adjust if necessary\nif not DATA_PATH.exists():  # fallback tiny synthetic data\n    print(\"SPR_BENCH not found \u2013 creating tiny synthetic data.\")\n    os.makedirs(DATA_PATH, exist_ok=True)\n    for split, s in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        seqs, labels = [], []\n        shapes = [\"A\", \"B\", \"C\"]\n        colors = [\"1\", \"2\", \"3\"]\n        rng = np.random.default_rng(0)\n        for _ in range(s):\n            n = rng.integers(3, 7)\n            seq = \" \".join(rng.choice(shapes) + rng.choice(colors) for _ in range(n))\n            label = rng.choice([\"yes\", \"no\"])\n            seqs.append(seq)\n            labels.append(label)\n        import csv\n\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            w = csv.writer(f)\n            w.writerow([\"id\", \"sequence\", \"label\"])\n            for i, (seq, lbl) in enumerate(zip(seqs, labels)):\n                w.writerow([f\"{split}_{i}\", seq, lbl])\n\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ------------- preprocessing: build vocab -------------\ndef parse_token(tok):\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor row in dsets[\"train\"]:\n    for tok in row[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nprint(\"Shapes:\", shape2id)\nprint(\"Colours:\", col2id)\n\n# label mapping\nall_labels = sorted({row[\"label\"] for row in dsets[\"train\"]})\nlabel2id = {l: i for i, l in enumerate(all_labels)}\n\n\n# ------------- sequence -> graph -------------\ndef seq_to_graph(sequence, lbl):\n    tokens = sequence.split()\n    n = len(tokens)\n    x = []\n    for tok in tokens:\n        s, c = parse_token(tok)\n        vec = np.zeros(len(shape2id) + len(col2id), dtype=np.float32)\n        vec[shape2id[s]] = 1.0\n        vec[len(shape2id) + col2id[c]] = 1.0\n        x.append(vec)\n    x = torch.tensor(np.stack(x))\n    # edges between consecutive positions (undirected)\n    if n > 1:\n        src = torch.arange(0, n - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2id[lbl]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y)\n\n\ndef build_graph_dataset(split):\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[split]]\n\n\ngraph_train = build_graph_dataset(\"train\")\ngraph_dev = build_graph_dataset(\"dev\")\ngraph_test = build_graph_dataset(\"test\")\n\n# ------------- Dataloaders -------------\ntrain_loader = DataLoader(graph_train, batch_size=64, shuffle=True)\ndev_loader = DataLoader(graph_dev, batch_size=128, shuffle=False)\ntest_loader = DataLoader(graph_test, batch_size=128, shuffle=False)\n\n\n# ------------- model -------------\nclass GCN(torch.nn.Module):\n    def __init__(self, in_dim, hid=64, num_classes=len(label2id)):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hid)\n        self.conv2 = GCNConv(hid, hid)\n        self.lin = torch.nn.Linear(hid, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\nmodel = GCN(in_dim=len(shape2id) + len(col2id)).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ------------- Complexity Weighted Accuracy -------------\ndef complexity_weight(seq):\n    toks = seq.split()\n    shapes = {t[0] for t in toks}\n    cols = {t[1:] if len(t) > 1 else \"0\" for t in toks}\n    return len(shapes) + len(cols)\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n    return sum(good) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ------------- tracking dict -------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ------------- training loop -------------\nEPOCHS = 10\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    tot_loss, tot_corr, tot_ex = 0.0, 0, 0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch.x, batch.edge_index, batch.batch)\n        loss = F.cross_entropy(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        pred = out.argmax(dim=-1)\n        tot_corr += int((pred == batch.y).sum().item())\n        tot_ex += batch.num_graphs\n    tr_loss = tot_loss / tot_ex\n    tr_acc = tot_corr / tot_ex\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(tr_acc)\n\n    # ---- validation ----\n    model.eval()\n    v_loss, v_corr, v_ex = 0.0, 0, 0\n    all_pred, all_gt, all_seq = [], [], []\n    with torch.no_grad():\n        for batch, raw in zip(dev_loader, dsets[\"dev\"]):\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            v_loss += loss.item() * batch.num_graphs\n            pred = out.argmax(dim=-1).cpu()\n            v_corr += int((pred == batch.y.cpu()).sum().item())\n            v_ex += batch.num_graphs\n            all_pred.extend(pred.tolist())\n            all_gt.extend(batch.y.cpu().tolist())\n            all_seq.append(raw[\"sequence\"])\n    val_loss = v_loss / v_ex\n    val_acc = v_corr / v_ex\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(val_acc)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}\")\n\n# ------------- final evaluation on dev for CompWA -------------\nseqs = [row[\"sequence\"] for row in dsets[\"dev\"]]\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for batch in dev_loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.batch)\n        preds.extend(out.argmax(dim=-1).cpu().tolist())\ncompwa = comp_weighted_accuracy(\n    seqs, [label2id[r[\"label\"]] for r in dsets[\"dev\"]], preds\n)\nprint(f\"Complexity-Weighted Accuracy (dev): {compwa:.4f}\")\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = [\n    label2id[r[\"label\"]] for r in dsets[\"dev\"]\n]\n\n# ------------- plot and save -------------\nplt.figure()\nplt.plot(experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"], label=\"train\")\nplt.plot(experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"], label=\"val\")\nplt.title(\"Cross-Entropy loss\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Data & plot saved to ./working\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, time, numpy as np, torch, torch.nn.functional as F, matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# ------------- required working dir -------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------- GPU/CPU handling -------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------- helper: load SPR_BENCH -------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # adjust if necessary\nif not DATA_PATH.exists():  # fallback tiny synthetic data\n    print(\"SPR_BENCH not found \u2013 creating tiny synthetic data.\")\n    os.makedirs(DATA_PATH, exist_ok=True)\n    for split, s in [(\"train\", 200), (\"dev\", 40), (\"test\", 40)]:\n        seqs, labels = [], []\n        shapes = [\"A\", \"B\", \"C\"]\n        colors = [\"1\", \"2\", \"3\"]\n        rng = np.random.default_rng(0)\n        for _ in range(s):\n            n = rng.integers(3, 7)\n            seq = \" \".join(rng.choice(shapes) + rng.choice(colors) for _ in range(n))\n            label = rng.choice([\"yes\", \"no\"])\n            seqs.append(seq)\n            labels.append(label)\n        import csv\n\n        with open(DATA_PATH / f\"{split}.csv\", \"w\", newline=\"\") as f:\n            w = csv.writer(f)\n            w.writerow([\"id\", \"sequence\", \"label\"])\n            for i, (seq, lbl) in enumerate(zip(seqs, labels)):\n                w.writerow([f\"{split}_{i}\", seq, lbl])\n\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ------------- preprocessing: build vocab -------------\ndef parse_token(tok):\n    return tok[0], tok[1:] if len(tok) > 1 else \"0\"\n\n\nshapes, colours = set(), set()\nfor row in dsets[\"train\"]:\n    for tok in row[\"sequence\"].split():\n        s, c = parse_token(tok)\n        shapes.add(s)\n        colours.add(c)\nshape2id = {s: i for i, s in enumerate(sorted(shapes))}\ncol2id = {c: i for i, c in enumerate(sorted(colours))}\nprint(\"Shapes:\", shape2id)\nprint(\"Colours:\", col2id)\n\n# label mapping\nall_labels = sorted({row[\"label\"] for row in dsets[\"train\"]})\nlabel2id = {l: i for i, l in enumerate(all_labels)}\n\n\n# ------------- sequence -> graph -------------\ndef seq_to_graph(sequence, lbl):\n    tokens = sequence.split()\n    n = len(tokens)\n    x = []\n    for tok in tokens:\n        s, c = parse_token(tok)\n        vec = np.zeros(len(shape2id) + len(col2id), dtype=np.float32)\n        vec[shape2id[s]] = 1.0\n        vec[len(shape2id) + col2id[c]] = 1.0\n        x.append(vec)\n    x = torch.tensor(np.stack(x))\n    # edges between consecutive positions (undirected)\n    if n > 1:\n        src = torch.arange(0, n - 1, dtype=torch.long)\n        dst = src + 1\n        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])], dim=0)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2id[lbl]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y)\n\n\ndef build_graph_dataset(split):\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in dsets[split]]\n\n\ngraph_train = build_graph_dataset(\"train\")\ngraph_dev = build_graph_dataset(\"dev\")\ngraph_test = build_graph_dataset(\"test\")\n\n# ------------- Dataloaders -------------\ntrain_loader = DataLoader(graph_train, batch_size=64, shuffle=True)\ndev_loader = DataLoader(graph_dev, batch_size=128, shuffle=False)\ntest_loader = DataLoader(graph_test, batch_size=128, shuffle=False)\n\n\n# ------------- model -------------\nclass GCN(torch.nn.Module):\n    def __init__(self, in_dim, hid=64, num_classes=len(label2id)):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hid)\n        self.conv2 = GCNConv(hid, hid)\n        self.lin = torch.nn.Linear(hid, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\nmodel = GCN(in_dim=len(shape2id) + len(col2id)).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ------------- Complexity Weighted Accuracy -------------\ndef complexity_weight(seq):\n    toks = seq.split()\n    shapes = {t[0] for t in toks}\n    cols = {t[1:] if len(t) > 1 else \"0\" for t in toks}\n    return len(shapes) + len(cols)\n\n\ndef comp_weighted_accuracy(seqs, y_true, y_pred):\n    w = [complexity_weight(s) for s in seqs]\n    good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n    return sum(good) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ------------- tracking dict -------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ------------- training loop -------------\nEPOCHS = 10\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    tot_loss, tot_corr, tot_ex = 0.0, 0, 0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch.x, batch.edge_index, batch.batch)\n        loss = F.cross_entropy(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n        pred = out.argmax(dim=-1)\n        tot_corr += int((pred == batch.y).sum().item())\n        tot_ex += batch.num_graphs\n    tr_loss = tot_loss / tot_ex\n    tr_acc = tot_corr / tot_ex\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(tr_acc)\n\n    # ---- validation ----\n    model.eval()\n    v_loss, v_corr, v_ex = 0.0, 0, 0\n    all_pred, all_gt, all_seq = [], [], []\n    with torch.no_grad():\n        for batch, raw in zip(dev_loader, dsets[\"dev\"]):\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = F.cross_entropy(out, batch.y)\n            v_loss += loss.item() * batch.num_graphs\n            pred = out.argmax(dim=-1).cpu()\n            v_corr += int((pred == batch.y.cpu()).sum().item())\n            v_ex += batch.num_graphs\n            all_pred.extend(pred.tolist())\n            all_gt.extend(batch.y.cpu().tolist())\n            all_seq.append(raw[\"sequence\"])\n    val_loss = v_loss / v_ex\n    val_acc = v_corr / v_ex\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(val_acc)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}\")\n\n# ------------- final evaluation on dev for CompWA -------------\nseqs = [row[\"sequence\"] for row in dsets[\"dev\"]]\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for batch in dev_loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.batch)\n        preds.extend(out.argmax(dim=-1).cpu().tolist())\ncompwa = comp_weighted_accuracy(\n    seqs, [label2id[r[\"label\"]] for r in dsets[\"dev\"]], preds\n)\nprint(f\"Complexity-Weighted Accuracy (dev): {compwa:.4f}\")\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = [\n    label2id[r[\"label\"]] for r in dsets[\"dev\"]\n]\n\n# ------------- plot and save -------------\nplt.figure()\nplt.plot(experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"], label=\"train\")\nplt.plot(experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"], label=\"val\")\nplt.title(\"Cross-Entropy loss\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Data & plot saved to ./working\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 creating tiny synthetic\ndata.', '\\n', '\\rGenerating train split: 0 examples [00:00, ? examples/s]', '',\n'\\rGenerating train split: 200 examples [00:00, 50870.88 examples/s]', '\\n',\n'\\rGenerating train split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating\ntrain split: 40 examples [00:00, 24683.27 examples/s]', '\\n', '\\rGenerating\ntrain split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating train split:\n40 examples [00:00, 24925.29 examples/s]', '\\n', \"{'train': 200, 'dev': 40,\n'test': 40}\", '\\n', 'Shapes:', ' ', \"{'A': 0, 'B': 1, 'C': 2}\", '\\n',\n'Colours:', ' ', \"{'1': 0, '2': 1, '3': 2}\", '\\n', 'Epoch 1: validation_loss =\n0.6919', '\\n', 'Epoch 2: validation_loss = 0.6906', '\\n', 'Epoch 3:\nvalidation_loss = 0.6906', '\\n', 'Epoch 4: validation_loss = 0.6924', '\\n',\n'Epoch 5: validation_loss = 0.6932', '\\n', 'Epoch 6: validation_loss = 0.6943',\n'\\n', 'Epoch 7: validation_loss = 0.6950', '\\n', 'Epoch 8: validation_loss =\n0.6960', '\\n', 'Epoch 9: validation_loss = 0.6936', '\\n', 'Epoch 10:\nvalidation_loss = 0.6919', '\\n', 'Complexity-Weighted Accuracy (dev): 0.4925',\n'\\n', 'Data & plot saved to ./working', '\\n', 'Execution time: 3 seconds seconds\n(time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found \u2013 creating tiny\nsynthetic data.', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 200 examples [00:00, 43729.39\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 40 examples [00:00, 22835.46\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 40 examples [00:00, 21997.14\nexamples/s]', '\\n', \"{'train': 200, 'dev': 40, 'test': 40}\", '\\n', '[EPOCHS_10]\nEpoch 1/10  val_loss=0.6919', '\\n', '[EPOCHS_10] Epoch 2/10  val_loss=0.6906',\n'\\n', '[EPOCHS_10] Epoch 3/10  val_loss=0.6906', '\\n', '[EPOCHS_10] Epoch 4/10\nval_loss=0.6924', '\\n', '[EPOCHS_10] Epoch 5/10  val_loss=0.6932', '\\n',\n'[EPOCHS_10] Epoch 6/10  val_loss=0.6943', '\\n', '[EPOCHS_10] Epoch 7/10\nval_loss=0.6950', '\\n', 'Early stopping at epoch 7', '\\n', '[EPOCHS_20] Epoch\n1/20  val_loss=0.6943', '\\n', '[EPOCHS_20] Epoch 2/20  val_loss=0.6937', '\\n',\n'[EPOCHS_20] Epoch 3/20  val_loss=0.6941', '\\n', '[EPOCHS_20] Epoch 4/20\nval_loss=0.6937', '\\n', '[EPOCHS_20] Epoch 5/20  val_loss=0.6925', '\\n',\n'[EPOCHS_20] Epoch 6/20  val_loss=0.6907', '\\n', '[EPOCHS_20] Epoch 7/20\nval_loss=0.6890', '\\n', '[EPOCHS_20] Epoch 8/20  val_loss=0.6877', '\\n',\n'[EPOCHS_20] Epoch 9/20  val_loss=0.6866', '\\n', '[EPOCHS_20] Epoch 10/20\nval_loss=0.6859', '\\n', '[EPOCHS_20] Epoch 11/20  val_loss=0.6851', '\\n',\n'[EPOCHS_20] Epoch 12/20  val_loss=0.6843', '\\n', '[EPOCHS_20] Epoch 13/20\nval_loss=0.6826', '\\n', '[EPOCHS_20] Epoch 14/20  val_loss=0.6801', '\\n',\n'[EPOCHS_20] Epoch 15/20  val_loss=0.6774', '\\n', '[EPOCHS_20] Epoch 16/20\nval_loss=0.6752', '\\n', '[EPOCHS_20] Epoch 17/20  val_loss=0.6744', '\\n',\n'[EPOCHS_20] Epoch 18/20  val_loss=0.6721', '\\n', '[EPOCHS_20] Epoch 19/20\nval_loss=0.6707', '\\n', '[EPOCHS_20] Epoch 20/20  val_loss=0.6704', '\\n',\n'[EPOCHS_40] Epoch 1/40  val_loss=0.6910', '\\n', '[EPOCHS_40] Epoch 2/40\nval_loss=0.6922', '\\n', '[EPOCHS_40] Epoch 3/40  val_loss=0.6946', '\\n',\n'[EPOCHS_40] Epoch 4/40  val_loss=0.6948', '\\n', '[EPOCHS_40] Epoch 5/40\nval_loss=0.6948', '\\n', '[EPOCHS_40] Epoch 6/40  val_loss=0.6940', '\\n', 'Early\nstopping at epoch 6', '\\n', '[EPOCHS_60] Epoch 1/60  val_loss=0.6919', '\\n',\n'[EPOCHS_60] Epoch 2/60  val_loss=0.6900', '\\n', '[EPOCHS_60] Epoch 3/60\nval_loss=0.6890', '\\n', '[EPOCHS_60] Epoch 4/60  val_loss=0.6903', '\\n',\n'[EPOCHS_60] Epoch 5/60  val_loss=0.6925', '\\n', '[EPOCHS_60] Epoch 6/60\nval_loss=0.6957', '\\n', '[EPOCHS_60] Epoch 7/60  val_loss=0.6959', '\\n',\n'[EPOCHS_60] Epoch 8/60  val_loss=0.6929', '\\n', 'Early stopping at epoch 8',\n'\\n', 'All data saved to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-6/working', '\\n', 'Execution time: 5 seconds seconds\n(time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 creating tiny synthetic\ndata.', '\\n', '\\rGenerating train split: 0 examples [00:00, ? examples/s]', '',\n'\\rGenerating train split: 200 examples [00:00, 42948.02 examples/s]', '\\n',\n'\\rGenerating train split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating\ntrain split: 40 examples [00:00, 14882.65 examples/s]', '\\n', '\\rGenerating\ntrain split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating train split:\n40 examples [00:00, 16571.73 examples/s]', '\\n', \"{'train': 200, 'dev': 40,\n'test': 40}\", '\\n', 'Shapes:', ' ', \"{'A': 0, 'B': 1, 'C': 2}\", ' ',\n'\\nColours:', ' ', \"{'1': 0, '2': 1, '3': 2}\", '\\n', '\\n=== Training with\nlearning rate 0.0005 ===', '\\n', '  Epoch 1: val_loss=0.6934, val_acc=0.500',\n'\\n', '  Epoch 2: val_loss=0.6919, val_acc=0.500', '\\n', '  Epoch 3:\nval_loss=0.6910, val_acc=0.500', '\\n', '  Epoch 4: val_loss=0.6908,\nval_acc=0.625', '\\n', '  Epoch 5: val_loss=0.6906, val_acc=0.575', '\\n', '\nEpoch 6: val_loss=0.6907, val_acc=0.525', '\\n', '  Epoch 7: val_loss=0.6909,\nval_acc=0.500', '\\n', '  Epoch 8: val_loss=0.6914, val_acc=0.500', '\\n', '\nEpoch 9: val_loss=0.6912, val_acc=0.500', '\\n', '  Epoch 10: val_loss=0.6914,\nval_acc=0.500', '\\n', '  Complexity-Weighted Accuracy: 0.4925', '\\n', '\\n===\nTraining with learning rate 0.001 ===', '\\n', '  Epoch 1: val_loss=0.6925,\nval_acc=0.525', '\\n', '  Epoch 2: val_loss=0.6909, val_acc=0.500', '\\n', '\nEpoch 3: val_loss=0.6897, val_acc=0.500', '\\n', '  Epoch 4: val_loss=0.6891,\nval_acc=0.500', '\\n', '  Epoch 5: val_loss=0.6895, val_acc=0.500', '\\n', '\nEpoch 6: val_loss=0.6891, val_acc=0.500', '\\n', '  Epoch 7: val_loss=0.6893,\nval_acc=0.500', '\\n', '  Epoch 8: val_loss=0.6891, val_acc=0.500', '\\n', '\nEpoch 9: val_loss=0.6887, val_acc=0.500', '\\n', '  Epoch 10: val_loss=0.6885,\nval_acc=0.500', '\\n', '  Complexity-Weighted Accuracy: 0.4925', '\\n', '\\n===\nTraining with learning rate 0.002 ===', '\\n', '  Epoch 1: val_loss=0.6926,\nval_acc=0.500', '\\n', '  Epoch 2: val_loss=0.6932, val_acc=0.500', '\\n', '\nEpoch 3: val_loss=0.6978, val_acc=0.500', '\\n', '  Epoch 4: val_loss=0.6924,\nval_acc=0.500', '\\n', '  Epoch 5: val_loss=0.6901, val_acc=0.500', '\\n', '\nEpoch 6: val_loss=0.6880, val_acc=0.500', '\\n', '  Epoch 7: val_loss=0.6873,\nval_acc=0.500', '\\n', '  Epoch 8: val_loss=0.6847, val_acc=0.500', '\\n', '\nEpoch 9: val_loss=0.6806, val_acc=0.550', '\\n', '  Epoch 10: val_loss=0.6763,\nval_acc=0.600', '\\n', '  Complexity-Weighted Accuracy: 0.5729', '\\n', '\\n===\nTraining with learning rate 0.005 ===', '\\n', '  Epoch 1: val_loss=0.6902,\nval_acc=0.500', '\\n', '  Epoch 2: val_loss=0.7098, val_acc=0.500', '\\n', '\nEpoch 3: val_loss=0.7079, val_acc=0.500', '\\n', '  Epoch 4: val_loss=0.6875,\nval_acc=0.500', '\\n', '  Epoch 5: val_loss=0.6812, val_acc=0.500', '\\n', '\nEpoch 6: val_loss=0.6773, val_acc=0.500', '\\n', '  Epoch 7: val_loss=0.6756,\nval_acc=0.525', '\\n', '  Epoch 8: val_loss=0.6823, val_acc=0.500', '\\n', '\nEpoch 9: val_loss=0.6824, val_acc=0.525', '\\n', '  Epoch 10: val_loss=0.6752,\nval_acc=0.550', '\\n', '  Complexity-Weighted Accuracy: 0.5427', '\\n', '\\nAll\ndata & plots saved to ./working', '\\n', 'Execution time: 4 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 creating tiny synthetic\ndata.', '\\n', '\\rGenerating train split: 0 examples [00:00, ? examples/s]', '',\n'\\rGenerating train split: 200 examples [00:00, 42060.81 examples/s]', '\\n',\n'\\rGenerating train split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating\ntrain split: 40 examples [00:00, 22375.59 examples/s]', '\\n', '\\rGenerating\ntrain split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating train split:\n40 examples [00:00, 24520.92 examples/s]', '\\n', \"{'train': 200, 'dev': 40,\n'test': 40}\", '\\n', 'Shapes:', ' ', \"{'A': 0, 'B': 1, 'C': 2}\", '\\n',\n'Colours:', ' ', \"{'1': 0, '2': 1, '3': 2}\", '\\n', '[batch_16] Epoch 1:\nval_loss=0.6915, val_acc=0.5000', '\\n', '[batch_16] Epoch 2: val_loss=0.6904,\nval_acc=0.5000', '\\n', '[batch_16] Epoch 3: val_loss=0.6897, val_acc=0.5000',\n'\\n', '[batch_16] Epoch 4: val_loss=0.6954, val_acc=0.5000', '\\n', '[batch_16]\nEpoch 5: val_loss=0.6866, val_acc=0.5000', '\\n', '[batch_16] Epoch 6:\nval_loss=0.6808, val_acc=0.5000', '\\n', '[batch_16] Epoch 7: val_loss=0.6770,\nval_acc=0.5250', '\\n', '[batch_16] Epoch 8: val_loss=0.6788, val_acc=0.5000',\n'\\n', '[batch_16] Epoch 9: val_loss=0.6677, val_acc=0.6000', '\\n', '[batch_16]\nEpoch 10: val_loss=0.6664, val_acc=0.6000', '\\n', '[batch_16] Complexity-\nWeighted Accuracy (dev): 0.5829', '\\n', '[batch_32] Epoch 1: val_loss=0.6931,\nval_acc=0.5000', '\\n', '[batch_32] Epoch 2: val_loss=0.6922, val_acc=0.5000',\n'\\n', '[batch_32] Epoch 3: val_loss=0.6910, val_acc=0.5000', '\\n', '[batch_32]\nEpoch 4: val_loss=0.6897, val_acc=0.5000', '\\n', '[batch_32] Epoch 5:\nval_loss=0.6890, val_acc=0.5000', '\\n', '[batch_32] Epoch 6: val_loss=0.6884,\nval_acc=0.5000', '\\n', '[batch_32] Epoch 7: val_loss=0.6879, val_acc=0.5000',\n'\\n', '[batch_32] Epoch 8: val_loss=0.6860, val_acc=0.5000', '\\n', '[batch_32]\nEpoch 9: val_loss=0.6839, val_acc=0.5000', '\\n', '[batch_32] Epoch 10:\nval_loss=0.6807, val_acc=0.5250', '\\n', '[batch_32] Complexity-Weighted Accuracy\n(dev): 0.5126', '\\n', '[batch_64] Epoch 1: val_loss=0.6945, val_acc=0.5250',\n'\\n', '[batch_64] Epoch 2: val_loss=0.6949, val_acc=0.5000', '\\n', '[batch_64]\nEpoch 3: val_loss=0.6974, val_acc=0.5000', '\\n', '[batch_64] Epoch 4:\nval_loss=0.6998, val_acc=0.5000', '\\n', '[batch_64] Epoch 5: val_loss=0.7015,\nval_acc=0.5000', '\\n', '[batch_64] Epoch 6: val_loss=0.7025, val_acc=0.5000',\n'\\n', '[batch_64] Epoch 7: val_loss=0.7005, val_acc=0.5000', '\\n', '[batch_64]\nEpoch 8: val_loss=0.6976, val_acc=0.5000', '\\n', '[batch_64] Epoch 9:\nval_loss=0.6951, val_acc=0.5000', '\\n', '[batch_64] Epoch 10: val_loss=0.6938,\nval_acc=0.5000', '\\n', '[batch_64] Complexity-Weighted Accuracy (dev): 0.4925',\n'\\n', '[batch_128] Epoch 1: val_loss=0.6903, val_acc=0.5000', '\\n', '[batch_128]\nEpoch 2: val_loss=0.6902, val_acc=0.5000', '\\n', '[batch_128] Epoch 3:\nval_loss=0.6900, val_acc=0.5000', '\\n', '[batch_128] Epoch 4: val_loss=0.6902,\nval_acc=0.5000', '\\n', '[batch_128] Epoch 5: val_loss=0.6900, val_acc=0.5000',\n'\\n', '[batch_128] Epoch 6: val_loss=0.6895, val_acc=0.5000', '\\n', '[batch_128]\nEpoch 7: val_loss=0.6893, val_acc=0.5000', '\\n', '[batch_128] Epoch 8:\nval_loss=0.6885, val_acc=0.5000', '\\n', '[batch_128] Epoch 9: val_loss=0.6877,\nval_acc=0.5000', '\\n', '[batch_128] Epoch 10: val_loss=0.6865, val_acc=0.5000',\n'\\n', '[batch_128] Complexity-Weighted Accuracy (dev): 0.4925', '\\n', 'All data\nsaved to ./working', '\\n', 'Execution time: 4 seconds seconds (time limit is 30\nminutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found \u2013 creating tiny\nsynthetic data.', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 200 examples [00:00, 33725.76\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 40 examples [00:00, 17248.09\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 40 examples [00:00, 18353.81\nexamples/s]', '\\n', \"{'train': 200, 'dev': 40, 'test': 40}\", '\\n', '\\n===\nTraining with weight_decay=0.0 ===', '\\n', 'Epoch 1: train_loss=0.7064\nval_loss=0.6902', '\\n', 'Epoch 2: train_loss=0.6952 val_loss=0.6876', '\\n',\n'Epoch 3: train_loss=0.6872 val_loss=0.6868', '\\n', 'Epoch 4: train_loss=0.6830\nval_loss=0.6876', '\\n', 'Epoch 5: train_loss=0.6790 val_loss=0.6875', '\\n',\n'Epoch 6: train_loss=0.6786 val_loss=0.6888', '\\n', 'Epoch 7: train_loss=0.6758\nval_loss=0.6894', '\\n', 'Epoch 8: train_loss=0.6751 val_loss=0.6879', '\\n',\n'Epoch 9: train_loss=0.6741 val_loss=0.6874', '\\n', 'Epoch 10: train_loss=0.6742\nval_loss=0.6886', '\\n', 'Weight decay 0.0: Complexity-Weighted Accuracy (dev) =\n0.4925', '\\n', '\\n=== Training with weight_decay=1e-05 ===', '\\n', 'Epoch 1:\ntrain_loss=0.6871 val_loss=0.6993', '\\n', 'Epoch 2: train_loss=0.6842\nval_loss=0.6994', '\\n', 'Epoch 3: train_loss=0.6831 val_loss=0.7004', '\\n',\n'Epoch 4: train_loss=0.6818 val_loss=0.7003', '\\n', 'Epoch 5: train_loss=0.6806\nval_loss=0.6993', '\\n', 'Epoch 6: train_loss=0.6795 val_loss=0.7001', '\\n',\n'Epoch 7: train_loss=0.6787 val_loss=0.7020', '\\n', 'Epoch 8: train_loss=0.6789\nval_loss=0.7031', '\\n', 'Epoch 9: train_loss=0.6787 val_loss=0.7028', '\\n',\n'Epoch 10: train_loss=0.6779 val_loss=0.7001', '\\n', 'Weight decay 1e-05:\nComplexity-Weighted Accuracy (dev) = 0.4925', '\\n', '\\n=== Training with\nweight_decay=0.0001 ===', '\\n', 'Epoch 1: train_loss=0.6935 val_loss=0.6901',\n'\\n', 'Epoch 2: train_loss=0.6886 val_loss=0.6908', '\\n', 'Epoch 3:\ntrain_loss=0.6836 val_loss=0.6909', '\\n', 'Epoch 4: train_loss=0.6822\nval_loss=0.6910', '\\n', 'Epoch 5: train_loss=0.6808 val_loss=0.6916', '\\n',\n'Epoch 6: train_loss=0.6790 val_loss=0.6924', '\\n', 'Epoch 7: train_loss=0.6787\nval_loss=0.6935', '\\n', 'Epoch 8: train_loss=0.6779 val_loss=0.6926', '\\n',\n'Epoch 9: train_loss=0.6768 val_loss=0.6900', '\\n', 'Epoch 10: train_loss=0.6758\nval_loss=0.6865', '\\n', 'Weight decay 0.0001: Complexity-Weighted Accuracy (dev)\n= 0.4925', '\\n', '\\n=== Training with weight_decay=0.001 ===', '\\n', 'Epoch 1:\ntrain_loss=0.6869 val_loss=0.6920', '\\n', 'Epoch 2: train_loss=0.6832\nval_loss=0.6921', '\\n', 'Epoch 3: train_loss=0.6810 val_loss=0.6907', '\\n',\n'Epoch 4: train_loss=0.6804 val_loss=0.6893', '\\n', 'Epoch 5: train_loss=0.6792\nval_loss=0.6889', '\\n', 'Epoch 6: train_loss=0.6782 val_loss=0.6876', '\\n',\n'Epoch 7: train_loss=0.6773 val_loss=0.6869', '\\n', 'Epoch 8: train_loss=0.6759\nval_loss=0.6877', '\\n', 'Epoch 9: train_loss=0.6757 val_loss=0.6886', '\\n',\n'Epoch 10: train_loss=0.6750 val_loss=0.6868', '\\n', 'Weight decay 0.001:\nComplexity-Weighted Accuracy (dev) = 0.4925', '\\n', '\\n=== Training with\nweight_decay=0.01 ===', '\\n', 'Epoch 1: train_loss=0.6935 val_loss=0.6899',\n'\\n', 'Epoch 2: train_loss=0.6895 val_loss=0.6892', '\\n', 'Epoch 3:\ntrain_loss=0.6874 val_loss=0.6888', '\\n', 'Epoch 4: train_loss=0.6858\nval_loss=0.6888', '\\n', 'Epoch 5: train_loss=0.6837 val_loss=0.6883', '\\n',\n'Epoch 6: train_loss=0.6826 val_loss=0.6877', '\\n', 'Epoch 7: train_loss=0.6812\nval_loss=0.6879', '\\n', 'Epoch 8: train_loss=0.6801 val_loss=0.6881', '\\n',\n'Epoch 9: train_loss=0.6798 val_loss=0.6887', '\\n', 'Epoch 10: train_loss=0.6787\nval_loss=0.6891', '\\n', 'Weight decay 0.01: Complexity-Weighted Accuracy (dev) =\n0.4925', '\\n', 'Saved results to working/experiment_data.npy and\nloss_curve.png', '\\n', 'Execution time: 4 seconds seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', \"{'train': 200, 'dev': 40, 'test': 40}\", '\\n',\n'Shapes', ' ', \"{'A': 0, 'B': 1, 'C': 2}\", ' ', 'Colours', ' ', \"{'1': 0, '2':\n1, '3': 2}\", ' ', 'Labels', ' ', \"{'no': 0, 'yes': 1}\", '\\n', '\\n=== Hidden dim:\n32 ===', '\\n', 'Epoch 1: val_loss 0.6909  val_acc 0.5250', '\\n', 'Epoch 2:\nval_loss 0.6896  val_acc 0.6250', '\\n', 'Epoch 3: val_loss 0.6887  val_acc\n0.6000', '\\n', 'Epoch 4: val_loss 0.6880  val_acc 0.4750', '\\n', 'Epoch 5:\nval_loss 0.6874  val_acc 0.5000', '\\n', 'Epoch 6: val_loss 0.6868  val_acc\n0.5000', '\\n', 'Epoch 7: val_loss 0.6863  val_acc 0.5000', '\\n', 'Epoch 8:\nval_loss 0.6862  val_acc 0.5000', '\\n', 'Epoch 9: val_loss 0.6865  val_acc\n0.5000', '\\n', 'Epoch 10: val_loss 0.6869  val_acc 0.5000', '\\n', 'Hidden 32:\nComp-Weighted Acc = 0.4925', '\\n', '\\n=== Hidden dim: 64 ===', '\\n', 'Epoch 1:\nval_loss 0.6946  val_acc 0.5000', '\\n', 'Epoch 2: val_loss 0.6917  val_acc\n0.5000', '\\n', 'Epoch 3: val_loss 0.6906  val_acc 0.5250', '\\n', 'Epoch 4:\nval_loss 0.6912  val_acc 0.5000', '\\n', 'Epoch 5: val_loss 0.6927  val_acc\n0.5000', '\\n', 'Epoch 6: val_loss 0.6933  val_acc 0.5000', '\\n', 'Epoch 7:\nval_loss 0.6924  val_acc 0.5000', '\\n', 'Epoch 8: val_loss 0.6911  val_acc\n0.5000', '\\n', 'Epoch 9: val_loss 0.6907  val_acc 0.5000', '\\n', 'Epoch 10:\nval_loss 0.6898  val_acc 0.5000', '\\n', 'Hidden 64: Comp-Weighted Acc = 0.4925',\n'\\n', '\\n=== Hidden dim: 128 ===', '\\n', 'Epoch 1: val_loss 0.6927  val_acc\n0.5000', '\\n', 'Epoch 2: val_loss 0.6942  val_acc 0.5000', '\\n', 'Epoch 3:\nval_loss 0.6947  val_acc 0.5000', '\\n', 'Epoch 4: val_loss 0.6977  val_acc\n0.5000', '\\n', 'Epoch 5: val_loss 0.6986  val_acc 0.5000', '\\n', 'Epoch 6:\nval_loss 0.6952  val_acc 0.5000', '\\n', 'Epoch 7: val_loss 0.6902  val_acc\n0.5000', '\\n', 'Epoch 8: val_loss 0.6867  val_acc 0.5000', '\\n', 'Epoch 9:\nval_loss 0.6859  val_acc 0.5000', '\\n', 'Epoch 10: val_loss 0.6845  val_acc\n0.5000', '\\n', 'Hidden 128: Comp-Weighted Acc = 0.4925', '\\n', '\\n=== Hidden\ndim: 256 ===', '\\n', 'Epoch 1: val_loss 0.6986  val_acc 0.5000', '\\n', 'Epoch 2:\nval_loss 0.7012  val_acc 0.5000', '\\n', 'Epoch 3: val_loss 0.6906  val_acc\n0.5000', '\\n', 'Epoch 4: val_loss 0.6831  val_acc 0.5250', '\\n', 'Epoch 5:\nval_loss 0.6791  val_acc 0.6250', '\\n', 'Epoch 6: val_loss 0.6768  val_acc\n0.6750', '\\n', 'Epoch 7: val_loss 0.6741  val_acc 0.6250', '\\n', 'Epoch 8:\nval_loss 0.6723  val_acc 0.6500', '\\n', 'Epoch 9: val_loss 0.6726  val_acc\n0.5750', '\\n', 'Epoch 10: val_loss 0.6709  val_acc 0.5750', '\\n', 'Hidden 256:\nComp-Weighted Acc = 0.5528', '\\n', 'All results saved in\n./working/experiment_data.npy', '\\n', 'Execution time: 9 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', \"{'train': 200, 'dev': 40, 'test': 40}\",\n'\\n', 'Shapes:', ' ', \"{'A': 0, 'B': 1, 'C': 2}\", ' ', '\\nColours:', ' ', \"{'1':\n0, '2': 1, '3': 2}\", ' ', '\\nLabels:', ' ', \"{'no': 0, 'yes': 1}\", '\\n',\n'[dropout_0.0] Epoch 01  val_loss=0.6919', '\\n', '[dropout_0.0] Epoch 02\nval_loss=0.6906', '\\n', '[dropout_0.0] Epoch 03  val_loss=0.6906', '\\n',\n'[dropout_0.0] Epoch 04  val_loss=0.6924', '\\n', '[dropout_0.0] Epoch 05\nval_loss=0.6932', '\\n', '[dropout_0.0] Epoch 06  val_loss=0.6943', '\\n',\n'[dropout_0.0] Epoch 07  val_loss=0.6950', '\\n', '[dropout_0.0] Epoch 08\nval_loss=0.6960', '\\n', '[dropout_0.0] Epoch 09  val_loss=0.6936', '\\n',\n'[dropout_0.0] Epoch 10  val_loss=0.6919', '\\n', '[dropout_0.0] Complexity-\nWeighted Accuracy: 0.4925', '\\n', '[dropout_0.1] Epoch 01  val_loss=0.6936',\n'\\n', '[dropout_0.1] Epoch 02  val_loss=0.6925', '\\n', '[dropout_0.1] Epoch 03\nval_loss=0.6913', '\\n', '[dropout_0.1] Epoch 04  val_loss=0.6901', '\\n',\n'[dropout_0.1] Epoch 05  val_loss=0.6894', '\\n', '[dropout_0.1] Epoch 06\nval_loss=0.6889', '\\n', '[dropout_0.1] Epoch 07  val_loss=0.6888', '\\n',\n'[dropout_0.1] Epoch 08  val_loss=0.6886', '\\n', '[dropout_0.1] Epoch 09\nval_loss=0.6886', '\\n', '[dropout_0.1] Epoch 10  val_loss=0.6880', '\\n',\n'[dropout_0.1] Complexity-Weighted Accuracy: 0.4925', '\\n', '[dropout_0.3] Epoch\n01  val_loss=0.6949', '\\n', '[dropout_0.3] Epoch 02  val_loss=0.6954', '\\n',\n'[dropout_0.3] Epoch 03  val_loss=0.6973', '\\n', '[dropout_0.3] Epoch 04\nval_loss=0.6988', '\\n', '[dropout_0.3] Epoch 05  val_loss=0.6999', '\\n',\n'[dropout_0.3] Epoch 06  val_loss=0.7006', '\\n', '[dropout_0.3] Epoch 07\nval_loss=0.6998', '\\n', '[dropout_0.3] Epoch 08  val_loss=0.6983', '\\n',\n'[dropout_0.3] Epoch 09  val_loss=0.6971', '\\n', '[dropout_0.3] Epoch 10\nval_loss=0.6969', '\\n', '[dropout_0.3] Complexity-Weighted Accuracy: 0.4925',\n'\\n', '[dropout_0.5] Epoch 01  val_loss=0.6900', '\\n', '[dropout_0.5] Epoch 02\nval_loss=0.6900', '\\n', '[dropout_0.5] Epoch 03  val_loss=0.6895', '\\n',\n'[dropout_0.5] Epoch 04  val_loss=0.6895', '\\n', '[dropout_0.5] Epoch 05\nval_loss=0.6896', '\\n', '[dropout_0.5] Epoch 06  val_loss=0.6896', '\\n',\n'[dropout_0.5] Epoch 07  val_loss=0.6900', '\\n', '[dropout_0.5] Epoch 08\nval_loss=0.6900', '\\n', '[dropout_0.5] Epoch 09  val_loss=0.6902', '\\n',\n'[dropout_0.5] Epoch 10  val_loss=0.6903', '\\n', '[dropout_0.5] Complexity-\nWeighted Accuracy: 0.4925', '\\n', 'All data saved to\n./working/experiment_data.npy', '\\n', 'Execution time: 4 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 200, 'dev': 40, 'test': 40}\", '\\n',\n'Shapes:', ' ', \"{'A': 0, 'B': 1, 'C': 2}\", ' ', '\\nColours:', ' ', \"{'1': 0,\n'2': 1, '3': 2}\", '\\n', '\\n=== Training model with 2 GCN layers ===', '\\n',\n'Depth 2 | Epoch 1 | val_loss 0.6919 | val_acc 0.500', '\\n', 'Depth 2 | Epoch 2\n| val_loss 0.6906 | val_acc 0.650', '\\n', 'Depth 2 | Epoch 3 | val_loss 0.6906 |\nval_acc 0.500', '\\n', 'Depth 2 | Epoch 4 | val_loss 0.6924 | val_acc 0.500',\n'\\n', 'Depth 2 | Epoch 5 | val_loss 0.6932 | val_acc 0.500', '\\n', 'Depth 2 |\nEpoch 6 | val_loss 0.6943 | val_acc 0.500', '\\n', 'Depth 2 | Epoch 7 | val_loss\n0.6950 | val_acc 0.500', '\\n', 'Depth 2 | Epoch 8 | val_loss 0.6960 | val_acc\n0.500', '\\n', 'Depth 2 | Epoch 9 | val_loss 0.6936 | val_acc 0.500', '\\n',\n'Depth 2 | Epoch 10 | val_loss 0.6919 | val_acc 0.500', '\\n', 'Depth 2 |\nComplexity Weighted Accuracy (dev): 0.4925', '\\n', '\\n=== Training model with 3\nGCN layers ===', '\\n', 'Depth 3 | Epoch 1 | val_loss 0.6945 | val_acc 0.500',\n'\\n', 'Depth 3 | Epoch 2 | val_loss 0.6922 | val_acc 0.500', '\\n', 'Depth 3 |\nEpoch 3 | val_loss 0.6916 | val_acc 0.500', '\\n', 'Depth 3 | Epoch 4 | val_loss\n0.6910 | val_acc 0.500', '\\n', 'Depth 3 | Epoch 5 | val_loss 0.6895 | val_acc\n0.500', '\\n', 'Depth 3 | Epoch 6 | val_loss 0.6869 | val_acc 0.500', '\\n',\n'Depth 3 | Epoch 7 | val_loss 0.6868 | val_acc 0.500', '\\n', 'Depth 3 | Epoch 8\n| val_loss 0.6862 | val_acc 0.500', '\\n', 'Depth 3 | Epoch 9 | val_loss 0.6847 |\nval_acc 0.500', '\\n', 'Depth 3 | Epoch 10 | val_loss 0.6843 | val_acc 0.500',\n'\\n', 'Depth 3 | Complexity Weighted Accuracy (dev): 0.4925', '\\n', '\\n===\nTraining model with 4 GCN layers ===', '\\n', 'Depth 4 | Epoch 1 | val_loss\n0.6948 | val_acc 0.500', '\\n', 'Depth 4 | Epoch 2 | val_loss 0.6948 | val_acc\n0.500', '\\n', 'Depth 4 | Epoch 3 | val_loss 0.6938 | val_acc 0.500', '\\n',\n'Depth 4 | Epoch 4 | val_loss 0.6933 | val_acc 0.500', '\\n', 'Depth 4 | Epoch 5\n| val_loss 0.6940 | val_acc 0.500', '\\n', 'Depth 4 | Epoch 6 | val_loss 0.6973 |\nval_acc 0.500', '\\n', 'Depth 4 | Epoch 7 | val_loss 0.7009 | val_acc 0.500',\n'\\n', 'Depth 4 | Epoch 8 | val_loss 0.6994 | val_acc 0.500', '\\n', 'Depth 4 |\nEpoch 9 | val_loss 0.6945 | val_acc 0.500', '\\n', 'Depth 4 | Epoch 10 | val_loss\n0.6897 | val_acc 0.500', '\\n', 'Depth 4 | Complexity Weighted Accuracy (dev):\n0.4925', '\\n', '\\nAll experiments finished. Data saved to\n./working/experiment_data.npy', '\\n', 'Execution time: 4 seconds seconds (time\nlimit is 30 minutes).']", "['device:', ' ', 'cuda', '\\n', \"{'train': 200, 'dev': 40, 'test': 40}\", '\\n',\n'[p=0.0] epoch 1: val_loss=0.6919', '\\n', '[p=0.0] epoch 2: val_loss=0.6906',\n'\\n', '[p=0.0] epoch 3: val_loss=0.6906', '\\n', '[p=0.0] epoch 4:\nval_loss=0.6924', '\\n', '[p=0.0] epoch 5: val_loss=0.6932', '\\n', '[p=0.0] epoch\n6: val_loss=0.6943', '\\n', '[p=0.0] epoch 7: val_loss=0.6950', '\\n', '[p=0.0]\nepoch 8: val_loss=0.6960', '\\n', '[p=0.0] epoch 9: val_loss=0.6936', '\\n',\n'[p=0.0] epoch 10: val_loss=0.6919', '\\n', '[p=0.0] Complexity-Weighted Acc\n(dev): 0.4925', '\\n', '[p=0.1] epoch 1: val_loss=0.6929', '\\n', '[p=0.1] epoch\n2: val_loss=0.6918', '\\n', '[p=0.1] epoch 3: val_loss=0.6910', '\\n', '[p=0.1]\nepoch 4: val_loss=0.6908', '\\n', '[p=0.1] epoch 5: val_loss=0.6913', '\\n',\n'[p=0.1] epoch 6: val_loss=0.6905', '\\n', '[p=0.1] epoch 7: val_loss=0.6903',\n'\\n', '[p=0.1] epoch 8: val_loss=0.6894', '\\n', '[p=0.1] epoch 9:\nval_loss=0.6885', '\\n', '[p=0.1] epoch 10: val_loss=0.6880', '\\n', '[p=0.1]\nComplexity-Weighted Acc (dev): 0.4925', '\\n', '[p=0.2] epoch 1:\nval_loss=0.6942', '\\n', '[p=0.2] epoch 2: val_loss=0.6936', '\\n', '[p=0.2] epoch\n3: val_loss=0.6953', '\\n', '[p=0.2] epoch 4: val_loss=0.6944', '\\n', '[p=0.2]\nepoch 5: val_loss=0.6948', '\\n', '[p=0.2] epoch 6: val_loss=0.6953', '\\n',\n'[p=0.2] epoch 7: val_loss=0.6961', '\\n', '[p=0.2] epoch 8: val_loss=0.6961',\n'\\n', '[p=0.2] epoch 9: val_loss=0.6953', '\\n', '[p=0.2] epoch 10:\nval_loss=0.6939', '\\n', '[p=0.2] Complexity-Weighted Acc (dev): 0.4925', '\\n',\n'[p=0.3] epoch 1: val_loss=0.6924', '\\n', '[p=0.3] epoch 2: val_loss=0.6935',\n'\\n', '[p=0.3] epoch 3: val_loss=0.6949', '\\n', '[p=0.3] epoch 4:\nval_loss=0.6943', '\\n', '[p=0.3] epoch 5: val_loss=0.6942', '\\n', '[p=0.3] epoch\n6: val_loss=0.6939', '\\n', '[p=0.3] epoch 7: val_loss=0.6937', '\\n', '[p=0.3]\nepoch 8: val_loss=0.6945', '\\n', '[p=0.3] epoch 9: val_loss=0.6949', '\\n',\n'[p=0.3] epoch 10: val_loss=0.6950', '\\n', '[p=0.3] Complexity-Weighted Acc\n(dev): 0.4925', '\\n', 'All results saved to ./working', '\\n', 'Execution time: 9\nseconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 200, 'dev': 40, 'test': 40}\", '\\n',\n'Shapes:', ' ', \"{'A': 0, 'B': 1, 'C': 2}\", '\\n', 'Colours:', ' ', \"{'1': 0,\n'2': 1, '3': 2}\", '\\n', 'Epoch 1: validation_loss = 0.6902', '\\n', 'Epoch 2:\nvalidation_loss = 0.6876', '\\n', 'Epoch 3: validation_loss = 0.6868', '\\n',\n'Epoch 4: validation_loss = 0.6876', '\\n', 'Epoch 5: validation_loss = 0.6875',\n'\\n', 'Epoch 6: validation_loss = 0.6888', '\\n', 'Epoch 7: validation_loss =\n0.6894', '\\n', 'Epoch 8: validation_loss = 0.6879', '\\n', 'Epoch 9:\nvalidation_loss = 0.6874', '\\n', 'Epoch 10: validation_loss = 0.6886', '\\n',\n'Complexity-Weighted Accuracy (dev): 0.4925', '\\n', 'Data & plot saved to\n./working', '\\n', 'Execution time: 4 seconds seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', \"{'train': 200, 'dev': 40, 'test': 40}\", '\\n',\n'Shapes:', ' ', \"{'A': 0, 'B': 1, 'C': 2}\", '\\n', 'Colours:', ' ', \"{'1': 0,\n'2': 1, '3': 2}\", '\\n', 'Epoch 1: validation_loss = 0.6983', '\\n', 'Epoch 2:\nvalidation_loss = 0.6973', '\\n', 'Epoch 3: validation_loss = 0.6953', '\\n',\n'Epoch 4: validation_loss = 0.6935', '\\n', 'Epoch 5: validation_loss = 0.6910',\n'\\n', 'Epoch 6: validation_loss = 0.6900', '\\n', 'Epoch 7: validation_loss =\n0.6900', '\\n', 'Epoch 8: validation_loss = 0.6900', '\\n', 'Epoch 9:\nvalidation_loss = 0.6878', '\\n', 'Epoch 10: validation_loss = 0.6859', '\\n',\n'Complexity-Weighted Accuracy (dev): 0.4925', '\\n', 'Data & plot saved to\n./working', '\\n', 'Execution time: 4 seconds seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', \"{'train': 200, 'dev': 40, 'test': 40}\", '\\n',\n'Shapes:', ' ', \"{'A': 0, 'B': 1, 'C': 2}\", '\\n', 'Colours:', ' ', \"{'1': 0,\n'2': 1, '3': 2}\", '\\n', 'Epoch 1: validation_loss = 0.6902', '\\n', 'Epoch 2:\nvalidation_loss = 0.6863', '\\n', 'Epoch 3: validation_loss = 0.6838', '\\n',\n'Epoch 4: validation_loss = 0.6825', '\\n', 'Epoch 5: validation_loss = 0.6827',\n'\\n', 'Epoch 6: validation_loss = 0.6833', '\\n', 'Epoch 7: validation_loss =\n0.6838', '\\n', 'Epoch 8: validation_loss = 0.6822', '\\n', 'Epoch 9:\nvalidation_loss = 0.6808', '\\n', 'Epoch 10: validation_loss = 0.6804', '\\n',\n'Complexity-Weighted Accuracy (dev): 0.4925', '\\n', 'Data & plot saved to\n./working', '\\n', 'Execution time: 4 seconds seconds (time limit is 30\nminutes).']", ""], "analysis": ["", "", "", "", "The training script executed successfully without any errors or bugs. However,\nthe performance across all weight decay hyperparameter settings remains\nstagnant, with a Complexity-Weighted Accuracy (CompWA) of 0.4925 on the\ndevelopment set. This indicates that the model may not be learning effectively,\npossibly due to the small size of the synthetic dataset (only 200 training\nexamples). To improve results, consider increasing the dataset size or further\ntuning other hyperparameters such as learning rate or model architecture.\nAdditionally, the validation loss curves show minimal improvement, which further\nsuggests the need for more diverse or larger data.", "The execution of the training script completed successfully without any errors\nor bugs. The model was trained with different hidden dimensions (32, 64, 128,\n256), and the results were logged for each configuration. The validation\naccuracy and loss were monitored, and the complexity-weighted accuracy (CompWA)\nwas calculated. The results were saved in a file for further analysis. The\nperformance improved slightly with a hidden dimension of 256, achieving a CompWA\nof 0.5528, indicating progress in tuning hyperparameters. No issues were\ndetected in the code or execution.", "The script executed successfully without any runtime errors or crashes. The\nloading of the SPR_BENCH dataset, model training, validation, and evaluation\nwere completed as expected. However, the performance of the model, as indicated\nby the Complexity-Weighted Accuracy (CompWA), remained constant at 0.4925 across\ndifferent dropout rates. This suggests that the model is not learning\neffectively or that the dataset is too simplistic for meaningful evaluation. A\npotential improvement could involve increasing the complexity of the dataset or\nexperimenting with additional hyperparameters and model architectures.", "The execution of the training script completed successfully without any errors\nor bugs. The results indicate that the model is not learning effectively as the\nvalidation accuracy remains constant at 0.500 across all depths, and the\nComplexity Weighted Accuracy (CWA) on the development set is also consistently\nlow at 0.4925. This suggests that the model might be unable to capture\nmeaningful patterns from the data, possibly due to insufficient model\ncomplexity, lack of relevant features, or an issue with the dataset itself.\nFurther investigation and experimentation with hyperparameters, feature\nengineering, or dataset quality might be needed to improve results.", "", "The model's validation loss does not decrease consistently over epochs,\nindicating potential issues with learning. Additionally, the Complexity-Weighted\nAccuracy (CompWA) on the dev set is very low at 0.4925, showing that the model's\nperformance is suboptimal. To address this, consider tuning the learning rate,\nincreasing the number of epochs to allow more training time, or experimenting\nwith different optimizers. Additionally, the batch size and hidden layer\ndimensions could be adjusted to improve learning dynamics.", "", "The training script successfully executed without runtime errors, but there are\nissues with the performance of the model. The validation loss decreases slightly\nbut remains high throughout the training process, indicating potential\nunderfitting. Additionally, the Complexity-Weighted Accuracy (CompWA) on the dev\nset is only 0.4925, which is relatively low and suggests that the model is not\nlearning effectively.   Proposed Fix: 1. Investigate and adjust hyperparameters\nsuch as the learning rate, batch size, and number of epochs to improve model\nperformance. 2. Consider using a more complex model architecture or adding\nregularization techniques like dropout to avoid underfitting. 3. Ensure the\nsynthetic dataset is sufficiently representative of the problem domain; if not,\nenhance the data generation process. 4. Experiment with different graph neural\nnetwork architectures and optimization techniques to improve learning.", ""], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.58, "best_value": 0.58}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.65, "best_value": 0.65}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "Loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.678, "best_value": 0.678}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6906, "best_value": 0.6906}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "EPOCHS_10", "final_value": 0.565, "best_value": 0.565}, {"dataset_name": "EPOCHS_20", "final_value": 0.605, "best_value": 0.605}, {"dataset_name": "EPOCHS_40", "final_value": 0.565, "best_value": 0.565}, {"dataset_name": "EPOCHS_60", "final_value": 0.565, "best_value": 0.565}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "EPOCHS_10", "final_value": 0.6804, "best_value": 0.6804}, {"dataset_name": "EPOCHS_20", "final_value": 0.6648, "best_value": 0.6648}, {"dataset_name": "EPOCHS_40", "final_value": 0.6817, "best_value": 0.6817}, {"dataset_name": "EPOCHS_60", "final_value": 0.6789, "best_value": 0.6789}]}, {"metric_name": "validation best accuracy", "lower_is_better": false, "description": "The best accuracy achieved on the validation dataset.", "data": [{"dataset_name": "EPOCHS_10", "final_value": 0.65, "best_value": 0.65}, {"dataset_name": "EPOCHS_20", "final_value": 0.6, "best_value": 0.6}, {"dataset_name": "EPOCHS_40", "final_value": 0.625, "best_value": 0.625}, {"dataset_name": "EPOCHS_60", "final_value": 0.55, "best_value": 0.55}]}, {"metric_name": "validation best loss", "lower_is_better": true, "description": "The best loss achieved on the validation dataset.", "data": [{"dataset_name": "EPOCHS_10", "final_value": 0.6906, "best_value": 0.6906}, {"dataset_name": "EPOCHS_20", "final_value": 0.6704, "best_value": 0.6704}, {"dataset_name": "EPOCHS_40", "final_value": 0.691, "best_value": 0.691}, {"dataset_name": "EPOCHS_60", "final_value": 0.689, "best_value": 0.689}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error in predictions during training.", "data": [{"dataset_name": "Training dataset", "final_value": 0.667, "best_value": 0.667}]}, {"metric_name": "training accuracy", "lower_is_better": false, "description": "Measures the proportion of correct predictions during training.", "data": [{"dataset_name": "Training dataset", "final_value": 0.565, "best_value": 0.575}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error in predictions during validation.", "data": [{"dataset_name": "Validation dataset", "final_value": 0.6752, "best_value": 0.6752}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Measures the proportion of correct predictions during validation.", "data": [{"dataset_name": "Validation dataset", "final_value": 0.55, "best_value": 0.6}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "A weighted accuracy metric based on the complexity of the validation samples.", "data": [{"dataset_name": "Validation dataset", "final_value": 0.5427, "best_value": 0.5729}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "batch_128", "final_value": 0.565, "best_value": 0.565}, {"dataset_name": "batch_16", "final_value": 0.595, "best_value": 0.595}, {"dataset_name": "batch_32", "final_value": 0.565, "best_value": 0.565}, {"dataset_name": "batch_64", "final_value": 0.565, "best_value": 0.565}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "batch_128", "final_value": 0.5, "best_value": 0.5}, {"dataset_name": "batch_16", "final_value": 0.6, "best_value": 0.6}, {"dataset_name": "batch_32", "final_value": 0.525, "best_value": 0.525}, {"dataset_name": "batch_64", "final_value": 0.5, "best_value": 0.5}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "batch_128", "final_value": 0.6769, "best_value": 0.6769}, {"dataset_name": "batch_16", "final_value": 0.6655, "best_value": 0.6655}, {"dataset_name": "batch_32", "final_value": 0.6713, "best_value": 0.6713}, {"dataset_name": "batch_64", "final_value": 0.6784, "best_value": 0.6784}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "batch_128", "final_value": 0.6865, "best_value": 0.6865}, {"dataset_name": "batch_16", "final_value": 0.6664, "best_value": 0.6664}, {"dataset_name": "batch_32", "final_value": 0.6807, "best_value": 0.6807}, {"dataset_name": "batch_64", "final_value": 0.6938, "best_value": 0.6938}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.565, "best_value": 0.565}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5, "best_value": 0.5}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6787, "best_value": 0.6742}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6891, "best_value": 0.6865}]}, {"metric_name": "complexity-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model weighted by complexity on the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4925, "best_value": 0.4925}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.565, "best_value": 0.565}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.575, "best_value": 0.675}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.667, "best_value": 0.667}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6709, "best_value": 0.6709}]}, {"metric_name": "complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy adjusted for model complexity.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5528, "best_value": 0.5528}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH (dropout_0.0)", "final_value": 0.565, "best_value": 0.565}, {"dataset_name": "SPR_BENCH (dropout_0.1)", "final_value": 0.565, "best_value": 0.565}, {"dataset_name": "SPR_BENCH (dropout_0.3)", "final_value": 0.56, "best_value": 0.56}, {"dataset_name": "SPR_BENCH (dropout_0.5)", "final_value": 0.565, "best_value": 0.565}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH (dropout_0.0)", "final_value": 0.5, "best_value": 0.5}, {"dataset_name": "SPR_BENCH (dropout_0.1)", "final_value": 0.5, "best_value": 0.5}, {"dataset_name": "SPR_BENCH (dropout_0.3)", "final_value": 0.5, "best_value": 0.5}, {"dataset_name": "SPR_BENCH (dropout_0.5)", "final_value": 0.5, "best_value": 0.5}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "Loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH (dropout_0.0)", "final_value": 0.678, "best_value": 0.678}, {"dataset_name": "SPR_BENCH (dropout_0.1)", "final_value": 0.6774, "best_value": 0.6774}, {"dataset_name": "SPR_BENCH (dropout_0.3)", "final_value": 0.6804, "best_value": 0.6804}, {"dataset_name": "SPR_BENCH (dropout_0.5)", "final_value": 0.6849, "best_value": 0.6849}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH (dropout_0.0)", "final_value": 0.6919, "best_value": 0.6919}, {"dataset_name": "SPR_BENCH (dropout_0.1)", "final_value": 0.688, "best_value": 0.688}, {"dataset_name": "SPR_BENCH (dropout_0.3)", "final_value": 0.6969, "best_value": 0.6969}, {"dataset_name": "SPR_BENCH (dropout_0.5)", "final_value": 0.6903, "best_value": 0.6903}]}, {"metric_name": "complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy of the model weighted by complexity.", "data": [{"dataset_name": "SPR_BENCH (dropout_0.0)", "final_value": 0.4925, "best_value": 0.4925}, {"dataset_name": "SPR_BENCH (dropout_0.1)", "final_value": 0.4925, "best_value": 0.4925}, {"dataset_name": "SPR_BENCH (dropout_0.3)", "final_value": 0.4925, "best_value": 0.4925}, {"dataset_name": "SPR_BENCH (dropout_0.5)", "final_value": 0.4925, "best_value": 0.4925}]}]}, {"metric_names": [{"metric_name": "Training accuracy", "lower_is_better": false, "description": "The proportion of correctly classified instances during training.", "data": [{"dataset_name": "SPR_BENCH (GCN layers: 2)", "final_value": 0.58, "best_value": 0.58}, {"dataset_name": "SPR_BENCH (GCN layers: 3)", "final_value": 0.565, "best_value": 0.565}, {"dataset_name": "SPR_BENCH (GCN layers: 4)", "final_value": 0.565, "best_value": 0.565}]}, {"metric_name": "Validation accuracy", "lower_is_better": false, "description": "The proportion of correctly classified instances during validation.", "data": [{"dataset_name": "SPR_BENCH (GCN layers: 2)", "final_value": 0.65, "best_value": 0.65}, {"dataset_name": "SPR_BENCH (GCN layers: 3)", "final_value": 0.5, "best_value": 0.5}, {"dataset_name": "SPR_BENCH (GCN layers: 4)", "final_value": 0.5, "best_value": 0.5}]}, {"metric_name": "Training loss", "lower_is_better": true, "description": "The error or loss during training.", "data": [{"dataset_name": "SPR_BENCH (GCN layers: 2)", "final_value": 0.678, "best_value": 0.678}, {"dataset_name": "SPR_BENCH (GCN layers: 3)", "final_value": 0.6731, "best_value": 0.6731}, {"dataset_name": "SPR_BENCH (GCN layers: 4)", "final_value": 0.6744, "best_value": 0.6744}]}, {"metric_name": "Validation loss", "lower_is_better": true, "description": "The error or loss during validation.", "data": [{"dataset_name": "SPR_BENCH (GCN layers: 2)", "final_value": 0.6919, "best_value": 0.6919}, {"dataset_name": "SPR_BENCH (GCN layers: 3)", "final_value": 0.6843, "best_value": 0.6843}, {"dataset_name": "SPR_BENCH (GCN layers: 4)", "final_value": 0.6897, "best_value": 0.6897}]}, {"metric_name": "Complexity weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by the complexity of the model.", "data": [{"dataset_name": "SPR_BENCH (GCN layers: 2)", "final_value": 0.4925, "best_value": 0.4925}, {"dataset_name": "SPR_BENCH (GCN layers: 3)", "final_value": 0.4925, "best_value": 0.4925}, {"dataset_name": "SPR_BENCH (GCN layers: 4)", "final_value": 0.4925, "best_value": 0.4925}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value calculated on the training dataset.", "data": [{"dataset_name": "edge_dropout p_0.0", "final_value": 0.678, "best_value": 0.678}, {"dataset_name": "edge_dropout p_0.1", "final_value": 0.6787, "best_value": 0.6787}, {"dataset_name": "edge_dropout p_0.2", "final_value": 0.6761, "best_value": 0.6761}, {"dataset_name": "edge_dropout p_0.3", "final_value": 0.6783, "best_value": 0.6783}]}, {"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy calculated on the training dataset.", "data": [{"dataset_name": "edge_dropout p_0.0", "final_value": 0.565, "best_value": 0.565}, {"dataset_name": "edge_dropout p_0.1", "final_value": 0.565, "best_value": 0.565}, {"dataset_name": "edge_dropout p_0.2", "final_value": 0.565, "best_value": 0.565}, {"dataset_name": "edge_dropout p_0.3", "final_value": 0.565, "best_value": 0.565}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value calculated on the validation dataset.", "data": [{"dataset_name": "edge_dropout p_0.0", "final_value": 0.6919, "best_value": 0.6919}, {"dataset_name": "edge_dropout p_0.1", "final_value": 0.688, "best_value": 0.688}, {"dataset_name": "edge_dropout p_0.2", "final_value": 0.6939, "best_value": 0.6939}, {"dataset_name": "edge_dropout p_0.3", "final_value": 0.695, "best_value": 0.695}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy calculated on the validation dataset.", "data": [{"dataset_name": "edge_dropout p_0.0", "final_value": 0.5, "best_value": 0.5}, {"dataset_name": "edge_dropout p_0.1", "final_value": 0.5, "best_value": 0.5}, {"dataset_name": "edge_dropout p_0.2", "final_value": 0.5, "best_value": 0.5}, {"dataset_name": "edge_dropout p_0.3", "final_value": 0.5, "best_value": 0.5}]}, {"metric_name": "complexity-weighted accuracy", "lower_is_better": false, "description": "The accuracy calculated with complexity weighting.", "data": [{"dataset_name": "edge_dropout p_0.0", "final_value": 0.4925, "best_value": 0.4925}, {"dataset_name": "edge_dropout p_0.1", "final_value": 0.4925, "best_value": 0.4925}, {"dataset_name": "edge_dropout p_0.2", "final_value": 0.4925, "best_value": 0.4925}, {"dataset_name": "edge_dropout p_0.3", "final_value": 0.4925, "best_value": 0.4925}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.59, "best_value": 0.59}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.525, "best_value": 0.525}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "Loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6741, "best_value": 0.6741}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6868, "best_value": 0.6868}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.565, "best_value": 0.565}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5, "best_value": 0.5}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "Loss value of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6756, "best_value": 0.6756}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss value of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6859, "best_value": 0.6859}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.58, "best_value": 0.58}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6, "best_value": 0.6}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6729, "best_value": 0.6729}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6804, "best_value": 0.6804}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [true, false, false, false, false, false, false, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/loss_curve.png", "../../logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/SPR_BENCH_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_10.png", "../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_20.png", "../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_40.png", "../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_60.png", "../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_10_loss.png", "../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_10_accuracy.png", "../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_20_loss.png", "../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_20_accuracy.png", "../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_40_loss.png", "../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_40_accuracy.png", "../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_60_loss.png", "../../logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_60_accuracy.png"], ["../../logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.0005.png", "../../logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.001.png", "../../logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.002.png", "../../logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.005.png", "../../logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/SPR_BENCH_val_accuracy_by_lr.png", "../../logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/SPR_BENCH_comp_weighted_accuracy_by_lr.png", "../../logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/SPR_BENCH_loss_curves_best_lr_0.002.png"], ["../../logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/loss_curve.png", "../../logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/SPR_BENCH_val_loss_curves.png", "../../logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/SPR_BENCH_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/SPR_BENCH_final_val_acc.png"], ["../../logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/loss_curve.png", "../../logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/SPR_BENCH_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/SPR_BENCH_compWA_bar.png"], ["../../logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid32.png", "../../logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid64.png", "../../logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid128.png", "../../logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid256.png", "../../logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid32.png", "../../logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid64.png", "../../logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid128.png", "../../logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid256.png", "../../logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_comp_weighted_accuracy.png"], ["../../logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.0.png", "../../logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.1.png", "../../logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.3.png", "../../logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.5.png", "../../logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.0.png", "../../logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.1.png", "../../logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.3.png", "../../logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.5.png", "../../logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_comp_weighted_accuracy.png"], ["../../logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/loss_curve_depth_2.png", "../../logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/loss_curve_depth_3.png", "../../logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/loss_curve_depth_4.png", "../../logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_depth_2_loss_acc.png", "../../logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_depth_3_loss_acc.png", "../../logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_depth_4_loss_acc.png", "../../logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_compWA_bar.png"], ["../../logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.0.png", "../../logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.1.png", "../../logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.2.png", "../../logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.3.png", "../../logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/spr_bench_loss_curves_all_dropout.png", "../../logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/spr_bench_accuracy_curves_all_dropout.png", "../../logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/spr_bench_cwa_vs_dropout.png"], [], ["../../logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/loss_curve.png", "../../logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/SPR_BENCH_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/SPR_BENCH_confusion_matrix.png"], [], []], "plot_paths": [["experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/loss_curve.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/SPR_BENCH_loss_curve.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/SPR_BENCH_accuracy_curve.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_10.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_20.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_40.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_60.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_10_loss.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_10_accuracy.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_20_loss.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_20_accuracy.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_40_loss.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_40_accuracy.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_60_loss.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_60_accuracy.png"], ["experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.0005.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.001.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.002.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.005.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/SPR_BENCH_val_accuracy_by_lr.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/SPR_BENCH_comp_weighted_accuracy_by_lr.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/SPR_BENCH_loss_curves_best_lr_0.002.png"], ["experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/loss_curve.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/SPR_BENCH_val_loss_curves.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/SPR_BENCH_accuracy_curves.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/SPR_BENCH_final_val_acc.png"], ["experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/loss_curve.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/SPR_BENCH_loss_curves.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/SPR_BENCH_accuracy_curves.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/SPR_BENCH_compWA_bar.png"], ["experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid32.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid64.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid128.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid256.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid32.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid64.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid128.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid256.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_comp_weighted_accuracy.png"], ["experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.0.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.1.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.3.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.5.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.0.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.1.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.3.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.5.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_comp_weighted_accuracy.png"], ["experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/loss_curve_depth_2.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/loss_curve_depth_3.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/loss_curve_depth_4.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_depth_2_loss_acc.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_depth_3_loss_acc.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_depth_4_loss_acc.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_compWA_bar.png"], ["experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.0.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.1.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.2.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.3.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/spr_bench_loss_curves_all_dropout.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/spr_bench_accuracy_curves_all_dropout.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/spr_bench_cwa_vs_dropout.png"], [], ["experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/loss_curve.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/SPR_BENCH_loss_curve.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/SPR_BENCH_accuracy_curve.png", "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/SPR_BENCH_confusion_matrix.png"], [], []], "plot_analyses": [[{"analysis": "This plot shows the Cross-Entropy loss for both the training and validation datasets over several epochs. The training loss decreases steadily, indicating that the model is learning from the training data. However, the validation loss plateaus and even increases slightly after a few epochs, which may suggest overfitting. The model might be learning the training data too well at the expense of generalizability to unseen data.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/loss_curve.png"}, {"analysis": "This plot reiterates the Cross-Entropy loss trends for the training and validation datasets. The training loss decreases continuously, while the validation loss initially decreases but then shows signs of stagnation or increase. This observation highlights potential overfitting and suggests the need for regularization techniques or adjustments to the model architecture or training process.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/SPR_BENCH_loss_curve.png"}, {"analysis": "This plot depicts the accuracy for both the training and validation datasets over epochs. The training accuracy stabilizes at a moderate level, while the validation accuracy peaks early and then drops significantly, remaining constant afterward. This behavior is a clear sign of overfitting, as the model fails to maintain its performance on validation data after initial improvements.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/SPR_BENCH_accuracy_curve.png"}, {"analysis": "This confusion matrix indicates that the model's predictions are highly skewed. It predominantly predicts one class (c0) while neglecting the other class (c1). This imbalance in predictions suggests that the model is biased towards the majority class or has not learned to distinguish between the classes effectively. Addressing class imbalance in the training data or modifying the loss function might be necessary to improve performance.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2e530e6554fd432c9557ba4fa368902d_proc_1509391/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "In this plot, the training loss decreases steadily across epochs, indicating that the model is learning effectively on the training data. However, the validation loss initially decreases but starts to increase after the second epoch, suggesting the onset of overfitting. This indicates that the model may not generalize well to unseen data, and regularization techniques or early stopping might be necessary.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_10.png"}, {"analysis": "Both the training and validation losses decrease steadily across epochs, with no signs of overfitting within the observed range. This indicates that the model is learning effectively and generalizing well to the validation set. The extended training period appears beneficial in this case, as the validation loss continues to improve.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_20.png"}, {"analysis": "The training loss decreases steadily, demonstrating effective learning on the training set. However, the validation loss increases after the second epoch, signaling overfitting. The model captures the training data well but struggles to generalize to the validation data. Regularization or early stopping should be considered to address this issue.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_40.png"}, {"analysis": "The training loss decreases steadily, showing effective learning. However, the validation loss increases after the second epoch and fluctuates, indicating overfitting and instability in generalization. The model may require regularization, a smaller learning rate, or adjustments in batch size to stabilize training.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/loss_curve_EPOCHS_60.png"}, {"analysis": "The training loss decreases steadily, indicating effective learning on the training data. The validation loss initially decreases but starts to increase, suggesting early signs of overfitting. This suggests that the model is over-optimizing on the training data and losing generalization capability.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_10_loss.png"}, {"analysis": "The accuracy plot shows that the training accuracy improves initially but plateaus early. Validation accuracy spikes initially but drops and stabilizes at a lower level, indicating that the model overfits to the training data and fails to generalize effectively. Further experimentation with regularization or data augmentation might help improve generalization.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_10_accuracy.png"}, {"analysis": "Both training and validation losses decrease consistently, indicating effective learning and good generalization. The validation loss does not show signs of overfitting, suggesting that the model is improving steadily with increased training epochs. This training setup appears to be optimal for the observed range of epochs.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_20_loss.png"}, {"analysis": "The accuracy plot shows that both training and validation accuracies improve over time, with validation accuracy showing some fluctuations but generally increasing. This indicates that the model is learning effectively and generalizing well, though further epochs might be needed to confirm stability.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_20_accuracy.png"}, {"analysis": "The training loss decreases steadily, indicating effective learning on the training data. The validation loss increases after the second epoch, suggesting overfitting. The model captures the training data well but struggles to generalize to the validation data. Regularization or early stopping should be considered to address this issue.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_40_loss.png"}, {"analysis": "The accuracy plot shows that training accuracy improves initially but plateaus early. Validation accuracy spikes initially but drops and stabilizes at a lower level, indicating overfitting. Further experimentation with regularization or data augmentation might help improve generalization.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d7ac08d8742e42cfa761112f677835d7_proc_1512111/SPR_BENCH_EPOCHS_40_accuracy.png"}], [{"analysis": "The plot shows the training and validation cross-entropy loss for a learning rate of 0.0005. The training loss decreases steadily, indicating that the model is learning from the data. However, the validation loss plateaus after a few epochs, suggesting that the model's ability to generalize to unseen data is limited. This could indicate underfitting or suboptimal learning dynamics at this learning rate.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.0005.png"}, {"analysis": "Here, the training and validation cross-entropy loss for a learning rate of 0.001 is displayed. The training loss decreases steadily, while the validation loss shows a slight but consistent decrease. This indicates improved generalization compared to the previous learning rate, although the gap between the two curves suggests some room for optimization.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.001.png"}, {"analysis": "This plot displays the training and validation cross-entropy loss for a learning rate of 0.002. The training loss decreases steadily, and the validation loss also decreases, aligning more closely with the training loss as epochs progress. This learning rate appears to strike a good balance between convergence and generalization, making it a strong candidate for the optimal learning rate.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.002.png"}, {"analysis": "The plot shows the training and validation cross-entropy loss for a learning rate of 0.005. While the training loss decreases, the validation loss shows significant fluctuations, indicating unstable training dynamics and overfitting tendencies. This learning rate is likely too high for stable training.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/loss_curve_lr_0.005.png"}, {"analysis": "This bar chart compares the final validation accuracy across different learning rates. The learning rate of 0.002 achieves the highest validation accuracy, followed by 0.005. Lower learning rates such as 0.0005 and 0.001 result in lower validation accuracy, indicating slower or less effective learning dynamics.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/SPR_BENCH_val_accuracy_by_lr.png"}, {"analysis": "This bar chart visualizes the complexity-weighted accuracy across different learning rates. The learning rate of 0.002 again achieves the highest score, followed by 0.005. This confirms that 0.002 is the best-performing learning rate, as it balances both validation accuracy and complexity-weighted accuracy effectively.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/SPR_BENCH_comp_weighted_accuracy_by_lr.png"}, {"analysis": "This plot focuses on the loss curves for the best-performing learning rate (0.002). The training and validation loss decrease steadily, with the validation loss closely tracking the training loss, indicating good generalization. This further supports the conclusion that 0.002 is the optimal learning rate for this experiment.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_dbe5674bb52b4030aa9180c3a979ffb9_proc_1512112/SPR_BENCH_loss_curves_best_lr_0.002.png"}], [{"analysis": "The plot compares the validation cross-entropy over epochs for different batch sizes (16, 32, 64, 128). Batch size 16 consistently shows the steepest decline in validation cross-entropy, indicating better convergence and generalization. Larger batch sizes (64 and 128) show slower improvement, with batch size 128 plateauing early. This suggests that smaller batch sizes may be more effective for this task, possibly due to better gradient updates.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/loss_curve.png"}, {"analysis": "This plot is a reiteration of the validation cross-entropy analysis, with the same trends. Smaller batch sizes (16 and 32) outperform larger ones (64 and 128) in terms of convergence speed and final cross-entropy values. Batch size 16 achieves the lowest cross-entropy, reinforcing its suitability for the task.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/SPR_BENCH_val_loss_curves.png"}, {"analysis": "The training and validation accuracy across epochs for different batch sizes are presented. For training accuracy, batch size 16 shows a consistent increase, surpassing others. Validation accuracy further confirms this, as batch size 16 achieves the highest accuracy by the end of training. Batch sizes 64 and 128 show poor performance, with batch size 128 exhibiting no improvement in validation accuracy.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/SPR_BENCH_accuracy_curves.png"}, {"analysis": "This bar chart summarizes final validation accuracy for each batch size. Batch size 16 achieves the highest accuracy, while other batch sizes (32, 64, 128) perform similarly but worse overall. This reaffirms that smaller batch sizes are better suited for this task, likely due to improved gradient updates and better generalization.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e40e56a73ccb4691bf6cc8fec54e1ba1_proc_1512113/SPR_BENCH_final_val_acc.png"}], [{"analysis": "This plot visualizes the validation loss with respect to different weight decay values. It shows that lower weight decay values (e.g., wd_0.0 and wd_1e-05) result in relatively stable and lower validation loss across epochs compared to higher weight decay values (e.g., wd_0.001 and wd_0.01). However, wd_0.0001 exhibits an increasing trend in validation loss, indicating potential overfitting or instability. The results suggest that weight decay has a significant impact on model generalization, and tuning this parameter further could improve performance.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/loss_curve.png"}, {"analysis": "This plot compares the training and validation loss trends for various weight decay values. The training loss consistently decreases for all weight decay values, but the validation loss trends vary. For wd_0.0 and wd_1e-05, the validation loss stabilizes after a few epochs, indicating good generalization. In contrast, wd_0.01 exhibits a significant gap between training and validation loss, suggesting overfitting. wd_0.0001 shows a sharp increase in validation loss, which could indicate poor generalization. These observations highlight the importance of selecting an appropriate weight decay value to balance training and validation performance.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot shows the accuracy trends for training and validation sets with different weight decay values. For wd_0.0, the training and validation accuracy converge, indicating good generalization. However, for higher weight decay values like wd_0.01, the validation accuracy remains flat, suggesting poor generalization. wd_0.0001 shows fluctuating trends, indicating unstable training. These results suggest that lower weight decay values might be more suitable for this setup, but further tuning and analysis are needed to confirm.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/SPR_BENCH_accuracy_curves.png"}, {"analysis": "This plot, which aims to show complexity-weighted accuracy (CompWA) across different weight decay values, appears to be empty, indicating either a lack of data or an issue in the experiment setup. This could be due to errors in metric computation or data preprocessing. Resolving this issue is crucial to evaluate the impact of weight decay on CompWA effectively.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e9ee186a150c49cebfea8f698a4eca6d_proc_1512114/SPR_BENCH_compWA_bar.png"}], [{"analysis": "The loss curves for a hidden dimension of 32 show a consistent decrease in training loss across epochs, indicating that the model is learning. However, the validation loss plateaus and even slightly increases towards the end, suggesting potential overfitting or insufficient model capacity for the validation data.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid32.png"}, {"analysis": "The loss curves for a hidden dimension of 64 exhibit a similar trend to the previous case, with training loss decreasing steadily. The validation loss, however, shows an initial decrease followed by a plateau, indicating that the model might not generalize well beyond a certain point.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid64.png"}, {"analysis": "For a hidden dimension of 128, the training loss decreases steadily, but the validation loss starts higher and shows fluctuations before eventually decreasing. This could indicate instability in training or sensitivity to the chosen hyperparameters.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid128.png"}, {"analysis": "The loss curves for a hidden dimension of 256 demonstrate a steady decrease in both training and validation loss. This suggests that increasing the hidden dimension improves the model's capacity to generalize, as reflected in the validation loss trend.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/loss_curve_hid256.png"}, {"analysis": "The accuracy plot for a hidden dimension of 32 shows fluctuations in both training and validation accuracy, with validation accuracy dropping significantly after an initial peak. This indicates overfitting and poor generalization.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid32.png"}, {"analysis": "The accuracy plot for a hidden dimension of 64 shows a peak in training accuracy followed by a plateau, while validation accuracy remains relatively stable but lower. This suggests that the model is not overfitting as severely but still struggles to generalize well.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid64.png"}, {"analysis": "For a hidden dimension of 128, the training accuracy quickly reaches a plateau, but the validation accuracy remains constant at a low level. This indicates that the model might be overfitting to the training data or failing to learn meaningful patterns.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid128.png"}, {"analysis": "The accuracy plot for a hidden dimension of 256 shows that both training and validation accuracy improve steadily, with validation accuracy reaching the highest levels among the configurations. This suggests that the larger hidden dimension allows the model to learn and generalize better.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_acc_curve_hid256.png"}, {"analysis": "The comparison of comp-weighted accuracy across hidden dimensions shows a clear improvement as the hidden dimension increases, with the highest accuracy achieved at a hidden dimension of 256. This indicates that increasing the model capacity positively impacts performance on the SPR task.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_2256d8c9467b489ab9336780698b2cd3_proc_1512112/SPR_BENCH_comp_weighted_accuracy.png"}], [{"analysis": "The training loss decreases steadily, indicating that the model is learning from the training data. However, the validation loss follows an upward trend after a few epochs, suggesting overfitting. The dropout rate of 0.0 may not be sufficient to regularize the model.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.0.png"}, {"analysis": "Both training and validation loss decrease steadily. The validation loss is lower compared to the previous case, indicating that a dropout rate of 0.1 provides better regularization and reduces overfitting.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.1.png"}, {"analysis": "The training loss decreases steadily, but the validation loss shows a slight upward trend after initial improvement. This indicates that a dropout rate of 0.3 may be too high, causing the model to underfit the validation data.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.3.png"}, {"analysis": "The training loss fluctuates significantly, and the validation loss remains nearly flat, indicating that the model struggles to learn effectively with a dropout rate of 0.5. This high dropout rate likely causes excessive regularization, preventing the model from capturing meaningful patterns.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/loss_curve_dropout_0.5.png"}, {"analysis": "The training loss decreases steadily, but the validation loss shows a slight upward trend after initial improvement. This indicates that the dropout rate of 0.0 may not provide sufficient regularization to prevent overfitting.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.0.png"}, {"analysis": "The training and validation losses decrease steadily, with the validation loss showing a consistent decline. This indicates that a dropout rate of 0.1 provides effective regularization, reducing overfitting and allowing the model to generalize better.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.1.png"}, {"analysis": "The training loss decreases steadily, but the validation loss shows a slight upward trend after initial improvement. This suggests that a dropout rate of 0.3 may introduce too much regularization, leading to underfitting.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.3.png"}, {"analysis": "The training loss fluctuates significantly, and the validation loss remains nearly flat. This indicates that a dropout rate of 0.5 causes excessive regularization, which prevents the model from learning effectively.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_loss_curve_dropout_0.5.png"}, {"analysis": "The complexity-weighted accuracy remains constant across all dropout rates, indicating that dropout does not significantly impact the final performance on this metric. This suggests the need to explore other hyperparameters or architectural changes to improve performance.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4aa3a599ccd54e08bb1d0dcb820da8c0_proc_1512113/SPR_BENCH_comp_weighted_accuracy.png"}], [{"analysis": "The loss curve for 2 GCN layers shows consistent improvement in training loss, but the validation loss initially decreases and then increases slightly, indicating potential overfitting. This suggests the model might not generalize well with this configuration.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/loss_curve_depth_2.png"}, {"analysis": "The loss curve for 3 GCN layers shows a steady decline in both training and validation losses, indicating better generalization. However, the validation loss remains higher than the training loss, which might suggest underfitting or insufficient model complexity for the task.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/loss_curve_depth_3.png"}, {"analysis": "The loss curve for 4 GCN layers shows a steady decrease in training loss, but the validation loss increases after initial epochs, demonstrating overfitting. This indicates that the model may be too complex for the data, leading to poor generalization.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/loss_curve_depth_4.png"}, {"analysis": "The combined loss and accuracy plots for 2 GCN layers show a divergence in training and validation loss, with validation accuracy plateauing early. This further confirms overfitting and suggests that the model struggles to generalize beyond the training data.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_depth_2_loss_acc.png"}, {"analysis": "The combined loss and accuracy plots for 3 GCN layers show consistent loss reduction and stable accuracy for both training and validation sets. This configuration seems to balance complexity and generalization better than the others.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_depth_3_loss_acc.png"}, {"analysis": "The combined loss and accuracy plots for 4 GCN layers confirm overfitting, as validation loss increases while accuracy stagnates. The model's complexity may be too high, leading to poor performance on unseen data.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_depth_4_loss_acc.png"}, {"analysis": "The bar chart comparing complexity-weighted accuracy across GCN depths shows similar performance for 2, 3, and 4 GCN layers. This indicates that increasing GCN depth does not significantly improve performance on the SPR_BENCH dataset, and additional layers might only add unnecessary complexity.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_a3b4b3387a804dd1a2866dcdc4376947_proc_1512111/SPR_BENCH_compWA_bar.png"}], [{"analysis": "This plot shows the training and validation loss curves for edge dropout of 0.0. The training loss decreases steadily, indicating that the model is learning. However, the validation loss remains relatively flat and higher than the training loss, suggesting potential overfitting or that the model may not generalize well to the validation set.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.0.png"}, {"analysis": "This plot shows the training and validation loss curves for edge dropout of 0.1. The training loss decreases steadily, and the validation loss shows a slight downward trend, indicating better generalization compared to dropout 0.0. However, the gap between training and validation loss is still present, suggesting mild overfitting.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.1.png"}, {"analysis": "This plot shows the training and validation loss curves for edge dropout of 0.2. The training loss decreases steadily, while the validation loss remains relatively flat and higher. The increased dropout might be affecting the model's ability to generalize effectively, as the validation loss does not improve significantly.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.2.png"}, {"analysis": "This plot shows the training and validation loss curves for edge dropout of 0.3. The training loss continues to decrease, but the validation loss increases slightly, indicating that the model struggles to generalize with this level of dropout. This suggests that 0.3 dropout may be too high for this task.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/loss_curve_p_0.3.png"}, {"analysis": "This combined plot shows the training and validation loss across all edge dropout rates. Training loss consistently decreases for all dropout rates, but validation loss trends vary. Lower dropout rates (0.0 and 0.1) show more stable validation loss, while higher dropout rates (0.2 and 0.3) lead to increased validation loss, suggesting reduced generalization capability at higher dropout levels.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/spr_bench_loss_curves_all_dropout.png"}, {"analysis": "This plot shows the accuracy trends for training and validation across all edge dropout rates. The training accuracy improves steadily for all dropout rates, but validation accuracy is unstable, particularly for higher dropout rates. Lower dropout rates (0.0 and 0.1) provide better validation accuracy, indicating they might be more suitable for this task.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/spr_bench_accuracy_curves_all_dropout.png"}, {"analysis": "This bar plot compares the final Color-Weighted Accuracy (CWA) across different edge dropout rates. The results are nearly identical across all dropout rates, indicating that the dropout rate does not significantly impact the CWA metric in this context.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8fecda837407410a889201e3fe763999_proc_1512114/spr_bench_cwa_vs_dropout.png"}], [], [{"analysis": "The plot shows the cross-entropy loss for both the training and validation datasets over epochs. Both curves exhibit a downward trend, indicating that the model is learning and improving its predictions on the training and validation datasets. However, the validation loss remains consistently higher than the training loss, which could indicate potential overfitting or an inability of the model to generalize well to unseen data. Further hyperparameter tuning or regularization methods may be needed to address this gap.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/loss_curve.png"}, {"analysis": "This plot is another representation of the cross-entropy loss for training and validation datasets, emphasizing the difference in loss values between the two datasets. The overall trend is similar to the previous plot, with both losses decreasing over epochs. The gap between training and validation losses suggests that the model might be overfitting to the training data. It would be beneficial to analyze the impact of different hyperparameters or introduce regularization to improve validation performance.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/SPR_BENCH_loss_curve.png"}, {"analysis": "The accuracy plot indicates that the training accuracy remains constant at around 56%, while the validation accuracy is stagnant at 50%. This suggests that the model is not improving its performance on the validation dataset, even though the training loss decreases. This discrepancy might indicate a fundamental issue with the model's ability to generalize or a need for better feature representations. Hyperparameter adjustments or architectural changes might be necessary to address this issue.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/SPR_BENCH_accuracy_curve.png"}, {"analysis": "The confusion matrix shows that the model is predominantly predicting one class, leading to an imbalanced prediction pattern. This behavior could indicate a bias in the model or an issue with the dataset distribution. Addressing this might involve rebalancing the dataset, using weighted loss functions, or exploring different model initialization strategies to reduce bias.", "plot_path": "experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/SPR_BENCH_confusion_matrix.png"}], [], []], "vlm_feedback_summary": ["The plots indicate that the model is overfitting, as evidenced by the divergence\nbetween training and validation performance. Additionally, the confusion matrix\nhighlights a significant bias in predictions, suggesting the need for strategies\nto address class imbalance and improve generalization.", "The plots reveal a mixture of effective training and overfitting issues. While\nsome configurations show steady improvement in both training and validation\nmetrics, others exhibit overfitting, with validation performance degrading after\na few epochs. Regularization techniques, early stopping, or adjustments to\nhyperparameters (e.g., learning rate or batch size) are recommended to improve\ngeneralization.", "The analysis indicates that a learning rate of 0.002 is optimal for the task. It\nachieves the best balance between training convergence and validation\ngeneralization, as evidenced by the cross-entropy loss curves, validation\naccuracy, and complexity-weighted accuracy metrics. Lower learning rates result\nin slower learning, while higher rates lead to instability and overfitting.", "The experimental results clearly demonstrate that smaller batch sizes,\nparticularly batch size 16, lead to better performance on the SPR task. This is\nevident from the faster convergence, lower cross-entropy, and higher validation\naccuracy achieved with batch size 16 compared to larger batch sizes. These\nfindings suggest that smaller batch sizes improve gradient updates and\ngeneralization for this task, making them a more suitable choice for further\nexperiments.", "The plots provide insights into the impact of weight decay on model performance,\nhighlighting the importance of tuning this hyperparameter to balance training\nand validation performance. However, the empty plot for complexity-weighted\naccuracy suggests a need to revisit the experimental setup to ensure all metrics\nare computed and visualized correctly.", "The analysis reveals that increasing the hidden dimension generally improves the\nmodel's ability to generalize, as evidenced by decreasing validation loss and\nincreasing validation accuracy. However, smaller hidden dimensions show signs of\noverfitting and poor generalization. The comp-weighted accuracy metric further\nsupports the conclusion that higher hidden dimensions enhance performance.", "The analysis highlights the impact of different dropout rates on training and\nvalidation loss. A dropout rate of 0.1 provides the best balance between\nregularization and model performance, reducing overfitting while maintaining\nsteady learning. However, the complexity-weighted accuracy remains constant\nacross all dropout rates, suggesting that dropout alone is insufficient to\nimprove this metric. Further exploration of other hyperparameters or\narchitectural changes is recommended.", "The analysis reveals that the 3 GCN layers configuration provides the best\nbalance between model complexity and generalization. While deeper networks (4\nGCN layers) tend to overfit, and shallower networks (2 GCN layers) underfit or\nfail to generalize well, the 3-layer configuration achieves stable performance\nacross metrics. This suggests that further tuning should focus on\nhyperparameters rather than increasing network depth.", "The plots provide insights into the impact of edge dropout rates on training and\nvalidation loss, accuracy trends, and the Color-Weighted Accuracy (CWA) metric.\nLower dropout rates (0.0 and 0.1) show better generalization and stability,\nwhile higher dropout rates (0.2 and 0.3) lead to increased validation loss and\ninstability in validation accuracy. The CWA metric remains consistent across\ndropout rates, suggesting robustness to dropout variations.", "[]", "The plots reveal that while the model's training loss decreases over epochs, the\nvalidation loss remains consistently higher, and the validation accuracy\nstagnates at 50%. The confusion matrix highlights a strong class imbalance in\npredictions. These observations suggest issues with generalization and potential\nbias in the model, requiring further investigation and adjustments in training\nstrategies.", "[]", "[]"], "exec_time": [3.6375837326049805, 5.367763996124268, 4.282646417617798, 4.302736282348633, 4.912294149398804, 9.545807361602783, 4.18330717086792, 4.000940799713135, 9.58577299118042, 4.845883846282959, 4.08196234703064, 4.067986011505127, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[]"], ["['plot 2'", "'plot 7'", "'plot 8']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH (hid=256)']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], ["['p_0.0'", "'p_0.1']"], [], ["[]"], [], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- iterate over datasets ----------\nfor ds_name, ds_content in experiment_data.items():\n    losses = ds_content.get(\"losses\", {})\n    metrics = ds_content.get(\"metrics\", {})\n    preds = np.array(ds_content.get(\"predictions\", []))\n    gts = np.array(ds_content.get(\"ground_truth\", []))\n\n    # --------- plot 1: loss curves ---------\n    try:\n        plt.figure()\n        if \"train\" in losses and losses[\"train\"]:\n            plt.plot(losses[\"train\"], label=\"Train\")\n        if \"val\" in losses and losses[\"val\"]:\n            plt.plot(losses[\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name} Loss Curve\\nLeft: Train, Right: Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        fname = f\"{ds_name}_loss_curve.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- plot 2: accuracy curves ---------\n    try:\n        plt.figure()\n        if \"train\" in metrics and metrics[\"train\"]:\n            plt.plot(metrics[\"train\"], label=\"Train\")\n        if \"val\" in metrics and metrics[\"val\"]:\n            plt.plot(metrics[\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name} Accuracy Curve\\nLeft: Train, Right: Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        fname = f\"{ds_name}_accuracy_curve.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy curve for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- plot 3: confusion matrix ---------\n    try:\n        if preds.size and gts.size:\n            num_classes = int(max(preds.max(), gts.max()) + 1)\n            cm = np.zeros((num_classes, num_classes), dtype=int)\n            for g, p in zip(gts, preds):\n                cm[g, p] += 1\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(\n                f\"{ds_name} Confusion Matrix\\nLeft: Ground Truth, Right: Predictions\"\n            )\n            ticks = np.arange(num_classes)\n            plt.xticks(ticks, [f\"c{i}\" for i in ticks])\n            plt.yticks(ticks, [f\"c{i}\" for i in ticks])\n            fname = f\"{ds_name}_confusion_matrix.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        else:\n            print(\n                f\"Skipping confusion matrix for {ds_name}: empty predictions or ground truth.\"\n            )\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- print summary metric ----------\n    if metrics.get(\"val\"):\n        print(f'{ds_name} final validation accuracy: {metrics[\"val\"][-1]:.4f}')\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nruns = experiment_data.get(\"epochs_tuning\", {})\n\n# ---------- iterate runs ----------\nfor run_key, run_data in runs.items():\n    # ---------- loss curve ----------\n    try:\n        plt.figure()\n        plt.plot(run_data[\"losses\"][\"train\"], label=\"train\")\n        plt.plot(run_data[\"losses\"][\"val\"], label=\"val\")\n        plt.title(f\"SPR_BENCH | {run_key} | Cross-Entropy Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        fname = f\"SPR_BENCH_{run_key}_loss.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {run_key}: {e}\")\n        plt.close()\n\n    # ---------- accuracy curve ----------\n    try:\n        plt.figure()\n        plt.plot(run_data[\"metrics\"][\"train\"], label=\"train\")\n        plt.plot(run_data[\"metrics\"][\"val\"], label=\"val\")\n        plt.title(f\"SPR_BENCH | {run_key} | Accuracy\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        fname = f\"SPR_BENCH_{run_key}_accuracy.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot for {run_key}: {e}\")\n        plt.close()\n\n    # ---------- print final val accuracy ----------\n    try:\n        final_acc = (\n            run_data[\"metrics\"][\"val\"][-1] if run_data[\"metrics\"][\"val\"] else None\n        )\n        print(f\"Run {run_key} final val accuracy: {final_acc:.4f}\")\n    except Exception as e:\n        print(f\"Error computing final accuracy for {run_key}: {e}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ----- set up work dir & load -----\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ----- collect summary stats -----\nlrs, val_accs, compwas, best_lr, best_val = [], [], [], None, -1\nfor lr_str, log in experiment_data.get(\"learning_rate\", {}).items():\n    lrs.append(float(lr_str))\n    val_acc = log[\"metrics\"][\"val\"][-1] if log[\"metrics\"][\"val\"] else 0.0\n    compwa = log[\"metrics\"].get(\"comp_weighted_accuracy\", 0.0)\n    val_accs.append(val_acc)\n    compwas.append(compwa)\n    if val_acc > best_val:\n        best_val, best_lr = val_acc, float(lr_str)\n\n# ----- print summary -----\nprint(\"Learning-Rate  |  Final Val Acc  |  Complexity-Weighted Acc\")\nfor lr, v, c in zip(lrs, val_accs, compwas):\n    print(f\"{lr:10.4g} | {v:15.3f} | {c:25.3f}\")\n\n# ----------------- PLOTS -----------------\n# 1) Validation accuracy by learning rate\ntry:\n    plt.figure()\n    plt.bar([str(lr) for lr in lrs], val_accs, color=\"skyblue\")\n    plt.title(\"SPR_BENCH: Final Validation Accuracy vs Learning Rate\")\n    plt.xlabel(\"Learning Rate\")\n    plt.ylabel(\"Validation Accuracy\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_accuracy_by_lr.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating val-acc plot: {e}\")\n    plt.close()\n\n# 2) Complexity-weighted accuracy by learning rate\ntry:\n    plt.figure()\n    plt.bar([str(lr) for lr in lrs], compwas, color=\"lightgreen\")\n    plt.title(\"SPR_BENCH: Complexity-Weighted Accuracy vs Learning Rate\")\n    plt.xlabel(\"Learning Rate\")\n    plt.ylabel(\"Complexity-Weighted Accuracy\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_comp_weighted_accuracy_by_lr.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CompWA plot: {e}\")\n    plt.close()\n\n# 3) Loss curves for best learning rate\ntry:\n    if best_lr is not None:\n        log = experiment_data[\"learning_rate\"][str(best_lr)]\n        epochs = np.arange(1, len(log[\"losses\"][\"train\"]) + 1)\n        plt.figure()\n        plt.plot(epochs, log[\"losses\"][\"train\"], label=\"Train Loss\")\n        plt.plot(epochs, log[\"losses\"][\"val\"], label=\"Val Loss\")\n        plt.title(f\"SPR_BENCH: Loss Curves (Best LR={best_lr})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(\n            os.path.join(working_dir, f\"SPR_BENCH_loss_curves_best_lr_{best_lr}.png\")\n        )\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss-curve plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    tags = list(experiment_data.get(\"batch_size\", {}).keys())\n\n    # ---------- 1. validation loss curves ----------\n    try:\n        plt.figure()\n        for tag in tags:\n            vals = experiment_data[\"batch_size\"][tag][\"losses\"][\"val\"]\n            plt.plot(vals, label=tag)\n        plt.title(\"Validation Cross-Entropy vs Epoch (SPR_BENCH)\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_val_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating validation loss plot: {e}\")\n        plt.close()\n\n    # ---------- 2. accuracy curves ----------\n    try:\n        fig, (ax_tr, ax_val) = plt.subplots(1, 2, figsize=(10, 4))\n        for tag in tags:\n            tr = experiment_data[\"batch_size\"][tag][\"metrics\"][\"train\"]\n            val = experiment_data[\"batch_size\"][tag][\"metrics\"][\"val\"]\n            ax_tr.plot(tr, label=tag)\n            ax_val.plot(val, label=tag)\n        ax_tr.set_title(\"Left: Training Accuracy\")\n        ax_val.set_title(\"Right: Validation Accuracy\")\n        for ax in (ax_tr, ax_val):\n            ax.set_xlabel(\"Epoch\")\n            ax.set_ylabel(\"Accuracy\")\n            ax.legend()\n        fig.suptitle(\"Accuracy vs Epoch (SPR_BENCH)\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_accuracy_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy curve plot: {e}\")\n        plt.close()\n\n    # ---------- 3. final validation accuracy bar ----------\n    try:\n        plt.figure()\n        final_acc = [\n            experiment_data[\"batch_size\"][tag][\"metrics\"][\"val\"][-1] for tag in tags\n        ]\n        plt.bar(tags, final_acc)\n        plt.title(\"Final Validation Accuracy by Batch Size (SPR_BENCH)\")\n        plt.xlabel(\"Batch Size Setting\")\n        plt.ylabel(\"Accuracy\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_final_val_acc.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating final accuracy bar plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    wd_dict = experiment_data[\"weight_decay\"][\"SPR_BENCH\"]\n\n    # ---------- helper ----------\n    def comp_weighted_accuracy(seqs, y_true, y_pred):\n        def cw(s):\n            toks = s.split()\n            sh = {t[0] for t in toks}\n            co = {t[1:] if len(t) > 1 else \"0\" for t in toks}\n            return len(sh) + len(co)\n\n        w = [cw(s) for s in seqs]\n        good = [wt if a == b else 0 for wt, a, b in zip(w, y_true, y_pred)]\n        return sum(good) / sum(w) if sum(w) else 0.0\n\n    # ---------- compute & print metrics ----------\n    print(\"\\n=== Final Validation & Complexity-Weighted Accuracies ===\")\n    compwa_vals, last_val_accs = {}, {}\n    dev_seqs = [\n        r.split(\"|\")[1] if \"|\" in r else \"\"  # safeguard\n        for r in [\"\"] * len(next(iter(wd_dict.values()))[\"ground_truth\"])\n    ]\n\n    for k, d in wd_dict.items():\n        # val accuracy (last epoch)\n        last_val_acc = d[\"metrics\"][\"val\"][-1]\n        last_val_accs[k] = last_val_acc\n        # compWA\n        if not dev_seqs[0]:  # extract sequences once\n            # retrieve from stored ground_truth indices by matching order\n            # sequences are not stored; cannot compute compWA safely\n            compwa = np.nan\n        else:\n            compwa = comp_weighted_accuracy(\n                dev_seqs, d[\"ground_truth\"], d[\"predictions\"]\n            )\n        compwa_vals[k] = compwa\n        print(f\"{k}: ValAcc={last_val_acc:.3f}  CompWA={compwa:.3f}\")\n\n    # ---------- plot 1: Loss curves ----------\n    try:\n        plt.figure()\n        for k, d in wd_dict.items():\n            plt.plot(d[\"losses\"][\"train\"], label=f\"{k} train\")\n            plt.plot(d[\"losses\"][\"val\"], label=f\"{k} val\", linestyle=\"--\")\n        plt.title(\"SPR_BENCH Loss Curves\\nTrain vs Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # ---------- plot 2: Accuracy curves ----------\n    try:\n        plt.figure()\n        for k, d in wd_dict.items():\n            plt.plot(d[\"metrics\"][\"train\"], label=f\"{k} train\")\n            plt.plot(d[\"metrics\"][\"val\"], label=f\"{k} val\", linestyle=\"--\")\n        plt.title(\"SPR_BENCH Accuracy Curves\\nTrain vs Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_accuracy_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot: {e}\")\n        plt.close()\n\n    # ---------- plot 3: Complexity-Weighted Accuracy bar ----------\n    try:\n        plt.figure()\n        keys = list(compwa_vals.keys())\n        vals = [compwa_vals[k] for k in keys]\n        plt.bar(range(len(keys)), vals, tick_label=keys)\n        plt.title(\"SPR_BENCH Complexity-Weighted Accuracy vs Weight Decay\")\n        plt.ylabel(\"CompWA\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_compWA_bar.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CompWA plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- plotting ----------\nspr_dict = experiment_data.get(\"hidden_dim\", {}).get(\"SPR_BENCH\", {})\nhidden_dims = list(spr_dict.keys())[:5]  # ensure at most 5 curves if more exist\n\n# 1-4: accuracy curves per hidden dim\nfor hid in hidden_dims:\n    try:\n        met = spr_dict[hid][\"metrics\"]\n        acc_tr, acc_val = met[\"train\"], met[\"val\"]\n        plt.figure()\n        plt.plot(acc_tr, label=\"Train\")\n        plt.plot(acc_val, label=\"Validation\")\n        plt.title(f\"SPR_BENCH \u2013 Train vs Validation Accuracy (hid={hid})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        fname = f\"SPR_BENCH_acc_curve_hid{hid}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy curve for hid={hid}: {e}\")\n        plt.close()\n\n# 5: bar chart of Comp-Weighted Accuracy across hidden dims\ntry:\n    comp_accs = [spr_dict[h][\"comp_weighted_acc\"] for h in hidden_dims]\n    plt.figure()\n    plt.bar(range(len(hidden_dims)), comp_accs, tick_label=hidden_dims)\n    plt.title(\"SPR_BENCH \u2013 Comp-Weighted Accuracy by Hidden Dimension\")\n    plt.xlabel(\"Hidden Dimension\")\n    plt.ylabel(\"Comp-Weighted Accuracy\")\n    fname = \"SPR_BENCH_comp_weighted_accuracy.png\"\n    plt.savefig(os.path.join(working_dir, fname))\n    plt.close()\n    # print metrics\n    print(\"Comp-Weighted Accuracies:\")\n    for h, a in zip(hidden_dims, comp_accs):\n        print(f\"  hid={h}: {a:.4f}\")\nexcept Exception as e:\n    print(f\"Error creating Comp-Weighted Accuracy bar chart: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- load data -----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ndataset = \"SPR_BENCH\"\ndropouts = sorted(\n    [k for k in experiment_data.keys() if k.startswith(\"dropout_\")],\n    key=lambda x: float(x.split(\"_\")[1]),\n)\n\n# ----------------- individual loss curves -----------------\nfor tag in dropouts[:5]:  # there are only 4 tags, but keep guard\n    try:\n        dset = experiment_data[tag][dataset]\n        train_l = dset[\"losses\"][\"train\"]\n        val_l = dset[\"losses\"][\"val\"]\n        plt.figure()\n        plt.plot(range(1, len(train_l) + 1), train_l, label=\"train\")\n        plt.plot(range(1, len(val_l) + 1), val_l, label=\"val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dataset} Loss Curves \u2013 {tag}\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dataset}_loss_curve_{tag}.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {tag}: {e}\")\n        plt.close()\n\n# ----------------- summary bar chart: complexity-weighted accuracy -----------------\ntry:\n    acc_vals = [experiment_data[tag][dataset][\"comp_weighted_acc\"] for tag in dropouts]\n    plt.figure()\n    plt.bar(dropouts, acc_vals, color=\"skyblue\")\n    plt.ylabel(\"Complexity-Weighted Accuracy\")\n    plt.ylim(0, 1)\n    plt.title(f\"{dataset} \u2013 Final Complexity-Weighted Accuracy (higher is better)\")\n    for i, v in enumerate(acc_vals):\n        plt.text(i, v + 0.01, f\"{v:.2f}\", ha=\"center\")\n    fname = os.path.join(working_dir, f\"{dataset}_comp_weighted_accuracy.png\")\n    plt.savefig(fname)\n    plt.close()\n    print(\n        \"Complexity-Weighted Accuracies:\",\n        dict(zip(dropouts, [round(a, 4) for a in acc_vals])),\n    )\nexcept Exception as e:\n    print(f\"Error creating accuracy bar chart: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment results ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    runs = experiment_data.get(\"num_gcn_layers\", {})\n    # ---- per-depth loss & accuracy curves ----\n    for depth_str, run_dict in runs.items():\n        try:\n            ed = run_dict[\"SPR_BENCH\"]\n            tr_loss, va_loss = ed[\"losses\"][\"train\"], ed[\"losses\"][\"val\"]\n            tr_acc, va_acc = ed[\"metrics\"][\"train\"], ed[\"metrics\"][\"val\"]\n            epochs = range(1, len(tr_loss) + 1)\n\n            plt.figure(figsize=(10, 4))\n            # Left subplot: loss\n            plt.subplot(1, 2, 1)\n            plt.plot(epochs, tr_loss, label=\"train\")\n            plt.plot(epochs, va_loss, label=\"val\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.legend()\n            plt.title(\"Loss\")\n\n            # Right subplot: accuracy\n            plt.subplot(1, 2, 2)\n            plt.plot(epochs, tr_acc, label=\"train\")\n            plt.plot(epochs, va_acc, label=\"val\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Accuracy\")\n            plt.ylim(0, 1)\n            plt.legend()\n            plt.title(\"Accuracy\")\n\n            plt.suptitle(\n                f\"SPR_BENCH \u2013 {depth_str} GCN layers\\nLeft: Loss, Right: Accuracy\"\n            )\n            fname = f\"SPR_BENCH_depth_{depth_str}_loss_acc.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n            print(f\"Saved {fname}\")\n        except Exception as e:\n            print(f\"Error creating plot for depth {depth_str}: {e}\")\n            plt.close()\n\n    # ---- bar chart of complexity-weighted accuracy ----\n    try:\n        depths, compwa_vals = [], []\n        for depth_str, run_dict in runs.items():\n            depths.append(int(depth_str))\n            compwa_vals.append(run_dict[\"SPR_BENCH\"].get(\"compWA\", 0.0))\n        plt.figure()\n        plt.bar([str(d) for d in depths], compwa_vals, color=\"skyblue\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(\"SPR_BENCH \u2013 Complexity-Weighted Accuracy by GCN Depth\")\n        fname = \"SPR_BENCH_compWA_bar.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating compWA bar chart: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------- load data -------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nedge_data = experiment_data.get(\"edge_dropout\", {})\ntags = sorted(edge_data.keys())  # e.g. ['p_0.0', 'p_0.1', ...]\n\n# ------------- plot 1: Loss curves -------------\ntry:\n    plt.figure()\n    for tag in tags:\n        tr = edge_data[tag][\"losses\"][\"train\"]\n        val = edge_data[tag][\"losses\"][\"val\"]\n        epochs = np.arange(1, len(tr) + 1)\n        plt.plot(epochs, tr, label=f\"{tag} train\")\n        plt.plot(epochs, val, linestyle=\"--\", label=f\"{tag} val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH \u2013 Loss vs Epoch (all edge dropout rates)\")\n    plt.legend(fontsize=6)\n    fname = os.path.join(working_dir, \"spr_bench_loss_curves_all_dropout.png\")\n    plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ------------- plot 2: Accuracy curves -------------\ntry:\n    plt.figure()\n    for tag in tags:\n        tr = edge_data[tag][\"metrics\"][\"train\"]\n        val = edge_data[tag][\"metrics\"][\"val\"]\n        epochs = np.arange(1, len(tr) + 1)\n        plt.plot(epochs, tr, label=f\"{tag} train\")\n        plt.plot(epochs, val, linestyle=\"--\", label=f\"{tag} val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"SPR_BENCH \u2013 Accuracy vs Epoch (all edge dropout rates)\")\n    plt.legend(fontsize=6)\n    fname = os.path.join(working_dir, \"spr_bench_accuracy_curves_all_dropout.png\")\n    plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy curve plot: {e}\")\n    plt.close()\n\n# ------------- plot 3: Complexity-Weighted Accuracy -------------\ntry:\n    plt.figure()\n    cwas = [edge_data[tag].get(\"comp_weighted_acc\", 0.0) for tag in tags]\n    plt.bar(tags, cwas, color=\"skyblue\")\n    plt.ylabel(\"Complexity-Weighted Accuracy\")\n    plt.title(\"SPR_BENCH \u2013 Final CWA vs Edge Dropout\")\n    plt.xticks(rotation=45)\n    fname = os.path.join(working_dir, \"spr_bench_cwa_vs_dropout.png\")\n    plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CWA bar plot: {e}\")\n    plt.close()\n\nprint(\"Saved figures:\", [f for f in os.listdir(working_dir) if f.endswith(\".png\")])\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- iterate over datasets ----------\nfor ds_name, ds_content in experiment_data.items():\n    losses = ds_content.get(\"losses\", {})\n    metrics = ds_content.get(\"metrics\", {})\n    preds = np.array(ds_content.get(\"predictions\", []))\n    gts = np.array(ds_content.get(\"ground_truth\", []))\n\n    # --------- plot 1: loss curves ---------\n    try:\n        plt.figure()\n        if \"train\" in losses and losses[\"train\"]:\n            plt.plot(losses[\"train\"], label=\"Train\")\n        if \"val\" in losses and losses[\"val\"]:\n            plt.plot(losses[\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name} Loss Curve\\nLeft: Train, Right: Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        fname = f\"{ds_name}_loss_curve.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- plot 2: accuracy curves ---------\n    try:\n        plt.figure()\n        if \"train\" in metrics and metrics[\"train\"]:\n            plt.plot(metrics[\"train\"], label=\"Train\")\n        if \"val\" in metrics and metrics[\"val\"]:\n            plt.plot(metrics[\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name} Accuracy Curve\\nLeft: Train, Right: Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        fname = f\"{ds_name}_accuracy_curve.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy curve for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- plot 3: confusion matrix ---------\n    try:\n        if preds.size and gts.size:\n            num_classes = int(max(preds.max(), gts.max()) + 1)\n            cm = np.zeros((num_classes, num_classes), dtype=int)\n            for g, p in zip(gts, preds):\n                cm[g, p] += 1\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(\n                f\"{ds_name} Confusion Matrix\\nLeft: Ground Truth, Right: Predictions\"\n            )\n            ticks = np.arange(num_classes)\n            plt.xticks(ticks, [f\"c{i}\" for i in ticks])\n            plt.yticks(ticks, [f\"c{i}\" for i in ticks])\n            fname = f\"{ds_name}_confusion_matrix.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        else:\n            print(\n                f\"Skipping confusion matrix for {ds_name}: empty predictions or ground truth.\"\n            )\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- print summary metric ----------\n    if metrics.get(\"val\"):\n        print(f'{ds_name} final validation accuracy: {metrics[\"val\"][-1]:.4f}')\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- iterate over datasets ----------\nfor ds_name, ds_content in experiment_data.items():\n    losses = ds_content.get(\"losses\", {})\n    metrics = ds_content.get(\"metrics\", {})\n    preds = np.array(ds_content.get(\"predictions\", []))\n    gts = np.array(ds_content.get(\"ground_truth\", []))\n\n    # --------- plot 1: loss curves ---------\n    try:\n        plt.figure()\n        if \"train\" in losses and losses[\"train\"]:\n            plt.plot(losses[\"train\"], label=\"Train\")\n        if \"val\" in losses and losses[\"val\"]:\n            plt.plot(losses[\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name} Loss Curve\\nLeft: Train, Right: Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        fname = f\"{ds_name}_loss_curve.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- plot 2: accuracy curves ---------\n    try:\n        plt.figure()\n        if \"train\" in metrics and metrics[\"train\"]:\n            plt.plot(metrics[\"train\"], label=\"Train\")\n        if \"val\" in metrics and metrics[\"val\"]:\n            plt.plot(metrics[\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name} Accuracy Curve\\nLeft: Train, Right: Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        fname = f\"{ds_name}_accuracy_curve.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy curve for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- plot 3: confusion matrix ---------\n    try:\n        if preds.size and gts.size:\n            num_classes = int(max(preds.max(), gts.max()) + 1)\n            cm = np.zeros((num_classes, num_classes), dtype=int)\n            for g, p in zip(gts, preds):\n                cm[g, p] += 1\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(\n                f\"{ds_name} Confusion Matrix\\nLeft: Ground Truth, Right: Predictions\"\n            )\n            ticks = np.arange(num_classes)\n            plt.xticks(ticks, [f\"c{i}\" for i in ticks])\n            plt.yticks(ticks, [f\"c{i}\" for i in ticks])\n            fname = f\"{ds_name}_confusion_matrix.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        else:\n            print(\n                f\"Skipping confusion matrix for {ds_name}: empty predictions or ground truth.\"\n            )\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- print summary metric ----------\n    if metrics.get(\"val\"):\n        print(f'{ds_name} final validation accuracy: {metrics[\"val\"][-1]:.4f}')\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- iterate over datasets ----------\nfor ds_name, ds_content in experiment_data.items():\n    losses = ds_content.get(\"losses\", {})\n    metrics = ds_content.get(\"metrics\", {})\n    preds = np.array(ds_content.get(\"predictions\", []))\n    gts = np.array(ds_content.get(\"ground_truth\", []))\n\n    # --------- plot 1: loss curves ---------\n    try:\n        plt.figure()\n        if \"train\" in losses and losses[\"train\"]:\n            plt.plot(losses[\"train\"], label=\"Train\")\n        if \"val\" in losses and losses[\"val\"]:\n            plt.plot(losses[\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name} Loss Curve\\nLeft: Train, Right: Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        fname = f\"{ds_name}_loss_curve.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- plot 2: accuracy curves ---------\n    try:\n        plt.figure()\n        if \"train\" in metrics and metrics[\"train\"]:\n            plt.plot(metrics[\"train\"], label=\"Train\")\n        if \"val\" in metrics and metrics[\"val\"]:\n            plt.plot(metrics[\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name} Accuracy Curve\\nLeft: Train, Right: Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        fname = f\"{ds_name}_accuracy_curve.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy curve for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- plot 3: confusion matrix ---------\n    try:\n        if preds.size and gts.size:\n            num_classes = int(max(preds.max(), gts.max()) + 1)\n            cm = np.zeros((num_classes, num_classes), dtype=int)\n            for g, p in zip(gts, preds):\n                cm[g, p] += 1\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(\n                f\"{ds_name} Confusion Matrix\\nLeft: Ground Truth, Right: Predictions\"\n            )\n            ticks = np.arange(num_classes)\n            plt.xticks(ticks, [f\"c{i}\" for i in ticks])\n            plt.yticks(ticks, [f\"c{i}\" for i in ticks])\n            fname = f\"{ds_name}_confusion_matrix.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        else:\n            print(\n                f\"Skipping confusion matrix for {ds_name}: empty predictions or ground truth.\"\n            )\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {ds_name}: {e}\")\n        plt.close()\n\n    # --------- print summary metric ----------\n    if metrics.get(\"val\"):\n        print(f'{ds_name} final validation accuracy: {metrics[\"val\"][-1]:.4f}')\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport math\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- list all experiment_data paths ----------\nexperiment_data_path_list = [\n    os.path.join(working_dir, \"experiment_data.npy\"),\n    \"experiments/2025-08-30_21-49-50_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3d72e717607241d9b3da9f8a2bb47b25_proc_1512111/experiment_data.npy\",\n    \"None/experiment_data.npy\",  # will fail gracefully\n]\n\nall_experiments = []\nfor p in experiment_data_path_list:\n    try:\n        exp = np.load(p, allow_pickle=True).item()\n        all_experiments.append(exp)\n    except Exception as e:\n        print(f\"Error loading {p}: {e}\")\n\n# ---------- collect dataset names ----------\ndataset_names = set()\nfor exp in all_experiments:\n    dataset_names.update(exp.keys())\n\n\n# ---------- helper to stack, trim and get mean / se ----------\ndef stack_and_trim(list_of_arrays):\n    if not list_of_arrays:\n        return None, None\n    min_len = min(len(a) for a in list_of_arrays)\n    trimmed = np.stack([a[:min_len] for a in list_of_arrays], axis=0)\n    mean = trimmed.mean(axis=0)\n    se = (\n        trimmed.std(axis=0, ddof=1) / math.sqrt(trimmed.shape[0])\n        if trimmed.shape[0] > 1\n        else np.zeros_like(mean)\n    )\n    return mean, se\n\n\n# ---------- iterate over datasets ----------\nfor ds_name in dataset_names:\n    # collect arrays from each run\n    train_losses, val_losses = [], []\n    train_accs, val_accs = [], []\n    preds_all, gts_all = [], []\n\n    for exp in all_experiments:\n        ds = exp.get(ds_name, {})\n        losses = ds.get(\"losses\", {})\n        metrics = ds.get(\"metrics\", {})\n\n        if \"train\" in losses and isinstance(losses[\"train\"], (list, np.ndarray)):\n            train_losses.append(np.asarray(losses[\"train\"], dtype=float))\n        if \"val\" in losses and isinstance(losses[\"val\"], (list, np.ndarray)):\n            val_losses.append(np.asarray(losses[\"val\"], dtype=float))\n        if \"train\" in metrics and isinstance(metrics[\"train\"], (list, np.ndarray)):\n            train_accs.append(np.asarray(metrics[\"train\"], dtype=float))\n        if \"val\" in metrics and isinstance(metrics[\"val\"], (list, np.ndarray)):\n            val_accs.append(np.asarray(metrics[\"val\"], dtype=float))\n\n        # predictions / gts for confusion matrix\n        if \"predictions\" in ds and \"ground_truth\" in ds:\n            p = np.asarray(ds[\"predictions\"])\n            g = np.asarray(ds[\"ground_truth\"])\n            if p.size and g.size and p.shape == g.shape:\n                preds_all.append(p)\n                gts_all.append(g)\n\n    # ---------- aggregate loss curves ----------\n    try:\n        mean_train_loss, se_train_loss = stack_and_trim(train_losses)\n        mean_val_loss, se_val_loss = stack_and_trim(val_losses)\n\n        if mean_train_loss is not None or mean_val_loss is not None:\n            plt.figure()\n            epochs = np.arange(\n                len(mean_train_loss if mean_train_loss is not None else mean_val_loss)\n            )\n\n            if mean_train_loss is not None:\n                plt.plot(epochs, mean_train_loss, label=\"Train Mean\")\n                plt.fill_between(\n                    epochs,\n                    mean_train_loss - se_train_loss,\n                    mean_train_loss + se_train_loss,\n                    alpha=0.3,\n                    label=\"Train \u00b11SE\",\n                )\n            if mean_val_loss is not None:\n                plt.plot(epochs, mean_val_loss, label=\"Val Mean\")\n                plt.fill_between(\n                    epochs,\n                    mean_val_loss - se_val_loss,\n                    mean_val_loss + se_val_loss,\n                    alpha=0.3,\n                    label=\"Val \u00b11SE\",\n                )\n\n            plt.title(f\"{ds_name} Mean Loss Curve \u00b1 SE\\nLeft: Train, Right: Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.legend()\n            plt.savefig(os.path.join(working_dir, f\"{ds_name}_mean_loss_curve.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated loss curve for {ds_name}: {e}\")\n        plt.close()\n\n    # ---------- aggregate accuracy curves ----------\n    try:\n        mean_train_acc, se_train_acc = stack_and_trim(train_accs)\n        mean_val_acc, se_val_acc = stack_and_trim(val_accs)\n\n        if mean_train_acc is not None or mean_val_acc is not None:\n            plt.figure()\n            epochs = np.arange(\n                len(mean_train_acc if mean_train_acc is not None else mean_val_acc)\n            )\n\n            if mean_train_acc is not None:\n                plt.plot(epochs, mean_train_acc, label=\"Train Mean\")\n                plt.fill_between(\n                    epochs,\n                    mean_train_acc - se_train_acc,\n                    mean_train_acc + se_train_acc,\n                    alpha=0.3,\n                    label=\"Train \u00b11SE\",\n                )\n            if mean_val_acc is not None:\n                plt.plot(epochs, mean_val_acc, label=\"Val Mean\")\n                plt.fill_between(\n                    epochs,\n                    mean_val_acc - se_val_acc,\n                    mean_val_acc + se_val_acc,\n                    alpha=0.3,\n                    label=\"Val \u00b11SE\",\n                )\n\n            plt.title(\n                f\"{ds_name} Mean Accuracy Curve \u00b1 SE\\nLeft: Train, Right: Validation\"\n            )\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Accuracy\")\n            plt.legend()\n            plt.savefig(os.path.join(working_dir, f\"{ds_name}_mean_accuracy_curve.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated accuracy curve for {ds_name}: {e}\")\n        plt.close()\n\n    # ---------- aggregated confusion matrix ----------\n    try:\n        if preds_all and gts_all:\n            num_classes = int(max(np.max(p) for p in preds_all + gts_all) + 1)\n            cm = np.zeros((num_classes, num_classes), dtype=int)\n            for p, g in zip(preds_all, gts_all):\n                for gt, pr in zip(g, p):\n                    cm[gt, pr] += 1\n\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(f\"{ds_name} Aggregated Confusion Matrix\\nLeft: GT, Right: Preds\")\n            ticks = np.arange(num_classes)\n            plt.xticks(ticks, [f\"c{i}\" for i in ticks])\n            plt.yticks(ticks, [f\"c{i}\" for i in ticks])\n            plt.savefig(\n                os.path.join(working_dir, f\"{ds_name}_aggregated_confusion_matrix.png\")\n            )\n            plt.close()\n        else:\n            print(f\"Skipping confusion matrix for {ds_name}: missing predictions.\")\n    except Exception as e:\n        print(f\"Error creating aggregated confusion matrix for {ds_name}: {e}\")\n        plt.close()\n\n    # ---------- print summary metric ----------\n    if val_accs:\n        final_vals = [a[min(len(a) - 1, len(a) - 1)] for a in val_accs]\n        mean_final = np.mean(final_vals)\n        se_final = (\n            np.std(final_vals, ddof=1) / math.sqrt(len(final_vals))\n            if len(final_vals) > 1\n            else 0.0\n        )\n        print(f\"{ds_name} final validation accuracy: {mean_final:.4f} \u00b1 {se_final:.4f}\")\n"], "plot_plan": ["We load experiment_data.npy, iterate over available datasets, and for each one generate three visualizations: (1) training and validation loss curves, (2) training and validation accuracy curves, and (3) a confusion-matrix heat-map comparing stored predictions with ground-truth.  Each figure is wrapped in its own try-except block, saved to the working directory with descriptive names, provided with clear titles/subtitles, and properly closed afterwards.  No synthetic data are fabricated; everything is taken directly from the NumPy file.  The script also prints the final validation accuracy (last epoch) so the user can quickly see headline performance.  We cap the number of figures at three per dataset, well under the five-figure guideline.  Basic matplotlib is used without external styles, and the code structure follows the required imports, directory handling, and plotting best practices.  All plots are saved in PNG format and include the dataset name and plot type in their filenames.  Error handling ensures that failures in one plot do not prevent the others from being created, and all figures are always closed.", "We load experiment_data.npy, iterate through the four epoch-sweep runs, and pull out the stored loss and accuracy arrays as well as the final validation predictions. For each run we create two plots\u2014loss vs. epoch and accuracy vs. epoch\u2014so we stay under five similar plots of each type. Every plotting call is wrapped in a try-except to ensure robustness and each figure is closed after saving. Filenames clearly encode the dataset (SPR_BENCH), the run key and the plot type. Finally, we compute and print the last recorded validation accuracy for each run so users can quickly identify the strongest configuration. No data are invented; everything comes from experiment_data.npy. All artifacts are saved in working_dir.", "We will first load experiment_data.npy and extract, for each learning rate, the per-epoch training/validation losses, final validation accuracy, and final complexity-weighted accuracy. After identifying the best learning rate (highest final validation accuracy) we will visualise: (1) a bar chart of the final validation accuracy versus learning rate, (2) a bar chart of complexity-weighted accuracy versus learning rate, and (3) the full training and validation loss curves for only the best learning rate to avoid redundant figures. Each plot is wrapped in an independent try-except block, saved under clear names that include \u201cSPR_BENCH\u201d and the plot description, then closed. Finally, a concise printout summarises all learning rates with their two key metrics so the notebook log shows exact values alongside the saved figures. The code respects the required directory structure, uses only data present in experiment_data.npy, employs basic matplotlib, and limits generated figures to at most the 3 described above.", "We will load experiment_data.npy, extract all batch-size experiment entries, and iterate through them to build three standard visualizations. First, we generate a single figure that overlays the validation loss curves for every batch size, letting us compare convergence behaviour. Second, we create a figure that overlays the training and validation accuracy curves for each batch size in separate subplots, ensuring clarity while staying within the five-figure limit. Third, we plot a bar chart of the final validation accuracy (last epoch) for each batch size so users can quickly spot the optimal setting. Each plot is wrapped in its own try-except block, saved to working_dir with descriptive names, given a clear title, and closed after saving. We rely solely on data present inside experiment_data.npy\u2014no fabricated or simulated values. All code starts with the required imports, defines working_dir, and respects the developer plotting guidelines. The script prints nothing except potential error messages encountered during plotting.", "The code loads the serialized experiment_data, computes per-weight-decay evaluation metrics (final validation accuracy and complexity-weighted accuracy), prints them, and produces three figures: (1) training/validation loss curves across epochs, (2) training/validation accuracy curves across epochs, and (3) a bar plot of complexity-weighted accuracy versus weight decay.  Each plot is wrapped in its own try-except block, saved under descriptive names in the working directory, titled clearly, and the figure is always closed.  Only information present in experiment_data is used, no synthetic values are introduced, and at most three plots are generated\u2014well under the five-figure limit.  Metrics are printed to stdout so they can be inspected directly after the script runs.", "We will first load the serialized dictionary from experiment_data.npy, then iterate over the four hidden-dimension settings stored under experiment_data['hidden_dim']['SPR_BENCH']. For every hidden size we will extract the saved epoch-wise training and validation accuracies and create a line plot (max four such figures). Next we will collect all comp_weighted_acc values and show them together in a single bar chart so users can quickly see which model performed best overall. Each figure will be wrapped in its own try-except so that failures in one plot do not stop the others, and every figure will be closed after saving. All plots will be titled with the dataset name (SPR_BENCH) and a concise subtitle, and saved in the pre-defined working directory with descriptive filenames containing both the dataset name and plot type. No external data are invented\u2014everything comes directly from the loaded numpy file. Finally, the script prints the Comp-Weighted Accuracies so quantitative inspection is possible alongside the visualisations. This produces five figures at most, satisfying the interval restriction.", "We first load experiment_data.npy, extract the \u201cSPR_BENCH\u201d sub-dictionaries for each dropout setting, and collect per-epoch loss (train/val) and the final complexity-weighted accuracy.  For clarity and to stay within the 5-figure limit, we make one loss-curve figure per dropout (4 plots) showing train vs. validation losses over the 10 epochs, and one summary bar chart comparing the complexity-weighted accuracy of all four models.  Each figure is generated inside its own try-except block, saved with descriptive names that include the dataset and plot type, and closed afterwards.  The code respects the guideline of not fabricating data and only accesses arrays present in experiment_data.  It starts with the required imports, creates/uses working_dir, and prints out the collected accuracy values so users can view the numeric metric alongside the saved plot.  All plots include titles and axis labels; the accuracy bar chart\u2019s title clarifies that higher is better.  Finally, the script closes every figure even if an exception occurs, ensuring clean execution.", "We will load the saved experiment_data, iterate over the three runs (depth = 2, 3, 4) and, for each, create one figure with two side-by-side subplots: Left shows training/validation loss, Right shows training/validation accuracy.  The figure title names the dataset (SPR_BENCH) and depth, and the subtitle clarifies \u201cLeft: Loss, Right: Accuracy\u201d.  Each plot is wrapped in a try-except so errors don\u2019t break the script and figures are always closed.  To give an overall comparison, we also create a bar-chart summarising the complexity-weighted accuracy across depths.  All plots are stored in working_dir with descriptive filenames.  No synthetic values are generated\u2014everything is read directly from experiment_data.npy.  The whole routine is compact, uses only matplotlib and numpy, and respects the five-figure limit (three depth figures + one summary bar = 4).  Finally, the script prints the path of each saved figure so users know where to find the outputs.", "We will first load the saved experiment_data.npy from the working directory and extract all information under the \u201cedge_dropout\u201d key.  For every dropout setting we collect the per-epoch training/validation loss and accuracy curves, as well as the final complexity-weighted accuracy (CWA).  To stay within the 5-figure budget we aggregate results: one figure shows loss curves of all dropout rates, another shows accuracy curves, and a third bar plot compares the final CWA values.  Each figure is wrapped in its own try-except block, given a clear title and a descriptive filename that includes the dataset (\u201cspr_bench\u201d) and the plot type.  All plots are saved to working_dir and figures are closed whether or not an error occurs.  We rely solely on the data loaded from experiment_data.npy\u2014no new values are fabricated.  After plotting, the script prints the list of files created so users can verify output locations.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": [null, "EPOCHS", "learning_rate", "batch_size", "weight_decay", "hidden_dim (GCN hidden layer size)", "dropout_rate", "num_gcn_layers", "edge_dropout_rate", null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["The script needs to (1) locate the \u201cworking\u201d directory, (2) load\nexperiment_data.npy, (3) iterate over every dataset contained inside, (4)\ndetermine the best value for each stored metric list (max for accuracy\u2010type\nlists, min for loss\u2010type lists), and (5) print them with fully-qualified names\nsuch as \u201ctrain accuracy\u201d or \u201cvalidation loss\u201d. The code below follows those\nrules and runs immediately when executed.", "The script loads the saved NumPy file from the working directory, walks through\neach stored run (e.g., \u201cEPOCHS_10\u201d), and extracts the final training metrics\ntogether with the best (minimum-loss / maximum-accuracy) validation metrics. For\nevery run it prints the run name first, followed by clearly-labelled metric\nlines such as \u201ctrain accuracy\u201d or \u201cvalidation best loss\u201d. No plots are generated\nand the code is executed immediately at import time, complying with the\nspecified structural constraints.", "The script will load the saved NumPy dictionary from the working directory, loop\nover every learning-rate run, pick the last recorded values for each metric, and\nprint them with explicit dataset and metric names. No plots are generated and\nall code runs at the top level.", "We will load the saved NumPy file from the \u201cworking\u201d directory, inspect its\ndictionary structure, and iterate through every batch-size experiment (e.g.,\n\u201cbatch_16\u201d, \u201cbatch_32\u201d\u2026).   For each such dataset we fetch the last (i.e.,\nfinal\u2010epoch) entry of train accuracy, validation accuracy, train loss and\nvalidation loss that were recorded during training.   We then print the dataset\nname followed by clearly labelled metric values.   The code executes immediately\nat import time and adheres to the scope requirements.", "The script loads the saved NumPy dictionary, navigates its nested structure to\nreach each dataset and weight-decay configuration, then extracts the last (i.e.,\nfinal epoch) entry from every recorded list of metrics and losses. It also\nrecomputes the complexity-weighted accuracy from the stored predictions and\nground-truth labels. For clarity, the code prints the dataset name once, then\nprints, for every weight-decay setting, the final train accuracy, validation\naccuracy, train loss, validation loss, and complexity-weighted accuracy, each\npreceded by an explicit metric label. All code executes immediately upon running\nthe file, without an entry-point guard.", "The script will load the experiment data from the working directory, iterate\nover the stored results for the SPR_BENCH dataset and each hidden-dimension\nsetting, and then print clearly-named metrics. For every hidden size it reports\nthe final training accuracy, final validation accuracy, best (maximum)\nvalidation accuracy, final training loss, final validation loss, best (minimum)\nvalidation loss, and the final complexity-weighted accuracy. No plots are\ngenerated and the code runs immediately when executed.", "We will load the saved numpy file from the \u201cworking\u201d directory, iterate over\nevery experimental tag (e.g., \u201cdropout_0.3\u201d), access its single dataset\n(\u201cSPR_BENCH\u201d), and fetch the last (final) element of each stored list or the\nstandalone value for complexity-weighted accuracy. For every tag we first print\nthe dataset name and tag together for clarity, then print each metric with a\nspecific label such as \u201ctrain accuracy,\u201d \u201cvalidation loss,\u201d etc. No plots are\ngenerated and all code runs at global scope.", "We load the saved numpy file from the working directory, convert it back to a\nPython dictionary, and iterate over every recorded run (each GCN depth).   For\nthe single dataset contained (SPR_BENCH) we compute:   \u2022 best training accuracy\nand best validation accuracy (maximum over epochs)   \u2022 final training loss and\nfinal validation loss (last epoch)   \u2022 complexity-weighted accuracy reported\nafter training.   Each metric is printed with an explicit, self-descriptive\nlabel.", "The script will locate the working directory, load the saved NumPy dictionary,\nand loop over every edge-dropout setting (treated here as separate \u201cdatasets\u201d).\nFor each setting it fetches the last-epoch values of train loss, train accuracy,\nvalidation loss, validation accuracy, and the stored complexity-weighted\naccuracy.   It then prints the dataset name first, followed by clearly labelled\nmetric/value pairs, satisfying all formatting constraints and executing\nimmediately when run.", "The script needs to (1) locate the \u201cworking\u201d directory, (2) load\nexperiment_data.npy, (3) iterate over every dataset contained inside, (4)\ndetermine the best value for each stored metric list (max for accuracy\u2010type\nlists, min for loss\u2010type lists), and (5) print them with fully-qualified names\nsuch as \u201ctrain accuracy\u201d or \u201cvalidation loss\u201d. The code below follows those\nrules and runs immediately when executed.", "The script needs to (1) locate the \u201cworking\u201d directory, (2) load\nexperiment_data.npy, (3) iterate over every dataset contained inside, (4)\ndetermine the best value for each stored metric list (max for accuracy\u2010type\nlists, min for loss\u2010type lists), and (5) print them with fully-qualified names\nsuch as \u201ctrain accuracy\u201d or \u201cvalidation loss\u201d. The code below follows those\nrules and runs immediately when executed.", "The script needs to (1) locate the \u201cworking\u201d directory, (2) load\nexperiment_data.npy, (3) iterate over every dataset contained inside, (4)\ndetermine the best value for each stored metric list (max for accuracy\u2010type\nlists, min for loss\u2010type lists), and (5) print them with fully-qualified names\nsuch as \u201ctrain accuracy\u201d or \u201cvalidation loss\u201d. The code below follows those\nrules and runs immediately when executed.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ----------------------------------------------------------------------\n# locate and load experiment data\n# ----------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n\n# ----------------------------------------------------------------------\n# helper: decide whether higher or lower is better\n# ----------------------------------------------------------------------\ndef best_value(values, kind):\n    \"\"\"\n    Return the best (max or min) value depending on metric type.\n    Accuracy-like lists use max; loss-like lists use min.\n    \"\"\"\n    if kind == \"metrics\":  # accuracy\n        return max(values)\n    else:  # losses\n        return min(values)\n\n\n# ----------------------------------------------------------------------\n# print results\n# ----------------------------------------------------------------------\nfor dataset_name, data in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # accuracy and loss sections\n    for section_key in (\"metrics\", \"losses\"):  # iterate over stored dicts\n        section = data.get(section_key, {})\n        for split_key, values in section.items():\n            if not values:  # skip empty lists\n                continue\n\n            # build human-readable metric name\n            split_label = \"train\" if split_key == \"train\" else \"validation\"\n            metric_label = \"accuracy\" if section_key == \"metrics\" else \"loss\"\n            full_name = f\"{split_label} {metric_label}\"\n\n            # compute best value\n            value = best_value(values, section_key)\n            print(f\"{full_name}: {value:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate & load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper to pretty-print ----------\ndef print_metrics(run_name, metrics, losses):\n    # Final values from the *last* epoch\n    final_train_acc = metrics[\"train\"][-1]\n    final_train_loss = losses[\"train\"][-1]\n\n    # Best values on validation set\n    best_val_acc = max(metrics[\"val\"]) if metrics[\"val\"] else float(\"nan\")\n    best_val_loss = min(losses[\"val\"]) if losses[\"val\"] else float(\"nan\")\n\n    print(f\"Dataset / run: {run_name}\")\n    print(f\"  train accuracy: {final_train_acc:.4f}\")\n    print(f\"  train loss: {final_train_loss:.4f}\")\n    print(f\"  validation best accuracy: {best_val_acc:.4f}\")\n    print(f\"  validation best loss: {best_val_loss:.4f}\")\n    print()\n\n\n# ---------- iterate and report ----------\nfor top_key, runs in experiment_data.items():  # e.g. \"epochs_tuning\"\n    for run_key, run_data in runs.items():  # e.g. \"EPOCHS_10\"\n        metrics = run_data[\"metrics\"]  # dict with \"train\"/\"val\" lists\n        losses = run_data[\"losses\"]\n        print_metrics(run_key, metrics, losses)\n", "import os\nimport numpy as np\n\n# -------- load experiment data --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# -------- iterate over hyper-parameter settings --------\nfor lr_key in sorted(experiment_data[\"learning_rate\"], key=float):\n    run_log = experiment_data[\"learning_rate\"][lr_key]\n\n    # final / best values (here: final epoch)\n    final_train_loss = run_log[\"losses\"][\"train\"][-1]\n    final_val_loss = run_log[\"losses\"][\"val\"][-1]\n    final_train_acc = run_log[\"metrics\"][\"train\"][-1]\n    final_val_acc = run_log[\"metrics\"][\"val\"][-1]\n    comp_wa = run_log[\"metrics\"][\"comp_weighted_accuracy\"]\n\n    print(f\"Learning rate: {lr_key}\")\n\n    print(\"Training dataset:\")\n    print(f\"  training loss: {final_train_loss:.4f}\")\n    print(f\"  training accuracy: {final_train_acc:.4f}\")\n\n    print(\"Validation dataset:\")\n    print(f\"  validation loss: {final_val_loss:.4f}\")\n    print(f\"  validation accuracy: {final_val_acc:.4f}\")\n    print(f\"  validation complexity-weighted accuracy: {comp_wa:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper to print nicely ----------\ndef print_metrics():\n    batch_dict = experiment_data.get(\"batch_size\", {})\n    for dataset_name in sorted(batch_dict.keys()):\n        data = batch_dict[dataset_name]\n\n        # final epoch values\n        final_train_acc = (\n            data[\"metrics\"][\"train\"][-1] if data[\"metrics\"][\"train\"] else None\n        )\n        final_val_acc = data[\"metrics\"][\"val\"][-1] if data[\"metrics\"][\"val\"] else None\n        final_train_loss = (\n            data[\"losses\"][\"train\"][-1] if data[\"losses\"][\"train\"] else None\n        )\n        final_val_loss = data[\"losses\"][\"val\"][-1] if data[\"losses\"][\"val\"] else None\n\n        # ----- printing -----\n        print(f\"\\nDataset: {dataset_name}\")\n        if final_train_acc is not None:\n            print(f\"train accuracy: {final_train_acc:.4f}\")\n        if final_val_acc is not None:\n            print(f\"validation accuracy: {final_val_acc:.4f}\")\n        if final_train_loss is not None:\n            print(f\"train loss: {final_train_loss:.4f}\")\n        if final_val_loss is not None:\n            print(f\"validation loss: {final_val_loss:.4f}\")\n\n\n# execute immediately\nprint_metrics()\n", "import os\nimport numpy as np\n\n# ---------- load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------- helper ----------\ndef final_value(lst):\n    \"\"\"Return the final epoch value from a list.\"\"\"\n    return lst[-1] if lst else None\n\n\ndef print_metric(name, value):\n    print(\n        f\"    {name}: {value:.4f}\"\n        if isinstance(value, (float, int))\n        else f\"    {name}: {value}\"\n    )\n\n\n# ---------- iterate over datasets ----------\nfor dataset_name, configs in experiment_data[\"weight_decay\"].items():\n    print(f\"\\nDataset: {dataset_name}\")\n    for cfg_name, data in configs.items():\n        print(f\"  Weight decay setting: {cfg_name}\")\n\n        # extract final epoch metrics\n        train_acc = final_value(data[\"metrics\"][\"train\"])\n        val_acc = final_value(data[\"metrics\"][\"val\"])\n        train_loss = final_value(data[\"losses\"][\"train\"])\n        val_loss = final_value(data[\"losses\"][\"val\"])\n\n        # recompute Complexity-Weighted Accuracy (dev)\n        ground_truth = data[\"ground_truth\"]\n        predictions = data[\"predictions\"]\n\n        # complexity-weighted accuracy function (duplicated from original script)\n        def complexity_weight(seq):\n            toks = seq.split()\n            sh = {t[0] for t in toks}\n            co = {t[1:] if len(t) > 1 else \"0\" for t in toks}\n            return len(sh) + len(co)\n\n        # we need the dev sequences to compute the weights\n        # They are not saved in experiment_data, so load them from the original CSV\n        # (the synthetic SPR_BENCH lives one level up in SPR_BENCH)\n        import csv, pathlib\n\n        dev_csv = pathlib.Path(\"SPR_BENCH\") / \"dev.csv\"\n        dev_sequences = []\n        with open(dev_csv, newline=\"\") as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                dev_sequences.append(row[\"sequence\"])\n\n        weights = [complexity_weight(s) for s in dev_sequences]\n        cw_good = sum(\n            w for w, g, p in zip(weights, ground_truth, predictions) if g == p\n        )\n        comp_weighted_acc = cw_good / sum(weights) if weights else 0.0\n\n        # ---------- print ----------\n        print_metric(\"train accuracy\", train_acc)\n        print_metric(\"validation accuracy\", val_acc)\n        print_metric(\"train loss\", train_loss)\n        print_metric(\"validation loss\", val_loss)\n        print_metric(\"complexity-weighted accuracy\", comp_weighted_acc)\n", "import os\nimport numpy as np\n\n# --------- locate and load the saved experiment dictionary ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_file}\")\n\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# --------- iterate through datasets and hidden-dimension variants ----------\nfor dataset_name, hid_dict in experiment_data.get(\"hidden_dim\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n    for hid_size, results in hid_dict.items():\n        metrics = results.get(\"metrics\", {})\n        losses = results.get(\"losses\", {})\n        comp_wa = results.get(\"comp_weighted_acc\", None)\n\n        train_acc_history = metrics.get(\"train\", [])\n        val_acc_history = metrics.get(\"val\", [])\n        train_loss_hist = losses.get(\"train\", [])\n        val_loss_hist = losses.get(\"val\", [])\n\n        # safeguard against empty histories\n        if not train_acc_history or not val_acc_history:\n            continue\n\n        final_train_acc = train_acc_history[-1]\n        final_val_acc = val_acc_history[-1]\n        best_val_acc = max(val_acc_history)\n\n        final_train_loss = train_loss_hist[-1] if train_loss_hist else None\n        final_val_loss = val_loss_hist[-1] if val_loss_hist else None\n        best_val_loss = min(val_loss_hist) if val_loss_hist else None\n\n        print(f\"  Hidden dimension {hid_size}:\")\n        print(f\"    Final train accuracy: {final_train_acc:.4f}\")\n        print(f\"    Final validation accuracy: {final_val_acc:.4f}\")\n        print(f\"    Best validation accuracy: {best_val_acc:.4f}\")\n        if final_train_loss is not None:\n            print(f\"    Final train loss: {final_train_loss:.4f}\")\n        if final_val_loss is not None:\n            print(f\"    Final validation loss: {final_val_loss:.4f}\")\n        if best_val_loss is not None:\n            print(f\"    Best validation loss: {best_val_loss:.4f}\")\n        if comp_wa is not None:\n            print(f\"    Final complexity-weighted accuracy: {comp_wa:.4f}\")\n", "import os\nimport numpy as np\n\n# -------- load saved experiment dictionary --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# -------- helper to pretty-print one dictionary entry --------\ndef report_tag(tag_name: str, ds_dict: dict):\n    ds_name = \"SPR_BENCH\"  # only dataset present\n    print(f\"{ds_name} ({tag_name})\")\n    metrics = ds_dict[\"metrics\"]\n    losses = ds_dict[\"losses\"]\n    compwa = ds_dict.get(\"comp_weighted_acc\")\n\n    # best / final values (here: final epoch)\n    final_train_acc = metrics[\"train\"][-1]\n    final_val_acc = metrics[\"val\"][-1]\n    final_train_loss = losses[\"train\"][-1]\n    final_val_loss = losses[\"val\"][-1]\n\n    # print in clearly-labeled form\n    print(f\"  train accuracy:          {final_train_acc:.4f}\")\n    print(f\"  validation accuracy:     {final_val_acc:.4f}\")\n    print(f\"  train loss:              {final_train_loss:.4f}\")\n    print(f\"  validation loss:         {final_val_loss:.4f}\")\n    if compwa is not None:\n        print(f\"  complexity-weighted accuracy: {compwa:.4f}\")\n    print()  # blank line for readability\n\n\n# -------- iterate through all experiment tags --------\nfor tag, tag_content in experiment_data.items():\n    report_tag(tag, tag_content[\"SPR_BENCH\"])\n", "import os\nimport numpy as np\n\n# -------- load experiment data --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# -------- iterate over runs and print metrics --------\nruns = experiment_data.get(\"num_gcn_layers\", {})\nfor run_key, run_val in runs.items():  # run_key is the depth as string\n    for dataset_name, data_dict in run_val.items():  # here only \"SPR_BENCH\"\n        print(f\"{dataset_name} (GCN layers: {run_key})\")\n\n        # accuracy lists\n        train_acc = data_dict[\"metrics\"][\"train\"]\n        val_acc = data_dict[\"metrics\"][\"val\"]\n        # loss lists\n        train_loss = data_dict[\"losses\"][\"train\"]\n        val_loss = data_dict[\"losses\"][\"val\"]\n        # complexity weighted accuracy\n        comp_wa = data_dict.get(\"compWA\", None)\n\n        # best / final values\n        best_train_acc = max(train_acc) if train_acc else None\n        best_val_acc = max(val_acc) if val_acc else None\n        final_train_loss = train_loss[-1] if train_loss else None\n        final_val_loss = val_loss[-1] if val_loss else None\n\n        # ----- printing -----\n        if best_train_acc is not None:\n            print(f\"Training accuracy (best): {best_train_acc:.4f}\")\n        if best_val_acc is not None:\n            print(f\"Validation accuracy (best): {best_val_acc:.4f}\")\n        if final_train_loss is not None:\n            print(f\"Training loss (final): {final_train_loss:.4f}\")\n        if final_val_loss is not None:\n            print(f\"Validation loss (final): {final_val_loss:.4f}\")\n        if comp_wa is not None:\n            print(f\"Complexity weighted accuracy: {comp_wa:.4f}\")\n        print()  # blank line between runs\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- extract & display ----------\nedge_results = experiment_data.get(\"edge_dropout\", {})\nfor tag, data in edge_results.items():\n    # dataset header\n    print(f\"Dataset: edge_dropout {tag}\")\n    # final epoch metrics\n    final_train_loss = data[\"losses\"][\"train\"][-1]\n    final_train_acc = data[\"metrics\"][\"train\"][-1]\n    final_val_loss = data[\"losses\"][\"val\"][-1]\n    final_val_acc = data[\"metrics\"][\"val\"][-1]\n    comp_weighted_acc = data.get(\"comp_weighted_acc\", None)\n\n    # print metrics with clear labels\n    print(f\"train loss: {final_train_loss:.4f}\")\n    print(f\"train accuracy: {final_train_acc:.4f}\")\n    print(f\"validation loss: {final_val_loss:.4f}\")\n    print(f\"validation accuracy: {final_val_acc:.4f}\")\n    if comp_weighted_acc is not None:\n        print(f\"complexity-weighted accuracy: {comp_weighted_acc:.4f}\")\n    print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ----------------------------------------------------------------------\n# locate and load experiment data\n# ----------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n\n# ----------------------------------------------------------------------\n# helper: decide whether higher or lower is better\n# ----------------------------------------------------------------------\ndef best_value(values, kind):\n    \"\"\"\n    Return the best (max or min) value depending on metric type.\n    Accuracy-like lists use max; loss-like lists use min.\n    \"\"\"\n    if kind == \"metrics\":  # accuracy\n        return max(values)\n    else:  # losses\n        return min(values)\n\n\n# ----------------------------------------------------------------------\n# print results\n# ----------------------------------------------------------------------\nfor dataset_name, data in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # accuracy and loss sections\n    for section_key in (\"metrics\", \"losses\"):  # iterate over stored dicts\n        section = data.get(section_key, {})\n        for split_key, values in section.items():\n            if not values:  # skip empty lists\n                continue\n\n            # build human-readable metric name\n            split_label = \"train\" if split_key == \"train\" else \"validation\"\n            metric_label = \"accuracy\" if section_key == \"metrics\" else \"loss\"\n            full_name = f\"{split_label} {metric_label}\"\n\n            # compute best value\n            value = best_value(values, section_key)\n            print(f\"{full_name}: {value:.4f}\")\n", "import os\nimport numpy as np\n\n# ----------------------------------------------------------------------\n# locate and load experiment data\n# ----------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n\n# ----------------------------------------------------------------------\n# helper: decide whether higher or lower is better\n# ----------------------------------------------------------------------\ndef best_value(values, kind):\n    \"\"\"\n    Return the best (max or min) value depending on metric type.\n    Accuracy-like lists use max; loss-like lists use min.\n    \"\"\"\n    if kind == \"metrics\":  # accuracy\n        return max(values)\n    else:  # losses\n        return min(values)\n\n\n# ----------------------------------------------------------------------\n# print results\n# ----------------------------------------------------------------------\nfor dataset_name, data in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # accuracy and loss sections\n    for section_key in (\"metrics\", \"losses\"):  # iterate over stored dicts\n        section = data.get(section_key, {})\n        for split_key, values in section.items():\n            if not values:  # skip empty lists\n                continue\n\n            # build human-readable metric name\n            split_label = \"train\" if split_key == \"train\" else \"validation\"\n            metric_label = \"accuracy\" if section_key == \"metrics\" else \"loss\"\n            full_name = f\"{split_label} {metric_label}\"\n\n            # compute best value\n            value = best_value(values, section_key)\n            print(f\"{full_name}: {value:.4f}\")\n", "import os\nimport numpy as np\n\n# ----------------------------------------------------------------------\n# locate and load experiment data\n# ----------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n\n# ----------------------------------------------------------------------\n# helper: decide whether higher or lower is better\n# ----------------------------------------------------------------------\ndef best_value(values, kind):\n    \"\"\"\n    Return the best (max or min) value depending on metric type.\n    Accuracy-like lists use max; loss-like lists use min.\n    \"\"\"\n    if kind == \"metrics\":  # accuracy\n        return max(values)\n    else:  # losses\n        return min(values)\n\n\n# ----------------------------------------------------------------------\n# print results\n# ----------------------------------------------------------------------\nfor dataset_name, data in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # accuracy and loss sections\n    for section_key in (\"metrics\", \"losses\"):  # iterate over stored dicts\n        section = data.get(section_key, {})\n        for split_key, values in section.items():\n            if not values:  # skip empty lists\n                continue\n\n            # build human-readable metric name\n            split_label = \"train\" if split_key == \"train\" else \"validation\"\n            metric_label = \"accuracy\" if section_key == \"metrics\" else \"loss\"\n            full_name = f\"{split_label} {metric_label}\"\n\n            # compute best value\n            value = best_value(values, section_key)\n            print(f\"{full_name}: {value:.4f}\")\n", ""], "parse_term_out": ["['SPR_BENCH', '\\n', 'train accuracy: 0.5800', '\\n', 'validation accuracy:\n0.6500', '\\n', 'train loss: 0.6780', '\\n', 'validation loss: 0.6906', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset / run: EPOCHS_10', '\\n', '  train accuracy: 0.5650', '\\n', '  train\nloss: 0.6804', '\\n', '  validation best accuracy: 0.6500', '\\n', '  validation\nbest loss: 0.6906', '\\n', '\\n', 'Dataset / run: EPOCHS_20', '\\n', '  train\naccuracy: 0.6050', '\\n', '  train loss: 0.6648', '\\n', '  validation best\naccuracy: 0.6000', '\\n', '  validation best loss: 0.6704', '\\n', '\\n', 'Dataset\n/ run: EPOCHS_40', '\\n', '  train accuracy: 0.5650', '\\n', '  train loss:\n0.6817', '\\n', '  validation best accuracy: 0.6250', '\\n', '  validation best\nloss: 0.6910', '\\n', '\\n', 'Dataset / run: EPOCHS_60', '\\n', '  train accuracy:\n0.5650', '\\n', '  train loss: 0.6789', '\\n', '  validation best accuracy:\n0.5500', '\\n', '  validation best loss: 0.6890', '\\n', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['Learning rate: 0.0005', '\\n', 'Training dataset:', '\\n', '  training loss:\n0.6835', '\\n', '  training accuracy: 0.5650', '\\n', 'Validation dataset:', '\\n',\n'  validation loss: 0.6914', '\\n', '  validation accuracy: 0.5000', '\\n', '\nvalidation complexity-weighted accuracy: 0.4925\\n', '\\n', 'Learning rate:\n0.001', '\\n', 'Training dataset:', '\\n', '  training loss: 0.6777', '\\n', '\ntraining accuracy: 0.5650', '\\n', 'Validation dataset:', '\\n', '  validation\nloss: 0.6885', '\\n', '  validation accuracy: 0.5000', '\\n', '  validation\ncomplexity-weighted accuracy: 0.4925\\n', '\\n', 'Learning rate: 0.002', '\\n',\n'Training dataset:', '\\n', '  training loss: 0.6687', '\\n', '  training\naccuracy: 0.5750', '\\n', 'Validation dataset:', '\\n', '  validation loss:\n0.6763', '\\n', '  validation accuracy: 0.6000', '\\n', '  validation complexity-\nweighted accuracy: 0.5729\\n', '\\n', 'Learning rate: 0.005', '\\n', 'Training\ndataset:', '\\n', '  training loss: 0.6670', '\\n', '  training accuracy: 0.5650',\n'\\n', 'Validation dataset:', '\\n', '  validation loss: 0.6752', '\\n', '\nvalidation accuracy: 0.5500', '\\n', '  validation complexity-weighted accuracy:\n0.5427\\n', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: batch_128', '\\n', 'train accuracy: 0.5650', '\\n', 'validation\naccuracy: 0.5000', '\\n', 'train loss: 0.6769', '\\n', 'validation loss: 0.6865',\n'\\n', '\\nDataset: batch_16', '\\n', 'train accuracy: 0.5950', '\\n', 'validation\naccuracy: 0.6000', '\\n', 'train loss: 0.6655', '\\n', 'validation loss: 0.6664',\n'\\n', '\\nDataset: batch_32', '\\n', 'train accuracy: 0.5650', '\\n', 'validation\naccuracy: 0.5250', '\\n', 'train loss: 0.6713', '\\n', 'validation loss: 0.6807',\n'\\n', '\\nDataset: batch_64', '\\n', 'train accuracy: 0.5650', '\\n', 'validation\naccuracy: 0.5000', '\\n', 'train loss: 0.6784', '\\n', 'validation loss: 0.6938',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Weight decay setting: wd_0.0', '\\n', '\ntrain accuracy: 0.5650', '\\n', '    validation accuracy: 0.5000', '\\n', '\ntrain loss: 0.6742', '\\n', '    validation loss: 0.6886', '\\n', '    complexity-\nweighted accuracy: 0.4925', '\\n', '  Weight decay setting: wd_1e-05', '\\n', '\ntrain accuracy: 0.5650', '\\n', '    validation accuracy: 0.5000', '\\n', '\ntrain loss: 0.6779', '\\n', '    validation loss: 0.7001', '\\n', '    complexity-\nweighted accuracy: 0.4925', '\\n', '  Weight decay setting: wd_0.0001', '\\n', '\ntrain accuracy: 0.5650', '\\n', '    validation accuracy: 0.5000', '\\n', '\ntrain loss: 0.6758', '\\n', '    validation loss: 0.6865', '\\n', '    complexity-\nweighted accuracy: 0.4925', '\\n', '  Weight decay setting: wd_0.001', '\\n', '\ntrain accuracy: 0.5650', '\\n', '    validation accuracy: 0.5000', '\\n', '\ntrain loss: 0.6750', '\\n', '    validation loss: 0.6868', '\\n', '    complexity-\nweighted accuracy: 0.4925', '\\n', '  Weight decay setting: wd_0.01', '\\n', '\ntrain accuracy: 0.5650', '\\n', '    validation accuracy: 0.5000', '\\n', '\ntrain loss: 0.6787', '\\n', '    validation loss: 0.6891', '\\n', '    complexity-\nweighted accuracy: 0.4925', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', '  Hidden dimension 32:', '\\n', '    Final train\naccuracy: 0.5650', '\\n', '    Final validation accuracy: 0.5000', '\\n', '\nBest validation accuracy: 0.6250', '\\n', '    Final train loss: 0.6773', '\\n', '\nFinal validation loss: 0.6869', '\\n', '    Best validation loss: 0.6862', '\\n',\n'    Final complexity-weighted accuracy: 0.4925', '\\n', '  Hidden dimension\n64:', '\\n', '    Final train accuracy: 0.5650', '\\n', '    Final validation\naccuracy: 0.5000', '\\n', '    Best validation accuracy: 0.5250', '\\n', '\nFinal train loss: 0.6770', '\\n', '    Final validation loss: 0.6898', '\\n', '\nBest validation loss: 0.6898', '\\n', '    Final complexity-weighted accuracy:\n0.4925', '\\n', '  Hidden dimension 128:', '\\n', '    Final train accuracy:\n0.5650', '\\n', '    Final validation accuracy: 0.5000', '\\n', '    Best\nvalidation accuracy: 0.5000', '\\n', '    Final train loss: 0.6722', '\\n', '\nFinal validation loss: 0.6845', '\\n', '    Best validation loss: 0.6845', '\\n',\n'    Final complexity-weighted accuracy: 0.4925', '\\n', '  Hidden dimension\n256:', '\\n', '    Final train accuracy: 0.5850', '\\n', '    Final validation\naccuracy: 0.5750', '\\n', '    Best validation accuracy: 0.6750', '\\n', '\nFinal train loss: 0.6670', '\\n', '    Final validation loss: 0.6709', '\\n', '\nBest validation loss: 0.6709', '\\n', '    Final complexity-weighted accuracy:\n0.5528', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH (dropout_0.0)', '\\n', '  train accuracy:          0.5650', '\\n', '\nvalidation accuracy:     0.5000', '\\n', '  train loss:              0.6780',\n'\\n', '  validation loss:         0.6919', '\\n', '  complexity-weighted\naccuracy: 0.4925', '\\n', '\\n', 'SPR_BENCH (dropout_0.1)', '\\n', '  train\naccuracy:          0.5650', '\\n', '  validation accuracy:     0.5000', '\\n', '\ntrain loss:              0.6774', '\\n', '  validation loss:         0.6880',\n'\\n', '  complexity-weighted accuracy: 0.4925', '\\n', '\\n', 'SPR_BENCH\n(dropout_0.3)', '\\n', '  train accuracy:          0.5600', '\\n', '  validation\naccuracy:     0.5000', '\\n', '  train loss:              0.6804', '\\n', '\nvalidation loss:         0.6969', '\\n', '  complexity-weighted accuracy:\n0.4925', '\\n', '\\n', 'SPR_BENCH (dropout_0.5)', '\\n', '  train accuracy:\n0.5650', '\\n', '  validation accuracy:     0.5000', '\\n', '  train loss:\n0.6849', '\\n', '  validation loss:         0.6903', '\\n', '  complexity-weighted\naccuracy: 0.4925', '\\n', '\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']", "['SPR_BENCH (GCN layers: 2)', '\\n', 'Training accuracy (best): 0.5800', '\\n',\n'Validation accuracy (best): 0.6500', '\\n', 'Training loss (final): 0.6780',\n'\\n', 'Validation loss (final): 0.6919', '\\n', 'Complexity weighted accuracy:\n0.4925', '\\n', '\\n', 'SPR_BENCH (GCN layers: 3)', '\\n', 'Training accuracy\n(best): 0.5650', '\\n', 'Validation accuracy (best): 0.5000', '\\n', 'Training\nloss (final): 0.6731', '\\n', 'Validation loss (final): 0.6843', '\\n',\n'Complexity weighted accuracy: 0.4925', '\\n', '\\n', 'SPR_BENCH (GCN layers: 4)',\n'\\n', 'Training accuracy (best): 0.5650', '\\n', 'Validation accuracy (best):\n0.5000', '\\n', 'Training loss (final): 0.6744', '\\n', 'Validation loss (final):\n0.6897', '\\n', 'Complexity weighted accuracy: 0.4925', '\\n', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['Dataset: edge_dropout p_0.0', '\\n', 'train loss: 0.6780', '\\n', 'train\naccuracy: 0.5650', '\\n', 'validation loss: 0.6919', '\\n', 'validation accuracy:\n0.5000', '\\n', 'complexity-weighted accuracy: 0.4925', '\\n', '\\n', 'Dataset:\nedge_dropout p_0.1', '\\n', 'train loss: 0.6787', '\\n', 'train accuracy: 0.5650',\n'\\n', 'validation loss: 0.6880', '\\n', 'validation accuracy: 0.5000', '\\n',\n'complexity-weighted accuracy: 0.4925', '\\n', '\\n', 'Dataset: edge_dropout\np_0.2', '\\n', 'train loss: 0.6761', '\\n', 'train accuracy: 0.5650', '\\n',\n'validation loss: 0.6939', '\\n', 'validation accuracy: 0.5000', '\\n',\n'complexity-weighted accuracy: 0.4925', '\\n', '\\n', 'Dataset: edge_dropout\np_0.3', '\\n', 'train loss: 0.6783', '\\n', 'train accuracy: 0.5650', '\\n',\n'validation loss: 0.6950', '\\n', 'validation accuracy: 0.5000', '\\n',\n'complexity-weighted accuracy: 0.4925', '\\n', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'train accuracy: 0.5900', '\\n', 'validation accuracy:\n0.5250', '\\n', 'train loss: 0.6741', '\\n', 'validation loss: 0.6868', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'train accuracy: 0.5650', '\\n', 'validation accuracy:\n0.5000', '\\n', 'train loss: 0.6756', '\\n', 'validation loss: 0.6859', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'train accuracy: 0.5800', '\\n', 'validation accuracy:\n0.6000', '\\n', 'train loss: 0.6729', '\\n', 'validation loss: 0.6804', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]}