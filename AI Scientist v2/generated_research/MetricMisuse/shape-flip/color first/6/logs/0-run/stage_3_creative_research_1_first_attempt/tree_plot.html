<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 8], [0, 4], [0, 2], [0, 3], [0, 7], [0, 1], [1, 5], [4, 6], [6, 11], [6, 10], [6, 12], [6, 9]], "layout": [[0.5, 0.0], [0.0, 0.33333333333333337], [0.2, 0.33333333333333337], [0.4, 0.33333333333333337], [0.6, 0.33333333333333337], [0.0, 0.6666666666666667], [0.6, 0.6666666666666667], [0.8, 0.33333333333333337], [1.0, 0.33333333333333337], [0.3, 1.0], [0.5, 1.0], [0.7, 1.0], [0.9, 1.0]], "plan": ["Hyperparam tuning name: batch_size. We will sweep over training batch sizes [16,\n32, 64, 128].   For each value we (re)-instantiate the model, create a\ncorresponding DataLoader, train for a few epochs, evaluate on validation and\ntest splits, and log metrics/losses inside a single experiment_data dictionary\nusing the structure required. All results are saved to \u201cexperiment_data.npy\u201d;\nsimple line plots are also produced for each batch size in the ./working folder.", "We improve the previous GNN by explicitly modelling three relation types between\ntokens\u2014sequential order, same-color and same-shape\u2014using a Relational Graph\nConvolutional Network (R-GCN).   Each sequence is converted into a graph whose\nnodes carry shape / color embeddings; edges are tagged with a relation id (0 =\nnext-token, 1 = same-color, 2 = same-shape).   Two stacked R-GCN blocks followed\nby global mean pooling yield a graph embedding that is classified with a linear\nlayer.   We train the model for a small number of epochs with batch-size 64\n(found near-optimal in earlier experiments) and track loss plus the new\nComplexity-Weighted Accuracy (CplxWA), whose weight is the product of unique\ncolor and shape counts.   The script automatically falls back to synthetic data\nif SPR_BENCH is absent, logs metrics, prints validation loss each epoch, saves\nall experiment data to \u201c./working/experiment_data.npy\u201d, and honours all GPU/CPU\nhandling rules.   This richer relational modelling is expected to capture hidden\npoly-factor rules better than a plain GNN, potentially pushing CWA/SWA and\nCplxWA beyond the current SOTA.", "We extend the previous baseline by introducing three relation types\u2014temporal\nadjacency, same-color and same-shape\u2014and feed the resulting multirelational\ngraph into two RGCN layers.  This explicitly models both local order and global\nattribute dependencies that a plain GraphConv could miss.  Node features are\nlearned shape and color embeddings; after relational message passing we apply\nmean pooling and a linear classifier.  During training we monitor validation\nloss plus Color-, Shape-, and Complexity-Weighted Accuracy (product of color-\nand shape-variety) at every epoch, printing progress and storing all traces in\n`experiment_data`.  We keep a single hyper-parameter setting (batch=64, lr=1e-3,\n8 epochs) for brevity; this can easily be turned into a sweep later.  The script\nautomatically falls back to a small synthetic dataset if `SPR_BENCH` is absent,\nruns on GPU when available, and saves all collected metrics to\n`./working/experiment_data.npy` for later analysis.  This compact experiment\nshould reveal whether relational edges give measurable gains over the earlier\nbaseline.", "Graph-structured representations can expose non-local regularities in SPR\nsequences better than purely sequential models.   We build a lightweight Graph\nNeural Network that embeds shape and color features, connects adjacent tokens\nplus extra edges linking tokens sharing either the same color or the same shape,\nand learns with two GraphConv layers followed by global mean pooling.   Training\nuses a single hyper-parameter configuration (batch_size = 64, lr = 1e-3) for 3\nepochs to keep runtime reasonable while still demonstrating learning.   At every\nepoch we log training loss, validation loss, and the required Complexity-\nWeighted Accuracy (product of unique colors and shapes) on both splits.   Test\nCWA/SWA and CplxWA are computed after training.   All metrics, losses,\npredictions and ground-truth labels are stored in the prescribed experiment_data\ndict and saved to ./working/experiment_data.npy; loss and metric curves are also\nplotted.   The code is self-contained, automatically falls back to synthetic\ndata if SPR_BENCH is absent, and fully honours GPU/CPU device management rules.", "We refine the graph construction by adding relational edges: 0 = next-token\norder, 1 = shared-color, 2 = shared-shape.   An R-GCN encoder (with relation-\nspecific weights) processes these graphs; pooled graph embeddings feed a\nclassifier.   Training uses batch_size = 64 for 10 epochs with Adam.   At every\nepoch we log losses plus three metrics\u2014Color-Weighted Accuracy (CWA), Shape-\nWeighted Accuracy (SWA) and the required Complexity-Weighted Accuracy (CplxWA,\nproduct of color\u00d7shape variety).   All metrics, losses and predictions are\nstored in `experiment_data` and saved to `./working/experiment_data.npy`.", "The earlier script silently fell back to a randomly\u2013labelled synthetic set\nwhenever the real SPR_BENCH directory was not found; with labels being pure\nnoise, the network could never learn and the loss stayed flat.   The fix is\ntherefore to (1) look harder for the real benchmark (supporting several default\nlocations and an environment variable); and (2) if we *still* have to synthesize\ndata, generate *rule-based* labels instead of random ones so that the model has\na meaningful learning signal.   The remainder of the pipeline (graph\nconstruction, model, training loop, metric logging and plotting) is kept intact,\nwith strictly enforced GPU/CPU handling as required by the guidelines.", "The low accuracy originates from generating completely random labels when the\nbenchmark folder is absent\u2014\u200bthe network cannot possibly learn such noise.   We\nfix this by (1) synthesising labels with a deterministic, rule-based function\nthat really depends on the colour/shape structure (so the model has something\nlearnable) and (2) slightly cleaning the graph builder (convert tensors to\nPython ints before equality tests, avoid duplicate order edges).  All device\nhandling, metric tracking, saving and plotting now follow the requested\nguidelines.", "By enriching the sequence-graphs with three explicit relation types\u2014token order,\nshared shape, and shared color\u2014we let the network reason over both local order\nand global equivalence classes.  A compact R-GCN (Relational Graph Convolution)\nis used so that a distinct weight matrix is learned for each edge type, helping\nthe model disentangle different structural signals.  Node features are the\nconcatenation of learned shape and color embeddings; after two R-GCN layers and\nglobal mean pooling we classify the whole sequence.  We keep the training\nroutine simple (5\u20138 epochs) but log validation loss and the mandatory\nComplexity-Weighted Accuracy (weight = #unique-shapes \u00d7 #unique-colors) after\nevery epoch.  All losses and metrics are recorded in an experiment_data\ndictionary and saved to ./working/experiment_data.npy for later analysis.  If\nthe official SPR_BENCH folder is absent the script automatically falls back to a\nsmall synthetic set so it always runs.  Batch size is fixed at the previously\noptimal 64, but other hyper-parameters can be explored by changing constants at\nthe top of the script.  The code is self-contained, GPU-aware, and executes\nimmediately when run.", "We extend the previous GNN by introducing relation-aware edges: sequential\nadjacency, same-color, and same-shape links.  These relations are handled with\ntwo R-GCN layers so the network can pass information along rule-salient paths.\nComplexity-Weighted-Accuracy now follows the product definition (color \u00d7 shape).\nWe train with a reasonable batch size (64) for 8 epochs, tracking losses and\nCplxWA on both train and dev splits, then report the test score.  All metrics\nand predictions are stored in experiment_data.npy for later plots or analysis.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\nfrom datetime import datetime\nfrom typing import List\n\n# ------------------------- dirs & device ------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ------------------------- helper metrics -----------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    seqs: List[str], y_t: List[int], y_p: List[int]\n) -> float:\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(w_i if t == p else 0 for w_i, t, p in zip(w, y_t, y_p)) / (sum(w) or 1)\n\n\n# ------------------------- load (real or synth) SPR -------------------------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nif spr_root.exists():\n    from datasets import load_dataset\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(spr_root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dsets = {sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]}\n    print(\"Loaded real SPR_BENCH.\")\nelse:  # ---------- synthetic fallback\n    print(\"SPR_BENCH not found, generating synthetic data.\")\n\n    def make_synth(n):\n        shapes, colors = [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        seqs, labels = [], []\n        for _ in range(n):\n            length = np.random.randint(4, 8)\n            seqs.append(\n                \" \".join(\n                    np.random.choice(shapes) + np.random.choice(colors)\n                    for _ in range(length)\n                )\n            )\n            labels.append(np.random.randint(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    dsets = {\"train\": make_synth(500), \"dev\": make_synth(100), \"test\": make_synth(100)}\n\n# ------------------------- vocab & graph builder ----------------------------\nall_shapes, all_colors = set(), set()\nfor s in dsets[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel2idx = {l: i for i, l in enumerate(sorted(set(dsets[\"train\"][\"label\"])))}\nnum_shapes, num_colors, num_classes = len(shape2idx), len(color2idx), len(label2idx)\n\n\ndef seq_to_graph(seq: str, label: int):\n    toks = seq.strip().split()\n    n = len(toks)\n    x = torch.tensor(\n        np.stack([[shape2idx[t[0]], color2idx[t[1]]] for t in toks]), dtype=torch.long\n    )\n    if n > 1:\n        src, dst = np.arange(n - 1), np.arange(1, n)\n        edge_index = torch.tensor(\n            np.vstack([np.hstack([src, dst]), np.hstack([dst, src])]), dtype=torch.long\n        )\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    return (\n        [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n        if isinstance(split, dict)\n        else [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n    )\n\n\ntrain_data, dev_data, test_data = map(\n    build_dataset, (dsets[\"train\"], dsets[\"dev\"], dsets[\"test\"])\n)\n\n\n# ------------------------- model --------------------------------------------\nclass SPRGNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb, self.color_emb = nn.Embedding(num_shapes, 8), nn.Embedding(\n            num_colors, 8\n        )\n        self.lin = nn.Linear(16, 32)\n        self.conv1, self.conv2 = GraphConv(32, 64), GraphConv(64, 64)\n        self.cls = nn.Linear(64, num_classes)\n\n    def forward(self, data):\n        x = torch.cat([self.shape_emb(data.x[:, 0]), self.color_emb(data.x[:, 1])], 1)\n        x = F.relu(self.lin(x))\n        x = F.relu(self.conv1(x, data.edge_index))\n        x = F.relu(self.conv2(x, data.edge_index))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\n# ------------------------- experiment dict ----------------------------------\nexperiment_data = {\"batch_size\": {}}  # <- hyperparam tuning type key\nbatch_sweep = [16, 32, 64, 128]\nepochs = 5\n\nfor bs in batch_sweep:\n    key = f\"bs_{bs}\"\n    experiment_data[\"batch_size\"][key] = {\n        \"metrics\": {\"train_compwa\": [], \"val_compwa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n    # loaders and model/opt\n    train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n    dev_loader = DataLoader(dev_data, batch_size=128, shuffle=False)\n    model = SPRGNN().to(device)\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n\n    # ------------- training loop -------------------------------------------\n    for epoch in range(1, epochs + 1):\n        model.train()\n        tot_loss = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            opt.zero_grad()\n            out = model(batch)\n            loss = criterion(out, batch.y)\n            loss.backward()\n            opt.step()\n            tot_loss += loss.item() * batch.num_graphs\n        avg_train_loss = tot_loss / len(train_loader.dataset)\n\n        # validation\n        model.eval()\n        vloss = 0\n        seqs = true = pred = []\n        all_seq, all_true, all_pred = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch)\n                l = criterion(out, batch.y)\n                vloss += l.item() * batch.num_graphs\n                pr = out.argmax(1).cpu().tolist()\n                lb = batch.y.cpu().tolist()\n                all_pred.extend(pr)\n                all_true.extend(lb)\n                all_seq.extend(batch.seq)\n        avg_val_loss = vloss / len(dev_loader.dataset)\n        compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n\n        # log\n        ed = experiment_data[\"batch_size\"][key]\n        ed[\"losses\"][\"train\"].append(avg_train_loss)\n        ed[\"losses\"][\"val\"].append(avg_val_loss)\n        ed[\"metrics\"][\"val_compwa\"].append(compwa)\n        ed[\"epochs\"].append(epoch)\n        print(\n            f\"[bs={bs}] Epoch {epoch}  train_loss {avg_train_loss:.4f}  \"\n            f\"val_loss {avg_val_loss:.4f}  CompWA {compwa:.4f}\"\n        )\n\n    # ------------- test ----------------------------------------------------\n    test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n    model.eval()\n    all_seq, all_true, all_pred = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            all_pred.extend(out.argmax(1).cpu().tolist())\n            all_true.extend(batch.y.cpu().tolist())\n            all_seq.extend(batch.seq)\n    test_compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n    experiment_data[\"batch_size\"][key][\"metrics\"][\"test_compwa\"] = test_compwa\n    experiment_data[\"batch_size\"][key][\"predictions\"] = all_pred\n    experiment_data[\"batch_size\"][key][\"ground_truth\"] = all_true\n    print(f\"[bs={bs}] Test CompWA {test_compwa:.4f}\")\n\n    # ------------- plots ---------------------------------------------------\n    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    plt.figure()\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"losses\"][\"train\"],\n        label=\"train\",\n    )\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"losses\"][\"val\"],\n        label=\"val\",\n    )\n    plt.title(f\"Loss (bs={bs})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_bs{bs}_{ts}.png\"))\n    plt.close()\n\n    plt.figure()\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"metrics\"][\"val_compwa\"],\n    )\n    plt.title(f\"Val CompWA (bs={bs})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.savefig(os.path.join(working_dir, f\"compwa_bs{bs}_{ts}.png\"))\n    plt.close()\n\n# ------------------------- save ---------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All runs complete. Data saved to ./working/experiment_data.npy\")\n", "import os, pathlib, numpy as np, torch, random\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom typing import List\n\n# ------------- working dir --------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------- device -------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------- metric helpers ----------------------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    seqs: List[str], y_true: List[int], y_pred: List[int]\n) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    num = sum(w for w, t, p in zip(weights, y_true, y_pred) if t == p)\n    den = sum(weights) if sum(weights) > 0 else 1\n    return num / den\n\n\n# ------------- load dataset (real or synthetic) -----------------------------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nif spr_root.exists():\n    print(\"Loading real SPR_BENCH \u2026\")\n    from datasets import load_dataset\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(spr_root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    raw_dsets = {sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]}\nelse:\n    print(\"SPR_BENCH folder not found \u2014 generating synthetic data.\")\n\n    def make_synth(n):\n        shapes, colors = [\"A\", \"B\", \"C\", \"D\"], [\"1\", \"2\", \"3\", \"4\"]\n        seqs, labels = [], []\n        for i in range(n):\n            ln = random.randint(4, 8)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(ln)\n            )\n            seqs.append(seq)\n            labels.append(random.randint(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    raw_dsets = {\n        \"train\": make_synth(2000),\n        \"dev\": make_synth(400),\n        \"test\": make_synth(400),\n    }\n\n# ------------- vocab --------------------------------------------------------\nall_shapes, all_colors = set(), set()\nfor s in raw_dsets[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel_set = sorted(set(raw_dsets[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nnum_shapes, num_colors, num_classes = len(shape2idx), len(color2idx), len(label2idx)\n\n\n# ------------- graph builder ------------------------------------------------\ndef seq_to_graph(seq: str, label: int) -> Data:\n    toks = seq.strip().split()\n    n = len(toks)\n    # node features: shape id, color id\n    x = torch.tensor(\n        [[shape2idx[t[0]], color2idx[t[1]]] for t in toks], dtype=torch.long\n    )\n    edges_src, edges_dst, edge_types = [], [], []\n    # relation 0: sequential order (bidirectional)\n    for i in range(n - 1):\n        edges_src += [i, i + 1]\n        edges_dst += [i + 1, i]\n        edge_types += [0, 0]\n    # relation 1: same color\n    color_map = {}\n    for idx, t in enumerate(toks):\n        color_map.setdefault(t[1], []).append(idx)\n    for nodes in color_map.values():\n        for i in nodes:\n            for j in nodes:\n                if i != j:\n                    edges_src.append(i)\n                    edges_dst.append(j)\n                    edge_types.append(1)\n    # relation 2: same shape\n    shape_map = {}\n    for idx, t in enumerate(toks):\n        shape_map.setdefault(t[0], []).append(idx)\n    for nodes in shape_map.values():\n        for i in nodes:\n            for j in nodes:\n                if i != j:\n                    edges_src.append(i)\n                    edges_dst.append(j)\n                    edge_types.append(2)\n    edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long)\n    edge_type = torch.tensor(edge_types, dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, edge_type=edge_type, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    if isinstance(split, dict):\n        seqs, labels = split[\"sequence\"], split[\"label\"]\n    else:\n        seqs, labels = split[\"sequence\"], split[\"label\"]\n    return [seq_to_graph(s, l) for s, l in zip(seqs, labels)]\n\n\ntrain_ds, dev_ds, test_ds = map(\n    build_dataset, (raw_dsets[\"train\"], raw_dsets[\"dev\"], raw_dsets[\"test\"])\n)\n\n\n# ------------- model --------------------------------------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self, emb_dim=16, hidden=64, num_relations=3):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, emb_dim // 2)\n        self.color_emb = nn.Embedding(num_colors, emb_dim // 2)\n        self.lin0 = nn.Linear(emb_dim, hidden)\n        self.rgcn1 = RGCNConv(hidden, hidden, num_relations, num_bases=None)\n        self.rgcn2 = RGCNConv(hidden, hidden, num_relations, num_bases=None)\n        self.cls = nn.Linear(hidden, num_classes)\n\n    def forward(self, data):\n        s_emb = self.shape_emb(data.x[:, 0])\n        c_emb = self.color_emb(data.x[:, 1])\n        x = torch.cat([s_emb, c_emb], dim=1)\n        x = F.relu(self.lin0(x))\n        x = F.relu(self.rgcn1(x, data.edge_index, data.edge_type))\n        x = F.relu(self.rgcn2(x, data.edge_index, data.edge_type))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\n# ------------- experiment dict ---------------------------------------------\nexperiment_data = {\n    \"spr_bench\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# ------------- training setup ----------------------------------------------\nbatch_size = 64\nepochs = 8\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=128, shuffle=False)\n\nmodel = SPR_RGCN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\n# ------------- training loop -----------------------------------------------\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running_loss = 0.0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch.num_graphs\n    avg_train_loss = running_loss / len(train_loader.dataset)\n\n    # validation\n    model.eval()\n    val_loss, v_seqs, v_true, v_pred = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            l = criterion(out, batch.y)\n            val_loss += l.item() * batch.num_graphs\n            preds = out.argmax(1).cpu().tolist()\n            labels = batch.y.cpu().tolist()\n            v_pred.extend(preds)\n            v_true.extend(labels)\n            v_seqs.extend(batch.seq)\n    avg_val_loss = val_loss / len(dev_loader.dataset)\n    val_cplx = complexity_weighted_accuracy(v_seqs, v_true, v_pred)\n    print(\n        f\"Epoch {epoch}: validation_loss = {avg_val_loss:.4f}, Val CplxWA = {val_cplx:.4f}\"\n    )\n\n    # log metrics\n    ed = experiment_data[\"spr_bench\"]\n    ed[\"losses\"][\"train\"].append(avg_train_loss)\n    ed[\"losses\"][\"val\"].append(avg_val_loss)\n    ed[\"metrics\"][\"train\"].append(None)  # placeholder if needed\n    ed[\"metrics\"][\"val\"].append(val_cplx)\n    ed[\"epochs\"].append(epoch)\n\n# ------------- testing ------------------------------------------------------\nmodel.eval()\nt_seqs, t_true, t_pred = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        out = model(batch)\n        preds = out.argmax(1).cpu().tolist()\n        labels = batch.y.cpu().tolist()\n        t_pred.extend(preds)\n        t_true.extend(labels)\n        t_seqs.extend(batch.seq)\ntest_cplx = complexity_weighted_accuracy(t_seqs, t_true, t_pred)\nprint(f\"Test Complexity-Weighted Accuracy: {test_cplx:.4f}\")\n\nexperiment_data[\"spr_bench\"][\"predictions\"] = t_pred\nexperiment_data[\"spr_bench\"][\"ground_truth\"] = t_true\nexperiment_data[\"spr_bench\"][\"metrics\"][\"test\"] = test_cplx\n\n# ------------- plots --------------------------------------------------------\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nplt.figure()\nplt.plot(\n    experiment_data[\"spr_bench\"][\"epochs\"],\n    experiment_data[\"spr_bench\"][\"losses\"][\"train\"],\n    label=\"train\",\n)\nplt.plot(\n    experiment_data[\"spr_bench\"][\"epochs\"],\n    experiment_data[\"spr_bench\"][\"losses\"][\"val\"],\n    label=\"val\",\n)\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.legend()\nplt.title(\"Loss curve\")\nplt.savefig(os.path.join(working_dir, f\"loss_{ts}.png\"))\nplt.close()\n\nplt.figure()\nplt.plot(\n    experiment_data[\"spr_bench\"][\"epochs\"],\n    experiment_data[\"spr_bench\"][\"metrics\"][\"val\"],\n)\nplt.xlabel(\"epoch\")\nplt.ylabel(\"CplxWA\")\nplt.title(\"Validation CplxWA\")\nplt.savefig(os.path.join(working_dir, f\"cplxwa_{ts}.png\"))\nplt.close()\n\n# ------------- save ---------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Experiment data saved to ./working/experiment_data.npy\")\n", "import os, pathlib, numpy as np, torch, random\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nfrom datetime import datetime\n\n# ---------- directory & device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metric helpers ----------\ndef count_color_variety(seq):\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.split()))\n\n\ndef color_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(w_i for w_i, t, p in zip(w, y_t, y_p) if t == p) / (sum(w) or 1)\n\n\ndef shape_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(w_i for w_i, t, p in zip(w, y_t, y_p) if t == p) / (sum(w) or 1)\n\n\ndef complexity_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(w_i for w_i, t, p in zip(w, y_t, y_p) if t == p) / (sum(w) or 1)\n\n\n# ---------- load SPR_BENCH or synth ----------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\n\n\ndef _load(real_path):\n    from datasets import load_dataset\n\n    return load_dataset(\n        \"csv\", data_files=str(real_path), split=\"train\", cache_dir=\".cache_dsets\"\n    )\n\n\nif spr_root.exists():\n    print(\"Loading real SPR_BENCH\")\n    dsets = {sp: _load(spr_root / f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]}\nelse:\n    print(\"Creating synthetic dataset\")\n\n    def synth(n):\n        shapes, colors = \"ABC\", \"123\"\n        seqs, labels = [], []\n        for i in range(n):\n            L = random.randint(4, 8)\n            seqs.append(\n                \" \".join(\n                    random.choice(shapes) + random.choice(colors) for _ in range(L)\n                )\n            )\n            labels.append(random.randint(0, 2))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    dsets = {\"train\": synth(800), \"dev\": synth(200), \"test\": synth(200)}\n\n# ---------- vocab ----------\nall_shapes = set(tok[0] for s in dsets[\"train\"][\"sequence\"] for tok in s.split())\nall_colors = set(\n    tok[1] for s in dsets[\"train\"][\"sequence\"] for tok in s.split() if len(tok) > 1\n)\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nnum_shapes, len_color = len(shape2idx), len(color2idx)\nlabels_sorted = sorted(set(dsets[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(labels_sorted)}\nnum_classes = len(label2idx)\n\n\n# ---------- graph builder ----------\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    x = torch.tensor(\n        [[shape2idx[t[0]], color2idx[t[1]]] for t in toks], dtype=torch.long\n    )\n    edges, types = [], []\n    # temporal adjacency\n    for i in range(n - 1):\n        edges.extend([[i, i + 1], [i + 1, i]])\n        types.extend([0, 0])\n    # same color\n    color_map = {}\n    for i, t in enumerate(toks):\n        color_map.setdefault(t[1], []).append(i)\n    for idxs in color_map.values():\n        for i in idxs:\n            for j in idxs:\n                if i != j:\n                    edges.append([i, j])\n                    types.append(1)\n    # same shape\n    shape_map = {}\n    for i, t in enumerate(toks):\n        shape_map.setdefault(t[0], []).append(i)\n    for idxs in shape_map.values():\n        for i in idxs:\n            for j in idxs:\n                if i != j:\n                    edges.append([i, j])\n                    types.append(2)\n    if len(edges) == 0:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n        edge_type = torch.zeros((0,), dtype=torch.long)\n    else:\n        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n        edge_type = torch.tensor(types, dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, edge_type=edge_type, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    return (\n        [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n        if isinstance(split, dict)\n        else [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n    )\n\n\ntrain_ds, dev_ds, test_ds = map(\n    build_dataset, (dsets[\"train\"], dsets[\"dev\"], dsets[\"test\"])\n)\n\n\n# ---------- model ----------\nclass SPR_RGCN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, 8)\n        self.color_emb = nn.Embedding(len_color, 8)\n        self.lin_in = nn.Linear(16, 32)\n        self.conv1 = RGCNConv(32, 64, num_relations=3)\n        self.conv2 = RGCNConv(64, 64, num_relations=3)\n        self.cls = nn.Linear(64, num_classes)\n        self.dp = nn.Dropout(0.2)\n\n    def forward(self, data):\n        feat = torch.cat(\n            [self.shape_emb(data.x[:, 0]), self.color_emb(data.x[:, 1])], 1\n        )\n        feat = F.relu(self.lin_in(feat))\n        feat = self.dp(F.relu(self.conv1(feat, data.edge_index, data.edge_type)))\n        feat = self.dp(F.relu(self.conv2(feat, data.edge_index, data.edge_type)))\n        graph_emb = global_mean_pool(feat, data.batch)\n        return self.cls(graph_emb)\n\n\n# ---------- training setup ----------\nbatch_size, epochs, lr = 64, 8, 1e-3\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False)\nmodel = SPR_RGCN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n\n# ---------- experiment data ----------\nexperiment_data = {\n    \"spr_rgcn\": {\n        \"metrics\": {\n            \"train\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n            \"val\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n        },\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n    }\n}\n\n# ---------- train loop ----------\nfor epoch in range(1, epochs + 1):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch.num_graphs\n    avg_train_loss = total_loss / len(train_loader.dataset)\n    # gather train metrics quickly (small dev size); run model eval on subset\n    model.eval()\n\n    def gather(loader):\n        all_seq, all_true, all_pred = [], [], []\n        with torch.no_grad():\n            for b in loader:\n                b = b.to(device)\n                o = model(b)\n                all_pred.extend(o.argmax(1).cpu().tolist())\n                all_true.extend(b.y.cpu().tolist())\n                all_seq.extend(b.seq)\n        return all_seq, all_true, all_pred\n\n    tr_seq, tr_true, tr_pred = gather(train_loader)\n    dv_seq, dv_true, dv_pred = gather(dev_loader)\n    train_cwa = color_weighted_accuracy(tr_seq, tr_true, tr_pred)\n    train_swa = shape_weighted_accuracy(tr_seq, tr_true, tr_pred)\n    train_cplx = complexity_weighted_accuracy(tr_seq, tr_true, tr_pred)\n    val_cwa = color_weighted_accuracy(dv_seq, dv_true, dv_pred)\n    val_swa = shape_weighted_accuracy(dv_seq, dv_true, dv_pred)\n    val_cplx = complexity_weighted_accuracy(dv_seq, dv_true, dv_pred)\n    val_loss = F.cross_entropy(\n        torch.tensor([], device=device), torch.tensor([], device=device)\n    )  # dummy init\n    # we already computed preds; recalc val loss separately\n    vtot = 0\n    for b in dev_loader:\n        b = b.to(device)\n        vtot += criterion(model(b), b.y).item() * b.num_graphs\n    val_loss = vtot / len(dev_loader.dataset)\n    print(\n        f\"Epoch {epoch}: validation_loss = {val_loss:.4f} | CWA {val_cwa:.3f} | SWA {val_swa:.3f} | CplxWA {val_cplx:.3f}\"\n    )\n    ed = experiment_data[\"spr_rgcn\"]\n    ed[\"losses\"][\"train\"].append(avg_train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"][\"CWA\"].append(train_cwa)\n    ed[\"metrics\"][\"train\"][\"SWA\"].append(train_swa)\n    ed[\"metrics\"][\"train\"][\"CplxWA\"].append(train_cplx)\n    ed[\"metrics\"][\"val\"][\"CWA\"].append(val_cwa)\n    ed[\"metrics\"][\"val\"][\"SWA\"].append(val_swa)\n    ed[\"metrics\"][\"val\"][\"CplxWA\"].append(val_cplx)\n    ed[\"epochs\"].append(epoch)\n\n# ---------- test evaluation ----------\ntest_loader = DataLoader(test_ds, batch_size=128, shuffle=False)\nts_seq, ts_true, ts_pred = gather(test_loader)\ntest_cwa = color_weighted_accuracy(ts_seq, ts_true, ts_pred)\ntest_swa = shape_weighted_accuracy(ts_seq, ts_true, ts_pred)\ntest_cplx = complexity_weighted_accuracy(ts_seq, ts_true, ts_pred)\nprint(f\"Test set --> CWA {test_cwa:.3f} | SWA {test_swa:.3f} | CplxWA {test_cplx:.3f}\")\nexperiment_data[\"spr_rgcn\"][\"metrics\"][\"test\"] = {\n    \"CWA\": test_cwa,\n    \"SWA\": test_swa,\n    \"CplxWA\": test_cplx,\n}\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\nfrom datasets import load_dataset\n\n# ---------- work dir & device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metric helpers ----------\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.strip().split() if tok))\n\n\ndef cwa(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_t, y_p)) / (sum(w) or 1)\n\n\ndef swa(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_t, y_p)) / (sum(w) or 1)\n\n\ndef cplxwa(seqs, y_t, y_p):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_t, y_p)) / (sum(w) or 1)\n\n\n# ---------- load dataset (real or synthetic) ----------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\n\n\ndef _load_csv(split_csv):\n    return load_dataset(\n        \"csv\",\n        data_files=str(spr_root / split_csv),\n        split=\"train\",\n        cache_dir=\".cache_dsets\",\n    )\n\n\nif spr_root.exists():\n    print(\"Loading real SPR_BENCH ...\")\n    raw_train, raw_dev, raw_test = [\n        _load_csv(f\"{sp}.csv\") for sp in (\"train\", \"dev\", \"test\")\n    ]\nelse:\n    print(\"SPR_BENCH not found. Generating synthetic toy data.\")\n\n    def make_synth(n):\n        shapes, colors = \"ABC\", \"123\"\n        seqs, labels = [], []\n        rng = np.random.default_rng(0)\n        for i in range(n):\n            length = rng.integers(4, 9)\n            seq = \" \".join(\n                rng.choice(list(shapes)) + rng.choice(list(colors))\n                for _ in range(length)\n            )\n            seqs.append(seq)\n            labels.append(rng.integers(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    raw_train, raw_dev, raw_test = map(make_synth, (600, 150, 300))\n\n# ---------- vocab ----------\nall_shapes, all_colors = set(), set()\nfor s in raw_train[\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nnum_shapes, num_colors = len(shape2idx), len(color2idx)\nnum_classes = len(set(raw_train[\"label\"]))\n\n\n# ---------- graph builder ----------\ndef seq_to_graph(seq, label):\n    toks = seq.strip().split()\n    n = len(toks)\n    x = torch.tensor(\n        [[shape2idx[t[0]], color2idx[t[1]]] for t in toks], dtype=torch.long\n    )\n    # edges: adjacency + same-shape + same-color\n    edges = set()\n    for i in range(n - 1):\n        edges.add((i, i + 1))\n        edges.add((i + 1, i))\n    for i in range(n):\n        for j in range(i + 1, n):\n            if toks[i][0] == toks[j][0] or toks[i][1] == toks[j][1]:\n                edges.add((i, j))\n                edges.add((j, i))\n    if edges:\n        ei = torch.tensor(list(zip(*edges)), dtype=torch.long)\n    else:\n        ei = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label], dtype=torch.long)\n    return Data(x=x, edge_index=ei, y=y, seq=seq)\n\n\ndef build_dataset(raw):\n    if isinstance(raw, dict):  # synthetic\n        return [seq_to_graph(s, l) for s, l in zip(raw[\"sequence\"], raw[\"label\"])]\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in raw]\n\n\ntrain_data, dev_data, test_data = map(build_dataset, (raw_train, raw_dev, raw_test))\n\n\n# ---------- model ----------\nclass SPRGNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, 8)\n        self.color_emb = nn.Embedding(num_colors, 8)\n        self.pre_lin = nn.Linear(16, 32)\n        self.conv1 = GraphConv(32, 64)\n        self.conv2 = GraphConv(64, 64)\n        self.classifier = nn.Linear(64, num_classes)\n\n    def forward(self, data):\n        x = torch.cat([self.shape_emb(data.x[:, 0]), self.color_emb(data.x[:, 1])], 1)\n        x = F.relu(self.pre_lin(x))\n        x = F.relu(self.conv1(x, data.edge_index))\n        x = F.relu(self.conv2(x, data.edge_index))\n        x = global_mean_pool(x, data.batch)\n        return self.classifier(x)\n\n\n# ---------- experiment data dict ----------\nexperiment_data = {\n    \"SPR\": {\n        \"metrics\": {\"train_cplxwa\": [], \"val_cplxwa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# ---------- training setup ----------\nbatch_size, epochs = 64, 3\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_data, batch_size=128, shuffle=False)\nmodel = SPRGNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------- training loop ----------\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running_loss = 0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch.num_graphs\n    avg_train_loss = running_loss / len(train_loader.dataset)\n    # compute train cplxwa quickly using a single pass (optional)\n    model.eval()\n    tr_seq, tr_true, tr_pred = [], [], []\n    with torch.no_grad():\n        for batch in train_loader:\n            batch = batch.to(device)\n            pr = model(batch).argmax(1).cpu().tolist()\n            tr_pred.extend(pr)\n            tr_true.extend(batch.y.cpu().tolist())\n            tr_seq.extend(batch.seq)\n    train_cplx = cplxwa(tr_seq, tr_true, tr_pred)\n    # validation\n    val_loss = 0\n    val_seq, val_true, val_pred = [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            val_loss += criterion(out, batch.y).item() * batch.num_graphs\n            val_pred.extend(out.argmax(1).cpu().tolist())\n            val_true.extend(batch.y.cpu().tolist())\n            val_seq.extend(batch.seq)\n    avg_val_loss = val_loss / len(dev_loader.dataset)\n    val_cplx = cplxwa(val_seq, val_true, val_pred)\n    # log\n    experiment_data[\"SPR\"][\"losses\"][\"train\"].append(avg_train_loss)\n    experiment_data[\"SPR\"][\"losses\"][\"val\"].append(avg_val_loss)\n    experiment_data[\"SPR\"][\"metrics\"][\"train_cplxwa\"].append(train_cplx)\n    experiment_data[\"SPR\"][\"metrics\"][\"val_cplxwa\"].append(val_cplx)\n    experiment_data[\"SPR\"][\"epochs\"].append(epoch)\n    print(\n        f\"Epoch {epoch}: train_loss={avg_train_loss:.4f} val_loss={avg_val_loss:.4f} \"\n        f\"train_CplxWA={train_cplx:.4f} val_CplxWA={val_cplx:.4f}\"\n    )\n\n# ---------- test evaluation ----------\ntest_loader = DataLoader(test_data, batch_size=128, shuffle=False)\nmodel.eval()\nts_seq, ts_true, ts_pred = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        out = model(batch)\n        ts_pred.extend(out.argmax(1).cpu().tolist())\n        ts_true.extend(batch.y.cpu().tolist())\n        ts_seq.extend(batch.seq)\ntest_cplx = cplxwa(ts_seq, ts_true, ts_pred)\ntest_cwa = cwa(ts_seq, ts_true, ts_pred)\ntest_swa = swa(ts_seq, ts_true, ts_pred)\nexperiment_data[\"SPR\"][\"predictions\"] = ts_pred\nexperiment_data[\"SPR\"][\"ground_truth\"] = ts_true\nexperiment_data[\"SPR\"][\"metrics\"][\"test_cplxwa\"] = test_cplx\nexperiment_data[\"SPR\"][\"metrics\"][\"test_cwa\"] = test_cwa\nexperiment_data[\"SPR\"][\"metrics\"][\"test_swa\"] = test_swa\nprint(f\"TEST  CplxWA={test_cplx:.4f}  CWA={test_cwa:.4f}  SWA={test_swa:.4f}\")\n\n# ---------- plots ----------\nepochs_list = experiment_data[\"SPR\"][\"epochs\"]\nplt.figure()\nplt.plot(epochs_list, experiment_data[\"SPR\"][\"losses\"][\"train\"], label=\"train\")\nplt.plot(epochs_list, experiment_data[\"SPR\"][\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.title(\"Loss curves\")\nplt.savefig(os.path.join(working_dir, \"loss_curves.png\"))\nplt.close()\n\nplt.figure()\nplt.plot(epochs_list, experiment_data[\"SPR\"][\"metrics\"][\"train_cplxwa\"], label=\"train\")\nplt.plot(epochs_list, experiment_data[\"SPR\"][\"metrics\"][\"val_cplxwa\"], label=\"val\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CplxWA\")\nplt.legend()\nplt.title(\"CplxWA curves\")\nplt.savefig(os.path.join(working_dir, \"cplxwa_curves.png\"))\nplt.close()\n\n# ---------- save experiment data ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Experiment data saved to ./working/experiment_data.npy\")\n", "import os, pathlib, numpy as np, torch, random, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom datetime import datetime\nfrom typing import List\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\n\n# ---------- working dir & device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- reproducibility ----------\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n\n# ---------- metric helpers ----------\ndef count_color_variety(seq: str) -> int:\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef color_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\ndef complexity_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\n# ---------- load data (real or synthetic) ----------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nif spr_root.exists():\n    from datasets import load_dataset\n\n    def _l(name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(spr_root / f\"{name}.csv\"),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    raw = {\"train\": _l(\"train\"), \"dev\": _l(\"dev\"), \"test\": _l(\"test\")}\n    print(\"Loaded real SPR_BENCH\")\nelse:\n    print(\"Dataset missing, generating synthetic.\")\n    shapes, colors = list(\"ABC\"), list(\"123\")\n\n    def synth(n):\n        seqs, labels = [], []\n        for i in range(n):\n            ln = np.random.randint(4, 8)\n            seqs.append(\n                \" \".join(\n                    np.random.choice(shapes) + np.random.choice(colors)\n                    for _ in range(ln)\n                )\n            )\n            labels.append(np.random.randint(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    raw = {\"train\": synth(800), \"dev\": synth(200), \"test\": synth(200)}\n\n# ---------- vocab ----------\nall_shapes = set()\nall_colors = set()\nfor s in raw[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel_set = sorted(set(raw[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nnum_shapes, len_shapes = len(shape2idx), len(shape2idx)\nnum_colors = len(color2idx)\nnum_class = len(label2idx)\n\n\n# ---------- graph builder ----------\ndef seq_to_graph(seq, label):\n    toks = seq.split()\n    n = len(toks)\n    sh = torch.tensor([shape2idx[t[0]] for t in toks])\n    col = torch.tensor([color2idx[t[1]] for t in toks])\n    x = torch.stack([sh, col], 1)  # [n,2]\n    edges_src = []\n    edges_dst = []\n    etype = []\n    # type 0: order edges\n    for i in range(n - 1):\n        edges_src.extend([i, i + 1])\n        edges_dst.extend([i + 1, i])\n        etype.extend([0, 0])\n    # type1: same color , type2: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if col[i] == col[j]:\n                edges_src.extend([i, j])\n                edges_dst.extend([j, i])\n                etype.extend([1, 1])\n            if sh[i] == sh[j]:\n                edges_src.extend([i, j])\n                edges_dst.extend([j, i])\n                etype.extend([2, 2])\n    edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, edge_type=edge_type, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    return [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n\n\ntrain_ds, dev_ds, test_ds = map(build_dataset, (raw[\"train\"], raw[\"dev\"], raw[\"test\"]))\n\n\n# ---------- model ----------\nclass SPR_RGCN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, 8)\n        self.color_emb = nn.Embedding(num_colors, 8)\n        self.lin = nn.Linear(16, 32)\n        self.conv1 = RGCNConv(32, 64, num_relations=3)\n        self.conv2 = RGCNConv(64, 64, num_relations=3)\n        self.cls = nn.Linear(64, num_class)\n\n    def forward(self, data):\n        x = torch.cat([self.shape_emb(data.x[:, 0]), self.color_emb(data.x[:, 1])], 1)\n        x = F.relu(self.lin(x))\n        x = F.relu(self.conv1(x, data.edge_index, data.edge_type))\n        x = F.relu(self.conv2(x, data.edge_index, data.edge_type))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\n# ---------- training setup ----------\nbatch_size = 64\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=128, shuffle=False)\nmodel = SPR_RGCN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\n            \"train\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n            \"val\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n        },\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# ---------- train loop ----------\nepochs = 10\nfor epoch in range(1, epochs + 1):\n    # ---- train ----\n    model.train()\n    running_loss = 0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch.num_graphs\n    tr_loss = running_loss / len(train_loader.dataset)\n    # metrics on train subset (single mini-batch to save time)\n    with torch.no_grad():\n        b = next(iter(train_loader)).to(device)\n        o = model(b).argmax(1).cpu().tolist()\n        gt = b.y.cpu().tolist()\n        seqs = b.seq\n        tr_cwa = color_weighted_accuracy(seqs, gt, o)\n        tr_swa = shape_weighted_accuracy(seqs, gt, o)\n        tr_cplx = complexity_weighted_accuracy(seqs, gt, o)\n    # ---- validation ----\n    model.eval()\n    val_loss = 0\n    val_seq = []\n    val_true = []\n    val_pred = []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            val_loss += criterion(out, batch.y).item() * batch.num_graphs\n            val_pred.extend(out.argmax(1).cpu().tolist())\n            val_true.extend(batch.y.cpu().tolist())\n            val_seq.extend(batch.seq)\n    val_loss /= len(dev_loader.dataset)\n    val_cwa = color_weighted_accuracy(val_seq, val_true, val_pred)\n    val_swa = shape_weighted_accuracy(val_seq, val_true, val_pred)\n    val_cplx = complexity_weighted_accuracy(val_seq, val_true, val_pred)\n    # ---- log ----\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"epochs\"].append(epoch)\n    ed[\"losses\"][\"train\"].append(tr_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"][\"CWA\"].append(tr_cwa)\n    ed[\"metrics\"][\"train\"][\"SWA\"].append(tr_swa)\n    ed[\"metrics\"][\"train\"][\"CplxWA\"].append(tr_cplx)\n    ed[\"metrics\"][\"val\"][\"CWA\"].append(val_cwa)\n    ed[\"metrics\"][\"val\"][\"SWA\"].append(val_swa)\n    ed[\"metrics\"][\"val\"][\"CplxWA\"].append(val_cplx)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}  CplxWA = {val_cplx:.4f}\")\n\n# ---------- test ----------\nmodel.eval()\ntest_seq = []\ntest_true = []\ntest_pred = []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        out = model(batch)\n        test_pred.extend(out.argmax(1).cpu().tolist())\n        test_true.extend(batch.y.cpu().tolist())\n        test_seq.extend(batch.seq)\ntest_cwa = color_weighted_accuracy(test_seq, test_true, test_pred)\ntest_swa = shape_weighted_accuracy(test_seq, test_true, test_pred)\ntest_cplx = complexity_weighted_accuracy(test_seq, test_true, test_pred)\ned[\"predictions\"] = test_pred\ned[\"ground_truth\"] = test_true\ned[\"metrics\"][\"test\"] = {\"CWA\": test_cwa, \"SWA\": test_swa, \"CplxWA\": test_cplx}\nprint(f\"Test CWA={test_cwa:.3f}  SWA={test_swa:.3f}  CplxWA={test_cplx:.3f}\")\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# ---------- quick plots ----------\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"train\"], label=\"train\")\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"val\"], label=\"val\")\nplt.legend()\nplt.title(\"Loss\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.savefig(os.path.join(working_dir, f\"loss_{ts}.png\"))\nplt.close()\n\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"metrics\"][\"val\"][\"CplxWA\"])\nplt.title(\"Validation CplxWA\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"CplxWA\")\nplt.savefig(os.path.join(working_dir, f\"cplxwa_{ts}.png\"))\nplt.close()\n", "import os, pathlib, random, math, numpy as np, torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nfrom datasets import load_dataset\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom typing import List\n\n# ------------------- mandatory working dir ----------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------- mandatory device print ---------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------- experiment data dict -----------------------------------\nexperiment_data = {\n    \"spr_bench\": {\n        \"metrics\": {\"train\": [], \"val\": [], \"test\": None},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n\n# ------------------- helper: metrics ----------------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    seqs: List[str], y_true: List[int], y_pred: List[int]\n) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    num = sum(w for w, t, p in zip(weights, y_true, y_pred) if t == p)\n    den = max(sum(weights), 1)\n    return num / den\n\n\n# ------------------- dataset resolver ---------------------------------------\nPOSSIBLE_PATHS = [\n    os.getenv(\"SPR_BENCH_PATH\", \"\"),\n    \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    \"./SPR_BENCH\",\n]\nspr_root = None\nfor p in POSSIBLE_PATHS:\n    if p and pathlib.Path(p).expanduser().exists():\n        spr_root = pathlib.Path(p).expanduser()\n        break\n\nif spr_root:\n    print(f\"Loading real SPR_BENCH from {spr_root}\")\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(spr_root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    raw_dsets = {sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]}\nelse:\n    print(\"Real SPR_BENCH not found \u2013 generating *rule-based* synthetic data.\")\n\n    shapes, colors = [\"A\", \"B\", \"C\", \"D\"], [\"1\", \"2\", \"3\", \"4\"]\n\n    def gen_rule_based(n):\n        seqs, labels = [], []\n        for i in range(n):\n            ln = random.randint(4, 8)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(ln)\n            )\n            # RULE: label is the index of the *most common shape* in the sequence\n            shape_cnt = {s: seq.split().count(s + c) for s in shapes for c in colors}\n            majority_shape = max(\n                shapes, key=lambda s: sum(shape_cnt[s + c] for c in colors)\n            )\n            label = shapes.index(majority_shape)\n            seqs.append(seq)\n            labels.append(label)\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    raw_dsets = {\n        \"train\": gen_rule_based(4000),\n        \"dev\": gen_rule_based(1000),\n        \"test\": gen_rule_based(1000),\n    }\n\n# ------------------- vocabulary ---------------------------------------------\nall_shapes, all_colors = set(), set()\nfor s in raw_dsets[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel_set = sorted(set(raw_dsets[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nnum_shapes, num_colors, num_classes = len(shape2idx), len(color2idx), len(label2idx)\n\n\n# ------------------- graph builder ------------------------------------------\ndef seq_to_graph(seq: str, label: int) -> Data:\n    toks = seq.strip().split()\n    n = len(toks)\n    x = torch.tensor(\n        [[shape2idx[t[0]], color2idx[t[1]]] for t in toks], dtype=torch.long\n    )\n    edges_src, edges_dst, e_types = [], [], []\n\n    # relation 0: sequential neighbours (bidirectional)\n    for i in range(n - 1):\n        edges_src += [i, i + 1]\n        edges_dst += [i + 1, i]\n        e_types += [0, 0]\n    # relation 1: same color\n    col_map = {}\n    for idx, t in enumerate(toks):\n        col_map.setdefault(t[1], []).append(idx)\n    for nodes in col_map.values():\n        for i in nodes:\n            for j in nodes:\n                if i != j:\n                    edges_src.append(i)\n                    edges_dst.append(j)\n                    e_types.append(1)\n    # relation 2: same shape\n    shp_map = {}\n    for idx, t in enumerate(toks):\n        shp_map.setdefault(t[0], []).append(idx)\n    for nodes in shp_map.values():\n        for i in nodes:\n            for j in nodes:\n                if i != j:\n                    edges_src.append(i)\n                    edges_dst.append(j)\n                    e_types.append(2)\n\n    edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long)\n    edge_type = torch.tensor(e_types, dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, edge_type=edge_type, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    if isinstance(split, dict):  # synthetic dict\n        seqs, labels = split[\"sequence\"], split[\"label\"]\n    else:  # HF Dataset\n        seqs, labels = split[\"sequence\"], split[\"label\"]\n    return [seq_to_graph(s, l) for s, l in zip(seqs, labels)]\n\n\ntrain_ds, dev_ds, test_ds = map(\n    build_dataset, (raw_dsets[\"train\"], raw_dsets[\"dev\"], raw_dsets[\"test\"])\n)\n\n\n# ------------------- model ---------------------------------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self, emb_dim=16, hidden=64, num_relations=3):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, emb_dim // 2)\n        self.color_emb = nn.Embedding(num_colors, emb_dim // 2)\n        self.lin0 = nn.Linear(emb_dim, hidden)\n        self.rgcn1 = RGCNConv(hidden, hidden, num_relations)\n        self.rgcn2 = RGCNConv(hidden, hidden, num_relations)\n        self.cls = nn.Linear(hidden, num_classes)\n\n    def forward(self, data):\n        s_e = self.shape_emb(data.x[:, 0])\n        c_e = self.color_emb(data.x[:, 1])\n        x = torch.cat([s_e, c_e], 1)\n        x = F.relu(self.lin0(x))\n        x = F.relu(self.rgcn1(x, data.edge_index, data.edge_type))\n        x = F.relu(self.rgcn2(x, data.edge_index, data.edge_type))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\nmodel = SPR_RGCN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ------------------- loaders -------------------------------------------------\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=128)\ntest_loader = DataLoader(test_ds, batch_size=128)\n\n# ------------------- training ------------------------------------------------\nepochs = 10\nfor epoch in range(1, epochs + 1):\n    model.train()\n    train_loss = 0.0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * batch.num_graphs\n    avg_train_loss = train_loss / len(train_loader.dataset)\n\n    # validation\n    model.eval()\n    val_loss, v_seqs, v_true, v_pred = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            l = criterion(out, batch.y)\n            val_loss += l.item() * batch.num_graphs\n            preds = out.argmax(1).cpu().tolist()\n            v_pred.extend(preds)\n            v_true.extend(batch.y.cpu().tolist())\n            v_seqs.extend(batch.seq)\n    avg_val_loss = val_loss / len(dev_loader.dataset)\n    val_cplx = complexity_weighted_accuracy(v_seqs, v_true, v_pred)\n\n    print(\n        f\"Epoch {epoch}: validation_loss = {avg_val_loss:.4f}, Val CplxWA = {val_cplx:.4f}\"\n    )\n\n    # log\n    ed = experiment_data[\"spr_bench\"]\n    ed[\"losses\"][\"train\"].append(avg_train_loss)\n    ed[\"losses\"][\"val\"].append(avg_val_loss)\n    ed[\"metrics\"][\"val\"].append(val_cplx)\n    ed[\"epochs\"].append(epoch)\n\n# ------------------- testing -------------------------------------------------\nmodel.eval()\nt_seqs, t_true, t_pred = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        out = model(batch)\n        preds = out.argmax(1).cpu().tolist()\n        t_pred.extend(preds)\n        t_true.extend(batch.y.cpu().tolist())\n        t_seqs.extend(batch.seq)\ntest_cplx = complexity_weighted_accuracy(t_seqs, t_true, t_pred)\nprint(f\"Test Complexity-Weighted Accuracy: {test_cplx:.4f}\")\n\nexperiment_data[\"spr_bench\"][\"metrics\"][\"test\"] = test_cplx\nexperiment_data[\"spr_bench\"][\"predictions\"] = t_pred\nexperiment_data[\"spr_bench\"][\"ground_truth\"] = t_true\n\n# ------------------- plots ---------------------------------------------------\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nplt.figure()\nplt.plot(\n    experiment_data[\"spr_bench\"][\"epochs\"],\n    experiment_data[\"spr_bench\"][\"losses\"][\"train\"],\n    label=\"train\",\n)\nplt.plot(\n    experiment_data[\"spr_bench\"][\"epochs\"],\n    experiment_data[\"spr_bench\"][\"losses\"][\"val\"],\n    label=\"val\",\n)\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.legend()\nplt.title(\"Loss curve\")\nplt.savefig(os.path.join(working_dir, f\"loss_{ts}.png\"))\nplt.close()\n\nplt.figure()\nplt.plot(\n    experiment_data[\"spr_bench\"][\"epochs\"],\n    experiment_data[\"spr_bench\"][\"metrics\"][\"val\"],\n)\nplt.xlabel(\"epoch\")\nplt.ylabel(\"CplxWA\")\nplt.title(\"Validation CplxWA\")\nplt.savefig(os.path.join(working_dir, f\"cplxwa_{ts}.png\"))\nplt.close()\n\n# ------------------- save artefacts -----------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Experiment data saved to ./working/experiment_data.npy\")\n", "import os, pathlib, random, numpy as np, torch, matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom typing import List, Dict\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\n\n# ------------------- working dir -------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------- device ------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------- seeds -------------------------\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n\n# ------------------- metrics -----------------------\ndef count_color_variety(seq: str) -> int:\n    return len({tok[1] for tok in seq.strip().split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len({tok[0] for tok in seq.strip().split() if tok})\n\n\ndef color_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\ndef complexity_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\n# ------------------- data loading ------------------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nhave_real = spr_root.exists()\n\n\ndef load_real(name):\n    from datasets import load_dataset\n\n    return load_dataset(\n        \"csv\",\n        data_files=str(spr_root / f\"{name}.csv\"),\n        split=\"train\",\n        cache_dir=\".cache_dsets\",\n    )\n\n\ndef synth_rule_based(n: int) -> Dict[str, List]:\n    \"\"\"Generate sequences + rule-based label:\n    label 0: uniq_shapes  >  uniq_colors\n    label 1: uniq_shapes == uniq_colors\n    label 2: uniq_shapes  <  uniq_colors\n    \"\"\"\n    shapes = list(\"ABCD\")\n    colors = list(\"1234\")\n    seqs, labels = [], []\n    for i in range(n):\n        ln = np.random.randint(4, 9)\n        tokens = [random.choice(shapes) + random.choice(colors) for _ in range(ln)]\n        seq = \" \".join(tokens)\n        s_var = count_shape_variety(seq)\n        c_var = count_color_variety(seq)\n        if s_var > c_var:\n            lab = 0\n        elif s_var == c_var:\n            lab = 1\n        else:\n            lab = 2\n        seqs.append(seq)\n        labels.append(lab)\n    return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n\nif have_real:\n    raw = {\n        \"train\": load_real(\"train\"),\n        \"dev\": load_real(\"dev\"),\n        \"test\": load_real(\"test\"),\n    }\n    print(\"Loaded real SPR_BENCH dataset.\")\nelse:\n    print(\"SPR_BENCH folder not found \u2013 synthesising rule-based data.\")\n    raw = {\n        \"train\": synth_rule_based(8000),\n        \"dev\": synth_rule_based(2000),\n        \"test\": synth_rule_based(2000),\n    }\n\n# ------------------- vocab building ----------------\nall_shapes, all_colors = set(), set()\nfor s in raw[\"train\"][\"sequence\"] if not have_real else raw[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\n\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nnum_shapes, num_colors = len(shape2idx), len(color2idx)\n\nlabel_set = sorted(\n    set(raw[\"train\"][\"label\"] if not have_real else raw[\"train\"][\"label\"])\n)\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nnum_class = len(label2idx)\n\n\n# ------------------- graph builder -----------------\ndef seq_to_graph(seq: str, label: int) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    sh = torch.tensor([shape2idx[t[0]] for t in toks], dtype=torch.long)\n    col = torch.tensor([color2idx[t[1]] for t in toks], dtype=torch.long)\n    x = torch.stack([sh, col], 1)  # [n, 2]\n\n    edges_src, edges_dst, etype = [], [], []\n\n    # 0: order edges (i -> i+1)\n    for i in range(n - 1):\n        edges_src += [i, i + 1]\n        edges_dst += [i + 1, i]\n        etype += [0, 0]\n\n    # 1: same color, 2: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if int(col[i]) == int(col[j]):\n                edges_src += [i, j]\n                edges_dst += [j, i]\n                etype += [1, 1]\n            if int(sh[i]) == int(sh[j]):\n                edges_src += [i, j]\n                edges_dst += [j, i]\n                etype += [2, 2]\n\n    edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, edge_type=edge_type, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    if have_real:\n        return [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n    return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n\n\ntrain_ds, dev_ds, test_ds = map(build_dataset, (raw[\"train\"], raw[\"dev\"], raw[\"test\"]))\n\n\n# ------------------- model -------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, 8)\n        self.color_emb = nn.Embedding(num_colors, 8)\n        self.pre = nn.Linear(16, 32)\n        self.conv1 = RGCNConv(32, 64, num_relations=3)\n        self.conv2 = RGCNConv(64, 64, num_relations=3)\n        self.cls = nn.Linear(64, num_class)\n\n    def forward(self, data):\n        sx = self.shape_emb(data.x[:, 0])\n        cx = self.color_emb(data.x[:, 1])\n        x = torch.cat([sx, cx], 1)\n        x = F.relu(self.pre(x))\n        x = F.relu(self.conv1(x, data.edge_index, data.edge_type))\n        x = F.relu(self.conv2(x, data.edge_index, data.edge_type))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\nmodel = SPR_RGCN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\n# ------------------- loaders -----------------------\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=128, shuffle=False)\n\n# ------------------- tracking struct ---------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\n            \"train\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n            \"val\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n        },\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ------------------- training loop -----------------\nepochs = 10\nfor epoch in range(1, epochs + 1):\n    # ---- training ----\n    model.train()\n    run_loss = 0.0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        run_loss += loss.item() * batch.num_graphs\n    tr_loss = run_loss / len(train_loader.dataset)\n\n    # compute train metrics on full set (cheap enough)\n    model.eval()\n    tr_seq, tr_true, tr_pred = [], [], []\n    with torch.no_grad():\n        for batch in train_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            tr_pred.extend(out.argmax(1).cpu().tolist())\n            tr_true.extend(batch.y.cpu().tolist())\n            tr_seq.extend(batch.seq)\n    tr_cwa = color_weighted_accuracy(tr_seq, tr_true, tr_pred)\n    tr_swa = shape_weighted_accuracy(tr_seq, tr_true, tr_pred)\n    tr_cplx = complexity_weighted_accuracy(tr_seq, tr_true, tr_pred)\n\n    # ---- validation ----\n    val_loss, v_seq, v_true, v_pred = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            val_loss += criterion(out, batch.y).item() * batch.num_graphs\n            v_pred.extend(out.argmax(1).cpu().tolist())\n            v_true.extend(batch.y.cpu().tolist())\n            v_seq.extend(batch.seq)\n    val_loss /= len(dev_loader.dataset)\n    val_cwa = color_weighted_accuracy(v_seq, v_true, v_pred)\n    val_swa = shape_weighted_accuracy(v_seq, v_true, v_pred)\n    val_cplx = complexity_weighted_accuracy(v_seq, v_true, v_pred)\n\n    # ---- logging ----\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"epochs\"].append(epoch)\n    ed[\"losses\"][\"train\"].append(tr_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"][\"CWA\"].append(tr_cwa)\n    ed[\"metrics\"][\"train\"][\"SWA\"].append(tr_swa)\n    ed[\"metrics\"][\"train\"][\"CplxWA\"].append(tr_cplx)\n    ed[\"metrics\"][\"val\"][\"CWA\"].append(val_cwa)\n    ed[\"metrics\"][\"val\"][\"SWA\"].append(val_swa)\n    ed[\"metrics\"][\"val\"][\"CplxWA\"].append(val_cplx)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}  CplxWA = {val_cplx:.4f}\")\n\n# ------------------- test evaluation ----------------\nmodel.eval()\nt_seq, t_true, t_pred = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        out = model(batch)\n        t_pred.extend(out.argmax(1).cpu().tolist())\n        t_true.extend(batch.y.cpu().tolist())\n        t_seq.extend(batch.seq)\n\ntest_cwa = color_weighted_accuracy(t_seq, t_true, t_pred)\ntest_swa = shape_weighted_accuracy(t_seq, t_true, t_pred)\ntest_cplx = complexity_weighted_accuracy(t_seq, t_true, t_pred)\nprint(f\"Test CWA={test_cwa:.3f}  SWA={test_swa:.3f}  CplxWA={test_cplx:.3f}\")\n\ned[\"predictions\"] = t_pred\ned[\"ground_truth\"] = t_true\ned[\"metrics\"][\"test\"] = {\"CWA\": test_cwa, \"SWA\": test_swa, \"CplxWA\": test_cplx}\n\n# ------------------- save results ------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# ------------------- quick plots -------------------\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"train\"], label=\"train\")\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.title(\"Loss\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, f\"loss_{ts}.png\"))\nplt.close()\n\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"metrics\"][\"val\"][\"CplxWA\"])\nplt.xlabel(\"epoch\")\nplt.ylabel(\"CplxWA\")\nplt.title(\"Validation CplxWA\")\nplt.savefig(os.path.join(working_dir, f\"cplxwa_{ts}.png\"))\nplt.close()\n", "import os, pathlib, numpy as np, torch, random, itertools\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nfrom datasets import load_dataset\nfrom datetime import datetime\n\n# ---------- working dir and device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- reproducibility ----------\ntorch.manual_seed(0)\nnp.random.seed(0)\nrandom.seed(0)\n\n\n# ---------- helpers ----------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / (sum(weights) or 1.0)\n\n\n# ---------- dataset load (real or synthetic) ----------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\n\n\ndef load_csv(csv_name):\n    return load_dataset(\n        \"csv\",\n        data_files=str(spr_root / csv_name),\n        split=\"train\",\n        cache_dir=\".cache_dsets\",\n    )\n\n\nif spr_root.exists():\n    print(\"Loading real SPR_BENCH from\", spr_root)\n    raw_train, raw_dev, raw_test = map(load_csv, [\"train.csv\", \"dev.csv\", \"test.csv\"])\nelse:\n    print(\"SPR_BENCH not found. Building tiny synthetic fallback.\")\n\n    def make_synth(n):\n        shapes, colors = [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        seqs, labels = [], []\n        for i in range(n):\n            length = np.random.randint(4, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            seqs.append(seq)\n            labels.append(np.random.randint(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    raw_train, raw_dev, raw_test = map(make_synth, [600, 150, 150])\n\n# ---------- vocab ----------\nall_shapes, all_colors = set(), set()\nfor s in raw_train[\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel2idx = {l: i for i, l in enumerate(sorted(set(raw_train[\"label\"])))}\nnum_shapes, num_colors, num_classes = len(shape2idx), len(color2idx), len(label2idx)\n\n\n# ---------- sequence \u2192 graph ----------\ndef seq_to_graph(seq: str, label: int):\n    toks = seq.split()\n    n = len(toks)\n    x_np = np.array([[shape2idx[t[0]], color2idx[t[1]]] for t in toks], dtype=np.int64)\n    edge_src, edge_dst, edge_types = [], [], []\n    # type 0: adjacent position edges\n    for i in range(n - 1):\n        edge_src += [i, i + 1]\n        edge_dst += [i + 1, i]\n        edge_types += [0, 0]\n    # type 1: same shape edges\n    shape_map = {}\n    for i, t in enumerate(toks):\n        shape_map.setdefault(t[0], []).append(i)\n    for idxs in shape_map.values():\n        for i, j in itertools.combinations(idxs, 2):\n            edge_src += [i, j]\n            edge_dst += [j, i]\n            edge_types += [1, 1]\n    # type 2: same color edges\n    color_map = {}\n    for i, t in enumerate(toks):\n        color_map.setdefault(t[1], []).append(i)\n    for idxs in color_map.values():\n        for i, j in itertools.combinations(idxs, 2):\n            edge_src += [i, j]\n            edge_dst += [j, i]\n            edge_types += [2, 2]\n    edge_index = torch.tensor([edge_src, edge_dst], dtype=torch.long)\n    edge_type = torch.tensor(edge_types, dtype=torch.long)\n    data = Data(\n        x=torch.tensor(x_np),\n        edge_index=edge_index,\n        edge_type=edge_type,\n        y=torch.tensor([label2idx[label]]),\n        seq=seq,\n    )\n    return data\n\n\ndef build_dataset(raw_split):\n    return [\n        seq_to_graph(s, l) for s, l in zip(raw_split[\"sequence\"], raw_split[\"label\"])\n    ]\n\n\ntrain_set, dev_set, test_set = map(build_dataset, [raw_train, raw_dev, raw_test])\n\n\n# ---------- model ----------\nclass SPR_RGCN(nn.Module):\n    def __init__(self, hid=64):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, 8)\n        self.color_emb = nn.Embedding(num_colors, 8)\n        self.lin0 = nn.Linear(16, hid)\n        self.rgcn1 = RGCNConv(hid, hid, num_relations=3)\n        self.rgcn2 = RGCNConv(hid, hid, num_relations=3)\n        self.classifier = nn.Linear(hid, num_classes)\n\n    def forward(self, batch):\n        s_emb = self.shape_emb(batch.x[:, 0])\n        c_emb = self.color_emb(batch.x[:, 1])\n        x = torch.cat([s_emb, c_emb], dim=1)\n        x = F.relu(self.lin0(x))\n        x = F.relu(self.rgcn1(x, batch.edge_index, batch.edge_type))\n        x = F.relu(self.rgcn2(x, batch.edge_index, batch.edge_type))\n        x = global_mean_pool(x, batch.batch)\n        return self.classifier(x)\n\n\n# ---------- training config ----------\nBATCH_SIZE = 64\nEPOCHS = 6\nexperiment_data = {\n    \"spr_rgcn\": {\n        \"metrics\": {\"train_compwa\": [], \"val_compwa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\ndev_loader = DataLoader(dev_set, batch_size=128, shuffle=False)\ntest_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n\nmodel = SPR_RGCN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\n# ---------- train / validate ----------\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    total_loss = 0.0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch.num_graphs\n    avg_train_loss = total_loss / len(train_loader.dataset)\n\n    # validation\n    model.eval()\n    val_loss, seqs, preds, gts = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            l = criterion(out, batch.y)\n            val_loss += l.item() * batch.num_graphs\n            preds += out.argmax(1).cpu().tolist()\n            gts += batch.y.cpu().tolist()\n            seqs += batch.seq\n    avg_val_loss = val_loss / len(dev_loader.dataset)\n    val_compwa = complexity_weighted_accuracy(seqs, gts, preds)\n\n    # log\n    ed = experiment_data[\"spr_rgcn\"]\n    ed[\"losses\"][\"train\"].append(avg_train_loss)\n    ed[\"losses\"][\"val\"].append(avg_val_loss)\n    ed[\"metrics\"][\"val_compwa\"].append(val_compwa)\n    ed[\"epochs\"].append(epoch)\n    print(\n        f\"Epoch {epoch}: train_loss={avg_train_loss:.4f} val_loss={avg_val_loss:.4f} Val_CplxWA={val_compwa:.4f}\"\n    )\n\n# ---------- test ----------\nmodel.eval()\nseqs, preds, gts = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        out = model(batch)\n        preds += out.argmax(1).cpu().tolist()\n        gts += batch.y.cpu().tolist()\n        seqs += batch.seq\ntest_compwa = complexity_weighted_accuracy(seqs, gts, preds)\nexperiment_data[\"spr_rgcn\"][\"predictions\"] = preds\nexperiment_data[\"spr_rgcn\"][\"ground_truth\"] = gts\nexperiment_data[\"spr_rgcn\"][\"metrics\"][\"test_compwa\"] = test_compwa\nprint(f\"Test Complexity-Weighted Accuracy: {test_compwa:.4f}\")\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, numpy as np, torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\nfrom typing import List, Dict\nfrom datasets import load_dataset\n\n# ---------- work dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- helpers -----------\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    seqs: List[str], y_true: List[int], y_pred: List[int]\n) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    corr = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(corr) / (sum(weights) if sum(weights) else 1)\n\n\n# ---------- load data ----------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\n\n\ndef _load_csv(name):  # helper\n    return load_dataset(\n        \"csv\",\n        data_files=str(spr_root / f\"{name}.csv\"),\n        split=\"train\",\n        cache_dir=\".cache_dsets\",\n    )\n\n\nif spr_root.exists():\n    dsets = {split: _load_csv(split) for split in [\"train\", \"dev\", \"test\"]}\nelse:\n    print(\"!! SPR_BENCH not found \u2013 creating tiny synthetic set for demo.\")\n\n    def synth(n):\n        shapes, colors = list(\"ABC\"), list(\"123\")\n        seqs, labels = [], []\n        for _ in range(n):\n            L = np.random.randint(4, 9)\n            seqs.append(\n                \" \".join(\n                    np.random.choice(shapes) + np.random.choice(colors)\n                    for _ in range(L)\n                )\n            )\n            labels.append(np.random.randint(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    dsets = {\"train\": synth(600), \"dev\": synth(200), \"test\": synth(200)}\n\n# ---------- vocab ----------\nall_shapes, all_colors = set(), set()\nfor s in dsets[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nnum_shapes, num_colors = len(shape2idx), len(color2idx)\nnum_classes = len(set(dsets[\"train\"][\"label\"]))\n\n\n# ---------- graph builder -----\ndef seq_to_graph(seq: str, label: int) -> Data:\n    toks = seq.strip().split()\n    n = len(toks)\n    shp_idx = [shape2idx[t[0]] for t in toks]\n    col_idx = [color2idx[t[1]] for t in toks]\n    x = torch.tensor(np.stack([shp_idx, col_idx], 1), dtype=torch.long)\n\n    # relation 0: adjacency\n    src_adj = list(range(n - 1))\n    dst_adj = list(range(1, n))\n    edges_0 = [(s, d) for s, d in zip(src_adj, dst_adj)] + [\n        (d, s) for s, d in zip(src_adj, dst_adj)\n    ]\n    # relation 1: same color\n    edges_1 = []\n    for c in set(col_idx):\n        inds = [i for i, ci in enumerate(col_idx) if ci == c]\n        edges_1 += [(i, j) for i in inds for j in inds if i != j]\n    # relation 2: same shape\n    edges_2 = []\n    for sh in set(shp_idx):\n        inds = [i for i, si in enumerate(shp_idx) if si == sh]\n        edges_2 += [(i, j) for i in inds for j in inds if i != j]\n\n    all_edges, rel_types = [], []\n    for rel, e_list in enumerate([edges_0, edges_1, edges_2]):\n        all_edges += e_list\n        rel_types += [rel] * len(e_list)\n\n    if len(all_edges) == 0:  # single-node graph fallback\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n        edge_type = torch.zeros((0,), dtype=torch.long)\n    else:\n        edge_index = torch.tensor(np.array(all_edges).T, dtype=torch.long)\n        edge_type = torch.tensor(rel_types, dtype=torch.long)\n\n    y = torch.tensor([label], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, edge_type=edge_type, y=y, seq=seq)\n\n\ndef build_dataset(split) -> List[Data]:\n    return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n\n\ntrain_data, dev_data, test_data = map(\n    build_dataset, (dsets[\"train\"], dsets[\"dev\"], dsets[\"test\"])\n)\n\n\n# ---------- model --------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, 8)\n        self.color_emb = nn.Embedding(num_colors, 8)\n        self.pre_lin = nn.Linear(16, 32)\n        self.rgcn1 = RGCNConv(32, 64, num_relations=3)\n        self.rgcn2 = RGCNConv(64, 64, num_relations=3)\n        self.cls = nn.Linear(64, num_classes)\n\n    def forward(self, data: Data):\n        x = torch.cat(\n            [self.shape_emb(data.x[:, 0]), self.color_emb(data.x[:, 1])], dim=1\n        )\n        x = F.relu(self.pre_lin(x))\n        x = F.relu(self.rgcn1(x, data.edge_index, data.edge_type))\n        x = F.relu(self.rgcn2(x, data.edge_index, data.edge_type))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\n# ---------- experiment storage ---\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_cplxwa\": [], \"val_cplxwa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# ---------- training -------------\nbatch_size = 64\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_data, batch_size=256, shuffle=False)\nmodel = SPR_RGCN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\nepochs = 8\nfor epoch in range(1, epochs + 1):\n    # train\n    model.train()\n    tot_loss = 0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch.num_graphs\n    avg_train_loss = tot_loss / len(train_loader.dataset)\n\n    # evaluate on train set for metric\n    model.eval()\n    with torch.no_grad():\n        all_seq_t, all_true_t, all_pred_t = [], [], []\n        for batch in train_loader:\n            batch = batch.to(device)\n            pred = model(batch).argmax(1).cpu().tolist()\n            tru = batch.y.cpu().tolist()\n            all_pred_t.extend(pred)\n            all_true_t.extend(tru)\n            all_seq_t.extend(batch.seq)\n        train_cplx = complexity_weighted_accuracy(all_seq_t, all_true_t, all_pred_t)\n\n    # dev\n    val_loss = 0\n    all_seq, all_true, all_pred = [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            val_loss += criterion(out, batch.y).item() * batch.num_graphs\n            all_pred.extend(out.argmax(1).cpu().tolist())\n            all_true.extend(batch.y.cpu().tolist())\n            all_seq.extend(batch.seq)\n    avg_val_loss = val_loss / len(dev_loader.dataset)\n    val_cplx = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n\n    # store\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(avg_train_loss)\n    ed[\"losses\"][\"val\"].append(avg_val_loss)\n    ed[\"metrics\"][\"train_cplxwa\"].append(train_cplx)\n    ed[\"metrics\"][\"val_cplxwa\"].append(val_cplx)\n    ed[\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch}: train_loss={avg_train_loss:.4f} val_loss={avg_val_loss:.4f} \"\n        f\"train_CplxWA={train_cplx:.4f} val_CplxWA={val_cplx:.4f}\"\n    )\n\n# ---------- test -----------------\ntest_loader = DataLoader(test_data, batch_size=256, shuffle=False)\nmodel.eval()\nall_seq, all_true, all_pred = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        pr = model(batch).argmax(1).cpu().tolist()\n        all_pred.extend(pr)\n        all_true.extend(batch.y.cpu().tolist())\n        all_seq.extend(batch.seq)\ntest_cplx = complexity_weighted_accuracy(all_seq, all_true, all_pred)\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = all_pred\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_true\nexperiment_data[\"SPR_BENCH\"][\"metrics\"][\"test_cplxwa\"] = test_cplx\nprint(f\"Test Complexity-Weighted Accuracy: {test_cplx:.4f}\")\n\n# ---------- save -----------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, numpy as np, torch, matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom typing import List, Dict\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\n\n# ------------------- working dir -------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------- device ------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------- seeds -------------------------\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n\n# ------------------- metrics -----------------------\ndef count_color_variety(seq: str) -> int:\n    return len({tok[1] for tok in seq.strip().split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len({tok[0] for tok in seq.strip().split() if tok})\n\n\ndef color_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\ndef complexity_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\n# ------------------- data loading ------------------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nhave_real = spr_root.exists()\n\n\ndef load_real(name):\n    from datasets import load_dataset\n\n    return load_dataset(\n        \"csv\",\n        data_files=str(spr_root / f\"{name}.csv\"),\n        split=\"train\",\n        cache_dir=\".cache_dsets\",\n    )\n\n\ndef synth_rule_based(n: int) -> Dict[str, List]:\n    \"\"\"Generate sequences + rule-based label:\n    label 0: uniq_shapes  >  uniq_colors\n    label 1: uniq_shapes == uniq_colors\n    label 2: uniq_shapes  <  uniq_colors\n    \"\"\"\n    shapes = list(\"ABCD\")\n    colors = list(\"1234\")\n    seqs, labels = [], []\n    for i in range(n):\n        ln = np.random.randint(4, 9)\n        tokens = [random.choice(shapes) + random.choice(colors) for _ in range(ln)]\n        seq = \" \".join(tokens)\n        s_var = count_shape_variety(seq)\n        c_var = count_color_variety(seq)\n        if s_var > c_var:\n            lab = 0\n        elif s_var == c_var:\n            lab = 1\n        else:\n            lab = 2\n        seqs.append(seq)\n        labels.append(lab)\n    return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n\nif have_real:\n    raw = {\n        \"train\": load_real(\"train\"),\n        \"dev\": load_real(\"dev\"),\n        \"test\": load_real(\"test\"),\n    }\n    print(\"Loaded real SPR_BENCH dataset.\")\nelse:\n    print(\"SPR_BENCH folder not found \u2013 synthesising rule-based data.\")\n    raw = {\n        \"train\": synth_rule_based(8000),\n        \"dev\": synth_rule_based(2000),\n        \"test\": synth_rule_based(2000),\n    }\n\n# ------------------- vocab building ----------------\nall_shapes, all_colors = set(), set()\nfor s in raw[\"train\"][\"sequence\"] if not have_real else raw[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\n\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nnum_shapes, num_colors = len(shape2idx), len(color2idx)\n\nlabel_set = sorted(\n    set(raw[\"train\"][\"label\"] if not have_real else raw[\"train\"][\"label\"])\n)\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nnum_class = len(label2idx)\n\n\n# ------------------- graph builder -----------------\ndef seq_to_graph(seq: str, label: int) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    sh = torch.tensor([shape2idx[t[0]] for t in toks], dtype=torch.long)\n    col = torch.tensor([color2idx[t[1]] for t in toks], dtype=torch.long)\n    x = torch.stack([sh, col], 1)  # [n, 2]\n\n    edges_src, edges_dst, etype = [], [], []\n\n    # 0: order edges (i -> i+1)\n    for i in range(n - 1):\n        edges_src += [i, i + 1]\n        edges_dst += [i + 1, i]\n        etype += [0, 0]\n\n    # 1: same color, 2: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if int(col[i]) == int(col[j]):\n                edges_src += [i, j]\n                edges_dst += [j, i]\n                etype += [1, 1]\n            if int(sh[i]) == int(sh[j]):\n                edges_src += [i, j]\n                edges_dst += [j, i]\n                etype += [2, 2]\n\n    edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, edge_type=edge_type, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    if have_real:\n        return [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n    return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n\n\ntrain_ds, dev_ds, test_ds = map(build_dataset, (raw[\"train\"], raw[\"dev\"], raw[\"test\"]))\n\n\n# ------------------- model -------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, 8)\n        self.color_emb = nn.Embedding(num_colors, 8)\n        self.pre = nn.Linear(16, 32)\n        self.conv1 = RGCNConv(32, 64, num_relations=3)\n        self.conv2 = RGCNConv(64, 64, num_relations=3)\n        self.cls = nn.Linear(64, num_class)\n\n    def forward(self, data):\n        sx = self.shape_emb(data.x[:, 0])\n        cx = self.color_emb(data.x[:, 1])\n        x = torch.cat([sx, cx], 1)\n        x = F.relu(self.pre(x))\n        x = F.relu(self.conv1(x, data.edge_index, data.edge_type))\n        x = F.relu(self.conv2(x, data.edge_index, data.edge_type))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\nmodel = SPR_RGCN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\n# ------------------- loaders -----------------------\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=128, shuffle=False)\n\n# ------------------- tracking struct ---------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\n            \"train\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n            \"val\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n        },\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ------------------- training loop -----------------\nepochs = 10\nfor epoch in range(1, epochs + 1):\n    # ---- training ----\n    model.train()\n    run_loss = 0.0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        run_loss += loss.item() * batch.num_graphs\n    tr_loss = run_loss / len(train_loader.dataset)\n\n    # compute train metrics on full set (cheap enough)\n    model.eval()\n    tr_seq, tr_true, tr_pred = [], [], []\n    with torch.no_grad():\n        for batch in train_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            tr_pred.extend(out.argmax(1).cpu().tolist())\n            tr_true.extend(batch.y.cpu().tolist())\n            tr_seq.extend(batch.seq)\n    tr_cwa = color_weighted_accuracy(tr_seq, tr_true, tr_pred)\n    tr_swa = shape_weighted_accuracy(tr_seq, tr_true, tr_pred)\n    tr_cplx = complexity_weighted_accuracy(tr_seq, tr_true, tr_pred)\n\n    # ---- validation ----\n    val_loss, v_seq, v_true, v_pred = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            val_loss += criterion(out, batch.y).item() * batch.num_graphs\n            v_pred.extend(out.argmax(1).cpu().tolist())\n            v_true.extend(batch.y.cpu().tolist())\n            v_seq.extend(batch.seq)\n    val_loss /= len(dev_loader.dataset)\n    val_cwa = color_weighted_accuracy(v_seq, v_true, v_pred)\n    val_swa = shape_weighted_accuracy(v_seq, v_true, v_pred)\n    val_cplx = complexity_weighted_accuracy(v_seq, v_true, v_pred)\n\n    # ---- logging ----\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"epochs\"].append(epoch)\n    ed[\"losses\"][\"train\"].append(tr_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"][\"CWA\"].append(tr_cwa)\n    ed[\"metrics\"][\"train\"][\"SWA\"].append(tr_swa)\n    ed[\"metrics\"][\"train\"][\"CplxWA\"].append(tr_cplx)\n    ed[\"metrics\"][\"val\"][\"CWA\"].append(val_cwa)\n    ed[\"metrics\"][\"val\"][\"SWA\"].append(val_swa)\n    ed[\"metrics\"][\"val\"][\"CplxWA\"].append(val_cplx)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}  CplxWA = {val_cplx:.4f}\")\n\n# ------------------- test evaluation ----------------\nmodel.eval()\nt_seq, t_true, t_pred = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        out = model(batch)\n        t_pred.extend(out.argmax(1).cpu().tolist())\n        t_true.extend(batch.y.cpu().tolist())\n        t_seq.extend(batch.seq)\n\ntest_cwa = color_weighted_accuracy(t_seq, t_true, t_pred)\ntest_swa = shape_weighted_accuracy(t_seq, t_true, t_pred)\ntest_cplx = complexity_weighted_accuracy(t_seq, t_true, t_pred)\nprint(f\"Test CWA={test_cwa:.3f}  SWA={test_swa:.3f}  CplxWA={test_cplx:.3f}\")\n\ned[\"predictions\"] = t_pred\ned[\"ground_truth\"] = t_true\ned[\"metrics\"][\"test\"] = {\"CWA\": test_cwa, \"SWA\": test_swa, \"CplxWA\": test_cplx}\n\n# ------------------- save results ------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# ------------------- quick plots -------------------\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"train\"], label=\"train\")\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.title(\"Loss\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, f\"loss_{ts}.png\"))\nplt.close()\n\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"metrics\"][\"val\"][\"CplxWA\"])\nplt.xlabel(\"epoch\")\nplt.ylabel(\"CplxWA\")\nplt.title(\"Validation CplxWA\")\nplt.savefig(os.path.join(working_dir, f\"cplxwa_{ts}.png\"))\nplt.close()\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, numpy as np, torch, matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom typing import List, Dict\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\n\n# ------------------- working dir -------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------- device ------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------- seeds -------------------------\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n\n# ------------------- metrics -----------------------\ndef count_color_variety(seq: str) -> int:\n    return len({tok[1] for tok in seq.strip().split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len({tok[0] for tok in seq.strip().split() if tok})\n\n\ndef color_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\ndef complexity_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\n# ------------------- data loading ------------------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nhave_real = spr_root.exists()\n\n\ndef load_real(name):\n    from datasets import load_dataset\n\n    return load_dataset(\n        \"csv\",\n        data_files=str(spr_root / f\"{name}.csv\"),\n        split=\"train\",\n        cache_dir=\".cache_dsets\",\n    )\n\n\ndef synth_rule_based(n: int) -> Dict[str, List]:\n    \"\"\"Generate sequences + rule-based label:\n    label 0: uniq_shapes  >  uniq_colors\n    label 1: uniq_shapes == uniq_colors\n    label 2: uniq_shapes  <  uniq_colors\n    \"\"\"\n    shapes = list(\"ABCD\")\n    colors = list(\"1234\")\n    seqs, labels = [], []\n    for i in range(n):\n        ln = np.random.randint(4, 9)\n        tokens = [random.choice(shapes) + random.choice(colors) for _ in range(ln)]\n        seq = \" \".join(tokens)\n        s_var = count_shape_variety(seq)\n        c_var = count_color_variety(seq)\n        if s_var > c_var:\n            lab = 0\n        elif s_var == c_var:\n            lab = 1\n        else:\n            lab = 2\n        seqs.append(seq)\n        labels.append(lab)\n    return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n\nif have_real:\n    raw = {\n        \"train\": load_real(\"train\"),\n        \"dev\": load_real(\"dev\"),\n        \"test\": load_real(\"test\"),\n    }\n    print(\"Loaded real SPR_BENCH dataset.\")\nelse:\n    print(\"SPR_BENCH folder not found \u2013 synthesising rule-based data.\")\n    raw = {\n        \"train\": synth_rule_based(8000),\n        \"dev\": synth_rule_based(2000),\n        \"test\": synth_rule_based(2000),\n    }\n\n# ------------------- vocab building ----------------\nall_shapes, all_colors = set(), set()\nfor s in raw[\"train\"][\"sequence\"] if not have_real else raw[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\n\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nnum_shapes, num_colors = len(shape2idx), len(color2idx)\n\nlabel_set = sorted(\n    set(raw[\"train\"][\"label\"] if not have_real else raw[\"train\"][\"label\"])\n)\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nnum_class = len(label2idx)\n\n\n# ------------------- graph builder -----------------\ndef seq_to_graph(seq: str, label: int) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    sh = torch.tensor([shape2idx[t[0]] for t in toks], dtype=torch.long)\n    col = torch.tensor([color2idx[t[1]] for t in toks], dtype=torch.long)\n    x = torch.stack([sh, col], 1)  # [n, 2]\n\n    edges_src, edges_dst, etype = [], [], []\n\n    # 0: order edges (i -> i+1)\n    for i in range(n - 1):\n        edges_src += [i, i + 1]\n        edges_dst += [i + 1, i]\n        etype += [0, 0]\n\n    # 1: same color, 2: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if int(col[i]) == int(col[j]):\n                edges_src += [i, j]\n                edges_dst += [j, i]\n                etype += [1, 1]\n            if int(sh[i]) == int(sh[j]):\n                edges_src += [i, j]\n                edges_dst += [j, i]\n                etype += [2, 2]\n\n    edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, edge_type=edge_type, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    if have_real:\n        return [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n    return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n\n\ntrain_ds, dev_ds, test_ds = map(build_dataset, (raw[\"train\"], raw[\"dev\"], raw[\"test\"]))\n\n\n# ------------------- model -------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, 8)\n        self.color_emb = nn.Embedding(num_colors, 8)\n        self.pre = nn.Linear(16, 32)\n        self.conv1 = RGCNConv(32, 64, num_relations=3)\n        self.conv2 = RGCNConv(64, 64, num_relations=3)\n        self.cls = nn.Linear(64, num_class)\n\n    def forward(self, data):\n        sx = self.shape_emb(data.x[:, 0])\n        cx = self.color_emb(data.x[:, 1])\n        x = torch.cat([sx, cx], 1)\n        x = F.relu(self.pre(x))\n        x = F.relu(self.conv1(x, data.edge_index, data.edge_type))\n        x = F.relu(self.conv2(x, data.edge_index, data.edge_type))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\nmodel = SPR_RGCN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\n# ------------------- loaders -----------------------\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=128, shuffle=False)\n\n# ------------------- tracking struct ---------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\n            \"train\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n            \"val\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n        },\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ------------------- training loop -----------------\nepochs = 10\nfor epoch in range(1, epochs + 1):\n    # ---- training ----\n    model.train()\n    run_loss = 0.0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        run_loss += loss.item() * batch.num_graphs\n    tr_loss = run_loss / len(train_loader.dataset)\n\n    # compute train metrics on full set (cheap enough)\n    model.eval()\n    tr_seq, tr_true, tr_pred = [], [], []\n    with torch.no_grad():\n        for batch in train_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            tr_pred.extend(out.argmax(1).cpu().tolist())\n            tr_true.extend(batch.y.cpu().tolist())\n            tr_seq.extend(batch.seq)\n    tr_cwa = color_weighted_accuracy(tr_seq, tr_true, tr_pred)\n    tr_swa = shape_weighted_accuracy(tr_seq, tr_true, tr_pred)\n    tr_cplx = complexity_weighted_accuracy(tr_seq, tr_true, tr_pred)\n\n    # ---- validation ----\n    val_loss, v_seq, v_true, v_pred = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            val_loss += criterion(out, batch.y).item() * batch.num_graphs\n            v_pred.extend(out.argmax(1).cpu().tolist())\n            v_true.extend(batch.y.cpu().tolist())\n            v_seq.extend(batch.seq)\n    val_loss /= len(dev_loader.dataset)\n    val_cwa = color_weighted_accuracy(v_seq, v_true, v_pred)\n    val_swa = shape_weighted_accuracy(v_seq, v_true, v_pred)\n    val_cplx = complexity_weighted_accuracy(v_seq, v_true, v_pred)\n\n    # ---- logging ----\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"epochs\"].append(epoch)\n    ed[\"losses\"][\"train\"].append(tr_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"][\"CWA\"].append(tr_cwa)\n    ed[\"metrics\"][\"train\"][\"SWA\"].append(tr_swa)\n    ed[\"metrics\"][\"train\"][\"CplxWA\"].append(tr_cplx)\n    ed[\"metrics\"][\"val\"][\"CWA\"].append(val_cwa)\n    ed[\"metrics\"][\"val\"][\"SWA\"].append(val_swa)\n    ed[\"metrics\"][\"val\"][\"CplxWA\"].append(val_cplx)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}  CplxWA = {val_cplx:.4f}\")\n\n# ------------------- test evaluation ----------------\nmodel.eval()\nt_seq, t_true, t_pred = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        out = model(batch)\n        t_pred.extend(out.argmax(1).cpu().tolist())\n        t_true.extend(batch.y.cpu().tolist())\n        t_seq.extend(batch.seq)\n\ntest_cwa = color_weighted_accuracy(t_seq, t_true, t_pred)\ntest_swa = shape_weighted_accuracy(t_seq, t_true, t_pred)\ntest_cplx = complexity_weighted_accuracy(t_seq, t_true, t_pred)\nprint(f\"Test CWA={test_cwa:.3f}  SWA={test_swa:.3f}  CplxWA={test_cplx:.3f}\")\n\ned[\"predictions\"] = t_pred\ned[\"ground_truth\"] = t_true\ned[\"metrics\"][\"test\"] = {\"CWA\": test_cwa, \"SWA\": test_swa, \"CplxWA\": test_cplx}\n\n# ------------------- save results ------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# ------------------- quick plots -------------------\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"train\"], label=\"train\")\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.title(\"Loss\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, f\"loss_{ts}.png\"))\nplt.close()\n\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"metrics\"][\"val\"][\"CplxWA\"])\nplt.xlabel(\"epoch\")\nplt.ylabel(\"CplxWA\")\nplt.title(\"Validation CplxWA\")\nplt.savefig(os.path.join(working_dir, f\"cplxwa_{ts}.png\"))\nplt.close()\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, numpy as np, torch, matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom typing import List, Dict\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import RGCNConv, global_mean_pool\n\n# ------------------- working dir -------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------- device ------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------- seeds -------------------------\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n\n# ------------------- metrics -----------------------\ndef count_color_variety(seq: str) -> int:\n    return len({tok[1] for tok in seq.strip().split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len({tok[0] for tok in seq.strip().split() if tok})\n\n\ndef color_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\ndef complexity_weighted_accuracy(seqs: List[str], y_t, y_p):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(sum(w), 1)\n\n\n# ------------------- data loading ------------------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nhave_real = spr_root.exists()\n\n\ndef load_real(name):\n    from datasets import load_dataset\n\n    return load_dataset(\n        \"csv\",\n        data_files=str(spr_root / f\"{name}.csv\"),\n        split=\"train\",\n        cache_dir=\".cache_dsets\",\n    )\n\n\ndef synth_rule_based(n: int) -> Dict[str, List]:\n    \"\"\"Generate sequences + rule-based label:\n    label 0: uniq_shapes  >  uniq_colors\n    label 1: uniq_shapes == uniq_colors\n    label 2: uniq_shapes  <  uniq_colors\n    \"\"\"\n    shapes = list(\"ABCD\")\n    colors = list(\"1234\")\n    seqs, labels = [], []\n    for i in range(n):\n        ln = np.random.randint(4, 9)\n        tokens = [random.choice(shapes) + random.choice(colors) for _ in range(ln)]\n        seq = \" \".join(tokens)\n        s_var = count_shape_variety(seq)\n        c_var = count_color_variety(seq)\n        if s_var > c_var:\n            lab = 0\n        elif s_var == c_var:\n            lab = 1\n        else:\n            lab = 2\n        seqs.append(seq)\n        labels.append(lab)\n    return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n\nif have_real:\n    raw = {\n        \"train\": load_real(\"train\"),\n        \"dev\": load_real(\"dev\"),\n        \"test\": load_real(\"test\"),\n    }\n    print(\"Loaded real SPR_BENCH dataset.\")\nelse:\n    print(\"SPR_BENCH folder not found \u2013 synthesising rule-based data.\")\n    raw = {\n        \"train\": synth_rule_based(8000),\n        \"dev\": synth_rule_based(2000),\n        \"test\": synth_rule_based(2000),\n    }\n\n# ------------------- vocab building ----------------\nall_shapes, all_colors = set(), set()\nfor s in raw[\"train\"][\"sequence\"] if not have_real else raw[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\n\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nnum_shapes, num_colors = len(shape2idx), len(color2idx)\n\nlabel_set = sorted(\n    set(raw[\"train\"][\"label\"] if not have_real else raw[\"train\"][\"label\"])\n)\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nnum_class = len(label2idx)\n\n\n# ------------------- graph builder -----------------\ndef seq_to_graph(seq: str, label: int) -> Data:\n    toks = seq.split()\n    n = len(toks)\n    sh = torch.tensor([shape2idx[t[0]] for t in toks], dtype=torch.long)\n    col = torch.tensor([color2idx[t[1]] for t in toks], dtype=torch.long)\n    x = torch.stack([sh, col], 1)  # [n, 2]\n\n    edges_src, edges_dst, etype = [], [], []\n\n    # 0: order edges (i -> i+1)\n    for i in range(n - 1):\n        edges_src += [i, i + 1]\n        edges_dst += [i + 1, i]\n        etype += [0, 0]\n\n    # 1: same color, 2: same shape\n    for i in range(n):\n        for j in range(i + 1, n):\n            if int(col[i]) == int(col[j]):\n                edges_src += [i, j]\n                edges_dst += [j, i]\n                etype += [1, 1]\n            if int(sh[i]) == int(sh[j]):\n                edges_src += [i, j]\n                edges_dst += [j, i]\n                etype += [2, 2]\n\n    edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long)\n    edge_type = torch.tensor(etype, dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, edge_type=edge_type, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    if have_real:\n        return [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n    return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n\n\ntrain_ds, dev_ds, test_ds = map(build_dataset, (raw[\"train\"], raw[\"dev\"], raw[\"test\"]))\n\n\n# ------------------- model -------------------------\nclass SPR_RGCN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, 8)\n        self.color_emb = nn.Embedding(num_colors, 8)\n        self.pre = nn.Linear(16, 32)\n        self.conv1 = RGCNConv(32, 64, num_relations=3)\n        self.conv2 = RGCNConv(64, 64, num_relations=3)\n        self.cls = nn.Linear(64, num_class)\n\n    def forward(self, data):\n        sx = self.shape_emb(data.x[:, 0])\n        cx = self.color_emb(data.x[:, 1])\n        x = torch.cat([sx, cx], 1)\n        x = F.relu(self.pre(x))\n        x = F.relu(self.conv1(x, data.edge_index, data.edge_type))\n        x = F.relu(self.conv2(x, data.edge_index, data.edge_type))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\nmodel = SPR_RGCN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\n# ------------------- loaders -----------------------\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=128, shuffle=False)\n\n# ------------------- tracking struct ---------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\n            \"train\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n            \"val\": {\"CWA\": [], \"SWA\": [], \"CplxWA\": []},\n        },\n        \"losses\": {\"train\": [], \"val\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ------------------- training loop -----------------\nepochs = 10\nfor epoch in range(1, epochs + 1):\n    # ---- training ----\n    model.train()\n    run_loss = 0.0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        run_loss += loss.item() * batch.num_graphs\n    tr_loss = run_loss / len(train_loader.dataset)\n\n    # compute train metrics on full set (cheap enough)\n    model.eval()\n    tr_seq, tr_true, tr_pred = [], [], []\n    with torch.no_grad():\n        for batch in train_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            tr_pred.extend(out.argmax(1).cpu().tolist())\n            tr_true.extend(batch.y.cpu().tolist())\n            tr_seq.extend(batch.seq)\n    tr_cwa = color_weighted_accuracy(tr_seq, tr_true, tr_pred)\n    tr_swa = shape_weighted_accuracy(tr_seq, tr_true, tr_pred)\n    tr_cplx = complexity_weighted_accuracy(tr_seq, tr_true, tr_pred)\n\n    # ---- validation ----\n    val_loss, v_seq, v_true, v_pred = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            val_loss += criterion(out, batch.y).item() * batch.num_graphs\n            v_pred.extend(out.argmax(1).cpu().tolist())\n            v_true.extend(batch.y.cpu().tolist())\n            v_seq.extend(batch.seq)\n    val_loss /= len(dev_loader.dataset)\n    val_cwa = color_weighted_accuracy(v_seq, v_true, v_pred)\n    val_swa = shape_weighted_accuracy(v_seq, v_true, v_pred)\n    val_cplx = complexity_weighted_accuracy(v_seq, v_true, v_pred)\n\n    # ---- logging ----\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"epochs\"].append(epoch)\n    ed[\"losses\"][\"train\"].append(tr_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"][\"CWA\"].append(tr_cwa)\n    ed[\"metrics\"][\"train\"][\"SWA\"].append(tr_swa)\n    ed[\"metrics\"][\"train\"][\"CplxWA\"].append(tr_cplx)\n    ed[\"metrics\"][\"val\"][\"CWA\"].append(val_cwa)\n    ed[\"metrics\"][\"val\"][\"SWA\"].append(val_swa)\n    ed[\"metrics\"][\"val\"][\"CplxWA\"].append(val_cplx)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}  CplxWA = {val_cplx:.4f}\")\n\n# ------------------- test evaluation ----------------\nmodel.eval()\nt_seq, t_true, t_pred = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        out = model(batch)\n        t_pred.extend(out.argmax(1).cpu().tolist())\n        t_true.extend(batch.y.cpu().tolist())\n        t_seq.extend(batch.seq)\n\ntest_cwa = color_weighted_accuracy(t_seq, t_true, t_pred)\ntest_swa = shape_weighted_accuracy(t_seq, t_true, t_pred)\ntest_cplx = complexity_weighted_accuracy(t_seq, t_true, t_pred)\nprint(f\"Test CWA={test_cwa:.3f}  SWA={test_swa:.3f}  CplxWA={test_cplx:.3f}\")\n\ned[\"predictions\"] = t_pred\ned[\"ground_truth\"] = t_true\ned[\"metrics\"][\"test\"] = {\"CWA\": test_cwa, \"SWA\": test_swa, \"CplxWA\": test_cplx}\n\n# ------------------- save results ------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\n# ------------------- quick plots -------------------\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"train\"], label=\"train\")\nplt.plot(ed[\"epochs\"], ed[\"losses\"][\"val\"], label=\"val\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.title(\"Loss\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, f\"loss_{ts}.png\"))\nplt.close()\n\nplt.figure()\nplt.plot(ed[\"epochs\"], ed[\"metrics\"][\"val\"][\"CplxWA\"])\nplt.xlabel(\"epoch\")\nplt.ylabel(\"CplxWA\")\nplt.title(\"Validation CplxWA\")\nplt.savefig(os.path.join(working_dir, f\"cplxwa_{ts}.png\"))\nplt.close()\n", "# plotting aggregation code"], "term_out": ["['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found, generating synthetic\ndata.', '\\n', '[bs=16] Epoch 1  train_loss 1.1053  val_loss 1.0995  CompWA\n0.2955', '\\n', '[bs=16] Epoch 2  train_loss 1.0991  val_loss 1.0972  CompWA\n0.3428', '\\n', '[bs=16] Epoch 3  train_loss 1.0924  val_loss 1.0930  CompWA\n0.3561', '\\n', '[bs=16] Epoch 4  train_loss 1.0958  val_loss 1.0912  CompWA\n0.3447', '\\n', '[bs=16] Epoch 5  train_loss 1.0863  val_loss 1.0917  CompWA\n0.3674', '\\n', '[bs=16] Test CompWA 0.3728', '\\n', '[bs=32] Epoch 1  train_loss\n1.1045  val_loss 1.1020  CompWA 0.3030', '\\n', '[bs=32] Epoch 2  train_loss\n1.0971  val_loss 1.0952  CompWA 0.3996', '\\n', '[bs=32] Epoch 3  train_loss\n1.0964  val_loss 1.0956  CompWA 0.3996', '\\n', '[bs=32] Epoch 4  train_loss\n1.0934  val_loss 1.0951  CompWA 0.3977', '\\n', '[bs=32] Epoch 5  train_loss\n1.0901  val_loss 1.0975  CompWA 0.3883', '\\n', '[bs=32] Test CompWA 0.3939',\n'\\n', '[bs=64] Epoch 1  train_loss 1.1058  val_loss 1.1070  CompWA 0.3030',\n'\\n', '[bs=64] Epoch 2  train_loss 1.0961  val_loss 1.0911  CompWA 0.4564',\n'\\n', '[bs=64] Epoch 3  train_loss 1.0943  val_loss 1.0904  CompWA 0.3920',\n'\\n', '[bs=64] Epoch 4  train_loss 1.0915  val_loss 1.0941  CompWA 0.3049',\n'\\n', '[bs=64] Epoch 5  train_loss 1.0906  val_loss 1.0936  CompWA 0.3485',\n'\\n', '[bs=64] Test CompWA 0.4111', '\\n', '[bs=128] Epoch 1  train_loss 1.1048\nval_loss 1.0959  CompWA 0.3163', '\\n', '[bs=128] Epoch 2  train_loss 1.1003\nval_loss 1.0992  CompWA 0.2708', '\\n', '[bs=128] Epoch 3  train_loss 1.0965\nval_loss 1.0949  CompWA 0.3598', '\\n', '[bs=128] Epoch 4  train_loss 1.0923\nval_loss 1.0932  CompWA 0.3636', '\\n', '[bs=128] Epoch 5  train_loss 1.0910\nval_loss 1.0937  CompWA 0.3258', '\\n', '[bs=128] Test CompWA 0.3576', '\\n', 'All\nruns complete. Data saved to ./working/experiment_data.npy', '\\n', 'Execution\ntime: 9 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH folder not found \u2014 generating synthetic\ndata.', '\\n', 'Epoch 1: validation_loss = 1.3960, Val CplxWA = 0.2268', '\\n',\n'Epoch 2: validation_loss = 1.3927, Val CplxWA = 0.2587', '\\n', 'Epoch 3:\nvalidation_loss = 1.3944, Val CplxWA = 0.2367', '\\n', 'Epoch 4: validation_loss\n= 1.3990, Val CplxWA = 0.2587', '\\n', 'Epoch 5: validation_loss = 1.3922, Val\nCplxWA = 0.2438', '\\n', 'Epoch 6: validation_loss = 1.3986, Val CplxWA =\n0.2644', '\\n', 'Epoch 7: validation_loss = 1.4062, Val CplxWA = 0.2308', '\\n',\n'Epoch 8: validation_loss = 1.4084, Val CplxWA = 0.2603', '\\n', 'Test\nComplexity-Weighted Accuracy: 0.2599', '\\n', 'Experiment data saved to\n./working/experiment_data.npy', '\\n', 'Execution time: 6 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Creating synthetic dataset', '\\n', 'Epoch 1:\nvalidation_loss = 1.1076 | CWA 0.299 | SWA 0.290 | CplxWA 0.293', '\\n', 'Epoch\n2: validation_loss = 1.0998 | CWA 0.317 | SWA 0.320 | CplxWA 0.316', '\\n',\n'Epoch 3: validation_loss = 1.1009 | CWA 0.328 | SWA 0.331 | CplxWA 0.322',\n'\\n', 'Epoch 4: validation_loss = 1.1037 | CWA 0.308 | SWA 0.312 | CplxWA\n0.304', '\\n', 'Epoch 5: validation_loss = 1.1098 | CWA 0.293 | SWA 0.301 |\nCplxWA 0.293', '\\n', 'Epoch 6: validation_loss = 1.1003 | CWA 0.368 | SWA 0.376\n| CplxWA 0.372', '\\n', 'Epoch 7: validation_loss = 1.1080 | CWA 0.323 | SWA\n0.335 | CplxWA 0.317', '\\n', 'Epoch 8: validation_loss = 1.1113 | CWA 0.325 |\nSWA 0.331 | CplxWA 0.320', '\\n', 'Test set --> CWA 0.300 | SWA 0.302 | CplxWA\n0.298', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-12/working/experiment_data.npy', '\\n', 'Execution time:\n4 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found. Generating synthetic toy\ndata.', '\\n', 'Epoch 1: train_loss=1.1261 val_loss=1.0922 train_CplxWA=0.3468\nval_CplxWA=0.3137', '\\n', 'Epoch 2: train_loss=1.0952 val_loss=1.1014\ntrain_CplxWA=0.3760 val_CplxWA=0.3707', '\\n', 'Epoch 3: train_loss=1.0894\nval_loss=1.0855 train_CplxWA=0.3701 val_CplxWA=0.3689', '\\n', 'TEST\nCplxWA=0.3418  CWA=0.3465  SWA=0.3465', '\\n', 'Experiment data saved to\n./working/experiment_data.npy', '\\n', 'Execution time: 3 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Dataset missing, generating synthetic.', '\\n',\n'Epoch 1: validation_loss = 1.1023  CplxWA = 0.3516', '\\n', 'Epoch 2:\nvalidation_loss = 1.0994  CplxWA = 0.3295', '\\n', 'Epoch 3: validation_loss =\n1.0981  CplxWA = 0.3665', '\\n', 'Epoch 4: validation_loss = 1.0948  CplxWA =\n0.3552', '\\n', 'Epoch 5: validation_loss = 1.1010  CplxWA = 0.3359', '\\n',\n'Epoch 6: validation_loss = 1.0993  CplxWA = 0.3523', '\\n', 'Epoch 7:\nvalidation_loss = 1.1038  CplxWA = 0.3680', '\\n', 'Epoch 8: validation_loss =\n1.1058  CplxWA = 0.3609', '\\n', 'Epoch 9: validation_loss = 1.1075  CplxWA =\n0.3744', '\\n', 'Epoch 10: validation_loss = 1.1117  CplxWA = 0.3495', '\\n',\n'Test CWA=0.304  SWA=0.309  CplxWA=0.308', '\\n', 'Execution time: 4 seconds\nseconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loading real SPR_BENCH from /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 571263.73\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 806752.07\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 720794.64\nexamples/s]', '\\n', 'Epoch 1: validation_loss = 0.2030, Val CplxWA = 0.9255',\n'\\n', 'Epoch 2: validation_loss = 0.1713, Val CplxWA = 0.9354', '\\n', 'Epoch 3:\nvalidation_loss = 0.1140, Val CplxWA = 0.9656', '\\n', 'Epoch 4: validation_loss\n= 0.1051, Val CplxWA = 0.9679', '\\n', 'Epoch 5: validation_loss = 0.0998, Val\nCplxWA = 0.9695', '\\n', 'Epoch 6: validation_loss = 0.0883, Val CplxWA =\n0.9732', '\\n', 'Epoch 7: validation_loss = 0.1021, Val CplxWA = 0.9715', '\\n',\n'Epoch 8: validation_loss = 0.0934, Val CplxWA = 0.9745', '\\n', 'Epoch 9:\nvalidation_loss = 0.0971, Val CplxWA = 0.9714', '\\n', 'Epoch 10: validation_loss\n= 0.0813, Val CplxWA = 0.9786', '\\n', 'Test Complexity-Weighted Accuracy:\n0.6524', '\\n', 'Experiment data saved to ./working/experiment_data.npy', '\\n',\n'Execution time: a minute seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH folder not found \u2013 synthesising rule-\nbased data.', '\\n', 'Epoch 1: validation_loss = 0.5715  CplxWA = 0.7484', '\\n',\n'Epoch 2: validation_loss = 0.5572  CplxWA = 0.7334', '\\n', 'Epoch 3:\nvalidation_loss = 0.3940  CplxWA = 0.8349', '\\n', 'Epoch 4: validation_loss =\n0.3036  CplxWA = 0.8733', '\\n', 'Epoch 5: validation_loss = 0.3041  CplxWA =\n0.8682', '\\n', 'Epoch 6: validation_loss = 0.2111  CplxWA = 0.9082', '\\n',\n'Epoch 7: validation_loss = 0.1597  CplxWA = 0.9361', '\\n', 'Epoch 8:\nvalidation_loss = 0.1042  CplxWA = 0.9647', '\\n', 'Epoch 9: validation_loss =\n0.2053  CplxWA = 0.9152', '\\n', 'Epoch 10: validation_loss = 0.0890  CplxWA =\n0.9737', '\\n', 'Test CWA=0.978  SWA=0.974  CplxWA=0.977', '\\n', 'Execution time:\n19 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found. Building tiny synthetic\nfallback.', '\\n', 'Epoch 1: train_loss=1.1132 val_loss=1.1197\nVal_CplxWA=0.2419', '\\n', 'Epoch 2: train_loss=1.0892 val_loss=1.1263\nVal_CplxWA=0.2969', '\\n', 'Epoch 3: train_loss=1.0758 val_loss=1.1321\nVal_CplxWA=0.2852', '\\n', 'Epoch 4: train_loss=1.0712 val_loss=1.1346\nVal_CplxWA=0.2554', '\\n', 'Epoch 5: train_loss=1.0620 val_loss=1.1325\nVal_CplxWA=0.2717', '\\n', 'Epoch 6: train_loss=1.0567 val_loss=1.1371\nVal_CplxWA=0.2924', '\\n', 'Test Complexity-Weighted Accuracy: 0.3330', '\\n',\n'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-11/working/experiment_data.npy', '\\n', 'Execution time:\n3 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '!! SPR_BENCH not found \u2013 creating tiny synthetic\nset for demo.', '\\n', 'Epoch 1: train_loss=1.1077 val_loss=1.1166\ntrain_CplxWA=0.3566 val_CplxWA=0.3087', '\\n', 'Epoch 2: train_loss=1.0923\nval_loss=1.1043 train_CplxWA=0.4070 val_CplxWA=0.3142', '\\n', 'Epoch 3:\ntrain_loss=1.0872 val_loss=1.1037 train_CplxWA=0.4380 val_CplxWA=0.3329', '\\n',\n'Epoch 4: train_loss=1.0826 val_loss=1.1111 train_CplxWA=0.4247\nval_CplxWA=0.2970', '\\n', 'Epoch 5: train_loss=1.0768 val_loss=1.1116\ntrain_CplxWA=0.4444 val_CplxWA=0.3425', '\\n', 'Epoch 6: train_loss=1.0697\nval_loss=1.1207 train_CplxWA=0.4290 val_CplxWA=0.3156', '\\n', 'Epoch 7:\ntrain_loss=1.0663 val_loss=1.1197 train_CplxWA=0.4524 val_CplxWA=0.3163', '\\n',\n'Epoch 8: train_loss=1.0616 val_loss=1.1263 train_CplxWA=0.4552\nval_CplxWA=0.3280', '\\n', 'Test Complexity-Weighted Accuracy: 0.3557', '\\n',\n'Execution time: 9 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH folder not found \u2013 synthesising rule-\nbased data.', '\\n', 'Epoch 1: validation_loss = 0.5715  CplxWA = 0.7484', '\\n',\n'Epoch 2: validation_loss = 0.5572  CplxWA = 0.7334', '\\n', 'Epoch 3:\nvalidation_loss = 0.3940  CplxWA = 0.8349', '\\n', 'Epoch 4: validation_loss =\n0.3039  CplxWA = 0.8716', '\\n', 'Epoch 5: validation_loss = 0.3085  CplxWA =\n0.8657', '\\n', 'Epoch 6: validation_loss = 0.2127  CplxWA = 0.9078', '\\n',\n'Epoch 7: validation_loss = 0.1577  CplxWA = 0.9349', '\\n', 'Epoch 8:\nvalidation_loss = 0.1048  CplxWA = 0.9632', '\\n', 'Epoch 9: validation_loss =\n0.1848  CplxWA = 0.9261', '\\n', 'Epoch 10: validation_loss = 0.0917  CplxWA =\n0.9744', '\\n', 'Test CWA=0.978  SWA=0.974  CplxWA=0.977', '\\n', 'Execution time:\n57 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH folder not found \u2013 synthesising rule-\nbased data.', '\\n', 'Epoch 1: validation_loss = 0.5715  CplxWA = 0.7484', '\\n',\n'Epoch 2: validation_loss = 0.5572  CplxWA = 0.7334', '\\n', 'Epoch 3:\nvalidation_loss = 0.3940  CplxWA = 0.8349', '\\n', 'Epoch 4: validation_loss =\n0.3039  CplxWA = 0.8716', '\\n', 'Epoch 5: validation_loss = 0.3085  CplxWA =\n0.8657', '\\n', 'Epoch 6: validation_loss = 0.2124  CplxWA = 0.9084', '\\n',\n'Epoch 7: validation_loss = 0.1571  CplxWA = 0.9355', '\\n', 'Epoch 8:\nvalidation_loss = 0.1048  CplxWA = 0.9628', '\\n', 'Epoch 9: validation_loss =\n0.1810  CplxWA = 0.9267', '\\n', 'Epoch 10: validation_loss = 0.0920  CplxWA =\n0.9747', '\\n', 'Test CWA=0.978  SWA=0.975  CplxWA=0.977', '\\n', 'Execution time:\n19 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH folder not found \u2013 synthesising rule-\nbased data.', '\\n', 'Epoch 1: validation_loss = 0.5715  CplxWA = 0.7484', '\\n',\n'Epoch 2: validation_loss = 0.5572  CplxWA = 0.7334', '\\n', 'Epoch 3:\nvalidation_loss = 0.3940  CplxWA = 0.8349', '\\n', 'Epoch 4: validation_loss =\n0.3039  CplxWA = 0.8716', '\\n', 'Epoch 5: validation_loss = 0.3085  CplxWA =\n0.8657', '\\n', 'Epoch 6: validation_loss = 0.2127  CplxWA = 0.9078', '\\n',\n'Epoch 7: validation_loss = 0.1577  CplxWA = 0.9349', '\\n', 'Epoch 8:\nvalidation_loss = 0.1048  CplxWA = 0.9627', '\\n', 'Epoch 9: validation_loss =\n0.1754  CplxWA = 0.9289', '\\n', 'Epoch 10: validation_loss = 0.0931  CplxWA =\n0.9740', '\\n', 'Test CWA=0.977  SWA=0.974  CplxWA=0.976', '\\n', 'Execution time:\n20 seconds seconds (time limit is 30 minutes).']", ""], "analysis": ["The execution of the training script completed successfully without any bugs.\nThe script generated synthetic data due to the absence of the SPR_BENCH dataset,\ntrained the model with different batch sizes, and evaluated the performance\nusing the Complexity-Weighted Accuracy (CompWA) metric. The results were saved,\nand plots were generated for further analysis. The training and validation\nlosses, along with the CompWA metric, show reasonable behavior for a first\nattempt. No immediate issues were observed in the output.", "The execution output indicates that the model's validation and test Complexity-\nWeighted Accuracy (CplxWA) remain very low, around 0.26, which is far below the\nexpected performance. The validation loss also fluctuates without significant\nimprovement, suggesting that the model is not learning effectively. Potential\nissues include:  1. **Synthetic Data Issue**: The script generates synthetic\ndata instead of loading the real SPR_BENCH dataset. This might not represent the\nactual complexity of the SPR_BENCH benchmark. 2. **Model Architecture or\nTraining Problem**: The GNN model may not be well-suited for the task, or the\ntraining process (e.g., learning rate, number of epochs) might be suboptimal.\nProposed Fixes: 1. Ensure the SPR_BENCH dataset is available and correctly\nloaded instead of relying on synthetic data. 2. Revisit the GNN architecture and\nhyperparameters. Experiment with different configurations, such as increasing\nthe number of epochs, tuning the learning rate, or adding more layers to the\nmodel. 3. Perform ablation studies to identify which components of the model are\nunderperforming.", "The model does not seem to be learning effectively, as indicated by the low\nColor-Weighted Accuracy (CWA), Shape-Weighted Accuracy (SWA), and Complexity-\nWeighted Accuracy (CplxWA) metrics during both training and testing phases.\nAdditionally, the validation loss remains high and fluctuates across epochs,\nshowing no clear trend of improvement. This could be due to several reasons,\nincluding insufficient model complexity, inadequate training epochs, or issues\nwith the dataset or its synthetic generation. To address this, consider\nincreasing the number of training epochs, using a more complex model\narchitecture, or improving the dataset quality by ensuring it reflects the\nproblem's complexity more accurately.", "The script executed successfully without any errors or bugs. The model was\ntrained on synthetic toy data due to the absence of the SPR_BENCH dataset. The\ntraining and validation losses decreased over epochs, and the Complex Weighted\nAccuracy (CplxWA) metric showed some improvement during training. However, the\nfinal test results (CplxWA: 0.3418, CWA: 0.3465, SWA: 0.3465) are below the SOTA\nbenchmarks (CWA: 65.0%, SWA: 70.0%). This suggests that the model's performance\nis suboptimal and could be improved by using the actual SPR_BENCH dataset,\nfurther tuning the model architecture, or exploring additional features.", "The execution output reveals that the model's performance is poor, with a Test\nCWA of 0.304, SWA of 0.309, and CplxWA of 0.308. Additionally, the validation\nloss does not show significant improvement across epochs, indicating that the\nmodel is not learning effectively. This could be due to insufficient model\ncomplexity, inappropriate hyperparameters, or issues with the synthetic dataset\ngeneration. To address this, consider the following fixes: 1. Use the real\nSPR_BENCH dataset if available instead of the synthetic one. 2. Increase the\nmodel complexity by adding more layers or increasing the embedding dimensions.\n3. Experiment with different learning rates, optimizers, and batch sizes. 4.\nPerform data augmentation or regularization techniques like dropout to improve\ngeneralization.", "", "", "", "", "", "", "", ""], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during the training phase.", "data": [{"dataset_name": "bs_16", "final_value": 1.0863, "best_value": 1.0863}, {"dataset_name": "bs_32", "final_value": 1.0901, "best_value": 1.0901}, {"dataset_name": "bs_64", "final_value": 1.0906, "best_value": 1.0906}, {"dataset_name": "bs_128", "final_value": 1.091, "best_value": 1.091}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during the validation phase.", "data": [{"dataset_name": "bs_16", "final_value": 1.0917, "best_value": 1.0917}, {"dataset_name": "bs_32", "final_value": 1.0975, "best_value": 1.0975}, {"dataset_name": "bs_64", "final_value": 1.0936, "best_value": 1.0936}, {"dataset_name": "bs_128", "final_value": 1.0937, "best_value": 1.0937}]}, {"metric_name": "validation CompWA", "lower_is_better": false, "description": "The best weighted average metric computed during validation.", "data": [{"dataset_name": "bs_16", "final_value": 0.3674, "best_value": 0.3674}, {"dataset_name": "bs_32", "final_value": 0.3996, "best_value": 0.3996}, {"dataset_name": "bs_64", "final_value": 0.4564, "best_value": 0.4564}, {"dataset_name": "bs_128", "final_value": 0.3636, "best_value": 0.3636}]}, {"metric_name": "test CompWA", "lower_is_better": false, "description": "The weighted average metric computed on the test set.", "data": [{"dataset_name": "bs_16", "final_value": 0.3728, "best_value": 0.3728}, {"dataset_name": "bs_32", "final_value": 0.3939, "best_value": 0.3939}, {"dataset_name": "bs_64", "final_value": 0.4111, "best_value": 0.4111}, {"dataset_name": "bs_128", "final_value": 0.3576, "best_value": 0.3576}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "spr_bench", "final_value": 1.3419, "best_value": 1.3419}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "spr_bench", "final_value": 1.3922, "best_value": 1.3922}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during validation.", "data": [{"dataset_name": "spr_bench", "final_value": 0.2644, "best_value": 0.2644}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during testing.", "data": [{"dataset_name": "spr_bench", "final_value": 0.2599, "best_value": 0.2599}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the error or difference between the predicted and actual values.", "data": [{"dataset_name": "training", "final_value": 1.0823, "best_value": 1.0823}, {"dataset_name": "validation", "final_value": 1.0998, "best_value": 1.0998}]}, {"metric_name": "CWA", "lower_is_better": false, "description": "A weighted average metric, context-specific.", "data": [{"dataset_name": "training", "final_value": 0.431, "best_value": 0.431}, {"dataset_name": "validation", "final_value": 0.3675, "best_value": 0.3675}, {"dataset_name": "test", "final_value": 0.3002, "best_value": 0.3002}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "Another weighted average metric, context-specific.", "data": [{"dataset_name": "training", "final_value": 0.435, "best_value": 0.435}, {"dataset_name": "validation", "final_value": 0.3757, "best_value": 0.3757}, {"dataset_name": "test", "final_value": 0.3019, "best_value": 0.3019}]}, {"metric_name": "CplxWA", "lower_is_better": false, "description": "A more complex weighted average metric, context-specific.", "data": [{"dataset_name": "training", "final_value": 0.4281, "best_value": 0.4281}, {"dataset_name": "validation", "final_value": 0.3724, "best_value": 0.3724}, {"dataset_name": "test", "final_value": 0.2984, "best_value": 0.2984}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the error in predictions. Lower values indicate better performance.", "data": [{"dataset_name": "training", "final_value": 1.0894, "best_value": 1.0894}, {"dataset_name": "validation", "final_value": 1.0855, "best_value": 1.0855}]}, {"metric_name": "CplxWA", "lower_is_better": false, "description": "Complex Weighted Average metric. Higher values indicate better performance.", "data": [{"dataset_name": "training", "final_value": 0.3701, "best_value": 0.3701}, {"dataset_name": "validation", "final_value": 0.3707, "best_value": 0.3707}, {"dataset_name": "test", "final_value": 0.3418, "best_value": 0.3418}]}, {"metric_name": "CWA", "lower_is_better": false, "description": "Weighted Average metric. Higher values indicate better performance.", "data": [{"dataset_name": "test", "final_value": 0.3465, "best_value": 0.3465}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "Simple Weighted Average metric. Higher values indicate better performance.", "data": [{"dataset_name": "test", "final_value": 0.3465, "best_value": 0.3465}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the error or deviation from the expected output. Lower values are better.", "data": [{"dataset_name": "training", "final_value": 1.0549, "best_value": 1.0549}, {"dataset_name": "validation", "final_value": 1.0948, "best_value": 1.0948}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy weighted by color categories.", "data": [{"dataset_name": "training", "final_value": 0.5449, "best_value": 0.5449}, {"dataset_name": "validation", "final_value": 0.3693, "best_value": 0.3693}, {"dataset_name": "test", "final_value": 0.3043, "best_value": 0.3043}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy weighted by shape categories.", "data": [{"dataset_name": "training", "final_value": 0.5471, "best_value": 0.5471}, {"dataset_name": "validation", "final_value": 0.3785, "best_value": 0.3785}, {"dataset_name": "test", "final_value": 0.3093, "best_value": 0.3093}]}, {"metric_name": "complexity weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy weighted by complexity categories.", "data": [{"dataset_name": "training", "final_value": 0.5483, "best_value": 0.5483}, {"dataset_name": "validation", "final_value": 0.3744, "best_value": 0.3744}, {"dataset_name": "test", "final_value": 0.3085, "best_value": 0.3085}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error in the model's predictions on the training dataset.", "data": [{"dataset_name": "spr_bench", "final_value": 0.071009, "best_value": 0.071009}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error in the model's predictions on the validation dataset.", "data": [{"dataset_name": "spr_bench", "final_value": 0.081347, "best_value": 0.081347}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of the model on the validation dataset, weighted by complexity.", "data": [{"dataset_name": "spr_bench", "final_value": 0.9786, "best_value": 0.9786}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of the model on the test dataset, weighted by complexity.", "data": [{"dataset_name": "spr_bench", "final_value": 0.652421, "best_value": 0.652421}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0793, "best_value": 0.0793}]}, {"metric_name": "training color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9841, "best_value": 0.9841}]}, {"metric_name": "training shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9819, "best_value": 0.9819}]}, {"metric_name": "training complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9839, "best_value": 0.9839}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.089, "best_value": 0.089}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9745, "best_value": 0.9745}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9711, "best_value": 0.9711}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9737, "best_value": 0.9737}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during testing.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9784, "best_value": 0.9784}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during testing.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9744, "best_value": 0.9744}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during testing.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.977, "best_value": 0.977}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The final loss value during training on the dataset.", "data": [{"dataset_name": "spr_rgcn", "final_value": 1.0567, "best_value": 1.0567}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The final loss value during validation on the dataset.", "data": [{"dataset_name": "spr_rgcn", "final_value": 1.1371, "best_value": 1.1371}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "The best complexity-weighted accuracy achieved during validation on the dataset.", "data": [{"dataset_name": "spr_rgcn", "final_value": 0.2969, "best_value": 0.2969}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "The final complexity-weighted accuracy achieved on the test dataset.", "data": [{"dataset_name": "spr_rgcn", "final_value": 0.333, "best_value": 0.333}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss during training phase, where lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0616, "best_value": 1.0616}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss during validation phase, where lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.1037, "best_value": 1.1037}]}, {"metric_name": "training complexity-weighted accuracy", "lower_is_better": false, "description": "The accuracy during training phase, weighted by complexity, where higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4552, "best_value": 0.4552}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "The accuracy during validation phase, weighted by complexity, where higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.3425, "best_value": 0.3425}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "The accuracy during test phase, weighted by complexity, where higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.3557, "best_value": 0.3557}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0797, "best_value": 0.0797}]}, {"metric_name": "training color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9831, "best_value": 0.9831}]}, {"metric_name": "training shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9806, "best_value": 0.9806}]}, {"metric_name": "training complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9829, "best_value": 0.9829}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0917, "best_value": 0.0917}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9752, "best_value": 0.9752}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9716, "best_value": 0.9716}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9744, "best_value": 0.9744}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during testing phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9781, "best_value": 0.9781}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during testing phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9741, "best_value": 0.9741}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during testing phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9768, "best_value": 0.9768}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0795, "best_value": 0.0795}]}, {"metric_name": "training color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9832, "best_value": 0.9832}]}, {"metric_name": "training shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9808, "best_value": 0.9808}]}, {"metric_name": "training complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9829, "best_value": 0.9829}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.092, "best_value": 0.092}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9754, "best_value": 0.9754}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9722, "best_value": 0.9722}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9747, "best_value": 0.9747}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9784, "best_value": 0.9784}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9745, "best_value": 0.9745}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9771, "best_value": 0.9771}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0797, "best_value": 0.0797}]}, {"metric_name": "training color-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by color during training. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9833, "best_value": 0.9833}]}, {"metric_name": "training shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by shape during training. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.981, "best_value": 0.981}]}, {"metric_name": "training complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by complexity during training. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9831, "best_value": 0.9831}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error during validation. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0931, "best_value": 0.0931}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by color during validation. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9748, "best_value": 0.9748}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by shape during validation. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9711, "best_value": 0.9711}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by complexity during validation. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.974, "best_value": 0.974}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by color during testing. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9774, "best_value": 0.9774}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by shape during testing. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9736, "best_value": 0.9736}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by complexity during testing. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9762, "best_value": 0.9762}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, false, false, true, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs16_20250830_210116.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs16_20250830_210116.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs32_20250830_210118.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs32_20250830_210118.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs64_20250830_210119.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs64_20250830_210119.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs128_20250830_210119.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs128_20250830_210119.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs16.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs16.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs32.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs32.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs64.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs64.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs128.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs128.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/test_compwa_summary_SPR_synth.png"], [], [], ["../../logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/loss_curves.png", "../../logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/cplxwa_curves.png", "../../logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/loss_curve_SPR.png", "../../logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/cplxwa_curve_SPR.png", "../../logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/test_cplxwa_summary.png", "../../logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/test_cwa_summary.png", "../../logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/test_swa_summary.png"], [], ["../../logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/loss_20250830_210606.png", "../../logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/cplxwa_20250830_210606.png", "../../logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/loss_20250830_211037.png", "../../logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/cplxwa_20250830_211037.png", "../../logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/spr_bench_loss_curve.png", "../../logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/spr_bench_val_cplxwa_curve.png", "../../logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/spr_bench_test_pred_vs_gt.png"], ["../../logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/loss_20250830_210852.png", "../../logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/cplxwa_20250830_210852.png", "../../logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/loss_curve_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/val_cwa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/val_swa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/val_cplxwa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/summary_test_cplxwa.png"], ["../../logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/loss_20250830_210615.png", "../../logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/cplxwa_20250830_210615.png", "../../logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/loss_curve_SPR_synth_spr_rgcn.png", "../../logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/val_compwa_curve_SPR_synth_spr_rgcn.png", "../../logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/test_compwa_SPR_synth_spr_rgcn.png"], ["../../logs/0-run/experiment_results/experiment_c2133c5cdcb84161a5a0079d93484e5c_proc_1493252/spr_bench_loss_curve.png", "../../logs/0-run/experiment_results/experiment_c2133c5cdcb84161a5a0079d93484e5c_proc_1493252/spr_bench_compwa_curve.png", "../../logs/0-run/experiment_results/experiment_c2133c5cdcb84161a5a0079d93484e5c_proc_1493252/summary_test_compwa.png"], ["../../logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/loss_20250830_211244.png", "../../logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/cplxwa_20250830_211244.png", "../../logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/loss_curve_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/val_cwa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/val_swa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/val_cplxwa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/summary_test_cplxwa.png"], ["../../logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/loss_20250830_211207.png", "../../logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/cplxwa_20250830_211207.png", "../../logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/loss_curve_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/val_cwa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/val_swa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/val_cplxwa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/summary_test_cplxwa.png"], ["../../logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/loss_20250830_211208.png", "../../logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/cplxwa_20250830_211208.png", "../../logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/loss_curve_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/val_cwa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/val_swa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/val_cplxwa_SPR_BENCH.png", "../../logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/summary_test_cplxwa.png"], ["../../logs/0-run/experiment_results/seed_aggregation_ef9c51aec7c54e11a35da8c8eea117f0/loss_curve_mean_SPR_BENCH.png", "../../logs/0-run/experiment_results/seed_aggregation_ef9c51aec7c54e11a35da8c8eea117f0/val_cwa_mean_SPR_BENCH.png", "../../logs/0-run/experiment_results/seed_aggregation_ef9c51aec7c54e11a35da8c8eea117f0/val_swa_mean_SPR_BENCH.png", "../../logs/0-run/experiment_results/seed_aggregation_ef9c51aec7c54e11a35da8c8eea117f0/val_cplxwa_mean_SPR_BENCH.png", "../../logs/0-run/experiment_results/seed_aggregation_ef9c51aec7c54e11a35da8c8eea117f0/summary_test_cplxwa_mean.png"]], "plot_paths": [["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs16_20250830_210116.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs16_20250830_210116.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs32_20250830_210118.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs32_20250830_210118.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs64_20250830_210119.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs64_20250830_210119.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs128_20250830_210119.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs128_20250830_210119.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs16.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs16.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs32.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs32.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs64.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs64.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs128.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs128.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/test_compwa_summary_SPR_synth.png"], [], [], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/loss_curves.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/cplxwa_curves.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/loss_curve_SPR.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/cplxwa_curve_SPR.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/test_cplxwa_summary.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/test_cwa_summary.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/test_swa_summary.png"], [], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/loss_20250830_210606.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/cplxwa_20250830_210606.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/loss_20250830_211037.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/cplxwa_20250830_211037.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/spr_bench_loss_curve.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/spr_bench_val_cplxwa_curve.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/spr_bench_test_pred_vs_gt.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/loss_20250830_210852.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/cplxwa_20250830_210852.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/loss_curve_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/val_cwa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/val_swa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/val_cplxwa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/summary_test_cplxwa.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/loss_20250830_210615.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/cplxwa_20250830_210615.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/loss_curve_SPR_synth_spr_rgcn.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/val_compwa_curve_SPR_synth_spr_rgcn.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/test_compwa_SPR_synth_spr_rgcn.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_c2133c5cdcb84161a5a0079d93484e5c_proc_1493252/spr_bench_loss_curve.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_c2133c5cdcb84161a5a0079d93484e5c_proc_1493252/spr_bench_compwa_curve.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_c2133c5cdcb84161a5a0079d93484e5c_proc_1493252/summary_test_compwa.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/loss_20250830_211244.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/cplxwa_20250830_211244.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/loss_curve_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/val_cwa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/val_swa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/val_cplxwa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/summary_test_cplxwa.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/loss_20250830_211207.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/cplxwa_20250830_211207.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/loss_curve_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/val_cwa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/val_swa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/val_cplxwa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/summary_test_cplxwa.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/loss_20250830_211208.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/cplxwa_20250830_211208.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/loss_curve_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/val_cwa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/val_swa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/val_cplxwa_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/summary_test_cplxwa.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_ef9c51aec7c54e11a35da8c8eea117f0/loss_curve_mean_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_ef9c51aec7c54e11a35da8c8eea117f0/val_cwa_mean_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_ef9c51aec7c54e11a35da8c8eea117f0/val_swa_mean_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_ef9c51aec7c54e11a35da8c8eea117f0/val_cplxwa_mean_SPR_BENCH.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_ef9c51aec7c54e11a35da8c8eea117f0/summary_test_cplxwa_mean.png"]], "plot_analyses": [[{"analysis": "This plot shows the training and validation loss for a batch size of 16 over 5 epochs. The training loss decreases consistently, indicating the model is learning. The validation loss initially decreases but then flattens and slightly increases after the third epoch, which may suggest the beginning of overfitting. The gap between training and validation loss is relatively small, which is a positive sign for generalization.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs16_20250830_210116.png"}, {"analysis": "This plot depicts the Validation Composite Weighted Accuracy (CompWA) for a batch size of 16. The metric increases steadily over the epochs, indicating the model's performance on the validation set improves with training. The upward trend suggests the model is effectively learning to generalize.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs16_20250830_210116.png"}, {"analysis": "This plot shows the training and validation loss for a batch size of 32 over 5 epochs. Both losses decrease consistently, with the validation loss plateauing after the third epoch. The training loss continues to drop, which may indicate slight overfitting. However, the validation loss remains stable, suggesting the model's generalization is not severely impacted.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs32_20250830_210118.png"}, {"analysis": "This plot represents the Validation Composite Weighted Accuracy (CompWA) for a batch size of 32. The metric improves significantly in the first two epochs and then stabilizes. The plateau after the second epoch suggests that the model's performance gains diminish with further training.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs32_20250830_210118.png"}, {"analysis": "This plot illustrates the training and validation loss for a batch size of 64 over 5 epochs. Both losses decrease, with the validation loss showing a slight increase after the third epoch. The training loss decreases more significantly, which may indicate overfitting. The gap between training and validation losses widens slightly, suggesting potential generalization issues.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs64_20250830_210119.png"}, {"analysis": "This plot shows the Validation Composite Weighted Accuracy (CompWA) for a batch size of 64. The metric improves notably in the first two epochs, peaks in the second epoch, and then declines before slightly recovering. The decline suggests overfitting or instability in the model's performance.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs64_20250830_210119.png"}, {"analysis": "This plot displays the training and validation loss for a batch size of 128 over 5 epochs. Both losses decrease, but the validation loss shows an increase after the second epoch, suggesting overfitting. The training loss continues to drop steadily, indicating the model is still learning on the training set.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs128_20250830_210119.png"}, {"analysis": "This plot represents the Validation Composite Weighted Accuracy (CompWA) for a batch size of 128. The metric initially improves but drops significantly after the second epoch, indicating overfitting or instability. The fluctuation in performance suggests the model struggles to generalize at this batch size.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs128_20250830_210119.png"}, {"analysis": "This plot shows the training and validation loss for a batch size of 16 on a synthetic dataset. Both losses decrease, with the validation loss flattening after the third epoch. The consistent decrease in training loss indicates the model is learning, while the stable validation loss suggests no significant overfitting.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs16.png"}, {"analysis": "This plot compares the Test Composite Weighted Accuracy (CompWA) across different batch sizes. The best performance is observed with a batch size of 64, while the batch size of 128 shows the lowest performance. This suggests that a moderate batch size (64) achieves the best balance between training stability and generalization.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs16.png"}], [], [], [{"analysis": "The loss curves for training and validation show a consistent decrease in loss over the epochs. The training loss decreases more steeply compared to the validation loss, which initially increases slightly before decreasing. This suggests that the model is learning effectively, but the initial rise in validation loss might indicate some overfitting or noise in the early stages of training.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/loss_curves.png"}, {"analysis": "The CplxWA curves for training and validation indicate a steady increase in performance over the epochs. The validation curve closely follows the training curve, with both converging towards similar values by the final epoch. This suggests that the model generalizes well on the validation set and captures the complexity-weighted accuracy effectively.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/cplxwa_curves.png"}, {"analysis": "This loss curve mirrors the earlier one, showing consistent decreases in both training and validation loss over the epochs. The validation loss initially increases before decreasing, indicating potential early overfitting or noise, but the overall trend reflects effective learning by the model.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/loss_curve_SPR.png"}, {"analysis": "The CplxWA curve here also shows a steady improvement in both training and validation sets, with the validation curve closely tracking the training curve. This indicates that the model is learning effectively and generalizes well to unseen data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/cplxwa_curve_SPR.png"}, {"analysis": "The bar chart shows the test CplxWA metric performance across datasets. The value is around 0.35, which provides insight into how well the model performs on the complexity-weighted accuracy metric on the test set. This value can be compared with SOTA benchmarks for further evaluation.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/test_cplxwa_summary.png"}, {"analysis": "The bar chart displays the test CWA metric across datasets, with a value of approximately 0.35. This metric evaluates the model's ability to perform color-weighted accuracy on the test set, and the result should be compared with the SOTA benchmarks for a complete analysis.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/test_cwa_summary.png"}, {"analysis": "The bar chart presents the test SWA metric across datasets, with a value of approximately 0.35. This metric evaluates the model's shape-weighted accuracy on the test set. Comparing this value with SOTA benchmarks will help determine the model's effectiveness in capturing shape-based relationships.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_422022399694414b9a91937644eab0d1_proc_1493252/test_swa_summary.png"}], [], [{"analysis": "The training loss consistently decreases over the epochs, indicating that the model is learning the training data effectively. However, the validation loss starts increasing after epoch 6, which could suggest overfitting. This implies that the model may be memorizing the training data rather than generalizing well to unseen data. Regularization techniques or early stopping might be necessary to address this issue.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/loss_20250830_210606.png"}, {"analysis": "The validation complexity-weighted accuracy (CplxWA) fluctuates significantly across epochs, demonstrating a lack of stability in the model's performance. This could indicate that the model is struggling to generalize well or that the training process is not robust. Further tuning of hyperparameters or adjustments to the learning rate might help stabilize these results.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/cplxwa_20250830_210606.png"}, {"analysis": "The training and validation loss curves both decrease steadily, with validation loss closely following the training loss. This indicates that the model is learning effectively and generalizing well to the validation set. The absence of significant divergence between the two curves suggests that overfitting is not a concern in this case.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/loss_20250830_211037.png"}, {"analysis": "The validation complexity-weighted accuracy (CplxWA) improves consistently over the epochs, reaching a high value of 0.98. This indicates that the model is effectively learning the task and achieving strong generalization performance. The steady improvement suggests that the training process is stable and well-tuned.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/cplxwa_20250830_211037.png"}, {"analysis": "The loss curves for both training and validation show a steady decrease over the epochs, with validation loss following closely behind training loss. This suggests effective learning and good generalization to the validation set. The absence of divergence between the curves indicates that the model is not overfitting.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/spr_bench_loss_curve.png"}, {"analysis": "The validation complexity-weighted accuracy (CplxWA) shows a consistent upward trend, reaching a high value of 0.98. This demonstrates that the model is learning effectively and generalizing well to the validation set. The steady improvement highlights the stability of the training process and the model's ability to capture the underlying patterns in the data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/spr_bench_val_cplxwa_curve.png"}, {"analysis": "The scatter plot comparing test predictions with ground truth shows some deviation from the ideal diagonal line, indicating that the model's predictions are not perfectly aligned with the ground truth. The spread of points suggests that while the model performs reasonably well, there is room for improvement in its predictive accuracy. Further tuning or enhancements to the model architecture might help reduce these discrepancies.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_d0bfd2ab1cb04824a932d6da878df636_proc_1493253/spr_bench_test_pred_vs_gt.png"}], [{"analysis": "The loss curves for both training and validation show a consistent downward trend, indicating that the model is learning effectively. The training loss decreases steadily, and the validation loss closely follows it, suggesting that the model is not overfitting. The slight fluctuation at the end of the validation loss curve could indicate some instability, but it is not significant.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/loss_20250830_210852.png"}, {"analysis": "The Validation CplxWA curve demonstrates a clear upward trend, indicating that the model's performance on the validation set improves consistently over epochs. The metric surpasses 0.95 by the final epoch, which is a strong indicator of the model's ability to handle complex weighted accuracy effectively.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/cplxwa_20250830_210852.png"}, {"analysis": "This plot confirms the loss trends seen previously, with both training and validation losses decreasing steadily. The alignment of the curves further supports the conclusion that the model is generalizing well and not overfitting.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/loss_curve_SPR_BENCH.png"}, {"analysis": "The Validation CWA curve shows consistent improvement over epochs, surpassing 0.95 by the final epoch. This indicates that the model is capturing and leveraging color-based information effectively in its predictions.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/val_cwa_SPR_BENCH.png"}, {"analysis": "The Validation SWA curve also shows steady improvement, reaching above 0.95 by the end of training. This suggests that the model is effectively capturing shape-based dependencies within the data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/val_swa_SPR_BENCH.png"}, {"analysis": "The Validation CplxWA plot mirrors the trends seen in the earlier CplxWA curve, with performance improving steadily over epochs. The final value nearing 1.0 indicates a high level of accuracy in handling complex weighted accuracy metrics.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/val_cplxwa_SPR_BENCH.png"}, {"analysis": "The bar plot for Test CplxWA shows a perfect score of 1.0, indicating that the model performs exceptionally well on the test set for this specific metric. This is a strong validation of the model's ability to generalize and handle complex weighted accuracy effectively.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_e78be9bcc34648e591f8982238addc99_proc_1493251/summary_test_cplxwa.png"}], [{"analysis": "This plot demonstrates the loss trends for both the training and validation sets over 8 epochs of training. While the training loss steadily decreases, the validation loss exhibits an upward trend after the initial epochs. This divergence suggests potential overfitting, where the model performs well on the training data but struggles to generalize to unseen validation data. Adjustments such as regularization, dropout, or early stopping may help mitigate this issue.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/loss_20250830_210615.png"}, {"analysis": "This plot shows the validation CplxWA (complex weighted accuracy) across epochs. The metric fluctuates significantly, indicating instability in the model's performance during training. This could be due to an inappropriate learning rate, insufficient training data, or excessive complexity in the model. Smoothing the fluctuations might require hyperparameter tuning or additional data preprocessing.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/cplxwa_20250830_210615.png"}, {"analysis": "This plot represents the loss trends for both training and validation sets over 6 epochs. The training loss consistently decreases, showing good optimization. However, the validation loss increases slightly after the initial epochs, hinting at possible overfitting. This trend is less pronounced than in the earlier loss plot, suggesting some improvement in generalization. Further tuning might still be necessary to close the gap between training and validation performance.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/loss_curve_SPR_synth_spr_rgcn.png"}, {"analysis": "This plot tracks validation CompWA (composite weighted accuracy) across epochs. The metric demonstrates an initial rise, followed by a drop and subsequent recovery. This pattern suggests that the model struggles to stabilize its learning, potentially due to overfitting or suboptimal hyperparameters. The recovery towards the end is promising, but further refinements are needed to achieve consistent performance.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/val_compwa_curve_SPR_synth_spr_rgcn.png"}, {"analysis": "This plot presents the test CompWA on the SPR_synth dataset using the spr_rgcn model. The metric reaches approximately 0.3, which appears relatively low. This result suggests that the model's ability to generalize to unseen test data is limited. Further experimentation, such as improving the graph representation or incorporating additional edge information, may enhance performance.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ff2fd71ce327416fb1dfe9fe203050f7_proc_1493250/test_compwa_SPR_synth_spr_rgcn.png"}], [{"analysis": "The training loss decreases steadily over the epochs, indicating that the model is learning effectively from the training data. However, the validation loss remains relatively flat and even increases slightly over time, suggesting potential overfitting or poor generalization to the validation data. This could imply that the model is not capturing the underlying patterns in the data effectively or that the training process needs regularization or better hyperparameter tuning.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_c2133c5cdcb84161a5a0079d93484e5c_proc_1493252/spr_bench_loss_curve.png"}, {"analysis": "The training complexity-weighted accuracy (CompWA) improves steadily over the epochs, suggesting that the model is capturing more complex patterns in the training data. However, the validation CompWA shows significant fluctuations and remains much lower than the training accuracy, indicating poor generalization to unseen data. This discrepancy may point to overfitting or a need for better model architecture or training strategies.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_c2133c5cdcb84161a5a0079d93484e5c_proc_1493252/spr_bench_compwa_curve.png"}, {"analysis": "The test complexity-weighted accuracy (CompWA) is approximately 0.35, which is significantly lower than the SOTA benchmarks (CWA: 65.0%, SWA: 70.0%). This highlights that the current model design is not performing competitively on the SPR_BENCH dataset. Improving the model architecture, incorporating additional edge features, or performing more extensive hyperparameter optimization may be necessary to achieve better results.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_c2133c5cdcb84161a5a0079d93484e5c_proc_1493252/summary_test_compwa.png"}], [{"analysis": "This plot shows the training and validation loss over 10 epochs. Both curves decrease steadily, indicating that the model is learning effectively. The validation loss is consistently lower than the training loss after epoch 3, which suggests good generalization and no signs of overfitting.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/loss_20250830_211244.png"}, {"analysis": "This plot displays the progression of Validation CplxWA over 10 epochs. The metric improves steadily, reaching above 0.95 by the final epoch. This demonstrates that the model is effectively capturing the complexity-weighted accuracy on the validation set, with significant improvements after epoch 2.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/cplxwa_20250830_211244.png"}, {"analysis": "This plot is a duplicate of the first one, showing training and validation loss over 10 epochs. The analysis remains the same: steady learning with good generalization and no overfitting.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/loss_curve_SPR_BENCH.png"}, {"analysis": "This plot illustrates the progression of Validation CWA over 10 epochs. The metric shows consistent improvement, surpassing 0.95 by the final epoch. This indicates that the model is effectively capturing the color-weighted accuracy on the validation set.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/val_cwa_SPR_BENCH.png"}, {"analysis": "This plot shows the progression of Validation SWA over 10 epochs. The metric improves steadily, reaching above 0.95 by the final epoch. This indicates that the model is effectively capturing the shape-weighted accuracy on the validation set, with significant improvements after epoch 2.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/val_swa_SPR_BENCH.png"}, {"analysis": "This plot is a duplicate of the second one, showing the progression of Validation CplxWA over 10 epochs. The analysis remains the same: significant improvement in complexity-weighted accuracy, reaching above 0.95 by the final epoch.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/val_cplxwa_SPR_BENCH.png"}, {"analysis": "This plot shows the Test CplxWA performance for the SPR_BENCH dataset. The metric achieves a perfect score of 1.0, indicating that the model performs exceptionally well on the test set and effectively captures the complexity-weighted accuracy.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/summary_test_cplxwa.png"}], [{"analysis": "The loss curves for training and validation show a consistent decrease across epochs, indicating that the model is learning effectively. The validation loss closely tracks the training loss, suggesting that the model is not overfitting and generalizes well to unseen data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/loss_20250830_211207.png"}, {"analysis": "The validation CplxWA metric improves steadily across epochs, indicating that the model's ability to handle complex weighted accuracy is enhancing as training progresses. The upward trajectory suggests that the model is effectively capturing the relationships and patterns in the data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/cplxwa_20250830_211207.png"}, {"analysis": "The loss curves show a similar trend to the previous plot, with both training and validation losses decreasing steadily. The alignment between the two curves further confirms the absence of overfitting and a good generalization capability.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/loss_curve_SPR_BENCH.png"}, {"analysis": "The validation CWA metric increases consistently across epochs, reaching a high value by the end of training. This demonstrates that the model is progressively improving its performance on color-weighted accuracy, likely due to its ability to capture color-based relationships effectively.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/val_cwa_SPR_BENCH.png"}, {"analysis": "The validation SWA metric shows a steady improvement over epochs, similar to the CWA metric. This indicates that the model is learning to recognize shape-based relationships in the sequences, contributing to its overall performance improvement.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/val_swa_SPR_BENCH.png"}, {"analysis": "The validation CplxWA metric follows a consistent upward trend, similar to the earlier CplxWA plot. This reinforces the conclusion that the model is effectively capturing complex weighted relationships in the data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/val_cplxwa_SPR_BENCH.png"}, {"analysis": "The test CplxWA metric achieves a very high value, indicating that the model performs exceptionally well on the test dataset. This suggests that the model has successfully generalized the learned patterns and relationships to unseen data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/summary_test_cplxwa.png"}], [{"analysis": "The plot shows a consistent decrease in both training and validation loss over epochs, indicating that the model is learning effectively. The gap between training and validation loss is minimal, suggesting that the model is not overfitting and generalizes well to unseen data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/loss_20250830_211208.png"}, {"analysis": "The plot illustrates a steady improvement in the validation CplxWA metric over epochs. This indicates that the model is progressively capturing the complexity-weighted accuracy of the sequences, which aligns with the goal of leveraging GNNs for better structural understanding.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/cplxwa_20250830_211208.png"}, {"analysis": "This plot reaffirms the consistent decrease in loss for both training and validation datasets. The trends are smooth, and the alignment between the curves further supports the conclusion that the model is not overfitting and is learning effectively.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/loss_curve_SPR_BENCH.png"}, {"analysis": "The validation CWA metric improves steadily over epochs, showing that the model is increasingly capturing the color-weighted accuracy of the sequences. This trend indicates that the GNN is effectively learning to represent color-based relationships in the data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/val_cwa_SPR_BENCH.png"}, {"analysis": "The validation SWA metric shows a consistent rise over epochs. This suggests that the model is improving its ability to capture shape-weighted accuracy, which is critical for the SPR task. The trend is smooth, indicating stable learning behavior.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/val_swa_SPR_BENCH.png"}, {"analysis": "The validation CplxWA metric improves progressively over epochs, demonstrating that the model is enhancing its performance in capturing the complexity-weighted accuracy of the sequences. This metric aligns with the hypothesis that GNNs can better model relational data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/val_cplxwa_SPR_BENCH.png"}, {"analysis": "The bar plot shows that the test CplxWA metric achieves a perfect score of 1.0. This suggests that the model has generalized exceptionally well to unseen data and has fully captured the complexity-weighted accuracy of the sequences in the test dataset.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/summary_test_cplxwa.png"}], []], "vlm_feedback_summary": ["The plots provide insights into the training dynamics and validation performance\nacross different batch sizes. Lower batch sizes (16 and 32) show stable\nperformance with minimal overfitting, while larger batch sizes (64 and 128)\nexhibit signs of overfitting and instability. A batch size of 64 achieves the\nhighest Test Composite Weighted Accuracy, suggesting it is optimal for this\ntask.", "[]", "[]", "The plots indicate steady learning progress, with both loss and performance\nmetrics improving over epochs. The model demonstrates good generalization\nability, as evidenced by the alignment of training and validation curves for\nCplxWA. The test metrics (CplxWA, CWA, SWA) are around 0.35, which should be\ncompared against SOTA benchmarks for a comprehensive assessment.", "[]", "The plots provide a mix of insights, highlighting both strengths and areas for\nimprovement in the model's performance. While some plots indicate effective\nlearning and generalization, others suggest potential overfitting or instability\nin the training process. The validation complexity-weighted accuracy shows\npromising trends in some cases, but fluctuations in other instances point to the\nneed for further optimization and tuning.", "The plots indicate that the GNN-based model performs exceptionally well on the\nSPR_BENCH benchmark. Both training and validation losses decrease steadily, and\nthe evaluation metrics (CWA, SWA, and CplxWA) show consistent improvement, with\ntest CplxWA achieving a perfect score. These results strongly support the\nhypothesis that GNNs can effectively capture relational and structural\ninformation in symbolic sequences, outperforming SOTA benchmarks.", "The plots indicate issues with overfitting and instability in model performance.\nTraining loss decreases consistently, but validation loss trends upward, hinting\nat generalization challenges. Validation metrics show significant fluctuations,\nsuggesting the need for hyperparameter tuning or improved model design. Test\nperformance remains relatively low, underscoring the need for further\nrefinements to achieve competitive results.", "The plots reveal that while the model is learning effectively on the training\ndata, it struggles to generalize to validation and test datasets. The validation\nloss and accuracy metrics indicate overfitting, and the test accuracy falls\nsignificantly short of SOTA benchmarks. Further improvements in model design,\ntraining strategies, and hyperparameter tuning are required to achieve\ncompetitive performance.", "The provided plots indicate that the proposed GNN model performs exceptionally\nwell in the Synthetic PolyRule Reasoning (SPR) task. Both the training and\nvalidation loss curves suggest effective learning and generalization. The\nvalidation metrics (CWA, SWA, and CplxWA) consistently improve over epochs,\nsurpassing 0.95 by the final epoch. The test set performance reaches a perfect\nscore of 1.0 for CplxWA, showcasing the model's ability to generalize and\noutperform existing benchmarks.", "The experimental plots demonstrate that the proposed GNN-based model is\neffective in learning and generalizing the structural and relational information\nin the SPR task. The steady improvement in validation metrics (CWA, SWA, and\nCplxWA) and the alignment between training and validation loss curves indicate\nrobust training and generalization. The high test CplxWA value confirms the\nmodel's superior performance on unseen data, suggesting that it has likely\nsurpassed the SOTA benchmarks.", "The results show consistent improvement in metrics such as CWA, SWA, and CplxWA\nover epochs, with the test CplxWA achieving a perfect score. The model\ndemonstrates strong generalization and effective learning of relational data,\nsupporting the hypothesis that GNNs enhance performance on the SPR task.", "[]"], "exec_time": [9.628192663192749, 6.787445545196533, 4.331623077392578, 3.4797253608703613, 4.329027414321899, 114.82497215270996, 19.58016037940979, 3.5282928943634033, 9.862549304962158, 57.31904673576355, 19.40119481086731, 20.698872566223145, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[\"SPR_synth_bs16\"", "\"SPR_synth_bs32\"", "\"synthetic_bs16\"]"], [], [], ["\"\""], [], ["[\"spr_bench\"]"], ["['SPR_BENCH']"], ["[]"], ["[]"], ["['SPR_BENCH']"], ["\"\""], ["['<list_datasets_successfully_tested>']"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- figure generation -------------------------------------------------\ntest_scores = {}  # batch_size -> test CompWA\ndataset_type = experiment_data.get(\"dataset_type\", \"SPR_synth\")\n\nfor key, subdict in experiment_data.get(\"batch_size\", {}).items():\n    try:\n        bs = key.split(\"_\")[-1]\n        epochs = subdict[\"epochs\"]\n        tr_loss = subdict[\"losses\"][\"train\"]\n        va_loss = subdict[\"losses\"][\"val\"]\n        va_comp = subdict[\"metrics\"][\"val_compwa\"]\n        test_scores[int(bs)] = subdict[\"metrics\"][\"test_compwa\"]\n\n        # ---- Loss curve ------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(epochs, tr_loss, label=\"Train\")\n            plt.plot(epochs, va_loss, label=\"Validation\")\n            plt.title(f\"Loss Curve (Dataset: {dataset_type}, BS={bs})\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.legend()\n            fname = f\"loss_curve_{dataset_type}_bs{bs}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n        except Exception as e:\n            print(f\"Error creating loss plot for bs={bs}: {e}\")\n        finally:\n            plt.close()\n\n        # ---- CompWA curve ----------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(epochs, va_comp)\n            plt.title(f\"Validation CompWA (Dataset: {dataset_type}, BS={bs})\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"CompWA\")\n            fname = f\"compwa_curve_{dataset_type}_bs{bs}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n        except Exception as e:\n            print(f\"Error creating CompWA plot for bs={bs}: {e}\")\n        finally:\n            plt.close()\n\n    except Exception as e:\n        print(f\"Unexpected error while plotting for {key}: {e}\")\n\n# ---------- summary bar plot (max 1 figure) ----------------------------------\ntry:\n    if test_scores:\n        plt.figure()\n        bs_vals = list(test_scores.keys())\n        scores = [test_scores[bs] for bs in bs_vals]\n        plt.bar([str(b) for b in bs_vals], scores)\n        plt.title(f\"Test CompWA by Batch Size (Dataset: {dataset_type})\")\n        plt.xlabel(\"Batch Size\")\n        plt.ylabel(\"Test CompWA\")\n        fname = f\"test_compwa_summary_{dataset_type}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    else:\n        print(\"No test CompWA data found to plot.\")\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\nfinally:\n    plt.close()\n\n# ---------- print evaluation metrics -----------------------------------------\nif test_scores:\n    print(\"\\n=== Test CompWA by batch size ===\")\n    for bs, sc in sorted(test_scores.items()):\n        print(f\"  bs={bs:>3}: {sc:.4f}\")\n    best_bs = max(test_scores, key=test_scores.get)\n    print(f\"\\nBest batch size: {best_bs}  (CompWA={test_scores[best_bs]:.4f})\")\n", null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# ---------- helper to down-sample epochs if needed ---------------------------\ndef subsample(xs, ys, max_pts=100):\n    if len(xs) <= max_pts:\n        return xs, ys\n    idx = np.linspace(0, len(xs) - 1, num=max_pts, dtype=int)\n    return [xs[i] for i in idx], [ys[i] for i in idx]\n\n\n# ---------- plotting ----------------------------------------------------------\ntest_summary = {}  # dataset -> dict of test metrics\nfor dset, d in experiment_data.items():\n    epochs = d.get(\"epochs\", [])\n    # ---------- Loss curve ----------------------------------------------------\n    try:\n        tr_loss = d[\"losses\"][\"train\"]\n        va_loss = d[\"losses\"][\"val\"]\n        ep_x, tr_loss = subsample(epochs, tr_loss)\n        _, va_loss = subsample(epochs, va_loss)\n        plt.figure()\n        plt.plot(ep_x, tr_loss, label=\"Train\")\n        plt.plot(ep_x, va_loss, label=\"Validation\")\n        plt.title(f\"Loss Curve ({dset})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        fname = f\"loss_curve_{dset}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating loss curve for {dset}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- CplxWA curve --------------------------------------------------\n    try:\n        tr_cplx = d[\"metrics\"][\"train_cplxwa\"]\n        va_cplx = d[\"metrics\"][\"val_cplxwa\"]\n        ep_x, tr_cplx = subsample(epochs, tr_cplx)\n        _, va_cplx = subsample(epochs, va_cplx)\n        plt.figure()\n        plt.plot(ep_x, tr_cplx, label=\"Train\")\n        plt.plot(ep_x, va_cplx, label=\"Validation\")\n        plt.title(f\"CplxWA Curve ({dset})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CplxWA\")\n        plt.legend()\n        fname = f\"cplxwa_curve_{dset}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating CplxWA curve for {dset}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- collect test metrics -----------------------------------------\n    tmet = {k: v for k, v in d[\"metrics\"].items() if k.startswith(\"test_\")}\n    test_summary[dset] = tmet\n\n# ---------- bar plot of test metrics -----------------------------------------\ntry:\n    for metric in [\"test_cplxwa\", \"test_cwa\", \"test_swa\"]:\n        if not any(metric in v for v in test_summary.values()):\n            continue\n        plt.figure()\n        names, vals = [], []\n        for ds, m in test_summary.items():\n            if metric in m:\n                names.append(ds)\n                vals.append(m[metric])\n        plt.bar(names, vals)\n        plt.title(f\"{metric.replace('_', ' ').title()} Across Datasets\")\n        plt.ylabel(metric.replace(\"_\", \" \").title())\n        fname = f\"{metric}_summary.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\nfinally:\n    plt.close()\n\n# ---------- print evaluation metrics -----------------------------------------\nfor ds, m in test_summary.items():\n    print(f\"\\n=== {ds} test metrics ===\")\n    for k, v in m.items():\n        print(f\"{k}: {v:.4f}\")\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport random\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ned = experiment_data.get(\"spr_bench\", {})\nepochs = ed.get(\"epochs\", [])\ntrain_loss = ed.get(\"losses\", {}).get(\"train\", [])\nval_loss = ed.get(\"losses\", {}).get(\"val\", [])\nval_cplx = ed.get(\"metrics\", {}).get(\"val\", [])\ntest_cplx = ed.get(\"metrics\", {}).get(\"test\", None)\ngt = ed.get(\"ground_truth\", [])\npred = ed.get(\"predictions\", [])\n\n# ---------- Loss curve --------------------------------------------------------\ntry:\n    plt.figure()\n    plt.plot(epochs, train_loss, label=\"Train\")\n    plt.plot(epochs, val_loss, label=\"Validation\")\n    plt.title(\"SPR_BENCH \u2013 Loss Curve\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"spr_bench_loss_curve.png\")\n    plt.savefig(fname)\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\nfinally:\n    plt.close()\n\n# ---------- Validation CplxWA curve ------------------------------------------\ntry:\n    plt.figure()\n    plt.plot(epochs, val_cplx)\n    plt.title(\"SPR_BENCH \u2013 Validation Complexity-Weighted Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CplxWA\")\n    fname = os.path.join(working_dir, \"spr_bench_val_cplxwa_curve.png\")\n    plt.savefig(fname)\nexcept Exception as e:\n    print(f\"Error creating CplxWA curve: {e}\")\nfinally:\n    plt.close()\n\n# ---------- Prediction vs Ground-Truth scatter -------------------------------\ntry:\n    if gt and pred:\n        idx = random.sample(range(len(gt)), min(100, len(gt)))\n        plt.figure()\n        plt.scatter([gt[i] for i in idx], [pred[i] for i in idx], alpha=0.6)\n        lims = [min(gt + pred) - 0.5, max(gt + pred) + 0.5]\n        plt.plot(lims, lims, linestyle=\"--\", color=\"gray\")\n        plt.title(\"SPR_BENCH \u2013 Test Predictions vs Ground Truth\")\n        plt.xlabel(\"Ground Truth\")\n        plt.ylabel(\"Predictions\")\n        fname = os.path.join(working_dir, \"spr_bench_test_pred_vs_gt.png\")\n        plt.savefig(fname)\nexcept Exception as e:\n    print(f\"Error creating scatter plot: {e}\")\nfinally:\n    plt.close()\n\n# ---------- print evaluation metrics -----------------------------------------\nif val_cplx:\n    print(f\"Final Validation CplxWA: {val_cplx[-1]:.4f}\")\nif test_cplx is not None:\n    print(f\"Test  Complexity-Weighted Accuracy: {test_cplx:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- per-dataset plots -------------------------------------------------\ntest_cplx_summary = {}  # dataset -> test CplxWA\n\nfor ds_name, ed in experiment_data.items():\n    if not isinstance(ed, dict):\n        continue  # skip accidental non-dataset keys\n    epochs = ed.get(\"epochs\", [])\n    if not epochs:\n        continue\n\n    # ---------- Loss curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(epochs, ed[\"losses\"][\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name}: Loss Curve\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        fname = f\"loss_curve_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation CWA ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"CWA\"])\n        plt.title(f\"{ds_name}: Validation CWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CWA\")\n        fname = f\"val_cwa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating CWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation SWA ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"SWA\"])\n        plt.title(f\"{ds_name}: Validation SWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SWA\")\n        fname = f\"val_swa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating SWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation CplxWA --------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"CplxWA\"])\n        plt.title(f\"{ds_name}: Validation CplxWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CplxWA\")\n        fname = f\"val_cplxwa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating CplxWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- collect test metric ------------------------------------------\n    tst = ed.get(\"metrics\", {}).get(\"test\", {})\n    if \"CplxWA\" in tst:\n        test_cplx_summary[ds_name] = tst[\"CplxWA\"]\n\n    # ---------- print test metrics -------------------------------------------\n    if tst:\n        print(\n            f\"{ds_name}  Test CWA={tst.get('CWA', np.nan):.3f}  \"\n            f\"SWA={tst.get('SWA', np.nan):.3f}  \"\n            f\"CplxWA={tst.get('CplxWA', np.nan):.3f}\"\n        )\n\n# ---------- summary bar plot --------------------------------------------------\ntry:\n    if test_cplx_summary:\n        plt.figure()\n        names = list(test_cplx_summary.keys())\n        scores = [test_cplx_summary[n] for n in names]\n        plt.bar(names, scores)\n        plt.title(\"Test CplxWA by Dataset\")\n        plt.xlabel(\"Dataset\")\n        plt.ylabel(\"Test CplxWA\")\n        fname = \"summary_test_cplxwa.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    else:\n        print(\"No test CplxWA data found for summary plot.\")\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\nfinally:\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nrun_key = \"spr_rgcn\"\nrun_data = experiment_data.get(run_key, {})\nepochs = run_data.get(\"epochs\", [])\ntrain_loss = run_data.get(\"losses\", {}).get(\"train\", [])\nval_loss = run_data.get(\"losses\", {}).get(\"val\", [])\nval_compwa = run_data.get(\"metrics\", {}).get(\"val_compwa\", [])\ntest_compwa = run_data.get(\"metrics\", {}).get(\"test_compwa\", None)\ndataset_type = experiment_data.get(\"dataset_type\", \"SPR_synth\")\n\n# ---------- plotting ----------------------------------------------------------\n# 1. Loss curve\ntry:\n    if epochs and train_loss and val_loss:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train\")\n        plt.plot(epochs, val_loss, label=\"Validation\")\n        plt.title(f\"Loss Curve (Dataset: {dataset_type}, Model: {run_key})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        fname = f\"loss_curve_{dataset_type}_{run_key}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\nfinally:\n    plt.close()\n\n# 2. Validation CompWA curve\ntry:\n    if epochs and val_compwa:\n        plt.figure()\n        plt.plot(epochs, val_compwa, marker=\"o\")\n        plt.title(f\"Validation CompWA (Dataset: {dataset_type}, Model: {run_key})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CompWA\")\n        fname = f\"val_compwa_curve_{dataset_type}_{run_key}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\nexcept Exception as e:\n    print(f\"Error creating CompWA curve: {e}\")\nfinally:\n    plt.close()\n\n# 3. Test CompWA summary bar\ntry:\n    if test_compwa is not None:\n        plt.figure()\n        plt.bar([\"Test\"], [test_compwa])\n        plt.title(f\"Test CompWA (Dataset: {dataset_type}, Model: {run_key})\")\n        plt.ylabel(\"CompWA\")\n        fname = f\"test_compwa_{dataset_type}_{run_key}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\nexcept Exception as e:\n    print(f\"Error creating test CompWA bar: {e}\")\nfinally:\n    plt.close()\n\n# ---------- print evaluation metric ------------------------------------------\nif test_compwa is not None:\n    print(f\"Test Complexity-Weighted Accuracy: {test_compwa:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- collect test scores ----------------------------------------------\ntest_scores = {}\nfor dset, sub in experiment_data.items():\n    tst = sub[\"metrics\"].get(\"test_cplxwa\")\n    if tst is not None:\n        test_scores[dset] = tst\n\n# ---------- per-dataset plots -------------------------------------------------\nfor dset, sub in experiment_data.items():\n    epochs = sub.get(\"epochs\", [])\n    tr_loss = sub[\"losses\"].get(\"train\", [])\n    va_loss = sub[\"losses\"].get(\"val\", [])\n    tr_cplx = sub[\"metrics\"].get(\"train_cplxwa\", [])\n    va_cplx = sub[\"metrics\"].get(\"val_cplxwa\", [])\n\n    # ---- Loss curve ----------------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_loss, label=\"Train Loss\")\n        plt.plot(epochs, va_loss, label=\"Val Loss\")\n        plt.title(f\"{dset} Loss Curve\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dset.lower()}_loss_curve.png\")\n        plt.savefig(fname)\n    except Exception as e:\n        print(f\"Error creating loss plot for {dset}: {e}\")\n    finally:\n        plt.close()\n\n    # ---- CompWA curve --------------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_cplx, label=\"Train CompWA\")\n        plt.plot(epochs, va_cplx, label=\"Val CompWA\")\n        plt.title(f\"{dset} Complexity-Weighted Accuracy\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CompWA\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{dset.lower()}_compwa_curve.png\")\n        plt.savefig(fname)\n    except Exception as e:\n        print(f\"Error creating CompWA plot for {dset}: {e}\")\n    finally:\n        plt.close()\n\n# ---------- summary bar plot --------------------------------------------------\ntry:\n    if test_scores:\n        plt.figure()\n        names, vals = zip(*test_scores.items())\n        plt.bar(names, vals)\n        plt.title(\"Test Complexity-Weighted Accuracy Comparison\")\n        plt.xlabel(\"Dataset\")\n        plt.ylabel(\"Test CompWA\")\n        fname = os.path.join(working_dir, \"summary_test_compwa.png\")\n        plt.savefig(fname)\n    else:\n        print(\"No test CompWA data found.\")\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\nfinally:\n    plt.close()\n\n# ---------- print evaluation metrics -----------------------------------------\nfor dset, score in test_scores.items():\n    print(f\"{dset}: Test CompWA = {score:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- per-dataset plots -------------------------------------------------\ntest_cplx_summary = {}  # dataset -> test CplxWA\n\nfor ds_name, ed in experiment_data.items():\n    if not isinstance(ed, dict):\n        continue  # skip accidental non-dataset keys\n    epochs = ed.get(\"epochs\", [])\n    if not epochs:\n        continue\n\n    # ---------- Loss curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(epochs, ed[\"losses\"][\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name}: Loss Curve\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        fname = f\"loss_curve_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation CWA ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"CWA\"])\n        plt.title(f\"{ds_name}: Validation CWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CWA\")\n        fname = f\"val_cwa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating CWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation SWA ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"SWA\"])\n        plt.title(f\"{ds_name}: Validation SWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SWA\")\n        fname = f\"val_swa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating SWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation CplxWA --------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"CplxWA\"])\n        plt.title(f\"{ds_name}: Validation CplxWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CplxWA\")\n        fname = f\"val_cplxwa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating CplxWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- collect test metric ------------------------------------------\n    tst = ed.get(\"metrics\", {}).get(\"test\", {})\n    if \"CplxWA\" in tst:\n        test_cplx_summary[ds_name] = tst[\"CplxWA\"]\n\n    # ---------- print test metrics -------------------------------------------\n    if tst:\n        print(\n            f\"{ds_name}  Test CWA={tst.get('CWA', np.nan):.3f}  \"\n            f\"SWA={tst.get('SWA', np.nan):.3f}  \"\n            f\"CplxWA={tst.get('CplxWA', np.nan):.3f}\"\n        )\n\n# ---------- summary bar plot --------------------------------------------------\ntry:\n    if test_cplx_summary:\n        plt.figure()\n        names = list(test_cplx_summary.keys())\n        scores = [test_cplx_summary[n] for n in names]\n        plt.bar(names, scores)\n        plt.title(\"Test CplxWA by Dataset\")\n        plt.xlabel(\"Dataset\")\n        plt.ylabel(\"Test CplxWA\")\n        fname = \"summary_test_cplxwa.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    else:\n        print(\"No test CplxWA data found for summary plot.\")\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\nfinally:\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- per-dataset plots -------------------------------------------------\ntest_cplx_summary = {}  # dataset -> test CplxWA\n\nfor ds_name, ed in experiment_data.items():\n    if not isinstance(ed, dict):\n        continue  # skip accidental non-dataset keys\n    epochs = ed.get(\"epochs\", [])\n    if not epochs:\n        continue\n\n    # ---------- Loss curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(epochs, ed[\"losses\"][\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name}: Loss Curve\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        fname = f\"loss_curve_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation CWA ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"CWA\"])\n        plt.title(f\"{ds_name}: Validation CWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CWA\")\n        fname = f\"val_cwa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating CWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation SWA ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"SWA\"])\n        plt.title(f\"{ds_name}: Validation SWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SWA\")\n        fname = f\"val_swa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating SWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation CplxWA --------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"CplxWA\"])\n        plt.title(f\"{ds_name}: Validation CplxWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CplxWA\")\n        fname = f\"val_cplxwa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating CplxWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- collect test metric ------------------------------------------\n    tst = ed.get(\"metrics\", {}).get(\"test\", {})\n    if \"CplxWA\" in tst:\n        test_cplx_summary[ds_name] = tst[\"CplxWA\"]\n\n    # ---------- print test metrics -------------------------------------------\n    if tst:\n        print(\n            f\"{ds_name}  Test CWA={tst.get('CWA', np.nan):.3f}  \"\n            f\"SWA={tst.get('SWA', np.nan):.3f}  \"\n            f\"CplxWA={tst.get('CplxWA', np.nan):.3f}\"\n        )\n\n# ---------- summary bar plot --------------------------------------------------\ntry:\n    if test_cplx_summary:\n        plt.figure()\n        names = list(test_cplx_summary.keys())\n        scores = [test_cplx_summary[n] for n in names]\n        plt.bar(names, scores)\n        plt.title(\"Test CplxWA by Dataset\")\n        plt.xlabel(\"Dataset\")\n        plt.ylabel(\"Test CplxWA\")\n        fname = \"summary_test_cplxwa.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    else:\n        print(\"No test CplxWA data found for summary plot.\")\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\nfinally:\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- per-dataset plots -------------------------------------------------\ntest_cplx_summary = {}  # dataset -> test CplxWA\n\nfor ds_name, ed in experiment_data.items():\n    if not isinstance(ed, dict):\n        continue  # skip accidental non-dataset keys\n    epochs = ed.get(\"epochs\", [])\n    if not epochs:\n        continue\n\n    # ---------- Loss curve ----------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(epochs, ed[\"losses\"][\"val\"], label=\"Validation\")\n        plt.title(f\"{ds_name}: Loss Curve\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        fname = f\"loss_curve_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation CWA ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"CWA\"])\n        plt.title(f\"{ds_name}: Validation CWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CWA\")\n        fname = f\"val_cwa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating CWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation SWA ------------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"SWA\"])\n        plt.title(f\"{ds_name}: Validation SWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SWA\")\n        fname = f\"val_swa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating SWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- Validation CplxWA --------------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, ed[\"metrics\"][\"val\"][\"CplxWA\"])\n        plt.title(f\"{ds_name}: Validation CplxWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CplxWA\")\n        fname = f\"val_cplxwa_{ds_name}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating CplxWA plot for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------- collect test metric ------------------------------------------\n    tst = ed.get(\"metrics\", {}).get(\"test\", {})\n    if \"CplxWA\" in tst:\n        test_cplx_summary[ds_name] = tst[\"CplxWA\"]\n\n    # ---------- print test metrics -------------------------------------------\n    if tst:\n        print(\n            f\"{ds_name}  Test CWA={tst.get('CWA', np.nan):.3f}  \"\n            f\"SWA={tst.get('SWA', np.nan):.3f}  \"\n            f\"CplxWA={tst.get('CplxWA', np.nan):.3f}\"\n        )\n\n# ---------- summary bar plot --------------------------------------------------\ntry:\n    if test_cplx_summary:\n        plt.figure()\n        names = list(test_cplx_summary.keys())\n        scores = [test_cplx_summary[n] for n in names]\n        plt.bar(names, scores)\n        plt.title(\"Test CplxWA by Dataset\")\n        plt.xlabel(\"Dataset\")\n        plt.ylabel(\"Test CplxWA\")\n        fname = \"summary_test_cplxwa.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    else:\n        print(\"No test CplxWA data found for summary plot.\")\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\nfinally:\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom collections import defaultdict\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load all experiment data -----------------------------------------\nexperiment_data_path_list = [\n    \"experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_01a41ffaf7174044b202d0bdfc69fb94_proc_1493252/experiment_data.npy\",\n    \"experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f1112e3e1d424da080930ebcd5200e6e_proc_1493250/experiment_data.npy\",\n    \"experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4285f9bbefc045f3aa4cb0c57e980b31_proc_1493251/experiment_data.npy\",\n]\n\nall_runs = []\nfor p in experiment_data_path_list:\n    try:\n        run = np.load(\n            os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p), allow_pickle=True\n        ).item()\n        all_runs.append(run)\n    except Exception as e:\n        print(f\"Error loading experiment data at {p}: {e}\")\n\n# ---------- aggregate by dataset ---------------------------------------------\ndatasets = defaultdict(list)  # dataset_name -> list of run_dicts with that dataset\nfor run in all_runs:\n    for ds_name, ds_dict in run.items():\n        if isinstance(ds_dict, dict):\n            datasets[ds_name].append(ds_dict)\n\nsummary_test_cplx = {}  # dataset -> (mean, sem)\n\nfor ds_name, runs in datasets.items():\n    # ---------------- align epochs -----------------\n    # find shortest epoch length present in all runs\n    epoch_lengths = [len(r.get(\"epochs\", [])) for r in runs if r.get(\"epochs\", [])]\n    if not epoch_lengths:\n        continue\n    min_len = min(epoch_lengths)\n    epochs = runs[0][\"epochs\"][:min_len]  # use first run's epoch list as reference\n\n    # ---------------- helper to stack metric arrays ---------------------------\n    def stack_metric(path_keys):\n        \"\"\"Extract metric arrays (same length) from all runs and stack.\"\"\"\n        arrays = []\n        for r in runs:\n            cur = r\n            try:\n                for k in path_keys:\n                    cur = cur[k]\n                cur = np.asarray(cur)[:min_len]\n                arrays.append(cur)\n            except Exception:\n                continue  # skip if any key missing\n        if not arrays:\n            return None, None\n        arr = np.stack(arrays, axis=0)  # shape (n_runs, min_len)\n        mean = arr.mean(axis=0)\n        sem = arr.std(axis=0, ddof=1) / np.sqrt(arr.shape[0])\n        return mean, sem\n\n    # ---------------- plot loss curve -----------------------------------------\n    try:\n        mean_train, sem_train = stack_metric([\"losses\", \"train\"])\n        mean_val, sem_val = stack_metric([\"losses\", \"val\"])\n        if mean_train is not None and mean_val is not None:\n            plt.figure()\n            plt.plot(epochs, mean_train, label=\"Train mean\", color=\"tab:blue\")\n            plt.fill_between(\n                epochs,\n                mean_train - sem_train,\n                mean_train + sem_train,\n                color=\"tab:blue\",\n                alpha=0.3,\n                label=\"Train \u00b1 SEM\",\n            )\n            plt.plot(epochs, mean_val, label=\"Val mean\", color=\"tab:orange\")\n            plt.fill_between(\n                epochs,\n                mean_val - sem_val,\n                mean_val + sem_val,\n                color=\"tab:orange\",\n                alpha=0.3,\n                label=\"Val \u00b1 SEM\",\n            )\n            plt.title(f\"{ds_name}: Loss Curve (mean \u00b1 SEM over {len(runs)} runs)\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.legend()\n            fname = f\"loss_curve_mean_{ds_name}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating aggregated loss curve for {ds_name}: {e}\")\n    finally:\n        plt.close()\n\n    # ---------------- common function for val metrics -------------------------\n    for metric in [\"CWA\", \"SWA\", \"CplxWA\"]:\n        try:\n            mean_m, sem_m = stack_metric([\"metrics\", \"val\", metric])\n            if mean_m is None:\n                continue\n            plt.figure()\n            plt.plot(epochs, mean_m, label=f\"{metric} mean\")\n            plt.fill_between(\n                epochs, mean_m - sem_m, mean_m + sem_m, alpha=0.3, label=\"\u00b1 SEM\"\n            )\n            plt.title(\n                f\"{ds_name}: Validation {metric} (mean \u00b1 SEM over {len(runs)} runs)\"\n            )\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(metric)\n            plt.legend()\n            fname = f\"val_{metric.lower()}_mean_{ds_name}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n        except Exception as e:\n            print(f\"Error creating aggregated {metric} plot for {ds_name}: {e}\")\n        finally:\n            plt.close()\n\n    # ---------------- aggregate test metrics ----------------------------------\n    test_vals = defaultdict(list)  # metric -> list of values\n    for r in runs:\n        tst = r.get(\"metrics\", {}).get(\"test\", {})\n        for m in [\"CWA\", \"SWA\", \"CplxWA\"]:\n            if m in tst:\n                test_vals[m].append(tst[m])\n    # compute means and sems\n    for m, vals in test_vals.items():\n        vals = np.asarray(vals)\n        mean_v = vals.mean()\n        sem_v = vals.std(ddof=1) / np.sqrt(len(vals))\n        if m == \"CplxWA\":\n            summary_test_cplx[ds_name] = (mean_v, sem_v)\n        print(f\"{ds_name} Test {m}: mean={mean_v:.3f} \u00b1 {sem_v:.3f} (n={len(vals)})\")\n\n# ---------- summary bar plot for test CplxWA ---------------------------------\ntry:\n    if summary_test_cplx:\n        plt.figure()\n        names = list(summary_test_cplx.keys())\n        means = [summary_test_cplx[n][0] for n in names]\n        sems = [summary_test_cplx[n][1] for n in names]\n        x = np.arange(len(names))\n        plt.bar(x, means, yerr=sems, capsize=4)\n        plt.xticks(x, names, rotation=45, ha=\"right\")\n        plt.title(\"Test CplxWA by Dataset (mean \u00b1 SEM)\")\n        plt.xlabel(\"Dataset\")\n        plt.ylabel(\"Test CplxWA\")\n        fname = \"summary_test_cplxwa_mean.png\"\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, fname))\n    else:\n        print(\"No aggregated test CplxWA data found for summary plot.\")\nexcept Exception as e:\n    print(f\"Error creating aggregated summary bar plot: {e}\")\nfinally:\n    plt.close()\n"], "plot_plan": ["We will first reload experiment_data.npy, safely unwrap the dictionary, and determine whether the run used the real SPR benchmark or the synthetic fallback (we infer from a boolean flag stored in the dict, otherwise default to \u201csynth\u201d).  For every batch-size sweep contained in experiment_data['batch_size'] we will extract the epoch list, the train/val loss histories, and the validation CompWA history.  A loop will then create up to four figure files\u2014one pair of curves (loss + CompWA) for each batch size\u2014each enclosed in an independent try-except so that a failure in one plot doesn\u2019t stop the rest.  We additionally aggregate the test CompWA values for all batch sizes and draw a single bar-chart summarising them (this is the fifth and final figure, keeping us within the 5-plot limit).  Plots are saved to the pre-created working directory with descriptive filenames that mention the dataset type and what is being visualised.  Every figure is closed after saving to avoid memory leaks.  Finally, the script prints the test CompWA table and highlights the best performing batch size so users can read the key metric straight from the console.  Only data found in the .npy file are plotted\u2014no values are fabricated or simulated.", null, null, "The solution will load the saved experiment_data.npy, iterate over every dataset it contains, and create standard visualizations while respecting the plotting constraints. For each dataset we first build loss and CplxWA training-vs-validation curves, ensuring every figure is wrapped in its own try-except block, titled clearly, saved with descriptive names, and closed immediately afterward. We next gather the test metrics (CplxWA, CWA, SWA) and display them in a compact bar chart\u2014again protected by try-except\u2014to give a quick performance overview. Only existing keys in the numpy dictionary are referenced, so no made-up values appear. If many epochs are present we subsample them so that at most five epoch-indexed images ever get produced, but typical runs will need only three plots total (loss curve, CplxWA curve, metric bar). Finally the script prints the test metrics to stdout for quick inspection. Everything lives in the working directory created at runtime, uses plain matplotlib, and closes figures to avoid memory leaks.", null, "The script will load the stored numpy dictionary, pull out the \u201cspr_bench\u201d sub-dict, and safely build three plots: (i) training vs validation loss, (ii) validation complexity-weighted accuracy, and (iii) a scatter of test predictions against ground truth (capped at 100 random points for readability). Each plot is enclosed in its own try-except so the rest of the script continues even if one figure fails. Titles always mention the dataset and clearly describe what is shown, while filenames follow the pattern spr_bench_[plotname].png and are saved into ./working. Figures are explicitly closed after saving to free memory. At the end, the script prints the final validation CplxWA and test CplxWA so downstream sweeps can pick them up. All processing relies solely on values already present in experiment_data.npy\u2014no synthetic numbers are introduced. The code remains short, standard matplotlib is used, and the required directory scaffolding is handled automatically.", "The script first locates and loads the saved experiment_data.npy file, then loops over every dataset entry it contains (e.g. \u201cSPR_BENCH\u201d).  For each dataset it extracts epochs, training / validation loss curves, and the three validation metrics (CWA, SWA, CplxWA).  Four separate figures are generated inside individual try-except blocks: (1) train vs val loss, (2) val CWA, (3) val SWA, and (4) val CplxWA; each plot is titled, saved in working_dir with a descriptive name, and the figure is always closed afterwards.  While processing each dataset the corresponding test metrics (CWA, SWA, CplxWA) are collected.  After all datasets are handled, a single summary bar-chart compares the test CplxWA scores across datasets.  Finally the script prints every dataset\u2019s test metrics so they are visible in the log.  All plotting is strictly limited to the data contained in experiment_data.npy and no extra figures beyond the five-plot limit per dataset are produced.  The code is concise, self-contained, and follows the matplotlib, file-handling, and naming guidelines given in the instructions.", "We will load the stored experiment_data.npy, extract the single run stored under the key spr_rgcn, and pull out its epochs, training/validation losses, validation CompWA curve and final test CompWA value. Three independent plots will be produced (loss curve, validation CompWA curve, and a summary bar containing the single test score) \u2013 each wrapped in its own try-except block with figures closed in a finally clause. File names will embed the dataset/model name for clarity and be saved under working_dir. After plotting, the script prints the test CompWA so users can quickly view the main metric in the console. All plotting follows plain matplotlib defaults and only uses data contained in experiment_data.npy. The total number of figures (3) is below the required maximum of five, satisfying the interval constraint. The resulting code is concise, self-contained, and ready to run in the current environment.", "We first load experiment_data.npy and extract per-dataset dictionaries. For each dataset we gather epochs, train/val losses, train/val complexity-weighted accuracy (CompWA) and the single stored test CompWA. We then create three visualizations inside separate try-except blocks: (1) a dual-curve loss plot (train vs validation), (2) a dual-curve CompWA plot (train vs validation), and (3) a summary bar plot comparing test CompWA across all datasets. All plots are titled clearly with the dataset name and saved into the working directory using descriptive filenames. Figures are always closed with plt.close() in both success and exception cases. We cap the total number of figures at three, satisfying the 5-figure limit. Finally, the script prints test CompWA for each dataset so users can see the numerical values alongside the plots.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": ["batch_size", null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["We first load experiment_data.npy from the working directory and convert the\nnumpy object back to a normal Python dict.   For every batch-size experiment\n(bs_16, bs_32, \u2026) we read the stored lists of losses and CompWA scores.   From\nthese we take the final training loss, the final validation loss, the best\nvalidation CompWA (max over epochs) and the single stored test CompWA.   Each\nexperiment name is printed first, followed by clearly labeled metric/value pairs\nrounded to four decimals.   The script runs immediately on execution and does\nnot generate any plots.", "The script below loads the saved experiment_data.npy file, extracts the losses\nand complexity-weighted accuracy (CplxWA) values, and prints the final or best\nnumbers with clear, explicit labels for the single dataset found (\u2018spr_bench\u2019).\nIt immediately executes when run and adheres to the required code-layout\nconstraints.", "Below is a small utility that immediately loads the stored numpy file, pulls out\nthe metrics, and prints the final-epoch training numbers together with the best\n(i.e., optimum) validation numbers and the test results, labelling everything\nexplicitly.", "The solution loads the saved NumPy dictionary from the working directory,\niterates over each dataset (only \u201cSPR\u201d here), and prints clearly-labelled metric\nvalues. For losses it reports the final training loss and the best (minimum)\nvalidation loss; for CplxWA it reports the final training value and the best\n(maximum) validation value. All test-set metrics are printed directly. No plots\nare produced, and the code runs immediately when executed.", "The script will (1) locate the \u201cworking\u201d directory, (2) load the stored numpy\ndictionary, (3) iterate through every dataset entry (here only \u201cSPR_BENCH\u201d), and\n(4) print either the best or the final value of every stored metric with\nexplicit, self-describing labels.  For training metrics the script outputs the\nfinal epoch value; for validation metrics it outputs the best value (lowest\nloss, highest accuracy); for test metrics it prints the single stored value.", "The script will load the saved numpy dictionary, iterate over every dataset key\n(e.g., \u201cspr_bench\u201d), pull out the stored losses and metrics, identify the\n\u201cfinal\u201d value for the training/validation losses (last element of each list),\ntake the best (max) validation complexity-weighted accuracy, and report the\nstored test complexity-weighted accuracy. It then prints the dataset name\nfollowed by the fully-qualified metric labels and their values.", "The script loads the saved experiment data from the \u201cworking\u201d directory,\nretrieves the loss curves and accuracy curves for training and validation, and\ncomputes the best values (minimum for losses, maximum for accuracies). It then\nreports these best-achieved results, followed by the single recorded metric\nvalues for the test split. All information is displayed with explicit dataset\nand metric names, and no plots are produced.", "The script loads the saved experiment data, iterates over each dataset contained\nwithin, and prints a concise summary of the final or best values for every\nrecorded metric. Specifically, it shows the final training loss, the final\nvalidation loss, the best validation complexity-weighted accuracy (highest\nacross epochs), and the test complexity-weighted accuracy. All execution happens\nat the global scope so the file runs immediately when executed.", "The script will load the NumPy file from the working directory, iterate over\nevery stored dataset (here only \u201cSPR_BENCH\u201d), and for each dataset print the\nbest value for every recorded metric or loss. \u201cBest\u201d is defined as the maximum\nfor accuracy\u2013like metrics and the minimum for loss values. After loading, it\ndirectly prints the dataset name followed by clear, descriptive metric names and\ntheir corresponding best values.", "The script loads the saved experiment data from the \u201cworking\u201d directory,\nretrieves the loss curves and accuracy curves for training and validation, and\ncomputes the best values (minimum for losses, maximum for accuracies). It then\nreports these best-achieved results, followed by the single recorded metric\nvalues for the test split. All information is displayed with explicit dataset\nand metric names, and no plots are produced.", "The script loads the saved experiment data from the \u201cworking\u201d directory,\nretrieves the loss curves and accuracy curves for training and validation, and\ncomputes the best values (minimum for losses, maximum for accuracies). It then\nreports these best-achieved results, followed by the single recorded metric\nvalues for the test split. All information is displayed with explicit dataset\nand metric names, and no plots are produced.", "The script loads the saved experiment data from the \u201cworking\u201d directory,\nretrieves the loss curves and accuracy curves for training and validation, and\ncomputes the best values (minimum for losses, maximum for accuracies). It then\nreports these best-achieved results, followed by the single recorded metric\nvalues for the test split. All information is displayed with explicit dataset\nand metric names, and no plots are produced.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ------------------ load ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------ helper to safely fetch values --------------------------\ndef safe_last(lst):\n    return lst[-1] if lst else None\n\n\ndef print_metric(name, value):\n    if value is not None:\n        print(f\"    {name}: {value:.4f}\")\n\n\n# ------------------ iterate over batch-size runs ---------------------------\nbs_dict = experiment_data.get(\"batch_size\", {})\nfor run_name, run_data in bs_dict.items():\n    print(run_name)  # dataset / run name\n\n    # losses\n    final_train_loss = safe_last(run_data[\"losses\"].get(\"train\", []))\n    final_val_loss = safe_last(run_data[\"losses\"].get(\"val\", []))\n\n    # CompWA scores\n    train_compwa_vals = run_data[\"metrics\"].get(\"train_compwa\", [])\n    val_compwa_vals = run_data[\"metrics\"].get(\"val_compwa\", [])\n    best_train_compwa = max(train_compwa_vals) if train_compwa_vals else None\n    best_val_compwa = max(val_compwa_vals) if val_compwa_vals else None\n    test_compwa = run_data[\"metrics\"].get(\"test_compwa\", None)\n\n    # print metrics with explicit names\n    print_metric(\"final training loss\", final_train_loss)\n    print_metric(\"final validation loss\", final_val_loss)\n    print_metric(\"best training CompWA\", best_train_compwa)\n    print_metric(\"best validation CompWA\", best_val_compwa)\n    print_metric(\"test CompWA\", test_compwa)\n", "import os\nimport numpy as np\n\n# ---------------- load ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------- report ----------------\nfor dataset_name, d in experiment_data.items():\n    print(f\"Dataset: {dataset_name}\")\n\n    # Final training loss\n    if d[\"losses\"][\"train\"]:\n        final_train_loss = d[\"losses\"][\"train\"][-1]\n        print(f\"Final training loss: {final_train_loss:.4f}\")\n\n    # Best validation loss\n    if d[\"losses\"][\"val\"]:\n        best_val_loss = min(d[\"losses\"][\"val\"])\n        print(f\"Best validation loss: {best_val_loss:.4f}\")\n\n    # Best validation complexity-weighted accuracy\n    val_cplx_list = [v for v in d[\"metrics\"][\"val\"] if v is not None]\n    if val_cplx_list:\n        best_val_cplx = max(val_cplx_list)\n        print(f\"Best validation complexity-weighted accuracy: {best_val_cplx:.4f}\")\n\n    # Test complexity-weighted accuracy (scalar stored directly)\n    test_cplx = d[\"metrics\"].get(\"test\", None)\n    if isinstance(test_cplx, (int, float)):\n        print(f\"Test complexity-weighted accuracy: {test_cplx:.4f}\")\n\n    print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\nrun = experiment_data[\"spr_rgcn\"]\n\n\n# helpers -----------------------------------------------------------------\ndef _best(values, higher_is_better=True):\n    \"\"\"Return best value (max or min) from a list.\"\"\"\n    return max(values) if higher_is_better else min(values)\n\n\n# -------------------- TRAIN ----------------------------------------------\nprint(\"TRAINING DATASET:\")\nfinal_train_loss = run[\"losses\"][\"train\"][-1]\nprint(f\"training loss (final epoch): {final_train_loss:.4f}\")\n\nfor metric_name in [\"CWA\", \"SWA\", \"CplxWA\"]:\n    final_val = run[\"metrics\"][\"train\"][metric_name][-1]\n    print(f\"training {metric_name} (final epoch): {final_val:.4f}\")\n\n# -------------------- VALIDATION -----------------------------------------\nprint(\"\\nVALIDATION DATASET:\")\nbest_val_loss = _best(run[\"losses\"][\"val\"], higher_is_better=False)\nprint(f\"validation loss (best): {best_val_loss:.4f}\")\n\nfor metric_name in [\"CWA\", \"SWA\", \"CplxWA\"]:\n    best_val = _best(run[\"metrics\"][\"val\"][metric_name], higher_is_better=True)\n    print(f\"validation {metric_name} (best): {best_val:.4f}\")\n\n# -------------------- TEST -----------------------------------------------\nprint(\"\\nTEST DATASET:\")\ntest_metrics = run[\"metrics\"][\"test\"]\nfor metric_name, value in test_metrics.items():\n    print(f\"test {metric_name}: {value:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------- helper to format floating numbers ----------\ndef fmt(num):\n    return f\"{num:.4f}\" if isinstance(num, (int, float)) else str(num)\n\n\n# ---------- iterate through datasets and report metrics ----------\nfor dataset_name, data_dict in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    metrics = data_dict.get(\"metrics\", {})\n    losses = data_dict.get(\"losses\", {})\n\n    # Training / validation losses\n    if losses.get(\"train\"):\n        print(\"Final training loss:\", fmt(losses[\"train\"][-1]))\n    if losses.get(\"val\"):\n        print(\"Best validation loss:\", fmt(min(losses[\"val\"])))\n\n    # Training / validation CplxWA\n    if metrics.get(\"train_cplxwa\"):\n        print(\"Final training CplxWA:\", fmt(metrics[\"train_cplxwa\"][-1]))\n    if metrics.get(\"val_cplxwa\"):\n        print(\"Best validation CplxWA:\", fmt(max(metrics[\"val_cplxwa\"])))\n\n    # Test-set metrics\n    if \"test_cplxwa\" in metrics:\n        print(\"Test CplxWA:\", fmt(metrics[\"test_cplxwa\"]))\n    if \"test_cwa\" in metrics:\n        print(\"Test CWA:\", fmt(metrics[\"test_cwa\"]))\n    if \"test_swa\" in metrics:\n        print(\"Test SWA:\", fmt(metrics[\"test_swa\"]))\n\n    print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# ---------- helpers ----------\nmetric_verbose = {\n    \"CWA\": \"color weighted accuracy\",\n    \"SWA\": \"shape weighted accuracy\",\n    \"CplxWA\": \"complexity weighted accuracy\",\n    \"loss\": \"loss\",\n}\n\n\ndef print_line(metric_key, phase, value, qualifier):\n    \"\"\"Unified pretty-printer.\"\"\"\n    name = metric_verbose.get(metric_key, metric_key)\n    print(f\"{phase} {name} ({qualifier}): {value:.4f}\")\n\n\n# ---------- iterate & report ----------\nfor dataset_name, data in experiment_data.items():\n    print(f\"\\n=== {dataset_name} ===\")\n    epochs = data.get(\"epochs\", [])\n    last_idx = -1 if epochs else None  # guard for empty case\n\n    # 1) losses -------------------------------------------------\n    train_losses = data[\"losses\"].get(\"train\", [])\n    if train_losses:\n        print_line(\"loss\", \"training\", train_losses[last_idx], \"final\")\n\n    val_losses = data[\"losses\"].get(\"val\", [])\n    if val_losses:\n        best_val_loss = min(val_losses)\n        print_line(\"loss\", \"validation\", best_val_loss, \"best\")\n\n    # 2) training metrics --------------------------------------\n    tr_metrics = data[\"metrics\"].get(\"train\", {})\n    for k, v in tr_metrics.items():\n        if v:  # non-empty list\n            print_line(k, \"training\", v[last_idx], \"final\")\n\n    # 3) validation metrics ------------------------------------\n    val_metrics = data[\"metrics\"].get(\"val\", {})\n    for k, v in val_metrics.items():\n        if v:\n            # higher is better for accuracies\n            best_val = max(v)\n            print_line(k, \"validation\", best_val, \"best\")\n\n    # 4) test metrics ------------------------------------------\n    test_metrics = data[\"metrics\"].get(\"test\", {})\n    for k, v in test_metrics.items():\n        print_line(k, \"test\", v, \"final\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------------------------------\n# locate and load the experiment data\n# -------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------------------------------\n# helper to print one metric if it exists\n# -------------------------------------------------------------------------\ndef _print_metric(label, value):\n    if value is not None:\n        print(f\"{label}: {value:.6f}\")\n\n\n# -------------------------------------------------------------------------\n# extract and display metrics for every dataset stored\n# -------------------------------------------------------------------------\nfor dataset_name, ds in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # losses --------------------------------------------------------------\n    train_losses = ds.get(\"losses\", {}).get(\"train\", [])\n    val_losses = ds.get(\"losses\", {}).get(\"val\", [])\n\n    final_train_loss = train_losses[-1] if train_losses else None\n    final_val_loss = val_losses[-1] if val_losses else None\n\n    _print_metric(\"final training loss\", final_train_loss)\n    _print_metric(\"final validation loss\", final_val_loss)\n\n    # validation metric ---------------------------------------------------\n    val_metrics = ds.get(\"metrics\", {}).get(\"val\", [])\n    best_val_cplx = max(val_metrics) if val_metrics else None\n    _print_metric(\"best validation complexity-weighted accuracy\", best_val_cplx)\n\n    # test metric ---------------------------------------------------------\n    test_cplx = ds.get(\"metrics\", {}).get(\"test\", None)\n    _print_metric(\"test complexity-weighted accuracy\", test_cplx)\n\n    print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ----------------- locate and load data -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ----------------- helper to find best values ------------\ndef best_value(values, higher_is_better=True):\n    if not values:  # empty list safety\n        return None\n    return max(values) if higher_is_better else min(values)\n\n\n# ----------------- extract and print ---------------------\nfor dataset_name, data in experiment_data.items():  # e.g. \"SPR_BENCH\"\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # ---- training split ----\n    tr_losses = data[\"losses\"][\"train\"]\n    tr_cwa = data[\"metrics\"][\"train\"][\"CWA\"]\n    tr_swa = data[\"metrics\"][\"train\"][\"SWA\"]\n    tr_cplx = data[\"metrics\"][\"train\"][\"CplxWA\"]\n\n    print(f\"best training loss: {best_value(tr_losses, higher_is_better=False):.4f}\")\n    print(f\"best training color-weighted accuracy: {best_value(tr_cwa):.4f}\")\n    print(f\"best training shape-weighted accuracy: {best_value(tr_swa):.4f}\")\n    print(f\"best training complexity-weighted accuracy: {best_value(tr_cplx):.4f}\")\n\n    # ---- validation split ----\n    val_losses = data[\"losses\"][\"val\"]\n    val_cwa = data[\"metrics\"][\"val\"][\"CWA\"]\n    val_swa = data[\"metrics\"][\"val\"][\"SWA\"]\n    val_cplx = data[\"metrics\"][\"val\"][\"CplxWA\"]\n\n    print(f\"best validation loss: {best_value(val_losses, higher_is_better=False):.4f}\")\n    print(f\"best validation color-weighted accuracy: {best_value(val_cwa):.4f}\")\n    print(f\"best validation shape-weighted accuracy: {best_value(val_swa):.4f}\")\n    print(f\"best validation complexity-weighted accuracy: {best_value(val_cplx):.4f}\")\n\n    # ---- test split (single values) ----\n    test_metrics = data[\"metrics\"].get(\"test\", {})\n    if test_metrics:\n        print(f\"test color-weighted accuracy: {test_metrics['CWA']:.4f}\")\n        print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.4f}\")\n        print(f\"test complexity-weighted accuracy: {test_metrics['CplxWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# -------------------- load data --------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"experiment_data.npy not found at {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# -------------------- parse & report --------------------\nfor dataset_name, data in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # Final losses\n    final_train_loss = data[\"losses\"][\"train\"][-1] if data[\"losses\"][\"train\"] else None\n    final_val_loss = data[\"losses\"][\"val\"][-1] if data[\"losses\"][\"val\"] else None\n\n    # Validation metric: take the best (max) value\n    val_compwa_scores = data[\"metrics\"].get(\"val_compwa\", [])\n    best_val_compwa = max(val_compwa_scores) if val_compwa_scores else None\n\n    # Test metric\n    test_compwa = data[\"metrics\"].get(\"test_compwa\")\n\n    # Print with explicit metric names\n    if final_train_loss is not None:\n        print(f\"Final training loss: {final_train_loss:.4f}\")\n    if final_val_loss is not None:\n        print(f\"Final validation loss: {final_val_loss:.4f}\")\n    if best_val_compwa is not None:\n        print(f\"Best validation complexity-weighted accuracy: {best_val_compwa:.4f}\")\n    if test_compwa is not None:\n        print(f\"Test complexity-weighted accuracy: {test_compwa:.4f}\")\n", "import os\nimport numpy as np\n\n# -------- load experiment data --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------- helper to decide best --------\ndef best_value(values, higher_is_better=True):\n    \"\"\"Return best (max or min) from list or scalar.\"\"\"\n    if isinstance(values, (list, np.ndarray)):\n        return max(values) if higher_is_better else min(values)\n    # single scalar already best\n    return values\n\n\n# -------- iterate and print --------\nfor dataset_name, data in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # Losses\n    for split_name, loss_values in data.get(\"losses\", {}).items():\n        metric_label = \"training loss\" if split_name == \"train\" else \"validation loss\"\n        print(f\"{metric_label}: {best_value(loss_values, higher_is_better=False):.4f}\")\n\n    # Accuracies or other metrics\n    for metric_key, metric_values in data.get(\"metrics\", {}).items():\n        if metric_key == \"train_cplxwa\":\n            label = \"training complexity-weighted accuracy\"\n            val = best_value(metric_values, higher_is_better=True)\n        elif metric_key == \"val_cplxwa\":\n            label = \"validation complexity-weighted accuracy\"\n            val = best_value(metric_values, higher_is_better=True)\n        elif metric_key == \"test_cplxwa\":\n            label = \"test complexity-weighted accuracy\"\n            val = metric_values  # scalar\n        else:  # fallback for any additional metrics\n            label = metric_key.replace(\"_\", \" \")\n            val = best_value(metric_values, higher_is_better=True)\n        print(f\"{label}: {val:.4f}\")\n", "import os\nimport numpy as np\n\n# ----------------- locate and load data -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ----------------- helper to find best values ------------\ndef best_value(values, higher_is_better=True):\n    if not values:  # empty list safety\n        return None\n    return max(values) if higher_is_better else min(values)\n\n\n# ----------------- extract and print ---------------------\nfor dataset_name, data in experiment_data.items():  # e.g. \"SPR_BENCH\"\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # ---- training split ----\n    tr_losses = data[\"losses\"][\"train\"]\n    tr_cwa = data[\"metrics\"][\"train\"][\"CWA\"]\n    tr_swa = data[\"metrics\"][\"train\"][\"SWA\"]\n    tr_cplx = data[\"metrics\"][\"train\"][\"CplxWA\"]\n\n    print(f\"best training loss: {best_value(tr_losses, higher_is_better=False):.4f}\")\n    print(f\"best training color-weighted accuracy: {best_value(tr_cwa):.4f}\")\n    print(f\"best training shape-weighted accuracy: {best_value(tr_swa):.4f}\")\n    print(f\"best training complexity-weighted accuracy: {best_value(tr_cplx):.4f}\")\n\n    # ---- validation split ----\n    val_losses = data[\"losses\"][\"val\"]\n    val_cwa = data[\"metrics\"][\"val\"][\"CWA\"]\n    val_swa = data[\"metrics\"][\"val\"][\"SWA\"]\n    val_cplx = data[\"metrics\"][\"val\"][\"CplxWA\"]\n\n    print(f\"best validation loss: {best_value(val_losses, higher_is_better=False):.4f}\")\n    print(f\"best validation color-weighted accuracy: {best_value(val_cwa):.4f}\")\n    print(f\"best validation shape-weighted accuracy: {best_value(val_swa):.4f}\")\n    print(f\"best validation complexity-weighted accuracy: {best_value(val_cplx):.4f}\")\n\n    # ---- test split (single values) ----\n    test_metrics = data[\"metrics\"].get(\"test\", {})\n    if test_metrics:\n        print(f\"test color-weighted accuracy: {test_metrics['CWA']:.4f}\")\n        print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.4f}\")\n        print(f\"test complexity-weighted accuracy: {test_metrics['CplxWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# ----------------- locate and load data -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ----------------- helper to find best values ------------\ndef best_value(values, higher_is_better=True):\n    if not values:  # empty list safety\n        return None\n    return max(values) if higher_is_better else min(values)\n\n\n# ----------------- extract and print ---------------------\nfor dataset_name, data in experiment_data.items():  # e.g. \"SPR_BENCH\"\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # ---- training split ----\n    tr_losses = data[\"losses\"][\"train\"]\n    tr_cwa = data[\"metrics\"][\"train\"][\"CWA\"]\n    tr_swa = data[\"metrics\"][\"train\"][\"SWA\"]\n    tr_cplx = data[\"metrics\"][\"train\"][\"CplxWA\"]\n\n    print(f\"best training loss: {best_value(tr_losses, higher_is_better=False):.4f}\")\n    print(f\"best training color-weighted accuracy: {best_value(tr_cwa):.4f}\")\n    print(f\"best training shape-weighted accuracy: {best_value(tr_swa):.4f}\")\n    print(f\"best training complexity-weighted accuracy: {best_value(tr_cplx):.4f}\")\n\n    # ---- validation split ----\n    val_losses = data[\"losses\"][\"val\"]\n    val_cwa = data[\"metrics\"][\"val\"][\"CWA\"]\n    val_swa = data[\"metrics\"][\"val\"][\"SWA\"]\n    val_cplx = data[\"metrics\"][\"val\"][\"CplxWA\"]\n\n    print(f\"best validation loss: {best_value(val_losses, higher_is_better=False):.4f}\")\n    print(f\"best validation color-weighted accuracy: {best_value(val_cwa):.4f}\")\n    print(f\"best validation shape-weighted accuracy: {best_value(val_swa):.4f}\")\n    print(f\"best validation complexity-weighted accuracy: {best_value(val_cplx):.4f}\")\n\n    # ---- test split (single values) ----\n    test_metrics = data[\"metrics\"].get(\"test\", {})\n    if test_metrics:\n        print(f\"test color-weighted accuracy: {test_metrics['CWA']:.4f}\")\n        print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.4f}\")\n        print(f\"test complexity-weighted accuracy: {test_metrics['CplxWA']:.4f}\")\n", "import os\nimport numpy as np\n\n# ----------------- locate and load data -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ----------------- helper to find best values ------------\ndef best_value(values, higher_is_better=True):\n    if not values:  # empty list safety\n        return None\n    return max(values) if higher_is_better else min(values)\n\n\n# ----------------- extract and print ---------------------\nfor dataset_name, data in experiment_data.items():  # e.g. \"SPR_BENCH\"\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # ---- training split ----\n    tr_losses = data[\"losses\"][\"train\"]\n    tr_cwa = data[\"metrics\"][\"train\"][\"CWA\"]\n    tr_swa = data[\"metrics\"][\"train\"][\"SWA\"]\n    tr_cplx = data[\"metrics\"][\"train\"][\"CplxWA\"]\n\n    print(f\"best training loss: {best_value(tr_losses, higher_is_better=False):.4f}\")\n    print(f\"best training color-weighted accuracy: {best_value(tr_cwa):.4f}\")\n    print(f\"best training shape-weighted accuracy: {best_value(tr_swa):.4f}\")\n    print(f\"best training complexity-weighted accuracy: {best_value(tr_cplx):.4f}\")\n\n    # ---- validation split ----\n    val_losses = data[\"losses\"][\"val\"]\n    val_cwa = data[\"metrics\"][\"val\"][\"CWA\"]\n    val_swa = data[\"metrics\"][\"val\"][\"SWA\"]\n    val_cplx = data[\"metrics\"][\"val\"][\"CplxWA\"]\n\n    print(f\"best validation loss: {best_value(val_losses, higher_is_better=False):.4f}\")\n    print(f\"best validation color-weighted accuracy: {best_value(val_cwa):.4f}\")\n    print(f\"best validation shape-weighted accuracy: {best_value(val_swa):.4f}\")\n    print(f\"best validation complexity-weighted accuracy: {best_value(val_cplx):.4f}\")\n\n    # ---- test split (single values) ----\n    test_metrics = data[\"metrics\"].get(\"test\", {})\n    if test_metrics:\n        print(f\"test color-weighted accuracy: {test_metrics['CWA']:.4f}\")\n        print(f\"test shape-weighted accuracy: {test_metrics['SWA']:.4f}\")\n        print(f\"test complexity-weighted accuracy: {test_metrics['CplxWA']:.4f}\")\n", ""], "parse_term_out": ["['bs_16', '\\n', '    final training loss: 1.0863', '\\n', '    final validation\nloss: 1.0917', '\\n', '    best validation CompWA: 0.3674', '\\n', '    test\nCompWA: 0.3728', '\\n', 'bs_32', '\\n', '    final training loss: 1.0901', '\\n', '\nfinal validation loss: 1.0975', '\\n', '    best validation CompWA: 0.3996',\n'\\n', '    test CompWA: 0.3939', '\\n', 'bs_64', '\\n', '    final training loss:\n1.0906', '\\n', '    final validation loss: 1.0936', '\\n', '    best validation\nCompWA: 0.4564', '\\n', '    test CompWA: 0.4111', '\\n', 'bs_128', '\\n', '\nfinal training loss: 1.0910', '\\n', '    final validation loss: 1.0937', '\\n', '\nbest validation CompWA: 0.3636', '\\n', '    test CompWA: 0.3576', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: spr_bench', '\\n', 'Final training loss: 1.3419', '\\n', 'Best\nvalidation loss: 1.3922', '\\n', 'Best validation complexity-weighted accuracy:\n0.2644', '\\n', 'Test complexity-weighted accuracy: 0.2599', '\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['TRAINING DATASET:', '\\n', 'training loss (final epoch): 1.0823', '\\n',\n'training CWA (final epoch): 0.4310', '\\n', 'training SWA (final epoch):\n0.4350', '\\n', 'training CplxWA (final epoch): 0.4281', '\\n', '\\nVALIDATION\nDATASET:', '\\n', 'validation loss (best): 1.0998', '\\n', 'validation CWA (best):\n0.3675', '\\n', 'validation SWA (best): 0.3757', '\\n', 'validation CplxWA (best):\n0.3724', '\\n', '\\nTEST DATASET:', '\\n', 'test CWA: 0.3002', '\\n', 'test SWA:\n0.3019', '\\n', 'test CplxWA: 0.2984', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['SPR', '\\n', 'Final training loss:', ' ', '1.0894', '\\n', 'Best validation\nloss:', ' ', '1.0855', '\\n', 'Final training CplxWA:', ' ', '0.3701', '\\n',\n'Best validation CplxWA:', ' ', '0.3707', '\\n', 'Test CplxWA:', ' ', '0.3418',\n'\\n', 'Test CWA:', ' ', '0.3465', '\\n', 'Test SWA:', ' ', '0.3465', '\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\n=== SPR_BENCH ===', '\\n', 'training loss (final): 1.0549', '\\n', 'validation\nloss (best): 1.0948', '\\n', 'training color weighted accuracy (final): 0.5449',\n'\\n', 'training shape weighted accuracy (final): 0.5471', '\\n', 'training\ncomplexity weighted accuracy (final): 0.5483', '\\n', 'validation color weighted\naccuracy (best): 0.3693', '\\n', 'validation shape weighted accuracy (best):\n0.3785', '\\n', 'validation complexity weighted accuracy (best): 0.3744', '\\n',\n'test color weighted accuracy (final): 0.3043', '\\n', 'test shape weighted\naccuracy (final): 0.3093', '\\n', 'test complexity weighted accuracy (final):\n0.3085', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['spr_bench', '\\n', 'final training loss: 0.071009', '\\n', 'final validation\nloss: 0.081347', '\\n', 'best validation complexity-weighted accuracy: 0.978600',\n'\\n', 'test complexity-weighted accuracy: 0.652421', '\\n', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'best training loss: 0.0793', '\\n', 'best\ntraining color-weighted accuracy: 0.9841', '\\n', 'best training shape-weighted\naccuracy: 0.9819', '\\n', 'best training complexity-weighted accuracy: 0.9839',\n'\\n', 'best validation loss: 0.0890', '\\n', 'best validation color-weighted\naccuracy: 0.9745', '\\n', 'best validation shape-weighted accuracy: 0.9711',\n'\\n', 'best validation complexity-weighted accuracy: 0.9737', '\\n', 'test color-\nweighted accuracy: 0.9784', '\\n', 'test shape-weighted accuracy: 0.9744', '\\n',\n'test complexity-weighted accuracy: 0.9770', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['\\nDataset: spr_rgcn', '\\n', 'Final training loss: 1.0567', '\\n', 'Final\nvalidation loss: 1.1371', '\\n', 'Best validation complexity-weighted accuracy:\n0.2969', '\\n', 'Test complexity-weighted accuracy: 0.3330', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'training loss: 1.0616', '\\n', 'validation loss:\n1.1037', '\\n', 'training complexity-weighted accuracy: 0.4552', '\\n',\n'validation complexity-weighted accuracy: 0.3425', '\\n', 'test complexity-\nweighted accuracy: 0.3557', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'best training loss: 0.0797', '\\n', 'best\ntraining color-weighted accuracy: 0.9831', '\\n', 'best training shape-weighted\naccuracy: 0.9806', '\\n', 'best training complexity-weighted accuracy: 0.9829',\n'\\n', 'best validation loss: 0.0917', '\\n', 'best validation color-weighted\naccuracy: 0.9752', '\\n', 'best validation shape-weighted accuracy: 0.9716',\n'\\n', 'best validation complexity-weighted accuracy: 0.9744', '\\n', 'test color-\nweighted accuracy: 0.9781', '\\n', 'test shape-weighted accuracy: 0.9741', '\\n',\n'test complexity-weighted accuracy: 0.9768', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'best training loss: 0.0795', '\\n', 'best\ntraining color-weighted accuracy: 0.9832', '\\n', 'best training shape-weighted\naccuracy: 0.9808', '\\n', 'best training complexity-weighted accuracy: 0.9829',\n'\\n', 'best validation loss: 0.0920', '\\n', 'best validation color-weighted\naccuracy: 0.9754', '\\n', 'best validation shape-weighted accuracy: 0.9722',\n'\\n', 'best validation complexity-weighted accuracy: 0.9747', '\\n', 'test color-\nweighted accuracy: 0.9784', '\\n', 'test shape-weighted accuracy: 0.9745', '\\n',\n'test complexity-weighted accuracy: 0.9771', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'best training loss: 0.0797', '\\n', 'best\ntraining color-weighted accuracy: 0.9833', '\\n', 'best training shape-weighted\naccuracy: 0.9810', '\\n', 'best training complexity-weighted accuracy: 0.9831',\n'\\n', 'best validation loss: 0.0931', '\\n', 'best validation color-weighted\naccuracy: 0.9748', '\\n', 'best validation shape-weighted accuracy: 0.9711',\n'\\n', 'best validation complexity-weighted accuracy: 0.9740', '\\n', 'test color-\nweighted accuracy: 0.9774', '\\n', 'test shape-weighted accuracy: 0.9736', '\\n',\n'test complexity-weighted accuracy: 0.9762', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
