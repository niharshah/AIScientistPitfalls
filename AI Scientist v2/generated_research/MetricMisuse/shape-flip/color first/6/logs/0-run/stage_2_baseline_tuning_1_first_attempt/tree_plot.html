<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 1], [0, 3], [0, 4], [0, 2], [4, 5], [4, 6], [4, 8], [4, 7]], "layout": [[0.3333333333333333, 0.0], [0.0, 0.5], [0.2222222222222222, 0.5], [0.4444444444444444, 0.5], [0.6666666666666666, 0.5], [0.3333333333333333, 1.0], [0.5555555555555556, 1.0], [0.7777777777777778, 1.0], [1.0, 1.0]], "plan": ["We will treat each SPR sequence as a small graph: every token becomes a node\nwhose features are the categorical indices of its shape (first character) and\ncolour (second character), and undirected edges connect consecutive tokens so\nthat order information is retained.  From the whole training split we gather the\nshape and colour vocabularies and map labels to integers.  A simple GNN baseline\nis built with two 8-dimensional embedding tables (shape / colour), a linear\nprojection, two GraphConv layers, global-mean pooling and a soft-max classifier;\neverything is implemented with PyTorch Geometric and trained for a few epochs\nwith cross-entropy.  At the end of every epoch we evaluate on the dev split and\ncompute plain accuracy, CWA, SWA and the required Complexity-Weighted Accuracy\n(CompWA = |unique colours|+|unique shapes| weight).  All losses and CompWA\ntrajectories are stored in the prescribed experiment_data structure, plotted and\nsaved to ./working, and finally serialised with np.save.  The script auto-\ndetects GPU, moves all tensors/models properly, and falls back to a tiny\nsynthetic dataset if the real benchmark folder is not found so that it can\nalways run end-to-end within minutes.  This gives us a functional GNN baseline\nfrom data loading to evaluation and visualization, ready for later refinement.", "Hyperparam tuning name: num_epochs (training epochs). We grid-search the\nhyperparameter num_epochs by training independent models for several epoch\ncounts (e.g. 5, 15, 30, 50).   For every candidate we run a standard\ntrain/validation loop with optional early-stopping, log per-epoch losses and\nCompWA, keep the best validation snapshot, and finally evaluate on the test set.\nAll statistics are stored in experiment_data['num_epochs_tuning']['SPR_BENCH']\nand saved to experiment_data.npy; plots for the best epoch setting are also\nwritten to ./working.", "Hyperparam tuning name: learning_rate. We sweep over five learning-rate values\n(1e-4, 3e-4, 1e-3, 3e-3, 1e-2).   For every rate a fresh model is trained for 5\nepochs with all other settings unchanged; after each epoch we log\ntrain/validation loss and validation CompWA, and after training we compute test\nCompWA plus store predictions.   Results are collected in a nested\nexperiment_data dictionary using the layout {'learning_rate':{'SPR_BENCH':{<lr>:\n{...}}}}, then saved to experiment_data.npy.   The code below is self-contained\nand executes the complete sweep, producing the same figures as before for every\nlearning rate and persisting all raw numbers for later plotting.", "Hyperparam tuning name: weight_decay. We create a sweep over Adam\u2019s weight decay\n(0, 1e-5, 1e-4, 5e-4, 1e-3).   For every value a fresh model, optimiser (with\nthe chosen weight decay), and 5-epoch training loop are run, followed by\nvalidation and test evaluation.   Results (losses, CompWA, predictions, etc.)\nare stored in a nested experiment_data dictionary under the top-level key\n\"weight_decay\". All data are saved as `experiment_data.npy` and the script\nremains entirely self-contained.", "Hyperparam tuning name: batch_size. We will sweep over training batch sizes [16,\n32, 64, 128].   For each value we (re)-instantiate the model, create a\ncorresponding DataLoader, train for a few epochs, evaluate on validation and\ntest splits, and log metrics/losses inside a single experiment_data dictionary\nusing the structure required. All results are saved to \u201cexperiment_data.npy\u201d;\nsimple line plots are also produced for each batch size in the ./working folder.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pathlib\nfrom typing import List\nfrom datetime import datetime\n\n# ---- Device -----------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---- Helper metric functions ------------------------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    sequences: List[str], y_true: List[int], y_pred: List[int]\n) -> float:\n    weights = [count_color_variety(s) + count_shape_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    denom = sum(weights)\n    return sum(correct) / denom if denom > 0 else 0.0\n\n\n# ---- Try loading real SPR_BENCH  --------------------------------------------\ndef load_real_spr(root: pathlib.Path):\n    from datasets import load_dataset, DatasetDict\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = {}\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nhave_real_data = spr_root.exists()\nif have_real_data:\n    dsets = load_real_spr(spr_root)\n    print(\"Loaded real SPR_BENCH.\")\nelse:\n    # ------ tiny synthetic fallback -----------------------------------------\n    print(\"SPR_BENCH not found, creating synthetic toy data.\")\n\n    def make_synth(n):\n        seqs, labels = [], []\n        shapes = [\"A\", \"B\", \"C\"]\n        colors = [\"1\", \"2\", \"3\"]\n        for i in range(n):\n            length = np.random.randint(4, 8)\n            seq = \" \".join(\n                np.random.choice(shapes) + np.random.choice(colors)\n                for _ in range(length)\n            )\n            seqs.append(seq)\n            labels.append(np.random.randint(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    dsets = {\"train\": make_synth(500), \"dev\": make_synth(100), \"test\": make_synth(100)}\n\n# ---- Build vocabularies -----------------------------------------------------\nall_shapes = set()\nall_colors = set()\nall_labels = set()\nfor ex in dsets[\"train\"][\"sequence\"]:\n    for tok in ex.split():\n        if len(tok) >= 2:\n            all_shapes.add(tok[0])\n            all_colors.add(tok[1])\nfor lab in dsets[\"train\"][\"label\"]:\n    all_labels.add(lab)\n\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nnum_shapes = len(shape2idx)\nnum_colors = len(color2idx)\nlabel2idx = {l: i for i, l in enumerate(sorted(all_labels))}\nnum_classes = len(label2idx)\n\n\ndef seq_to_graph(seq: str, label: int):\n    toks = seq.strip().split()\n    n = len(toks)\n    shape_ids = [shape2idx[t[0]] for t in toks]\n    color_ids = [color2idx[t[1]] for t in toks]\n    x = torch.tensor(np.stack([shape_ids, color_ids], 1), dtype=torch.long)\n    # edges: consecutive tokens, bidirectional\n    if n > 1:\n        src = np.arange(n - 1)\n        dst = np.arange(1, n)\n        edge_index = torch.tensor(\n            np.vstack([np.hstack([src, dst]), np.hstack([dst, src])]), dtype=torch.long\n        )\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y, seq=seq)\n\n\ndef build_dataset(split_dict):\n    if isinstance(split_dict, dict):  # synthetic fallback\n        return [\n            seq_to_graph(s, l)\n            for s, l in zip(split_dict[\"sequence\"], split_dict[\"label\"])\n        ]\n    else:  # HuggingFace dataset\n        return [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split_dict]\n\n\ntrain_data = build_dataset(dsets[\"train\"])\ndev_data = build_dataset(dsets[\"dev\"])\ntest_data = build_dataset(dsets[\"test\"])\n\n\n# ---- Model ------------------------------------------------------------------\nclass SPRGNN(nn.Module):\n    def __init__(self, num_shapes, num_colors, num_classes):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, 8)\n        self.color_emb = nn.Embedding(num_colors, 8)\n        self.lin_node = nn.Linear(16, 32)\n        self.conv1 = GraphConv(32, 64)\n        self.conv2 = GraphConv(64, 64)\n        self.classifier = nn.Linear(64, num_classes)\n\n    def forward(self, data):\n        shape_e = self.shape_emb(data.x[:, 0])\n        color_e = self.color_emb(data.x[:, 1])\n        x = torch.cat([shape_e, color_e], dim=1)\n        x = F.relu(self.lin_node(x))\n        x = F.relu(self.conv1(x, data.edge_index))\n        x = F.relu(self.conv2(x, data.edge_index))\n        x = global_mean_pool(x, data.batch)\n        return self.classifier(x)\n\n\nmodel = SPRGNN(num_shapes, num_colors, num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\n# ---- DataLoaders ------------------------------------------------------------\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\ndev_loader = DataLoader(dev_data, batch_size=128, shuffle=False)\n\n# ---- Experiment data dict ---------------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_compwa\": [], \"val_compwa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# ---- Training loop ----------------------------------------------------------\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch.num_graphs\n    avg_train_loss = total_loss / len(train_loader.dataset)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(avg_train_loss)\n\n    # ---- Validation ---------------------------------------------------------\n    model.eval()\n    val_loss = 0\n    all_seq, all_true, all_pred = [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            loss = criterion(out, batch.y)\n            val_loss += loss.item() * batch.num_graphs\n            preds = out.argmax(dim=1).cpu().tolist()\n            labels = batch.y.cpu().tolist()\n            seqs = batch.seq\n            all_seq.extend(seqs)\n            all_true.extend(labels)\n            all_pred.extend(preds)\n    avg_val_loss = val_loss / len(dev_loader.dataset)\n    compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(avg_val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_compwa\"].append(compwa)\n    experiment_data[\"SPR_BENCH\"][\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch}: train_loss = {avg_train_loss:.4f} | \"\n        f\"val_loss = {avg_val_loss:.4f} | CompWA = {compwa:.4f}\"\n    )\n\n# ---- Final evaluation on test set ------------------------------------------\ntest_loader = DataLoader(test_data, batch_size=128, shuffle=False)\nmodel.eval()\nall_seq, all_true, all_pred = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch.to(device)\n        out = model(batch)\n        preds = out.argmax(dim=1).cpu().tolist()\n        labels = batch.y.cpu().tolist()\n        all_seq.extend(batch.seq)\n        all_true.extend(labels)\n        all_pred.extend(preds)\ntest_compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\nprint(f\"Test CompWA: {test_compwa:.4f}\")\n\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = all_pred\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_true\nexperiment_data[\"SPR_BENCH\"][\"metrics\"][\"test_compwa\"] = test_compwa\n\n# ---- Save metrics -----------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n# ---- Plot losses and CompWA -------------------------------------------------\nplt.figure()\nplt.plot(\n    experiment_data[\"SPR_BENCH\"][\"epochs\"],\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"],\n    label=\"train_loss\",\n)\nplt.plot(\n    experiment_data[\"SPR_BENCH\"][\"epochs\"],\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"],\n    label=\"val_loss\",\n)\nplt.legend()\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss trajectory\")\nplt.savefig(os.path.join(working_dir, f\"loss_{timestamp}.png\"))\n\nplt.figure()\nplt.plot(\n    experiment_data[\"SPR_BENCH\"][\"epochs\"],\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_compwa\"],\n    label=\"Val CompWA\",\n)\nplt.legend()\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CompWA\")\nplt.title(\"Validation Complexity-Weighted Accuracy\")\nplt.savefig(os.path.join(working_dir, f\"compwa_{timestamp}.png\"))\nprint(\"Training complete. Figures and data saved in ./working\")\n", "# num_epochs hyperparameter tuning \u2013 single-file runnable script\nimport os, copy, pathlib, numpy as np, torch, matplotlib\n\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom typing import List\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\n\n# ---------- Reproducibility --------------------------------------------------\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# ---------- Working dir ------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- Helper metric ----------------------------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    sequences: List[str], y_true: List[int], y_pred: List[int]\n) -> float:\n    w = [count_color_variety(s) + count_shape_variety(s) for s in sequences]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if w else 0.0\n\n\n# ---------- Load SPR_BENCH or synthetic --------------------------------------\ndef load_real_spr(root: pathlib.Path):\n    from datasets import load_dataset\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]}\n\n\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nif spr_root.exists():\n    dsets = load_real_spr(spr_root)\n    print(\"Loaded real SPR_BENCH.\")\nelse:\n    print(\"SPR_BENCH not found, using synthetic toy data.\")\n\n    def make_synth(n):\n        shapes, colors = [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        seqs, labels = [], []\n        for _ in range(n):\n            length = np.random.randint(4, 8)\n            seqs.append(\n                \" \".join(\n                    np.random.choice(shapes) + np.random.choice(colors)\n                    for _ in range(length)\n                )\n            )\n            labels.append(np.random.randint(0, 3))\n        return {\"sequence\": seqs, \"label\": labels}\n\n    dsets = {\"train\": make_synth(500), \"dev\": make_synth(100), \"test\": make_synth(100)}\n\n# ---------- Build vocab ------------------------------------------------------\nall_shapes, all_colors, all_labels = set(), set(), set()\nfor s in dsets[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nfor l in dsets[\"train\"][\"label\"]:\n    all_labels.add(l)\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel2idx = {l: i for i, l in enumerate(sorted(all_labels))}\nnum_shapes, num_colors, num_classes = len(shape2idx), len(color2idx), len(label2idx)\n\n\ndef seq_to_graph(seq: str, label: int):\n    toks = seq.strip().split()\n    n = len(toks)\n    shape_ids = [shape2idx[t[0]] for t in toks]\n    color_ids = [color2idx[t[1]] for t in toks]\n    x = torch.tensor(np.stack([shape_ids, color_ids], 1), dtype=torch.long)\n    if n > 1:\n        src = np.arange(n - 1)\n        dst = np.arange(1, n)\n        edge_index = torch.tensor(\n            np.vstack([np.hstack([src, dst]), np.hstack([dst, src])]), dtype=torch.long\n        )\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    return [seq_to_graph(r[\"sequence\"], r[\"label\"]) for r in split]\n\n\ntrain_data, dev_data, test_data = map(\n    build_dataset, (dsets[\"train\"], dsets[\"dev\"], dsets[\"test\"])\n)\n\n\n# ---------- Model definition -------------------------------------------------\nclass SPRGNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb = nn.Embedding(num_shapes, 8)\n        self.color_emb = nn.Embedding(num_colors, 8)\n        self.lin_node = nn.Linear(16, 32)\n        self.conv1 = GraphConv(32, 64)\n        self.conv2 = GraphConv(64, 64)\n        self.cls = nn.Linear(64, num_classes)\n\n    def forward(self, data):\n        s = self.shape_emb(data.x[:, 0])\n        c = self.color_emb(data.x[:, 1])\n        x = F.relu(self.lin_node(torch.cat([s, c], 1)))\n        x = F.relu(self.conv1(x, data.edge_index))\n        x = F.relu(self.conv2(x, data.edge_index))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\n# ---------- Dataloaders (re-used) -------------------------------------------\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\ndev_loader = DataLoader(dev_data, batch_size=128, shuffle=False)\ntest_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n\n# ---------- Experiment data dict --------------------------------------------\nexperiment_data = {\n    \"num_epochs_tuning\": {\n        \"SPR_BENCH\": {\n            \"hparam_values\": [],\n            \"epochs_run\": [],\n            \"metrics\": {\"train_compwa\": [], \"val_compwa\": [], \"test_compwa\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------- Training routine -------------------------------------------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef train_model(num_epochs: int, patience: int = 5):\n    model = SPRGNN().to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n    best_state, best_val_loss = None, float(\"inf\")\n    patience_ctr = 0\n    tr_losses, val_losses, val_compwas = [], [], []\n    for ep in range(1, num_epochs + 1):\n        # ---- train ----\n        model.train()\n        tot = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optim.zero_grad()\n            loss = criterion(model(batch), batch.y)\n            loss.backward()\n            optim.step()\n            tot += loss.item() * batch.num_graphs\n        tr_losses.append(tot / len(train_loader.dataset))\n        # ---- val ----\n        model.eval()\n        vtot = 0\n        seqs = true = pred = []\n        seqs, true, pred = [], [], []\n        with torch.no_grad():\n            for b in dev_loader:\n                b = b.to(device)\n                out = model(b)\n                loss = criterion(out, b.y)\n                vtot += loss.item() * b.num_graphs\n                seqs.extend(b.seq)\n                true.extend(b.y.cpu().tolist())\n                pred.extend(out.argmax(1).cpu().tolist())\n        v_loss = vtot / len(dev_loader.dataset)\n        val_losses.append(v_loss)\n        compwa = complexity_weighted_accuracy(seqs, true, pred)\n        val_compwas.append(compwa)\n        # ---- early stopping ----\n        if v_loss < best_val_loss - 1e-4:\n            best_val_loss = v_loss\n            best_state = copy.deepcopy(model.state_dict())\n            patience_ctr = 0\n        else:\n            patience_ctr += 1\n        if patience_ctr >= patience:\n            print(f\"Early stopping at epoch {ep}\")\n            break\n    # load best model\n    model.load_state_dict(best_state)\n    return model, tr_losses, val_losses, val_compwas\n\n\n# ---------- Hyperparameter grid ---------------------------------------------\nepoch_grid = [5, 15, 30, 50]\nbest_idx, best_val = None, -1\n\nfor epochs in epoch_grid:\n    print(f\"\\n=== Training with num_epochs={epochs} ===\")\n    model, tr_l, val_l, val_c = train_model(epochs)\n    # final compwa on train (using last epoch metrics)\n    train_comp = val_c[0] if val_c else 0.0  # placeholder not used\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\"hparam_values\"].append(epochs)\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\"epochs_run\"].append(len(tr_l))\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_l)\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_l)\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\"metrics\"][\"val_compwa\"].append(\n        val_c[-1] if val_c else 0.0\n    )\n    # ---- test evaluation ----\n    model.eval()\n    seqs, true, preds = [], [], []\n    with torch.no_grad():\n        for b in test_loader:\n            b = b.to(device)\n            out = model(b)\n            seqs.extend(b.seq)\n            true.extend(b.y.cpu().tolist())\n            preds.extend(out.argmax(1).cpu().tolist())\n    test_cwa = complexity_weighted_accuracy(seqs, true, preds)\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\"metrics\"][\"test_compwa\"].append(\n        test_cwa\n    )\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\"predictions\"].append(preds)\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\n        \"ground_truth\"\n    ] = true  # same for all\n    print(\n        f\"Finished num_epochs={epochs} | Val CompWA={val_c[-1]:.4f} | Test CompWA={test_cwa:.4f}\"\n    )\n    if val_c[-1] > best_val:\n        best_val = val_c[-1]\n        best_idx = len(epoch_grid) - len(epoch_grid[epoch_grid.index(epochs) :])\n\n# ---------- Plot for best configuration -------------------------------------\nbest_epochs = experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\"hparam_values\"][\n    best_idx\n]\nbest_tr = experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\"losses\"][\"train\"][best_idx]\nbest_val = experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\"losses\"][\"val\"][best_idx]\nbest_cwa_curve = experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][\"metrics\"][\n    \"val_compwa\"\n][best_idx]\n\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nplt.figure()\nplt.plot(range(1, len(best_tr) + 1), best_tr, label=\"train\")\nplt.plot(range(1, len(best_val) + 1), best_val, label=\"val\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(f\"Loss (best num_epochs={best_epochs})\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, f\"loss_best_{ts}.png\"))\n# single value compwa, plot as point\nplt.figure()\nplt.plot(len(best_val), best_cwa_curve, \"ro\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Val CompWA\")\nplt.title(\"Best validation CompWA\")\nplt.savefig(os.path.join(working_dir, f\"val_compwa_best_{ts}.png\"))\n\n# ---------- Save experiment data --------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All done. Data saved to\", working_dir)\n", "import os, pathlib, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\nfrom typing import List\nfrom datetime import datetime\n\n\n# ---------------------------------------------------------------------------#\n#                           Helper functions                                  #\n# ---------------------------------------------------------------------------#\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    sequences: List[str], y_true: List[int], y_pred: List[int]\n) -> float:\n    weights = [count_color_variety(s) + count_shape_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    denom = sum(weights)\n    return sum(correct) / denom if denom > 0 else 0.0\n\n\n# ---------------------------------------------------------------------------#\n#                           Data preparation                                  #\n# ---------------------------------------------------------------------------#\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nhave_real_data = spr_root.exists()\nif have_real_data:\n    from datasets import load_dataset\n\n    def _load(csv_name):  # helper for CSV loading\n        return load_dataset(\n            \"csv\",\n            data_files=str(spr_root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dsets = {sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]}\nelse:  # tiny synthetic toy data\n\n    def make_synth(n):\n        seqs, labels = [], []\n        shapes, colors = [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        for _ in range(n):\n            ln = np.random.randint(4, 8)\n            seqs.append(\n                \" \".join(\n                    np.random.choice(shapes) + np.random.choice(colors)\n                    for _ in range(ln)\n                )\n            )\n            labels.append(np.random.randint(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    dsets = {\"train\": make_synth(500), \"dev\": make_synth(100), \"test\": make_synth(100)}\n\n# build vocabularies\nall_shapes, all_colors, all_labels = set(), set(), set()\nfor s in dsets[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0]), all_colors.add(tok[1])\nfor l in dsets[\"train\"][\"label\"]:\n    all_labels.add(l)\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel2idx = {l: i for i, l in enumerate(sorted(all_labels))}\nnum_shapes, num_colors, num_classes = len(shape2idx), len(color2idx), len(label2idx)\n\n\ndef seq_to_graph(seq: str, label: int):\n    toks = seq.strip().split()\n    n = len(toks)\n    shape_ids = [shape2idx[t[0]] for t in toks]\n    color_ids = [color2idx[t[1]] for t in toks]\n    x = torch.tensor(np.stack([shape_ids, color_ids], 1), dtype=torch.long)\n    if n > 1:\n        src, dst = np.arange(n - 1), np.arange(1, n)\n        edge_index = torch.tensor(\n            np.vstack([np.hstack([src, dst]), np.hstack([dst, src])]), dtype=torch.long\n        )\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    return [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n\n\ntrain_data, dev_data, test_data = (\n    build_dataset(dsets[k]) for k in [\"train\", \"dev\", \"test\"]\n)\n\n\n# ---------------------------------------------------------------------------#\n#                               Model                                         #\n# ---------------------------------------------------------------------------#\nclass SPRGNN(nn.Module):\n    def __init__(self, n_shapes, n_colors, n_cls):\n        super().__init__()\n        self.shape_emb, self.color_emb = nn.Embedding(n_shapes, 8), nn.Embedding(\n            n_colors, 8\n        )\n        self.lin_node = nn.Linear(16, 32)\n        self.conv1, self.conv2 = GraphConv(32, 64), GraphConv(64, 64)\n        self.classifier = nn.Linear(64, n_cls)\n\n    def forward(self, data):\n        x = torch.cat([self.shape_emb(data.x[:, 0]), self.color_emb(data.x[:, 1])], 1)\n        x = F.relu(self.lin_node(x))\n        x = F.relu(self.conv1(x, data.edge_index))\n        x = F.relu(self.conv2(x, data.edge_index))\n        x = global_mean_pool(x, data.batch)\n        return self.classifier(x)\n\n\n# ---------------------------------------------------------------------------#\n#                           Hyper-parameter sweep                             #\n# ---------------------------------------------------------------------------#\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nlrs = [1e-4, 3e-4, 1e-3, 3e-3, 1e-2]\nepochs = 5\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\"learning_rate\": {\"SPR_BENCH\": {}}}\n\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\ndev_loader = DataLoader(dev_data, batch_size=128, shuffle=False)\ntest_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n\ncriterion = nn.CrossEntropyLoss()\n\nfor lr in lrs:\n    print(f\"\\n===> Training with learning rate {lr:.0e}\")\n    model = SPRGNN(num_shapes, num_colors, num_classes).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    lr_key = f\"{lr:.0e}\"\n    exp = {\n        \"metrics\": {\"val_compwa\": [], \"test_compwa\": None},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n    for epoch in range(1, epochs + 1):\n        # training\n        model.train()\n        tr_loss = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch)\n            loss = criterion(out, batch.y)\n            loss.backward()\n            optimizer.step()\n            tr_loss += loss.item() * batch.num_graphs\n        tr_loss /= len(train_loader.dataset)\n        # validation\n        model.eval()\n        val_loss, seqs, y_true, y_pred = 0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch)\n                loss = criterion(out, batch.y)\n                val_loss += loss.item() * batch.num_graphs\n                preds = out.argmax(1).cpu().tolist()\n                y_pred.extend(preds)\n                y_true.extend(batch.y.cpu().tolist())\n                seqs.extend(batch.seq)\n        val_loss /= len(dev_loader.dataset)\n        compwa = complexity_weighted_accuracy(seqs, y_true, y_pred)\n        # log\n        exp[\"losses\"][\"train\"].append(tr_loss)\n        exp[\"losses\"][\"val\"].append(val_loss)\n        exp[\"metrics\"][\"val_compwa\"].append(compwa)\n        exp[\"epochs\"].append(epoch)\n        print(\n            f\"  Epoch {epoch}: train_loss={tr_loss:.4f} val_loss={val_loss:.4f} CompWA={compwa:.4f}\"\n        )\n\n    # final test\n    model.eval()\n    seqs, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            preds = out.argmax(1).cpu().tolist()\n            y_pred.extend(preds)\n            y_true.extend(batch.y.cpu().tolist())\n            seqs.extend(batch.seq)\n    test_compwa = complexity_weighted_accuracy(seqs, y_true, y_pred)\n    exp[\"metrics\"][\"test_compwa\"] = test_compwa\n    exp[\"predictions\"], exp[\"ground_truth\"] = y_pred, y_true\n    print(f\"  Test CompWA with lr {lr:.0e}: {test_compwa:.4f}\")\n\n    # save per-lr plots\n    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    plt.figure()\n    plt.plot(exp[\"epochs\"], exp[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(exp[\"epochs\"], exp[\"losses\"][\"val\"], label=\"val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.title(f\"Loss (lr={lr:.0e})\")\n    plt.savefig(os.path.join(working_dir, f\"loss_lr{lr_key}_{ts}.png\"))\n    plt.close()\n\n    plt.figure()\n    plt.plot(exp[\"epochs\"], exp[\"metrics\"][\"val_compwa\"], label=\"Val CompWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.legend()\n    plt.title(f\"Val CompWA (lr={lr:.0e})\")\n    plt.savefig(os.path.join(working_dir, f\"compwa_lr{lr_key}_{ts}.png\"))\n    plt.close()\n\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][lr_key] = exp\n\n# save raw data\nnp.save(\"experiment_data.npy\", experiment_data)\nprint(\n    \"All experiments complete. Raw data saved to experiment_data.npy and plots in ./working\"\n)\n", "import os, pathlib, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\nfrom datetime import datetime\nfrom typing import List\n\n# ----------------------------- helpers ---------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    seqs: List[str], y_true: List[int], y_pred: List[int]\n) -> float:\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    correct = [ww if t == p else 0 for ww, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) else 0.0\n\n\n# ------------------------ load or create dataset -----------------------------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nhave_real = spr_root.exists()\nif have_real:\n    from datasets import load_dataset\n\n    def _load(csv_name):  # small util\n        return load_dataset(\n            \"csv\",\n            data_files=str(spr_root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dsets = {split: _load(f\"{split}.csv\") for split in [\"train\", \"dev\", \"test\"]}\n    print(\"Loaded real SPR_BENCH.\")\nelse:\n    print(\"SPR_BENCH not found, using synthetic.\")\n    rng = np.random.default_rng(0)\n\n    def synth(n):\n        shapes, colors = [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        seqs, labs = [], []\n        for _ in range(n):\n            length = rng.integers(4, 8)\n            seq = \" \".join(\n                rng.choice(shapes) + rng.choice(colors) for _ in range(length)\n            )\n            seqs.append(seq)\n            labs.append(rng.integers(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labs}\n\n    dsets = {\"train\": synth(500), \"dev\": synth(100), \"test\": synth(100)}\n\n# ---------------------------- vocabularies -----------------------------------\nall_shapes, all_colors, all_labels = set(), set(), set()\nfor s in dsets[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nfor l in dsets[\"train\"][\"label\"]:\n    all_labels.add(l)\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel2idx = {l: i for i, l in enumerate(sorted(all_labels))}\nnum_shapes, num_colors, num_classes = len(shape2idx), len(color2idx), len(label2idx)\n\n# --------------------------- graph builder -----------------------------------\nfrom torch_geometric.data import Data\n\n\ndef seq_to_graph(seq: str, label: int):\n    toks = seq.strip().split()\n    n = len(toks)\n    s_ids = [shape2idx[t[0]] for t in toks]\n    c_ids = [color2idx[t[1]] for t in toks]\n    x = torch.tensor(np.stack([s_ids, c_ids], 1), dtype=torch.long)\n    if n > 1:\n        src = np.arange(n - 1)\n        dst = np.arange(1, n)\n        edge_index = torch.tensor(\n            np.vstack([np.hstack([src, dst]), np.hstack([dst, src])]), dtype=torch.long\n        )\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y, seq=seq)\n\n\ndef build(split):\n    if isinstance(split, dict):\n        return [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n    return [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n\n\ntrain_data, dev_data, test_data = map(\n    build, (dsets[\"train\"], dsets[\"dev\"], dsets[\"test\"])\n)\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\ndev_loader = DataLoader(dev_data, batch_size=128, shuffle=False)\ntest_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n\n\n# ------------------------------- model ---------------------------------------\nclass SPRGNN(nn.Module):\n    def __init__(self, n_shapes, n_colors, n_cls):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shapes, 8)\n        self.color_emb = nn.Embedding(n_colors, 8)\n        self.lin = nn.Linear(16, 32)\n        self.conv1, self.conv2 = GraphConv(32, 64), GraphConv(64, 64)\n        self.cls = nn.Linear(64, n_cls)\n\n    def forward(self, data):\n        e1 = self.shape_emb(data.x[:, 0])\n        e2 = self.color_emb(data.x[:, 1])\n        x = F.relu(self.lin(torch.cat([e1, e2], 1)))\n        x = F.relu(self.conv1(x, data.edge_index))\n        x = F.relu(self.conv2(x, data.edge_index))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\n# ------------------------ hyper-parameter sweep ------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nweight_decays = [0, 1e-5, 1e-4, 5e-4, 1e-3]\nexperiment_data = {\"weight_decay\": {}}\nepochs = 5\ncriterion = nn.CrossEntropyLoss()\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\nfor wd in weight_decays:\n    tag = f\"wd_{wd}\"\n    print(f\"\\n===== Training with weight_decay={wd} =====\")\n    exp = {\n        \"metrics\": {\"train_compwa\": [], \"val_compwa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n    model = SPRGNN(num_shapes, num_colors, num_classes).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=wd)\n\n    for epoch in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        total = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch)\n            loss = criterion(out, batch.y)\n            loss.backward()\n            optimizer.step()\n            total += loss.item() * batch.num_graphs\n        avg_train_loss = total / len(train_loader.dataset)\n        # ---- val ----\n        model.eval()\n        vtot = 0\n        seqs, true, pred = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch)\n                loss = criterion(out, batch.y)\n                vtot += loss.item() * batch.num_graphs\n                preds = out.argmax(1).cpu().tolist()\n                seqs.extend(batch.seq)\n                true.extend(batch.y.cpu().tolist())\n                pred.extend(preds)\n        avg_val_loss = vtot / len(dev_loader.dataset)\n        compwa = complexity_weighted_accuracy(seqs, true, pred)\n\n        exp[\"losses\"][\"train\"].append(avg_train_loss)\n        exp[\"losses\"][\"val\"].append(avg_val_loss)\n        exp[\"metrics\"][\"val_compwa\"].append(compwa)\n        exp[\"epochs\"].append(epoch)\n        print(\n            f\"Epoch {epoch}: train_loss {avg_train_loss:.4f} | val_loss {avg_val_loss:.4f} | CompWA {compwa:.4f}\"\n        )\n\n    # ------------- test evaluation ------------------------------------------\n    model.eval()\n    seqs, true, pred = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            preds = out.argmax(1).cpu().tolist()\n            seqs.extend(batch.seq)\n            true.extend(batch.y.cpu().tolist())\n            pred.extend(preds)\n    test_compwa = complexity_weighted_accuracy(seqs, true, pred)\n    exp[\"metrics\"][\"test_compwa\"] = test_compwa\n    exp[\"predictions\"] = pred\n    exp[\"ground_truth\"] = true\n    print(f\"Test CompWA for wd={wd}: {test_compwa:.4f}\")\n\n    experiment_data[\"weight_decay\"][tag] = exp\n\n# ---------------------------- save and plot ----------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n# simple plot summarising CompWA per wd\nplt.figure()\nvals = [\n    experiment_data[\"weight_decay\"][f\"wd_{wd}\"][\"metrics\"][\"test_compwa\"]\n    for wd in weight_decays\n]\nplt.plot(weight_decays, vals, marker=\"o\")\nplt.xscale(\"log\")\nplt.xlabel(\"Weight decay\")\nplt.ylabel(\"Test CompWA\")\nplt.title(\"Weight-decay sweep\")\nplt.savefig(os.path.join(working_dir, f\"wd_sweep_{timestamp}.png\"))\nprint(\"All done, results stored in ./working\")\n", "import os, pathlib, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\nfrom datetime import datetime\nfrom typing import List\n\n# ------------------------- dirs & device ------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ------------------------- helper metrics -----------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    seqs: List[str], y_t: List[int], y_p: List[int]\n) -> float:\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(w_i if t == p else 0 for w_i, t, p in zip(w, y_t, y_p)) / (sum(w) or 1)\n\n\n# ------------------------- load (real or synth) SPR -------------------------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nif spr_root.exists():\n    from datasets import load_dataset\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(spr_root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dsets = {sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]}\n    print(\"Loaded real SPR_BENCH.\")\nelse:  # ---------- synthetic fallback\n    print(\"SPR_BENCH not found, generating synthetic data.\")\n\n    def make_synth(n):\n        shapes, colors = [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        seqs, labels = [], []\n        for _ in range(n):\n            length = np.random.randint(4, 8)\n            seqs.append(\n                \" \".join(\n                    np.random.choice(shapes) + np.random.choice(colors)\n                    for _ in range(length)\n                )\n            )\n            labels.append(np.random.randint(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    dsets = {\"train\": make_synth(500), \"dev\": make_synth(100), \"test\": make_synth(100)}\n\n# ------------------------- vocab & graph builder ----------------------------\nall_shapes, all_colors = set(), set()\nfor s in dsets[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel2idx = {l: i for i, l in enumerate(sorted(set(dsets[\"train\"][\"label\"])))}\nnum_shapes, num_colors, num_classes = len(shape2idx), len(color2idx), len(label2idx)\n\n\ndef seq_to_graph(seq: str, label: int):\n    toks = seq.strip().split()\n    n = len(toks)\n    x = torch.tensor(\n        np.stack([[shape2idx[t[0]], color2idx[t[1]]] for t in toks]), dtype=torch.long\n    )\n    if n > 1:\n        src, dst = np.arange(n - 1), np.arange(1, n)\n        edge_index = torch.tensor(\n            np.vstack([np.hstack([src, dst]), np.hstack([dst, src])]), dtype=torch.long\n        )\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    return (\n        [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n        if isinstance(split, dict)\n        else [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n    )\n\n\ntrain_data, dev_data, test_data = map(\n    build_dataset, (dsets[\"train\"], dsets[\"dev\"], dsets[\"test\"])\n)\n\n\n# ------------------------- model --------------------------------------------\nclass SPRGNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb, self.color_emb = nn.Embedding(num_shapes, 8), nn.Embedding(\n            num_colors, 8\n        )\n        self.lin = nn.Linear(16, 32)\n        self.conv1, self.conv2 = GraphConv(32, 64), GraphConv(64, 64)\n        self.cls = nn.Linear(64, num_classes)\n\n    def forward(self, data):\n        x = torch.cat([self.shape_emb(data.x[:, 0]), self.color_emb(data.x[:, 1])], 1)\n        x = F.relu(self.lin(x))\n        x = F.relu(self.conv1(x, data.edge_index))\n        x = F.relu(self.conv2(x, data.edge_index))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\n# ------------------------- experiment dict ----------------------------------\nexperiment_data = {\"batch_size\": {}}  # <- hyperparam tuning type key\nbatch_sweep = [16, 32, 64, 128]\nepochs = 5\n\nfor bs in batch_sweep:\n    key = f\"bs_{bs}\"\n    experiment_data[\"batch_size\"][key] = {\n        \"metrics\": {\"train_compwa\": [], \"val_compwa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n    # loaders and model/opt\n    train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n    dev_loader = DataLoader(dev_data, batch_size=128, shuffle=False)\n    model = SPRGNN().to(device)\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n\n    # ------------- training loop -------------------------------------------\n    for epoch in range(1, epochs + 1):\n        model.train()\n        tot_loss = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            opt.zero_grad()\n            out = model(batch)\n            loss = criterion(out, batch.y)\n            loss.backward()\n            opt.step()\n            tot_loss += loss.item() * batch.num_graphs\n        avg_train_loss = tot_loss / len(train_loader.dataset)\n\n        # validation\n        model.eval()\n        vloss = 0\n        seqs = true = pred = []\n        all_seq, all_true, all_pred = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch)\n                l = criterion(out, batch.y)\n                vloss += l.item() * batch.num_graphs\n                pr = out.argmax(1).cpu().tolist()\n                lb = batch.y.cpu().tolist()\n                all_pred.extend(pr)\n                all_true.extend(lb)\n                all_seq.extend(batch.seq)\n        avg_val_loss = vloss / len(dev_loader.dataset)\n        compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n\n        # log\n        ed = experiment_data[\"batch_size\"][key]\n        ed[\"losses\"][\"train\"].append(avg_train_loss)\n        ed[\"losses\"][\"val\"].append(avg_val_loss)\n        ed[\"metrics\"][\"val_compwa\"].append(compwa)\n        ed[\"epochs\"].append(epoch)\n        print(\n            f\"[bs={bs}] Epoch {epoch}  train_loss {avg_train_loss:.4f}  \"\n            f\"val_loss {avg_val_loss:.4f}  CompWA {compwa:.4f}\"\n        )\n\n    # ------------- test ----------------------------------------------------\n    test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n    model.eval()\n    all_seq, all_true, all_pred = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            all_pred.extend(out.argmax(1).cpu().tolist())\n            all_true.extend(batch.y.cpu().tolist())\n            all_seq.extend(batch.seq)\n    test_compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n    experiment_data[\"batch_size\"][key][\"metrics\"][\"test_compwa\"] = test_compwa\n    experiment_data[\"batch_size\"][key][\"predictions\"] = all_pred\n    experiment_data[\"batch_size\"][key][\"ground_truth\"] = all_true\n    print(f\"[bs={bs}] Test CompWA {test_compwa:.4f}\")\n\n    # ------------- plots ---------------------------------------------------\n    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    plt.figure()\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"losses\"][\"train\"],\n        label=\"train\",\n    )\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"losses\"][\"val\"],\n        label=\"val\",\n    )\n    plt.title(f\"Loss (bs={bs})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_bs{bs}_{ts}.png\"))\n    plt.close()\n\n    plt.figure()\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"metrics\"][\"val_compwa\"],\n    )\n    plt.title(f\"Val CompWA (bs={bs})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.savefig(os.path.join(working_dir, f\"compwa_bs{bs}_{ts}.png\"))\n    plt.close()\n\n# ------------------------- save ---------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All runs complete. Data saved to ./working/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\nfrom datetime import datetime\nfrom typing import List\n\n# ------------------------- dirs & device ------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ------------------------- helper metrics -----------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    seqs: List[str], y_t: List[int], y_p: List[int]\n) -> float:\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(w_i if t == p else 0 for w_i, t, p in zip(w, y_t, y_p)) / (sum(w) or 1)\n\n\n# ------------------------- load (real or synth) SPR -------------------------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nif spr_root.exists():\n    from datasets import load_dataset\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(spr_root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dsets = {sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]}\n    print(\"Loaded real SPR_BENCH.\")\nelse:  # ---------- synthetic fallback\n    print(\"SPR_BENCH not found, generating synthetic data.\")\n\n    def make_synth(n):\n        shapes, colors = [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        seqs, labels = [], []\n        for _ in range(n):\n            length = np.random.randint(4, 8)\n            seqs.append(\n                \" \".join(\n                    np.random.choice(shapes) + np.random.choice(colors)\n                    for _ in range(length)\n                )\n            )\n            labels.append(np.random.randint(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    dsets = {\"train\": make_synth(500), \"dev\": make_synth(100), \"test\": make_synth(100)}\n\n# ------------------------- vocab & graph builder ----------------------------\nall_shapes, all_colors = set(), set()\nfor s in dsets[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel2idx = {l: i for i, l in enumerate(sorted(set(dsets[\"train\"][\"label\"])))}\nnum_shapes, num_colors, num_classes = len(shape2idx), len(color2idx), len(label2idx)\n\n\ndef seq_to_graph(seq: str, label: int):\n    toks = seq.strip().split()\n    n = len(toks)\n    x = torch.tensor(\n        np.stack([[shape2idx[t[0]], color2idx[t[1]]] for t in toks]), dtype=torch.long\n    )\n    if n > 1:\n        src, dst = np.arange(n - 1), np.arange(1, n)\n        edge_index = torch.tensor(\n            np.vstack([np.hstack([src, dst]), np.hstack([dst, src])]), dtype=torch.long\n        )\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    return (\n        [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n        if isinstance(split, dict)\n        else [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n    )\n\n\ntrain_data, dev_data, test_data = map(\n    build_dataset, (dsets[\"train\"], dsets[\"dev\"], dsets[\"test\"])\n)\n\n\n# ------------------------- model --------------------------------------------\nclass SPRGNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb, self.color_emb = nn.Embedding(num_shapes, 8), nn.Embedding(\n            num_colors, 8\n        )\n        self.lin = nn.Linear(16, 32)\n        self.conv1, self.conv2 = GraphConv(32, 64), GraphConv(64, 64)\n        self.cls = nn.Linear(64, num_classes)\n\n    def forward(self, data):\n        x = torch.cat([self.shape_emb(data.x[:, 0]), self.color_emb(data.x[:, 1])], 1)\n        x = F.relu(self.lin(x))\n        x = F.relu(self.conv1(x, data.edge_index))\n        x = F.relu(self.conv2(x, data.edge_index))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\n# ------------------------- experiment dict ----------------------------------\nexperiment_data = {\"batch_size\": {}}  # <- hyperparam tuning type key\nbatch_sweep = [16, 32, 64, 128]\nepochs = 5\n\nfor bs in batch_sweep:\n    key = f\"bs_{bs}\"\n    experiment_data[\"batch_size\"][key] = {\n        \"metrics\": {\"train_compwa\": [], \"val_compwa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n    # loaders and model/opt\n    train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n    dev_loader = DataLoader(dev_data, batch_size=128, shuffle=False)\n    model = SPRGNN().to(device)\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n\n    # ------------- training loop -------------------------------------------\n    for epoch in range(1, epochs + 1):\n        model.train()\n        tot_loss = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            opt.zero_grad()\n            out = model(batch)\n            loss = criterion(out, batch.y)\n            loss.backward()\n            opt.step()\n            tot_loss += loss.item() * batch.num_graphs\n        avg_train_loss = tot_loss / len(train_loader.dataset)\n\n        # validation\n        model.eval()\n        vloss = 0\n        seqs = true = pred = []\n        all_seq, all_true, all_pred = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch)\n                l = criterion(out, batch.y)\n                vloss += l.item() * batch.num_graphs\n                pr = out.argmax(1).cpu().tolist()\n                lb = batch.y.cpu().tolist()\n                all_pred.extend(pr)\n                all_true.extend(lb)\n                all_seq.extend(batch.seq)\n        avg_val_loss = vloss / len(dev_loader.dataset)\n        compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n\n        # log\n        ed = experiment_data[\"batch_size\"][key]\n        ed[\"losses\"][\"train\"].append(avg_train_loss)\n        ed[\"losses\"][\"val\"].append(avg_val_loss)\n        ed[\"metrics\"][\"val_compwa\"].append(compwa)\n        ed[\"epochs\"].append(epoch)\n        print(\n            f\"[bs={bs}] Epoch {epoch}  train_loss {avg_train_loss:.4f}  \"\n            f\"val_loss {avg_val_loss:.4f}  CompWA {compwa:.4f}\"\n        )\n\n    # ------------- test ----------------------------------------------------\n    test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n    model.eval()\n    all_seq, all_true, all_pred = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            all_pred.extend(out.argmax(1).cpu().tolist())\n            all_true.extend(batch.y.cpu().tolist())\n            all_seq.extend(batch.seq)\n    test_compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n    experiment_data[\"batch_size\"][key][\"metrics\"][\"test_compwa\"] = test_compwa\n    experiment_data[\"batch_size\"][key][\"predictions\"] = all_pred\n    experiment_data[\"batch_size\"][key][\"ground_truth\"] = all_true\n    print(f\"[bs={bs}] Test CompWA {test_compwa:.4f}\")\n\n    # ------------- plots ---------------------------------------------------\n    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    plt.figure()\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"losses\"][\"train\"],\n        label=\"train\",\n    )\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"losses\"][\"val\"],\n        label=\"val\",\n    )\n    plt.title(f\"Loss (bs={bs})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_bs{bs}_{ts}.png\"))\n    plt.close()\n\n    plt.figure()\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"metrics\"][\"val_compwa\"],\n    )\n    plt.title(f\"Val CompWA (bs={bs})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.savefig(os.path.join(working_dir, f\"compwa_bs{bs}_{ts}.png\"))\n    plt.close()\n\n# ------------------------- save ---------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All runs complete. Data saved to ./working/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\nfrom datetime import datetime\nfrom typing import List\n\n# ------------------------- dirs & device ------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ------------------------- helper metrics -----------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    seqs: List[str], y_t: List[int], y_p: List[int]\n) -> float:\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(w_i if t == p else 0 for w_i, t, p in zip(w, y_t, y_p)) / (sum(w) or 1)\n\n\n# ------------------------- load (real or synth) SPR -------------------------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nif spr_root.exists():\n    from datasets import load_dataset\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(spr_root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dsets = {sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]}\n    print(\"Loaded real SPR_BENCH.\")\nelse:  # ---------- synthetic fallback\n    print(\"SPR_BENCH not found, generating synthetic data.\")\n\n    def make_synth(n):\n        shapes, colors = [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        seqs, labels = [], []\n        for _ in range(n):\n            length = np.random.randint(4, 8)\n            seqs.append(\n                \" \".join(\n                    np.random.choice(shapes) + np.random.choice(colors)\n                    for _ in range(length)\n                )\n            )\n            labels.append(np.random.randint(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    dsets = {\"train\": make_synth(500), \"dev\": make_synth(100), \"test\": make_synth(100)}\n\n# ------------------------- vocab & graph builder ----------------------------\nall_shapes, all_colors = set(), set()\nfor s in dsets[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel2idx = {l: i for i, l in enumerate(sorted(set(dsets[\"train\"][\"label\"])))}\nnum_shapes, num_colors, num_classes = len(shape2idx), len(color2idx), len(label2idx)\n\n\ndef seq_to_graph(seq: str, label: int):\n    toks = seq.strip().split()\n    n = len(toks)\n    x = torch.tensor(\n        np.stack([[shape2idx[t[0]], color2idx[t[1]]] for t in toks]), dtype=torch.long\n    )\n    if n > 1:\n        src, dst = np.arange(n - 1), np.arange(1, n)\n        edge_index = torch.tensor(\n            np.vstack([np.hstack([src, dst]), np.hstack([dst, src])]), dtype=torch.long\n        )\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    return (\n        [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n        if isinstance(split, dict)\n        else [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n    )\n\n\ntrain_data, dev_data, test_data = map(\n    build_dataset, (dsets[\"train\"], dsets[\"dev\"], dsets[\"test\"])\n)\n\n\n# ------------------------- model --------------------------------------------\nclass SPRGNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb, self.color_emb = nn.Embedding(num_shapes, 8), nn.Embedding(\n            num_colors, 8\n        )\n        self.lin = nn.Linear(16, 32)\n        self.conv1, self.conv2 = GraphConv(32, 64), GraphConv(64, 64)\n        self.cls = nn.Linear(64, num_classes)\n\n    def forward(self, data):\n        x = torch.cat([self.shape_emb(data.x[:, 0]), self.color_emb(data.x[:, 1])], 1)\n        x = F.relu(self.lin(x))\n        x = F.relu(self.conv1(x, data.edge_index))\n        x = F.relu(self.conv2(x, data.edge_index))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\n# ------------------------- experiment dict ----------------------------------\nexperiment_data = {\"batch_size\": {}}  # <- hyperparam tuning type key\nbatch_sweep = [16, 32, 64, 128]\nepochs = 5\n\nfor bs in batch_sweep:\n    key = f\"bs_{bs}\"\n    experiment_data[\"batch_size\"][key] = {\n        \"metrics\": {\"train_compwa\": [], \"val_compwa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n    # loaders and model/opt\n    train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n    dev_loader = DataLoader(dev_data, batch_size=128, shuffle=False)\n    model = SPRGNN().to(device)\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n\n    # ------------- training loop -------------------------------------------\n    for epoch in range(1, epochs + 1):\n        model.train()\n        tot_loss = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            opt.zero_grad()\n            out = model(batch)\n            loss = criterion(out, batch.y)\n            loss.backward()\n            opt.step()\n            tot_loss += loss.item() * batch.num_graphs\n        avg_train_loss = tot_loss / len(train_loader.dataset)\n\n        # validation\n        model.eval()\n        vloss = 0\n        seqs = true = pred = []\n        all_seq, all_true, all_pred = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch)\n                l = criterion(out, batch.y)\n                vloss += l.item() * batch.num_graphs\n                pr = out.argmax(1).cpu().tolist()\n                lb = batch.y.cpu().tolist()\n                all_pred.extend(pr)\n                all_true.extend(lb)\n                all_seq.extend(batch.seq)\n        avg_val_loss = vloss / len(dev_loader.dataset)\n        compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n\n        # log\n        ed = experiment_data[\"batch_size\"][key]\n        ed[\"losses\"][\"train\"].append(avg_train_loss)\n        ed[\"losses\"][\"val\"].append(avg_val_loss)\n        ed[\"metrics\"][\"val_compwa\"].append(compwa)\n        ed[\"epochs\"].append(epoch)\n        print(\n            f\"[bs={bs}] Epoch {epoch}  train_loss {avg_train_loss:.4f}  \"\n            f\"val_loss {avg_val_loss:.4f}  CompWA {compwa:.4f}\"\n        )\n\n    # ------------- test ----------------------------------------------------\n    test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n    model.eval()\n    all_seq, all_true, all_pred = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            all_pred.extend(out.argmax(1).cpu().tolist())\n            all_true.extend(batch.y.cpu().tolist())\n            all_seq.extend(batch.seq)\n    test_compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n    experiment_data[\"batch_size\"][key][\"metrics\"][\"test_compwa\"] = test_compwa\n    experiment_data[\"batch_size\"][key][\"predictions\"] = all_pred\n    experiment_data[\"batch_size\"][key][\"ground_truth\"] = all_true\n    print(f\"[bs={bs}] Test CompWA {test_compwa:.4f}\")\n\n    # ------------- plots ---------------------------------------------------\n    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    plt.figure()\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"losses\"][\"train\"],\n        label=\"train\",\n    )\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"losses\"][\"val\"],\n        label=\"val\",\n    )\n    plt.title(f\"Loss (bs={bs})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_bs{bs}_{ts}.png\"))\n    plt.close()\n\n    plt.figure()\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"metrics\"][\"val_compwa\"],\n    )\n    plt.title(f\"Val CompWA (bs={bs})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.savefig(os.path.join(working_dir, f\"compwa_bs{bs}_{ts}.png\"))\n    plt.close()\n\n# ------------------------- save ---------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All runs complete. Data saved to ./working/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\nfrom datetime import datetime\nfrom typing import List\n\n# ------------------------- dirs & device ------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ------------------------- helper metrics -----------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef complexity_weighted_accuracy(\n    seqs: List[str], y_t: List[int], y_p: List[int]\n) -> float:\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(w_i if t == p else 0 for w_i, t, p in zip(w, y_t, y_p)) / (sum(w) or 1)\n\n\n# ------------------------- load (real or synth) SPR -------------------------\nspr_root = pathlib.Path(os.getenv(\"SPR_BENCH_PATH\", \"SPR_BENCH\"))\nif spr_root.exists():\n    from datasets import load_dataset\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(spr_root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dsets = {sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]}\n    print(\"Loaded real SPR_BENCH.\")\nelse:  # ---------- synthetic fallback\n    print(\"SPR_BENCH not found, generating synthetic data.\")\n\n    def make_synth(n):\n        shapes, colors = [\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"]\n        seqs, labels = [], []\n        for _ in range(n):\n            length = np.random.randint(4, 8)\n            seqs.append(\n                \" \".join(\n                    np.random.choice(shapes) + np.random.choice(colors)\n                    for _ in range(length)\n                )\n            )\n            labels.append(np.random.randint(0, 3))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    dsets = {\"train\": make_synth(500), \"dev\": make_synth(100), \"test\": make_synth(100)}\n\n# ------------------------- vocab & graph builder ----------------------------\nall_shapes, all_colors = set(), set()\nfor s in dsets[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        all_shapes.add(tok[0])\n        all_colors.add(tok[1])\nshape2idx = {s: i for i, s in enumerate(sorted(all_shapes))}\ncolor2idx = {c: i for i, c in enumerate(sorted(all_colors))}\nlabel2idx = {l: i for i, l in enumerate(sorted(set(dsets[\"train\"][\"label\"])))}\nnum_shapes, num_colors, num_classes = len(shape2idx), len(color2idx), len(label2idx)\n\n\ndef seq_to_graph(seq: str, label: int):\n    toks = seq.strip().split()\n    n = len(toks)\n    x = torch.tensor(\n        np.stack([[shape2idx[t[0]], color2idx[t[1]]] for t in toks]), dtype=torch.long\n    )\n    if n > 1:\n        src, dst = np.arange(n - 1), np.arange(1, n)\n        edge_index = torch.tensor(\n            np.vstack([np.hstack([src, dst]), np.hstack([dst, src])]), dtype=torch.long\n        )\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n    y = torch.tensor([label2idx[label]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y, seq=seq)\n\n\ndef build_dataset(split):\n    return (\n        [seq_to_graph(s, l) for s, l in zip(split[\"sequence\"], split[\"label\"])]\n        if isinstance(split, dict)\n        else [seq_to_graph(rec[\"sequence\"], rec[\"label\"]) for rec in split]\n    )\n\n\ntrain_data, dev_data, test_data = map(\n    build_dataset, (dsets[\"train\"], dsets[\"dev\"], dsets[\"test\"])\n)\n\n\n# ------------------------- model --------------------------------------------\nclass SPRGNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.shape_emb, self.color_emb = nn.Embedding(num_shapes, 8), nn.Embedding(\n            num_colors, 8\n        )\n        self.lin = nn.Linear(16, 32)\n        self.conv1, self.conv2 = GraphConv(32, 64), GraphConv(64, 64)\n        self.cls = nn.Linear(64, num_classes)\n\n    def forward(self, data):\n        x = torch.cat([self.shape_emb(data.x[:, 0]), self.color_emb(data.x[:, 1])], 1)\n        x = F.relu(self.lin(x))\n        x = F.relu(self.conv1(x, data.edge_index))\n        x = F.relu(self.conv2(x, data.edge_index))\n        x = global_mean_pool(x, data.batch)\n        return self.cls(x)\n\n\n# ------------------------- experiment dict ----------------------------------\nexperiment_data = {\"batch_size\": {}}  # <- hyperparam tuning type key\nbatch_sweep = [16, 32, 64, 128]\nepochs = 5\n\nfor bs in batch_sweep:\n    key = f\"bs_{bs}\"\n    experiment_data[\"batch_size\"][key] = {\n        \"metrics\": {\"train_compwa\": [], \"val_compwa\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n    # loaders and model/opt\n    train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n    dev_loader = DataLoader(dev_data, batch_size=128, shuffle=False)\n    model = SPRGNN().to(device)\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n\n    # ------------- training loop -------------------------------------------\n    for epoch in range(1, epochs + 1):\n        model.train()\n        tot_loss = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            opt.zero_grad()\n            out = model(batch)\n            loss = criterion(out, batch.y)\n            loss.backward()\n            opt.step()\n            tot_loss += loss.item() * batch.num_graphs\n        avg_train_loss = tot_loss / len(train_loader.dataset)\n\n        # validation\n        model.eval()\n        vloss = 0\n        seqs = true = pred = []\n        all_seq, all_true, all_pred = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = batch.to(device)\n                out = model(batch)\n                l = criterion(out, batch.y)\n                vloss += l.item() * batch.num_graphs\n                pr = out.argmax(1).cpu().tolist()\n                lb = batch.y.cpu().tolist()\n                all_pred.extend(pr)\n                all_true.extend(lb)\n                all_seq.extend(batch.seq)\n        avg_val_loss = vloss / len(dev_loader.dataset)\n        compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n\n        # log\n        ed = experiment_data[\"batch_size\"][key]\n        ed[\"losses\"][\"train\"].append(avg_train_loss)\n        ed[\"losses\"][\"val\"].append(avg_val_loss)\n        ed[\"metrics\"][\"val_compwa\"].append(compwa)\n        ed[\"epochs\"].append(epoch)\n        print(\n            f\"[bs={bs}] Epoch {epoch}  train_loss {avg_train_loss:.4f}  \"\n            f\"val_loss {avg_val_loss:.4f}  CompWA {compwa:.4f}\"\n        )\n\n    # ------------- test ----------------------------------------------------\n    test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n    model.eval()\n    all_seq, all_true, all_pred = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            all_pred.extend(out.argmax(1).cpu().tolist())\n            all_true.extend(batch.y.cpu().tolist())\n            all_seq.extend(batch.seq)\n    test_compwa = complexity_weighted_accuracy(all_seq, all_true, all_pred)\n    experiment_data[\"batch_size\"][key][\"metrics\"][\"test_compwa\"] = test_compwa\n    experiment_data[\"batch_size\"][key][\"predictions\"] = all_pred\n    experiment_data[\"batch_size\"][key][\"ground_truth\"] = all_true\n    print(f\"[bs={bs}] Test CompWA {test_compwa:.4f}\")\n\n    # ------------- plots ---------------------------------------------------\n    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    plt.figure()\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"losses\"][\"train\"],\n        label=\"train\",\n    )\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"losses\"][\"val\"],\n        label=\"val\",\n    )\n    plt.title(f\"Loss (bs={bs})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_bs{bs}_{ts}.png\"))\n    plt.close()\n\n    plt.figure()\n    plt.plot(\n        experiment_data[\"batch_size\"][key][\"epochs\"],\n        experiment_data[\"batch_size\"][key][\"metrics\"][\"val_compwa\"],\n    )\n    plt.title(f\"Val CompWA (bs={bs})\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.savefig(os.path.join(working_dir, f\"compwa_bs{bs}_{ts}.png\"))\n    plt.close()\n\n# ------------------------- save ---------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All runs complete. Data saved to ./working/experiment_data.npy\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'SPR_BENCH not found, creating synthetic toy\ndata.', '\\n', 'Epoch 1: train_loss = 1.1037 | val_loss = 1.0975 | CompWA =\n0.3068', '\\n', 'Epoch 2: train_loss = 1.0956 | val_loss = 1.0969 | CompWA =\n0.3125', '\\n', 'Epoch 3: train_loss = 1.0931 | val_loss = 1.0971 | CompWA =\n0.3201', '\\n', 'Epoch 4: train_loss = 1.0919 | val_loss = 1.0937 | CompWA =\n0.3447', '\\n', 'Epoch 5: train_loss = 1.0892 | val_loss = 1.0915 | CompWA =\n0.3655', '\\n', 'Test CompWA: 0.3920', '\\n', 'Training complete. Figures and data\nsaved in ./working', '\\n', 'Execution time: 2 seconds seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found, using synthetic toy data.',\n'\\n', '\\n=== Training with num_epochs=5 ===', '\\n', 'Finished num_epochs=5 | Val\nCompWA=0.3043 | Test CompWA=0.3055', '\\n', '\\n=== Training with num_epochs=15\n===', '\\n', 'Early stopping at epoch 6', '\\n', 'Finished num_epochs=15 | Val\nCompWA=0.2854 | Test CompWA=0.3359', '\\n', '\\n=== Training with num_epochs=30\n===', '\\n', 'Early stopping at epoch 6', '\\n', 'Finished num_epochs=30 | Val\nCompWA=0.2987 | Test CompWA=0.3435', '\\n', '\\n=== Training with num_epochs=50\n===', '\\n', 'Early stopping at epoch 6', '\\n', 'Finished num_epochs=50 | Val\nCompWA=0.2647 | Test CompWA=0.3681', '\\n', 'All done. Data saved to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_20-55-\n34_gnn_for_spr_attempt_0/0-run/process_ForkProcess-6/working', '\\n', 'Execution\ntime: 7 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\n===> Training with learning rate 1e-04', '\\n', '\nEpoch 1: train_loss=1.1083 val_loss=1.0979 CompWA=0.3939', '\\n', '  Epoch 2:\ntrain_loss=1.1046 val_loss=1.0970 CompWA=0.3939', '\\n', '  Epoch 3:\ntrain_loss=1.1025 val_loss=1.0964 CompWA=0.3939', '\\n', '  Epoch 4:\ntrain_loss=1.1006 val_loss=1.0961 CompWA=0.3939', '\\n', '  Epoch 5:\ntrain_loss=1.0993 val_loss=1.0960 CompWA=0.3939', '\\n', '  Test CompWA with lr\n1e-04: 0.3021', '\\n', '\\n===> Training with learning rate 3e-04', '\\n', '  Epoch\n1: train_loss=1.1020 val_loss=1.0971 CompWA=0.3939', '\\n', '  Epoch 2:\ntrain_loss=1.0984 val_loss=1.0977 CompWA=0.3447', '\\n', '  Epoch 3:\ntrain_loss=1.0976 val_loss=1.0981 CompWA=0.3277', '\\n', '  Epoch 4:\ntrain_loss=1.0967 val_loss=1.0978 CompWA=0.3598', '\\n', '  Epoch 5:\ntrain_loss=1.0960 val_loss=1.0981 CompWA=0.3504', '\\n', '  Test CompWA with lr\n3e-04: 0.3633', '\\n', '\\n===> Training with learning rate 1e-03', '\\n', '  Epoch\n1: train_loss=1.1058 val_loss=1.1070 CompWA=0.3030', '\\n', '  Epoch 2:\ntrain_loss=1.0961 val_loss=1.0911 CompWA=0.4564', '\\n', '  Epoch 3:\ntrain_loss=1.0943 val_loss=1.0904 CompWA=0.3920', '\\n', '  Epoch 4:\ntrain_loss=1.0915 val_loss=1.0941 CompWA=0.3049', '\\n', '  Epoch 5:\ntrain_loss=1.0906 val_loss=1.0936 CompWA=0.3485', '\\n', '  Test CompWA with lr\n1e-03: 0.4111', '\\n', '\\n===> Training with learning rate 3e-03', '\\n', '  Epoch\n1: train_loss=1.1052 val_loss=1.0953 CompWA=0.3201', '\\n', '  Epoch 2:\ntrain_loss=1.0954 val_loss=1.0917 CompWA=0.3409', '\\n', '  Epoch 3:\ntrain_loss=1.0930 val_loss=1.0915 CompWA=0.3409', '\\n', '  Epoch 4:\ntrain_loss=1.0889 val_loss=1.0919 CompWA=0.3485', '\\n', '  Epoch 5:\ntrain_loss=1.0868 val_loss=1.0908 CompWA=0.3485', '\\n', '  Test CompWA with lr\n3e-03: 0.3365', '\\n', '\\n===> Training with learning rate 1e-02', '\\n', '  Epoch\n1: train_loss=1.1278 val_loss=1.1051 CompWA=0.3030', '\\n', '  Epoch 2:\ntrain_loss=1.1000 val_loss=1.1016 CompWA=0.3220', '\\n', '  Epoch 3:\ntrain_loss=1.0979 val_loss=1.1011 CompWA=0.3182', '\\n', '  Epoch 4:\ntrain_loss=1.0952 val_loss=1.1003 CompWA=0.3182', '\\n', '  Epoch 5:\ntrain_loss=1.0965 val_loss=1.0986 CompWA=0.3258', '\\n', '  Test CompWA with lr\n1e-02: 0.3767', '\\n', 'All experiments complete. Raw data saved to\nexperiment_data.npy and plots in ./working', '\\n', 'Execution time: 5 seconds\nseconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found, using synthetic.', '\\n',\n'\\n===== Training with weight_decay=0 =====', '\\n', 'Epoch 1: train_loss 1.1054\n| val_loss 1.1082 | CompWA 0.1698', '\\n', 'Epoch 2: train_loss 1.0988 | val_loss\n1.1099 | CompWA 0.2176', '\\n', 'Epoch 3: train_loss 1.0966 | val_loss 1.1019 |\nCompWA 0.3550', '\\n', 'Epoch 4: train_loss 1.0950 | val_loss 1.1029 | CompWA\n0.3073', '\\n', 'Epoch 5: train_loss 1.0944 | val_loss 1.1103 | CompWA 0.2538',\n'\\n', 'Test CompWA for wd=0: 0.3535', '\\n', '\\n===== Training with\nweight_decay=1e-05 =====', '\\n', 'Epoch 1: train_loss 1.1036 | val_loss 1.0974 |\nCompWA 0.3740', '\\n', 'Epoch 2: train_loss 1.0969 | val_loss 1.1053 | CompWA\n0.2481', '\\n', 'Epoch 3: train_loss 1.0963 | val_loss 1.1054 | CompWA 0.2462',\n'\\n', 'Epoch 4: train_loss 1.0947 | val_loss 1.1019 | CompWA 0.2863', '\\n',\n'Epoch 5: train_loss 1.0932 | val_loss 1.1034 | CompWA 0.2805', '\\n', 'Test\nCompWA for wd=1e-05: 0.2892', '\\n', '\\n===== Training with weight_decay=0.0001\n=====', '\\n', 'Epoch 1: train_loss 1.1151 | val_loss 1.0981 | CompWA 0.4065',\n'\\n', 'Epoch 2: train_loss 1.1011 | val_loss 1.1116 | CompWA 0.2366', '\\n',\n'Epoch 3: train_loss 1.0999 | val_loss 1.1044 | CompWA 0.3225', '\\n', 'Epoch 4:\ntrain_loss 1.0957 | val_loss 1.1052 | CompWA 0.2252', '\\n', 'Epoch 5: train_loss\n1.0947 | val_loss 1.1089 | CompWA 0.2500', '\\n', 'Test CompWA for wd=0.0001:\n0.3308', '\\n', '\\n===== Training with weight_decay=0.0005 =====', '\\n', 'Epoch\n1: train_loss 1.1052 | val_loss 1.0957 | CompWA 0.2653', '\\n', 'Epoch 2:\ntrain_loss 1.0976 | val_loss 1.0969 | CompWA 0.2844', '\\n', 'Epoch 3: train_loss\n1.0947 | val_loss 1.1018 | CompWA 0.2481', '\\n', 'Epoch 4: train_loss 1.0937 |\nval_loss 1.1005 | CompWA 0.3473', '\\n', 'Epoch 5: train_loss 1.0921 | val_loss\n1.0996 | CompWA 0.2977', '\\n', 'Test CompWA for wd=0.0005: 0.3422', '\\n',\n'\\n===== Training with weight_decay=0.001 =====', '\\n', 'Epoch 1: train_loss\n1.1048 | val_loss 1.1033 | CompWA 0.3950', '\\n', 'Epoch 2: train_loss 1.0987 |\nval_loss 1.1126 | CompWA 0.3168', '\\n', 'Epoch 3: train_loss 1.0974 | val_loss\n1.1062 | CompWA 0.2309', '\\n', 'Epoch 4: train_loss 1.0942 | val_loss 1.1039 |\nCompWA 0.3244', '\\n', 'Epoch 5: train_loss 1.0910 | val_loss 1.1069 | CompWA\n0.2519', '\\n', 'Test CompWA for wd=0.001: 0.3327', '\\n', 'All done, results\nstored in ./working', '\\n', 'Execution time: 4 seconds seconds (time limit is 30\nminutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found, generating synthetic\ndata.', '\\n', '[bs=16] Epoch 1  train_loss 1.1053  val_loss 1.0995  CompWA\n0.2955', '\\n', '[bs=16] Epoch 2  train_loss 1.0991  val_loss 1.0972  CompWA\n0.3428', '\\n', '[bs=16] Epoch 3  train_loss 1.0924  val_loss 1.0930  CompWA\n0.3561', '\\n', '[bs=16] Epoch 4  train_loss 1.0958  val_loss 1.0912  CompWA\n0.3447', '\\n', '[bs=16] Epoch 5  train_loss 1.0863  val_loss 1.0917  CompWA\n0.3674', '\\n', '[bs=16] Test CompWA 0.3728', '\\n', '[bs=32] Epoch 1  train_loss\n1.1045  val_loss 1.1020  CompWA 0.3030', '\\n', '[bs=32] Epoch 2  train_loss\n1.0971  val_loss 1.0952  CompWA 0.3996', '\\n', '[bs=32] Epoch 3  train_loss\n1.0964  val_loss 1.0956  CompWA 0.3996', '\\n', '[bs=32] Epoch 4  train_loss\n1.0934  val_loss 1.0951  CompWA 0.3977', '\\n', '[bs=32] Epoch 5  train_loss\n1.0901  val_loss 1.0975  CompWA 0.3883', '\\n', '[bs=32] Test CompWA 0.3939',\n'\\n', '[bs=64] Epoch 1  train_loss 1.1058  val_loss 1.1070  CompWA 0.3030',\n'\\n', '[bs=64] Epoch 2  train_loss 1.0961  val_loss 1.0911  CompWA 0.4564',\n'\\n', '[bs=64] Epoch 3  train_loss 1.0943  val_loss 1.0904  CompWA 0.3920',\n'\\n', '[bs=64] Epoch 4  train_loss 1.0915  val_loss 1.0941  CompWA 0.3049',\n'\\n', '[bs=64] Epoch 5  train_loss 1.0906  val_loss 1.0936  CompWA 0.3485',\n'\\n', '[bs=64] Test CompWA 0.4111', '\\n', '[bs=128] Epoch 1  train_loss 1.1048\nval_loss 1.0959  CompWA 0.3163', '\\n', '[bs=128] Epoch 2  train_loss 1.1003\nval_loss 1.0992  CompWA 0.2708', '\\n', '[bs=128] Epoch 3  train_loss 1.0965\nval_loss 1.0949  CompWA 0.3598', '\\n', '[bs=128] Epoch 4  train_loss 1.0923\nval_loss 1.0932  CompWA 0.3636', '\\n', '[bs=128] Epoch 5  train_loss 1.0910\nval_loss 1.0937  CompWA 0.3258', '\\n', '[bs=128] Test CompWA 0.3576', '\\n', 'All\nruns complete. Data saved to ./working/experiment_data.npy', '\\n', 'Execution\ntime: 9 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found, generating synthetic\ndata.', '\\n', '[bs=16] Epoch 1  train_loss 1.1040  val_loss 1.0864  CompWA\n0.3889', '\\n', '[bs=16] Epoch 2  train_loss 1.0974  val_loss 1.1146  CompWA\n0.2739', '\\n', '[bs=16] Epoch 3  train_loss 1.1042  val_loss 1.1003  CompWA\n0.3123', '\\n', '[bs=16] Epoch 4  train_loss 1.0929  val_loss 1.1049  CompWA\n0.3410', '\\n', '[bs=16] Epoch 5  train_loss 1.0911  val_loss 1.1192  CompWA\n0.3161', '\\n', '[bs=16] Test CompWA 0.2852', '\\n', '[bs=32] Epoch 1  train_loss\n1.1059  val_loss 1.0992  CompWA 0.3755', '\\n', '[bs=32] Epoch 2  train_loss\n1.0989  val_loss 1.1034  CompWA 0.3506', '\\n', '[bs=32] Epoch 3  train_loss\n1.0959  val_loss 1.1059  CompWA 0.3199', '\\n', '[bs=32] Epoch 4  train_loss\n1.0948  val_loss 1.1072  CompWA 0.3103', '\\n', '[bs=32] Epoch 5  train_loss\n1.0951  val_loss 1.1082  CompWA 0.3199', '\\n', '[bs=32] Test CompWA 0.2270',\n'\\n', '[bs=64] Epoch 1  train_loss 1.1114  val_loss 1.1191  CompWA 0.2299',\n'\\n', '[bs=64] Epoch 2  train_loss 1.0974  val_loss 1.1008  CompWA 0.3487',\n'\\n', '[bs=64] Epoch 3  train_loss 1.0944  val_loss 1.0995  CompWA 0.3716',\n'\\n', '[bs=64] Epoch 4  train_loss 1.0938  val_loss 1.1026  CompWA 0.3276',\n'\\n', '[bs=64] Epoch 5  train_loss 1.0934  val_loss 1.1102  CompWA 0.3314',\n'\\n', '[bs=64] Test CompWA 0.2908', '\\n', '[bs=128] Epoch 1  train_loss 1.1124\nval_loss 1.0999  CompWA 0.2969', '\\n', '[bs=128] Epoch 2  train_loss 1.0962\nval_loss 1.1086  CompWA 0.3103', '\\n', '[bs=128] Epoch 3  train_loss 1.0940\nval_loss 1.1119  CompWA 0.3218', '\\n', '[bs=128] Epoch 4  train_loss 1.0926\nval_loss 1.1122  CompWA 0.3180', '\\n', '[bs=128] Epoch 5  train_loss 1.0918\nval_loss 1.1145  CompWA 0.3314', '\\n', '[bs=128] Test CompWA 0.2495', '\\n', 'All\nruns complete. Data saved to ./working/experiment_data.npy', '\\n', 'Execution\ntime: 9 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found, generating synthetic\ndata.', '\\n', '[bs=16] Epoch 1  train_loss 1.1077  val_loss 1.1123  CompWA\n0.3372', '\\n', '[bs=16] Epoch 2  train_loss 1.0994  val_loss 1.1118  CompWA\n0.3544', '\\n', '[bs=16] Epoch 3  train_loss 1.0971  val_loss 1.1118  CompWA\n0.2969', '\\n', '[bs=16] Epoch 4  train_loss 1.0919  val_loss 1.1158  CompWA\n0.3448', '\\n', '[bs=16] Epoch 5  train_loss 1.0902  val_loss 1.1176  CompWA\n0.3372', '\\n', '[bs=16] Test CompWA 0.3757', '\\n', '[bs=32] Epoch 1  train_loss\n1.1026  val_loss 1.1055  CompWA 0.3506', '\\n', '[bs=32] Epoch 2  train_loss\n1.0993  val_loss 1.1023  CompWA 0.3180', '\\n', '[bs=32] Epoch 3  train_loss\n1.0935  val_loss 1.1046  CompWA 0.3199', '\\n', '[bs=32] Epoch 4  train_loss\n1.0919  val_loss 1.1060  CompWA 0.3103', '\\n', '[bs=32] Epoch 5  train_loss\n1.0926  val_loss 1.1061  CompWA 0.3352', '\\n', '[bs=32] Test CompWA 0.3834',\n'\\n', '[bs=64] Epoch 1  train_loss 1.1073  val_loss 1.1040  CompWA 0.3372',\n'\\n', '[bs=64] Epoch 2  train_loss 1.0973  val_loss 1.1029  CompWA 0.3238',\n'\\n', '[bs=64] Epoch 3  train_loss 1.0947  val_loss 1.1033  CompWA 0.3372',\n'\\n', '[bs=64] Epoch 4  train_loss 1.0934  val_loss 1.1040  CompWA 0.3429',\n'\\n', '[bs=64] Epoch 5  train_loss 1.0923  val_loss 1.1015  CompWA 0.3276',\n'\\n', '[bs=64] Test CompWA 0.3776', '\\n', '[bs=128] Epoch 1  train_loss 1.1095\nval_loss 1.1011  CompWA 0.3218', '\\n', '[bs=128] Epoch 2  train_loss 1.0973\nval_loss 1.1035  CompWA 0.3352', '\\n', '[bs=128] Epoch 3  train_loss 1.0965\nval_loss 1.1057  CompWA 0.3314', '\\n', '[bs=128] Epoch 4  train_loss 1.0967\nval_loss 1.1049  CompWA 0.3314', '\\n', '[bs=128] Epoch 5  train_loss 1.0956\nval_loss 1.1026  CompWA 0.3352', '\\n', '[bs=128] Test CompWA 0.3661', '\\n', 'All\nruns complete. Data saved to ./working/experiment_data.npy', '\\n', 'Execution\ntime: 4 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found, generating synthetic\ndata.', '\\n', '[bs=16] Epoch 1  train_loss 1.1069  val_loss 1.1021  CompWA\n0.2973', '\\n', '[bs=16] Epoch 2  train_loss 1.0948  val_loss 1.0999  CompWA\n0.3069', '\\n', '[bs=16] Epoch 3  train_loss 1.0948  val_loss 1.1015  CompWA\n0.2954', '\\n', '[bs=16] Epoch 4  train_loss 1.0912  val_loss 1.1049  CompWA\n0.3127', '\\n', '[bs=16] Epoch 5  train_loss 1.0914  val_loss 1.1024  CompWA\n0.2896', '\\n', '[bs=16] Test CompWA 0.4189', '\\n', '[bs=32] Epoch 1  train_loss\n1.1013  val_loss 1.1063  CompWA 0.2973', '\\n', '[bs=32] Epoch 2  train_loss\n1.0955  val_loss 1.1069  CompWA 0.3089', '\\n', '[bs=32] Epoch 3  train_loss\n1.0904  val_loss 1.1049  CompWA 0.3398', '\\n', '[bs=32] Epoch 4  train_loss\n1.0853  val_loss 1.1110  CompWA 0.3127', '\\n', '[bs=32] Epoch 5  train_loss\n1.0835  val_loss 1.1095  CompWA 0.3205', '\\n', '[bs=32] Test CompWA 0.4094',\n'\\n', '[bs=64] Epoch 1  train_loss 1.0993  val_loss 1.1024  CompWA 0.3436',\n'\\n', '[bs=64] Epoch 2  train_loss 1.0955  val_loss 1.1005  CompWA 0.3359',\n'\\n', '[bs=64] Epoch 3  train_loss 1.0894  val_loss 1.1014  CompWA 0.2934',\n'\\n', '[bs=64] Epoch 4  train_loss 1.0886  val_loss 1.1040  CompWA 0.2896',\n'\\n', '[bs=64] Epoch 5  train_loss 1.0866  val_loss 1.1009  CompWA 0.3127',\n'\\n', '[bs=64] Test CompWA 0.3491', '\\n', '[bs=128] Epoch 1  train_loss 1.0984\nval_loss 1.1042  CompWA 0.2876', '\\n', '[bs=128] Epoch 2  train_loss 1.0958\nval_loss 1.1053  CompWA 0.2876', '\\n', '[bs=128] Epoch 3  train_loss 1.0945\nval_loss 1.0995  CompWA 0.2973', '\\n', '[bs=128] Epoch 4  train_loss 1.0915\nval_loss 1.1018  CompWA 0.3108', '\\n', '[bs=128] Epoch 5  train_loss 1.0900\nval_loss 1.1077  CompWA 0.2799', '\\n', '[bs=128] Test CompWA 0.3340', '\\n', 'All\nruns complete. Data saved to ./working/experiment_data.npy', '\\n', 'Execution\ntime: 4 seconds seconds (time limit is 30 minutes).']", ""], "analysis": ["", "The execution of the training script completed successfully without any errors\nor bugs. The script evaluated different values for the `num_epochs`\nhyperparameter and utilized early stopping based on validation loss. The results\nshowed that the model achieved the best test Complexity-Weighted Accuracy\n(CompWA) of 0.3681 with `num_epochs=50`. However, the early stopping mechanism\ntriggered at epoch 6 for all configurations except for `num_epochs=5`. The\nsynthetic toy data was used instead of the real SPR_BENCH dataset. All results\nand experiment data were saved as expected.", "", "The execution completed successfully without any bugs. The training script ran\nmultiple experiments with different weight decay hyperparameters, and the\nresults were saved appropriately. The script also produced a plot summarizing\nthe CompWA metric across different weight decay values. The results and outputs\nwere stored in the specified directory. No issues were encountered during the\nexecution.", "The execution of the training script completed successfully without any bugs.\nThe script generated synthetic data due to the absence of the SPR_BENCH dataset,\ntrained the model with different batch sizes, and evaluated the performance\nusing the Complexity-Weighted Accuracy (CompWA) metric. The results were saved,\nand plots were generated for further analysis. The training and validation\nlosses, along with the CompWA metric, show reasonable behavior for a first\nattempt. No immediate issues were observed in the output.", "", "", "", ""], "exc_type": [null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating the model's performance on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.089228, "best_value": 1.089228}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset, used to gauge the model's performance on unseen data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.091475, "best_value": 1.091475}]}, {"metric_name": "validation Complexity-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy metric weighted by complexity on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.36553, "best_value": 0.36553}]}, {"metric_name": "test Complexity-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy metric weighted by complexity on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.391969, "best_value": 0.391969}]}]}, {"metric_names": [{"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by complexity on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.3043, "best_value": 0.3043}]}, {"metric_name": "test complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by complexity on the test set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.3055, "best_value": 0.3055}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Loss value on the training set at the end of training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.091311, "best_value": 1.091311}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss value on the validation set at the end of training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.112126, "best_value": 1.112126}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Loss value for the training dataset.", "data": [{"dataset_name": "wd_0", "final_value": 1.0943584184646606, "best_value": 1.0943584184646606}, {"dataset_name": "wd_1e-05", "final_value": 1.0931620817184449, "best_value": 1.0931620817184449}, {"dataset_name": "wd_0.0001", "final_value": 1.0946537275314332, "best_value": 1.0946537275314332}, {"dataset_name": "wd_0.0005", "final_value": 1.0921184406280517, "best_value": 1.0921184406280517}, {"dataset_name": "wd_0.001", "final_value": 1.0909885768890382, "best_value": 1.0909885768890382}]}, {"metric_name": "validation complexity weighted accuracy", "lower_is_better": false, "description": "Complexity weighted accuracy for the validation dataset.", "data": [{"dataset_name": "wd_0", "final_value": 0.2538167938931298, "best_value": 0.2538167938931298}, {"dataset_name": "wd_1e-05", "final_value": 0.28053435114503816, "best_value": 0.28053435114503816}, {"dataset_name": "wd_0.0001", "final_value": 0.25, "best_value": 0.25}, {"dataset_name": "wd_0.0005", "final_value": 0.29770992366412213, "best_value": 0.29770992366412213}, {"dataset_name": "wd_0.001", "final_value": 0.25190839694656486, "best_value": 0.25190839694656486}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss value for the validation dataset.", "data": [{"dataset_name": "wd_0", "final_value": 1.1103160381317139, "best_value": 1.1103160381317139}, {"dataset_name": "wd_1e-05", "final_value": 1.103369951248169, "best_value": 1.103369951248169}, {"dataset_name": "wd_0.0001", "final_value": 1.108932614326477, "best_value": 1.108932614326477}, {"dataset_name": "wd_0.0005", "final_value": 1.0996052026748657, "best_value": 1.0996052026748657}, {"dataset_name": "wd_0.001", "final_value": 1.1068536043167114, "best_value": 1.1068536043167114}]}, {"metric_name": "test complexity weighted accuracy", "lower_is_better": false, "description": "Complexity weighted accuracy for the test dataset.", "data": [{"dataset_name": "wd_0", "final_value": 0.3534971644612476, "best_value": 0.3534971644612476}, {"dataset_name": "wd_1e-05", "final_value": 0.2892249527410208, "best_value": 0.2892249527410208}, {"dataset_name": "wd_0.0001", "final_value": 0.33081285444234404, "best_value": 0.33081285444234404}, {"dataset_name": "wd_0.0005", "final_value": 0.34215500945179583, "best_value": 0.34215500945179583}, {"dataset_name": "wd_0.001", "final_value": 0.332703213610586, "best_value": 0.332703213610586}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during the training phase.", "data": [{"dataset_name": "bs_16", "final_value": 1.0863, "best_value": 1.0863}, {"dataset_name": "bs_32", "final_value": 1.0901, "best_value": 1.0901}, {"dataset_name": "bs_64", "final_value": 1.0906, "best_value": 1.0906}, {"dataset_name": "bs_128", "final_value": 1.091, "best_value": 1.091}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during the validation phase.", "data": [{"dataset_name": "bs_16", "final_value": 1.0917, "best_value": 1.0917}, {"dataset_name": "bs_32", "final_value": 1.0975, "best_value": 1.0975}, {"dataset_name": "bs_64", "final_value": 1.0936, "best_value": 1.0936}, {"dataset_name": "bs_128", "final_value": 1.0937, "best_value": 1.0937}]}, {"metric_name": "validation CompWA", "lower_is_better": false, "description": "The best weighted average metric computed during validation.", "data": [{"dataset_name": "bs_16", "final_value": 0.3674, "best_value": 0.3674}, {"dataset_name": "bs_32", "final_value": 0.3996, "best_value": 0.3996}, {"dataset_name": "bs_64", "final_value": 0.4564, "best_value": 0.4564}, {"dataset_name": "bs_128", "final_value": 0.3636, "best_value": 0.3636}]}, {"metric_name": "test CompWA", "lower_is_better": false, "description": "The weighted average metric computed on the test set.", "data": [{"dataset_name": "bs_16", "final_value": 0.3728, "best_value": 0.3728}, {"dataset_name": "bs_32", "final_value": 0.3939, "best_value": 0.3939}, {"dataset_name": "bs_64", "final_value": 0.4111, "best_value": 0.4111}, {"dataset_name": "bs_128", "final_value": 0.3576, "best_value": 0.3576}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value indicating the model's performance on the training dataset.", "data": [{"dataset_name": "bs_16", "final_value": 1.0911, "best_value": 1.0911}, {"dataset_name": "bs_32", "final_value": 1.0951, "best_value": 1.0951}, {"dataset_name": "bs_64", "final_value": 1.0934, "best_value": 1.0934}, {"dataset_name": "bs_128", "final_value": 1.0918, "best_value": 1.0918}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value indicating the model's performance on the validation dataset.", "data": [{"dataset_name": "bs_16", "final_value": 1.1192, "best_value": 1.1192}, {"dataset_name": "bs_32", "final_value": 1.1082, "best_value": 1.1082}, {"dataset_name": "bs_64", "final_value": 1.1102, "best_value": 1.1102}, {"dataset_name": "bs_128", "final_value": 1.1145, "best_value": 1.1145}]}, {"metric_name": "validation CompWA", "lower_is_better": false, "description": "The composite weighted accuracy metric for the validation dataset.", "data": [{"dataset_name": "bs_16", "final_value": 0.3889, "best_value": 0.3889}, {"dataset_name": "bs_32", "final_value": 0.3755, "best_value": 0.3755}, {"dataset_name": "bs_64", "final_value": 0.3716, "best_value": 0.3716}, {"dataset_name": "bs_128", "final_value": 0.3314, "best_value": 0.3314}]}, {"metric_name": "test CompWA", "lower_is_better": false, "description": "The composite weighted accuracy metric for the test dataset.", "data": [{"dataset_name": "bs_16", "final_value": 0.2852, "best_value": 0.2852}, {"dataset_name": "bs_32", "final_value": 0.227, "best_value": 0.227}, {"dataset_name": "bs_64", "final_value": 0.2908, "best_value": 0.2908}, {"dataset_name": "bs_128", "final_value": 0.2495, "best_value": 0.2495}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The final and best training loss values for different batch sizes.", "data": [{"dataset_name": "bs_16", "final_value": 1.0902, "best_value": 1.0902}, {"dataset_name": "bs_32", "final_value": 1.0926, "best_value": 1.0926}, {"dataset_name": "bs_64", "final_value": 1.0923, "best_value": 1.0923}, {"dataset_name": "bs_128", "final_value": 1.0956, "best_value": 1.0956}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The final and best validation loss values for different batch sizes.", "data": [{"dataset_name": "bs_16", "final_value": 1.1176, "best_value": 1.1176}, {"dataset_name": "bs_32", "final_value": 1.1061, "best_value": 1.1061}, {"dataset_name": "bs_64", "final_value": 1.1015, "best_value": 1.1015}, {"dataset_name": "bs_128", "final_value": 1.1026, "best_value": 1.1026}]}, {"metric_name": "validation CompWA", "lower_is_better": false, "description": "The best validation CompWA score for different batch sizes.", "data": [{"dataset_name": "bs_16", "final_value": 0.3544, "best_value": 0.3544}, {"dataset_name": "bs_32", "final_value": 0.3506, "best_value": 0.3506}, {"dataset_name": "bs_64", "final_value": 0.3429, "best_value": 0.3429}, {"dataset_name": "bs_128", "final_value": 0.3352, "best_value": 0.3352}]}, {"metric_name": "test CompWA", "lower_is_better": false, "description": "The final test CompWA score for different batch sizes.", "data": [{"dataset_name": "bs_16", "final_value": 0.3757, "best_value": 0.3757}, {"dataset_name": "bs_32", "final_value": 0.3834, "best_value": 0.3834}, {"dataset_name": "bs_64", "final_value": 0.3776, "best_value": 0.3776}, {"dataset_name": "bs_128", "final_value": 0.3661, "best_value": 0.3661}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value computed on the training dataset.", "data": [{"dataset_name": "bs_16", "final_value": 1.0914, "best_value": 1.0914}, {"dataset_name": "bs_32", "final_value": 1.0835, "best_value": 1.0835}, {"dataset_name": "bs_64", "final_value": 1.0866, "best_value": 1.0866}, {"dataset_name": "bs_128", "final_value": 1.09, "best_value": 1.09}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value computed on the validation dataset.", "data": [{"dataset_name": "bs_16", "final_value": 1.1024, "best_value": 1.1024}, {"dataset_name": "bs_32", "final_value": 1.1095, "best_value": 1.1095}, {"dataset_name": "bs_64", "final_value": 1.1009, "best_value": 1.1009}, {"dataset_name": "bs_128", "final_value": 1.1077, "best_value": 1.1077}]}, {"metric_name": "validation CompWA", "lower_is_better": false, "description": "The best CompWA score achieved on the validation dataset.", "data": [{"dataset_name": "bs_16", "final_value": 0.3127, "best_value": 0.3127}, {"dataset_name": "bs_32", "final_value": 0.3398, "best_value": 0.3398}, {"dataset_name": "bs_64", "final_value": 0.3436, "best_value": 0.3436}, {"dataset_name": "bs_128", "final_value": 0.3108, "best_value": 0.3108}]}, {"metric_name": "test CompWA", "lower_is_better": false, "description": "The CompWA score computed on the test dataset.", "data": [{"dataset_name": "bs_16", "final_value": 0.4189, "best_value": 0.4189}, {"dataset_name": "bs_32", "final_value": 0.4094, "best_value": 0.4094}, {"dataset_name": "bs_64", "final_value": 0.3491, "best_value": 0.3491}, {"dataset_name": "bs_128", "final_value": 0.334, "best_value": 0.334}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, true, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/loss_20250830_205718.png", "../../logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/compwa_20250830_205718.png", "../../logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/SPR_BENCH_compwa_curve.png", "../../logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/loss_best_20250830_210109.png", "../../logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/val_compwa_best_20250830_210109.png", "../../logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_best_loss.png", "../../logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_val_compwa_bar.png", "../../logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_test_compwa_bar.png", "../../logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_epochs_run.png", "../../logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr1e-04_20250830_210106.png", "../../logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr1e-04_20250830_210106.png", "../../logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr3e-04_20250830_210107.png", "../../logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr3e-04_20250830_210107.png", "../../logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr1e-03_20250830_210107.png", "../../logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr1e-03_20250830_210107.png", "../../logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr3e-03_20250830_210108.png", "../../logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr3e-03_20250830_210108.png", "../../logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr1e-02_20250830_210108.png", "../../logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr1e-02_20250830_210108.png"], ["../../logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/wd_sweep_20250830_210102.png", "../../logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/synthetic_test_compwa_bar.png", "../../logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/synthetic_val_compwa_curves.png", "../../logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/synthetic_loss_curves.png"], ["../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs16_20250830_210116.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs16_20250830_210116.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs32_20250830_210118.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs32_20250830_210118.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs64_20250830_210119.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs64_20250830_210119.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs128_20250830_210119.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs128_20250830_210119.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs16.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs16.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs32.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs32.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs64.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs64.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs128.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs128.png", "../../logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/test_compwa_summary_SPR_synth.png"], ["../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs16_20250830_210256.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs16_20250830_210256.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs32_20250830_210258.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs32_20250830_210258.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs64_20250830_210259.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs64_20250830_210259.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs128_20250830_210259.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs128_20250830_210259.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_curve_SPR_synth_bs16.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_curve_SPR_synth_bs16.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_curve_SPR_synth_bs32.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_curve_SPR_synth_bs32.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_curve_SPR_synth_bs64.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_curve_SPR_synth_bs64.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_curve_SPR_synth_bs128.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_curve_SPR_synth_bs128.png", "../../logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/test_compwa_summary_SPR_synth.png"], ["../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs16_20250830_210254.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs16_20250830_210254.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs32_20250830_210255.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs32_20250830_210255.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs64_20250830_210255.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs64_20250830_210255.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs128_20250830_210255.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs128_20250830_210255.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_curve_SPR_synth_bs16.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_curve_SPR_synth_bs16.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_curve_SPR_synth_bs32.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_curve_SPR_synth_bs32.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_curve_SPR_synth_bs64.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_curve_SPR_synth_bs64.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_curve_SPR_synth_bs128.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_curve_SPR_synth_bs128.png", "../../logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/test_compwa_summary_SPR_synth.png"], ["../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs16_20250830_210254.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs16_20250830_210254.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs32_20250830_210254.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs32_20250830_210254.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs64_20250830_210255.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs64_20250830_210255.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs128_20250830_210255.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs128_20250830_210255.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_curve_SPR_synth_bs16.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_curve_SPR_synth_bs16.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_curve_SPR_synth_bs32.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_curve_SPR_synth_bs32.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_curve_SPR_synth_bs64.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_curve_SPR_synth_bs64.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_curve_SPR_synth_bs128.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_curve_SPR_synth_bs128.png", "../../logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/test_compwa_summary_SPR_synth.png"], ["../../logs/0-run/experiment_results/seed_aggregation_383c6b8874c54990b051cb548785b7d6/test_compwa_agg_unknown.png", "../../logs/0-run/experiment_results/seed_aggregation_383c6b8874c54990b051cb548785b7d6/loss_curve_agg_unknown_bs16.png", "../../logs/0-run/experiment_results/seed_aggregation_383c6b8874c54990b051cb548785b7d6/loss_curve_agg_unknown_bs32.png", "../../logs/0-run/experiment_results/seed_aggregation_383c6b8874c54990b051cb548785b7d6/loss_curve_agg_unknown_bs64.png", "../../logs/0-run/experiment_results/seed_aggregation_383c6b8874c54990b051cb548785b7d6/loss_curve_agg_unknown_bs128.png"]], "plot_paths": [["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/loss_20250830_205718.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/compwa_20250830_205718.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/SPR_BENCH_loss_curve.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/SPR_BENCH_compwa_curve.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/loss_best_20250830_210109.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/val_compwa_best_20250830_210109.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_best_loss.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_val_compwa_bar.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_test_compwa_bar.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_epochs_run.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr1e-04_20250830_210106.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr1e-04_20250830_210106.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr3e-04_20250830_210107.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr3e-04_20250830_210107.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr1e-03_20250830_210107.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr1e-03_20250830_210107.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr3e-03_20250830_210108.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr3e-03_20250830_210108.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr1e-02_20250830_210108.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr1e-02_20250830_210108.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/wd_sweep_20250830_210102.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/synthetic_test_compwa_bar.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/synthetic_val_compwa_curves.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/synthetic_loss_curves.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs16_20250830_210116.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs16_20250830_210116.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs32_20250830_210118.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs32_20250830_210118.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs64_20250830_210119.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs64_20250830_210119.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs128_20250830_210119.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs128_20250830_210119.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs16.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs16.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs32.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs32.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs64.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs64.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs128.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs128.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/test_compwa_summary_SPR_synth.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs16_20250830_210256.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs16_20250830_210256.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs32_20250830_210258.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs32_20250830_210258.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs64_20250830_210259.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs64_20250830_210259.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs128_20250830_210259.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs128_20250830_210259.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_curve_SPR_synth_bs16.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_curve_SPR_synth_bs16.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_curve_SPR_synth_bs32.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_curve_SPR_synth_bs32.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_curve_SPR_synth_bs64.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_curve_SPR_synth_bs64.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_curve_SPR_synth_bs128.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_curve_SPR_synth_bs128.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/test_compwa_summary_SPR_synth.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs16_20250830_210254.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs16_20250830_210254.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs32_20250830_210255.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs32_20250830_210255.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs64_20250830_210255.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs64_20250830_210255.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs128_20250830_210255.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs128_20250830_210255.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_curve_SPR_synth_bs16.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_curve_SPR_synth_bs16.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_curve_SPR_synth_bs32.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_curve_SPR_synth_bs32.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_curve_SPR_synth_bs64.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_curve_SPR_synth_bs64.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_curve_SPR_synth_bs128.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_curve_SPR_synth_bs128.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/test_compwa_summary_SPR_synth.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs16_20250830_210254.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs16_20250830_210254.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs32_20250830_210254.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs32_20250830_210254.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs64_20250830_210255.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs64_20250830_210255.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs128_20250830_210255.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs128_20250830_210255.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_curve_SPR_synth_bs16.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_curve_SPR_synth_bs16.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_curve_SPR_synth_bs32.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_curve_SPR_synth_bs32.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_curve_SPR_synth_bs64.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_curve_SPR_synth_bs64.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_curve_SPR_synth_bs128.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_curve_SPR_synth_bs128.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/test_compwa_summary_SPR_synth.png"], ["experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_383c6b8874c54990b051cb548785b7d6/test_compwa_agg_unknown.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_383c6b8874c54990b051cb548785b7d6/loss_curve_agg_unknown_bs16.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_383c6b8874c54990b051cb548785b7d6/loss_curve_agg_unknown_bs32.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_383c6b8874c54990b051cb548785b7d6/loss_curve_agg_unknown_bs64.png", "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/seed_aggregation_383c6b8874c54990b051cb548785b7d6/loss_curve_agg_unknown_bs128.png"]], "plot_analyses": [[{"analysis": "This plot shows the training and validation loss trajectories over five epochs. Both losses decrease steadily, indicating that the model is learning effectively. The gap between training and validation loss remains small, suggesting that the model is not overfitting at this stage. However, further epochs should be monitored to ensure this trend continues.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/loss_20250830_205718.png"}, {"analysis": "This plot depicts the validation Complexity-Weighted Accuracy (CompWA) over five epochs. The CompWA improves consistently, indicating that the model's performance on the validation set is getting better as training progresses. This is a positive sign of the model's ability to generalize.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/compwa_20250830_205718.png"}, {"analysis": "This plot repeats the training and validation loss trajectories, reinforcing the observation that both losses decrease steadily. The consistency between this and the earlier loss plot confirms the reliability of the training process.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/SPR_BENCH_loss_curve.png"}, {"analysis": "This plot shows the validation Complexity-Weighted Accuracy (CompWA) over five epochs, similar to the earlier CompWA plot. The steady increase in CompWA highlights the model's improving performance on the validation set, confirming its ability to learn effectively.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/SPR_BENCH_compwa_curve.png"}, {"analysis": "This confusion matrix provides insights into the model's performance on the test set. The diagonal elements represent correct predictions, while off-diagonal elements indicate misclassifications. The model shows reasonable performance, but there are noticeable misclassifications, especially for class 1. Future work could focus on improving the model's ability to distinguish between these classes.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_4c738d63e6724eb6863da4464bfa2f48_proc_1488362/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The training loss decreases steadily over the epochs, indicating that the model is learning effectively. However, the validation loss increases, which suggests overfitting. The model performs better on the training data but fails to generalize well to the validation data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/loss_best_20250830_210109.png"}, {"analysis": "The best validation Composite Weighted Accuracy (CompWA) is recorded at epoch 5, with a value of approximately 0.305. This suggests that the model achieves its peak validation performance early in training, but further epochs do not improve this metric.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/val_compwa_best_20250830_210109.png"}, {"analysis": "This loss curve reaffirms the earlier observation where the training loss decreases while the validation loss increases. This divergence highlights overfitting, where the model memorizes the training data but fails to generalize.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_best_loss.png"}, {"analysis": "The validation Composite Weighted Accuracy (CompWA) is highest at 5 epochs and decreases with more epochs. This trend suggests that early stopping might be beneficial as the model's generalization ability diminishes with extended training.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_val_compwa_bar.png"}, {"analysis": "The test Composite Weighted Accuracy (CompWA) improves with the number of epochs, peaking at 50 epochs. This indicates that while validation performance saturates, test performance continues to improve, potentially due to the model learning more generalized patterns over longer training periods.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_test_compwa_bar.png"}, {"analysis": "The early-stopping effect plot shows that the model runs for fewer epochs when early stopping is applied, with the number of epochs increasing as the maximum allowed epochs increase. This suggests that early stopping is effective in preventing overfitting in shorter training settings.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_epochs_run.png"}, {"analysis": "The confusion matrix shows that the model struggles with certain classes, as evidenced by the diagonal dominance but with some misclassifications. This indicates that while the model performs reasonably well overall, there is room for improvement in capturing the distinctions between some classes.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_676f657204194f7aacd41c1bb1f00265_proc_1490560/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The training and validation loss curves show a steady decrease over the epochs, indicating that the model is learning with this learning rate. However, the validation loss plateauing at a higher value than the training loss suggests some underfitting or insufficient model capacity. The Val CompWA metric remains constant across epochs, indicating that the model is not improving its performance on this metric despite the reduction in loss. This could imply that the current learning rate is too low to allow significant updates to the model parameters.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr1e-04_20250830_210106.png"}, {"analysis": "The training loss decreases steadily, while the validation loss initially decreases but then starts to increase slightly after the second epoch. This might indicate the onset of overfitting. The Val CompWA metric shows a sharp decline initially, followed by a recovery and stabilization, suggesting that the model struggles to generalize well with this learning rate. This learning rate might be too high, leading to instability in the optimization process.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr1e-04_20250830_210106.png"}, {"analysis": "The training and validation loss curves both decrease, but the validation loss shows fluctuations, indicating potential instability or overfitting. The Val CompWA metric exhibits a sharp increase initially but then declines and partially recovers, showing inconsistency in performance. This learning rate might be on the higher side, causing the optimizer to overshoot optimal solutions.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr3e-04_20250830_210107.png"}, {"analysis": "The training loss decreases steadily, while the validation loss shows a slight plateauing behavior, suggesting that the model is learning but might be close to underfitting. The Val CompWA metric shows a consistent increase, indicating that the model is improving its generalization capability with this learning rate. This learning rate seems to strike a better balance between stability and learning.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/compwa_lr3e-04_20250830_210107.png"}, {"analysis": "The training loss decreases steadily, and the validation loss follows a similar trend, indicating that the model is learning effectively. The Val CompWA metric shows a consistent upward trend, suggesting improved performance on the validation set. This learning rate appears to be well-suited for the task and might be optimal among the tested rates.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cdb91d7976a0459abd8a2399bfa02196_proc_1490561/loss_lr1e-03_20250830_210107.png"}], [{"analysis": "The plot shows the effect of varying weight decay on the test Color-Weighted Accuracy (CompWA). The performance improves as weight decay increases from 10^-5 to 10^-4, reaching a peak at 10^-4. However, further increasing weight decay to 10^-3 results in a slight decline in performance. This suggests that moderate regularization via weight decay is beneficial, but excessive regularization can harm model performance.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/wd_sweep_20250830_210102.png"}, {"analysis": "This plot compares test CompWA for different weight decay values. The best performance is achieved with no weight decay (0.0) and with 0.0005, both yielding comparable results. Weight decay values of 10^-5 and 0.001 perform worse, indicating that the choice of weight decay significantly impacts performance and should be tuned carefully.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/synthetic_test_compwa_bar.png"}, {"analysis": "This plot tracks validation CompWA over epochs for different weight decay values. The trends show significant fluctuations in validation performance, particularly for weight decay values of 0.0 and 0.001. The instability suggests that the model's ability to generalize varies depending on weight decay. The weight decay of 0.0005 appears to provide relatively stable and competitive performance across epochs.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/synthetic_val_compwa_curves.png"}, {"analysis": "The plot compares train and validation cross-entropy loss across epochs for different weight decay values. The training loss decreases consistently for all weight decay values, but the validation loss shows different trends. For weight decay values of 0.0 and 0.001, the validation loss increases after an initial decrease, indicating potential overfitting. Weight decay values like 0.0005 show a more stable validation loss, suggesting better generalization.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_6f79636585ac470b86e12728be55da5f_proc_1490562/synthetic_loss_curves.png"}], [{"analysis": "This plot shows the training and validation loss for a batch size of 16 over 5 epochs. The training loss decreases consistently, indicating the model is learning. The validation loss initially decreases but then flattens and slightly increases after the third epoch, which may suggest the beginning of overfitting. The gap between training and validation loss is relatively small, which is a positive sign for generalization.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs16_20250830_210116.png"}, {"analysis": "This plot depicts the Validation Composite Weighted Accuracy (CompWA) for a batch size of 16. The metric increases steadily over the epochs, indicating the model's performance on the validation set improves with training. The upward trend suggests the model is effectively learning to generalize.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs16_20250830_210116.png"}, {"analysis": "This plot shows the training and validation loss for a batch size of 32 over 5 epochs. Both losses decrease consistently, with the validation loss plateauing after the third epoch. The training loss continues to drop, which may indicate slight overfitting. However, the validation loss remains stable, suggesting the model's generalization is not severely impacted.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs32_20250830_210118.png"}, {"analysis": "This plot represents the Validation Composite Weighted Accuracy (CompWA) for a batch size of 32. The metric improves significantly in the first two epochs and then stabilizes. The plateau after the second epoch suggests that the model's performance gains diminish with further training.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs32_20250830_210118.png"}, {"analysis": "This plot illustrates the training and validation loss for a batch size of 64 over 5 epochs. Both losses decrease, with the validation loss showing a slight increase after the third epoch. The training loss decreases more significantly, which may indicate overfitting. The gap between training and validation losses widens slightly, suggesting potential generalization issues.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs64_20250830_210119.png"}, {"analysis": "This plot shows the Validation Composite Weighted Accuracy (CompWA) for a batch size of 64. The metric improves notably in the first two epochs, peaks in the second epoch, and then declines before slightly recovering. The decline suggests overfitting or instability in the model's performance.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs64_20250830_210119.png"}, {"analysis": "This plot displays the training and validation loss for a batch size of 128 over 5 epochs. Both losses decrease, but the validation loss shows an increase after the second epoch, suggesting overfitting. The training loss continues to drop steadily, indicating the model is still learning on the training set.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_bs128_20250830_210119.png"}, {"analysis": "This plot represents the Validation Composite Weighted Accuracy (CompWA) for a batch size of 128. The metric initially improves but drops significantly after the second epoch, indicating overfitting or instability. The fluctuation in performance suggests the model struggles to generalize at this batch size.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_bs128_20250830_210119.png"}, {"analysis": "This plot shows the training and validation loss for a batch size of 16 on a synthetic dataset. Both losses decrease, with the validation loss flattening after the third epoch. The consistent decrease in training loss indicates the model is learning, while the stable validation loss suggests no significant overfitting.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/loss_curve_SPR_synth_bs16.png"}, {"analysis": "This plot compares the Test Composite Weighted Accuracy (CompWA) across different batch sizes. The best performance is observed with a batch size of 64, while the batch size of 128 shows the lowest performance. This suggests that a moderate batch size (64) achieves the best balance between training stability and generalization.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_ca1bec6343304b748fede089172b795c_proc_1490563/compwa_curve_SPR_synth_bs16.png"}], [{"analysis": "The training loss decreases steadily, indicating the model learns effectively with batch size 16. However, the validation loss fluctuates and increases after epoch 3, suggesting potential overfitting or insufficient generalization. The gap between training and validation loss widens, reinforcing the overfitting concern.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs16_20250830_210256.png"}, {"analysis": "Validation Color-Weighted Accuracy (CompWA) starts high but drops sharply by epoch 2, then recovers slightly before declining again. This instability implies the model struggles to generalize consistently, likely due to the small batch size.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs16_20250830_210256.png"}, {"analysis": "Training loss decreases consistently with batch size 32, showing effective learning. However, validation loss increases steadily, indicating overfitting as the model performs worse on unseen data. The smaller gap compared to batch size 16 suggests less severe overfitting.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs32_20250830_210258.png"}, {"analysis": "Validation CompWA decreases steadily with batch size 32, suggesting the model consistently struggles to generalize well, potentially due to insufficient capacity or improper hyperparameter settings.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs32_20250830_210258.png"}, {"analysis": "Training loss decreases steadily with batch size 64, and validation loss initially decreases but starts to increase after epoch 3. This suggests the model initially generalizes well but overfits as training progresses. The trend is more stable than batch sizes 16 and 32.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs64_20250830_210259.png"}, {"analysis": "Validation CompWA improves significantly until epoch 3 and then starts to decline. This trend suggests the model benefits from the larger batch size initially but cannot sustain generalization, possibly due to overfitting or insufficient training epochs.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs64_20250830_210259.png"}, {"analysis": "Training loss decreases steadily with batch size 128, while validation loss increases consistently. The widening gap between training and validation loss indicates significant overfitting, likely due to the large batch size reducing model updates.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_bs128_20250830_210259.png"}, {"analysis": "Validation CompWA increases steadily with batch size 128 but remains lower overall compared to smaller batch sizes. This suggests the model's performance is less effective at capturing the complex data relationships with larger batch sizes.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_bs128_20250830_210259.png"}, {"analysis": "The loss curve for batch size 16 shows significant instability in validation loss, with the training loss decreasing steadily. This reinforces the overfitting problem observed earlier, as the model fails to generalize effectively.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/loss_curve_SPR_synth_bs16.png"}, {"analysis": "The test CompWA across batch sizes highlights that batch size 64 achieves the highest performance, followed by 16, 128, and 32. This trend suggests that an intermediate batch size balances effective learning and generalization better than smaller or larger batch sizes.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/compwa_curve_SPR_synth_bs16.png"}], [{"analysis": "The training loss decreases steadily over the epochs, indicating effective learning by the model. However, the validation loss shows an upward trend, suggesting potential overfitting to the training data. Further regularization techniques or adjustments in hyperparameters might be needed to improve generalization.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs16_20250830_210254.png"}, {"analysis": "The validation Color-Weighted Accuracy (CompWA) fluctuates significantly across epochs, indicating instability in the model's performance. This could be due to the small batch size or suboptimal learning rate. Exploring more stable training configurations is recommended.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs16_20250830_210254.png"}, {"analysis": "The training loss decreases steadily, and the validation loss decreases initially but then plateaus, showing better generalization compared to the previous configuration. However, the gap between training and validation loss suggests some overfitting, albeit less pronounced.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs32_20250830_210255.png"}, {"analysis": "The validation Color-Weighted Accuracy (CompWA) shows a downward trend initially, followed by a recovery. This suggests that the model struggles to maintain consistent performance and might benefit from strategies like learning rate scheduling or data augmentation.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs32_20250830_210255.png"}, {"analysis": "The training loss decreases consistently, and the validation loss shows a slight decreasing trend, indicating improved generalization. However, the gap between training and validation loss is still noticeable, hinting at mild overfitting.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs64_20250830_210255.png"}, {"analysis": "The validation Color-Weighted Accuracy (CompWA) fluctuates but shows a slight improvement compared to smaller batch sizes. This indicates that a larger batch size might help stabilize performance, though further tuning is needed.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs64_20250830_210255.png"}, {"analysis": "The training loss decreases steadily, and the validation loss shows a slight decreasing trend, similar to the previous batch size. The trend suggests that increasing the batch size does not significantly affect the generalization performance.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_bs128_20250830_210255.png"}, {"analysis": "The validation Color-Weighted Accuracy (CompWA) improves slightly with larger batch sizes, but the fluctuations remain, indicating that batch size alone might not be sufficient to stabilize performance. Additional tuning of learning rate or training epochs might be necessary.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_bs128_20250830_210255.png"}, {"analysis": "The training loss decreases steadily, and the validation loss shows an upward trend, suggesting overfitting. The consistent pattern across different batch sizes indicates that the current model configuration might need regularization adjustments.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/loss_curve_SPR_synth_bs16.png"}, {"analysis": "The test Color-Weighted Accuracy (CompWA) is relatively stable across different batch sizes, with minor variations. This suggests that batch size has a limited impact on the final test performance, and other hyperparameters might be more critical for further improvement.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/compwa_curve_SPR_synth_bs16.png"}], [{"analysis": "The loss curves for training and validation indicate that the training loss decreases consistently with epochs, showing effective learning by the model. However, the validation loss does not follow a consistent trend, with fluctuations observed. This suggests potential overfitting or instability in the model's generalization capability for this batch size (16).", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs16_20250830_210254.png"}, {"analysis": "The validation Color-Weighted Accuracy (CompWA) metric shows significant fluctuations across epochs, indicating that the model's performance is not stable for this batch size (16). While there are peaks in performance, the drops suggest issues with generalization or sensitivity to the training process.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs16_20250830_210254.png"}, {"analysis": "For batch size 32, the training loss decreases steadily, indicating effective learning. The validation loss, however, shows a slight upward trend after the initial epochs, which may indicate overfitting as the model starts to memorize the training data.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs32_20250830_210254.png"}, {"analysis": "The validation CompWA metric for batch size 32 shows an upward trend initially, reaching a peak, but then drops significantly. This suggests that while the model may achieve good performance at certain points, it struggles to maintain consistent generalization, possibly due to overfitting or hyperparameter sensitivity.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs32_20250830_210254.png"}, {"analysis": "The training loss for batch size 64 decreases steadily, showing effective learning. The validation loss, however, remains relatively high and exhibits fluctuations, suggesting that the model may not generalize well to unseen data at this batch size.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs64_20250830_210255.png"}, {"analysis": "The validation CompWA metric for batch size 64 shows a declining trend after the first epoch, reaching a low point before slightly recovering. This indicates that the model's ability to generalize is reduced as the training progresses, possibly due to the batch size being too large for effective gradient updates.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs64_20250830_210255.png"}, {"analysis": "The training loss for batch size 128 decreases steadily, but the validation loss shows an increasing trend, suggesting significant overfitting. The larger batch size may be causing the model to converge to sharp minima that do not generalize well.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_bs128_20250830_210255.png"}, {"analysis": "The validation CompWA metric for batch size 128 shows an initial increase followed by a sharp decline, indicating poor generalization and instability in the model's performance. This could be due to the batch size being too large, leading to less frequent parameter updates and poorer gradient estimation.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_bs128_20250830_210255.png"}, {"analysis": "The bar chart for test CompWA across different batch sizes shows that smaller batch sizes (16 and 32) achieve better performance compared to larger batch sizes (64 and 128). This indicates that smaller batch sizes might be more suitable for this task, as they allow for more frequent parameter updates and better generalization.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/loss_curve_SPR_synth_bs16.png"}, {"analysis": "The loss curve for batch size 64 confirms the trends observed earlier, with the training loss decreasing steadily while the validation loss remains relatively high and fluctuates. This reinforces the observation that this batch size may not be optimal for achieving good generalization.", "plot_path": "experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/compwa_curve_SPR_synth_bs16.png"}], []], "vlm_feedback_summary": ["The provided plots demonstrate steady improvement in model performance, with\ndecreasing losses and increasing validation Complexity-Weighted Accuracy. The\nconfusion matrix indicates reasonable test set performance but highlights areas\nfor improvement in class-specific predictions.", "The plots reveal that the model is overfitting, as indicated by the divergence\nbetween training and validation losses. Early stopping at around 5 epochs\nappears beneficial for validation performance, but test performance continues to\nimprove with more epochs. The confusion matrix highlights some\nmisclassifications, suggesting potential areas for improvement in class-specific\npredictions.", "The analysis highlights the impact of different learning rates on model\nperformance. Lower learning rates lead to slower learning and potential\nunderfitting, while higher rates introduce instability or overfitting. A mid-\nrange learning rate, such as 1e-02, provides a good balance, enabling the model\nto effectively learn and generalize, as evidenced by consistent improvements in\nthe Val CompWA metric.", "The experimental results indicate that weight decay plays a critical role in\nmodel performance and generalization. Moderate weight decay values (e.g.,\n0.0005) strike a balance between underfitting and overfitting, as evidenced by\nstable validation loss and competitive test CompWA. However, excessive or\ninsufficient weight decay harms performance, either by over-regularizing or\nfailing to prevent overfitting.", "The plots provide insights into the training dynamics and validation performance\nacross different batch sizes. Lower batch sizes (16 and 32) show stable\nperformance with minimal overfitting, while larger batch sizes (64 and 128)\nexhibit signs of overfitting and instability. A batch size of 64 achieves the\nhighest Test Composite Weighted Accuracy, suggesting it is optimal for this\ntask.", "The analysis highlights significant overfitting across all batch sizes, with\nbatch size 64 achieving the best balance between learning and generalization.\nSmaller batch sizes show instability, while larger batch sizes lead to reduced\ngeneralization. Adjusting hyperparameters or using regularization techniques may\nimprove performance.", "The plots suggest that while the model exhibits effective learning on the\ntraining data, generalization to validation and test datasets is inconsistent.\nValidation loss trends and fluctuating Color-Weighted Accuracy indicate\npotential overfitting and instability. Strategies like regularization, learning\nrate adjustments, and data augmentation are recommended to improve performance.", "The analysis of the plots reveals that smaller batch sizes (16 and 32) yield\nbetter generalization and performance, as indicated by the validation CompWA\nmetric and test performance. Larger batch sizes (64 and 128) show signs of\noverfitting and instability in generalization. The validation loss fluctuations\nand trends suggest that hyperparameter tuning, especially for batch size, is\ncrucial for improving model performance.", "[]"], "exec_time": [2.993237018585205, 7.348408222198486, 5.401106357574463, 4.055068016052246, 9.628192663192749, 9.30691933631897, 4.986776351928711, 4.910961627960205, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["['dataset_1'", "'dataset_2'", "'dataset_3']"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"Synthetic SPR_BENCH\"]"], ["[\"SPR_synth_bs16\"", "\"SPR_synth_bs32\"", "\"synthetic_bs16\"]"], ["['SPR_synth']"], ["[]"], ["['SPR_synth']"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# prepare working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# iterate through each dataset stored\nfor dname, dct in experiment_data.items():\n    epochs = dct.get(\"epochs\", None)\n    train_losses = dct.get(\"losses\", {}).get(\"train\", [])\n    val_losses = dct.get(\"losses\", {}).get(\"val\", [])\n    val_compwa = dct.get(\"metrics\", {}).get(\"val_compwa\", [])\n    preds = np.array(dct.get(\"predictions\", []))\n    gts = np.array(dct.get(\"ground_truth\", []))\n\n    # 1) Loss curves\n    try:\n        if len(epochs) and len(train_losses) and len(val_losses):\n            plt.figure()\n            plt.plot(epochs, train_losses, label=\"Train Loss\")\n            plt.plot(epochs, val_losses, label=\"Val Loss\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.title(f\"{dname} \u2013 Training vs Validation Loss\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dname}_loss_curve.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {dname}: {e}\")\n        plt.close()\n\n    # 2) CompWA curve\n    try:\n        if len(epochs) and len(val_compwa):\n            plt.figure()\n            plt.plot(epochs, val_compwa, label=\"Val CompWA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"CompWA\")\n            plt.title(f\"{dname} \u2013 Validation Complexity-Weighted Accuracy\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dname}_compwa_curve.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating CompWA plot for {dname}: {e}\")\n        plt.close()\n\n    # 3) Confusion matrix heat-map (optional)\n    try:\n        if preds.size and gts.size:\n            classes = sorted(list(set(gts) | set(preds)))\n            conf = np.zeros((len(classes), len(classes)), dtype=int)\n            for t, p in zip(gts, preds):\n                conf[classes.index(t), classes.index(p)] += 1\n            plt.figure()\n            im = plt.imshow(conf, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xticks(range(len(classes)), classes)\n            plt.yticks(range(len(classes)), classes)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(f\"{dname} \u2013 Confusion Matrix (Test Set)\")\n            fname = os.path.join(working_dir, f\"{dname}_confusion_matrix.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dname}: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- Load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nspr_data = experiment_data.get(\"num_epochs_tuning\", {}).get(\"SPR_BENCH\", {})\n\nhparams = spr_data.get(\"hparam_values\", [])\nepochs_run = spr_data.get(\"epochs_run\", [])\nloss_tr = spr_data.get(\"losses\", {}).get(\"train\", [])\nloss_val = spr_data.get(\"losses\", {}).get(\"val\", [])\nval_cwa = spr_data.get(\"metrics\", {}).get(\"val_compwa\", [])\ntest_cwa = spr_data.get(\"metrics\", {}).get(\"test_compwa\", [])\npredictions = spr_data.get(\"predictions\", [])\nground_truth = spr_data.get(\"ground_truth\", [])\n\n# ---------- Identify best configuration ----------\nbest_idx = int(np.argmax(val_cwa)) if val_cwa else None\n\n# ---- 1. Best loss curve ----\ntry:\n    if best_idx is not None:\n        plt.figure()\n        ep_range = range(1, len(loss_tr[best_idx]) + 1)\n        plt.plot(ep_range, loss_tr[best_idx], label=\"Train\")\n        plt.plot(ep_range, loss_val[best_idx], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH Loss Curve (Best num_epochs={})\".format(hparams[best_idx]))\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_best_loss.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating best loss plot: {e}\")\n    plt.close()\n\n# ---- 2. Validation CompWA per hyper-param ----\ntry:\n    if val_cwa:\n        plt.figure()\n        plt.bar([str(h) for h in hparams], val_cwa, color=\"skyblue\")\n        plt.xlabel(\"num_epochs\")\n        plt.ylabel(\"Validation CompWA\")\n        plt.title(\"SPR_BENCH Validation CompWA vs. num_epochs\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_compwa_bar.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating val CompWA bar: {e}\")\n    plt.close()\n\n# ---- 3. Test CompWA per hyper-param ----\ntry:\n    if test_cwa:\n        plt.figure()\n        plt.bar([str(h) for h in hparams], test_cwa, color=\"lightgreen\")\n        plt.xlabel(\"num_epochs\")\n        plt.ylabel(\"Test CompWA\")\n        plt.title(\"SPR_BENCH Test CompWA vs. num_epochs\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_test_compwa_bar.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test CompWA bar: {e}\")\n    plt.close()\n\n# ---- 4. Epochs actually run ----\ntry:\n    if epochs_run:\n        plt.figure()\n        plt.bar([str(h) for h in hparams], epochs_run, color=\"salmon\")\n        plt.xlabel(\"num_epochs setting\")\n        plt.ylabel(\"Epochs Run\")\n        plt.title(\"SPR_BENCH Early-Stopping Effect (Epochs Run)\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_epochs_run.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating epochs-run bar: {e}\")\n    plt.close()\n\n# ---- 5. Confusion matrix for best config ----\ntry:\n    if best_idx is not None and predictions:\n        preds = np.array(predictions[best_idx])\n        truth = np.array(ground_truth)\n        classes = np.unique(np.concatenate([truth, preds]))\n        cm = np.zeros((len(classes), len(classes)), dtype=int)\n        for t, p in zip(truth, preds):\n            cm[t, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im, fraction=0.046, pad=0.04)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\n            \"SPR_BENCH Confusion Matrix (Best num_epochs={})\".format(hparams[best_idx])\n        )\n        plt.xticks(classes)\n        plt.yticks(classes)\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    exp = np.load(\"experiment_data.npy\", allow_pickle=True).item()\n    lr_data = exp[\"learning_rate\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    lr_data = {}\n\n# Collect common information\nlrs_sorted = sorted(lr_data.keys(), key=lambda x: float(x.replace(\"e\", \"e+\")))\ncolors = plt.cm.tab10(np.linspace(0, 1, len(lrs_sorted)))\n\n# 1) Train / Val loss curves in one figure\ntry:\n    plt.figure()\n    for clr, lr in zip(colors, lrs_sorted):\n        epochs = lr_data[lr][\"epochs\"]\n        plt.plot(\n            epochs,\n            lr_data[lr][\"losses\"][\"train\"],\n            color=clr,\n            linestyle=\"-\",\n            label=f\"train lr={lr}\",\n        )\n        plt.plot(\n            epochs,\n            lr_data[lr][\"losses\"][\"val\"],\n            color=clr,\n            linestyle=\"--\",\n            label=f\"val lr={lr}\",\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"SPR_BENCH: Train vs Val Loss Curves\")\n    plt.legend(fontsize=7)\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve figure: {e}\")\n    plt.close()\n\n# 2) Validation CompWA curves\ntry:\n    plt.figure()\n    for clr, lr in zip(colors, lrs_sorted):\n        epochs = lr_data[lr][\"epochs\"]\n        plt.plot(\n            epochs, lr_data[lr][\"metrics\"][\"val_compwa\"], color=clr, label=f\"lr={lr}\"\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.title(\"SPR_BENCH: Validation CompWA over Epochs\")\n    plt.legend(fontsize=7)\n    fname = os.path.join(working_dir, \"SPR_BENCH_val_compwa_curves.png\")\n    plt.savefig(fname, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CompWA curve figure: {e}\")\n    plt.close()\n\n# 3) Test CompWA bar chart\ntry:\n    plt.figure()\n    test_scores = [lr_data[lr][\"metrics\"][\"test_compwa\"] for lr in lrs_sorted]\n    plt.bar(range(len(lrs_sorted)), test_scores, color=colors)\n    plt.xticks(range(len(lrs_sorted)), lrs_sorted, rotation=45)\n    plt.ylabel(\"CompWA\")\n    plt.title(\"SPR_BENCH: Test CompWA vs Learning Rate\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_test_compwa_bar.png\")\n    plt.savefig(fname, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating Test CompWA bar figure: {e}\")\n    plt.close()\n\nprint(\"Plots saved to:\", working_dir)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------------------------------\n# load data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    wd_dict = experiment_data.get(\"weight_decay\", {})\n    tags = list(wd_dict.keys())  # e.g. ['wd_0', 'wd_1e-5', ...]\n    # numeric wd values for x-axis ordering\n    wd_vals = [float(t.split(\"_\", 1)[1]) for t in tags]\n    order = np.argsort(wd_vals)\n    tags = [tags[i] for i in order]\n    wd_vals = [wd_vals[i] for i in order]\n\n    # gather metrics\n    test_compwa = [wd_dict[t][\"metrics\"][\"test_compwa\"] for t in tags]\n    max_epochs = max(len(wd_dict[t][\"epochs\"]) for t in tags)\n\n    # --------------------- Figure 1 : Test CompWA bar ----------------------\n    try:\n        plt.figure()\n        plt.bar(range(len(wd_vals)), test_compwa)\n        plt.xticks(range(len(wd_vals)), [str(w) for w in wd_vals])\n        plt.xlabel(\"Weight Decay\")\n        plt.ylabel(\"Test CompWA\")\n        plt.title(\"Synthetic SPR_BENCH: Test CompWA vs Weight Decay\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"synthetic_test_compwa_bar.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating bar chart: {e}\")\n        plt.close()\n\n    # -------- Figure 2 : Validation CompWA curves across epochs ------------\n    try:\n        plt.figure()\n        for t, w in zip(tags, wd_vals):\n            epochs = wd_dict[t][\"epochs\"]\n            vals = wd_dict[t][\"metrics\"][\"val_compwa\"]\n            if vals:\n                plt.plot(epochs, vals, marker=\"o\", label=f\"wd={w}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation CompWA\")\n        plt.title(\"Synthetic SPR_BENCH: Val CompWA over Epochs\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"synthetic_val_compwa_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CompWA curve plot: {e}\")\n        plt.close()\n\n    # -------- Figure 3 : Train/Val loss curves across epochs --------------\n    try:\n        plt.figure()\n        for t, w in zip(tags, wd_vals):\n            ep = wd_dict[t][\"epochs\"]\n            tr = wd_dict[t][\"losses\"][\"train\"]\n            vl = wd_dict[t][\"losses\"][\"val\"]\n            plt.plot(ep, tr, label=f\"train wd={w}\")\n            plt.plot(ep, vl, linestyle=\"--\", label=f\"val wd={w}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"Synthetic SPR_BENCH: Train vs Val Loss\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"synthetic_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # --------------------- print summary table -----------------------------\n    print(\"\\nFinal Test CompWA per weight decay\")\n    for w, c in zip(wd_vals, test_compwa):\n        print(f\"  wd={w:<10} -> {c:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- figure generation -------------------------------------------------\ntest_scores = {}  # batch_size -> test CompWA\ndataset_type = experiment_data.get(\"dataset_type\", \"SPR_synth\")\n\nfor key, subdict in experiment_data.get(\"batch_size\", {}).items():\n    try:\n        bs = key.split(\"_\")[-1]\n        epochs = subdict[\"epochs\"]\n        tr_loss = subdict[\"losses\"][\"train\"]\n        va_loss = subdict[\"losses\"][\"val\"]\n        va_comp = subdict[\"metrics\"][\"val_compwa\"]\n        test_scores[int(bs)] = subdict[\"metrics\"][\"test_compwa\"]\n\n        # ---- Loss curve ------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(epochs, tr_loss, label=\"Train\")\n            plt.plot(epochs, va_loss, label=\"Validation\")\n            plt.title(f\"Loss Curve (Dataset: {dataset_type}, BS={bs})\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.legend()\n            fname = f\"loss_curve_{dataset_type}_bs{bs}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n        except Exception as e:\n            print(f\"Error creating loss plot for bs={bs}: {e}\")\n        finally:\n            plt.close()\n\n        # ---- CompWA curve ----------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(epochs, va_comp)\n            plt.title(f\"Validation CompWA (Dataset: {dataset_type}, BS={bs})\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"CompWA\")\n            fname = f\"compwa_curve_{dataset_type}_bs{bs}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n        except Exception as e:\n            print(f\"Error creating CompWA plot for bs={bs}: {e}\")\n        finally:\n            plt.close()\n\n    except Exception as e:\n        print(f\"Unexpected error while plotting for {key}: {e}\")\n\n# ---------- summary bar plot (max 1 figure) ----------------------------------\ntry:\n    if test_scores:\n        plt.figure()\n        bs_vals = list(test_scores.keys())\n        scores = [test_scores[bs] for bs in bs_vals]\n        plt.bar([str(b) for b in bs_vals], scores)\n        plt.title(f\"Test CompWA by Batch Size (Dataset: {dataset_type})\")\n        plt.xlabel(\"Batch Size\")\n        plt.ylabel(\"Test CompWA\")\n        fname = f\"test_compwa_summary_{dataset_type}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    else:\n        print(\"No test CompWA data found to plot.\")\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\nfinally:\n    plt.close()\n\n# ---------- print evaluation metrics -----------------------------------------\nif test_scores:\n    print(\"\\n=== Test CompWA by batch size ===\")\n    for bs, sc in sorted(test_scores.items()):\n        print(f\"  bs={bs:>3}: {sc:.4f}\")\n    best_bs = max(test_scores, key=test_scores.get)\n    print(f\"\\nBest batch size: {best_bs}  (CompWA={test_scores[best_bs]:.4f})\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- figure generation -------------------------------------------------\ntest_scores = {}  # batch_size -> test CompWA\ndataset_type = experiment_data.get(\"dataset_type\", \"SPR_synth\")\n\nfor key, subdict in experiment_data.get(\"batch_size\", {}).items():\n    try:\n        bs = key.split(\"_\")[-1]\n        epochs = subdict[\"epochs\"]\n        tr_loss = subdict[\"losses\"][\"train\"]\n        va_loss = subdict[\"losses\"][\"val\"]\n        va_comp = subdict[\"metrics\"][\"val_compwa\"]\n        test_scores[int(bs)] = subdict[\"metrics\"][\"test_compwa\"]\n\n        # ---- Loss curve ------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(epochs, tr_loss, label=\"Train\")\n            plt.plot(epochs, va_loss, label=\"Validation\")\n            plt.title(f\"Loss Curve (Dataset: {dataset_type}, BS={bs})\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.legend()\n            fname = f\"loss_curve_{dataset_type}_bs{bs}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n        except Exception as e:\n            print(f\"Error creating loss plot for bs={bs}: {e}\")\n        finally:\n            plt.close()\n\n        # ---- CompWA curve ----------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(epochs, va_comp)\n            plt.title(f\"Validation CompWA (Dataset: {dataset_type}, BS={bs})\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"CompWA\")\n            fname = f\"compwa_curve_{dataset_type}_bs{bs}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n        except Exception as e:\n            print(f\"Error creating CompWA plot for bs={bs}: {e}\")\n        finally:\n            plt.close()\n\n    except Exception as e:\n        print(f\"Unexpected error while plotting for {key}: {e}\")\n\n# ---------- summary bar plot (max 1 figure) ----------------------------------\ntry:\n    if test_scores:\n        plt.figure()\n        bs_vals = list(test_scores.keys())\n        scores = [test_scores[bs] for bs in bs_vals]\n        plt.bar([str(b) for b in bs_vals], scores)\n        plt.title(f\"Test CompWA by Batch Size (Dataset: {dataset_type})\")\n        plt.xlabel(\"Batch Size\")\n        plt.ylabel(\"Test CompWA\")\n        fname = f\"test_compwa_summary_{dataset_type}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    else:\n        print(\"No test CompWA data found to plot.\")\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\nfinally:\n    plt.close()\n\n# ---------- print evaluation metrics -----------------------------------------\nif test_scores:\n    print(\"\\n=== Test CompWA by batch size ===\")\n    for bs, sc in sorted(test_scores.items()):\n        print(f\"  bs={bs:>3}: {sc:.4f}\")\n    best_bs = max(test_scores, key=test_scores.get)\n    print(f\"\\nBest batch size: {best_bs}  (CompWA={test_scores[best_bs]:.4f})\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- figure generation -------------------------------------------------\ntest_scores = {}  # batch_size -> test CompWA\ndataset_type = experiment_data.get(\"dataset_type\", \"SPR_synth\")\n\nfor key, subdict in experiment_data.get(\"batch_size\", {}).items():\n    try:\n        bs = key.split(\"_\")[-1]\n        epochs = subdict[\"epochs\"]\n        tr_loss = subdict[\"losses\"][\"train\"]\n        va_loss = subdict[\"losses\"][\"val\"]\n        va_comp = subdict[\"metrics\"][\"val_compwa\"]\n        test_scores[int(bs)] = subdict[\"metrics\"][\"test_compwa\"]\n\n        # ---- Loss curve ------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(epochs, tr_loss, label=\"Train\")\n            plt.plot(epochs, va_loss, label=\"Validation\")\n            plt.title(f\"Loss Curve (Dataset: {dataset_type}, BS={bs})\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.legend()\n            fname = f\"loss_curve_{dataset_type}_bs{bs}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n        except Exception as e:\n            print(f\"Error creating loss plot for bs={bs}: {e}\")\n        finally:\n            plt.close()\n\n        # ---- CompWA curve ----------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(epochs, va_comp)\n            plt.title(f\"Validation CompWA (Dataset: {dataset_type}, BS={bs})\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"CompWA\")\n            fname = f\"compwa_curve_{dataset_type}_bs{bs}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n        except Exception as e:\n            print(f\"Error creating CompWA plot for bs={bs}: {e}\")\n        finally:\n            plt.close()\n\n    except Exception as e:\n        print(f\"Unexpected error while plotting for {key}: {e}\")\n\n# ---------- summary bar plot (max 1 figure) ----------------------------------\ntry:\n    if test_scores:\n        plt.figure()\n        bs_vals = list(test_scores.keys())\n        scores = [test_scores[bs] for bs in bs_vals]\n        plt.bar([str(b) for b in bs_vals], scores)\n        plt.title(f\"Test CompWA by Batch Size (Dataset: {dataset_type})\")\n        plt.xlabel(\"Batch Size\")\n        plt.ylabel(\"Test CompWA\")\n        fname = f\"test_compwa_summary_{dataset_type}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    else:\n        print(\"No test CompWA data found to plot.\")\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\nfinally:\n    plt.close()\n\n# ---------- print evaluation metrics -----------------------------------------\nif test_scores:\n    print(\"\\n=== Test CompWA by batch size ===\")\n    for bs, sc in sorted(test_scores.items()):\n        print(f\"  bs={bs:>3}: {sc:.4f}\")\n    best_bs = max(test_scores, key=test_scores.get)\n    print(f\"\\nBest batch size: {best_bs}  (CompWA={test_scores[best_bs]:.4f})\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ---------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- figure generation -------------------------------------------------\ntest_scores = {}  # batch_size -> test CompWA\ndataset_type = experiment_data.get(\"dataset_type\", \"SPR_synth\")\n\nfor key, subdict in experiment_data.get(\"batch_size\", {}).items():\n    try:\n        bs = key.split(\"_\")[-1]\n        epochs = subdict[\"epochs\"]\n        tr_loss = subdict[\"losses\"][\"train\"]\n        va_loss = subdict[\"losses\"][\"val\"]\n        va_comp = subdict[\"metrics\"][\"val_compwa\"]\n        test_scores[int(bs)] = subdict[\"metrics\"][\"test_compwa\"]\n\n        # ---- Loss curve ------------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(epochs, tr_loss, label=\"Train\")\n            plt.plot(epochs, va_loss, label=\"Validation\")\n            plt.title(f\"Loss Curve (Dataset: {dataset_type}, BS={bs})\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Loss\")\n            plt.legend()\n            fname = f\"loss_curve_{dataset_type}_bs{bs}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n        except Exception as e:\n            print(f\"Error creating loss plot for bs={bs}: {e}\")\n        finally:\n            plt.close()\n\n        # ---- CompWA curve ----------------------------------------------------\n        try:\n            plt.figure()\n            plt.plot(epochs, va_comp)\n            plt.title(f\"Validation CompWA (Dataset: {dataset_type}, BS={bs})\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"CompWA\")\n            fname = f\"compwa_curve_{dataset_type}_bs{bs}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n        except Exception as e:\n            print(f\"Error creating CompWA plot for bs={bs}: {e}\")\n        finally:\n            plt.close()\n\n    except Exception as e:\n        print(f\"Unexpected error while plotting for {key}: {e}\")\n\n# ---------- summary bar plot (max 1 figure) ----------------------------------\ntry:\n    if test_scores:\n        plt.figure()\n        bs_vals = list(test_scores.keys())\n        scores = [test_scores[bs] for bs in bs_vals]\n        plt.bar([str(b) for b in bs_vals], scores)\n        plt.title(f\"Test CompWA by Batch Size (Dataset: {dataset_type})\")\n        plt.xlabel(\"Batch Size\")\n        plt.ylabel(\"Test CompWA\")\n        fname = f\"test_compwa_summary_{dataset_type}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    else:\n        print(\"No test CompWA data found to plot.\")\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\nfinally:\n    plt.close()\n\n# ---------- print evaluation metrics -----------------------------------------\nif test_scores:\n    print(\"\\n=== Test CompWA by batch size ===\")\n    for bs, sc in sorted(test_scores.items()):\n        print(f\"  bs={bs:>3}: {sc:.4f}\")\n    best_bs = max(test_scores, key=test_scores.get)\n    print(f\"\\nBest batch size: {best_bs}  (CompWA={test_scores[best_bs]:.4f})\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up working dir ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ALL experiment data -----------------------------------------\nexperiment_data_path_list = [\n    \"experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_eb770f9faf4e441fb17dfb78889a5153_proc_1490561/experiment_data.npy\",\n    \"experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8c1e7392314448968448e948c16bacb2_proc_1490562/experiment_data.npy\",\n    \"experiments/2025-08-30_20-55-34_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_63cc822c90fe4fb592d5ce5b5bac42b9_proc_1490560/experiment_data.npy\",\n]\nall_experiment_data = []\nfor rel_path in experiment_data_path_list:\n    try:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), rel_path)\n        exp = np.load(full_path, allow_pickle=True).item()\n        all_experiment_data.append(exp)\n    except Exception as e:\n        print(f\"Error loading {rel_path}: {e}\")\n\nif not all_experiment_data:\n    print(\"No experiment data could be loaded \u2013 nothing to plot.\")\n    exit()\n\ndataset_type = all_experiment_data[0].get(\"dataset_type\", \"unknown\")\n\n# ---------- aggregate metrics -------------------------------------------------\ntest_scores = {}  # bs -> list of scores\nlosses_train = {}  # bs -> list of np.arrays\nlosses_val = {}\n\nfor exp in all_experiment_data:\n    for key, subd in exp.get(\"batch_size\", {}).items():\n        try:\n            bs_int = int(key.split(\"_\")[-1])\n            test_scores.setdefault(bs_int, []).append(subd[\"metrics\"][\"test_compwa\"])\n            losses_train.setdefault(bs_int, []).append(\n                np.asarray(subd[\"losses\"][\"train\"])\n            )\n            losses_val.setdefault(bs_int, []).append(np.asarray(subd[\"losses\"][\"val\"]))\n        except Exception as e:\n            print(f\"Error aggregating data for key {key}: {e}\")\n\n# ---------- bar plot: mean \u00b1 SE test CompWA ----------------------------------\ntry:\n    plt.figure()\n    bs_sorted = sorted(test_scores.keys())\n    means = [np.mean(test_scores[bs]) for bs in bs_sorted]\n    ses = [\n        np.std(test_scores[bs], ddof=1) / np.sqrt(len(test_scores[bs]))\n        for bs in bs_sorted\n    ]\n    plt.bar(\n        [str(b) for b in bs_sorted],\n        means,\n        yerr=ses,\n        capsize=5,\n        alpha=0.7,\n        label=\"Mean \u00b1 SE\",\n    )\n    plt.title(f\"Test CompWA (Mean \u00b1 SE) by Batch Size\\nDataset: {dataset_type}\")\n    plt.xlabel(\"Batch Size\")\n    plt.ylabel(\"Test CompWA\")\n    plt.legend()\n    fname = f\"test_compwa_agg_{dataset_type}.png\"\n    plt.savefig(os.path.join(working_dir, fname))\nexcept Exception as e:\n    print(f\"Error creating aggregated CompWA bar plot: {e}\")\nfinally:\n    plt.close()\n\n# ---------- aggregated loss curves (max 5 batch sizes) ------------------------\nmax_plots = 5\nfor i, bs in enumerate(bs_sorted[:max_plots]):\n    try:\n        tr_runs = losses_train.get(bs, [])\n        va_runs = losses_val.get(bs, [])\n        if not tr_runs or not va_runs:\n            continue\n\n        # Align epochs by shortest run length\n        min_len = min([len(x) for x in tr_runs])\n        tr_stack = np.vstack([r[:min_len] for r in tr_runs])\n        va_stack = np.vstack([r[:min_len] for r in va_runs])\n        epochs = np.arange(min_len)\n\n        tr_mean, tr_se = tr_stack.mean(axis=0), tr_stack.std(axis=0, ddof=1) / np.sqrt(\n            tr_stack.shape[0]\n        )\n        va_mean, va_se = va_stack.mean(axis=0), va_stack.std(axis=0, ddof=1) / np.sqrt(\n            va_stack.shape[0]\n        )\n\n        plt.figure()\n        plt.plot(epochs, tr_mean, label=\"Train Mean\", color=\"tab:blue\")\n        plt.fill_between(\n            epochs,\n            tr_mean - tr_se,\n            tr_mean + tr_se,\n            color=\"tab:blue\",\n            alpha=0.2,\n            label=\"Train \u00b1SE\",\n        )\n        plt.plot(epochs, va_mean, label=\"Val Mean\", color=\"tab:orange\")\n        plt.fill_between(\n            epochs,\n            va_mean - va_se,\n            va_mean + va_se,\n            color=\"tab:orange\",\n            alpha=0.2,\n            label=\"Val \u00b1SE\",\n        )\n        plt.title(\n            f\"Aggregated Loss Curve (Mean \u00b1 SE)\\nDataset: {dataset_type}, BS={bs}\"\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        fname = f\"loss_curve_agg_{dataset_type}_bs{bs}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n    except Exception as e:\n        print(f\"Error creating aggregated loss plot for bs={bs}: {e}\")\n    finally:\n        plt.close()\n\n# ---------- print aggregated evaluation metrics ------------------------------\nprint(\"\\n=== Aggregated Test CompWA by Batch Size ===\")\nfor bs in bs_sorted:\n    m = np.mean(test_scores[bs])\n    se = np.std(test_scores[bs], ddof=1) / np.sqrt(len(test_scores[bs]))\n    print(f\"  bs={bs:>3}: {m:.4f} \u00b1 {se:.4f}\")\nbest_bs = bs_sorted[int(np.argmax([np.mean(test_scores[bs]) for bs in bs_sorted]))]\nprint(f\"\\nBest batch size (highest mean CompWA): {best_bs}\")\n"], "plot_plan": ["We first load the stored experiment_data.npy and iterate over every dataset entry it contains. For each dataset we extract the epoch numbers, training/validation loss arrays, validation CompWA values, and, if present, the final ground-truth and prediction vectors. Three independent plotting blocks will then visualize: (1) the loss trajectory of training vs. validation, (2) the CompWA progression across epochs, and (3) a confusion-matrix style heat-map comparing predictions to ground truth on the test set (only created if both arrays are non-empty). Each figure is wrapped in its own try-except section to prevent one faulty plot from halting the rest, and every figure is saved with a descriptive filename that includes the dataset name and plot type. All plots are written to the ./working directory, a new directory is created if necessary, and every figure is properly closed after saving to avoid memory leaks. Titles clarify the dataset and the content, and subtitles are added where helpful (e.g., \u201cLeft: Ground Truth, Right: Generated Samples\u201d isn\u2019t needed here, but the template shows how to add subtitles if multiple panes existed). Only information found inside experiment_data.npy is used; no synthetic points are generated. The code is concise and relies solely on matplotlib and NumPy, following the provided style constraints.", "We first load experiment_data.npy, locate the \u201cnum_epochs_tuning \u2192 SPR_BENCH\u201d entry, and pull out the lists for hparam_values, epochs_run, losses, and metrics.  We decide which run is \u201cbest\u201d via the highest validation CompWA, and gather its training/validation loss sequences plus its predictions/ground-truth labels.  Five figures are produced: (1) the best run\u2019s train/val loss curve; (2) a bar chart comparing validation CompWA for each epoch setting; (3) a matching bar chart for test CompWA; (4) a bar chart of the number of epochs actually run (useful for early-stopping diagnostics); and (5) a confusion-matrix heat-map for the best run.  Each figure is wrapped in its own try-except block, saved to working_dir with descriptive names, closed afterwards, and titled clearly with dataset and plot type.  All plotting uses only the data loaded from experiment_data.npy; no synthetic values are created.  At most five figures are emitted, satisfying the \u201c\u22645 similar plots\u201d guideline, and every plot includes a legend or axis labels for clarity.  The code is concise, starting with the required imports and guaranteeing working_dir exists.", "We first load the serialized dictionary from experiment_data.npy and extract the sub-tree experiment_data['learning_rate']['SPR_BENCH'].  \nFor each learning-rate entry we read the lists of epoch indices, training losses, validation losses and validation CompWA values as well as the scalar test CompWA.  \nBecause we have five learning rates, we overlay all of them in a single figure for losses and another single figure for validation CompWA, keeping the total number of figures small (\u22645).  \nA third figure shows a bar chart of the final test CompWA obtained with each learning rate so that the best hyper-parameter can be spotted at a glance.  \nEvery figure is wrapped in its own try-except block, saved to working_dir with descriptive names and then closed to avoid memory leakage.  \nEach plot carries a clear title specifying the dataset (SPR_BENCH) and the content (e.g. \u201cLoss Curves\u201d) and uses ordinary matplotlib defaults.  \nNo synthetic data are fabricated; every curve and bar comes directly from the arrays stored in experiment_data.npy.  \nThe script meets the guidelines by starting with the required imports, ensuring the working directory exists, and printing a short confirmation after all plots are successfully stored.", "The solution loads the serialized experiment_data.npy, extracts per-weight-decay histories (train/val loss and CompWA) and the final test CompWA values, and then produces three concise visualizations.  \n1) A bar chart summarising the final test CompWA for each weight-decay helps spot the best regularisation strength.  \n2) A multi-line plot overlays the validation CompWA curves for all weight-decays across epochs, enabling quick inspection of convergence behaviour.  \n3) A second multi-line plot does the same for train and validation loss, using dashed lines for validation to distinguish them.  \nEach figure is produced inside its own try-except block, saved to the working directory with descriptive filenames that include the synthetic dataset name and plot type, and the figures are always closed to avoid memory leaks.  \nThe code respects the five-figure cap (only three plots) and automatically skips plotting if any expected field is missing.  \nAfter plotting, it prints a neat table showing weight-decay values and their corresponding test CompWA to echo the key metric in the console.  \nAll plotting relies strictly on the data stored in experiment_data.npy, adhering to the requirements.", "We will first reload experiment_data.npy, safely unwrap the dictionary, and determine whether the run used the real SPR benchmark or the synthetic fallback (we infer from a boolean flag stored in the dict, otherwise default to \u201csynth\u201d).  For every batch-size sweep contained in experiment_data['batch_size'] we will extract the epoch list, the train/val loss histories, and the validation CompWA history.  A loop will then create up to four figure files\u2014one pair of curves (loss + CompWA) for each batch size\u2014each enclosed in an independent try-except so that a failure in one plot doesn\u2019t stop the rest.  We additionally aggregate the test CompWA values for all batch sizes and draw a single bar-chart summarising them (this is the fifth and final figure, keeping us within the 5-plot limit).  Plots are saved to the pre-created working directory with descriptive filenames that mention the dataset type and what is being visualised.  Every figure is closed after saving to avoid memory leaks.  Finally, the script prints the test CompWA table and highlights the best performing batch size so users can read the key metric straight from the console.  Only data found in the .npy file are plotted\u2014no values are fabricated or simulated.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null], "hyperparam_name": [null, "num_epochs (training epochs)", "learning_rate", "weight_decay", "batch_size", null, null, null, null], "is_seed_node": [false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["The script will first locate the working directory, load the saved numpy\ndictionary, and iterate over every dataset it contains. For each dataset it\nprints: (1) the final training loss, (2) the best (minimum) validation loss, (3)\nthe best (maximum) validation complexity-weighted accuracy, and (4) the test\ncomplexity-weighted accuracy if present. All code sits at global scope so that\nit executes immediately upon running the file.", "The script below loads the saved NumPy dictionary, finds the hyper-parameter\nsetting with the highest validation complexity-weighted accuracy for each\ndataset, and then prints the key metrics for that best run. It follows the\nrequired directory conventions, immediately executes on run, and produces no\nplots.", "", "The script loads experiment_data.npy from the \u201cworking\u201d directory, iterates\nthrough every weight-decay experiment, and for each one prints the final metrics\nstored. For the train and validation splits, the final (last epoch) complexity-\nweighted accuracy and loss are reported; for the test split, the stored test\ncomplexity-weighted accuracy is reported. Each dataset name is printed before\nits metrics, and every metric is explicitly labeled for clarity. No plots are\ngenerated and the code runs immediately when executed.", "We first load experiment_data.npy from the working directory and convert the\nnumpy object back to a normal Python dict.   For every batch-size experiment\n(bs_16, bs_32, \u2026) we read the stored lists of losses and CompWA scores.   From\nthese we take the final training loss, the final validation loss, the best\nvalidation CompWA (max over epochs) and the single stored test CompWA.   Each\nexperiment name is printed first, followed by clearly labeled metric/value pairs\nrounded to four decimals.   The script runs immediately on execution and does\nnot generate any plots.", "We first load experiment_data.npy from the working directory and convert the\nnumpy object back to a normal Python dict.   For every batch-size experiment\n(bs_16, bs_32, \u2026) we read the stored lists of losses and CompWA scores.   From\nthese we take the final training loss, the final validation loss, the best\nvalidation CompWA (max over epochs) and the single stored test CompWA.   Each\nexperiment name is printed first, followed by clearly labeled metric/value pairs\nrounded to four decimals.   The script runs immediately on execution and does\nnot generate any plots.", "We first load experiment_data.npy from the working directory and convert the\nnumpy object back to a normal Python dict.   For every batch-size experiment\n(bs_16, bs_32, \u2026) we read the stored lists of losses and CompWA scores.   From\nthese we take the final training loss, the final validation loss, the best\nvalidation CompWA (max over epochs) and the single stored test CompWA.   Each\nexperiment name is printed first, followed by clearly labeled metric/value pairs\nrounded to four decimals.   The script runs immediately on execution and does\nnot generate any plots.", "We first load experiment_data.npy from the working directory and convert the\nnumpy object back to a normal Python dict.   For every batch-size experiment\n(bs_16, bs_32, \u2026) we read the stored lists of losses and CompWA scores.   From\nthese we take the final training loss, the final validation loss, the best\nvalidation CompWA (max over epochs) and the single stored test CompWA.   Each\nexperiment name is printed first, followed by clearly labeled metric/value pairs\nrounded to four decimals.   The script runs immediately on execution and does\nnot generate any plots.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load the experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy at {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# Extract and report metrics\n# ------------------------------------------------------------------\nfor dataset_name, dataset_info in experiment_data.items():\n    print(f\"Dataset: {dataset_name}\")\n\n    # ----- Training loss ----------------------------------------------------\n    train_losses = dataset_info.get(\"losses\", {}).get(\"train\", [])\n    if train_losses:\n        final_train_loss = train_losses[-1]\n        print(f\"Final training loss: {final_train_loss:.6f}\")\n\n    # ----- Validation loss --------------------------------------------------\n    val_losses = dataset_info.get(\"losses\", {}).get(\"val\", [])\n    if val_losses:\n        best_val_loss = min(val_losses)\n        print(f\"Best validation loss: {best_val_loss:.6f}\")\n\n    # ----- Validation CompWA -------------------------------------------------\n    val_compwa = dataset_info.get(\"metrics\", {}).get(\"val_compwa\", [])\n    if val_compwa:\n        best_val_compwa = max(val_compwa)\n        print(f\"Best validation Complexity-Weighted Accuracy: {best_val_compwa:.6f}\")\n\n    # ----- Test CompWA -------------------------------------------------------\n    test_compwa = dataset_info.get(\"metrics\", {}).get(\"test_compwa\", None)\n    if test_compwa is not None:\n        print(f\"Test Complexity-Weighted Accuracy: {test_compwa:.6f}\")\n\n    print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# -------------------------------------------------------------------------\n# Locate and load experiment data\n# -------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nnpy_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(npy_path):\n    raise FileNotFoundError(f\"Could not locate experiment_data.npy in {working_dir}\")\n\nexperiment_data = np.load(npy_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------------------------------\n# Helper to print metrics for the best hyper-parameter configuration\n# -------------------------------------------------------------------------\ndef report_best_metrics(exp_dict):\n    \"\"\"\n    exp_dict has keys:\n        - hparam_values           : list\n        - epochs_run              : list\n        - metrics  -> {val_compwa, test_compwa}\n        - losses   -> {train, val}\n    \"\"\"\n    val_scores = exp_dict[\"metrics\"][\"val_compwa\"]\n    if not val_scores:\n        print(\"  No validation scores found.\")\n        return\n\n    best_index = int(np.argmax(val_scores))\n\n    # Extract losses for final epoch of that run\n    train_loss_curve = exp_dict[\"losses\"][\"train\"][best_index]\n    val_loss_curve = exp_dict[\"losses\"][\"val\"][best_index]\n\n    final_train_loss = train_loss_curve[-1] if train_loss_curve else float(\"nan\")\n    final_val_loss = val_loss_curve[-1] if val_loss_curve else float(\"nan\")\n\n    # Collect metrics\n    best_val_cwa = val_scores[best_index]\n    best_test_cwa = exp_dict[\"metrics\"][\"test_compwa\"][best_index]\n\n    # Print metrics with explicit labels\n    print(f\"  best validation complexity-weighted accuracy: {best_val_cwa:.4f}\")\n    print(f\"  corresponding test complexity-weighted accuracy: {best_test_cwa:.4f}\")\n    print(f\"  final training loss: {final_train_loss:.6f}\")\n    print(f\"  final validation loss: {final_val_loss:.6f}\")\n\n\n# -------------------------------------------------------------------------\n# Iterate through all experiments and datasets\n# -------------------------------------------------------------------------\nfor exp_name, datasets in experiment_data.items():  # e.g. 'num_epochs_tuning'\n    for dataset_name, dataset_dict in datasets.items():  # e.g. 'SPR_BENCH'\n        print(f\"Dataset: {dataset_name}\")\n        report_best_metrics(dataset_dict)\n", "", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------------\n# locate and load the saved experiment dictionary\n# --------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# --------------------------------------------------------------------------\n# helper for pretty, requirement-compliant printing\n# --------------------------------------------------------------------------\ndef print_metrics(tag: str, exp: dict):\n    \"\"\"\n    Print final metrics for one weight-decay experiment in the required format.\n    \"\"\"\n    # final = last epoch\n    last_idx = -1\n\n    # ------------- TRAIN -------------\n    print(\"TRAIN dataset\")\n    # train complexity weighted accuracy\n    train_cwa = (\n        exp[\"metrics\"][\"train_compwa\"][last_idx]\n        if exp[\"metrics\"].get(\"train_compwa\")\n        else \"N/A\"\n    )\n    print(f\"train complexity weighted accuracy: {train_cwa}\")\n    # train loss\n    train_loss = exp[\"losses\"][\"train\"][last_idx]\n    print(f\"train loss: {train_loss}\")\n\n    # ----------- VALIDATION ----------\n    print(\"VALIDATION dataset\")\n    val_cwa = exp[\"metrics\"][\"val_compwa\"][last_idx]\n    print(f\"validation complexity weighted accuracy: {val_cwa}\")\n    val_loss = exp[\"losses\"][\"val\"][last_idx]\n    print(f\"validation loss: {val_loss}\")\n\n    # --------------- TEST ------------\n    print(\"TEST dataset\")\n    test_cwa = exp[\"metrics\"][\"test_compwa\"]\n    print(f\"test complexity weighted accuracy: {test_cwa}\")\n    print(\"-\" * 40)  # separator between experiments\n\n\n# --------------------------------------------------------------------------\n# iterate over all weight-decay settings and display their results\n# --------------------------------------------------------------------------\nfor tag in sorted(\n    experiment_data[\"weight_decay\"].keys(), key=lambda x: float(x.split(\"_\")[1])\n):  # sort by wd value\n    print(f\"Experiment '{tag}'\")\n    print_metrics(tag, experiment_data[\"weight_decay\"][tag])\n", "import os\nimport numpy as np\n\n# ------------------ load ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------ helper to safely fetch values --------------------------\ndef safe_last(lst):\n    return lst[-1] if lst else None\n\n\ndef print_metric(name, value):\n    if value is not None:\n        print(f\"    {name}: {value:.4f}\")\n\n\n# ------------------ iterate over batch-size runs ---------------------------\nbs_dict = experiment_data.get(\"batch_size\", {})\nfor run_name, run_data in bs_dict.items():\n    print(run_name)  # dataset / run name\n\n    # losses\n    final_train_loss = safe_last(run_data[\"losses\"].get(\"train\", []))\n    final_val_loss = safe_last(run_data[\"losses\"].get(\"val\", []))\n\n    # CompWA scores\n    train_compwa_vals = run_data[\"metrics\"].get(\"train_compwa\", [])\n    val_compwa_vals = run_data[\"metrics\"].get(\"val_compwa\", [])\n    best_train_compwa = max(train_compwa_vals) if train_compwa_vals else None\n    best_val_compwa = max(val_compwa_vals) if val_compwa_vals else None\n    test_compwa = run_data[\"metrics\"].get(\"test_compwa\", None)\n\n    # print metrics with explicit names\n    print_metric(\"final training loss\", final_train_loss)\n    print_metric(\"final validation loss\", final_val_loss)\n    print_metric(\"best training CompWA\", best_train_compwa)\n    print_metric(\"best validation CompWA\", best_val_compwa)\n    print_metric(\"test CompWA\", test_compwa)\n", "import os\nimport numpy as np\n\n# ------------------ load ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------ helper to safely fetch values --------------------------\ndef safe_last(lst):\n    return lst[-1] if lst else None\n\n\ndef print_metric(name, value):\n    if value is not None:\n        print(f\"    {name}: {value:.4f}\")\n\n\n# ------------------ iterate over batch-size runs ---------------------------\nbs_dict = experiment_data.get(\"batch_size\", {})\nfor run_name, run_data in bs_dict.items():\n    print(run_name)  # dataset / run name\n\n    # losses\n    final_train_loss = safe_last(run_data[\"losses\"].get(\"train\", []))\n    final_val_loss = safe_last(run_data[\"losses\"].get(\"val\", []))\n\n    # CompWA scores\n    train_compwa_vals = run_data[\"metrics\"].get(\"train_compwa\", [])\n    val_compwa_vals = run_data[\"metrics\"].get(\"val_compwa\", [])\n    best_train_compwa = max(train_compwa_vals) if train_compwa_vals else None\n    best_val_compwa = max(val_compwa_vals) if val_compwa_vals else None\n    test_compwa = run_data[\"metrics\"].get(\"test_compwa\", None)\n\n    # print metrics with explicit names\n    print_metric(\"final training loss\", final_train_loss)\n    print_metric(\"final validation loss\", final_val_loss)\n    print_metric(\"best training CompWA\", best_train_compwa)\n    print_metric(\"best validation CompWA\", best_val_compwa)\n    print_metric(\"test CompWA\", test_compwa)\n", "import os\nimport numpy as np\n\n# ------------------ load ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------ helper to safely fetch values --------------------------\ndef safe_last(lst):\n    return lst[-1] if lst else None\n\n\ndef print_metric(name, value):\n    if value is not None:\n        print(f\"    {name}: {value:.4f}\")\n\n\n# ------------------ iterate over batch-size runs ---------------------------\nbs_dict = experiment_data.get(\"batch_size\", {})\nfor run_name, run_data in bs_dict.items():\n    print(run_name)  # dataset / run name\n\n    # losses\n    final_train_loss = safe_last(run_data[\"losses\"].get(\"train\", []))\n    final_val_loss = safe_last(run_data[\"losses\"].get(\"val\", []))\n\n    # CompWA scores\n    train_compwa_vals = run_data[\"metrics\"].get(\"train_compwa\", [])\n    val_compwa_vals = run_data[\"metrics\"].get(\"val_compwa\", [])\n    best_train_compwa = max(train_compwa_vals) if train_compwa_vals else None\n    best_val_compwa = max(val_compwa_vals) if val_compwa_vals else None\n    test_compwa = run_data[\"metrics\"].get(\"test_compwa\", None)\n\n    # print metrics with explicit names\n    print_metric(\"final training loss\", final_train_loss)\n    print_metric(\"final validation loss\", final_val_loss)\n    print_metric(\"best training CompWA\", best_train_compwa)\n    print_metric(\"best validation CompWA\", best_val_compwa)\n    print_metric(\"test CompWA\", test_compwa)\n", "import os\nimport numpy as np\n\n# ------------------ load ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------ helper to safely fetch values --------------------------\ndef safe_last(lst):\n    return lst[-1] if lst else None\n\n\ndef print_metric(name, value):\n    if value is not None:\n        print(f\"    {name}: {value:.4f}\")\n\n\n# ------------------ iterate over batch-size runs ---------------------------\nbs_dict = experiment_data.get(\"batch_size\", {})\nfor run_name, run_data in bs_dict.items():\n    print(run_name)  # dataset / run name\n\n    # losses\n    final_train_loss = safe_last(run_data[\"losses\"].get(\"train\", []))\n    final_val_loss = safe_last(run_data[\"losses\"].get(\"val\", []))\n\n    # CompWA scores\n    train_compwa_vals = run_data[\"metrics\"].get(\"train_compwa\", [])\n    val_compwa_vals = run_data[\"metrics\"].get(\"val_compwa\", [])\n    best_train_compwa = max(train_compwa_vals) if train_compwa_vals else None\n    best_val_compwa = max(val_compwa_vals) if val_compwa_vals else None\n    test_compwa = run_data[\"metrics\"].get(\"test_compwa\", None)\n\n    # print metrics with explicit names\n    print_metric(\"final training loss\", final_train_loss)\n    print_metric(\"final validation loss\", final_val_loss)\n    print_metric(\"best training CompWA\", best_train_compwa)\n    print_metric(\"best validation CompWA\", best_val_compwa)\n    print_metric(\"test CompWA\", test_compwa)\n", ""], "parse_term_out": ["['Dataset: SPR_BENCH', '\\n', 'Final training loss: 1.089228', '\\n', 'Best\nvalidation loss: 1.091475', '\\n', 'Best validation Complexity-Weighted Accuracy:\n0.365530', '\\n', 'Test Complexity-Weighted Accuracy: 0.391969', '\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', '  best validation complexity-weighted accuracy:\n0.3043', '\\n', '  corresponding test complexity-weighted accuracy: 0.3055',\n'\\n', '  final training loss: 1.091311', '\\n', '  final validation loss:\n1.112126', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "", "[\"Experiment 'wd_0'\", '\\n', 'TRAIN dataset', '\\n', 'train complexity weighted\naccuracy: N/A', '\\n', 'train loss: 1.0943584184646606', '\\n', 'VALIDATION\ndataset', '\\n', 'validation complexity weighted accuracy: 0.2538167938931298',\n'\\n', 'validation loss: 1.1103160381317139', '\\n', 'TEST dataset', '\\n', 'test\ncomplexity weighted accuracy: 0.3534971644612476', '\\n',\n'----------------------------------------', '\\n', \"Experiment 'wd_1e-05'\", '\\n',\n'TRAIN dataset', '\\n', 'train complexity weighted accuracy: N/A', '\\n', 'train\nloss: 1.0931620817184449', '\\n', 'VALIDATION dataset', '\\n', 'validation\ncomplexity weighted accuracy: 0.28053435114503816', '\\n', 'validation loss:\n1.103369951248169', '\\n', 'TEST dataset', '\\n', 'test complexity weighted\naccuracy: 0.2892249527410208', '\\n', '----------------------------------------',\n'\\n', \"Experiment 'wd_0.0001'\", '\\n', 'TRAIN dataset', '\\n', 'train complexity\nweighted accuracy: N/A', '\\n', 'train loss: 1.0946537275314332', '\\n',\n'VALIDATION dataset', '\\n', 'validation complexity weighted accuracy: 0.25',\n'\\n', 'validation loss: 1.108932614326477', '\\n', 'TEST dataset', '\\n', 'test\ncomplexity weighted accuracy: 0.33081285444234404', '\\n',\n'----------------------------------------', '\\n', \"Experiment 'wd_0.0005'\",\n'\\n', 'TRAIN dataset', '\\n', 'train complexity weighted accuracy: N/A', '\\n',\n'train loss: 1.0921184406280517', '\\n', 'VALIDATION dataset', '\\n', 'validation\ncomplexity weighted accuracy: 0.29770992366412213', '\\n', 'validation loss:\n1.0996052026748657', '\\n', 'TEST dataset', '\\n', 'test complexity weighted\naccuracy: 0.34215500945179583', '\\n',\n'----------------------------------------', '\\n', \"Experiment 'wd_0.001'\", '\\n',\n'TRAIN dataset', '\\n', 'train complexity weighted accuracy: N/A', '\\n', 'train\nloss: 1.0909885768890382', '\\n', 'VALIDATION dataset', '\\n', 'validation\ncomplexity weighted accuracy: 0.25190839694656486', '\\n', 'validation loss:\n1.1068536043167114', '\\n', 'TEST dataset', '\\n', 'test complexity weighted\naccuracy: 0.332703213610586', '\\n', '----------------------------------------',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['bs_16', '\\n', '    final training loss: 1.0863', '\\n', '    final validation\nloss: 1.0917', '\\n', '    best validation CompWA: 0.3674', '\\n', '    test\nCompWA: 0.3728', '\\n', 'bs_32', '\\n', '    final training loss: 1.0901', '\\n', '\nfinal validation loss: 1.0975', '\\n', '    best validation CompWA: 0.3996',\n'\\n', '    test CompWA: 0.3939', '\\n', 'bs_64', '\\n', '    final training loss:\n1.0906', '\\n', '    final validation loss: 1.0936', '\\n', '    best validation\nCompWA: 0.4564', '\\n', '    test CompWA: 0.4111', '\\n', 'bs_128', '\\n', '\nfinal training loss: 1.0910', '\\n', '    final validation loss: 1.0937', '\\n', '\nbest validation CompWA: 0.3636', '\\n', '    test CompWA: 0.3576', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['bs_16', '\\n', '    final training loss: 1.0911', '\\n', '    final validation\nloss: 1.1192', '\\n', '    best validation CompWA: 0.3889', '\\n', '    test\nCompWA: 0.2852', '\\n', 'bs_32', '\\n', '    final training loss: 1.0951', '\\n', '\nfinal validation loss: 1.1082', '\\n', '    best validation CompWA: 0.3755',\n'\\n', '    test CompWA: 0.2270', '\\n', 'bs_64', '\\n', '    final training loss:\n1.0934', '\\n', '    final validation loss: 1.1102', '\\n', '    best validation\nCompWA: 0.3716', '\\n', '    test CompWA: 0.2908', '\\n', 'bs_128', '\\n', '\nfinal training loss: 1.0918', '\\n', '    final validation loss: 1.1145', '\\n', '\nbest validation CompWA: 0.3314', '\\n', '    test CompWA: 0.2495', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['bs_16', '\\n', '    final training loss: 1.0902', '\\n', '    final validation\nloss: 1.1176', '\\n', '    best validation CompWA: 0.3544', '\\n', '    test\nCompWA: 0.3757', '\\n', 'bs_32', '\\n', '    final training loss: 1.0926', '\\n', '\nfinal validation loss: 1.1061', '\\n', '    best validation CompWA: 0.3506',\n'\\n', '    test CompWA: 0.3834', '\\n', 'bs_64', '\\n', '    final training loss:\n1.0923', '\\n', '    final validation loss: 1.1015', '\\n', '    best validation\nCompWA: 0.3429', '\\n', '    test CompWA: 0.3776', '\\n', 'bs_128', '\\n', '\nfinal training loss: 1.0956', '\\n', '    final validation loss: 1.1026', '\\n', '\nbest validation CompWA: 0.3352', '\\n', '    test CompWA: 0.3661', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['bs_16', '\\n', '    final training loss: 1.0914', '\\n', '    final validation\nloss: 1.1024', '\\n', '    best validation CompWA: 0.3127', '\\n', '    test\nCompWA: 0.4189', '\\n', 'bs_32', '\\n', '    final training loss: 1.0835', '\\n', '\nfinal validation loss: 1.1095', '\\n', '    best validation CompWA: 0.3398',\n'\\n', '    test CompWA: 0.4094', '\\n', 'bs_64', '\\n', '    final training loss:\n1.0866', '\\n', '    final validation loss: 1.1009', '\\n', '    best validation\nCompWA: 0.3436', '\\n', '    test CompWA: 0.3491', '\\n', 'bs_128', '\\n', '\nfinal training loss: 1.0900', '\\n', '    final validation loss: 1.1077', '\\n', '\nbest validation CompWA: 0.3108', '\\n', '    test CompWA: 0.3340', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
