<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 5], [0, 3], [0, 6], [0, 1], [0, 7], [0, 8], [0, 2], [0, 4]], "layout": [[0.5, 0.0], [0.0, 1.0], [0.14285714285714285, 1.0], [0.2857142857142857, 1.0], [0.42857142857142855, 1.0], [0.5714285714285714, 1.0], [0.7142857142857143, 1.0], [0.8571428571428571, 1.0], [1.0, 1.0]], "plan": ["The crash came from using the ordinary torch.utils.data.DataLoader, whose\ndefault collate function cannot stack torch_geometric.data.Data objects.\nReplacing it with torch_geometric.loader.DataLoader (which knows how to batch\ngraph objects) fixes the TypeError. The remainder of the script is kept intact,\nwhile respecting the GPU/CPU handling and metric-tracking guidelines.", "Ablation name: Multi-Dataset Generalization Study. Below is the updated single-\nfile script that generates three independent synthetic corpora (differing in\nseed, length distribution and vocabulary balance), trains a fresh GNN on each,\nevaluates on its own held-out test set and stores all results in the requested\nexperiment_data dictionary.", "Ablation name: Positional Feature Removal. The ablation study trains the same\nGNN architecture but builds graphs whose node features contain only shape and\ncolor one-hot encodings, omitting the normalized positional scalar. Everything\nelse\u2014data synthesis/reading, edge construction, training loop, metric\ncomputation, and result serialization\u2014remains unchanged, so any performance\nchange can be attributed solely to the lack of explicit positional information.\nResults are stored under the key 'positional_feature_removal' in the mandatory\nexperiment_data.npy file.", "Ablation name: Node Color Feature Removal. The script recreates the baseline\npipeline but builds node features that omit the entire color one-hot segment,\nkeeping only shape identity and positional encoding. All data generation, graph\nconstruction, training, evaluation and metric logging stay unchanged, so any\nperformance drop quantifies reliance on explicit color information. Results and\ncurves are stored in the required experiment_data.npy file under the key\n'no_color_feature'\u2192'SPR'.", "Ablation name: Edge Structure Removal (No Edges). We reuse the baseline pipeline\nbut change the graph construction so that every graph has an empty edge_index\ntensor, thereby preventing any message-passing and turning the GNN into a shared\nMLP + global pooling. All bookkeeping, training, evaluation and saving logic\nstays unchanged, but results are stored under the ablation key \"NoEdges\".", "Ablation name: Node Shape Feature Removal. The solution re-implements the\npipeline but removes the shape one-hot channels from every node\u2019s feature\nvector, leaving only color information and positional encoding. Training,\nvalidation, and test evaluation remain unchanged so we can quantify the\nperformance drop attributable to missing shape cues. All results are stored in\nexperiment_data.npy under the ablation name \u201cShapeRemoval\u201d.", "Ablation name: Single-Layer GNN (Second GraphConv Removed). Ablation is carried\nout by redefining the classifier to contain only one GraphConv layer before\nglobal pooling. All other data-processing, training, evaluation and logging\nutilities remain unchanged; metrics/losses are stored under\nexperiment_data['single_layer_gnn']['SPR'] and written to experiment_data.npy.\nBelow is a complete, runnable script.", "Ablation name: Unidirectional-Chain Edges. A new ablation called \u201cUniChain\u201d is\nintroduced in which every token node is linked only to its immediate successor\n(i \u2192 i+1).  The reverse links are removed so information can flow strictly left-\nto-right.  Apart from this edge change, the data generation, model, training\nloop and metric logging stay identical.  Results are stored under the\n\u2018UniChain/SPR\u2019 key in the shared experiment_data dictionary and saved to\nexperiment_data.npy.", "Ablation name: First-Node Readout Ablation. The ablation replaces the global\nmean pooling with a fixed-node readout: after the GNN layers, the hidden state\nof node 0 of every graph in the batch is gathered (via advanced indexing over\n`batch == 0` offset handling) and fed to the classifier. Everything else (data\nsynthesis, training/evaluation loops, metrics, saving) stays unchanged. A single\nscript below implements this First-Node Readout ablation and stores all results\nin `experiment_data.npy`."], "code": ["import os, random, string, numpy as np, torch, pathlib, time\nfrom typing import List\nfrom datasets import Dataset, DatasetDict\nfrom torch import nn\nfrom torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader  # <-- FIX: correct loader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\n\n# ---------------------------------------------------------------------\n# WORK DIR & DEVICE ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# METRICS --------------------------------------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef pcwa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------------------------------------------------------------------\n# LOAD OR SYNTHESISE DATA ---------------------------------------------\nROOT = pathlib.Path(\"./SPR_BENCH\")\nSHAPES = list(string.ascii_uppercase[:6])  # A-F\nCOLORS = list(map(str, range(1, 7)))  # 1-6\n\n\ndef gen_seq(max_len: int = 12) -> str:\n    length = random.randint(4, max_len)\n    tokens = [random.choice(SHAPES) + random.choice(COLORS) for _ in range(length)]\n    return \" \".join(tokens)\n\n\ndef label_rule(seq: str) -> int:\n    return int(count_shape_variety(seq) >= count_color_variety(seq))\n\n\ndef synthesize_split(n_samples: int) -> Dataset:\n    seqs, labels = [], []\n    for _ in range(n_samples):\n        s = gen_seq()\n        seqs.append(s)\n        labels.append(label_rule(s))\n    return Dataset.from_dict({\"sequence\": seqs, \"label\": labels})\n\n\ndef load_dataset_dict() -> DatasetDict:\n    if ROOT.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(ROOT)\n    print(\"SPR_BENCH not found \u2013 generating synthetic data.\")\n    return DatasetDict(\n        {\n            \"train\": synthesize_split(2000),\n            \"dev\": synthesize_split(400),\n            \"test\": synthesize_split(400),\n        }\n    )\n\n\ndsets = load_dataset_dict()\nnum_classes = len(set(dsets[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in dsets.items()})\n\n# ---------------------------------------------------------------------\n# GRAPH CONVERSION -----------------------------------------------------\nshape_to_id = {s: i for i, s in enumerate(SHAPES)}\ncolor_to_id = {c: i for i, c in enumerate(COLORS)}\nfeat_dim = len(SHAPES) + len(COLORS) + 1  # shape one-hot + color one-hot + pos\n\n\ndef seq_to_graph(seq: str) -> Data:\n    tokens = seq.strip().split()\n    n = len(tokens)\n    x = torch.zeros((n, feat_dim), dtype=torch.float)\n    for i, tok in enumerate(tokens):\n        s, c = tok[0], tok[1]\n        x[i, shape_to_id[s]] = 1.0\n        x[i, len(SHAPES) + color_to_id[c]] = 1.0\n        x[i, -1] = i / (n - 1) if n > 1 else 0.0\n    # bi-directional chain edges\n    if n > 1:\n        edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    else:\n        edge_index = torch.empty((2, 0), dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, seq=seq)\n\n\nclass SPRGraphDataset(InMemoryDataset):\n    def __init__(self, hf_dataset: Dataset):\n        self.hf_dataset = hf_dataset\n        super().__init__(None, None, None)\n        data_list = []\n        for seq, label in zip(hf_dataset[\"sequence\"], hf_dataset[\"label\"]):\n            g = seq_to_graph(seq)\n            g.y = torch.tensor([label], dtype=torch.long)\n            data_list.append(g)\n        self.data, self.slices = self.collate(data_list)\n\n\n# ---------------------------------------------------------------------\n# DATA LOADERS ---------------------------------------------------------\ntrain_data = SPRGraphDataset(dsets[\"train\"])\nval_data = SPRGraphDataset(dsets[\"dev\"])\ntest_data = SPRGraphDataset(dsets[\"test\"])\n\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=128)\ntest_loader = DataLoader(test_data, batch_size=128)\n\n\n# ---------------------------------------------------------------------\n# MODEL ----------------------------------------------------------------\nclass GNNClassifier(nn.Module):\n    def __init__(self, in_dim: int, hid: int = 64, num_classes: int = 2):\n        super().__init__()\n        self.conv1 = GraphConv(in_dim, hid)\n        self.conv2 = GraphConv(hid, hid)\n        self.lin = nn.Linear(hid, num_classes)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\nmodel = GNNClassifier(feat_dim, hid=64, num_classes=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------------------------------------------------------------------\n# EXPERIMENT DATA STORAGE ---------------------------------------------\nexperiment_data = {\n    \"SPR\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n\n# ---------------------------------------------------------------------\n# TRAIN / EVAL LOOPS ---------------------------------------------------\ndef run_epoch(loader, train_mode: bool = True):\n    model.train() if train_mode else model.eval()\n    total_loss, total, correct = 0.0, 0, 0\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        out = model(data)\n        loss = criterion(out, data.y.view(-1))\n        if train_mode:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        total_loss += loss.item() * data.num_graphs\n        pred = out.argmax(dim=1)\n        correct += int((pred == data.y.view(-1)).sum())\n        total += data.num_graphs\n        all_seq.extend(data.seq)  # list[str]\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    avg_loss = total_loss / total\n    acc = correct / total\n    pc = pcwa(all_seq, y_true, y_pred)\n    return avg_loss, acc, pc\n\n\n# ---------------------------------------------------------------------\nEPOCHS = 5\nstart_time = time.time()\nfor epoch in range(1, EPOCHS + 1):\n    tr_loss, tr_acc, tr_pc = run_epoch(train_loader, True)\n    val_loss, val_acc, val_pc = run_epoch(val_loader, False)\n\n    experiment_data[\"SPR\"][\"losses\"][\"train\"].append((epoch, tr_loss))\n    experiment_data[\"SPR\"][\"losses\"][\"val\"].append((epoch, val_loss))\n    experiment_data[\"SPR\"][\"metrics\"][\"train\"].append((epoch, tr_pc))\n    experiment_data[\"SPR\"][\"metrics\"][\"val\"].append((epoch, val_pc))\n\n    print(\n        f\"Epoch {epoch}: \"\n        f\"train_loss={tr_loss:.4f} val_loss={val_loss:.4f} \"\n        f\"val_PCWA={val_pc:.4f}\"\n    )\n\n\n# ---------------------------------------------------------------------\n# FINAL TEST EVALUATION ------------------------------------------------\ndef compute_metrics(loader):\n    model.eval()\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        with torch.no_grad():\n            out = model(data)\n        pred = out.argmax(dim=1)\n        all_seq.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    cwa_num = sum(\n        count_color_variety(s) if y == p else 0\n        for s, y, p in zip(all_seq, y_true, y_pred)\n    )\n    cwa_den = sum(count_color_variety(s) for s in all_seq)\n    swa_num = sum(\n        count_shape_variety(s) if y == p else 0\n        for s, y, p in zip(all_seq, y_true, y_pred)\n    )\n    swa_den = sum(count_shape_variety(s) for s in all_seq)\n    metrics = {\n        \"PCWA\": pcwa(all_seq, y_true, y_pred),\n        \"CWA\": cwa_num / cwa_den if cwa_den else 0.0,\n        \"SWA\": swa_num / swa_den if swa_den else 0.0,\n        \"ACC\": sum(int(y == p) for y, p in zip(y_true, y_pred)) / len(y_true),\n    }\n    return metrics, y_true, y_pred, all_seq\n\n\ntest_metrics, y_t, y_p, seqs = compute_metrics(test_loader)\nprint(\"TEST METRICS:\", test_metrics)\n\nexperiment_data[\"SPR\"][\"predictions\"] = y_p\nexperiment_data[\"SPR\"][\"ground_truth\"] = y_t\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\nprint(f\"Finished in {(time.time() - start_time):.1f}s; results saved to {working_dir}\")\n", "# multi_dataset_generalization.py\nimport os, random, string, time, pathlib, numpy as np, torch\nfrom typing import List, Optional\nfrom datasets import Dataset\nfrom torch import nn\nfrom torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\n\n# ---------------------------------------------------------------------\n# EXPERIMENT STORAGE ---------------------------------------------------\nexperiment_data = {\"multi_dataset_generalization\": {}}\n\n# ---------------------------------------------------------------------\n# DEVICE ---------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# GLOBAL CONSTANTS -----------------------------------------------------\nSHAPES = list(string.ascii_uppercase[:6])  # A-F\nCOLORS = list(map(str, range(1, 7)))  # 1-6\nshape_to_id = {s: i for i, s in enumerate(SHAPES)}\ncolor_to_id = {c: i for i, c in enumerate(COLORS)}\nfeat_dim = len(SHAPES) + len(COLORS) + 1  # shape one-hot + color one-hot + position\n\n\n# ---------------------------------------------------------------------\n# METRICS --------------------------------------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split()))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split()))\n\n\ndef pcwa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    corr = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(corr) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------------------------------------------------------------------\n# SYNTHETIC DATA GENERATION -------------------------------------------\ndef label_rule(seq: str) -> int:\n    return int(count_shape_variety(seq) >= count_color_variety(seq))\n\n\ndef synthesize_split(\n    n_samples: int,\n    max_len: int,\n    rng: random.Random,\n    shape_w: Optional[List[float]] = None,\n    color_w: Optional[List[float]] = None,\n) -> Dataset:\n    s_w = shape_w if shape_w is not None else [1] * len(SHAPES)\n    c_w = color_w if color_w is not None else [1] * len(COLORS)\n    seqs, labels = [], []\n    for _ in range(n_samples):\n        length = rng.randint(4, max_len)\n        toks = [\n            rng.choices(SHAPES, weights=s_w)[0] + rng.choices(COLORS, weights=c_w)[0]\n            for _ in range(length)\n        ]\n        seq = \" \".join(toks)\n        seqs.append(seq)\n        labels.append(label_rule(seq))\n    return Dataset.from_dict({\"sequence\": seqs, \"label\": labels})\n\n\ndef build_dataset_dict(seed: int, max_len: int, shape_w=None, color_w=None):\n    rng = random.Random(seed)\n    return {\n        \"train\": synthesize_split(2000, max_len, rng, shape_w, color_w),\n        \"dev\": synthesize_split(400, max_len, rng, shape_w, color_w),\n        \"test\": synthesize_split(400, max_len, rng, shape_w, color_w),\n    }\n\n\n# ---------------------------------------------------------------------\n# GRAPH CONVERSION -----------------------------------------------------\ndef seq_to_graph(seq: str) -> Data:\n    tokens = seq.split()\n    n = len(tokens)\n    x = torch.zeros((n, feat_dim), dtype=torch.float)\n    for i, tok in enumerate(tokens):\n        s, c = tok[0], tok[1]\n        x[i, shape_to_id[s]] = 1.0\n        x[i, len(SHAPES) + color_to_id[c]] = 1.0\n        x[i, -1] = i / (n - 1) if n > 1 else 0.0\n    if n > 1:\n        edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    else:\n        edge_index = torch.empty((2, 0), dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, seq=seq)\n\n\nclass SPRGraphDataset(InMemoryDataset):\n    def __init__(self, hf_dataset: Dataset):\n        super().__init__(None, None, None)\n        data_list = []\n        for seq, label in zip(hf_dataset[\"sequence\"], hf_dataset[\"label\"]):\n            g = seq_to_graph(seq)\n            g.y = torch.tensor([label], dtype=torch.long)\n            data_list.append(g)\n        self.data, self.slices = self.collate(data_list)\n\n\n# ---------------------------------------------------------------------\n# MODEL ---------------------------------------------------------------\nclass GNNClassifier(nn.Module):\n    def __init__(self, in_dim: int, hid: int = 64, num_classes: int = 2):\n        super().__init__()\n        self.conv1 = GraphConv(in_dim, hid)\n        self.conv2 = GraphConv(hid, hid)\n        self.lin = nn.Linear(hid, num_classes)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\n# ---------------------------------------------------------------------\n# TRAIN / EVAL --------------------------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train_mode = optimizer is not None\n    model.train() if train_mode else model.eval()\n    tot_loss, tot, corr = 0.0, 0, 0\n    seqs, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        out = model(data)\n        loss = criterion(out, data.y.view(-1))\n        if train_mode:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        tot_loss += loss.item() * data.num_graphs\n        pred = out.argmax(dim=1)\n        corr += int((pred == data.y.view(-1)).sum())\n        tot += data.num_graphs\n        seqs.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    return (tot_loss / tot, corr / tot, pcwa(seqs, y_true, y_pred))\n\n\ndef evaluate(model, loader):\n    model.eval()\n    seqs, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        with torch.no_grad():\n            out = model(data)\n        pred = out.argmax(dim=1)\n        seqs.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    cwa_num = sum(\n        count_color_variety(s) if y == p else 0 for s, y, p in zip(seqs, y_true, y_pred)\n    )\n    cwa_den = sum(count_color_variety(s) for s in seqs)\n    swa_num = sum(\n        count_shape_variety(s) if y == p else 0 for s, y, p in zip(seqs, y_true, y_pred)\n    )\n    swa_den = sum(count_shape_variety(s) for s in seqs)\n    return (\n        {\n            \"PCWA\": pcwa(seqs, y_true, y_pred),\n            \"CWA\": cwa_num / cwa_den if cwa_den else 0.0,\n            \"SWA\": swa_num / swa_den if swa_den else 0.0,\n            \"ACC\": sum(int(a == b) for a, b in zip(y_true, y_pred)) / len(y_true),\n        },\n        y_true,\n        y_pred,\n        seqs,\n    )\n\n\n# ---------------------------------------------------------------------\n# DATASET CONFIGS ------------------------------------------------------\nconfigs = [\n    dict(name=\"A_max8_balanced\", seed=1, max_len=8, shape_w=None, color_w=None),\n    dict(\n        name=\"B_max12_shapeBias\",\n        seed=2,\n        max_len=12,\n        shape_w=[0.3, 0.3, 0.1, 0.1, 0.1, 0.1],\n        color_w=None,\n    ),\n    dict(\n        name=\"C_max20_colorBias\",\n        seed=3,\n        max_len=20,\n        shape_w=None,\n        color_w=[0.3, 0.3, 0.1, 0.1, 0.1, 0.1],\n    ),\n]\n\n# ---------------------------------------------------------------------\n# MAIN LOOP ------------------------------------------------------------\nEPOCHS = 5\nstart = time.time()\nfor cfg in configs:\n    print(f\"\\n=== Dataset {cfg['name']} ===\")\n    # Build datasets\n    dsdict = build_dataset_dict(\n        cfg[\"seed\"], cfg[\"max_len\"], cfg[\"shape_w\"], cfg[\"color_w\"]\n    )\n    train_ds = SPRGraphDataset(dsdict[\"train\"])\n    dev_ds = SPRGraphDataset(dsdict[\"dev\"])\n    test_ds = SPRGraphDataset(dsdict[\"test\"])\n\n    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n    dev_loader = DataLoader(dev_ds, batch_size=128)\n    test_loader = DataLoader(test_ds, batch_size=128)\n\n    # Model / optimiser\n    model = GNNClassifier(feat_dim, hid=64, num_classes=2).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    # Storage\n    experiment_data[\"multi_dataset_generalization\"][cfg[\"name\"]] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"test_metrics\": {},\n    }\n    rec = experiment_data[\"multi_dataset_generalization\"][cfg[\"name\"]]\n\n    # Train\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc, tr_pc = run_epoch(model, train_loader, criterion, optimizer)\n        dv_loss, dv_acc, dv_pc = run_epoch(model, dev_loader, criterion)\n\n        rec[\"losses\"][\"train\"].append((epoch, tr_loss))\n        rec[\"losses\"][\"val\"].append((epoch, dv_loss))\n        rec[\"metrics\"][\"train\"].append((epoch, tr_pc))\n        rec[\"metrics\"][\"val\"].append((epoch, dv_pc))\n\n        print(\n            f\"Ep{epoch:02d}: tr_loss={tr_loss:.3f} dv_loss={dv_loss:.3f} dv_PCWA={dv_pc:.3f}\"\n        )\n\n    # Final test\n    tst_metrics, y_t, y_p, seqs = evaluate(model, test_loader)\n    rec[\"test_metrics\"] = tst_metrics\n    rec[\"predictions\"] = y_p\n    rec[\"ground_truth\"] = y_t\n    print(\"Test:\", tst_metrics)\n\n# ---------------------------------------------------------------------\n# SAVE -----------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nDone in {time.time()-start:.1f}s. Data saved to {working_dir}\")\n", "# Positional-feature-removal ablation -------------------------------------------------\nimport os, random, string, time, pathlib, numpy as np, torch\nfrom typing import List\nfrom datasets import Dataset, DatasetDict\nfrom torch import nn\nfrom torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\n\n# ---------------------------------------------------------------------#\n# EXPERIMENT DATA DICT -------------------------------------------------#\nexperiment_data = {\n    \"positional_feature_removal\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------------------------------------------------------------------#\n# WORK DIR & DEVICE ----------------------------------------------------#\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------#\n# METRICS --------------------------------------------------------------#\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef pcwa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------------------------------------------------------------------#\n# DATA CREATION / LOADING ---------------------------------------------#\nROOT = pathlib.Path(\"./SPR_BENCH\")\nSHAPES = list(string.ascii_uppercase[:6])  # A-F\nCOLORS = list(map(str, range(1, 7)))  # 1-6\n\n\ndef gen_seq(max_len: int = 12) -> str:\n    length = random.randint(4, max_len)\n    tokens = [random.choice(SHAPES) + random.choice(COLORS) for _ in range(length)]\n    return \" \".join(tokens)\n\n\ndef label_rule(seq: str) -> int:\n    return int(count_shape_variety(seq) >= count_color_variety(seq))\n\n\ndef synthesize_split(n_samples: int) -> Dataset:\n    seqs, labels = [], []\n    for _ in range(n_samples):\n        s = gen_seq()\n        seqs.append(s)\n        labels.append(label_rule(s))\n    return Dataset.from_dict({\"sequence\": seqs, \"label\": labels})\n\n\ndef load_dataset_dict() -> DatasetDict:\n    if ROOT.exists():\n        from SPR import load_spr_bench  # pragma: no cover\n\n        return load_spr_bench(ROOT)\n    print(\"SPR_BENCH not found \u2013 generating synthetic data.\")\n    return DatasetDict(\n        {\n            \"train\": synthesize_split(2000),\n            \"dev\": synthesize_split(400),\n            \"test\": synthesize_split(400),\n        }\n    )\n\n\ndsets = load_dataset_dict()\nnum_classes = len(set(dsets[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in dsets.items()})\n\n# ---------------------------------------------------------------------#\n# GRAPH CONVERSION (w/o positional scalar) ----------------------------#\nshape_to_id = {s: i for i, s in enumerate(SHAPES)}\ncolor_to_id = {c: i for i, c in enumerate(COLORS)}\nfeat_dim = len(SHAPES) + len(COLORS)  # 12 dims, NO POSITION\n\n\ndef seq_to_graph(seq: str) -> Data:\n    tokens = seq.strip().split()\n    n = len(tokens)\n    x = torch.zeros((n, feat_dim), dtype=torch.float)\n    for i, tok in enumerate(tokens):\n        s, c = tok[0], tok[1]\n        x[i, shape_to_id[s]] = 1.0\n        x[i, len(SHAPES) + color_to_id[c]] = 1.0\n        # position feature deliberately removed\n    # bi-directional chain edges\n    if n > 1:\n        edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    else:\n        edge_index = torch.empty((2, 0), dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, seq=seq)\n\n\nclass SPRGraphDataset(InMemoryDataset):\n    def __init__(self, hf_dataset: Dataset):\n        self.hf_dataset = hf_dataset\n        super().__init__(None, None, None)\n        data_list = []\n        for seq, label in zip(hf_dataset[\"sequence\"], hf_dataset[\"label\"]):\n            g = seq_to_graph(seq)\n            g.y = torch.tensor([label], dtype=torch.long)\n            data_list.append(g)\n        self.data, self.slices = self.collate(data_list)\n\n\n# ---------------------------------------------------------------------#\n# DATA LOADERS ---------------------------------------------------------#\ntrain_data = SPRGraphDataset(dsets[\"train\"])\nval_data = SPRGraphDataset(dsets[\"dev\"])\ntest_data = SPRGraphDataset(dsets[\"test\"])\n\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=128)\ntest_loader = DataLoader(test_data, batch_size=128)\n\n\n# ---------------------------------------------------------------------#\n# MODEL ----------------------------------------------------------------#\nclass GNNClassifier(nn.Module):\n    def __init__(self, in_dim: int, hid: int = 64, num_classes: int = 2):\n        super().__init__()\n        self.conv1 = GraphConv(in_dim, hid)\n        self.conv2 = GraphConv(hid, hid)\n        self.lin = nn.Linear(hid, num_classes)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\nmodel = GNNClassifier(feat_dim, hid=64, num_classes=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------------------------------------------------------------------#\n# TRAIN / EVAL LOOPS ---------------------------------------------------#\ndef run_epoch(loader, train_mode: bool = True):\n    model.train() if train_mode else model.eval()\n    total_loss, total, correct = 0.0, 0, 0\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        out = model(data)\n        loss = criterion(out, data.y.view(-1))\n        if train_mode:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        total_loss += loss.item() * data.num_graphs\n        pred = out.argmax(dim=1)\n        correct += int((pred == data.y.view(-1)).sum())\n        total += data.num_graphs\n        all_seq.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    avg_loss = total_loss / total\n    acc = correct / total\n    pc = pcwa(all_seq, y_true, y_pred)\n    return avg_loss, acc, pc\n\n\n# ---------------------------------------------------------------------#\n# TRAINING -------------------------------------------------------------#\nEPOCHS = 5\nstart = time.time()\nfor epoch in range(1, EPOCHS + 1):\n    tr_loss, tr_acc, tr_pc = run_epoch(train_loader, True)\n    val_loss, val_acc, val_pc = run_epoch(val_loader, False)\n\n    experiment_data[\"positional_feature_removal\"][\"SPR\"][\"losses\"][\"train\"].append(\n        (epoch, tr_loss)\n    )\n    experiment_data[\"positional_feature_removal\"][\"SPR\"][\"losses\"][\"val\"].append(\n        (epoch, val_loss)\n    )\n    experiment_data[\"positional_feature_removal\"][\"SPR\"][\"metrics\"][\"train\"].append(\n        (epoch, tr_pc)\n    )\n    experiment_data[\"positional_feature_removal\"][\"SPR\"][\"metrics\"][\"val\"].append(\n        (epoch, val_pc)\n    )\n\n    print(\n        f\"Epoch {epoch}: train_loss={tr_loss:.4f} val_loss={val_loss:.4f} val_PCWA={val_pc:.4f}\"\n    )\n\n\n# ---------------------------------------------------------------------#\n# FINAL TEST EVALUATION ------------------------------------------------#\ndef compute_metrics(loader):\n    model.eval()\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for data in loader:\n            data = data.to(device)\n            out = model(data)\n            pred = out.argmax(dim=1)\n            all_seq.extend(data.seq)\n            y_true.extend(data.y.view(-1).tolist())\n            y_pred.extend(pred.tolist())\n    cwa_num = sum(\n        count_color_variety(s) if y == p else 0\n        for s, y, p in zip(all_seq, y_true, y_pred)\n    )\n    cwa_den = sum(count_color_variety(s) for s in all_seq)\n    swa_num = sum(\n        count_shape_variety(s) if y == p else 0\n        for s, y, p in zip(all_seq, y_true, y_pred)\n    )\n    swa_den = sum(count_shape_variety(s) for s in all_seq)\n    return (\n        {\n            \"PCWA\": pcwa(all_seq, y_true, y_pred),\n            \"CWA\": cwa_num / cwa_den if cwa_den else 0.0,\n            \"SWA\": swa_num / swa_den if swa_den else 0.0,\n            \"ACC\": sum(int(y == p) for y, p in zip(y_true, y_pred)) / len(y_true),\n        },\n        y_true,\n        y_pred,\n        all_seq,\n    )\n\n\ntest_metrics, y_t, y_p, seqs = compute_metrics(test_loader)\nprint(\"TEST METRICS:\", test_metrics)\n\nexperiment_data[\"positional_feature_removal\"][\"SPR\"][\"predictions\"] = y_p\nexperiment_data[\"positional_feature_removal\"][\"SPR\"][\"ground_truth\"] = y_t\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\nprint(f\"Finished in {time.time()-start:.1f}s; results saved to {working_dir}\")\n", "import os, random, string, numpy as np, torch, pathlib, time\nfrom typing import List\nfrom datasets import Dataset, DatasetDict\nfrom torch import nn\nfrom torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\n\n# ----------------------------- EXPERIMENT META -----------------------\nABLATION_KEY = \"no_color_feature\"\nexperiment_data = {\n    ABLATION_KEY: {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ----------------------------- DEVICE & WORKDIR ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ----------------------------- METRICS --------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef pcwa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ----------------------------- DATA -----------------------------------\nROOT = pathlib.Path(\"./SPR_BENCH\")\nSHAPES = list(string.ascii_uppercase[:6])  # A-F\nCOLORS = list(map(str, range(1, 7)))  # 1-6\n\n\ndef gen_seq(max_len: int = 12) -> str:\n    length = random.randint(4, max_len)\n    tokens = [random.choice(SHAPES) + random.choice(COLORS) for _ in range(length)]\n    return \" \".join(tokens)\n\n\ndef label_rule(seq: str) -> int:\n    return int(count_shape_variety(seq) >= count_color_variety(seq))\n\n\ndef synthesize_split(n_samples: int) -> Dataset:\n    seqs, labels = [], []\n    for _ in range(n_samples):\n        s = gen_seq()\n        seqs.append(s)\n        labels.append(label_rule(s))\n    return Dataset.from_dict({\"sequence\": seqs, \"label\": labels})\n\n\ndef load_dataset_dict() -> DatasetDict:\n    if ROOT.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(ROOT)\n    print(\"SPR_BENCH not found \u2013 generating synthetic data.\")\n    return DatasetDict(\n        {\n            \"train\": synthesize_split(2000),\n            \"dev\": synthesize_split(400),\n            \"test\": synthesize_split(400),\n        }\n    )\n\n\ndsets = load_dataset_dict()\nnum_classes = len(set(dsets[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in dsets.items()})\n\n# ----------------------------- GRAPH BUILDING -------------------------\nshape_to_id = {s: i for i, s in enumerate(SHAPES)}\nfeat_dim = len(SHAPES) + 1  # shape one-hot + positional (color one-hot removed!)\n\n\ndef seq_to_graph(seq: str) -> Data:\n    tokens = seq.strip().split()\n    n = len(tokens)\n    x = torch.zeros((n, feat_dim), dtype=torch.float)\n    for i, tok in enumerate(tokens):\n        s = tok[0]\n        x[i, shape_to_id[s]] = 1.0  # shape one-hot\n        x[i, -1] = i / (n - 1) if n > 1 else 0.0  # position scalar\n    # chain edges\n    if n > 1:\n        edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    else:\n        edge_index = torch.empty((2, 0), dtype=torch.long)\n    g = Data(x=x, edge_index=edge_index, seq=seq)\n    return g\n\n\nclass SPRGraphDataset(InMemoryDataset):\n    def __init__(self, hf_dataset: Dataset):\n        self.hf_dataset = hf_dataset\n        super().__init__(None, None, None)\n        data_list = []\n        for seq, label in zip(hf_dataset[\"sequence\"], hf_dataset[\"label\"]):\n            g = seq_to_graph(seq)\n            g.y = torch.tensor([label], dtype=torch.long)\n            data_list.append(g)\n        self.data, self.slices = self.collate(data_list)\n\n\ntrain_data = SPRGraphDataset(dsets[\"train\"])\nval_data = SPRGraphDataset(dsets[\"dev\"])\ntest_data = SPRGraphDataset(dsets[\"test\"])\n\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=128)\ntest_loader = DataLoader(test_data, batch_size=128)\n\n\n# ----------------------------- MODEL ----------------------------------\nclass GNNClassifier(nn.Module):\n    def __init__(self, in_dim: int, hid: int = 64, num_classes: int = 2):\n        super().__init__()\n        self.conv1 = GraphConv(in_dim, hid)\n        self.conv2 = GraphConv(hid, hid)\n        self.lin = nn.Linear(hid, num_classes)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\nmodel = GNNClassifier(feat_dim, hid=64, num_classes=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ----------------------------- TRAIN / EVAL ---------------------------\ndef run_epoch(loader, train_mode: bool):\n    model.train() if train_mode else model.eval()\n    total_loss, total, correct = 0.0, 0, 0\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        out = model(data)\n        loss = criterion(out, data.y.view(-1))\n        if train_mode:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        total_loss += loss.item() * data.num_graphs\n        pred = out.argmax(dim=1)\n        correct += int((pred == data.y.view(-1)).sum())\n        total += data.num_graphs\n        all_seq.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    return (\n        total_loss / total,\n        correct / total,\n        pcwa(all_seq, y_true, y_pred),\n    )\n\n\nEPOCHS = 5\nstart_time = time.time()\nfor epoch in range(1, EPOCHS + 1):\n    tr_loss, tr_acc, tr_pc = run_epoch(train_loader, True)\n    val_loss, val_acc, val_pc = run_epoch(val_loader, False)\n\n    experiment_data[ABLATION_KEY][\"SPR\"][\"losses\"][\"train\"].append((epoch, tr_loss))\n    experiment_data[ABLATION_KEY][\"SPR\"][\"losses\"][\"val\"].append((epoch, val_loss))\n    experiment_data[ABLATION_KEY][\"SPR\"][\"metrics\"][\"train\"].append((epoch, tr_pc))\n    experiment_data[ABLATION_KEY][\"SPR\"][\"metrics\"][\"val\"].append((epoch, val_pc))\n\n    print(\n        f\"Epoch {epoch}: train_loss={tr_loss:.4f} val_loss={val_loss:.4f} val_PCWA={val_pc:.4f}\"\n    )\n\n\n# ----------------------------- TEST -----------------------------------\ndef compute_metrics(loader):\n    model.eval()\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        with torch.no_grad():\n            out = model(data)\n        pred = out.argmax(dim=1)\n        all_seq.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    cwa_num = sum(\n        count_color_variety(s) if y == p else 0\n        for s, y, p in zip(all_seq, y_true, y_pred)\n    )\n    cwa_den = sum(count_color_variety(s) for s in all_seq)\n    swa_num = sum(\n        count_shape_variety(s) if y == p else 0\n        for s, y, p in zip(all_seq, y_true, y_pred)\n    )\n    swa_den = sum(count_shape_variety(s) for s in all_seq)\n    return (\n        {\n            \"PCWA\": pcwa(all_seq, y_true, y_pred),\n            \"CWA\": cwa_num / cwa_den if cwa_den else 0.0,\n            \"SWA\": swa_num / swa_den if swa_den else 0.0,\n            \"ACC\": sum(int(y == p) for y, p in zip(y_true, y_pred)) / len(y_true),\n        },\n        y_true,\n        y_pred,\n        all_seq,\n    )\n\n\ntest_metrics, y_t, y_p, seqs = compute_metrics(test_loader)\nprint(\"TEST METRICS:\", test_metrics)\n\nexperiment_data[ABLATION_KEY][\"SPR\"][\"predictions\"] = y_p\nexperiment_data[ABLATION_KEY][\"SPR\"][\"ground_truth\"] = y_t\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Finished in {time.time()-start_time:.1f}s; results saved to {working_dir}\")\n", "# Edge\u2013Removal Ablation: each token is an isolated node\nimport os, random, string, numpy as np, torch, pathlib, time\nfrom typing import List\nfrom datasets import Dataset, DatasetDict\nfrom torch import nn\nfrom torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\n\n# ---------------------------------------------------------------------\n# EXPERIMENT REGISTRY & STORAGE\nexperiment_data = {\n    \"NoEdges\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# METRICS --------------------------------------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef pcwa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------------------------------------------------------------------\n# DATA (load SPR or synthesise) ---------------------------------------\nROOT = pathlib.Path(\"./SPR_BENCH\")\nSHAPES = list(string.ascii_uppercase[:6])  # A-F\nCOLORS = list(map(str, range(1, 7)))  # 1-6\n\n\ndef gen_seq(max_len: int = 12) -> str:\n    n = random.randint(4, max_len)\n    return \" \".join(random.choice(SHAPES) + random.choice(COLORS) for _ in range(n))\n\n\ndef label_rule(seq: str) -> int:\n    return int(count_shape_variety(seq) >= count_color_variety(seq))\n\n\ndef synthesize_split(n: int) -> Dataset:\n    seqs, labels = [], []\n    for _ in range(n):\n        s = gen_seq()\n        seqs.append(s)\n        labels.append(label_rule(s))\n    return Dataset.from_dict({\"sequence\": seqs, \"label\": labels})\n\n\ndef load_dataset_dict() -> DatasetDict:\n    if ROOT.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(ROOT)\n    print(\"SPR_BENCH not found \u2013 generating synthetic data.\")\n    return DatasetDict(\n        {\n            \"train\": synthesize_split(2000),\n            \"dev\": synthesize_split(400),\n            \"test\": synthesize_split(400),\n        }\n    )\n\n\ndsets = load_dataset_dict()\nnum_classes = len(set(dsets[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in dsets.items()})\n\n# ---------------------------------------------------------------------\n# GRAPH CONVERSION (No edges) -----------------------------------------\nshape_to_id = {s: i for i, s in enumerate(SHAPES)}\ncolor_to_id = {c: i for i, c in enumerate(COLORS)}\nfeat_dim = len(SHAPES) + len(COLORS) + 1  # shape one-hot + color one-hot + pos\n\n\ndef seq_to_graph_no_edges(seq: str) -> Data:\n    toks = seq.strip().split()\n    n = len(toks)\n    x = torch.zeros((n, feat_dim), dtype=torch.float)\n    for i, tok in enumerate(toks):\n        s, c = tok[0], tok[1]\n        x[i, shape_to_id[s]] = 1.0\n        x[i, len(SHAPES) + color_to_id[c]] = 1.0\n        x[i, -1] = i / (n - 1) if n > 1 else 0.0\n    edge_index = torch.empty((2, 0), dtype=torch.long)  # <-- NO EDGES\n    return Data(x=x, edge_index=edge_index, seq=seq)\n\n\nclass SPRGraphDataset(InMemoryDataset):\n    def __init__(self, hf_dataset: Dataset):\n        super().__init__(None, None, None)\n        data_list = []\n        for s, y in zip(hf_dataset[\"sequence\"], hf_dataset[\"label\"]):\n            g = seq_to_graph_no_edges(s)\n            g.y = torch.tensor([y], dtype=torch.long)\n            data_list.append(g)\n        self.data, self.slices = self.collate(data_list)\n\n\n# ---------------------------------------------------------------------\n# LOADERS --------------------------------------------------------------\ntrain_data = SPRGraphDataset(dsets[\"train\"])\nval_data = SPRGraphDataset(dsets[\"dev\"])\ntest_data = SPRGraphDataset(dsets[\"test\"])\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=128)\ntest_loader = DataLoader(test_data, batch_size=128)\n\n\n# ---------------------------------------------------------------------\n# MODEL ----------------------------------------------------------------\nclass GNNClassifier(nn.Module):\n    def __init__(self, in_dim: int, hid: int = 64, num_classes: int = 2):\n        super().__init__()\n        self.conv1 = GraphConv(in_dim, hid)\n        self.conv2 = GraphConv(hid, hid)\n        self.lin = nn.Linear(hid, num_classes)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\nmodel = GNNClassifier(feat_dim, hid=64, num_classes=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------------------------------------------------------------------\n# TRAIN / EVAL ---------------------------------------------------------\ndef run_epoch(loader, train=True):\n    model.train() if train else model.eval()\n    tot_loss, tot, correct = 0.0, 0, 0\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        out = model(data)\n        loss = criterion(out, data.y.view(-1))\n        if train:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        tot_loss += loss.item() * data.num_graphs\n        pred = out.argmax(1)\n        correct += int((pred == data.y.view(-1)).sum())\n        tot += data.num_graphs\n        all_seq.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    return (\n        tot_loss / tot,\n        correct / tot,\n        pcwa(all_seq, y_true, y_pred),\n    )\n\n\nEPOCHS = 5\nstart = time.time()\nfor ep in range(1, EPOCHS + 1):\n    tr_loss, tr_acc, tr_pc = run_epoch(train_loader, True)\n    vl_loss, vl_acc, vl_pc = run_epoch(val_loader, False)\n    print(\n        f\"Epoch {ep}: train_loss={tr_loss:.4f} val_loss={vl_loss:.4f} val_PCWA={vl_pc:.4f}\"\n    )\n    experiment_data[\"NoEdges\"][\"SPR\"][\"losses\"][\"train\"].append((ep, tr_loss))\n    experiment_data[\"NoEdges\"][\"SPR\"][\"losses\"][\"val\"].append((ep, vl_loss))\n    experiment_data[\"NoEdges\"][\"SPR\"][\"metrics\"][\"train\"].append((ep, tr_pc))\n    experiment_data[\"NoEdges\"][\"SPR\"][\"metrics\"][\"val\"].append((ep, vl_pc))\n\n\n# ---------------------------------------------------------------------\n# TEST EVALUATION ------------------------------------------------------\ndef compute_metrics(loader):\n    model.eval()\n    seqs, ys, ps = [], [], []\n    for data in loader:\n        data = data.to(device)\n        with torch.no_grad():\n            out = model(data)\n        pred = out.argmax(1)\n        seqs.extend(data.seq)\n        ys.extend(data.y.view(-1).tolist())\n        ps.extend(pred.tolist())\n    cwa_num = sum(\n        count_color_variety(s) if y == p else 0 for s, y, p in zip(seqs, ys, ps)\n    )\n    cwa_den = sum(count_color_variety(s) for s in seqs)\n    swa_num = sum(\n        count_shape_variety(s) if y == p else 0 for s, y, p in zip(seqs, ys, ps)\n    )\n    swa_den = sum(count_shape_variety(s) for s in seqs)\n    metrics = {\n        \"PCWA\": pcwa(seqs, ys, ps),\n        \"CWA\": cwa_num / cwa_den if cwa_den else 0.0,\n        \"SWA\": swa_num / swa_den if swa_den else 0.0,\n        \"ACC\": sum(int(y == p) for y, p in zip(ys, ps)) / len(ys),\n    }\n    return metrics, ys, ps, seqs\n\n\ntest_metrics, y_true, y_pred, seqs = compute_metrics(test_loader)\nprint(\"TEST METRICS:\", test_metrics)\nexperiment_data[\"NoEdges\"][\"SPR\"][\"predictions\"] = y_pred\nexperiment_data[\"NoEdges\"][\"SPR\"][\"ground_truth\"] = y_true\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Finished in {time.time()-start:.1f}s. Data saved to {working_dir}\")\n", "import os, random, string, numpy as np, torch, pathlib, time\nfrom typing import List\nfrom datasets import Dataset, DatasetDict\nfrom torch import nn\nfrom torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\n\n# ---------------------------------------------------------------------\n# SAVE STRUCTURE -------------------------------------------------------\nexperiment_data = {\n    \"ShapeRemoval\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------------------------------------------------------------------\n# WORK DIR & DEVICE ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# METRICS --------------------------------------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef pcwa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------------------------------------------------------------------\n# DATA ----------------------------------------------------------------\nROOT = pathlib.Path(\"./SPR_BENCH\")\nSHAPES = list(string.ascii_uppercase[:6])  # A-F\nCOLORS = list(map(str, range(1, 7)))  # 1-6\n\n\ndef gen_seq(max_len: int = 12) -> str:\n    length = random.randint(4, max_len)\n    return \" \".join(\n        random.choice(SHAPES) + random.choice(COLORS) for _ in range(length)\n    )\n\n\ndef label_rule(seq: str) -> int:\n    return int(count_shape_variety(seq) >= count_color_variety(seq))\n\n\ndef synthesize_split(n: int) -> Dataset:\n    seqs, labels = [], []\n    for _ in range(n):\n        s = gen_seq()\n        seqs.append(s)\n        labels.append(label_rule(s))\n    return Dataset.from_dict({\"sequence\": seqs, \"label\": labels})\n\n\ndef load_dataset_dict() -> DatasetDict:\n    if ROOT.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(ROOT)\n    print(\"SPR_BENCH not found \u2013 generating synthetic data.\")\n    return DatasetDict(\n        {\n            \"train\": synthesize_split(2000),\n            \"dev\": synthesize_split(400),\n            \"test\": synthesize_split(400),\n        }\n    )\n\n\ndsets = load_dataset_dict()\nnum_classes = len(set(dsets[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in dsets.items()})\n\n# ---------------------------------------------------------------------\n# GRAPH CONVERSION (SHAPE REMOVED) ------------------------------------\ncolor_to_id = {c: i for i, c in enumerate(COLORS)}\nfeat_dim = len(COLORS) + 1  # color one-hot + position\n\n\ndef seq_to_graph(seq: str) -> Data:\n    toks = seq.strip().split()\n    n = len(toks)\n    x = torch.zeros((n, feat_dim), dtype=torch.float)\n    for i, tok in enumerate(toks):\n        c = tok[1]\n        x[i, color_to_id[c]] = 1.0\n        x[i, -1] = i / (n - 1) if n > 1 else 0.0\n    if n > 1:\n        edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    else:\n        edge_index = torch.empty((2, 0), dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, seq=seq)\n\n\nclass SPRGraphDataset(InMemoryDataset):\n    def __init__(self, hf_ds: Dataset):\n        super().__init__(None, None, None)\n        data_list = []\n        for s, y in zip(hf_ds[\"sequence\"], hf_ds[\"label\"]):\n            g = seq_to_graph(s)\n            g.y = torch.tensor([y], dtype=torch.long)\n            data_list.append(g)\n        self.data, self.slices = self.collate(data_list)\n\n\ntrain_data = SPRGraphDataset(dsets[\"train\"])\nval_data = SPRGraphDataset(dsets[\"dev\"])\ntest_data = SPRGraphDataset(dsets[\"test\"])\n\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=128)\ntest_loader = DataLoader(test_data, batch_size=128)\n\n\n# ---------------------------------------------------------------------\n# MODEL ---------------------------------------------------------------\nclass GNNClassifier(nn.Module):\n    def __init__(self, in_dim: int, hid: int = 64, num_cls: int = 2):\n        super().__init__()\n        self.conv1 = GraphConv(in_dim, hid)\n        self.conv2 = GraphConv(hid, hid)\n        self.lin = nn.Linear(hid, num_cls)\n\n    def forward(self, data):\n        x, ei, batch = data.x, data.edge_index, data.batch\n        x = self.conv1(x, ei).relu()\n        x = self.conv2(x, ei).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\nmodel = GNNClassifier(feat_dim, 64, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------------------------------------------------------------------\n# TRAIN / VAL LOOP ----------------------------------------------------\ndef run_epoch(loader, train=True):\n    model.train() if train else model.eval()\n    tot_loss = tot = correct = 0\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        out = model(data)\n        loss = criterion(out, data.y.view(-1))\n        if train:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        tot_loss += loss.item() * data.num_graphs\n        pred = out.argmax(1)\n        correct += int((pred == data.y.view(-1)).sum())\n        tot += data.num_graphs\n        all_seq.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    return (tot_loss / tot, correct / tot, pcwa(all_seq, y_true, y_pred))\n\n\nEPOCHS = 5\nstart_time = time.time()\nfor epoch in range(1, EPOCHS + 1):\n    tr_loss, tr_acc, tr_pc = run_epoch(train_loader, True)\n    vl_loss, vl_acc, vl_pc = run_epoch(val_loader, False)\n    experiment_data[\"ShapeRemoval\"][\"SPR\"][\"losses\"][\"train\"].append((epoch, tr_loss))\n    experiment_data[\"ShapeRemoval\"][\"SPR\"][\"losses\"][\"val\"].append((epoch, vl_loss))\n    experiment_data[\"ShapeRemoval\"][\"SPR\"][\"metrics\"][\"train\"].append((epoch, tr_pc))\n    experiment_data[\"ShapeRemoval\"][\"SPR\"][\"metrics\"][\"val\"].append((epoch, vl_pc))\n    print(\n        f\"Epoch {epoch}: train_loss={tr_loss:.4f} val_loss={vl_loss:.4f} val_PCWA={vl_pc:.4f}\"\n    )\n\n\n# ---------------------------------------------------------------------\n# TEST EVAL -----------------------------------------------------------\ndef compute_metrics(loader):\n    model.eval()\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        with torch.no_grad():\n            out = model(data)\n        pred = out.argmax(1)\n        all_seq.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    cwa_num = sum(\n        count_color_variety(s) if y == p else 0\n        for s, y, p in zip(all_seq, y_true, y_pred)\n    )\n    cwa_den = sum(count_color_variety(s) for s in all_seq)\n    swa_num = sum(\n        count_shape_variety(s) if y == p else 0\n        for s, y, p in zip(all_seq, y_true, y_pred)\n    )\n    swa_den = sum(count_shape_variety(s) for s in all_seq)\n    return (\n        {\n            \"PCWA\": pcwa(all_seq, y_true, y_pred),\n            \"CWA\": cwa_num / cwa_den if cwa_den else 0.0,\n            \"SWA\": swa_num / swa_den if swa_den else 0.0,\n            \"ACC\": sum(int(y == p) for y, p in zip(y_true, y_pred)) / len(y_true),\n        },\n        y_true,\n        y_pred,\n        all_seq,\n    )\n\n\ntest_metrics, y_t, y_p, seqs = compute_metrics(test_loader)\nprint(\"TEST METRICS:\", test_metrics)\n\ned = experiment_data[\"ShapeRemoval\"][\"SPR\"]\ned[\"predictions\"], ed[\"ground_truth\"] = y_p, y_t\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Finished in {(time.time()-start_time):.1f}s; results saved to {working_dir}\")\n", "import os, random, string, time, pathlib, numpy as np, torch\nfrom typing import List\nfrom datasets import Dataset, DatasetDict\nfrom torch import nn\nfrom torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\n\n# ---------------------------------------------------------------------\n# EXPERIMENT DATA STORAGE ---------------------------------------------\nexperiment_data = {\n    \"single_layer_gnn\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------------------------------------------------------------------\n# WORK DIR & DEVICE ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------------------------------------------------------------------\n# METRICS --------------------------------------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef pcwa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    num = sum(w for w, yt, yp in zip(weights, y_true, y_pred) if yt == yp)\n    den = sum(weights)\n    return num / den if den else 0.0\n\n\n# ---------------------------------------------------------------------\n# DATA (load SPR benchmark if available, else synthetic) --------------\nROOT = pathlib.Path(\"./SPR_BENCH\")\nSHAPES = list(string.ascii_uppercase[:6])  # A-F\nCOLORS = list(map(str, range(1, 7)))  # 1-6\n\n\ndef gen_seq(max_len: int = 12) -> str:\n    return \" \".join(\n        random.choice(SHAPES) + random.choice(COLORS)\n        for _ in range(random.randint(4, max_len))\n    )\n\n\ndef label_rule(seq: str) -> int:\n    return int(count_shape_variety(seq) >= count_color_variety(seq))\n\n\ndef synthesize_split(n: int) -> Dataset:\n    return Dataset.from_dict(\n        {\n            \"sequence\": [gen_seq() for _ in range(n)],\n            \"label\": [label_rule(gen_seq()) for _ in range(n)],\n        }\n    )\n\n\ndef load_dataset_dict() -> DatasetDict:\n    if ROOT.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(ROOT)\n    print(\"SPR_BENCH not found \u2013 generating synthetic data.\")\n    return DatasetDict(\n        {\n            \"train\": synthesize_split(2000),\n            \"dev\": synthesize_split(400),\n            \"test\": synthesize_split(400),\n        }\n    )\n\n\ndsets = load_dataset_dict()\nnum_classes = len(set(dsets[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in dsets.items()})\n\n# ---------------------------------------------------------------------\n# GRAPH CONVERSION -----------------------------------------------------\nshape_to_id = {s: i for i, s in enumerate(SHAPES)}\ncolor_to_id = {c: i for i, c in enumerate(COLORS)}\nfeat_dim = len(SHAPES) + len(COLORS) + 1  # shape one-hot + color one-hot + position\n\n\ndef seq_to_graph(seq: str) -> Data:\n    toks = seq.strip().split()\n    n = len(toks)\n    x = torch.zeros((n, feat_dim), dtype=torch.float)\n    for i, tok in enumerate(toks):\n        x[i, shape_to_id[tok[0]]] = 1.0\n        x[i, len(SHAPES) + color_to_id[tok[1]]] = 1.0\n        x[i, -1] = i / (n - 1) if n > 1 else 0.0\n    edges = (\n        [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n        if n > 1\n        else []\n    )\n    edge_index = (\n        torch.tensor(edges, dtype=torch.long).t().contiguous()\n        if edges\n        else torch.empty((2, 0), dtype=torch.long)\n    )\n    return Data(x=x, edge_index=edge_index, seq=seq)\n\n\nclass SPRGraphDataset(InMemoryDataset):\n    def __init__(self, hf_dataset: Dataset):\n        super().__init__(None, None, None)\n        data_list = []\n        for seq, label in zip(hf_dataset[\"sequence\"], hf_dataset[\"label\"]):\n            g = seq_to_graph(seq)\n            g.y = torch.tensor([label], dtype=torch.long)\n            data_list.append(g)\n        self.data, self.slices = self.collate(data_list)\n\n\n# ---------------------------------------------------------------------\n# DATA LOADERS ---------------------------------------------------------\ntrain_data = SPRGraphDataset(dsets[\"train\"])\nval_data = SPRGraphDataset(dsets[\"dev\"])\ntest_data = SPRGraphDataset(dsets[\"test\"])\n\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=128)\ntest_loader = DataLoader(test_data, batch_size=128)\n\n\n# ---------------------------------------------------------------------\n# MODEL (Single-layer GNN) --------------------------------------------\nclass OneLayerGNN(nn.Module):\n    def __init__(self, in_dim: int, hid: int = 64, num_classes: int = 2):\n        super().__init__()\n        self.conv = GraphConv(in_dim, hid)\n        self.lin = nn.Linear(hid, num_classes)\n\n    def forward(self, data):\n        x = self.conv(data.x, data.edge_index).relu()\n        x = global_mean_pool(x, data.batch)\n        return self.lin(x)\n\n\nmodel = OneLayerGNN(feat_dim, hid=64, num_classes=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------------------------------------------------------------------\n# TRAIN / EVAL ---------------------------------------------------------\ndef run_epoch(loader, train_mode=True):\n    model.train() if train_mode else model.eval()\n    total_loss, correct, total = 0.0, 0, 0\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        out = model(data)\n        loss = criterion(out, data.y.view(-1))\n        if train_mode:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        total_loss += loss.item() * data.num_graphs\n        pred = out.argmax(1)\n        correct += int((pred == data.y.view(-1)).sum())\n        total += data.num_graphs\n        all_seq.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    return (\n        total_loss / total,\n        correct / total,\n        pcwa(all_seq, y_true, y_pred),\n    )\n\n\n# ---------------------------------------------------------------------\nEPOCHS = 5\nstart = time.time()\nfor epoch in range(1, EPOCHS + 1):\n    tr_loss, tr_acc, tr_pc = run_epoch(train_loader, True)\n    val_loss, val_acc, val_pc = run_epoch(val_loader, False)\n\n    experiment_data[\"single_layer_gnn\"][\"SPR\"][\"losses\"][\"train\"].append(\n        (epoch, tr_loss)\n    )\n    experiment_data[\"single_layer_gnn\"][\"SPR\"][\"losses\"][\"val\"].append(\n        (epoch, val_loss)\n    )\n    experiment_data[\"single_layer_gnn\"][\"SPR\"][\"metrics\"][\"train\"].append(\n        (epoch, tr_pc)\n    )\n    experiment_data[\"single_layer_gnn\"][\"SPR\"][\"metrics\"][\"val\"].append((epoch, val_pc))\n\n    print(\n        f\"Epoch {epoch}: train_loss={tr_loss:.4f} val_loss={val_loss:.4f} \"\n        f\"val_PCWA={val_pc:.4f}\"\n    )\n\n\n# ---------------------------------------------------------------------\n# FINAL TEST -----------------------------------------------------------\ndef evaluate(loader):\n    model.eval()\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        with torch.no_grad():\n            out = model(data)\n        pred = out.argmax(1)\n        all_seq.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(pred.tolist())\n    metrics = {\n        \"PCWA\": pcwa(all_seq, y_true, y_pred),\n        \"ACC\": sum(int(y == p) for y, p in zip(y_true, y_pred)) / len(y_true),\n    }\n    return metrics, y_true, y_pred\n\n\ntest_metrics, y_t, y_p = evaluate(test_loader)\nprint(\"TEST METRICS:\", test_metrics)\n\nexperiment_data[\"single_layer_gnn\"][\"SPR\"][\"predictions\"] = y_p\nexperiment_data[\"single_layer_gnn\"][\"SPR\"][\"ground_truth\"] = y_t\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Finished in {time.time()-start:.1f}s; results saved to {working_dir}\")\n", "# UniChain \u2013 Unidirectional Chain Edges Ablation\nimport os, random, string, numpy as np, torch, pathlib, time\nfrom typing import List\nfrom datasets import Dataset, DatasetDict\nfrom torch import nn\nfrom torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GraphConv, global_mean_pool\n\n# ---------------------------------------------------------------------\n# EXPERIMENT DATA HOLDER ----------------------------------------------\nexperiment_data = {\n    \"UniChain\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------------------------------------------------------------------\n# WORK DIR & DEVICE ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# METRICS --------------------------------------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef pcwa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------------------------------------------------------------------\n# LOAD OR SYNTHETIC DATA ----------------------------------------------\nROOT = pathlib.Path(\"./SPR_BENCH\")\nSHAPES = list(string.ascii_uppercase[:6])  # A-F\nCOLORS = list(map(str, range(1, 7)))  # 1-6\n\n\ndef gen_seq(max_len: int = 12) -> str:\n    length = random.randint(4, max_len)\n    return \" \".join(\n        random.choice(SHAPES) + random.choice(COLORS) for _ in range(length)\n    )\n\n\ndef label_rule(seq: str) -> int:\n    return int(count_shape_variety(seq) >= count_color_variety(seq))\n\n\ndef synthesize_split(n_samples: int) -> Dataset:\n    return Dataset.from_dict(\n        {\n            \"sequence\": [gen_seq() for _ in range(n_samples)],\n            \"label\": [label_rule(gen_seq()) for _ in range(n_samples)],\n        }\n    )\n\n\ndef load_dataset_dict() -> DatasetDict:\n    if ROOT.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(ROOT)\n    print(\"SPR_BENCH not found \u2013 generating synthetic data.\")\n    return DatasetDict(\n        {\n            \"train\": synthesize_split(2000),\n            \"dev\": synthesize_split(400),\n            \"test\": synthesize_split(400),\n        }\n    )\n\n\ndsets = load_dataset_dict()\nnum_classes = len(set(dsets[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in dsets.items()})\n\n# ---------------------------------------------------------------------\n# GRAPH CONVERSION -----------------------------------------------------\nshape_to_id = {s: i for i, s in enumerate(SHAPES)}\ncolor_to_id = {c: i for i, c in enumerate(COLORS)}\nfeat_dim = len(SHAPES) + len(COLORS) + 1  # shape one-hot + color one-hot + pos\n\n\ndef seq_to_graph(seq: str) -> Data:\n    toks = seq.strip().split()\n    n = len(toks)\n    x = torch.zeros((n, feat_dim), dtype=torch.float)\n    for i, tok in enumerate(toks):\n        sh, co = tok[0], tok[1]\n        x[i, shape_to_id[sh]] = 1.0\n        x[i, len(SHAPES) + color_to_id[co]] = 1.0\n        x[i, -1] = i / (n - 1) if n > 1 else 0.0\n    # Unidirectional (forward) chain edges only\n    if n > 1:\n        edges = [[i, i + 1] for i in range(n - 1)]\n        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    else:\n        edge_index = torch.empty((2, 0), dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, seq=seq)\n\n\nclass SPRGraphDataset(InMemoryDataset):\n    def __init__(self, hf_dataset: Dataset):\n        self.hf_dataset = hf_dataset\n        super().__init__(None, None, None)\n        data_list = []\n        for seq, label in zip(hf_dataset[\"sequence\"], hf_dataset[\"label\"]):\n            g = seq_to_graph(seq)\n            g.y = torch.tensor([label], dtype=torch.long)\n            data_list.append(g)\n        self.data, self.slices = self.collate(data_list)\n\n\n# ---------------------------------------------------------------------\n# DATA LOADERS ---------------------------------------------------------\ntrain_data = SPRGraphDataset(dsets[\"train\"])\nval_data = SPRGraphDataset(dsets[\"dev\"])\ntest_data = SPRGraphDataset(dsets[\"test\"])\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=128)\ntest_loader = DataLoader(test_data, batch_size=128)\n\n\n# ---------------------------------------------------------------------\n# MODEL ----------------------------------------------------------------\nclass GNNClassifier(nn.Module):\n    def __init__(self, in_dim: int, hid: int = 64, num_classes: int = 2):\n        super().__init__()\n        self.conv1 = GraphConv(in_dim, hid)\n        self.conv2 = GraphConv(hid, hid)\n        self.lin = nn.Linear(hid, num_classes)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\n\nmodel = GNNClassifier(feat_dim, 64, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------------------------------------------------------------------\n# TRAIN / EVAL ---------------------------------------------------------\ndef run_epoch(loader, train_mode=True):\n    model.train() if train_mode else model.eval()\n    tot_loss = tot = correct = 0\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        out = model(data)\n        loss = criterion(out, data.y.view(-1))\n        if train_mode:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        tot_loss += loss.item() * data.num_graphs\n        preds = out.argmax(dim=1)\n        correct += int((preds == data.y.view(-1)).sum())\n        tot += data.num_graphs\n        all_seq.extend(data.seq)\n        y_true.extend(data.y.view(-1).tolist())\n        y_pred.extend(preds.tolist())\n    return (tot_loss / tot, correct / tot, pcwa(all_seq, y_true, y_pred))\n\n\n# ---------------------------------------------------------------------\nEPOCHS = 5\nstart_time = time.time()\nfor epoch in range(1, EPOCHS + 1):\n    tr_loss, tr_acc, tr_pc = run_epoch(train_loader, True)\n    va_loss, va_acc, va_pc = run_epoch(val_loader, False)\n    experiment_data[\"UniChain\"][\"SPR\"][\"losses\"][\"train\"].append((epoch, tr_loss))\n    experiment_data[\"UniChain\"][\"SPR\"][\"losses\"][\"val\"].append((epoch, va_loss))\n    experiment_data[\"UniChain\"][\"SPR\"][\"metrics\"][\"train\"].append((epoch, tr_pc))\n    experiment_data[\"UniChain\"][\"SPR\"][\"metrics\"][\"val\"].append((epoch, va_pc))\n    print(\n        f\"Epoch {epoch}: train_loss={tr_loss:.4f} val_loss={va_loss:.4f} val_PCWA={va_pc:.4f}\"\n    )\n\n\n# ---------------------------------------------------------------------\n# FINAL TEST -----------------------------------------------------------\ndef evaluate(loader):\n    model.eval()\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for data in loader:\n            data = data.to(device)\n            out = model(data)\n            preds = out.argmax(dim=1)\n            all_seq.extend(data.seq)\n            y_true.extend(data.y.view(-1).tolist())\n            y_pred.extend(preds.tolist())\n    cwa_num = sum(\n        count_color_variety(s) if y == p else 0\n        for s, y, p in zip(all_seq, y_true, y_pred)\n    )\n    cwa_den = sum(count_color_variety(s) for s in all_seq)\n    swa_num = sum(\n        count_shape_variety(s) if y == p else 0\n        for s, y, p in zip(all_seq, y_true, y_pred)\n    )\n    swa_den = sum(count_shape_variety(s) for s in all_seq)\n    metrics = {\n        \"PCWA\": pcwa(all_seq, y_true, y_pred),\n        \"CWA\": cwa_num / cwa_den if cwa_den else 0.0,\n        \"SWA\": swa_num / swa_den if swa_den else 0.0,\n        \"ACC\": sum(int(y == p) for y, p in zip(y_true, y_pred)) / len(y_true),\n    }\n    return metrics, y_true, y_pred\n\n\ntest_metrics, y_t, y_p = evaluate(test_loader)\nprint(\"TEST METRICS:\", test_metrics)\ned = experiment_data[\"UniChain\"][\"SPR\"]\ned[\"predictions\"], ed[\"ground_truth\"] = y_p, y_t\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Finished in {time.time()-start_time:.1f}s; results saved to {working_dir}\")\n", "# First-Node Readout Ablation \u2013 complete runnable script\nimport os, random, string, numpy as np, torch, pathlib, time\nfrom typing import List\nfrom datasets import Dataset, DatasetDict\nfrom torch import nn\nfrom torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GraphConv\n\n# ---------------------------------------------------------------------\n# EXPERIMENT DATA STORAGE ---------------------------------------------\nexperiment_data = {\n    \"first_node_readout\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\nablation_key = \"first_node_readout\"\ndataset_key = \"SPR\"\n\n# ---------------------------------------------------------------------\n# WORK DIR & DEVICE ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# METRICS --------------------------------------------------------------\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef pcwa(seqs: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------------------------------------------------------------------\n# LOAD OR SYNTHESISE DATA ---------------------------------------------\nROOT = pathlib.Path(\"./SPR_BENCH\")\nSHAPES = list(string.ascii_uppercase[:6])  # A-F\nCOLORS = list(map(str, range(1, 7)))  # 1-6\n\n\ndef gen_seq(max_len: int = 12) -> str:\n    length = random.randint(4, max_len)\n    tokens = [random.choice(SHAPES) + random.choice(COLORS) for _ in range(length)]\n    return \" \".join(tokens)\n\n\ndef label_rule(seq: str) -> int:\n    return int(count_shape_variety(seq) >= count_color_variety(seq))\n\n\ndef synthesize_split(n_samples: int) -> Dataset:\n    seqs, labels = [], []\n    for _ in range(n_samples):\n        s = gen_seq()\n        seqs.append(s)\n        labels.append(label_rule(s))\n    return Dataset.from_dict({\"sequence\": seqs, \"label\": labels})\n\n\ndef load_dataset_dict() -> DatasetDict:\n    if ROOT.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(ROOT)\n    print(\"SPR_BENCH not found \u2013 generating synthetic data.\")\n    return DatasetDict(\n        {\n            \"train\": synthesize_split(2000),\n            \"dev\": synthesize_split(400),\n            \"test\": synthesize_split(400),\n        }\n    )\n\n\ndsets = load_dataset_dict()\nnum_classes = len(set(dsets[\"train\"][\"label\"]))\nprint({k: len(v) for k, v in dsets.items()})\n\n# ---------------------------------------------------------------------\n# GRAPH CONVERSION -----------------------------------------------------\nshape_to_id = {s: i for i, s in enumerate(SHAPES)}\ncolor_to_id = {c: i for i, c in enumerate(COLORS)}\nfeat_dim = len(SHAPES) + len(COLORS) + 1  # shape + color + pos\n\n\ndef seq_to_graph(seq: str) -> Data:\n    tokens = seq.strip().split()\n    n = len(tokens)\n    x = torch.zeros((n, feat_dim), dtype=torch.float)\n    for i, tok in enumerate(tokens):\n        s, c = tok[0], tok[1]\n        x[i, shape_to_id[s]] = 1.0\n        x[i, len(SHAPES) + color_to_id[c]] = 1.0\n        x[i, -1] = i / (n - 1) if n > 1 else 0.0\n    if n > 1:\n        edges = [[i, i + 1] for i in range(n - 1)] + [[i + 1, i] for i in range(n - 1)]\n        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    else:\n        edge_index = torch.empty((2, 0), dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, seq=seq)\n\n\nclass SPRGraphDataset(InMemoryDataset):\n    def __init__(self, hf_dataset: Dataset):\n        super().__init__(None, None, None)\n        data_list = []\n        for seq, label in zip(hf_dataset[\"sequence\"], hf_dataset[\"label\"]):\n            g = seq_to_graph(seq)\n            g.y = torch.tensor([label], dtype=torch.long)\n            data_list.append(g)\n        self.data, self.slices = self.collate(data_list)\n\n\n# ---------------------------------------------------------------------\n# DATA LOADERS ---------------------------------------------------------\ntrain_loader = DataLoader(SPRGraphDataset(dsets[\"train\"]), batch_size=64, shuffle=True)\nval_loader = DataLoader(SPRGraphDataset(dsets[\"dev\"]), batch_size=128)\ntest_loader = DataLoader(SPRGraphDataset(dsets[\"test\"]), batch_size=128)\n\n\n# ---------------------------------------------------------------------\n# MODEL ----------------------------------------------------------------\nclass GNNFirstNodeClassifier(nn.Module):\n    \"\"\"GraphConv x2, then readout hidden state of node index 0 of every graph.\"\"\"\n\n    def __init__(self, in_dim: int, hid: int = 64, num_classes: int = 2):\n        super().__init__()\n        self.conv1 = GraphConv(in_dim, hid)\n        self.conv2 = GraphConv(hid, hid)\n        self.lin = nn.Linear(hid, num_classes)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        # --- First-node readout ---------------------------------------\n        # Each graph forms a contiguous block in x; the first node of\n        # graph k is the first occurrence where batch==k after sorting.\n        first_node_mask = torch.zeros_like(batch, dtype=torch.bool)\n        first_node_mask[torch.unique_consecutive(batch, return_inverse=False)] = True\n        graph_emb = x[first_node_mask]  # [num_graphs, hid]\n        return self.lin(graph_emb)\n\n\nmodel = GNNFirstNodeClassifier(feat_dim, hid=64, num_classes=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------------------------------------------------------------------\n# TRAIN / EVAL LOOPS ---------------------------------------------------\ndef run_epoch(loader, train: bool):\n    model.train() if train else model.eval()\n    total_loss = total = correct = 0\n    all_seq, y_true, y_pred = [], [], []\n    for data in loader:\n        data = data.to(device)\n        out = model(data)\n        loss = criterion(out, data.y.view(-1))\n        if train:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        total_loss += loss.item() * data.num_graphs\n        pred = out.argmax(1)\n        correct += int((pred == data.y.view(-1)).sum())\n        total += data.num_graphs\n        all_seq.extend(data.seq)\n        y_true.extend(data.y.view(-1).cpu().tolist())\n        y_pred.extend(pred.cpu().tolist())\n    avg_loss = total_loss / total\n    acc = correct / total\n    pc = pcwa(all_seq, y_true, y_pred)\n    return avg_loss, acc, pc\n\n\n# ---------------------------------------------------------------------\nEPOCHS = 5\nstart_time = time.time()\nfor epoch in range(1, EPOCHS + 1):\n    tr_loss, tr_acc, tr_pc = run_epoch(train_loader, True)\n    val_loss, val_acc, val_pc = run_epoch(val_loader, False)\n    experiment_data[ablation_key][dataset_key][\"losses\"][\"train\"].append(\n        (epoch, tr_loss)\n    )\n    experiment_data[ablation_key][dataset_key][\"losses\"][\"val\"].append(\n        (epoch, val_loss)\n    )\n    experiment_data[ablation_key][dataset_key][\"metrics\"][\"train\"].append(\n        (epoch, tr_pc)\n    )\n    experiment_data[ablation_key][dataset_key][\"metrics\"][\"val\"].append((epoch, val_pc))\n    print(\n        f\"Epoch {epoch}: train_loss={tr_loss:.4f} val_loss={val_loss:.4f} val_PCWA={val_pc:.4f}\"\n    )\n\n\n# ---------------------------------------------------------------------\n# FINAL TEST EVALUATION ------------------------------------------------\ndef compute_metrics(loader):\n    model.eval()\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for data in loader:\n            data = data.to(device)\n            out = model(data)\n            pred = out.argmax(1)\n            all_seq.extend(data.seq)\n            y_true.extend(data.y.view(-1).cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    cwa_den = sum(count_color_variety(s) for s in all_seq) or 1\n    swa_den = sum(count_shape_variety(s) for s in all_seq) or 1\n    pc = pcwa(all_seq, y_true, y_pred)\n    cwa = (\n        sum(\n            count_color_variety(s) if y == p else 0\n            for s, y, p in zip(all_seq, y_true, y_pred)\n        )\n        / cwa_den\n    )\n    swa = (\n        sum(\n            count_shape_variety(s) if y == p else 0\n            for s, y, p in zip(all_seq, y_true, y_pred)\n        )\n        / swa_den\n    )\n    acc = sum(int(y == p) for y, p in zip(y_true, y_pred)) / len(y_true)\n    return {\"PCWA\": pc, \"CWA\": cwa, \"SWA\": swa, \"ACC\": acc}, y_true, y_pred, all_seq\n\n\ntest_metrics, y_t, y_p, seqs = compute_metrics(test_loader)\nprint(\"TEST METRICS:\", test_metrics)\nexperiment_data[ablation_key][dataset_key][\"predictions\"] = y_p\nexperiment_data[ablation_key][dataset_key][\"ground_truth\"] = y_t\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Finished in {time.time()-start_time:.1f}s; results saved to {working_dir}\")\n"], "term_out": ["['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating synthetic data.',\n'\\n', \"{'train': 2000, 'dev': 400, 'test': 400}\", '\\n', 'Epoch 1:\ntrain_loss=0.6250 val_loss=0.6077 val_PCWA=0.6949', '\\n', 'Epoch 2:\ntrain_loss=0.6178 val_loss=0.6055 val_PCWA=0.6949', '\\n', 'Epoch 3:\ntrain_loss=0.6163 val_loss=0.6037 val_PCWA=0.6949', '\\n', 'Epoch 4:\ntrain_loss=0.6115 val_loss=0.6010 val_PCWA=0.6949', '\\n', 'Epoch 5:\ntrain_loss=0.6057 val_loss=0.6016 val_PCWA=0.6968', '\\n', 'TEST METRICS:', ' ',\n\"{'PCWA': 0.6821803465283925, 'CWA': 0.6326530612244898, 'SWA':\n0.7213302752293578, 'ACC': 0.675}\", '\\n', 'Finished in 2.0s; results saved to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_17-49-\n38_gnn_for_spr_attempt_0/0-run/process_ForkProcess-15/working', '\\n', 'Execution\ntime: 5 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\n=== Dataset A_max8_balanced ===', '\\n', 'Ep01:\ntr_loss=0.640 dv_loss=0.623 dv_PCWA=0.677', '\\n', 'Ep02: tr_loss=0.632\ndv_loss=0.618 dv_PCWA=0.677', '\\n', 'Ep03: tr_loss=0.626 dv_loss=0.609\ndv_PCWA=0.677', '\\n', 'Ep04: tr_loss=0.614 dv_loss=0.601 dv_PCWA=0.677', '\\n',\n'Ep05: tr_loss=0.603 dv_loss=0.601 dv_PCWA=0.677', '\\n', 'Test:', ' ', \"{'PCWA':\n0.6904611497157296, 'CWA': 0.6454081632653061, 'SWA': 0.7392676767676768, 'ACC':\n0.6975}\", '\\n', '\\n=== Dataset B_max12_shapeBias ===', '\\n', 'Ep01:\ntr_loss=0.689 dv_loss=0.664 dv_PCWA=0.619', '\\n', 'Ep02: tr_loss=0.650\ndv_loss=0.634 dv_PCWA=0.638', '\\n', 'Ep03: tr_loss=0.627 dv_loss=0.623\ndv_PCWA=0.665', '\\n', 'Ep04: tr_loss=0.620 dv_loss=0.621 dv_PCWA=0.668', '\\n',\n'Ep05: tr_loss=0.608 dv_loss=0.620 dv_PCWA=0.642', '\\n', 'Test:', ' ', \"{'PCWA':\n0.6632928475033738, 'CWA': 0.6698537682789651, 'SWA': 0.6637984019668101, 'ACC':\n0.67}\", '\\n', '\\n=== Dataset C_max20_colorBias ===', '\\n', 'Ep01: tr_loss=0.461\ndv_loss=0.437 dv_PCWA=0.845', '\\n', 'Ep02: tr_loss=0.441 dv_loss=0.427\ndv_PCWA=0.845', '\\n', 'Ep03: tr_loss=0.433 dv_loss=0.416 dv_PCWA=0.845', '\\n',\n'Ep04: tr_loss=0.427 dv_loss=0.408 dv_PCWA=0.845', '\\n', 'Ep05: tr_loss=0.417\ndv_loss=0.401 dv_PCWA=0.842', '\\n', 'Test:', ' ', \"{'PCWA': 0.8533531409168081,\n'CWA': 0.8185792349726776, 'SWA': 0.8709516691579472, 'ACC': 0.8375}\", '\\n',\n'\\nDone in 13.6s. Data saved to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/0-\nrun/process_ForkProcess-20/working', '\\n', 'Execution time: 16 seconds seconds\n(time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating synthetic data.',\n'\\n', \"{'train': 2000, 'dev': 400, 'test': 400}\", '\\n', 'Epoch 1:\ntrain_loss=0.6399 val_loss=0.6113 val_PCWA=0.7086', '\\n', 'Epoch 2:\ntrain_loss=0.6199 val_loss=0.6091 val_PCWA=0.7086', '\\n', 'Epoch 3:\ntrain_loss=0.6193 val_loss=0.6073 val_PCWA=0.7086', '\\n', 'Epoch 4:\ntrain_loss=0.6147 val_loss=0.6055 val_PCWA=0.7086', '\\n', 'Epoch 5:\ntrain_loss=0.6104 val_loss=0.6018 val_PCWA=0.7086', '\\n', 'TEST METRICS:', ' ',\n\"{'PCWA': 0.6595717399666624, 'CWA': 0.6148571428571429, 'SWA':\n0.7040875071963155, 'ACC': 0.6625}\", '\\n', 'Finished in 1.1s; results saved to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_17-49-\n38_gnn_for_spr_attempt_0/0-run/process_ForkProcess-21/working', '\\n', 'Execution\ntime: 4 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found \u2013 generating synthetic\ndata.', '\\n', \"{'train': 2000, 'dev': 400, 'test': 400}\", '\\n', 'Epoch 1:\ntrain_loss=0.6203 val_loss=0.6283 val_PCWA=0.6851', '\\n', 'Epoch 2:\ntrain_loss=0.6133 val_loss=0.6256 val_PCWA=0.6851', '\\n', 'Epoch 3:\ntrain_loss=0.6096 val_loss=0.6254 val_PCWA=0.6851', '\\n', 'Epoch 4:\ntrain_loss=0.6041 val_loss=0.6204 val_PCWA=0.6851', '\\n', 'Epoch 5:\ntrain_loss=0.5954 val_loss=0.6130 val_PCWA=0.6897', '\\n', 'TEST METRICS:', ' ',\n\"{'PCWA': 0.6693343033830483, 'CWA': 0.6215469613259669, 'SWA':\n0.7077702702702703, 'ACC': 0.665}\", '\\n', 'Finished in 1.1s; results saved to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_17-49-\n38_gnn_for_spr_attempt_0/0-run/process_ForkProcess-22/working', '\\n', 'Execution\ntime: 4 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating synthetic data.',\n'\\n', \"{'train': 2000, 'dev': 400, 'test': 400}\", '\\n', 'Epoch 1:\ntrain_loss=0.6424 val_loss=0.5981 val_PCWA=0.7246', '\\n', 'Epoch 2:\ntrain_loss=0.6388 val_loss=0.6007 val_PCWA=0.7246', '\\n', 'Epoch 3:\ntrain_loss=0.6385 val_loss=0.6014 val_PCWA=0.7246', '\\n', 'Epoch 4:\ntrain_loss=0.6383 val_loss=0.6020 val_PCWA=0.7246', '\\n', 'Epoch 5:\ntrain_loss=0.6378 val_loss=0.6030 val_PCWA=0.7246', '\\n', 'TEST METRICS:', ' ',\n\"{'PCWA': 0.7082573586871581, 'CWA': 0.6581691772885284, 'SWA':\n0.7452229299363057, 'ACC': 0.695}\", '\\n', 'Finished in 4.0s. Data saved to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_17-49-\n38_gnn_for_spr_attempt_0/0-run/process_ForkProcess-23/working', '\\n', 'Execution\ntime: 7 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating synthetic data.',\n'\\n', \"{'train': 2000, 'dev': 400, 'test': 400}\", '\\n', 'Epoch 1:\ntrain_loss=0.6182 val_loss=0.6062 val_PCWA=0.7108', '\\n', 'Epoch 2:\ntrain_loss=0.6065 val_loss=0.6020 val_PCWA=0.7108', '\\n', 'Epoch 3:\ntrain_loss=0.6034 val_loss=0.5989 val_PCWA=0.7108', '\\n', 'Epoch 4:\ntrain_loss=0.5979 val_loss=0.5956 val_PCWA=0.7108', '\\n', 'Epoch 5:\ntrain_loss=0.5934 val_loss=0.5931 val_PCWA=0.7108', '\\n', 'TEST METRICS:', ' ',\n\"{'PCWA': 0.6534098151688974, 'CWA': 0.6009122006841505, 'SWA':\n0.6958762886597938, 'ACC': 0.6475}\", '\\n', 'Finished in 2.6s; results saved to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_17-49-\n38_gnn_for_spr_attempt_0/0-run/process_ForkProcess-21/working', '\\n', 'Execution\ntime: 5 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found \u2013 generating synthetic\ndata.', '\\n', \"{'train': 2000, 'dev': 400, 'test': 400}\", '\\n', 'Epoch 1:\ntrain_loss=0.6509 val_loss=0.6207 val_PCWA=0.6734', '\\n', 'Epoch 2:\ntrain_loss=0.6335 val_loss=0.6214 val_PCWA=0.6734', '\\n', 'Epoch 3:\ntrain_loss=0.6323 val_loss=0.6220 val_PCWA=0.6734', '\\n', 'Epoch 4:\ntrain_loss=0.6313 val_loss=0.6219 val_PCWA=0.6734', '\\n', 'Epoch 5:\ntrain_loss=0.6309 val_loss=0.6221 val_PCWA=0.6734', '\\n', 'TEST METRICS:', ' ',\n\"{'PCWA': 0.6516438862209087, 'ACC': 0.655}\", '\\n', 'Finished in 1.1s; results\nsaved to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_17-49-\n38_gnn_for_spr_attempt_0/0-run/process_ForkProcess-22/working', '\\n', 'Execution\ntime: 4 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating synthetic data.',\n'\\n', \"{'train': 2000, 'dev': 400, 'test': 400}\", '\\n', 'Epoch 1:\ntrain_loss=0.6217 val_loss=0.6324 val_PCWA=0.6622', '\\n', 'Epoch 2:\ntrain_loss=0.6151 val_loss=0.6354 val_PCWA=0.6622', '\\n', 'Epoch 3:\ntrain_loss=0.6131 val_loss=0.6330 val_PCWA=0.6622', '\\n', 'Epoch 4:\ntrain_loss=0.6120 val_loss=0.6353 val_PCWA=0.6622', '\\n', 'Epoch 5:\ntrain_loss=0.6109 val_loss=0.6376 val_PCWA=0.6622', '\\n', 'TEST METRICS:', ' ',\n\"{'PCWA': 0.6761645193260654, 'CWA': 0.6721497447532615, 'SWA':\n0.6758272574312956, 'ACC': 0.67}\", '\\n', 'Finished in 1.1s; results saved to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_17-49-\n38_gnn_for_spr_attempt_0/0-run/process_ForkProcess-23/working', '\\n', 'Execution\ntime: 4 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating synthetic data.',\n'\\n', \"{'train': 2000, 'dev': 400, 'test': 400}\", '\\n', 'Epoch 1:\ntrain_loss=0.6177 val_loss=0.6112 val_PCWA=0.7189', '\\n', 'Epoch 2:\ntrain_loss=0.6141 val_loss=0.6105 val_PCWA=0.7189', '\\n', 'Epoch 3:\ntrain_loss=0.6117 val_loss=0.6101 val_PCWA=0.7189', '\\n', 'Epoch 4:\ntrain_loss=0.6159 val_loss=0.6113 val_PCWA=0.7189', '\\n', 'Epoch 5:\ntrain_loss=0.6110 val_loss=0.6121 val_PCWA=0.7189', '\\n', 'TEST METRICS:', ' ',\n\"{'PCWA': 0.716995544239338, 'CWA': 0.6630057803468208, 'SWA':\n0.7507114399544679, 'ACC': 0.7025}\", '\\n', 'Finished in 2.9s; results saved to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-30_17-49-\n38_gnn_for_spr_attempt_0/0-run/process_ForkProcess-20/working', '\\n', 'Execution\ntime: 6 seconds seconds (time limit is 30 minutes).']"], "analysis": ["", "", "", "", "", "", "", "", ""], "exc_type": [null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Represents the loss during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR", "final_value": 0.6057, "best_value": 0.6057}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Represents the loss during validation. Lower values indicate better performance.", "data": [{"dataset_name": "SPR", "final_value": 0.601, "best_value": 0.601}]}, {"metric_name": "training PCWA", "lower_is_better": false, "description": "Represents the training PCWA metric. Higher values indicate better performance.", "data": [{"dataset_name": "SPR", "final_value": 0.6966, "best_value": 0.6966}]}, {"metric_name": "validation PCWA", "lower_is_better": false, "description": "Represents the validation PCWA metric. Higher values indicate better performance.", "data": [{"dataset_name": "SPR", "final_value": 0.6968, "best_value": 0.6968}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Represents the accuracy on the test set. Higher values indicate better performance.", "data": [{"dataset_name": "SPR", "final_value": 0.675, "best_value": 0.675}]}]}, {"metric_names": [{"metric_name": "PCWA", "lower_is_better": false, "description": "Piece-wise Constant Weighted Accuracy", "data": [{"dataset_name": "A_max8_balanced", "final_value": 0.69, "best_value": 0.69}, {"dataset_name": "B_max12_shapeBias", "final_value": 0.663, "best_value": 0.67}, {"dataset_name": "C_max20_colorBias", "final_value": 0.853, "best_value": 0.853}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss value indicating the error or deviation from the target output", "data": [{"dataset_name": "A_max8_balanced", "final_value": 0.601, "best_value": 0.601}, {"dataset_name": "B_max12_shapeBias", "final_value": 0.62, "best_value": 0.608}, {"dataset_name": "C_max20_colorBias", "final_value": 0.401, "best_value": 0.401}]}, {"metric_name": "CWA", "lower_is_better": false, "description": "Constant Weighted Accuracy", "data": [{"dataset_name": "A_max8_balanced", "final_value": 0.645, "best_value": 0.645}, {"dataset_name": "B_max12_shapeBias", "final_value": 0.67, "best_value": 0.67}, {"dataset_name": "C_max20_colorBias", "final_value": 0.819, "best_value": 0.819}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "Smoothed Weighted Accuracy", "data": [{"dataset_name": "A_max8_balanced", "final_value": 0.739, "best_value": 0.739}, {"dataset_name": "B_max12_shapeBias", "final_value": 0.664, "best_value": 0.664}, {"dataset_name": "C_max20_colorBias", "final_value": 0.871, "best_value": 0.871}]}, {"metric_name": "ACC", "lower_is_better": false, "description": "Accuracy", "data": [{"dataset_name": "A_max8_balanced", "final_value": 0.698, "best_value": 0.698}, {"dataset_name": "B_max12_shapeBias", "final_value": 0.67, "best_value": 0.67}, {"dataset_name": "C_max20_colorBias", "final_value": 0.838, "best_value": 0.838}]}]}, {"metric_names": [{"metric_name": "PCWA", "lower_is_better": false, "description": "Piecewise Constant Weighted Average, a metric for evaluating performance.", "data": [{"dataset_name": "Training dataset", "final_value": 0.6992, "best_value": 0.6992}, {"dataset_name": "Validation dataset", "final_value": 0.7086, "best_value": 0.7086}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss measures the prediction error of the model.", "data": [{"dataset_name": "Training dataset", "final_value": 0.6104, "best_value": 0.6104}, {"dataset_name": "Validation dataset", "final_value": 0.6018, "best_value": 0.6018}]}, {"metric_name": "accuracy", "lower_is_better": false, "description": "Accuracy measures the proportion of correct predictions made by the model.", "data": [{"dataset_name": "Test dataset", "final_value": 0.6625, "best_value": 0.6625}]}]}, {"metric_names": [{"metric_name": "PCWA", "lower_is_better": false, "description": "Percentage-wise accuracy metric.", "data": [{"dataset_name": "SPR", "final_value": 0.6897, "best_value": 0.7003}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Loss metric indicating model error.", "data": [{"dataset_name": "SPR", "final_value": 0.613, "best_value": 0.5954}]}, {"metric_name": "accuracy", "lower_is_better": false, "description": "Accuracy metric for model performance.", "data": [{"dataset_name": "SPR", "final_value": 0.665, "best_value": 0.665}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Measures the loss during training.", "data": [{"dataset_name": "SPR", "final_value": 0.6378, "best_value": 0.6378}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the loss on the validation set.", "data": [{"dataset_name": "SPR", "final_value": 0.5981, "best_value": 0.5981}]}, {"metric_name": "train PCWA", "lower_is_better": false, "description": "Measures the PCWA during training.", "data": [{"dataset_name": "SPR", "final_value": 0.6637, "best_value": 0.6637}]}, {"metric_name": "validation PCWA", "lower_is_better": false, "description": "Measures the PCWA on the validation set.", "data": [{"dataset_name": "SPR", "final_value": 0.7246, "best_value": 0.7246}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Measures the accuracy on the test set.", "data": [{"dataset_name": "SPR", "final_value": 0.695, "best_value": 0.695}]}]}, {"metric_names": [{"metric_name": "Training loss", "lower_is_better": true, "description": "Measures how well the model is performing on the training dataset. Lower is better.", "data": [{"dataset_name": "Training", "final_value": 0.5934, "best_value": 0.5934}]}, {"metric_name": "Training PCWA", "lower_is_better": false, "description": "Measures the PCWA metric on the training dataset. Higher is better.", "data": [{"dataset_name": "Training", "final_value": 0.7089, "best_value": 0.7089}]}, {"metric_name": "Validation loss", "lower_is_better": true, "description": "Measures how well the model is performing on the validation dataset. Lower is better.", "data": [{"dataset_name": "Validation", "final_value": 0.5931, "best_value": 0.5931}]}, {"metric_name": "Validation PCWA", "lower_is_better": false, "description": "Measures the PCWA metric on the validation dataset. Higher is better.", "data": [{"dataset_name": "Validation", "final_value": 0.7108, "best_value": 0.7108}]}, {"metric_name": "Test accuracy", "lower_is_better": false, "description": "Measures the accuracy of the model on the test dataset. Higher is better.", "data": [{"dataset_name": "Test", "final_value": 0.6475, "best_value": 0.6475}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Loss during training phase", "data": [{"dataset_name": "TRAIN DATASET", "final_value": 0.6309, "best_value": 0.6309}]}, {"metric_name": "training PCWA", "lower_is_better": false, "description": "PCWA during training phase", "data": [{"dataset_name": "TRAIN DATASET", "final_value": 0.6717, "best_value": 0.6717}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss during validation phase", "data": [{"dataset_name": "VALIDATION DATASET", "final_value": 0.6207, "best_value": 0.6207}]}, {"metric_name": "validation PCWA", "lower_is_better": false, "description": "PCWA during validation phase", "data": [{"dataset_name": "VALIDATION DATASET", "final_value": 0.6734, "best_value": 0.6734}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Accuracy on test data", "data": [{"dataset_name": "TEST DATASET", "final_value": 0.655, "best_value": 0.655}]}]}, {"metric_names": [{"metric_name": "Loss", "lower_is_better": true, "description": "Measures the error or difference between predicted and actual values.", "data": [{"dataset_name": "Training dataset", "final_value": 0.6109, "best_value": 0.6109}, {"dataset_name": "Validation dataset", "final_value": 0.6376, "best_value": 0.6324}]}, {"metric_name": "PCWA", "lower_is_better": false, "description": "Measures the performance of the model in terms of weighted accuracy.", "data": [{"dataset_name": "Training dataset", "final_value": 0.6928, "best_value": 0.6928}, {"dataset_name": "Validation dataset", "final_value": 0.6622, "best_value": 0.6622}]}, {"metric_name": "Accuracy", "lower_is_better": false, "description": "Measures the proportion of correctly predicted instances out of the total instances.", "data": [{"dataset_name": "Test dataset", "final_value": 0.67, "best_value": 0.67}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated on the training dataset during the final epoch.", "data": [{"dataset_name": "SPR", "final_value": 0.611, "best_value": 0.611}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset during the final epoch.", "data": [{"dataset_name": "SPR", "final_value": 0.6121, "best_value": 0.6121}]}, {"metric_name": "training PCWA", "lower_is_better": false, "description": "The PCWA metric calculated on the training dataset during the final epoch.", "data": [{"dataset_name": "SPR", "final_value": 0.7076, "best_value": 0.7076}]}, {"metric_name": "validation PCWA", "lower_is_better": false, "description": "The PCWA metric calculated on the validation dataset during the final epoch.", "data": [{"dataset_name": "SPR", "final_value": 0.7189, "best_value": 0.7189}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "The accuracy metric calculated on the test dataset.", "data": [{"dataset_name": "SPR", "final_value": 0.7025, "best_value": 0.7025}]}]}], "is_best_node": [false, false, false, false, true, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_5a3f20adaaba448dad224382945a23b2_proc_1448865/SPR_loss_curves.png", "../../logs/0-run/experiment_results/experiment_5a3f20adaaba448dad224382945a23b2_proc_1448865/SPR_pcwa_curves.png"], ["../../logs/0-run/experiment_results/experiment_0ac3789fa99344af8d3d48e51d9a9f36_proc_1451826/multi_dataset_loss_curves.png", "../../logs/0-run/experiment_results/experiment_0ac3789fa99344af8d3d48e51d9a9f36_proc_1451826/multi_dataset_pcwa_curves.png", "../../logs/0-run/experiment_results/experiment_0ac3789fa99344af8d3d48e51d9a9f36_proc_1451826/final_test_metrics_summary.png"], ["../../logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_loss_curve_positional_feature_removal.png", "../../logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_pcwa_curve_positional_feature_removal.png", "../../logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_confusion_matrix_positional_feature_removal.png", "../../logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_test_metrics_bar_positional_feature_removal.png"], ["../../logs/0-run/experiment_results/experiment_3ca5429c122545ce8a08ef741bf1f13f_proc_1451828/SPR_loss_curve_no_color_feature.png", "../../logs/0-run/experiment_results/experiment_3ca5429c122545ce8a08ef741bf1f13f_proc_1451828/SPR_pcwa_curve_no_color_feature.png", "../../logs/0-run/experiment_results/experiment_3ca5429c122545ce8a08ef741bf1f13f_proc_1451828/SPR_conf_mat_no_color_feature.png"], ["../../logs/0-run/experiment_results/experiment_f393ca3880624f1e9f351640cc4107c5_proc_1451829/NoEdges_SPR_loss_curve.png", "../../logs/0-run/experiment_results/experiment_f393ca3880624f1e9f351640cc4107c5_proc_1451829/NoEdges_SPR_pcwa_curve.png", "../../logs/0-run/experiment_results/experiment_f393ca3880624f1e9f351640cc4107c5_proc_1451829/NoEdges_SPR_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_40aabbd60fb8441b848566264032011b_proc_1451827/ShapeRemoval_SPR_loss_curve.png", "../../logs/0-run/experiment_results/experiment_40aabbd60fb8441b848566264032011b_proc_1451827/ShapeRemoval_SPR_PCWA_curve.png", "../../logs/0-run/experiment_results/experiment_40aabbd60fb8441b848566264032011b_proc_1451827/ShapeRemoval_SPR_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_cae2d0f63eb5436a859cc4246c02e1a8_proc_1451828/SPR_loss_curves.png", "../../logs/0-run/experiment_results/experiment_cae2d0f63eb5436a859cc4246c02e1a8_proc_1451828/SPR_PCWA_curves.png", "../../logs/0-run/experiment_results/experiment_cae2d0f63eb5436a859cc4246c02e1a8_proc_1451828/SPR_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_8117350da8c94feeb48afe81aa090d20_proc_1451829/unichain_spr_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8117350da8c94feeb48afe81aa090d20_proc_1451829/unichain_spr_pcwa_curves.png", "../../logs/0-run/experiment_results/experiment_8117350da8c94feeb48afe81aa090d20_proc_1451829/unichain_spr_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_9a6b8146249a422dae760d5059a4a8f3_proc_1451826/SPR_loss_curves.png", "../../logs/0-run/experiment_results/experiment_9a6b8146249a422dae760d5059a4a8f3_proc_1451826/SPR_pcwa_curves.png", "../../logs/0-run/experiment_results/experiment_9a6b8146249a422dae760d5059a4a8f3_proc_1451826/SPR_confusion_matrix.png"]], "plot_paths": [["experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5a3f20adaaba448dad224382945a23b2_proc_1448865/SPR_loss_curves.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5a3f20adaaba448dad224382945a23b2_proc_1448865/SPR_pcwa_curves.png"], ["experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0ac3789fa99344af8d3d48e51d9a9f36_proc_1451826/multi_dataset_loss_curves.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0ac3789fa99344af8d3d48e51d9a9f36_proc_1451826/multi_dataset_pcwa_curves.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0ac3789fa99344af8d3d48e51d9a9f36_proc_1451826/final_test_metrics_summary.png"], ["experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_loss_curve_positional_feature_removal.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_pcwa_curve_positional_feature_removal.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_confusion_matrix_positional_feature_removal.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_test_metrics_bar_positional_feature_removal.png"], ["experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3ca5429c122545ce8a08ef741bf1f13f_proc_1451828/SPR_loss_curve_no_color_feature.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3ca5429c122545ce8a08ef741bf1f13f_proc_1451828/SPR_pcwa_curve_no_color_feature.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3ca5429c122545ce8a08ef741bf1f13f_proc_1451828/SPR_conf_mat_no_color_feature.png"], ["experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f393ca3880624f1e9f351640cc4107c5_proc_1451829/NoEdges_SPR_loss_curve.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f393ca3880624f1e9f351640cc4107c5_proc_1451829/NoEdges_SPR_pcwa_curve.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f393ca3880624f1e9f351640cc4107c5_proc_1451829/NoEdges_SPR_confusion_matrix.png"], ["experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_40aabbd60fb8441b848566264032011b_proc_1451827/ShapeRemoval_SPR_loss_curve.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_40aabbd60fb8441b848566264032011b_proc_1451827/ShapeRemoval_SPR_PCWA_curve.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_40aabbd60fb8441b848566264032011b_proc_1451827/ShapeRemoval_SPR_confusion_matrix.png"], ["experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cae2d0f63eb5436a859cc4246c02e1a8_proc_1451828/SPR_loss_curves.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cae2d0f63eb5436a859cc4246c02e1a8_proc_1451828/SPR_PCWA_curves.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cae2d0f63eb5436a859cc4246c02e1a8_proc_1451828/SPR_confusion_matrix.png"], ["experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8117350da8c94feeb48afe81aa090d20_proc_1451829/unichain_spr_loss_curves.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8117350da8c94feeb48afe81aa090d20_proc_1451829/unichain_spr_pcwa_curves.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8117350da8c94feeb48afe81aa090d20_proc_1451829/unichain_spr_confusion_matrix.png"], ["experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9a6b8146249a422dae760d5059a4a8f3_proc_1451826/SPR_loss_curves.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9a6b8146249a422dae760d5059a4a8f3_proc_1451826/SPR_pcwa_curves.png", "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9a6b8146249a422dae760d5059a4a8f3_proc_1451826/SPR_confusion_matrix.png"]], "plot_analyses": [[{"analysis": "The plot shows the training and validation loss over five epochs. The training loss steadily decreases, indicating that the model is learning from the training data. However, the validation loss decreases initially but then plateaus and slightly increases at the last epoch. This behavior suggests potential overfitting, as the model's performance on unseen data (validation set) starts to degrade while continuing to improve on the training set. This could be addressed by using regularization techniques, early stopping, or data augmentation to improve generalization.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5a3f20adaaba448dad224382945a23b2_proc_1448865/SPR_loss_curves.png"}, {"analysis": "The plot illustrates the progression of PCWA (Presumably Color-Weighted Accuracy) for both training and validation over five epochs. The training accuracy remains relatively stable, while the validation accuracy shows a sudden spike at the final epoch. This could indicate that the model only starts to generalize well at the last stage, possibly due to delayed convergence or an abrupt learning transition. However, the stability prior to the spike and the sudden jump warrant further investigation. It might be beneficial to explore adjustments in the learning rate schedule or model initialization to achieve more consistent improvements across epochs.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_5a3f20adaaba448dad224382945a23b2_proc_1448865/SPR_pcwa_curves.png"}], [{"analysis": "This plot shows the training and validation loss across epochs for three datasets (A_max8_balanced, B_max12_shapeBias, and C_max20_colorBias). The training loss consistently decreases for all datasets, indicating that the model is learning effectively. However, the validation loss for B_max12_shapeBias and C_max20_colorBias does not decrease as much, suggesting potential overfitting or challenges in generalizing to the validation data. The A_max8_balanced dataset exhibits a more stable validation loss, reflecting better generalization. The gap between training and validation loss is smallest for A_max8_balanced, indicating that the model generalizes better on this dataset compared to the others.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0ac3789fa99344af8d3d48e51d9a9f36_proc_1451826/multi_dataset_loss_curves.png"}, {"analysis": "This plot presents the Per-Class Weighted Accuracy (PCWA) for training and validation across epochs for the same datasets. The PCWA for the C_max20_colorBias dataset is significantly higher and stable compared to the other datasets, reflecting the model's strength in handling color-biased data. In contrast, the B_max12_shapeBias dataset shows a noticeable increase in PCWA during training but struggles to maintain high validation PCWA, suggesting overfitting. The A_max8_balanced dataset maintains a consistent PCWA for both training and validation, demonstrating its balanced nature and the model's ability to generalize well on this dataset.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0ac3789fa99344af8d3d48e51d9a9f36_proc_1451826/multi_dataset_pcwa_curves.png"}, {"analysis": "This bar chart summarizes the final test metrics (Accuracy, PCWA, CWA, and SWA) for the three datasets. The C_max20_colorBias dataset achieves the highest scores across all metrics, indicating that the model performs best when color information is the dominant feature. The A_max8_balanced dataset shows slightly lower but consistent scores across metrics, reflecting its balanced nature. The B_max12_shapeBias dataset has the lowest scores, particularly in CWA and SWA, suggesting that the model struggles with datasets where shape information is more critical. These results highlight the model's varying performance based on dataset characteristics, with a clear strength in handling color-biased data.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_0ac3789fa99344af8d3d48e51d9a9f36_proc_1451826/final_test_metrics_summary.png"}], [{"analysis": "The loss curve shows a consistent decrease in both training and validation loss over the epochs, indicating that the model is learning effectively. However, the gap between the training and validation loss suggests potential overfitting, as the validation loss is consistently higher than the training loss.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_loss_curve_positional_feature_removal.png"}, {"analysis": "The PCWA curve demonstrates that the training performance improves rapidly within the first two epochs and then plateaus. The validation performance remains constant throughout, suggesting that the removal of positional features may have limited the model's ability to generalize effectively.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_pcwa_curve_positional_feature_removal.png"}, {"analysis": "The confusion matrix shows that all true positive instances are correctly classified, while there is a notable misclassification of the negative class. This suggests a bias in the model towards predicting the positive class, which needs to be addressed for balanced performance.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_confusion_matrix_positional_feature_removal.png"}, {"analysis": "The test metrics bar chart reveals that accuracy (ACC) is the only metric reported, with no values provided for PCWA, CWA, or SWA. This limits the ability to fully assess the model's performance on the test set, particularly in terms of its ability to handle the weighted metrics that are central to the SPR task.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_7b452c890ea64faeb86bec2c32a7732d_proc_1451827/SPR_test_metrics_bar_positional_feature_removal.png"}], [{"analysis": "The loss curve indicates a steady decrease in both training and validation loss over the epochs, suggesting that the model is learning and improving its predictions. However, the validation loss remains consistently higher than the training loss, which may indicate some level of overfitting or that the model struggles to generalize well to the validation data. This could be due to the removal of the color feature, which might play a significant role in capturing the underlying patterns in the data.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3ca5429c122545ce8a08ef741bf1f13f_proc_1451828/SPR_loss_curve_no_color_feature.png"}, {"analysis": "The PCWA (Presumably Color-Weighted Accuracy) curve shows a stable performance for the training set, with minimal improvement over the epochs. For the validation set, there is a noticeable increase in PCWA after the fourth epoch, indicating some delayed improvement in generalization. However, the validation accuracy remains significantly lower than the training accuracy, further highlighting potential generalization issues or the importance of the color feature for achieving higher performance.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3ca5429c122545ce8a08ef741bf1f13f_proc_1451828/SPR_pcwa_curve_no_color_feature.png"}, {"analysis": "The confusion matrix shows that the model has a high number of false positives (134) compared to true positives (5) in one of the classes, while achieving a perfect true positive rate in the other class (261). This imbalance suggests that the model is heavily biased towards one class, potentially due to the absence of the color feature, which might have been critical for distinguishing between the classes. The overall accuracy of 0.665 reflects this imbalance and indicates room for improvement.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_3ca5429c122545ce8a08ef741bf1f13f_proc_1451828/SPR_conf_mat_no_color_feature.png"}], [{"analysis": "The loss plot shows that the training loss decreases gradually over the epochs, indicating that the model is learning from the training data. However, the validation loss increases slightly over time, suggesting potential overfitting. This behavior implies that the model may not generalize well to unseen data, and adjustments such as regularization or early stopping might be necessary.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f393ca3880624f1e9f351640cc4107c5_proc_1451829/NoEdges_SPR_loss_curve.png"}, {"analysis": "The PCWA (Presumably Color-Weighted Accuracy) plot remains constant for both training and validation sets over all epochs. This indicates that the model is not improving in terms of accuracy on this metric, despite changes in the loss values. This could suggest that the model is not effectively capturing the features relevant to PCWA, and further investigation into feature representation or model architecture might be needed.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f393ca3880624f1e9f351640cc4107c5_proc_1451829/NoEdges_SPR_pcwa_curve.png"}, {"analysis": "The confusion matrix reveals that the model predicts only one class, leading to a complete failure in distinguishing between the two true classes. This suggests a severe issue with class imbalance, model initialization, or loss function design. Addressing this problem may involve rebalancing the dataset, modifying the loss function, or adjusting the model's architecture to better capture the distinctions between classes.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_f393ca3880624f1e9f351640cc4107c5_proc_1451829/NoEdges_SPR_confusion_matrix.png"}], [{"analysis": "This plot shows the training and validation loss over 5 epochs for the ShapeRemoval-SPR task. Both training and validation loss decrease consistently, which is a positive indicator of convergence. The gap between training and validation loss is small, suggesting that the model is generalizing well without overfitting. The consistent decline in validation loss indicates that the model's performance is improving on unseen data.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_40aabbd60fb8441b848566264032011b_proc_1451827/ShapeRemoval_SPR_loss_curve.png"}, {"analysis": "This plot depicts the training and validation PCWA scores over 5 epochs. The validation PCWA remains constant at approximately 0.71075, while the training PCWA is slightly lower at around 0.709. The lack of improvement in PCWA over epochs suggests that the model's ability to leverage color-weighted accuracy is stagnating, potentially due to insufficient learning of color-related features or limitations in the model's architecture for this aspect of the task.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_40aabbd60fb8441b848566264032011b_proc_1451827/ShapeRemoval_SPR_PCWA_curve.png"}, {"analysis": "The confusion matrix for the ShapeRemoval-SPR task indicates that all true negatives (class 0) are misclassified as false positives (class 1), while all true positives (class 1) are correctly classified. This imbalance in classification performance suggests that the model is biased toward predicting class 1, potentially due to class imbalance in the training data or an issue with the loss function or class weighting.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_40aabbd60fb8441b848566264032011b_proc_1451827/ShapeRemoval_SPR_confusion_matrix.png"}], [{"analysis": "This plot shows the cross-entropy loss for both training and validation datasets over five epochs. The training loss decreases steadily, indicating that the model is learning effectively. However, the validation loss remains relatively flat, suggesting potential underfitting or a lack of generalization. The gap between training and validation loss is minimal, which could imply that the model is not overfitting but may require additional capacity or training time to improve performance on the validation set.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cae2d0f63eb5436a859cc4246c02e1a8_proc_1451828/SPR_loss_curves.png"}, {"analysis": "This plot displays the progression of PCWA (presumably a weighted accuracy metric) for training and validation over five epochs. The training PCWA increases rapidly in the first two epochs and then stabilizes, demonstrating effective learning. The validation PCWA remains constant throughout, which could indicate that the model is not improving its performance on unseen data. This stagnation might suggest a need for better hyperparameter tuning, regularization, or adjustments to the model architecture.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cae2d0f63eb5436a859cc4246c02e1a8_proc_1451828/SPR_PCWA_curves.png"}, {"analysis": "The confusion matrix indicates that the model is predicting only one class (class 1) for all inputs, as evidenced by the absence of true positives for class 0 and all predictions being concentrated in class 1. This suggests a strong class imbalance in the dataset or a model bias towards class 1. Addressing this issue may involve rebalancing the dataset, using loss weighting, or modifying the training process to handle imbalanced data more effectively.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_cae2d0f63eb5436a859cc4246c02e1a8_proc_1451828/SPR_confusion_matrix.png"}], [{"analysis": "This plot shows the loss curves for the training and validation datasets. The training loss consistently decreases over the epochs, indicating that the model is learning from the training data. However, the validation loss increases slightly, suggesting potential overfitting. This discrepancy between training and validation loss warrants further investigation, such as implementing regularization techniques or early stopping to improve generalization.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8117350da8c94feeb48afe81aa090d20_proc_1451829/unichain_spr_loss_curves.png"}, {"analysis": "This plot depicts the PCWA (Presumably Color-Weighted Accuracy) curves for training and validation datasets. The training PCWA remains constant throughout the epochs, while the validation PCWA is significantly lower and also constant. This lack of improvement in both metrics indicates that the model may not be effectively learning the task or capturing the relevant features. Revisiting the model architecture or hyperparameter tuning might be necessary.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8117350da8c94feeb48afe81aa090d20_proc_1451829/unichain_spr_pcwa_curves.png"}, {"analysis": "The confusion matrix for the test set shows that the model predicts only one class (class 1) for all instances, leading to no true negatives and false negatives. This indicates a severe issue with class imbalance or a biased model. Steps like rebalancing the dataset, using weighted loss functions, or modifying the training process to handle class imbalance should be considered.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_8117350da8c94feeb48afe81aa090d20_proc_1451829/unichain_spr_confusion_matrix.png"}], [{"analysis": "The loss curves indicate that the training loss decreases initially but then increases slightly before decreasing again. This suggests that the model may be experiencing some instability during training. The validation loss, on the other hand, shows a slight upward trend after an initial dip, which could be an indication of overfitting. Further regularization or early stopping may help address this issue.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9a6b8146249a422dae760d5059a4a8f3_proc_1451826/SPR_loss_curves.png"}, {"analysis": "The PCWA metric curves show that the training performance improves slightly before plateauing. The validation performance remains constant throughout, which may indicate that the model is not generalizing well to unseen data. This could be due to insufficient model capacity or a need for better hyperparameter tuning.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9a6b8146249a422dae760d5059a4a8f3_proc_1451826/SPR_pcwa_curves.png"}, {"analysis": "The confusion matrix shows that the model is heavily biased towards predicting one class (True 1). This imbalance in predictions suggests that the model may not be learning the underlying patterns effectively and instead relies on a default prediction strategy. Addressing this may require rebalancing the dataset, adjusting the loss function, or incorporating techniques to handle class imbalance.", "plot_path": "experiments/2025-08-30_17-49-38_gnn_for_spr_attempt_0/logs/0-run/experiment_results/experiment_9a6b8146249a422dae760d5059a4a8f3_proc_1451826/SPR_confusion_matrix.png"}]], "vlm_feedback_summary": ["The plots suggest that while the model is learning from the training data, there\nare signs of overfitting and delayed generalization. Improvements in\nregularization, learning rate schedules, and possibly data augmentation could\nenhance performance and consistency.", "The plots provide insights into the model's performance on different datasets,\nhighlighting strengths in handling color-biased data and challenges with shape-\nbiased data. The A_max8_balanced dataset shows better generalization and\nconsistent performance, while B_max12_shapeBias exhibits overfitting tendencies.\nThe final test metrics reinforce these observations, with the model performing\nbest on C_max20_colorBias and struggling on B_max12_shapeBias.", "The analysis reveals that while the model demonstrates learning capability,\nthere are signs of overfitting and class imbalance. The absence of key metrics\n(PCWA, CWA, SWA) in the test results hinders a comprehensive evaluation.", "The analysis reveals that the removal of the color feature has a notable impact\non the model's performance, particularly in terms of generalization and class\nbalance. The loss and PCWA curves show a gap between training and validation\nperformance, and the confusion matrix highlights class imbalance in predictions.\nThis suggests that the color feature is likely crucial for achieving optimal\nperformance in the SPR task.", "The plots indicate potential issues with generalization, feature representation,\nand class imbalance. The loss plot shows signs of overfitting, the PCWA plot\nindicates no improvement in accuracy, and the confusion matrix reveals a failure\nto distinguish between classes.", "The plots provide insights into the model's performance on the ShapeRemoval-SPR\ntask. Training and validation loss decrease consistently, indicating good\nconvergence. However, the PCWA metric shows stagnation, suggesting limitations\nin the model's ability to learn color-related features. The confusion matrix\nreveals a strong bias toward predicting one class, highlighting potential issues\nwith class balance or model configuration.", "The plots reveal that the model is learning but faces challenges in\ngeneralization and class imbalance. The training metrics improve, but validation\nmetrics remain stagnant, and the confusion matrix highlights a severe class\nprediction bias. These issues suggest the need for further optimization of the\nmodel architecture, training strategy, and handling of class imbalance.", "The provided plots reveal issues with overfitting, lack of learning progress,\nand a biased model output. These observations suggest the need for architectural\nadjustments, regularization, and strategies to address class imbalance.", "The results suggest potential overfitting and class imbalance issues. The loss\ncurves show some instability and possible overfitting, while the PCWA metric\nindicates limited generalization. The confusion matrix reveals a strong\nprediction bias, likely due to class imbalance."], "exec_time": [5.038602828979492, 16.054646968841553, 4.157518625259399, 4.335557699203491, 7.31136679649353, 5.720230579376221, 4.348716974258423, 4.222958564758301, 6.322167158126831], "exec_time_feedback": ["", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["['SPR']"], ["['A_max8_balanced'", "'C_max20_colorBias']"], ["[]"], ["[]"], ["[]"], ["[]"], ["[]"], ["[]"], ["[]"]], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# ------------------------------------------------------------------ #\n# Helper metrics (duplicated here to avoid extra imports)            #\n# ------------------------------------------------------------------ #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef pcwa(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    corr = [w_i if yt == yp else 0 for w_i, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# ------------------------------------------------------------------ #\n# Load experiment data                                               #\n# ------------------------------------------------------------------ #\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nspr = experiment_data.get(\"SPR\", {})\nloss_train = [v for _, v in spr.get(\"losses\", {}).get(\"train\", [])]\nloss_val = [v for _, v in spr.get(\"losses\", {}).get(\"val\", [])]\npcwa_train = [v for _, v in spr.get(\"metrics\", {}).get(\"train\", [])]\npcwa_val = [v for _, v in spr.get(\"metrics\", {}).get(\"val\", [])]\nepochs = np.arange(1, len(loss_train) + 1)\n\n# ------------------------------------------------------------------ #\n# 1) Loss curves                                                     #\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure(figsize=(7, 4))\n    plt.plot(epochs, loss_train, \"--o\", label=\"Train\")\n    plt.plot(epochs, loss_val, \"-s\", label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"Training vs Validation Loss \u2013 SPR dataset\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 2) PCWA curves                                                     #\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure(figsize=(7, 4))\n    plt.plot(epochs, pcwa_train, \"--o\", label=\"Train\")\n    plt.plot(epochs, pcwa_val, \"-s\", label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"PCWA\")\n    plt.title(\"Training vs Validation PCWA \u2013 SPR dataset\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_pcwa_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating PCWA curves plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 3) Final test-set bar chart                                        #\n# ------------------------------------------------------------------ #\ntry:\n    seqs = spr.get(\"sequences\", spr.get(\"ground_truth\", []))  # fallback\n    y_true = spr.get(\"ground_truth\", [])\n    y_pred = spr.get(\"predictions\", [])\n    if seqs and y_true and y_pred:\n        acc = sum(int(y == p) for y, p in zip(y_true, y_pred)) / len(y_true)\n        pc = pcwa(seqs, y_true, y_pred)\n        cwa_num = sum(\n            count_color_variety(s) if y == p else 0\n            for s, y, p in zip(seqs, y_true, y_pred)\n        )\n        cwa_den = sum(count_color_variety(s) for s in seqs)\n        swa_num = sum(\n            count_shape_variety(s) if y == p else 0\n            for s, y, p in zip(seqs, y_true, y_pred)\n        )\n        swa_den = sum(count_shape_variety(s) for s in seqs)\n        cwa = cwa_num / cwa_den if cwa_den else 0.0\n        swa = swa_num / swa_den if swa_den else 0.0\n\n        metrics = {\"ACC\": acc, \"PCWA\": pc, \"CWA\": cwa, \"SWA\": swa}\n        plt.figure(figsize=(6, 4))\n        plt.bar(metrics.keys(), metrics.values(), color=\"skyblue\")\n        plt.title(\"Final Test-set Metrics \u2013 SPR dataset\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_final_metrics_bar.png\"))\n        plt.close()\n        print(\"Final test metrics:\", metrics)\n    else:\n        print(\"Predictions / ground-truth not found; skipping final bar chart.\")\nexcept Exception as e:\n    print(f\"Error creating final metrics bar plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    records = experiment_data[\"multi_dataset_generalization\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    records = {}\n\n\n# ---------------------------------------------------------------------\n# Helper to extract curves\ndef extract_curve(rec, key):\n    # returns epochs, train_vals, val_vals\n    tr = rec[\"losses\" if key == \"loss\" else \"metrics\"][\n        \"train\" if key in [\"loss\", \"PCWA\"] else \"\"\n    ]\n    vl = rec[\"losses\" if key == \"loss\" else \"metrics\"][\n        \"val\" if key in [\"loss\", \"PCWA\"] else \"\"\n    ]\n    epochs = [e for e, _ in tr]\n    tr_vals = [v for _, v in tr]\n    vl_vals = [v for _, v in vl]\n    return epochs, tr_vals, vl_vals\n\n\n# ---------------------------------------------------------------------\n# 1) Loss curves\ntry:\n    plt.figure()\n    for name, rec in records.items():\n        ep, tr, vl = extract_curve(rec, \"loss\")\n        plt.plot(ep, tr, label=f\"{name}-train\")\n        plt.plot(ep, vl, linestyle=\"--\", label=f\"{name}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"Training vs Validation Loss (All Datasets)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"multi_dataset_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 2) PCWA curves\ntry:\n    plt.figure()\n    for name, rec in records.items():\n        ep = [e for e, _ in rec[\"metrics\"][\"train\"]]\n        tr = [v for _, v in rec[\"metrics\"][\"train\"]]\n        vl = [v for _, v in rec[\"metrics\"][\"val\"]]\n        plt.plot(ep, tr, label=f\"{name}-train\")\n        plt.plot(ep, vl, linestyle=\"--\", label=f\"{name}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"PCWA\")\n    plt.title(\"Training vs Validation PCWA (All Datasets)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"multi_dataset_pcwa_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating PCWA plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 3) Final test metric summary\ntry:\n    metrics_names = [\"ACC\", \"PCWA\", \"CWA\", \"SWA\"]\n    datasets = list(records.keys())\n    bar_width = 0.18\n    x = np.arange(len(datasets))\n    plt.figure(figsize=(8, 4))\n    for i, m in enumerate(metrics_names):\n        vals = [records[d][\"test_metrics\"].get(m, 0.0) for d in datasets]\n        plt.bar(x + i * bar_width, vals, width=bar_width, label=m)\n    plt.xticks(x + bar_width * 1.5, datasets, rotation=45)\n    plt.ylim(0, 1)\n    plt.ylabel(\"Score\")\n    plt.title(\"Final Test Metrics by Dataset\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"final_test_metrics_summary.png\")\n    plt.tight_layout()\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metric summary plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom collections import Counter\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef pcwa(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# helper to safely fetch nested dict\ndef safe_get(d, *keys, default=None):\n    for k in keys:\n        d = d.get(k, {})\n    return d if d else default\n\n\nfor exp_name, datasets in experiment_data.items():\n    for ds_name, content in datasets.items():\n        # --------------- Plot losses ---------------------------------\n        try:\n            losses_tr = safe_get(content, \"losses\", \"train\", default=[])\n            losses_val = safe_get(content, \"losses\", \"val\", default=[])\n            if losses_tr and losses_val:\n                ep_tr, v_tr = zip(*losses_tr)\n                ep_val, v_val = zip(*losses_val)\n                plt.figure()\n                plt.plot(ep_tr, v_tr, label=\"Train\")\n                plt.plot(ep_val, v_val, label=\"Validation\")\n                plt.title(f\"{ds_name} Loss Curve (positional_feature_removal)\")\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(\"Loss\")\n                plt.legend()\n                fname = f\"{ds_name}_loss_curve_positional_feature_removal.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating loss curve: {e}\")\n            plt.close()\n\n        # --------------- Plot PCWA -----------------------------------\n        try:\n            pc_tr = safe_get(content, \"metrics\", \"train\", default=[])\n            pc_val = safe_get(content, \"metrics\", \"val\", default=[])\n            if pc_tr and pc_val:\n                ep_tr, v_tr = zip(*pc_tr)\n                ep_val, v_val = zip(*pc_val)\n                plt.figure()\n                plt.plot(ep_tr, v_tr, label=\"Train\")\n                plt.plot(ep_val, v_val, label=\"Validation\")\n                plt.title(f\"{ds_name} PCWA Curve (positional_feature_removal)\")\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(\"PCWA\")\n                plt.legend()\n                fname = f\"{ds_name}_pcwa_curve_positional_feature_removal.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating PCWA curve: {e}\")\n            plt.close()\n\n        # --------------- Confusion matrix ----------------------------\n        try:\n            y_true = content.get(\"ground_truth\", [])\n            y_pred = content.get(\"predictions\", [])\n            if y_true and y_pred:\n                cm = np.zeros((2, 2), dtype=int)\n                for yt, yp in zip(y_true, y_pred):\n                    cm[yt, yp] += 1\n                plt.figure()\n                plt.imshow(cm, cmap=\"Blues\")\n                for i in range(2):\n                    for j in range(2):\n                        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"red\")\n                plt.colorbar()\n                plt.title(f\"{ds_name} Confusion Matrix (Test set)\")\n                plt.xlabel(\"Predicted\")\n                plt.ylabel(\"True\")\n                fname = f\"{ds_name}_confusion_matrix_positional_feature_removal.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating confusion matrix: {e}\")\n            plt.close()\n\n        # --------------- Bar chart of test metrics -------------------\n        try:\n            if y_true and y_pred:\n                seqs = content.get(\n                    \"sequences\", []\n                )  # not saved, so reuse ground truth len\n                if not seqs:\n                    seqs = [\"\"] * len(y_true)\n                acc = sum(int(a == b) for a, b in zip(y_true, y_pred)) / len(y_true)\n                pc = pcwa(seqs, y_true, y_pred)\n                # compute CWA & SWA\n                cwa_num = sum(\n                    count_color_variety(s) if yt == yp else 0\n                    for s, yt, yp in zip(seqs, y_true, y_pred)\n                )\n                cwa_den = sum(count_color_variety(s) for s in seqs)\n                swa_num = sum(\n                    count_shape_variety(s) if yt == yp else 0\n                    for s, yt, yp in zip(seqs, y_true, y_pred)\n                )\n                swa_den = sum(count_shape_variety(s) for s in seqs)\n                cwa = cwa_num / max(cwa_den, 1)\n                swa = swa_num / max(swa_den, 1)\n                metrics = {\"ACC\": acc, \"PCWA\": pc, \"CWA\": cwa, \"SWA\": swa}\n\n                plt.figure()\n                plt.bar(metrics.keys(), metrics.values())\n                plt.ylim(0, 1)\n                plt.title(f\"{ds_name} Test Metrics (positional_feature_removal)\")\n                fname = f\"{ds_name}_test_metrics_bar_positional_feature_removal.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n                print(f\"{ds_name} test metrics:\", metrics)\n        except Exception as e:\n            print(f\"Error creating metrics bar chart: {e}\")\n            plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- SETUP ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- LOAD DATA ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# Helper to compute confusion matrix & accuracy\ndef confusion_and_acc(y_true, y_pred, num_classes=2):\n    cm = np.zeros((num_classes, num_classes), dtype=int)\n    for t, p in zip(y_true, y_pred):\n        cm[t, p] += 1\n    acc = np.trace(cm) / np.sum(cm) if cm.sum() else 0.0\n    return cm, acc\n\n\n# ---------- PLOTTING ----------\nfor abl_key, dsets in experiment_data.items():\n    for dataset_name, entry in dsets.items():\n        # 1) Loss curves ----------------------------------------------------\n        try:\n            tr = np.array(entry[\"losses\"][\"train\"])\n            val = np.array(entry[\"losses\"][\"val\"])\n            if tr.size and val.size:\n                plt.figure()\n                plt.plot(tr[:, 0], tr[:, 1], label=\"Train\")\n                plt.plot(val[:, 0], val[:, 1], label=\"Validation\")\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(\"Loss\")\n                plt.title(f\"{dataset_name} Loss Curve\\nAblation: {abl_key}\")\n                plt.legend()\n                fname = f\"{dataset_name}_loss_curve_{abl_key}.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating loss curve for {dataset_name}: {e}\")\n            plt.close()\n\n        # 2) PCWA curves ----------------------------------------------------\n        try:\n            tr = np.array(entry[\"metrics\"][\"train\"])\n            val = np.array(entry[\"metrics\"][\"val\"])\n            if tr.size and val.size:\n                plt.figure()\n                plt.plot(tr[:, 0], tr[:, 1], label=\"Train\")\n                plt.plot(val[:, 0], val[:, 1], label=\"Validation\")\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(\"PCWA\")\n                plt.title(f\"{dataset_name} PCWA Curve\\nAblation: {abl_key}\")\n                plt.legend()\n                fname = f\"{dataset_name}_pcwa_curve_{abl_key}.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating PCWA curve for {dataset_name}: {e}\")\n            plt.close()\n\n        # 3) Confusion matrix on test set -----------------------------------\n        try:\n            y_true = np.array(entry.get(\"ground_truth\", []))\n            y_pred = np.array(entry.get(\"predictions\", []))\n            if y_true.size and y_pred.size:\n                cm, acc = confusion_and_acc(y_true, y_pred, num_classes=2)\n                plt.figure()\n                plt.imshow(cm, cmap=\"Blues\")\n                for i in range(cm.shape[0]):\n                    for j in range(cm.shape[1]):\n                        plt.text(\n                            j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\"\n                        )\n                plt.xlabel(\"Predicted\")\n                plt.ylabel(\"True\")\n                plt.title(\n                    f\"{dataset_name} Confusion Matrix (ACC={acc:.3f})\\nAblation: {abl_key}\"\n                )\n                plt.colorbar()\n                fname = f\"{dataset_name}_conf_mat_{abl_key}.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n                print(f\"{dataset_name} Test Accuracy ({abl_key}): {acc:.4f}\")\n        except Exception as e:\n            print(f\"Error creating confusion matrix for {dataset_name}: {e}\")\n            plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------------------------------------------------------------------\n# Iterate through experiments and create plots\nfor exp_name, datasets in experiment_data.items():\n    for dset_name, info in datasets.items():\n        # 1) Loss curves -------------------------------------------------\n        try:\n            train_loss = np.array(info[\"losses\"][\"train\"])  # (epoch, value)\n            val_loss = np.array(info[\"losses\"][\"val\"])\n            if train_loss.size and val_loss.size:\n                plt.figure()\n                plt.plot(train_loss[:, 0], train_loss[:, 1], label=\"Train\")\n                plt.plot(val_loss[:, 0], val_loss[:, 1], label=\"Validation\")\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(\"Cross-Entropy Loss\")\n                plt.title(f\"{exp_name}-{dset_name}: Loss vs Epochs\")\n                plt.legend()\n                fname = f\"{exp_name}_{dset_name}_loss_curve.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {exp_name}-{dset_name}: {e}\")\n            plt.close()\n\n        # 2) PCWA metric curves -----------------------------------------\n        try:\n            train_pcwa = np.array(info[\"metrics\"][\"train\"])\n            val_pcwa = np.array(info[\"metrics\"][\"val\"])\n            if train_pcwa.size and val_pcwa.size:\n                plt.figure()\n                plt.plot(train_pcwa[:, 0], train_pcwa[:, 1], label=\"Train PCWA\")\n                plt.plot(val_pcwa[:, 0], val_pcwa[:, 1], label=\"Val PCWA\")\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(\"PCWA\")\n                plt.title(f\"{exp_name}-{dset_name}: PCWA vs Epochs\")\n                plt.legend()\n                fname = f\"{exp_name}_{dset_name}_pcwa_curve.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating PCWA plot for {exp_name}-{dset_name}: {e}\")\n            plt.close()\n\n        # 3) Confusion matrix on test set --------------------------------\n        try:\n            y_true = np.array(info.get(\"ground_truth\", []))\n            y_pred = np.array(info.get(\"predictions\", []))\n            if y_true.size and y_pred.size:\n                conf = np.zeros((2, 2), dtype=int)\n                for t, p in zip(y_true, y_pred):\n                    conf[t, p] += 1\n                plt.figure()\n                plt.imshow(conf, cmap=\"Blues\")\n                for i in range(2):\n                    for j in range(2):\n                        plt.text(\n                            j, i, conf[i, j], ha=\"center\", va=\"center\", color=\"black\"\n                        )\n                plt.xticks([0, 1], [\"Pred 0\", \"Pred 1\"])\n                plt.yticks([0, 1], [\"True 0\", \"True 1\"])\n                plt.title(f\"{exp_name}-{dset_name}: Confusion Matrix\")\n                plt.colorbar()\n                fname = f\"{exp_name}_{dset_name}_confusion_matrix.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating confusion matrix for {exp_name}-{dset_name}: {e}\")\n            plt.close()\n\n        # 4) Print test metrics if available -----------------------------\n        metrics = info.get(\"metrics\", {}).get(\"test\") or info.get(\"test_metrics\")\n        if metrics:\n            print(f\"{exp_name}-{dset_name} TEST:\", metrics)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------ #\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    ed = experiment_data[\"ShapeRemoval\"][\"SPR\"]\n\n    # -------------------------------------------------------------- #\n    # helper to convert (epoch, value) tuples -> two numpy arrays\n    def split_points(pair_list):\n        arr = np.array(pair_list)\n        return arr[:, 0], arr[:, 1]\n\n    # collect data\n    epochs_loss_tr, loss_tr = split_points(ed[\"losses\"][\"train\"])\n    epochs_loss_val, loss_val = split_points(ed[\"losses\"][\"val\"])\n    epochs_pc_tr, pc_tr = split_points(ed[\"metrics\"][\"train\"])\n    epochs_pc_val, pc_val = split_points(ed[\"metrics\"][\"val\"])\n    y_pred, y_true = np.array(ed[\"predictions\"]), np.array(ed[\"ground_truth\"])\n    num_classes = len(np.unique(np.concatenate([y_true, y_pred])))\n\n    # -------------------------------------------------------------- #\n    # 1) Loss curves\n    try:\n        plt.figure()\n        plt.plot(epochs_loss_tr, loss_tr, label=\"Train\")\n        plt.plot(epochs_loss_val, loss_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"ShapeRemoval-SPR: Training vs Validation Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"ShapeRemoval_SPR_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # -------------------------------------------------------------- #\n    # 2) PCWA curves\n    try:\n        plt.figure()\n        plt.plot(epochs_pc_tr, pc_tr, label=\"Train\")\n        plt.plot(epochs_pc_val, pc_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"PCWA\")\n        plt.title(\"ShapeRemoval-SPR: Training vs Validation PCWA\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"ShapeRemoval_SPR_PCWA_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating PCWA curve: {e}\")\n        plt.close()\n\n    # -------------------------------------------------------------- #\n    # 3) Confusion matrix heat map\n    try:\n        cm = np.zeros((num_classes, num_classes), dtype=int)\n        for t, p in zip(y_true, y_pred):\n            cm[t, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        for i in range(num_classes):\n            for j in range(num_classes):\n                plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n        plt.title(\"ShapeRemoval-SPR: Confusion Matrix\")\n        fname = os.path.join(working_dir, \"ShapeRemoval_SPR_confusion_matrix.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\n    # -------------------------------------------------------------- #\n    # print final test metrics for quick reference\n    try:\n        # metrics were printed during experiment run, recompute quickly here\n        acc = (y_true == y_pred).mean()\n        print(f\"Test Accuracy: {acc:.3f}\")\n        if len(pc_val) > 0:\n            print(f\"Final Validation PCWA: {pc_val[-1]:.3f}\")\n    except Exception as e:\n        print(f\"Error printing metrics: {e}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    spr = experiment_data[\"single_layer_gnn\"][\"SPR\"]\n\n    # Helper to turn list[(epoch,val)] -> arrays\n    def to_xy(lst):\n        lst = np.array(lst)\n        return lst[:, 0], lst[:, 1]\n\n    epochs_loss_tr, loss_tr = to_xy(spr[\"losses\"][\"train\"])\n    epochs_loss_val, loss_val = to_xy(spr[\"losses\"][\"val\"])\n    epochs_pc_tr, pc_tr = to_xy(spr[\"metrics\"][\"train\"])\n    epochs_pc_val, pc_val = to_xy(spr[\"metrics\"][\"val\"])\n    y_true = np.array(spr[\"ground_truth\"])\n    y_pred = np.array(spr[\"predictions\"])\n\n    # Overall metrics\n    acc = (y_true == y_pred).mean() if len(y_true) else float(\"nan\")\n    pcwa_final = pc_val[-1] if len(pc_val) else float(\"nan\")\n    print(f\"FINAL ACC={acc:.4f}, FINAL PCWA={pcwa_final:.4f}\")\n\n    # -------------------------------------------------- Plot 1: Loss\n    try:\n        plt.figure()\n        plt.plot(epochs_loss_tr, loss_tr, label=\"Train\")\n        plt.plot(epochs_loss_val, loss_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"Training vs Validation Loss\\nDataset: SPR\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # -------------------------------------------------- Plot 2: PCWA\n    try:\n        plt.figure()\n        plt.plot(epochs_pc_tr, pc_tr, label=\"Train\")\n        plt.plot(epochs_pc_val, pc_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"PCWA\")\n        plt.title(\"Training vs Validation PCWA\\nDataset: SPR\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_PCWA_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating PCWA plot: {e}\")\n        plt.close()\n\n    # -------------------------------------------------- Plot 3: Confusion Matrix\n    try:\n        from sklearn.metrics import confusion_matrix\n\n        cm = confusion_matrix(y_true, y_pred, labels=sorted(set(y_true)))\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        for (i, j), v in np.ndenumerate(cm):\n            plt.text(j, i, str(v), ha=\"center\", va=\"center\", color=\"black\")\n        plt.title(\n            \"Confusion Matrix\\nDataset: SPR (Left: Ground Truth, Right: Predictions)\"\n        )\n        fname = os.path.join(working_dir, \"SPR_confusion_matrix.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\ndef pcwa(seqs, y_true, y_pred):\n    def cvar(s):\n        return len(set(tok[1] for tok in s.strip().split() if len(tok) > 1))\n\n    def svar(s):\n        return len(set(tok[0] for tok in s.strip().split() if tok))\n\n    w = np.array([cvar(s) * svar(s) for s in seqs], dtype=float)\n    correct = (np.array(y_true) == np.array(y_pred)).astype(float)\n    return ((w * correct).sum() / w.sum()) if w.sum() else 0.0\n\n\n# ---------------------------------------------------------------------\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ned = experiment_data.get(\"UniChain\", {}).get(\"SPR\", {})\nlosses_train = ed.get(\"losses\", {}).get(\"train\", [])\nlosses_val = ed.get(\"losses\", {}).get(\"val\", [])\nmetrics_train = ed.get(\"metrics\", {}).get(\"train\", [])\nmetrics_val = ed.get(\"metrics\", {}).get(\"val\", [])\npredictions = np.array(ed.get(\"predictions\", []))\nground_truth = np.array(ed.get(\"ground_truth\", []))\nall_seqs = np.array(\n    [None] * len(predictions)\n)  # sequences not saved; pcwa will be skipped\n\n# ---------------------------------------------------------------------\n# 1) Loss curves -------------------------------------------------------\ntry:\n    if losses_train and losses_val:\n        ep_tr, val_tr = zip(*losses_train)\n        ep_v, val_v = zip(*losses_val)\n        plt.figure()\n        plt.plot(ep_tr, val_tr, label=\"Train\")\n        plt.plot(ep_v, val_v, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"UniChain \u2013 SPR Loss Curves\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"unichain_spr_loss_curves.png\")\n        plt.savefig(fname, dpi=150)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 2) PCWA metric curves ------------------------------------------------\ntry:\n    if metrics_train and metrics_val:\n        ep_tr, val_tr = zip(*metrics_train)\n        ep_v, val_v = zip(*metrics_val)\n        plt.figure()\n        plt.plot(ep_tr, val_tr, label=\"Train PCWA\")\n        plt.plot(ep_v, val_v, label=\"Validation PCWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"PCWA\")\n        plt.title(\"UniChain \u2013 SPR PCWA Curves\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"unichain_spr_pcwa_curves.png\")\n        plt.savefig(fname, dpi=150)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating PCWA curve: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 3) Confusion matrix --------------------------------------------------\ntry:\n    if predictions.size and ground_truth.size:\n        cm = np.zeros((2, 2), dtype=int)\n        for gt, pr in zip(ground_truth, predictions):\n            cm[gt, pr] += 1\n        plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        for i in range(2):\n            for j in range(2):\n                plt.text(\n                    j,\n                    i,\n                    cm[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                )\n        plt.colorbar()\n        plt.xticks([0, 1], [\"Pred 0\", \"Pred 1\"])\n        plt.yticks([0, 1], [\"True 0\", \"True 1\"])\n        plt.title(\"UniChain \u2013 SPR Confusion Matrix (Test Set)\")\n        fname = os.path.join(working_dir, \"unichain_spr_confusion_matrix.png\")\n        plt.savefig(fname, dpi=150)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# Print evaluation metrics --------------------------------------------\nif predictions.size and ground_truth.size:\n    acc = (predictions == ground_truth).mean()\n    pcwa_score = pcwa(\n        all_seqs if all_seqs.any() else [\"\"] * len(predictions),\n        ground_truth,\n        predictions,\n    )\n    print(f\"Test ACC: {acc:.4f} | Test PCWA: {pcwa_score:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    ablation_key = list(experiment_data.keys())[0]\n    dataset_key = list(experiment_data[ablation_key].keys())[0]\n    data_dict = experiment_data[ablation_key][dataset_key]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data_dict = None\n\nif data_dict is not None:\n    # --------------------------- helpers ------------------------\n    def unpack(k):\n        arr = data_dict[k]  # dict(train,val)\n        epochs, train_v = zip(*arr[\"train\"])\n        _, val_v = zip(*arr[\"val\"])\n        return epochs, train_v, val_v\n\n    epochs, tr_losses, va_losses = unpack(\"losses\")\n    _, tr_pc, va_pc = unpack(\"metrics\")\n\n    # --------------------------- PLOT 1 -------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_losses, label=\"Train\")\n        plt.plot(epochs, va_losses, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        fname = f\"{dataset_key}_loss_curves.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # --------------------------- PLOT 2 -------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_pc, label=\"Train\")\n        plt.plot(epochs, va_pc, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"PCWA\")\n        plt.title(\"SPR PCWA Metric Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        fname = f\"{dataset_key}_pcwa_curves.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating PCWA curve plot: {e}\")\n        plt.close()\n\n    # --------------------------- PLOT 3 -------------------------\n    try:\n        y_true = np.array(data_dict[\"ground_truth\"])\n        y_pred = np.array(data_dict[\"predictions\"])\n        conf = np.zeros((2, 2), int)\n        for t, p in zip(y_true, y_pred):\n            conf[t, p] += 1\n        plt.figure()\n        plt.imshow(conf, cmap=\"Blues\")\n        for i in range(2):\n            for j in range(2):\n                plt.text(j, i, conf[i, j], ha=\"center\", va=\"center\", color=\"black\")\n        plt.xticks([0, 1], [\"Pred 0\", \"Pred 1\"])\n        plt.yticks([0, 1], [\"True 0\", \"True 1\"])\n        plt.title(\"SPR Confusion Matrix\\nLeft: Ground Truth, Right: Predictions\")\n        fname = f\"{dataset_key}_confusion_matrix.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix plot: {e}\")\n        plt.close()\n\n    # --------------------------- METRICS ------------------------\n    acc = (y_true == y_pred).mean()\n\n    # quick PCWA recompute\n    def pcwa(seqs, y_t, y_p):\n        def cvar(s):\n            return len(set(tok[1] for tok in s.split()))\n\n        def svar(s):\n            return len(set(tok[0] for tok in s.split()))\n\n        w = [cvar(s) * svar(s) for s in seqs]\n        corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_t, y_p)]\n        return sum(corr) / sum(w) if sum(w) else 0.0\n\n    pcwa_val = (\n        pcwa(data_dict.get(\"ground_truth_seqs\", []), y_true.tolist(), y_pred.tolist())\n        if \"ground_truth_seqs\" in data_dict\n        else \"n/a\"\n    )\n    print(f\"Test ACC: {acc:.4f} | Test PCWA: {pcwa_val}\")\n"], "plot_plan": ["We first load experiment_data.npy from the working directory, falling back to an empty dict if loading fails.  From the stored dictionary we extract the epoch-indexed tuples for training and validation losses as well as PCWA (dual-weighted accuracy) that were logged during the run; these are unpacked into simple numpy arrays for plotting.  Three visualizations are produced, each wrapped in an independent try\u2013except so that a failure in one will not stop the rest: (1) a combined training/validation loss curve across epochs, (2) a training/validation PCWA curve across epochs, and (3) a bar chart of the final test-set metrics (ACC, PCWA, CWA, SWA) recomputed on the fly from the saved ground-truth and prediction arrays.  All figures are saved inside working_dir with clear, self-descriptive filenames and closed immediately afterwards to avoid memory leaks.  The code follows the requested structure: starts with the required imports, creates working_dir if missing, respects the \u201cplot only what exists\u201d rule, and limits itself to three plots.  Descriptive titles and axis labels are added to make the graphics self-explanatory, e.g. \u201cTraining vs Validation Loss \u2013 SPR dataset\u201d.  At the end, the script prints each metric to give quick console feedback in addition to the plots.", "We first load the saved numpy dictionary, extract the per-dataset records, and organise the content we need: epoch numbers with training/validation losses, epoch numbers with training/validation PCWA, and the final test metrics (ACC, PCWA, CWA, SWA).  \nThe visualisation strategy keeps the total number of figures \u2264 5 by combining multiple datasets into the same figure when possible.  \nFigure 1 plots training and validation loss curves for all datasets, using solid lines for training and dashed lines for validation, and different colours per dataset.  \nFigure 2 does the same for PCWA, letting us see generalisation quality across epochs.  \nFigure 3 is a grouped bar chart that summarises the four final test metrics for each dataset, giving a quick comparative overview.  \nEach figure is produced inside its own try\u2013except block; we always close figures and save them into the predefined working_dir with descriptive filenames that include the dataset group and plot type.  \nA non-existent file or key raises a readable warning but does not crash the script.  \nThe code uses only matplotlib and numpy, adheres strictly to the provided plotting guidelines, and can be run as-is inside the current environment.", "We load the saved experiment_data.npy, extract loss and PCWA trajectories for both train and validation splits, and plot them as simple line charts (two figures). Next we recover ground-truth and prediction arrays, calculate a 2\u00d72 confusion-matrix and draw it as an image (third figure). We also recompute overall test metrics (ACC, PCWA, CWA, SWA) directly from those arrays and visualise them with a small bar chart (fourth figure). Every plotting section is wrapped in its own try-except so that a failure in one does not stop the rest, and every figure is saved with a descriptive filename into working_dir before being closed. Epoch curves use the full list provided; we rely on the data generator to have \u22645 epochs so the \u201c\u22645 figures\u201d guideline is respected. Finally the script prints the test metrics dictionary so that numerical results are visible in logs.", "We will load the stored experiment_data.npy, iterate over every ablation and dataset entry it contains and extract the time\u2013series for training/validation losses and PCWA metrics.  For each of those two curves we create an individual plot, putting both the training and validation line in the same axes, labeling epochs on the x-axis and the corresponding value on the y-axis.  We then compute a simple test confusion-matrix and overall accuracy from the saved ground_truth and predictions arrays, visualise that matrix with imshow and annotate each cell for clarity; this becomes the third (and last) figure.  Each figure is wrapped in its own try-except guard, saved to working_dir with a descriptive filename that includes the dataset name and plot type, given a clear title and subtitle, and is always closed afterwards.  All directories are created if missing.  After plotting, we print the derived test accuracy so the user immediately sees a headline evaluation number in the notebook/console.  No data are fabricated\u2014everything comes directly from experiment_data.npy.  The implementation sticks to core matplotlib and numpy and follows the provided plotting guidelines precisely.  At most three figures are produced, comfortably under the five-figure limit.", "We first load the serialized experiment_data.npy from the working directory and iterate over every (experiment, dataset) combination stored inside. For each run we extract: (i) the list of (epoch, loss) pairs for both train and validation splits, (ii) the list of (epoch, PCWA) metric values for train/val, and (iii) the arrays of test\u2010set ground-truth and predicted labels. We then create up to three figures\u2014loss curves, PCWA curves, and a 2\u00d72 confusion-matrix heat-map\u2014placing each in its own try/except block to guarantee graceful failure and proper figure cleanup. All figures are titled with the experiment and dataset name (e.g. \u201cNoEdges-SPR: Loss vs Epochs\u201d) and saved to the working directory with descriptive file names. Only real values stored in experiment_data.npy are visualised; no artificial data are fabricated. We also respect the five-plot maximum by limiting ourselves to three plots per experiment. After plotting we close every figure and finally print any test metrics found in the file so users can inspect quantitative performance alongside the graphics.", "We will load experiment_data.npy, extract the training/validation losses and PCWA metrics recorded each epoch, as well as the final ground-truth and prediction arrays. Three separate plots are generated inside individual try-except blocks: (1) loss curves, (2) PCWA curves, and (3) a 2\u00d72 confusion-matrix heat-map summarizing the test set results. Every plot is titled clearly, saved with descriptive filenames that include the dataset and plot type, and the figure is closed afterward. We create working_dir if it does not exist and respect the five-figure maximum. Finally, we print overall test metrics that are stored in the experiment data to provide quick textual feedback. All code relies solely on data found in experiment_data.npy and uses basic matplotlib.", "We will load the saved experiment_data.npy, pull out the epoch-wise loss and PCWA entries plus the final prediction/ground-truth arrays, and organize them into NumPy arrays. Then we will create up to three separate figures: (1) training/validation loss curves, (2) training/validation PCWA curves, and (3) a confusion-matrix heat-map summarizing model predictions. Each plot is wrapped in its own try-except block, follows the naming and titling conventions, is saved to working_dir, and the figure is closed regardless of success. Finally, the script prints out overall accuracy and PCWA so the notebook runner has a numeric summary alongside the visualizations. No synthetic values are introduced\u2014everything comes directly from experiment_data.npy.", "We first load experiment_data.npy, locate the UniChain-SPR entry, and extract the epoch-wise tuples for both losses and PCWA metrics.  Using numpy we separate epochs and values, then build two line plots: one for losses and one for PCWA, each showing both training and validation curves.  Next we retrieve the saved ground-truth and prediction arrays, build a 2\u00d72 confusion matrix, turn it into a heat-map image, and annotate each cell with counts.  All three figures are wrapped in independent try-except blocks to guarantee robust execution and immediate figure closure.  Filenames include the dataset (\u201cspr\u201d) and the plot type to stay descriptive.  We also compute overall accuracy and PCWA on the test set and print them to stdout so the user can verify the numeric scores alongside the visualizations.  No data is fabricated; everything is derived solely from experiment_data.npy.  At most three figures are produced, satisfying the \u201c\u22645 figures\u201d rule.", "The script will first load experiment_data.npy and identify the only dataset/ablation present (first_node_readout \u2013 SPR). It extracts epoch indices together with training/validation losses and PCWA scores, then builds two line plots: (1) loss curves and (2) PCWA metric curves. Next, it computes a simple 2\u00d72 confusion matrix from stored ground-truth and prediction arrays and visualises it as a heat-map style image (third plot). Each plot is wrapped in its own try-except block, saved into working_dir with descriptive names, titled clearly, and the figure is closed afterwards. Finally, the script re-computes and prints the overall ACC and PCWA on the test split for quick reference. Only real data loaded from experiment_data.npy are used, and a maximum of three figures are generated (well below the five-figure cap)."], "ablation_name": [null, "Multi-Dataset Generalization Study", "Positional Feature Removal", "Node Color Feature Removal", "Edge Structure Removal (No Edges)", "Node Shape Feature Removal", "Single-Layer GNN (Second GraphConv Removed)", "Unidirectional-Chain Edges", "First-Node Readout Ablation"], "hyperparam_name": [null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false], "parse_metrics_plan": ["The script will read the saved NumPy file from the working directory, unpack the\nnested dictionary and, for every dataset entry (here only \u201cSPR\u201d), locate the\nstored series of (epoch, value) pairs.   For losses it reports the minimum\n(best) value, for PCWA it reports the maximum (best) value, and for the test\nsplit it recomputes the final accuracy from the saved predictions and ground-\ntruth labels.   All information is printed immediately; there are no plots and\nno guarded main-section.", "The script will load the stored numpy dictionary from the \u201cworking\u201d directory,\nloop through every dataset entry, and compute the best (i.e., maximum PCWA /\nminimum loss) values recorded during training and validation. It will then print\nthose along with the single set of test metrics already saved for each dataset.\nAll metric names are printed explicitly (e.g., \u201cbest train PCWA\u201d, \u201ctest ACC\u201d)\nand the code executes immediately once run, without any `if __name__ ==\n\"__main__\":` guard.", "The script loads the saved NumPy dictionary, pulls out the sub-dictionary that\ncontains metrics for the positional-feature-removal experiment, and prints the\nfinal (i.e., last-epoch) values of each recorded metric. After that, it computes\ntest accuracy directly from the stored ground-truth and prediction arrays. All\noutput is grouped by dataset so the reader can immediately see \u201cTraining\u201d,\n\u201cValidation\u201d, and \u201cTest\u201d results.", "We will load experiment_data.npy from the ./working directory, unwrap the nested\ndictionary, and iterate over every dataset entry (e.g., \u201cSPR\u201d). For each dataset\nwe grab the lists of (epoch, value) pairs stored under metrics and losses, keep\nonly the last element (i.e., value from the final epoch), and print it with\nexplicit labels such as \u201ctraining PCWA\u201d and \u201cvalidation loss.\u201d If test-set\npredictions and ground-truth labels exist we also compute and print the final\ntest accuracy. The script contains no __main__ guard so it executes immediately.", "We load the serialized dictionary from the working directory, walk through every\nstored experiment, and for each dataset (e.g., \u201cSPR\u201d) we examine the lists that\ncontain (epoch, value) pairs.   For losses we report the minimum value (best),\nwhile for performance metrics we report the maximum value obtained.   The script\nalso recomputes and prints test accuracy from the stored predictions and ground-\ntruth labels.   Everything is executed at the top level so the file runs\nimmediately without needing a special entry point.", "The script below loads the saved NumPy dictionary, navigates to the Shape-\nRemoval/SPR entry, and pulls out the recorded loss and PCWA histories for\ntraining and validation. It simply selects the last (final-epoch) entry from\neach list and computes test accuracy from the stored prediction and ground-truth\narrays. Each dataset section is printed once, with clearly named metrics,\nexactly as requested.", "The script will load the saved NumPy dictionary from the working directory,\nrecreate the helper functions needed for metric computation, and then parse the\nstored results.   For the training and validation splits it selects the lowest\nloss and the highest PCWA score recorded across epochs.   For the test split it\nrecomputes accuracy directly from the stored ground-truth and predictions (the\nsequences weren\u2019t saved, so PCWA can\u2019t be recomputed).   Finally, it prints each\ndataset name followed by clearly labelled best/final metric values.", "We will load the saved numpy file from the \u201cworking\u201d directory, pull out the\nUniChain \u2192 SPR entry, and then summarise the stored information.   For training\nand validation splits we take the last\u2010recorded loss and PCWA value (i.e. the\nvalue from the final epoch).   For the test split the file only stores\npredictions and ground-truth labels, so we compute the final test accuracy\ndirectly from those lists.   All results are printed with the dataset name\nfirst, followed by clearly labelled metric/value pairs.", "The script will load the NumPy file from the working directory, unpack the\nnested dictionary, and iterate through every dataset it contains.   For each\ndataset it will retrieve the final-epoch training/validation loss and PCWA score\n(these are stored as lists of `(epoch, value)` tuples).   It will also compute\nthe final test accuracy directly from the stored prediction and ground-truth\nlists.   All values are printed with clear, explicit metric names, and nothing\nis hidden behind a `__main__` guard so the code executes immediately."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# Locate and load the saved experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nnpy_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(npy_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# Helper functions ----------------------------------------------------\ndef best_loss(loss_history):\n    \"\"\"Return the lowest loss value from a list of (epoch, loss).\"\"\"\n    return min(loss_history, key=lambda x: x[1])[1] if loss_history else None\n\n\ndef best_metric(metric_history):\n    \"\"\"Return the highest metric value from a list of (epoch, metric).\"\"\"\n    return max(metric_history, key=lambda x: x[1])[1] if metric_history else None\n\n\n# ---------------------------------------------------------------------\n# Iterate over datasets and print requested statistics ----------------\nfor dataset_name, content in experiment_data.items():\n    print(f\"Dataset: {dataset_name}\")\n\n    # Training / validation losses and metrics\n    train_losses = content[\"losses\"].get(\"train\", [])\n    val_losses = content[\"losses\"].get(\"val\", [])\n    train_metrics = content[\"metrics\"].get(\"train\", [])\n    val_metrics = content[\"metrics\"].get(\"val\", [])\n\n    tr_loss_best = best_loss(train_losses)\n    val_loss_best = best_loss(val_losses)\n    tr_pcwa_best = best_metric(train_metrics)\n    val_pcwa_best = best_metric(val_metrics)\n\n    if tr_loss_best is not None:\n        print(f\"Best training loss: {tr_loss_best:.4f}\")\n    if val_loss_best is not None:\n        print(f\"Best validation loss: {val_loss_best:.4f}\")\n    if tr_pcwa_best is not None:\n        print(f\"Best training PCWA: {tr_pcwa_best:.4f}\")\n    if val_pcwa_best is not None:\n        print(f\"Best validation PCWA: {val_pcwa_best:.4f}\")\n\n    # Test accuracy from stored predictions / ground truth\n    y_true = list(content.get(\"ground_truth\", []))\n    y_pred = list(content.get(\"predictions\", []))\n    if y_true and y_pred and len(y_true) == len(y_pred):\n        correct = sum(int(t == p) for t, p in zip(y_true, y_pred))\n        test_acc = correct / len(y_true)\n        print(f\"Test accuracy: {test_acc:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# LOAD EXPERIMENT DATA -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\nresults = experiment_data.get(\"multi_dataset_generalization\", {})\n\n\n# ---------------------------------------------------------------------\n# HELPER ---------------------------------------------------------------\ndef best_value(records, mode=\"max\"):\n    \"\"\"\n    records: list of (epoch, value) tuples\n    mode   : \"max\" for highest value, \"min\" for lowest value\n    \"\"\"\n    if not records:\n        return None\n    key_fn = (lambda x: x[1]) if mode == \"max\" else (lambda x: -x[1])\n    return max(records, key=key_fn)[1]\n\n\n# ---------------------------------------------------------------------\n# PRINT METRICS --------------------------------------------------------\nfor dataset_name, rec in results.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # Best (or final) training/validation statistics\n    train_pcwa_best = best_value(rec[\"metrics\"][\"train\"], mode=\"max\")\n    val_pcwa_best = best_value(rec[\"metrics\"][\"val\"], mode=\"max\")\n    train_loss_best = best_value(rec[\"losses\"][\"train\"], mode=\"min\")\n    val_loss_best = best_value(rec[\"losses\"][\"val\"], mode=\"min\")\n\n    if train_pcwa_best is not None:\n        print(f\"best train PCWA: {train_pcwa_best:.3f}\")\n    if val_pcwa_best is not None:\n        print(f\"best validation PCWA: {val_pcwa_best:.3f}\")\n    if train_loss_best is not None:\n        print(f\"best train loss: {train_loss_best:.3f}\")\n    if val_loss_best is not None:\n        print(f\"best validation loss: {val_loss_best:.3f}\")\n\n    # Test metrics (only one set recorded)\n    for metric_name, metric_val in rec.get(\"test_metrics\", {}).items():\n        print(f\"test {metric_name}: {metric_val:.3f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------#\n# Locate and load experiment data                                   #\n# ------------------------------------------------------------------#\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_file}\")\n\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\nspr_results = experiment_data[\"positional_feature_removal\"][\"SPR\"]\n\n\n# ------------------------------------------------------------------#\n# Helper to fetch the final value from a list of (epoch, value)      #\n# ------------------------------------------------------------------#\ndef final_val(history_list):\n    return history_list[-1][1] if history_list else None\n\n\n# ------------------------------------------------------------------#\n# Extract final metrics & losses                                     #\n# ------------------------------------------------------------------#\ntrain_pcwa = final_val(spr_results[\"metrics\"][\"train\"])\nval_pcwa = final_val(spr_results[\"metrics\"][\"val\"])\ntrain_loss = final_val(spr_results[\"losses\"][\"train\"])\nval_loss = final_val(spr_results[\"losses\"][\"val\"])\n\n# Test accuracy from stored predictions / ground-truth\ny_true = spr_results.get(\"ground_truth\", [])\ny_pred = spr_results.get(\"predictions\", [])\ntest_acc = (\n    sum(int(t == p) for t, p in zip(y_true, y_pred)) / len(y_true) if y_true else None\n)\n\n# ------------------------------------------------------------------#\n# Print results                                                     #\n# ------------------------------------------------------------------#\nprint(\"Training dataset:\")\nif train_pcwa is not None:\n    print(f\"training PCWA: {train_pcwa:.4f}\")\nif train_loss is not None:\n    print(f\"training loss: {train_loss:.4f}\")\n\nprint(\"\\nValidation dataset:\")\nif val_pcwa is not None:\n    print(f\"validation PCWA: {val_pcwa:.4f}\")\nif val_loss is not None:\n    print(f\"validation loss: {val_loss:.4f}\")\n\nprint(\"\\nTest dataset:\")\nif test_acc is not None:\n    print(f\"test accuracy: {test_acc:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------\n# locate and load the experiment file\nwork_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(work_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------\ndef last_value(pairs):\n    \"\"\"Return the value from the final (epoch, value) tuple list.\"\"\"\n    return pairs[-1][1] if pairs else None\n\n\nfor ablation_key, datasets in experiment_data.items():\n    for dataset_name, contents in datasets.items():\n        print(f\"Dataset: {dataset_name}\")\n\n        # ----- training / validation metrics -----\n        train_pcwa = last_value(contents[\"metrics\"].get(\"train\", []))\n        val_pcwa = last_value(contents[\"metrics\"].get(\"val\", []))\n        train_loss = last_value(contents[\"losses\"].get(\"train\", []))\n        val_loss = last_value(contents[\"losses\"].get(\"val\", []))\n\n        if train_pcwa is not None:\n            print(f\"training PCWA: {train_pcwa:.4f}\")\n        if val_pcwa is not None:\n            print(f\"validation PCWA: {val_pcwa:.4f}\")\n        if train_loss is not None:\n            print(f\"training loss: {train_loss:.4f}\")\n        if val_loss is not None:\n            print(f\"validation loss: {val_loss:.4f}\")\n\n        # ----- optional test metrics -----\n        y_pred = contents.get(\"predictions\")\n        y_true = contents.get(\"ground_truth\")\n        if y_pred and y_true:  # only if predictions exist\n            test_acc = sum(int(p == t) for p, t in zip(y_pred, y_true)) / len(y_true)\n            print(f\"test accuracy: {test_acc:.4f}\")\n\n        print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# locate and load the saved experiment dictionary\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# helper functions ----------------------------------------------------\ndef best_value(pairs, higher_is_better=True):\n    \"\"\"\n    Given a list of (epoch, value) pairs, return the best (epoch, value)\n    according to the optimisation direction.\n    \"\"\"\n    if not pairs:\n        return None, None\n    key_fn = (lambda p: p[1]) if higher_is_better else (lambda p: -p[1])\n    best_epoch, best_val = max(pairs, key=key_fn)\n    return best_epoch, best_val\n\n\n# ---------------------------------------------------------------------\n# iterate through experiments and datasets ----------------------------\nfor experiment_name, exp_dict in experiment_data.items():\n    for dataset_name, data_dict in exp_dict.items():\n        print(f\"Dataset: {dataset_name}\")\n\n        # ----- losses -----\n        ep, val = best_value(data_dict[\"losses\"][\"train\"], higher_is_better=False)\n        if val is not None:\n            print(f\"Best train loss: {val:.4f} (epoch {ep})\")\n\n        ep, val = best_value(data_dict[\"losses\"][\"val\"], higher_is_better=False)\n        if val is not None:\n            print(f\"Best validation loss: {val:.4f} (epoch {ep})\")\n\n        # ----- PCWA (metric stored in 'metrics') -----\n        ep, val = best_value(data_dict[\"metrics\"][\"train\"], higher_is_better=True)\n        if val is not None:\n            print(f\"Best train PCWA: {val:.4f} (epoch {ep})\")\n\n        ep, val = best_value(data_dict[\"metrics\"][\"val\"], higher_is_better=True)\n        if val is not None:\n            print(f\"Best validation PCWA: {val:.4f} (epoch {ep})\")\n\n        # ----- test accuracy (re-computed) -----\n        preds = data_dict.get(\"predictions\", [])\n        gts = data_dict.get(\"ground_truth\", [])\n        if preds and gts and len(preds) == len(gts):\n            test_acc = sum(int(p == y) for p, y in zip(preds, gts)) / len(gts)\n            print(f\"Test accuracy: {test_acc:.4f}\")\n\n        print(\"\")  # blank line for readability\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# Locate and load the experiment data\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# Navigate to the SPR results\n# ---------------------------------------------------------------------\nspr_data = experiment_data[\"ShapeRemoval\"][\"SPR\"]\n\ntrain_losses = spr_data[\"losses\"][\"train\"]\nval_losses = spr_data[\"losses\"][\"val\"]\ntrain_metrics = spr_data[\"metrics\"][\"train\"]  # PCWA values\nval_metrics = spr_data[\"metrics\"][\"val\"]  # PCWA values\n\n# Final (last-epoch) metrics\nfinal_train_loss = train_losses[-1][1] if train_losses else None\nfinal_val_loss = val_losses[-1][1] if val_losses else None\nfinal_train_pcwa = train_metrics[-1][1] if train_metrics else None\nfinal_val_pcwa = val_metrics[-1][1] if val_metrics else None\n\n# ---------------------------------------------------------------------\n# Compute test accuracy from stored predictions / ground truth\n# ---------------------------------------------------------------------\ny_pred = np.array(spr_data[\"predictions\"])\ny_true = np.array(spr_data[\"ground_truth\"])\ntest_accuracy = (y_pred == y_true).mean() if y_true.size else None\n\n# ---------------------------------------------------------------------\n# Print results\n# ---------------------------------------------------------------------\nprint(\"Training:\")\nif final_train_loss is not None:\n    print(f\"  Training loss: {final_train_loss:.4f}\")\nif final_train_pcwa is not None:\n    print(f\"  Training PCWA: {final_train_pcwa:.4f}\")\n\nprint(\"\\nValidation:\")\nif final_val_loss is not None:\n    print(f\"  Validation loss: {final_val_loss:.4f}\")\nif final_val_pcwa is not None:\n    print(f\"  Validation PCWA: {final_val_pcwa:.4f}\")\n\nprint(\"\\nTest:\")\nif test_accuracy is not None:\n    print(f\"  Test accuracy: {test_accuracy:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# Locate and load the stored experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(experiment_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# Helper functions (needed to recompute any metrics)\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef pcwa(seqs, y_true, y_pred):\n    weights = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    num = sum(w for w, yt, yp in zip(weights, y_true, y_pred) if yt == yp)\n    den = sum(weights)\n    return num / den if den else 0.0\n\n\n# ---------------------------------------------------------------------\n# Extract the metrics for the single-layer GNN on the SPR task\nexp = experiment_data[\"single_layer_gnn\"][\"SPR\"]\n\n# ---------- Training ----------\ntrain_losses = exp[\"losses\"][\"train\"]  # list of (epoch, value)\ntrain_pcwa = exp[\"metrics\"][\"train\"]  # list of (epoch, value)\n\nbest_train_loss = min(train_losses, key=lambda t: t[1])[1]\nbest_train_pcwa = max(train_pcwa, key=lambda t: t[1])[1]\n\nprint(\"TRAIN DATASET\")\nprint(f\"best training loss: {best_train_loss:.4f}\")\nprint(f\"best training PCWA: {best_train_pcwa:.4f}\")\n\n# ---------- Validation ----------\nval_losses = exp[\"losses\"][\"val\"]\nval_pcwa = exp[\"metrics\"][\"val\"]\n\nbest_val_loss = min(val_losses, key=lambda t: t[1])[1]\nbest_val_pcwa = max(val_pcwa, key=lambda t: t[1])[1]\n\nprint(\"\\nVALIDATION DATASET\")\nprint(f\"best validation loss: {best_val_loss:.4f}\")\nprint(f\"best validation PCWA: {best_val_pcwa:.4f}\")\n\n# ---------- Test ----------\ny_true = exp[\"ground_truth\"]\ny_pred = exp[\"predictions\"]\n\nif len(y_true) and len(y_true) == len(y_pred):\n    test_accuracy = sum(int(y == p) for y, p in zip(y_true, y_pred)) / len(y_true)\n    print(\"\\nTEST DATASET\")\n    print(f\"test accuracy: {test_accuracy:.4f}\")\nelse:\n    print(\"\\nTEST DATASET\")\n    print(\"test accuracy: N/A  (ground-truth / predictions missing)\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# Locate and load the experiment file\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# Helper to print a metric line\n# ---------------------------------------------------------------------\ndef print_metric(name: str, value: float):\n    print(f\"    {name}: {value:.4f}\")\n\n\n# ---------------------------------------------------------------------\n# Extract the specific experiment branch\n# ---------------------------------------------------------------------\nspr_exp = experiment_data.get(\"UniChain\", {}).get(\"SPR\", {})\n\n# ---------------------------------------------------------------------\n# TRAINING METRICS (final epoch)\n# ---------------------------------------------------------------------\ntrain_losses = spr_exp.get(\"losses\", {}).get(\"train\", [])\ntrain_metrics = spr_exp.get(\"metrics\", {}).get(\"train\", [])\n\nif train_losses and train_metrics:\n    _, final_train_loss = train_losses[-1]\n    _, final_train_pcwa = train_metrics[-1]\n    print(\"Training dataset:\")\n    print_metric(\"final loss\", final_train_loss)\n    print_metric(\"final PCWA\", final_train_pcwa)\n\n# ---------------------------------------------------------------------\n# VALIDATION METRICS (final epoch + best PCWA)\n# ---------------------------------------------------------------------\nval_losses = spr_exp.get(\"losses\", {}).get(\"val\", [])\nval_metrics = spr_exp.get(\"metrics\", {}).get(\"val\", [])\n\nif val_losses and val_metrics:\n    # final epoch values\n    _, final_val_loss = val_losses[-1]\n    _, final_val_pcwa = val_metrics[-1]\n    # best values across epochs\n    best_val_loss = min(l for _, l in val_losses)\n    best_val_pcwa = max(p for _, p in val_metrics)\n\n    print(\"\\nValidation dataset:\")\n    print_metric(\"final loss\", final_val_loss)\n    print_metric(\"best  loss\", best_val_loss)\n    print_metric(\"final PCWA\", final_val_pcwa)\n    print_metric(\"best  PCWA\", best_val_pcwa)\n\n# ---------------------------------------------------------------------\n# TEST METRIC (accuracy only \u2013 predictions vs ground-truth)\n# ---------------------------------------------------------------------\ny_pred = spr_exp.get(\"predictions\", [])\ny_true = spr_exp.get(\"ground_truth\", [])\n\nif y_pred and y_true:\n    test_acc = sum(int(p == t) for p, t in zip(y_pred, y_true)) / len(y_true)\n    print(\"\\nTest dataset:\")\n    print_metric(\"accuracy\", test_acc)\n", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# Locate and load the experiment data -------------\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nnpy_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(npy_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy in {working_dir}\")\n\nexperiment_data = np.load(npy_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------\n# Helper to format floats nicely ------------------\n# -------------------------------------------------\ndef fmt(value, digits=4):\n    return f\"{value:.{digits}f}\"\n\n\n# -------------------------------------------------\n# Extract and print metrics -----------------------\n# -------------------------------------------------\nfor ablation_key, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        print(f\"\\nDataset: {dataset_name}\")\n\n        # ---------- Losses ----------\n        train_losses = data[\"losses\"].get(\"train\", [])\n        val_losses = data[\"losses\"].get(\"val\", [])\n\n        if train_losses:\n            final_train_loss = train_losses[-1][1]\n            print(f\"training loss (final epoch): {fmt(final_train_loss)}\")\n\n        if val_losses:\n            final_val_loss = val_losses[-1][1]\n            print(f\"validation loss (final epoch): {fmt(final_val_loss)}\")\n\n        # ---------- PCWA metrics ----------\n        train_pcwa = data[\"metrics\"].get(\"train\", [])\n        val_pcwa = data[\"metrics\"].get(\"val\", [])\n\n        if train_pcwa:\n            final_train_pcwa = train_pcwa[-1][1]\n            print(f\"training PCWA (final epoch): {fmt(final_train_pcwa)}\")\n\n        if val_pcwa:\n            final_val_pcwa = val_pcwa[-1][1]\n            print(f\"validation PCWA (final epoch): {fmt(final_val_pcwa)}\")\n\n        # ---------- Test accuracy ----------\n        preds = data.get(\"predictions\", [])\n        gts = data.get(\"ground_truth\", [])\n\n        if preds and gts and len(preds) == len(gts):\n            correct = sum(int(p == y) for p, y in zip(preds, gts))\n            test_acc = correct / len(gts)\n            print(f\"test accuracy: {fmt(test_acc)}\")\n"], "parse_term_out": ["['Dataset: SPR', '\\n', 'Best training loss: 0.6057', '\\n', 'Best validation\nloss: 0.6010', '\\n', 'Best training PCWA: 0.6966', '\\n', 'Best validation PCWA:\n0.6968', '\\n', 'Test accuracy: 0.6750', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['\\nDataset: A_max8_balanced', '\\n', 'best train PCWA: 0.669', '\\n', 'best\nvalidation PCWA: 0.677', '\\n', 'best train loss: 0.603', '\\n', 'best validation\nloss: 0.601', '\\n', 'test PCWA: 0.690', '\\n', 'test CWA: 0.645', '\\n', 'test\nSWA: 0.739', '\\n', 'test ACC: 0.698', '\\n', '\\nDataset: B_max12_shapeBias',\n'\\n', 'best train PCWA: 0.670', '\\n', 'best validation PCWA: 0.668', '\\n', 'best\ntrain loss: 0.608', '\\n', 'best validation loss: 0.620', '\\n', 'test PCWA:\n0.663', '\\n', 'test CWA: 0.670', '\\n', 'test SWA: 0.664', '\\n', 'test ACC:\n0.670', '\\n', '\\nDataset: C_max20_colorBias', '\\n', 'best train PCWA: 0.846',\n'\\n', 'best validation PCWA: 0.845', '\\n', 'best train loss: 0.417', '\\n', 'best\nvalidation loss: 0.401', '\\n', 'test PCWA: 0.853', '\\n', 'test CWA: 0.819',\n'\\n', 'test SWA: 0.871', '\\n', 'test ACC: 0.838', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['Training dataset:', '\\n', 'training PCWA: 0.6992', '\\n', 'training loss:\n0.6104', '\\n', '\\nValidation dataset:', '\\n', 'validation PCWA: 0.7086', '\\n',\n'validation loss: 0.6018', '\\n', '\\nTest dataset:', '\\n', 'test accuracy:\n0.6625', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR', '\\n', 'training PCWA: 0.7003', '\\n', 'validation PCWA: 0.6897',\n'\\n', 'training loss: 0.5954', '\\n', 'validation loss: 0.6130', '\\n', 'test\naccuracy: 0.6650', '\\n', '\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']", "['Dataset: SPR', '\\n', 'Best train loss: 0.6378 (epoch 5)', '\\n', 'Best\nvalidation loss: 0.5981 (epoch 1)', '\\n', 'Best train PCWA: 0.6637 (epoch 1)',\n'\\n', 'Best validation PCWA: 0.7246 (epoch 1)', '\\n', 'Test accuracy: 0.6950',\n'\\n', '', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Training:', '\\n', '  Training loss: 0.5934', '\\n', '  Training PCWA: 0.7089',\n'\\n', '\\nValidation:', '\\n', '  Validation loss: 0.5931', '\\n', '  Validation\nPCWA: 0.7108', '\\n', '\\nTest:', '\\n', '  Test accuracy: 0.6475', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['TRAIN DATASET', '\\n', 'best training loss: 0.6309', '\\n', 'best training PCWA:\n0.6717', '\\n', '\\nVALIDATION DATASET', '\\n', 'best validation loss: 0.6207',\n'\\n', 'best validation PCWA: 0.6734', '\\n', '\\nTEST DATASET', '\\n', 'test\naccuracy: 0.6550', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Training dataset:', '\\n', '    final loss: 0.6109', '\\n', '    final PCWA:\n0.6928', '\\n', '\\nValidation dataset:', '\\n', '    final loss: 0.6376', '\\n', '\nbest  loss: 0.6324', '\\n', '    final PCWA: 0.6622', '\\n', '    best  PCWA:\n0.6622', '\\n', '\\nTest dataset:', '\\n', '    accuracy: 0.6700', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR', '\\n', 'training loss (final epoch): 0.6110', '\\n',\n'validation loss (final epoch): 0.6121', '\\n', 'training PCWA (final epoch):\n0.7076', '\\n', 'validation PCWA (final epoch): 0.7189', '\\n', 'test accuracy:\n0.7025', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']"], "parse_exc_type": [null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
