\begin{thebibliography}{10}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bortolotti et~al.(2024)Bortolotti, Marconato, Carraro, Morettin, van
  Krieken, Vergari, Teso, and Passerini]{bortolotti2024anb}
Samuele Bortolotti, Emanuele Marconato, Tommaso Carraro, Paolo Morettin, Emile
  van Krieken, Antonio Vergari, Stefano Teso, and Andrea Passerini.
\newblock A neuro-symbolic benchmark suite for concept quality and reasoning
  shortcuts.
\newblock 2024.

\bibitem[Cinque et~al.(2022)Cinque, Battiloro, and
  Lorenzo]{cinque2022poolingsf}
Domenico~Mattia Cinque, Claudio Battiloro, and P.~Lorenzo.
\newblock Pooling strategies for simplicial convolutional networks.
\newblock \emph{ICASSP 2023 - 2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  1--5, 2022.

\bibitem[Diao \& Loynd(2022)Diao and Loynd]{diao2022relationalag}
Cameron Diao and Ricky Loynd.
\newblock Relational attention: Generalizing transformers for graph-structured
  tasks.
\newblock \emph{ArXiv}, abs/2210.05062, 2022.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, Courville, and
  Bengio]{goodfellow2016deep}
Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio.
\newblock \emph{Deep learning}, volume~1.
\newblock MIT Press, 2016.

\bibitem[Liu et~al.(2025)Liu, Feng, Shen, Liu, Wan, and Sun]{liu2025vcra}
Sannyuya Liu, Jintian Feng, Xiaoxuan Shen, Shengyingjie Liu, Qian Wan, and
  Jianwen Sun.
\newblock Vcr: A "cone of experience" driven synthetic data generation
  framework for mathematical reasoning.
\newblock pp.\  24650--24658, 2025.

\bibitem[Wu et~al.(2019)Wu, Pan, Chen, Long, Zhang, and Yu]{wu2019acs}
Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and
  Philip~S. Yu.
\newblock A comprehensive survey on graph neural networks.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  32:\penalty0 4--24, 2019.

\bibitem[Xu et~al.(2018)Xu, Hu, Leskovec, and Jegelka]{xu2018howpa}
Keyulu Xu, Weihua Hu, J.~Leskovec, and S.~Jegelka.
\newblock How powerful are graph neural networks?
\newblock \emph{ArXiv}, abs/1810.00826, 2018.

\bibitem[Zhang et~al.(2022)Zhang, Zhang, Li, and Xing]{zhang2022evaluatingsr}
Hanlin Zhang, Yi-Fan Zhang, Li~Erran Li, and Eric~P. Xing.
\newblock Evaluating step-by-step reasoning through symbolic verification.
\newblock pp.\  2984--3002, 2022.

\bibitem[Zhang et~al.(2024)Zhang, Jiang, and You]{zhang2024cdfgnnas}
Shuai Zhang, Zite Jiang, and Haihang You.
\newblock Cdfgnn: a systematic design of cache-based distributed full-batch
  graph neural network training with communication reduction.
\newblock \emph{ArXiv}, abs/2408.00232, 2024.

\bibitem[Zheng et~al.(2020)Zheng, Zhou, Li, Wang, and Gao]{zheng2020graphnn}
Xuebin Zheng, Bingxin Zhou, Ming Li, Yu~Guang Wang, and Junbin Gao.
\newblock Graph neural networks with haar transform-based convolution and
  pooling: A complete guide.
\newblock \emph{ArXiv}, abs/2007.11202, 2020.

\end{thebibliography}
