
% This paper, 'Neural-symbolic integration and the Semantic Web' by Hitzler et al., provides a foundational perspective on neural-symbolic integration, discussing its principles, challenges, and benefits. It is relevant to the proposed research as it contextualizes the integration of neural networks with symbolic reasoning frameworks, which is central to the hypothesis. This citation should appear in the introduction to support the foundational motivation for the research.
@article{hitzler2020neuralsymbolicia,
 author = {P. Hitzler and Federico Bianchi and Monireh Ebrahimi and Md Kamruzzaman Sarker},
 booktitle = {Semantic Web},
 journal = {Semantic Web},
 pages = {3-11},
 title = {Neural-symbolic integration and the Semantic Web},
 volume = {11},
 year = {2020}
}

% The paper 'Mind Reasoning Manners: Enhancing Type Perception for Generalized Zero-Shot Logical Reasoning Over Text' introduces a benchmark (ZsLR) for generalized zero-shot logical reasoning. It highlights the challenges of testing models on unseen reasoning types, which parallels the goals of SPR_BENCH in evaluating the model's ability to generalize to unseen rules. This citation should be included in the related work section to contextualize the design and evaluation of SPR_BENCH.
@article{xu2023mindrm,
 author = {Fangzhi Xu and Jun Liu and Qika Lin and Tianzhe Zhao and Jian Zhang and Lingling Zhang},
 booktitle = {IEEE Transactions on Neural Networks and Learning Systems},
 journal = {IEEE Transactions on Neural Networks and Learning Systems},
 pages = {18499-18511},
 title = {Mind Reasoning Manners: Enhancing Type Perception for Generalized Zero-Shot Logical Reasoning Over Text},
 volume = {35},
 year = {2023}
}

% The paper 'Interpretable Neural-Symbolic Concept Reasoning' introduces the Deep Concept Reasoner (DCR), a model that combines neural networks and symbolic reasoning to improve generalization and interpretability. This is highly relevant to the hypothesis that symbolic reasoning can enhance generalization in neural networks, especially in tasks requiring rule-based abstraction. It should be cited in the related work and methodology sections to strengthen the argument for neural-symbolic integration.
@article{barbiero2023interpretablenc,
 author = {Pietro Barbiero and Gabriele Ciravegna and Francesco Giannini and Mateo Espinosa Zarlenga and Lucie Charlotte Magister and A. Tonda and Pietro Lio' and F. Precioso and M. Jamnik and G. Marra},
 booktitle = {International Workshop on Neural-Symbolic Learning and Reasoning},
 journal = {ArXiv},
 title = {Interpretable Neural-Symbolic Concept Reasoning},
 volume = {abs/2304.14068},
 year = {2023}
}

% The paper 'Graph Knows Unknowns: Reformulate Zero-Shot Learning as Sample-Level Graph Recognition' investigates a novel perspective on zero-shot learning by formulating it as a graph-to-semantics mapping task using graph neural networks. It addresses the domain bias problem, which is a significant challenge in zero-shot learning, and demonstrates competitive performance on benchmark datasets. This work is relevant to the challenges of generalization in zero-shot learning and should be cited in the related work section to contextualize methods and challenges in achieving robust generalization in unseen tasks.
@article{guo2023graphku,
 author = {Jingcai Guo and Song Guo and Qihua Zhou and Ziming Liu and Xiaocheng Lu and Fushuo Huo},
 booktitle = {AAAI Conference on Artificial Intelligence},
 pages = {7775-7783},
 title = {Graph Knows Unknowns: Reformulate Zero-Shot Learning as Sample-Level Graph Recognition},
 year = {2023}
}

% The paper 'A Novel Neural-symbolic System under Statistical Relational Learning' discusses the limitations of current neural-symbolic frameworks, such as integration, generalization, and interpretability, and proposes a novel framework (NSF-SRL) that addresses these issues. It is relevant for highlighting research gaps in symbolic reasoning frameworks, especially in the context of zero-shot scenarios, and should be cited in the introduction or related work section to contextualize the challenges addressed by the proposed model.
@article{yu2023ann,
 author = {Dongran Yu and Xueyan Liu and Shirui Pan and Anchen Li and Bo Yang},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {A Novel Neural-symbolic System under Statistical Relational Learning},
 volume = {abs/2309.08931},
 year = {2023}
}

% The paper 'Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs' introduces a novel zero-shot reasoning algorithm that integrates knowledge graphs with language models and evaluates on benchmark datasets. This work is relevant for contextualizing the use of benchmarks such as SPR_BENCH in zero-shot reasoning tasks and should be cited in the related work section to provide additional context on evaluation methods and benchmarks in this domain.
@article{markowitz2024treeoftraversalsaz,
 author = {Elan Markowitz and Anil Ramakrishna and J. Dhamala and Ninareh Mehrabi and Charith Peris and Rahul Gupta and Kai-Wei Chang and A. Galstyan},
 booktitle = {Annual Meeting of the Association for Computational Linguistics},
 pages = {12302-12319},
 title = {Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs},
 year = {2024}
}

% The paper 'MM-InstructEval: Zero-Shot Evaluation of (Multimodal) Large Language Models on Multimodal Reasoning Tasks' introduces a comprehensive evaluation framework with diverse metrics for multimodal reasoning tasks, including zero-shot evaluation. This is relevant for contextualizing the use of task-specific evaluation metrics like Shape-Weighted Accuracy (SWA) and Color-Weighted Accuracy (CWA) in reasoning tasks. It should be cited in the methodology section to support the importance of robust and diverse evaluation metrics.
@article{yang2024mminstructevalze,
 author = {Xiaocui Yang and Wenfang Wu and Shi Feng and Ming Wang and Daling Wang and Yang Li and Qi Sun and Yifei Zhang and Xiaoming Fu and Soujanya Poria},
 booktitle = {Information Fusion},
 journal = {ArXiv},
 title = {MM-InstructEval: Zero-Shot Evaluation of (Multimodal) Large Language Models on Multimodal Reasoning Tasks},
 volume = {abs/2405.07229},
 year = {2024}
}

% The paper 'Augmenting deep neural networks with symbolic knowledge: Towards trustworthy and interpretable AI for education' discusses key challenges in integrating symbolic reasoning with neural networks, including interpretability, scalability, and biases. This is highly relevant for contextualizing the risk factors and limitations of the proposed neural-symbolic model, particularly in addressing computational complexity and generalization issues. It should be cited in the risk factors and limitations section to strengthen the discussion of these challenges.
@article{hooshyar2023augmentingdn,
 author = {Danial Hooshyar and Roger Azevedo and Yeongwook Yang},
 booktitle = {Machine Learning and Knowledge Extraction},
 journal = {Mach. Learn. Knowl. Extr.},
 pages = {593-618},
 title = {Augmenting deep neural networks with symbolic knowledge: Towards trustworthy and interpretable AI for education},
 volume = {6},
 year = {2023}
}

% The paper 'Explainable Visual Question Answering via Hybrid Neural-Logical Reasoning' discusses a hybrid neural-symbolic reasoning approach with an ablation study of its components. This is relevant to support the methodology section, specifically the ablation study, in the proposed experiments to evaluate the contributions of the neural and symbolic components in the model.
@article{gao2024explainablevq,
 author = {Jingying Gao and Alan Blair and M. Pagnucco},
 booktitle = {IEEE International Joint Conference on Neural Network},
 journal = {2024 International Joint Conference on Neural Networks (IJCNN)},
 pages = {1-10},
 title = {Explainable Visual Question Answering via Hybrid Neural-Logical Reasoning},
 year = {2024}
}
