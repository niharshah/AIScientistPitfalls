<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 8], [0, 1], [0, 2], [0, 3], [0, 7], [0, 4], [3, 5], [3, 6], [7, 9], [7, 11], [7, 12], [7, 10]], "layout": [[0.43589743589743585, 0.0], [0.0, 0.5], [0.15384615384615385, 0.5], [0.3076923076923077, 0.5], [0.46153846153846156, 0.5], [0.23076923076923078, 1.0], [0.38461538461538464, 1.0], [0.7692307692307693, 0.5], [0.9230769230769231, 0.5], [0.5384615384615384, 1.0], [0.6923076923076923, 1.0], [0.8461538461538461, 1.0], [1.0, 1.0]], "plan": ["Below we implement a very first-cut baseline: a light GRU encoder that learns\nfrom SPR_BENCH training examples to predict the rule label. Tokens (e.g. \u201cA1\u201d,\n\u201cB3\u201d) are embedded and mean-pooled before a softmax layer. We track classic\naccuracy plus the requested Zero-Shot Rule Transfer Accuracy (ZSRTA), computed\non test items whose labels never appeared in training. Shape-Weighted and Color-\nWeighted accuracy are also reported. All metrics/losses are stored under\n./working for later analysis.", "Hyperparam tuning name: EPOCHS. We will grid-search the single hyper-parameter\n\u201cnumber of epochs\u201d.   For each candidate epoch value we freshly initialize the\nsame model/optimizer, train for that many epochs, log train/validation curves,\nthen evaluate on the test split.   Results are stored in\n`experiment_data['EPOCHS_TUNING']['SPR_BENCH'][epochs_value]` and finally\nwritten to `experiment_data.npy`.", "Hyperparam tuning name: learning_rate. We will grid-search four learning-rates\n{3e-4, 5e-4, 1e-3, 2e-3}.   For each rate we rebuild the model, train for a few\nepochs, record per-epoch train/validation losses and accuracies, and keep the\nfinal validation accuracy.   After the sweep we pick the rate with the highest\nvalidation accuracy, retrain a fresh model with that rate, and evaluate it on\nthe test split, storing predictions and extra metrics.   All results are\ngathered in the required experiment_data structure and saved to\nexperiment_data.npy.", "Hyperparam tuning name: batch_size. We sweep over several training batch sizes\n(32 \u2013 512), retrain a fresh model for each value, and log per-epoch\ntrain/validation metrics plus final test statistics. All results are stored in\nexperiment_data['batch_size_tuning']['SPR_BENCH']['bs{size}'] and finally saved\nto experiment_data.npy.", "Hyperparam tuning name: dropout_rate. We add an nn.Dropout layer between the\nconcatenated bidirectional-GRU hidden state and the final classifier and sweep\ndropout_rate \u2208 {0.0, 0.2, 0.4, 0.6}.   For every value we train the model for\nthe same number of epochs, record train/validation metrics and keep a copy of\nthe parameters that obtain the highest validation accuracy.   After the sweep we\nreload the best checkpoint, evaluate on the test set, compute all requested\nmetrics, store them in the experiment_data structure under the key\n\"dropout_tuning\", and persist everything with np.save(\"experiment_data.npy\").", "The previous experiment never actually confronted unseen rule labels because\nevery dev/test example was force-mapped to the train label set; any truly novel\nlabel would have raised a KeyError and stopped training.  We fix this by (1)\nletting the dataset keep its raw string labels for all splits; (2) keeping an\n`id` mapping **only for those labels observed in the training split**, while\ndev/test items whose label is unseen are given a sentinel id `-1` that the loss\nignores.  This allows zero-shot items to flow through the pipeline so ZSRTA can\nbe computed correctly.  In addition, evaluation metrics now ignore padding/unk\ntokens when computing shape/color variety and we add the requested Harmonic-Mean\nAccuracy (HMA).  Nothing else in the model architecture is touched, but the last\nlinear layer is automatically resized when the train-label vocabulary changes,\nwhich is permitted because the network topology stays identical.  All metrics\nare logged and saved according to the new guidelines.", "The previous script did not track the requested Shape-Color Harmonic-Mean\nAccuracy (HMA) and therefore could not select hyper-parameters on the proper\ntarget metric.   We fix this by (1) adding an HMA computation, (2) logging SWA,\nCWA and HMA on the dev-set every epoch, and (3) persisting those metrics inside\n`experiment_data` so downstream analysis can pick the best run.   No\narchitectural change is introduced; we only extend the evaluation logic and tidy\nup GPU handling as required by the guidelines.", "Hyperparam tuning name: hidden_dim. The solution iterates over a list of\ncandidate hidden\u2010state sizes (64 / 128 / 256 / 512).   For each size it builds a\nfresh SimpleSPRModel, trains it for a few epochs, evaluates on the dev and test\nsets, records all relevant statistics in a structured experiment_data dictionary\nkeyed by the hyper-parameter value, and finally saves the dictionary to\nexperiment_data.npy.", "Hyperparam tuning name: weight_decay. We grid-search five weight_decay values\nfor the Adam optimizer (0, 1e-6, 1e-5, 1e-4, 1e-3).   For every value we re-\ninstantiate the model, optimizer and train for five epochs, logging\ntrain/validation loss and accuracy.   After training we evaluate on the held-out\ntest set and store all metrics, losses, predictions and ground-truth labels in a\nnested experiment_data dictionary keyed by weight_decay.   Finally the whole\nstructure is saved as experiment_data.npy for later plotting or analysis.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, time, random, math, json, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import DatasetDict\nfrom typing import List, Dict\n\n# ----------------------------------------------------------------------\n# house-keeping / caching\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"val_loss\": [], \"ZSRTA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n# ----------------------------------------------------------------------\n# device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------------------------------------------------------------\n# util from prompt ------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    from datasets import load_dataset\n\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ----------------------------------------------------------------------\n# load data -------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ----------------------------------------------------------------------\n# vocab + label mapping -------------------------------------------------\ndef build_vocab(dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\ndef encode_seq(seq: str, vocab: Dict[str, int]) -> List[int]:\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\n# label ids\ntrain_labels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(train_labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\nprint(f\"#seen rule labels: {num_labels}\")\n\n\n# ----------------------------------------------------------------------\n# Torch Dataset ---------------------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, label2id, train_mode=True):\n        self.seq_enc = [encode_seq(s, vocab) for s in split[\"sequence\"]]\n        self.labels = split[\"label\"]\n        self.train_mode = train_mode\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.seq_enc)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.seq_enc[idx], dtype=torch.long)\n        if self.train_mode:\n            y = torch.tensor(self.label2id[self.labels[idx]], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            return {\"input\": x, \"label_str\": self.labels[idx]}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = [len(x) for x in xs]\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": torch.tensor(lens, dtype=torch.long)}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    else:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id, True)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id, True)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, label2id, False)\n\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=256, shuffle=False, collate_fn=collate)\n\n\n# ----------------------------------------------------------------------\n# Model ----------------------------------------------------------------\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.lin = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x, lengths):\n        e = self.emb(x)  # (B,L,D)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)  # h: (2, B, H)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)  # (B, 2H)\n        logits = self.lin(h_cat)\n        return logits\n\n\nmodel = SimpleSPRModel(len(vocab), 64, 128, num_labels).to(device)\ncriterion = nn.CrossEntropyLoss()\nopt = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ----------------------------------------------------------------------\n# helpers ---------------------------------------------------------------\ndef run_epoch(loader, train=True):\n    if train:\n        model.train()\n    else:\n        model.eval()\n    total_loss, total_ok, total = 0.0, 0, 0\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            lbl = batch[\"label\"].to(device)\n            logits = model(inp, lens)\n            loss = criterion(logits, lbl)\n            if train:\n                opt.zero_grad()\n                loss.backward()\n                opt.step()\n            total_loss += loss.item() * inp.size(0)\n            preds = logits.argmax(1)\n            total_ok += (preds == lbl).sum().item()\n            total += inp.size(0)\n    return total_loss / total, total_ok / total\n\n\n# ----------------------------------------------------------------------\n# training loop ---------------------------------------------------------\nEPOCHS = 5\nfor epoch in range(1, EPOCHS + 1):\n    tr_loss, tr_acc = run_epoch(train_loader, True)\n    val_loss, val_acc = run_epoch(dev_loader, False)\n\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train_acc\"].append(tr_acc)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_acc\"].append(val_acc)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_loss\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"timestamps\"].append(time.time())\n\n    print(\n        f\"Epoch {epoch}: train_acc={tr_acc:.4f}  val_acc={val_acc:.4f}  val_loss={val_loss:.4f}\"\n    )\n\n# ----------------------------------------------------------------------\n# evaluation on test ----------------------------------------------------\nmodel.eval()\nall_preds, all_labels, all_seqs = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        inp = batch[\"input\"].to(device)\n        lens = batch[\"lengths\"].to(device)\n        logits = model(inp, lens)\n        preds = logits.argmax(1).cpu().tolist()\n        label_strs = batch[\"label_str\"]\n        all_preds.extend([id2label.get(p, \"UNK\") for p in preds])\n        all_labels.extend(label_strs)\n        all_seqs.extend(\n            [\n                \" \".join([list(vocab.keys())[tok] for tok in seq.tolist() if tok != 0])\n                for seq in batch[\"input\"]\n            ]\n        )\n\n# compute metrics -------------------------------------------------------\noverall_acc = np.mean([p == t for p, t in zip(all_preds, all_labels)])\nswa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\ncwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n\n# ZSRTA\nseen_rules = set(train_labels)\nzs_indices = [i for i, lbl in enumerate(all_labels) if lbl not in seen_rules]\nif zs_indices:\n    zs_acc = np.mean([all_preds[i] == all_labels[i] for i in zs_indices])\nelse:\n    zs_acc = float(\"nan\")\n\nexperiment_data[\"SPR_BENCH\"][\"metrics\"][\"ZSRTA\"].append(zs_acc)\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = all_preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_labels\n\nprint(\n    f\"\\nTEST Acc: {overall_acc:.4f} | SWA: {swa:.4f} | CWA: {cwa:.4f} | ZSRTA: {zs_acc:.4f}\"\n)\n\n# ----------------------------------------------------------------------\n# save artefacts --------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Experiment data saved to {working_dir}\")\n", "# EPOCHS hyper-parameter tuning for SPR-BENCH\nimport os, pathlib, time, random, math, json, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import DatasetDict\nfrom typing import List, Dict\n\n# ----------------------------------------------------------------------\n# saving dict -----------------------------------------------------------\nexperiment_data = {\"EPOCHS_TUNING\": {\"SPR_BENCH\": {}}}\n\n# ----------------------------------------------------------------------\n# device / seeds --------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nrandom.seed(42)\nnp.random.seed(42)\nprint(f\"Using device: {device}\")\n\n\n# ----------------------------------------------------------------------\n# util functions --------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    from datasets import load_dataset\n\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ----------------------------------------------------------------------\n# data -----------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\ndef build_vocab(dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(\"Vocab size:\", len(vocab))\n\n\ndef encode_seq(seq: str, vocab: Dict[str, int]) -> List[int]:\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\ntrain_labels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(train_labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\nprint(\"#seen rule labels:\", num_labels)\n\n\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, label2id, train_mode=True):\n        self.seq_enc = [encode_seq(s, vocab) for s in split[\"sequence\"]]\n        self.labels = split[\"label\"]\n        self.train_mode = train_mode\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.seq_enc)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.seq_enc[idx], dtype=torch.long)\n        if self.train_mode:\n            y = torch.tensor(self.label2id[self.labels[idx]], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            return {\"input\": x, \"label_str\": self.labels[idx]}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = [len(x) for x in xs]\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": torch.tensor(lens, dtype=torch.long)}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    else:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id, True)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id, True)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, label2id, False)\n\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=256, shuffle=False, collate_fn=collate)\n\n\n# ----------------------------------------------------------------------\n# model def -------------------------------------------------------------\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.lin = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x, lengths):\n        e = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)\n        return self.lin(h_cat)\n\n\n# ----------------------------------------------------------------------\n# training helpers ------------------------------------------------------\ndef run_epoch(model, loader, criterion, opt=None):\n    train = opt is not None\n    model.train() if train else model.eval()\n    total_loss, total_ok, total = 0.0, 0, 0\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            lbl = batch[\"label\"].to(device)\n            logits = model(inp, lens)\n            loss = criterion(logits, lbl)\n            if train:\n                opt.zero_grad()\n                loss.backward()\n                opt.step()\n            total_loss += loss.item() * inp.size(0)\n            total_ok += (logits.argmax(1) == lbl).sum().item()\n            total += inp.size(0)\n    return total_loss / total, total_ok / total\n\n\n# ----------------------------------------------------------------------\n# hyper-parameter grid --------------------------------------------------\nepoch_grid = [5, 10, 15, 20, 25]\n\nfor EPOCHS in epoch_grid:\n    print(f\"\\n=== Training for {EPOCHS} epochs ===\")\n    model = SimpleSPRModel(len(vocab), 64, 128, num_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    # storage for this run\n    run_dict = {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"val_loss\": [], \"ZSRTA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc = run_epoch(model, train_loader, criterion, opt)\n        val_loss, val_acc = run_epoch(model, dev_loader, criterion, None)\n        run_dict[\"metrics\"][\"train_acc\"].append(tr_acc)\n        run_dict[\"metrics\"][\"val_acc\"].append(val_acc)\n        run_dict[\"metrics\"][\"val_loss\"].append(val_loss)\n        run_dict[\"losses\"][\"train\"].append(tr_loss)\n        run_dict[\"losses\"][\"val\"].append(val_loss)\n        run_dict[\"timestamps\"].append(time.time())\n        print(f\"Epoch {epoch}/{EPOCHS}: train_acc={tr_acc:.4f}  val_acc={val_acc:.4f}\")\n\n    # ------------------- evaluate on test ------------------------------\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            logits = model(inp, lens)\n            preds = logits.argmax(1).cpu().tolist()\n            label_strs = batch[\"label_str\"]\n            all_preds.extend([id2label.get(p, \"UNK\") for p in preds])\n            all_labels.extend(label_strs)\n            all_seqs.extend(\n                [\n                    \" \".join(\n                        [list(vocab.keys())[tok] for tok in seq.tolist() if tok != 0]\n                    )\n                    for seq in batch[\"input\"]\n                ]\n            )\n    overall_acc = np.mean([p == t for p, t in zip(all_preds, all_labels)])\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    seen_rules = set(train_labels)\n    zs_idx = [i for i, l in enumerate(all_labels) if l not in seen_rules]\n    zs_acc = (\n        np.mean([all_preds[i] == all_labels[i] for i in zs_idx])\n        if zs_idx\n        else float(\"nan\")\n    )\n    run_dict[\"metrics\"][\"ZSRTA\"].append(zs_acc)\n    run_dict[\"predictions\"] = all_preds\n    run_dict[\"ground_truth\"] = all_labels\n    print(\n        f\"TEST Acc={overall_acc:.4f} | SWA={swa:.4f} | CWA={cwa:.4f} | ZSRTA={zs_acc:.4f}\"\n    )\n\n    experiment_data[\"EPOCHS_TUNING\"][\"SPR_BENCH\"][EPOCHS] = run_dict\n\n# ----------------------------------------------------------------------\n# save artifacts --------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nAll results saved to {working_dir}/experiment_data.npy\")\n", "import os, pathlib, time, random, math, json, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import DatasetDict\n\n# ----------------------------------------------------------------------\n# reproducibility -------------------------------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# ----------------------------------------------------------------------\n# experiment data container -------------------------------------------\nexperiment_data = {\n    \"learning_rate\": {\n        \"SPR_BENCH\": {\n            \"lr_values\": [],\n            \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"val_loss\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"ZSRTA\": [],\n            \"best_lr\": None,\n            \"timestamps\": [],\n        }\n    }\n}\n\n# ----------------------------------------------------------------------\n# house-keeping ---------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------------------------------------------------------------\n# device ---------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------------------------------------------------------------\n# util functions -------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    from datasets import load_dataset\n\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ----------------------------------------------------------------------\n# data -----------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# vocab ----------------------------------------------------------------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\ndef encode_seq(seq, vocab):\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\ntrain_labels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(train_labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\n\n\n# ----------------------------------------------------------------------\n# dataset --------------------------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, label2id, train_mode=True):\n        self.seq_enc = [encode_seq(s, vocab) for s in split[\"sequence\"]]\n        self.labels = split[\"label\"]\n        self.train_mode = train_mode\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.seq_enc)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.seq_enc[idx], dtype=torch.long)\n        if self.train_mode:\n            y = torch.tensor(self.label2id[self.labels[idx]], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            return {\"input\": x, \"label_str\": self.labels[idx]}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = [len(x) for x in xs]\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": torch.tensor(lens, dtype=torch.long)}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    else:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id, True)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id, True)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, label2id, False)\n\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=256, shuffle=False, collate_fn=collate)\n\n\n# ----------------------------------------------------------------------\n# model ----------------------------------------------------------------\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.lin = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x, lengths):\n        e = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)\n        return self.lin(h_cat)\n\n\n# ----------------------------------------------------------------------\n# training helpers -----------------------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train = optimizer is not None\n    model.train() if train else model.eval()\n    total_loss, total_ok, total = 0.0, 0, 0\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            lbl = batch[\"label\"].to(device)\n            logits = model(inp, lens)\n            loss = criterion(logits, lbl)\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            total_loss += loss.item() * inp.size(0)\n            total_ok += (logits.argmax(1) == lbl).sum().item()\n            total += inp.size(0)\n    return total_loss / total, total_ok / total\n\n\ndef train_with_lr(lr, epochs=5):\n    model = SimpleSPRModel(len(vocab), 64, 128, num_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    tr_acc_hist, val_acc_hist, val_loss_hist, tr_loss_hist = [], [], [], []\n    for ep in range(1, epochs + 1):\n        tr_loss, tr_acc = run_epoch(model, train_loader, criterion, optimizer)\n        val_loss, val_acc = run_epoch(model, dev_loader, criterion, None)\n        tr_acc_hist.append(tr_acc)\n        val_acc_hist.append(val_acc)\n        tr_loss_hist.append(tr_loss)\n        val_loss_hist.append(val_loss)\n        print(f\"[lr={lr}] Epoch {ep}: train_acc={tr_acc:.4f} val_acc={val_acc:.4f}\")\n    return model, tr_acc_hist, val_acc_hist, tr_loss_hist, val_loss_hist\n\n\n# ----------------------------------------------------------------------\n# hyperparameter sweep --------------------------------------------------\nlr_grid = [3e-4, 5e-4, 1e-3, 2e-3]\nbest_val_acc, best_lr, best_model_state = -1, None, None\n\nfor lr in lr_grid:\n    model, tr_acc_hist, val_acc_hist, tr_loss_hist, val_loss_hist = train_with_lr(\n        lr, epochs=5\n    )\n    final_val_acc = val_acc_hist[-1]\n    final_val_loss = val_loss_hist[-1]\n\n    # store\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"lr_values\"].append(lr)\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"metrics\"][\"train_acc\"].append(\n        tr_acc_hist\n    )\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"metrics\"][\"val_acc\"].append(\n        val_acc_hist\n    )\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"metrics\"][\"val_loss\"].append(\n        val_loss_hist\n    )\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"losses\"][\"train\"].append(\n        tr_loss_hist\n    )\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss_hist)\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"timestamps\"].append(time.time())\n\n    # best tracking\n    if final_val_acc > best_val_acc:\n        best_val_acc, best_lr = final_val_acc, lr\n        best_model_state = {k: v.cpu() for k, v in model.state_dict().items()}\n\nprint(f\"\\nBest lr selected: {best_lr} with dev acc {best_val_acc:.4f}\")\nexperiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"best_lr\"] = best_lr\n\n# ----------------------------------------------------------------------\n# retrain best model on train+dev and test evaluation ------------------\n# create combined loader\nfull_train_dataset = SPRTorchDataset(\n    DatasetDict(\n        {\n            \"sequence\": spr[\"train\"][\"sequence\"] + spr[\"dev\"][\"sequence\"],\n            \"label\": spr[\"train\"][\"label\"] + spr[\"dev\"][\"label\"],\n        }\n    ),\n    vocab,\n    label2id,\n    True,\n)\nfull_train_loader = DataLoader(\n    full_train_dataset, batch_size=128, shuffle=True, collate_fn=collate\n)\n\nbest_model = SimpleSPRModel(len(vocab), 64, 128, num_labels).to(device)\nbest_model.load_state_dict(best_model_state)  # start from earlier weights\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(best_model.parameters(), lr=best_lr)\n\nfor ep in range(2):  # a couple extra epochs on combined\n    run_epoch(best_model, full_train_loader, criterion, optimizer)\n\n# evaluation on test ---------------------------------------------------\nbest_model.eval()\nall_preds, all_labels, all_seqs = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        inp = batch[\"input\"].to(device)\n        lens = batch[\"lengths\"].to(device)\n        logits = best_model(inp, lens)\n        preds = logits.argmax(1).cpu().tolist()\n        label_strs = batch[\"label_str\"]\n        all_preds.extend([id2label.get(p, \"UNK\") for p in preds])\n        all_labels.extend(label_strs)\n        all_seqs.extend(\n            [\n                \" \".join([list(vocab.keys())[tok] for tok in seq.tolist() if tok != 0])\n                for seq in batch[\"input\"]\n            ]\n        )\n\noverall_acc = np.mean([p == t for p, t in zip(all_preds, all_labels)])\nswa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\ncwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\nseen_rules = set(train_labels)\nzs_indices = [i for i, lbl in enumerate(all_labels) if lbl not in seen_rules]\nzs_acc = (\n    np.mean([all_preds[i] == all_labels[i] for i in zs_indices])\n    if zs_indices\n    else float(\"nan\")\n)\n\nprint(\n    f\"\\nTEST Acc: {overall_acc:.4f} | SWA: {swa:.4f} | CWA: {cwa:.4f} | ZSRTA: {zs_acc:.4f}\"\n)\n\nexperiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"predictions\"] = all_preds\nexperiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"ground_truth\"] = all_labels\nexperiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"ZSRTA\"].append(zs_acc)\n\n# ----------------------------------------------------------------------\n# save data ------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Results saved to {working_dir}/experiment_data.npy\")\n", "import os, pathlib, time, random, math, json, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import DatasetDict, load_dataset\nfrom typing import List, Dict\n\n# ----------------------------------------------------------------------\n# reproducibility -------------------------------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\n# ----------------------------------------------------------------------\n# experiment data skeleton ---------------------------------------------\nexperiment_data = {\"batch_size_tuning\": {\"SPR_BENCH\": {}}}\n\n# ----------------------------------------------------------------------\n# device ----------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------------------------------------------------------------\n# util ------------------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    for spl in [\"train\", \"dev\", \"test\"]:\n        dset[spl] = _load(f\"{spl}.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ----------------------------------------------------------------------\n# data ------------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\ndef build_vocab(dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\ndef encode_seq(seq: str, vocab: Dict[str, int]) -> List[int]:\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\ntrain_labels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(train_labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\nprint(f\"#seen rule labels: {num_labels}\")\n\n\n# ----------------------------------------------------------------------\n# torch dataset ---------------------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, label2id, train_mode=True):\n        self.seq_enc = [encode_seq(s, vocab) for s in split[\"sequence\"]]\n        self.labels = split[\"label\"]\n        self.train_mode = train_mode\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.seq_enc)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.seq_enc[idx], dtype=torch.long)\n        if self.train_mode:\n            y = torch.tensor(self.label2id[self.labels[idx]], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            return {\"input\": x, \"label_str\": self.labels[idx]}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = [len(x) for x in xs]\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": torch.tensor(lens, dtype=torch.long)}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    else:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id, True)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id, True)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, label2id, False)\n\nDEV_TEST_BS = 256  # fixed for eval\n\n\n# ----------------------------------------------------------------------\n# model -----------------------------------------------------------------\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.lin = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x, lengths):\n        e = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)  # (2,B,H)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)\n        return self.lin(h_cat)\n\n\n# ----------------------------------------------------------------------\n# training utilities ----------------------------------------------------\ndef run_epoch(model, loader, criterion, opt=None):\n    train = opt is not None\n    model.train() if train else model.eval()\n    total_loss, total_ok, total = 0.0, 0, 0\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            lbl = batch[\"label\"].to(device)\n            logits = model(inp, lens)\n            loss = criterion(logits, lbl)\n            if train:\n                opt.zero_grad()\n                loss.backward()\n                opt.step()\n            total_loss += loss.item() * inp.size(0)\n            preds = logits.argmax(1)\n            total_ok += (preds == lbl).sum().item()\n            total += inp.size(0)\n    return total_loss / total, total_ok / total\n\n\ndef evaluate_on_test(model):\n    test_loader = DataLoader(\n        test_ds, batch_size=DEV_TEST_BS, shuffle=False, collate_fn=collate\n    )\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            logits = model(inp, lens)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend([id2label.get(p, \"UNK\") for p in preds])\n            all_labels.extend(batch[\"label_str\"])\n            all_seqs.extend(\n                [\n                    \" \".join(\n                        [list(vocab.keys())[tok] for tok in seq.tolist() if tok != 0]\n                    )\n                    for seq in batch[\"input\"]\n                ]\n            )\n    overall_acc = np.mean([p == t for p, t in zip(all_preds, all_labels)])\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    seen_rules = set(train_labels)\n    zs_ids = [i for i, lbl in enumerate(all_labels) if lbl not in seen_rules]\n    zs_acc = (\n        np.mean([all_preds[i] == all_labels[i] for i in zs_ids])\n        if zs_ids\n        else float(\"nan\")\n    )\n    return overall_acc, swa, cwa, zs_acc, all_preds, all_labels\n\n\n# ----------------------------------------------------------------------\n# hyperparameter sweep --------------------------------------------------\nBATCH_SIZES = [32, 64, 128, 256, 512]\nEPOCHS = 5\n\nfor bs in BATCH_SIZES:\n    print(f\"\\n===== Training with batch size {bs} =====\")\n    tag = f\"bs{bs}\"\n    experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"][tag] = {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"val_loss\": [], \"ZSRTA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n\n    train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate)\n    dev_loader = DataLoader(\n        dev_ds, batch_size=DEV_TEST_BS, shuffle=False, collate_fn=collate\n    )\n\n    model = SimpleSPRModel(len(vocab), 64, 128, num_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc = run_epoch(model, train_loader, criterion, opt)\n        val_loss, val_acc = run_epoch(model, dev_loader, criterion)\n        print(\n            f\"Epoch {epoch}: train_acc={tr_acc:.4f} val_acc={val_acc:.4f} val_loss={val_loss:.4f}\"\n        )\n        ed = experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"][tag]\n        ed[\"metrics\"][\"train_acc\"].append(tr_acc)\n        ed[\"metrics\"][\"val_acc\"].append(val_acc)\n        ed[\"metrics\"][\"val_loss\"].append(val_loss)\n        ed[\"losses\"][\"train\"].append(tr_loss)\n        ed[\"losses\"][\"val\"].append(val_loss)\n        ed[\"timestamps\"].append(time.time())\n\n    # ------------------ test ------------------------------------------------\n    overall_acc, swa, cwa, zs_acc, preds, truth = evaluate_on_test(model)\n    print(\n        f\"TEST Acc: {overall_acc:.4f} | SWA: {swa:.4f} | CWA: {cwa:.4f} | ZSRTA: {zs_acc:.4f}\"\n    )\n    ed = experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"][tag]\n    ed[\"metrics\"][\"ZSRTA\"].append(zs_acc)\n    ed[\"predictions\"] = preds\n    ed[\"ground_truth\"] = truth\n\n# ----------------------------------------------------------------------\n# save all experiment data ---------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nAll experiment data serialized to {working_dir}/experiment_data.npy\")\n", "import os, pathlib, time, random, math, json, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import DatasetDict\nfrom typing import List, Dict\n\n# ---------------------------------------------------------\n# reproducibility\nSEED = 2024\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\n# ---------------------------------------------------------\n# experiment bookkeeping\nexperiment_data = {\n    \"dropout_tuning\": {}  # a dict keyed by dropout value that will hold metrics\n}\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------\n# device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------\n# util\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    from datasets import load_dataset\n\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------------------------------------------------------\n# data\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# vocab + label mapping\ndef build_vocab(dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\ndef encode_seq(seq: str, vocab: Dict[str, int]) -> List[int]:\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\ntrain_labels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(train_labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\nprint(f\"#seen rule labels: {num_labels}\")\n\n\n# ---------------------------------------------------------\n# Torch dataset\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, label2id, train_mode=True):\n        self.seq_enc = [encode_seq(s, vocab) for s in split[\"sequence\"]]\n        self.labels = split[\"label\"]\n        self.train_mode = train_mode\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.seq_enc)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.seq_enc[idx], dtype=torch.long)\n        if self.train_mode:\n            y = torch.tensor(self.label2id[self.labels[idx]], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            return {\"input\": x, \"label_str\": self.labels[idx]}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = [len(x) for x in xs]\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": torch.tensor(lens, dtype=torch.long)}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    else:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id, True)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id, True)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, label2id, False)\n\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=256, shuffle=False, collate_fn=collate)\n\n\n# ---------------------------------------------------------\n# Model with dropout\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, dropout_rate=0.0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.lin = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x, lengths):\n        e = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)  # h: (2,B,H)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)  # (B,2H)\n        h_cat = self.dropout(h_cat)\n        logits = self.lin(h_cat)\n        return logits\n\n\n# ---------------------------------------------------------\n# training / eval helpers\ndef run_epoch(model, loader, criterion, opt=None):\n    train = opt is not None\n    model.train() if train else model.eval()\n    total_loss, total_ok, total = 0.0, 0, 0\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            if train:\n                lbl = batch[\"label\"].to(device)\n            else:\n                lbl = batch[\"label\"].to(device)\n            logits = model(inp, lens)\n            loss = criterion(logits, lbl)\n            if train:\n                opt.zero_grad()\n                loss.backward()\n                opt.step()\n            total_loss += loss.item() * inp.size(0)\n            preds = logits.argmax(1)\n            total_ok += (preds == lbl).sum().item()\n            total += inp.size(0)\n    return total_loss / total, total_ok / total\n\n\n# ---------------------------------------------------------\n# hyperparameter sweep\ndropout_values = [0.0, 0.2, 0.4, 0.6]\nEPOCHS = 5\nbest_val_acc, best_state, best_dropout = -1, None, None\n\nfor d_rate in dropout_values:\n    print(f\"\\n=== Training with dropout={d_rate} ===\")\n    exp_key = f\"dropout_{d_rate}\"\n    experiment_data[\"dropout_tuning\"][exp_key] = {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"val_loss\": [], \"ZSRTA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    model = SimpleSPRModel(len(vocab), 64, 128, num_labels, dropout_rate=d_rate).to(\n        device\n    )\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc = run_epoch(model, train_loader, criterion, opt)\n        val_loss, val_acc = run_epoch(model, dev_loader, criterion, None)\n\n        ed = experiment_data[\"dropout_tuning\"][exp_key]\n        ed[\"metrics\"][\"train_acc\"].append(tr_acc)\n        ed[\"metrics\"][\"val_acc\"].append(val_acc)\n        ed[\"metrics\"][\"val_loss\"].append(val_loss)\n        ed[\"losses\"][\"train\"].append(tr_loss)\n        ed[\"losses\"][\"val\"].append(val_loss)\n        ed[\"timestamps\"].append(time.time())\n\n        print(\n            f\"  Epoch {epoch}: train_acc={tr_acc:.4f} val_acc={val_acc:.4f} val_loss={val_loss:.4f}\"\n        )\n\n    # keep best model based on final val acc\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_state = model.state_dict()\n        best_dropout = d_rate\n\nprint(f\"\\nBest dropout according to dev accuracy: {best_dropout} ({best_val_acc:.4f})\")\n\n# ---------------------------------------------------------\n# test evaluation with best model\nbest_model = SimpleSPRModel(\n    len(vocab), 64, 128, num_labels, dropout_rate=best_dropout\n).to(device)\nbest_model.load_state_dict(best_state)\nbest_model.eval()\n\nall_preds, all_labels, all_seqs = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        inp = batch[\"input\"].to(device)\n        lens = batch[\"lengths\"].to(device)\n        logits = best_model(inp, lens)\n        preds = logits.argmax(1).cpu().tolist()\n        label_strs = batch[\"label_str\"]\n        all_preds.extend([id2label.get(p, \"UNK\") for p in preds])\n        all_labels.extend(label_strs)\n        all_seqs.extend(\n            [\n                \" \".join([list(vocab.keys())[tok] for tok in seq.tolist() if tok != 0])\n                for seq in batch[\"input\"]\n            ]\n        )\n\noverall_acc = np.mean([p == t for p, t in zip(all_preds, all_labels)])\nswa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\ncwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\nseen_rules = set(train_labels)\nzs_indices = [i for i, lbl in enumerate(all_labels) if lbl not in seen_rules]\nzs_acc = (\n    np.mean([all_preds[i] == all_labels[i] for i in zs_indices])\n    if zs_indices\n    else float(\"nan\")\n)\n\nbest_key = f\"dropout_{best_dropout}\"\nexperiment_data[\"dropout_tuning\"][best_key][\"metrics\"][\"ZSRTA\"].append(zs_acc)\nexperiment_data[\"dropout_tuning\"][best_key][\"predictions\"] = all_preds\nexperiment_data[\"dropout_tuning\"][best_key][\"ground_truth\"] = all_labels\n\nprint(\n    f\"\\nTEST Acc: {overall_acc:.4f} | SWA: {swa:.4f} | CWA: {cwa:.4f} | ZSRTA: {zs_acc:.4f}\"\n)\n\n# ---------------------------------------------------------\n# save artefacts\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Experiment data saved to {working_dir}\")\n", "import os, pathlib, time, random, math, json, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import DatasetDict, load_dataset\nfrom typing import List, Dict\n\n# ----------------------------------------------------------------------\n# working dir & reproducibility ----------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\n# ----------------------------------------------------------------------\n# GPU / CPU -------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ----------------------------------------------------------------------\n# experiment data skeleton ---------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\n            \"train_acc\": [],\n            \"val_acc\": [],\n            \"val_loss\": [],\n            \"swa\": [],\n            \"cwa\": [],\n            \"hma\": [],\n            \"zs_acc\": [],\n        },\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\n# ----------------------------------------------------------------------\n# data helpers ----------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    out = DatasetDict()\n    for sp in [\"train\", \"dev\", \"test\"]:\n        out[sp] = _load(f\"{sp}.csv\")\n    return out\n\n\ndef build_vocab(dataset) -> Dict[str, int]:\n    \"\"\"token -> id; id 0=<pad>, 1=<unk>\"\"\"\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef encode_seq(seq: str, vocab: Dict[str, int]) -> List[int]:\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\ndef count_shape_variety(sequence: str) -> int:\n    toks = [t for t in sequence.strip().split() if t not in {\"<pad>\", \"<unk>\"}]\n    return len(set(tok[0] for tok in toks))\n\n\ndef count_color_variety(sequence: str) -> int:\n    toks = [t for t in sequence.strip().split() if t not in {\"<pad>\", \"<unk>\"}]\n    return len(set(tok[1] for tok in toks if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) else 0.0\n\n\ndef harmonic_mean(a, b):\n    return 2 * a * b / (a + b) if (a + b) else 0.0\n\n\n# ----------------------------------------------------------------------\n# datasets --------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\nvocab = build_vocab(spr[\"train\"])\nid2tok = {i: t for t, i in vocab.items()}\nprint(f\"Vocab size: {len(vocab)}\")\n\ntrain_label_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(train_label_set)}\nid2label = {i: l for l, i in label2id.items()}\nnum_train_labels = len(label2id)\nprint(f\"# train labels: {num_train_labels}\")\n\n\n# ----------------------------------------------------------------------\n# torch dataset ---------------------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split, vocab, label2id, train_mode=True):\n        self.seqs = hf_split[\"sequence\"]\n        self.seq_enc = [encode_seq(s, vocab) for s in self.seqs]\n        self.labels = hf_split[\"label\"]\n        self.train_mode = train_mode\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.seq_enc)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.seq_enc[idx], dtype=torch.long)\n        y_str = self.labels[idx]\n        if self.train_mode:\n            y = torch.tensor(self.label2id[y_str], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            # unseen labels mapped to -1 sentinel\n            y = torch.tensor(self.label2id.get(y_str, -1), dtype=torch.long)\n            return {\"input\": x, \"label\": y, \"label_str\": y_str}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = torch.tensor([len(x) for x in xs], dtype=torch.long)\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": lens}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    if \"label_str\" in batch[0]:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id, True)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id, False)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, label2id, False)\n\n\n# ----------------------------------------------------------------------\n# model -----------------------------------------------------------------\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.lin = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, tok_ids, lengths):\n        x = self.emb(tok_ids)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)  # (2,B,H)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)\n        return self.lin(h_cat)\n\n\n# ----------------------------------------------------------------------\n# training helpers ------------------------------------------------------\ndef run_epoch(model, loader, criterion, opt=None):\n    train = opt is not None\n    model.train() if train else model.eval()\n    total_loss, total_ok, total = 0.0, 0, 0\n    for batch in loader:\n        # move tensor items to device\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        logits = model(batch[\"input\"], batch[\"lengths\"])\n        loss_mask = batch[\"label\"] != -1  # mask for zero-shot samples\n        if loss_mask.any():\n            loss = criterion(logits[loss_mask], batch[\"label\"][loss_mask])\n        else:\n            # no supervised instances inside this batch (unlikely)\n            loss = torch.zeros(1, device=device, requires_grad=train)\n        if train:\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n        with torch.no_grad():\n            preds = logits.argmax(1)\n            supervised = loss_mask\n            if supervised.any():\n                total_ok += (\n                    (preds[supervised] == batch[\"label\"][supervised]).sum().item()\n                )\n                total += supervised.sum().item()\n            total_loss += loss.item() * loss_mask.sum().item()\n    acc = total_ok / total if total else 0.0\n    avg_loss = total_loss / total if total else 0.0\n    return avg_loss, acc\n\n\ndef evaluate(model, dataset):\n    loader = DataLoader(dataset, batch_size=256, shuffle=False, collate_fn=collate)\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            raw_input = batch[\"input\"]\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input\"], batch[\"lengths\"])\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend([id2label[p] if p in id2label else \"UNK\" for p in preds])\n            all_labels.extend(batch[\"label_str\"])\n            # reconstruct sequence\n            for seq in raw_input:\n                toks = [\n                    id2tok.get(tid, \"<unk>\") for tid in seq.tolist() if tid not in (0,)\n                ]\n                all_seqs.append(\" \".join(toks))\n    overall_acc = np.mean([p == t for p, t in zip(all_preds, all_labels)])\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    hma = harmonic_mean(swa, cwa)\n    seen = set(train_label_set)\n    zs_ids = [i for i, lbl in enumerate(all_labels) if lbl not in seen]\n    zs_acc = np.mean([all_preds[i] == all_labels[i] for i in zs_ids]) if zs_ids else 0.0\n    return overall_acc, swa, cwa, hma, zs_acc, all_preds, all_labels\n\n\n# ----------------------------------------------------------------------\n# hyper-parameter tuning (batch size only) ------------------------------\nBATCH_SIZES = [32, 64, 128, 256, 512]\nEPOCHS = 5\n\nfor bs in BATCH_SIZES:\n    print(f\"\\n===== Training with batch size {bs} =====\")\n    train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate)\n    dev_loader = DataLoader(dev_ds, batch_size=256, shuffle=False, collate_fn=collate)\n\n    model = SimpleSPRModel(len(vocab), 64, 128, num_train_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc = run_epoch(model, train_loader, criterion, optim)\n        val_loss, val_acc = run_epoch(model, dev_loader, criterion, None)\n        overall_acc, swa, cwa, hma, zs_acc, _, _ = evaluate(model, dev_ds)\n        print(\n            f\"Epoch {epoch}: train_acc={tr_acc:.4f} val_acc={val_acc:.4f} \"\n            f\"val_loss={val_loss:.4f} HMA={hma:.4f}\"\n        )\n\n        experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train_acc\"].append(tr_acc)\n        experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_acc\"].append(val_acc)\n        experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_loss\"].append(val_loss)\n        experiment_data[\"SPR_BENCH\"][\"metrics\"][\"swa\"].append(swa)\n        experiment_data[\"SPR_BENCH\"][\"metrics\"][\"cwa\"].append(cwa)\n        experiment_data[\"SPR_BENCH\"][\"metrics\"][\"hma\"].append(hma)\n        experiment_data[\"SPR_BENCH\"][\"metrics\"][\"zs_acc\"].append(zs_acc)\n        experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n        experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n        experiment_data[\"SPR_BENCH\"][\"timestamps\"].append(time.time())\n\n    # final test evaluation ------------------------------------------------\n    overall_acc, swa, cwa, hma, zs_acc, preds, truth = evaluate(model, test_ds)\n    print(\n        f\"TEST  acc={overall_acc:.4f} SWA={swa:.4f} CWA={cwa:.4f} \"\n        f\"HMA={hma:.4f} ZSRTA={zs_acc:.4f}\"\n    )\n\n    experiment_data[\"SPR_BENCH\"][\"predictions\"].append(preds)\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"].append(truth)\n\n# ----------------------------------------------------------------------\n# save all experiment data ---------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nAll experiment data saved to {working_dir}/experiment_data.npy\")\n", "import os, pathlib, time, random, math, json\nimport numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom typing import Dict, List\n\n# ---------------------------------------------------------------------\n# mandatory working directory & reproducibility -----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\n# ---------------------------------------------------------------------\n# device announcement --------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# metrics --------------------------------------------------------------\ndef count_shape_variety(seq: str) -> int:\n    return len({tok[0] for tok in seq.strip().split() if tok})\n\n\ndef count_color_variety(seq: str) -> int:\n    return len({tok[1] for tok in seq.strip().split() if len(tok) > 1})\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) else 0.0\n\n\ndef harmonic_mean(a, b):\n    return 2 * a * b / (a + b) if (a + b) else 0.0\n\n\n# ---------------------------------------------------------------------\n# data helpers ---------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for spl in [\"train\", \"dev\", \"test\"]:\n        d[spl] = _load(f\"{spl}.csv\")\n    return d\n\n\ndef build_vocab(dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef encode_seq(seq: str, vocab: Dict[str, int]) -> List[int]:\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\n# ---------------------------------------------------------------------\n# torch dataset --------------------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, label2id, train=True):\n        self.inputs = [encode_seq(s, vocab) for s in split[\"sequence\"]]\n        self.labels_str = split[\"label\"]\n        self.train = train\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.inputs[idx], dtype=torch.long)\n        if self.train:\n            y = torch.tensor(self.label2id[self.labels_str[idx]], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            return {\"input\": x, \"label_str\": self.labels_str[idx]}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = torch.tensor([len(x) for x in xs], dtype=torch.long)\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": lens}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    else:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\n# ---------------------------------------------------------------------\n# model ----------------------------------------------------------------\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hid_dim, num_labels):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True, bidirectional=True)\n        self.lin = nn.Linear(hid_dim * 2, num_labels)\n\n    def forward(self, x, lengths):\n        e = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)  # (2,B,H)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)\n        return self.lin(h_cat)\n\n\n# ---------------------------------------------------------------------\n# training / evaluation helpers ---------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    is_train = optimizer is not None\n    model.train() if is_train else model.eval()\n    total_loss, total_ok, total = 0.0, 0, 0\n    for batch in loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        logits = model(batch[\"input\"], batch[\"lengths\"])\n        loss = criterion(logits, batch[\"label\"])\n        if is_train:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        total_loss += loss.item() * batch[\"input\"].size(0)\n        preds = logits.argmax(-1)\n        total_ok += (preds == batch[\"label\"]).sum().item()\n        total += batch[\"input\"].size(0)\n    return total_loss / total, total_ok / total\n\n\ndef decode_sequences(tensor_batch, id2tok):\n    seqs = []\n    for row in tensor_batch:\n        tokens = [id2tok[idx] for idx in row.tolist() if idx != 0]\n        seqs.append(\" \".join(tokens))\n    return seqs\n\n\ndef evaluate_full(model, loader, id2label, id2tok, seen_labels):\n    model.eval()\n    all_preds, all_truth, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            logits = model(inp, lens)\n            preds = logits.argmax(-1).cpu().tolist()\n            seqs = decode_sequences(batch[\"input\"], id2tok)\n            all_preds.extend([id2label[p] for p in preds])\n            all_truth.extend(batch[\"label_str\"])\n            all_seqs.extend(seqs)\n    acc = np.mean([p == t for p, t in zip(all_preds, all_truth)])\n    swa = shape_weighted_accuracy(all_seqs, all_truth, all_preds)\n    cwa = color_weighted_accuracy(all_seqs, all_truth, all_preds)\n    hma = harmonic_mean(swa, cwa)\n    zs_ids = [i for i, t in enumerate(all_truth) if t not in seen_labels]\n    zs_acc = (\n        np.mean([all_preds[i] == all_truth[i] for i in zs_ids])\n        if zs_ids\n        else float(\"nan\")\n    )\n    return acc, swa, cwa, hma, zs_acc, all_preds, all_truth\n\n\n# ---------------------------------------------------------------------\n# experiment data container -------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"val_HMA\": [], \"val_loss\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ---------------------------------------------------------------------\n# load data ------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\ndsets = load_spr_bench(DATA_PATH)\nvocab = build_vocab(dsets[\"train\"])\nid2tok = {i: tok for tok, i in vocab.items()}\n\nlabels_seen = sorted(set(dsets[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(labels_seen)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\n\ntrain_ds = SPRTorchDataset(dsets[\"train\"], vocab, label2id, train=True)\ndev_ds = SPRTorchDataset(dsets[\"dev\"], vocab, label2id, train=False)\ntest_ds = SPRTorchDataset(dsets[\"test\"], vocab, label2id, train=False)\n\n# ---------------------------------------------------------------------\n# hyper-parameter grid -------------------------------------------------\nBATCH_SIZES = [64, 128, 256]\nLR = 1e-3\nEPOCHS = 5\nDEV_TEST_BS = 256\n\nfor bs in BATCH_SIZES:\n    print(f\"\\n=== Batch-size sweep: {bs} ===\")\n    train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate)\n    dev_loader = DataLoader(\n        dev_ds, batch_size=DEV_TEST_BS, shuffle=False, collate_fn=collate\n    )\n    model = SimpleSPRModel(len(vocab), 64, 128, num_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc = run_epoch(model, train_loader, criterion, optimizer)\n        val_loss, val_acc = run_epoch(model, dev_loader, criterion)\n        # full dev evaluation for SWA/CWA/HMA\n        _, swa, cwa, hma, _, _, _ = evaluate_full(\n            model, dev_loader, id2label, id2tok, set(labels_seen)\n        )\n        print(\n            f\"Epoch {epoch}: train_acc={tr_acc:.4f} val_acc={val_acc:.4f} \"\n            f\"val_loss={val_loss:.4f} HMA={hma:.4f}\"\n        )\n        experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train_acc\"].append(tr_acc)\n        experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_acc\"].append(val_acc)\n        experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_HMA\"].append(hma)\n        experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_loss\"].append(val_loss)\n        experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n        experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n\n# ---------------------------------------------------------------------\n# final test evaluation ------------------------------------------------\ntest_loader = DataLoader(\n    test_ds, batch_size=DEV_TEST_BS, shuffle=False, collate_fn=collate\n)\nacc, swa, cwa, hma, zs_acc, preds, truth = evaluate_full(\n    model, test_loader, id2label, id2tok, set(labels_seen)\n)\nprint(f\"\\nTEST | Acc={acc:.4f} SWA={swa:.4f} CWA={cwa:.4f} HMA={hma:.4f} ZS={zs_acc}\")\n\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = truth\n\n# ---------------------------------------------------------------------\n# persist --------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"All experiment data saved to {working_dir}/experiment_data.npy\")\n", "# hyper_dim_tuning.py\nimport os, pathlib, time, random, json, math, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import DatasetDict, load_dataset\nfrom typing import List, Dict\n\n# ----------------------------------------------------------------------\n# reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n# ----------------------------------------------------------------------\n# experiment container --------------------------------------------------\nexperiment_data = {\"hidden_dim_tuning\": {\"SPR_BENCH\": {}}}\n# ----------------------------------------------------------------------\n# working dir / save path ----------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n# ----------------------------------------------------------------------\n# device ----------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------------------------------------------------------------\n# util functions --------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    d[\"train\"] = _load(\"train.csv\")\n    d[\"dev\"] = _load(\"dev.csv\")\n    d[\"test\"] = _load(\"test.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ----------------------------------------------------------------------\n# load data -------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ----------------------------------------------------------------------\n# vocab + label mapping -------------------------------------------------\ndef build_vocab(dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\ndef encode_seq(seq: str, vocab: Dict[str, int]) -> List[int]:\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\ntrain_labels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(train_labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\nprint(f\"# seen rule labels: {num_labels}\")\n\n\n# ----------------------------------------------------------------------\n# Torch dataset ---------------------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, label2id, train_mode=True):\n        self.seq_enc = [encode_seq(s, vocab) for s in split[\"sequence\"]]\n        self.labels = split[\"label\"]\n        self.train_mode = train_mode\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.seq_enc)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.seq_enc[idx], dtype=torch.long)\n        if self.train_mode:\n            y = torch.tensor(self.label2id[self.labels[idx]], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            return {\"input\": x, \"label_str\": self.labels[idx]}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = [len(x) for x in xs]\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": torch.tensor(lens, dtype=torch.long)}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    else:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\n# create loaders (same across experiments)\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id, True)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id, True)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, label2id, False)\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=256, shuffle=False, collate_fn=collate)\n\n\n# ----------------------------------------------------------------------\n# Model ----------------------------------------------------------------\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.lin = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x, lengths):\n        e = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)\n        return self.lin(h_cat)\n\n\n# ----------------------------------------------------------------------\n# training / eval helpers ----------------------------------------------\ndef run_epoch(model, loader, criterion, opt=None):\n    train = opt is not None\n    model.train() if train else model.eval()\n    tot_loss = tot_ok = tot = 0\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            lbl = batch[\"label\"].to(device)\n            logits = model(inp, lens)\n            loss = criterion(logits, lbl)\n            if train:\n                opt.zero_grad()\n                loss.backward()\n                opt.step()\n            tot_loss += loss.item() * inp.size(0)\n            preds = logits.argmax(1)\n            tot_ok += (preds == lbl).sum().item()\n            tot += inp.size(0)\n    return tot_loss / tot, tot_ok / tot\n\n\ndef evaluate_test(model):\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            logits = model(inp, lens)\n            preds = logits.argmax(1).cpu().tolist()\n            label_strs = batch[\"label_str\"]\n            all_preds.extend([id2label.get(p, \"UNK\") for p in preds])\n            all_labels.extend(label_strs)\n            all_seqs.extend(\n                [\n                    \" \".join(\n                        [list(vocab.keys())[tok] for tok in seq.tolist() if tok != 0]\n                    )\n                    for seq in batch[\"input\"]\n                ]\n            )\n    overall_acc = np.mean([p == t for p, t in zip(all_preds, all_labels)])\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    seen_rules = set(train_labels)\n    zs_idx = [i for i, lbl in enumerate(all_labels) if lbl not in seen_rules]\n    zs_acc = (\n        np.mean([all_preds[i] == all_labels[i] for i in zs_idx])\n        if zs_idx\n        else float(\"nan\")\n    )\n    return overall_acc, swa, cwa, zs_acc, all_preds, all_labels\n\n\n# ----------------------------------------------------------------------\n# hyperparameter search -------------------------------------------------\nhidden_dims = [64, 128, 256, 512]\nEPOCHS = 5\nfor hd in hidden_dims:\n    print(f\"\\n=== Training with hidden_dim={hd} ===\")\n    # init model/optim/criterion\n    model = SimpleSPRModel(len(vocab), 64, hd, num_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    # containers\n    mdata = {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"val_loss\": [], \"ZSRTA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    # train loop\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc = run_epoch(model, train_loader, criterion, opt)\n        val_loss, val_acc = run_epoch(model, dev_loader, criterion)\n        mdata[\"metrics\"][\"train_acc\"].append(tr_acc)\n        mdata[\"metrics\"][\"val_acc\"].append(val_acc)\n        mdata[\"metrics\"][\"val_loss\"].append(val_loss)\n        mdata[\"losses\"][\"train\"].append(tr_loss)\n        mdata[\"losses\"][\"val\"].append(val_loss)\n        mdata[\"timestamps\"].append(time.time())\n        print(\n            f\"Epoch {epoch}: train_acc={tr_acc:.4f} val_acc={val_acc:.4f} val_loss={val_loss:.4f}\"\n        )\n    # final evaluation\n    overall_acc, swa, cwa, zs_acc, all_preds, all_labels = evaluate_test(model)\n    mdata[\"metrics\"][\"ZSRTA\"].append(zs_acc)\n    mdata[\"predictions\"] = all_preds\n    mdata[\"ground_truth\"] = all_labels\n    print(\n        f\"TEST Acc={overall_acc:.4f} | SWA={swa:.4f} | CWA={cwa:.4f} | ZSRTA={zs_acc:.4f}\"\n    )\n    experiment_data[\"hidden_dim_tuning\"][\"SPR_BENCH\"][f\"hidden_{hd}\"] = mdata\n\n# ----------------------------------------------------------------------\n# save ------------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment data to {working_dir}/experiment_data.npy\")\n", "import os, pathlib, time, random, math, json, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import DatasetDict\nfrom typing import List, Dict\n\n# ----------------------------------------------------------------------\n# reproducibility -------------------------------------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# ----------------------------------------------------------------------\n# house-keeping ---------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\n    \"weight_decay\": {}  # will be filled with one entry per weight_decay value\n}\n\n# ----------------------------------------------------------------------\n# device ---------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------------------------------------------------------------\n# util functions -------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    \"\"\"Load csv files of SPR-BENCH into a HuggingFace DatasetDict\"\"\"\n    from datasets import load_dataset\n\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ----------------------------------------------------------------------\n# load data ------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ----------------------------------------------------------------------\n# vocab / label mapping ------------------------------------------------\ndef build_vocab(dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\ndef encode_seq(seq: str, vocab: Dict[str, int]) -> List[int]:\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\ntrain_labels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(train_labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\nprint(f\"#seen rule labels: {num_labels}\")\n\n\n# ----------------------------------------------------------------------\n# Torch Dataset --------------------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, label2id, train_mode=True):\n        self.seq_enc = [encode_seq(s, vocab) for s in split[\"sequence\"]]\n        self.labels = split[\"label\"]\n        self.train_mode = train_mode\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.seq_enc)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.seq_enc[idx], dtype=torch.long)\n        if self.train_mode:\n            y = torch.tensor(self.label2id[self.labels[idx]], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            return {\"input\": x, \"label_str\": self.labels[idx]}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = [len(x) for x in xs]\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": torch.tensor(lens, dtype=torch.long)}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    else:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\n# create static datasets (they are small so fine to keep in memory)\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id, True)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id, True)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, label2id, False)\n\n\n# ----------------------------------------------------------------------\n# Model definition -----------------------------------------------------\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.lin = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x, lengths):\n        e = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)\n        return self.lin(h_cat)\n\n\n# ----------------------------------------------------------------------\n# training / evaluation helpers ---------------------------------------\ndef run_epoch(model, loader, criterion, optimizer=None):\n    train = optimizer is not None\n    model.train() if train else model.eval()\n    total_loss, total_ok, total = 0.0, 0, 0\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            lbl = batch[\"label\"].to(device)\n            logits = model(inp, lens)\n            loss = criterion(logits, lbl)\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            total_loss += loss.item() * inp.size(0)\n            total_ok += (logits.argmax(1) == lbl).sum().item()\n            total += inp.size(0)\n    return total_loss / total, total_ok / total\n\n\ndef evaluate_test(model, loader):\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            logits = model(inp, lens)\n            preds = logits.argmax(1).cpu().tolist()\n            label_strs = batch[\"label_str\"]\n            all_preds.extend([id2label.get(p, \"UNK\") for p in preds])\n            all_labels.extend(label_strs)\n            all_seqs.extend(\n                [\n                    \" \".join(\n                        [list(vocab.keys())[tok] for tok in seq.tolist() if tok != 0]\n                    )\n                    for seq in batch[\"input\"]\n                ]\n            )\n    overall_acc = np.mean([p == t for p, t in zip(all_preds, all_labels)])\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    seen_rules = set(train_labels)\n    zs_indices = [i for i, lbl in enumerate(all_labels) if lbl not in seen_rules]\n    zs_acc = (\n        np.mean([all_preds[i] == all_labels[i] for i in zs_indices])\n        if zs_indices\n        else float(\"nan\")\n    )\n    return overall_acc, swa, cwa, zs_acc, all_preds, all_labels\n\n\n# ----------------------------------------------------------------------\n# Hyperparameter grid search ------------------------------------------\ngrid = [0.0, 1e-6, 1e-5, 1e-4, 1e-3]\nEPOCHS = 5\nfor wd in grid:\n    print(f\"\\n===== Training with weight_decay={wd} =====\")\n    # loaders (fresh DataLoader each run for fresh shuffling behaviour)\n    train_loader = DataLoader(\n        train_ds, batch_size=128, shuffle=True, collate_fn=collate\n    )\n    dev_loader = DataLoader(dev_ds, batch_size=256, shuffle=False, collate_fn=collate)\n    test_loader = DataLoader(test_ds, batch_size=256, shuffle=False, collate_fn=collate)\n\n    model = SimpleSPRModel(len(vocab), 64, 128, num_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=wd)\n\n    # prepare experiment_data entry\n    run_key = f\"wd_{wd}\"\n    experiment_data[\"weight_decay\"][run_key] = {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"val_loss\": [], \"ZSRTA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc = run_epoch(model, train_loader, criterion, optimizer)\n        val_loss, val_acc = run_epoch(model, dev_loader, criterion, optimizer=None)\n\n        ed = experiment_data[\"weight_decay\"][run_key]\n        ed[\"metrics\"][\"train_acc\"].append(tr_acc)\n        ed[\"metrics\"][\"val_acc\"].append(val_acc)\n        ed[\"metrics\"][\"val_loss\"].append(val_loss)\n        ed[\"losses\"][\"train\"].append(tr_loss)\n        ed[\"losses\"][\"val\"].append(val_loss)\n        ed[\"timestamps\"].append(time.time())\n\n        print(\n            f\"Epoch {epoch}: train_acc={tr_acc:.4f} | val_acc={val_acc:.4f} | val_loss={val_loss:.4f}\"\n        )\n\n    # final evaluation on test\n    overall_acc, swa, cwa, zs_acc, preds, labels = evaluate_test(model, test_loader)\n    ed[\"metrics\"][\"ZSRTA\"].append(zs_acc)\n    ed[\"predictions\"] = preds\n    ed[\"ground_truth\"] = labels\n    print(\n        f\"TEST Acc={overall_acc:.4f} | SWA={swa:.4f} | CWA={cwa:.4f} | ZSRTA={zs_acc:.4f}\"\n    )\n\n# ----------------------------------------------------------------------\n# Save artefacts -------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nAll experiment data saved in {working_dir}/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n# hyper_dim_tuning.py\nimport os, pathlib, time, random, json, math, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import DatasetDict, load_dataset\nfrom typing import List, Dict\n\n# ----------------------------------------------------------------------\n# reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n# ----------------------------------------------------------------------\n# experiment container --------------------------------------------------\nexperiment_data = {\"hidden_dim_tuning\": {\"SPR_BENCH\": {}}}\n# ----------------------------------------------------------------------\n# working dir / save path ----------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n# ----------------------------------------------------------------------\n# device ----------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------------------------------------------------------------\n# util functions --------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    d[\"train\"] = _load(\"train.csv\")\n    d[\"dev\"] = _load(\"dev.csv\")\n    d[\"test\"] = _load(\"test.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ----------------------------------------------------------------------\n# load data -------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ----------------------------------------------------------------------\n# vocab + label mapping -------------------------------------------------\ndef build_vocab(dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\ndef encode_seq(seq: str, vocab: Dict[str, int]) -> List[int]:\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\ntrain_labels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(train_labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\nprint(f\"# seen rule labels: {num_labels}\")\n\n\n# ----------------------------------------------------------------------\n# Torch dataset ---------------------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, label2id, train_mode=True):\n        self.seq_enc = [encode_seq(s, vocab) for s in split[\"sequence\"]]\n        self.labels = split[\"label\"]\n        self.train_mode = train_mode\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.seq_enc)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.seq_enc[idx], dtype=torch.long)\n        if self.train_mode:\n            y = torch.tensor(self.label2id[self.labels[idx]], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            return {\"input\": x, \"label_str\": self.labels[idx]}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = [len(x) for x in xs]\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": torch.tensor(lens, dtype=torch.long)}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    else:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\n# create loaders (same across experiments)\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id, True)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id, True)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, label2id, False)\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=256, shuffle=False, collate_fn=collate)\n\n\n# ----------------------------------------------------------------------\n# Model ----------------------------------------------------------------\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.lin = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x, lengths):\n        e = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)\n        return self.lin(h_cat)\n\n\n# ----------------------------------------------------------------------\n# training / eval helpers ----------------------------------------------\ndef run_epoch(model, loader, criterion, opt=None):\n    train = opt is not None\n    model.train() if train else model.eval()\n    tot_loss = tot_ok = tot = 0\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            lbl = batch[\"label\"].to(device)\n            logits = model(inp, lens)\n            loss = criterion(logits, lbl)\n            if train:\n                opt.zero_grad()\n                loss.backward()\n                opt.step()\n            tot_loss += loss.item() * inp.size(0)\n            preds = logits.argmax(1)\n            tot_ok += (preds == lbl).sum().item()\n            tot += inp.size(0)\n    return tot_loss / tot, tot_ok / tot\n\n\ndef evaluate_test(model):\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            logits = model(inp, lens)\n            preds = logits.argmax(1).cpu().tolist()\n            label_strs = batch[\"label_str\"]\n            all_preds.extend([id2label.get(p, \"UNK\") for p in preds])\n            all_labels.extend(label_strs)\n            all_seqs.extend(\n                [\n                    \" \".join(\n                        [list(vocab.keys())[tok] for tok in seq.tolist() if tok != 0]\n                    )\n                    for seq in batch[\"input\"]\n                ]\n            )\n    overall_acc = np.mean([p == t for p, t in zip(all_preds, all_labels)])\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    seen_rules = set(train_labels)\n    zs_idx = [i for i, lbl in enumerate(all_labels) if lbl not in seen_rules]\n    zs_acc = (\n        np.mean([all_preds[i] == all_labels[i] for i in zs_idx])\n        if zs_idx\n        else float(\"nan\")\n    )\n    return overall_acc, swa, cwa, zs_acc, all_preds, all_labels\n\n\n# ----------------------------------------------------------------------\n# hyperparameter search -------------------------------------------------\nhidden_dims = [64, 128, 256, 512]\nEPOCHS = 5\nfor hd in hidden_dims:\n    print(f\"\\n=== Training with hidden_dim={hd} ===\")\n    # init model/optim/criterion\n    model = SimpleSPRModel(len(vocab), 64, hd, num_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    # containers\n    mdata = {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"val_loss\": [], \"ZSRTA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    # train loop\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc = run_epoch(model, train_loader, criterion, opt)\n        val_loss, val_acc = run_epoch(model, dev_loader, criterion)\n        mdata[\"metrics\"][\"train_acc\"].append(tr_acc)\n        mdata[\"metrics\"][\"val_acc\"].append(val_acc)\n        mdata[\"metrics\"][\"val_loss\"].append(val_loss)\n        mdata[\"losses\"][\"train\"].append(tr_loss)\n        mdata[\"losses\"][\"val\"].append(val_loss)\n        mdata[\"timestamps\"].append(time.time())\n        print(\n            f\"Epoch {epoch}: train_acc={tr_acc:.4f} val_acc={val_acc:.4f} val_loss={val_loss:.4f}\"\n        )\n    # final evaluation\n    overall_acc, swa, cwa, zs_acc, all_preds, all_labels = evaluate_test(model)\n    mdata[\"metrics\"][\"ZSRTA\"].append(zs_acc)\n    mdata[\"predictions\"] = all_preds\n    mdata[\"ground_truth\"] = all_labels\n    print(\n        f\"TEST Acc={overall_acc:.4f} | SWA={swa:.4f} | CWA={cwa:.4f} | ZSRTA={zs_acc:.4f}\"\n    )\n    experiment_data[\"hidden_dim_tuning\"][\"SPR_BENCH\"][f\"hidden_{hd}\"] = mdata\n\n# ----------------------------------------------------------------------\n# save ------------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment data to {working_dir}/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n# hyper_dim_tuning.py\nimport os, pathlib, time, random, json, math, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import DatasetDict, load_dataset\nfrom typing import List, Dict\n\n# ----------------------------------------------------------------------\n# reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n# ----------------------------------------------------------------------\n# experiment container --------------------------------------------------\nexperiment_data = {\"hidden_dim_tuning\": {\"SPR_BENCH\": {}}}\n# ----------------------------------------------------------------------\n# working dir / save path ----------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n# ----------------------------------------------------------------------\n# device ----------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------------------------------------------------------------\n# util functions --------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    d[\"train\"] = _load(\"train.csv\")\n    d[\"dev\"] = _load(\"dev.csv\")\n    d[\"test\"] = _load(\"test.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ----------------------------------------------------------------------\n# load data -------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ----------------------------------------------------------------------\n# vocab + label mapping -------------------------------------------------\ndef build_vocab(dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\ndef encode_seq(seq: str, vocab: Dict[str, int]) -> List[int]:\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\ntrain_labels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(train_labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\nprint(f\"# seen rule labels: {num_labels}\")\n\n\n# ----------------------------------------------------------------------\n# Torch dataset ---------------------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, label2id, train_mode=True):\n        self.seq_enc = [encode_seq(s, vocab) for s in split[\"sequence\"]]\n        self.labels = split[\"label\"]\n        self.train_mode = train_mode\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.seq_enc)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.seq_enc[idx], dtype=torch.long)\n        if self.train_mode:\n            y = torch.tensor(self.label2id[self.labels[idx]], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            return {\"input\": x, \"label_str\": self.labels[idx]}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = [len(x) for x in xs]\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": torch.tensor(lens, dtype=torch.long)}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    else:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\n# create loaders (same across experiments)\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id, True)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id, True)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, label2id, False)\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=256, shuffle=False, collate_fn=collate)\n\n\n# ----------------------------------------------------------------------\n# Model ----------------------------------------------------------------\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.lin = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x, lengths):\n        e = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)\n        return self.lin(h_cat)\n\n\n# ----------------------------------------------------------------------\n# training / eval helpers ----------------------------------------------\ndef run_epoch(model, loader, criterion, opt=None):\n    train = opt is not None\n    model.train() if train else model.eval()\n    tot_loss = tot_ok = tot = 0\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            lbl = batch[\"label\"].to(device)\n            logits = model(inp, lens)\n            loss = criterion(logits, lbl)\n            if train:\n                opt.zero_grad()\n                loss.backward()\n                opt.step()\n            tot_loss += loss.item() * inp.size(0)\n            preds = logits.argmax(1)\n            tot_ok += (preds == lbl).sum().item()\n            tot += inp.size(0)\n    return tot_loss / tot, tot_ok / tot\n\n\ndef evaluate_test(model):\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            logits = model(inp, lens)\n            preds = logits.argmax(1).cpu().tolist()\n            label_strs = batch[\"label_str\"]\n            all_preds.extend([id2label.get(p, \"UNK\") for p in preds])\n            all_labels.extend(label_strs)\n            all_seqs.extend(\n                [\n                    \" \".join(\n                        [list(vocab.keys())[tok] for tok in seq.tolist() if tok != 0]\n                    )\n                    for seq in batch[\"input\"]\n                ]\n            )\n    overall_acc = np.mean([p == t for p, t in zip(all_preds, all_labels)])\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    seen_rules = set(train_labels)\n    zs_idx = [i for i, lbl in enumerate(all_labels) if lbl not in seen_rules]\n    zs_acc = (\n        np.mean([all_preds[i] == all_labels[i] for i in zs_idx])\n        if zs_idx\n        else float(\"nan\")\n    )\n    return overall_acc, swa, cwa, zs_acc, all_preds, all_labels\n\n\n# ----------------------------------------------------------------------\n# hyperparameter search -------------------------------------------------\nhidden_dims = [64, 128, 256, 512]\nEPOCHS = 5\nfor hd in hidden_dims:\n    print(f\"\\n=== Training with hidden_dim={hd} ===\")\n    # init model/optim/criterion\n    model = SimpleSPRModel(len(vocab), 64, hd, num_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    # containers\n    mdata = {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"val_loss\": [], \"ZSRTA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    # train loop\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc = run_epoch(model, train_loader, criterion, opt)\n        val_loss, val_acc = run_epoch(model, dev_loader, criterion)\n        mdata[\"metrics\"][\"train_acc\"].append(tr_acc)\n        mdata[\"metrics\"][\"val_acc\"].append(val_acc)\n        mdata[\"metrics\"][\"val_loss\"].append(val_loss)\n        mdata[\"losses\"][\"train\"].append(tr_loss)\n        mdata[\"losses\"][\"val\"].append(val_loss)\n        mdata[\"timestamps\"].append(time.time())\n        print(\n            f\"Epoch {epoch}: train_acc={tr_acc:.4f} val_acc={val_acc:.4f} val_loss={val_loss:.4f}\"\n        )\n    # final evaluation\n    overall_acc, swa, cwa, zs_acc, all_preds, all_labels = evaluate_test(model)\n    mdata[\"metrics\"][\"ZSRTA\"].append(zs_acc)\n    mdata[\"predictions\"] = all_preds\n    mdata[\"ground_truth\"] = all_labels\n    print(\n        f\"TEST Acc={overall_acc:.4f} | SWA={swa:.4f} | CWA={cwa:.4f} | ZSRTA={zs_acc:.4f}\"\n    )\n    experiment_data[\"hidden_dim_tuning\"][\"SPR_BENCH\"][f\"hidden_{hd}\"] = mdata\n\n# ----------------------------------------------------------------------\n# save ------------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment data to {working_dir}/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\n# hyper_dim_tuning.py\nimport os, pathlib, time, random, json, math, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import DatasetDict, load_dataset\nfrom typing import List, Dict\n\n# ----------------------------------------------------------------------\n# reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n# ----------------------------------------------------------------------\n# experiment container --------------------------------------------------\nexperiment_data = {\"hidden_dim_tuning\": {\"SPR_BENCH\": {}}}\n# ----------------------------------------------------------------------\n# working dir / save path ----------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n# ----------------------------------------------------------------------\n# device ----------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------------------------------------------------------------\n# util functions --------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    d[\"train\"] = _load(\"train.csv\")\n    d[\"dev\"] = _load(\"dev.csv\")\n    d[\"test\"] = _load(\"test.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ----------------------------------------------------------------------\n# load data -------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ----------------------------------------------------------------------\n# vocab + label mapping -------------------------------------------------\ndef build_vocab(dataset) -> Dict[str, int]:\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for seq in dataset[\"sequence\"]:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\ndef encode_seq(seq: str, vocab: Dict[str, int]) -> List[int]:\n    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in seq.strip().split()]\n\n\ntrain_labels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(train_labels)}\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\nprint(f\"# seen rule labels: {num_labels}\")\n\n\n# ----------------------------------------------------------------------\n# Torch dataset ---------------------------------------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split, vocab, label2id, train_mode=True):\n        self.seq_enc = [encode_seq(s, vocab) for s in split[\"sequence\"]]\n        self.labels = split[\"label\"]\n        self.train_mode = train_mode\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.seq_enc)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.seq_enc[idx], dtype=torch.long)\n        if self.train_mode:\n            y = torch.tensor(self.label2id[self.labels[idx]], dtype=torch.long)\n            return {\"input\": x, \"label\": y}\n        else:\n            return {\"input\": x, \"label_str\": self.labels[idx]}\n\n\ndef collate(batch):\n    xs = [b[\"input\"] for b in batch]\n    lens = [len(x) for x in xs]\n    xs_pad = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n    out = {\"input\": xs_pad, \"lengths\": torch.tensor(lens, dtype=torch.long)}\n    if \"label\" in batch[0]:\n        out[\"label\"] = torch.stack([b[\"label\"] for b in batch])\n    else:\n        out[\"label_str\"] = [b[\"label_str\"] for b in batch]\n    return out\n\n\n# create loaders (same across experiments)\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id, True)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id, True)\ntest_ds = SPRTorchDataset(spr[\"test\"], vocab, label2id, False)\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=256, shuffle=False, collate_fn=collate)\n\n\n# ----------------------------------------------------------------------\n# Model ----------------------------------------------------------------\nclass SimpleSPRModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.lin = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x, lengths):\n        e = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)\n        return self.lin(h_cat)\n\n\n# ----------------------------------------------------------------------\n# training / eval helpers ----------------------------------------------\ndef run_epoch(model, loader, criterion, opt=None):\n    train = opt is not None\n    model.train() if train else model.eval()\n    tot_loss = tot_ok = tot = 0\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            lbl = batch[\"label\"].to(device)\n            logits = model(inp, lens)\n            loss = criterion(logits, lbl)\n            if train:\n                opt.zero_grad()\n                loss.backward()\n                opt.step()\n            tot_loss += loss.item() * inp.size(0)\n            preds = logits.argmax(1)\n            tot_ok += (preds == lbl).sum().item()\n            tot += inp.size(0)\n    return tot_loss / tot, tot_ok / tot\n\n\ndef evaluate_test(model):\n    model.eval()\n    all_preds, all_labels, all_seqs = [], [], []\n    with torch.no_grad():\n        for batch in test_loader:\n            inp = batch[\"input\"].to(device)\n            lens = batch[\"lengths\"].to(device)\n            logits = model(inp, lens)\n            preds = logits.argmax(1).cpu().tolist()\n            label_strs = batch[\"label_str\"]\n            all_preds.extend([id2label.get(p, \"UNK\") for p in preds])\n            all_labels.extend(label_strs)\n            all_seqs.extend(\n                [\n                    \" \".join(\n                        [list(vocab.keys())[tok] for tok in seq.tolist() if tok != 0]\n                    )\n                    for seq in batch[\"input\"]\n                ]\n            )\n    overall_acc = np.mean([p == t for p, t in zip(all_preds, all_labels)])\n    swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n    cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n    seen_rules = set(train_labels)\n    zs_idx = [i for i, lbl in enumerate(all_labels) if lbl not in seen_rules]\n    zs_acc = (\n        np.mean([all_preds[i] == all_labels[i] for i in zs_idx])\n        if zs_idx\n        else float(\"nan\")\n    )\n    return overall_acc, swa, cwa, zs_acc, all_preds, all_labels\n\n\n# ----------------------------------------------------------------------\n# hyperparameter search -------------------------------------------------\nhidden_dims = [64, 128, 256, 512]\nEPOCHS = 5\nfor hd in hidden_dims:\n    print(f\"\\n=== Training with hidden_dim={hd} ===\")\n    # init model/optim/criterion\n    model = SimpleSPRModel(len(vocab), 64, hd, num_labels).to(device)\n    criterion = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    # containers\n    mdata = {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"val_loss\": [], \"ZSRTA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    # train loop\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss, tr_acc = run_epoch(model, train_loader, criterion, opt)\n        val_loss, val_acc = run_epoch(model, dev_loader, criterion)\n        mdata[\"metrics\"][\"train_acc\"].append(tr_acc)\n        mdata[\"metrics\"][\"val_acc\"].append(val_acc)\n        mdata[\"metrics\"][\"val_loss\"].append(val_loss)\n        mdata[\"losses\"][\"train\"].append(tr_loss)\n        mdata[\"losses\"][\"val\"].append(val_loss)\n        mdata[\"timestamps\"].append(time.time())\n        print(\n            f\"Epoch {epoch}: train_acc={tr_acc:.4f} val_acc={val_acc:.4f} val_loss={val_loss:.4f}\"\n        )\n    # final evaluation\n    overall_acc, swa, cwa, zs_acc, all_preds, all_labels = evaluate_test(model)\n    mdata[\"metrics\"][\"ZSRTA\"].append(zs_acc)\n    mdata[\"predictions\"] = all_preds\n    mdata[\"ground_truth\"] = all_labels\n    print(\n        f\"TEST Acc={overall_acc:.4f} | SWA={swa:.4f} | CWA={cwa:.4f} | ZSRTA={zs_acc:.4f}\"\n    )\n    experiment_data[\"hidden_dim_tuning\"][\"SPR_BENCH\"][f\"hidden_{hd}\"] = mdata\n\n# ----------------------------------------------------------------------\n# save ------------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment data to {working_dir}/experiment_data.npy\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 426417.25\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 540113.32\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 629926.71\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize: 18', '\\n', '#seen rule labels: 2', '\\n', 'Epoch 1: train_acc=0.9284\nval_acc=0.9648  val_loss=0.1207', '\\n', 'Epoch 2: train_acc=0.9809\nval_acc=0.9902  val_loss=0.0276', '\\n', 'Epoch 3: train_acc=0.9967\nval_acc=0.9968  val_loss=0.0096', '\\n', 'Epoch 4: train_acc=0.9991\nval_acc=0.9984  val_loss=0.0051', '\\n', 'Epoch 5: train_acc=0.9999\nval_acc=0.9998  val_loss=0.0021', '\\n', '\\nTEST Acc: 0.7002 | SWA: 0.6525 | CWA:\n0.7008 | ZSRTA: nan', '\\n', 'Experiment data saved to /home/zxl240011/AI-Scienti\nst-v2/experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/0-\nrun/process_ForkProcess-1/working', '\\n', 'Execution time: 6 seconds seconds\n(time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 509187.41\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 558957.33\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 707529.23\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize:', ' ', '18', '\\n', '#seen rule labels:', ' ', '2', '\\n', '\\n=== Training\nfor 5 epochs ===', '\\n', 'Epoch 1/5: train_acc=0.9368  val_acc=0.9644', '\\n',\n'Epoch 2/5: train_acc=0.9837  val_acc=0.9936', '\\n', 'Epoch 3/5:\ntrain_acc=0.9954  val_acc=0.9966', '\\n', 'Epoch 4/5: train_acc=0.9987\nval_acc=0.9994', '\\n', 'Epoch 5/5: train_acc=1.0000  val_acc=0.9996', '\\n',\n'TEST Acc=0.7002 | SWA=0.6525 | CWA=0.7007 | ZSRTA=nan', '\\n', '\\n=== Training\nfor 10 epochs ===', '\\n', 'Epoch 1/10: train_acc=0.9391  val_acc=0.9654', '\\n',\n'Epoch 2/10: train_acc=0.9795  val_acc=0.9864', '\\n', 'Epoch 3/10:\ntrain_acc=0.9924  val_acc=0.9940', '\\n', 'Epoch 4/10: train_acc=0.9972\nval_acc=0.9972', '\\n', 'Epoch 5/10: train_acc=0.9990  val_acc=0.9986', '\\n',\n'Epoch 6/10: train_acc=0.9999  val_acc=0.9992', '\\n', 'Epoch 7/10:\ntrain_acc=1.0000  val_acc=0.9994', '\\n', 'Epoch 8/10: train_acc=1.0000\nval_acc=0.9996', '\\n', 'Epoch 9/10: train_acc=1.0000  val_acc=0.9996', '\\n',\n'Epoch 10/10: train_acc=1.0000  val_acc=0.9996', '\\n', 'TEST Acc=0.7003 |\nSWA=0.6526 | CWA=0.7008 | ZSRTA=nan', '\\n', '\\n=== Training for 15 epochs ===',\n'\\n', 'Epoch 1/15: train_acc=0.9328  val_acc=0.9704', '\\n', 'Epoch 2/15:\ntrain_acc=0.9807  val_acc=0.9904', '\\n', 'Epoch 3/15: train_acc=0.9939\nval_acc=0.9954', '\\n', 'Epoch 4/15: train_acc=0.9984  val_acc=0.9984', '\\n',\n'Epoch 5/15: train_acc=0.9999  val_acc=0.9996', '\\n', 'Epoch 6/15:\ntrain_acc=1.0000  val_acc=0.9998', '\\n', 'Epoch 7/15: train_acc=0.9996\nval_acc=0.9996', '\\n', 'Epoch 8/15: train_acc=1.0000  val_acc=0.9996', '\\n',\n'Epoch 9/15: train_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 10/15:\ntrain_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 11/15: train_acc=1.0000\nval_acc=0.9996', '\\n', 'Epoch 12/15: train_acc=1.0000  val_acc=0.9996', '\\n',\n'Epoch 13/15: train_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 14/15:\ntrain_acc=1.0000  val_acc=0.9998', '\\n', 'Epoch 15/15: train_acc=1.0000\nval_acc=0.9996', '\\n', 'TEST Acc=0.6999 | SWA=0.6521 | CWA=0.7004 | ZSRTA=nan',\n'\\n', '\\n=== Training for 20 epochs ===', '\\n', 'Epoch 1/20: train_acc=0.9327\nval_acc=0.9662', '\\n', 'Epoch 2/20: train_acc=0.9800  val_acc=0.9870', '\\n',\n'Epoch 3/20: train_acc=0.9943  val_acc=0.9950', '\\n', 'Epoch 4/20:\ntrain_acc=0.9980  val_acc=0.9984', '\\n', 'Epoch 5/20: train_acc=0.9997\nval_acc=0.9984', '\\n', 'Epoch 6/20: train_acc=1.0000  val_acc=0.9990', '\\n',\n'Epoch 7/20: train_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 8/20:\ntrain_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 9/20: train_acc=1.0000\nval_acc=0.9994', '\\n', 'Epoch 10/20: train_acc=1.0000  val_acc=0.9994', '\\n',\n'Epoch 11/20: train_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 12/20:\ntrain_acc=1.0000  val_acc=0.9994', '\\n', 'Epoch 13/20: train_acc=1.0000\nval_acc=0.9994', '\\n', 'Epoch 14/20: train_acc=1.0000  val_acc=0.9994', '\\n',\n'Epoch 15/20: train_acc=1.0000  val_acc=0.9994', '\\n', 'Epoch 16/20:\ntrain_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 17/20: train_acc=1.0000\nval_acc=0.9994', '\\n', 'Epoch 18/20: train_acc=1.0000  val_acc=0.9996', '\\n',\n'Epoch 19/20: train_acc=1.0000  val_acc=0.9994', '\\n', 'Epoch 20/20:\ntrain_acc=1.0000  val_acc=0.9994', '\\n', 'TEST Acc=0.7001 | SWA=0.6524 |\nCWA=0.7007 | ZSRTA=nan', '\\n', '\\n=== Training for 25 epochs ===', '\\n', 'Epoch\n1/25: train_acc=0.9329  val_acc=0.9584', '\\n', 'Epoch 2/25: train_acc=0.9751\nval_acc=0.9902', '\\n', 'Epoch 3/25: train_acc=0.9934  val_acc=0.9970', '\\n',\n'Epoch 4/25: train_acc=0.9979  val_acc=0.9984', '\\n', 'Epoch 5/25:\ntrain_acc=1.0000  val_acc=0.9994', '\\n', 'Epoch 6/25: train_acc=1.0000\nval_acc=0.9996', '\\n', 'Epoch 7/25: train_acc=1.0000  val_acc=0.9996', '\\n',\n'Epoch 8/25: train_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 9/25:\ntrain_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 10/25: train_acc=1.0000\nval_acc=0.9996', '\\n', 'Epoch 11/25: train_acc=1.0000  val_acc=0.9996', '\\n',\n'Epoch 12/25: train_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 13/25:\ntrain_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 14/25: train_acc=1.0000\nval_acc=0.9996', '\\n', 'Epoch 15/25: train_acc=1.0000  val_acc=0.9996', '\\n',\n'Epoch 16/25: train_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 17/25:\ntrain_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 18/25: train_acc=1.0000\nval_acc=0.9996', '\\n', 'Epoch 19/25: train_acc=1.0000  val_acc=0.9996', '\\n',\n'Epoch 20/25: train_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 21/25:\ntrain_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 22/25: train_acc=1.0000\nval_acc=0.9996', '\\n', 'Epoch 23/25: train_acc=1.0000  val_acc=0.9996', '\\n',\n'Epoch 24/25: train_acc=1.0000  val_acc=0.9996', '\\n', 'Epoch 25/25:\ntrain_acc=1.0000  val_acc=0.9996', '\\n', 'TEST Acc=0.7002 | SWA=0.6525 |\nCWA=0.7007 | ZSRTA=nan', '\\n', '\\nAll results saved to /home/zxl240011/AI-Scient\nist-v2/experiments/2025-07-27_23-49-\n14_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-\n6/working/experiment_data.npy', '\\n', 'Execution time: 54 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 388744.83\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 435021.57\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 508579.26\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize: 18', '\\n', '[lr=0.0003] Epoch 1: train_acc=0.9062 val_acc=0.9486', '\\n',\n'[lr=0.0003] Epoch 2: train_acc=0.9565 val_acc=0.9630', '\\n', '[lr=0.0003] Epoch\n3: train_acc=0.9670 val_acc=0.9748', '\\n', '[lr=0.0003] Epoch 4:\ntrain_acc=0.9776 val_acc=0.9842', '\\n', '[lr=0.0003] Epoch 5: train_acc=0.9862\nval_acc=0.9900', '\\n', '[lr=0.0005] Epoch 1: train_acc=0.9141 val_acc=0.9556',\n'\\n', '[lr=0.0005] Epoch 2: train_acc=0.9643 val_acc=0.9736', '\\n', '[lr=0.0005]\nEpoch 3: train_acc=0.9813 val_acc=0.9860', '\\n', '[lr=0.0005] Epoch 4:\ntrain_acc=0.9898 val_acc=0.9906', '\\n', '[lr=0.0005] Epoch 5: train_acc=0.9942\nval_acc=0.9946', '\\n', '[lr=0.001] Epoch 1: train_acc=0.9321 val_acc=0.9580',\n'\\n', '[lr=0.001] Epoch 2: train_acc=0.9748 val_acc=0.9848', '\\n', '[lr=0.001]\nEpoch 3: train_acc=0.9925 val_acc=0.9956', '\\n', '[lr=0.001] Epoch 4:\ntrain_acc=0.9977 val_acc=0.9974', '\\n', '[lr=0.001] Epoch 5: train_acc=0.9991\nval_acc=0.9980', '\\n', '[lr=0.002] Epoch 1: train_acc=0.9527 val_acc=0.9836',\n'\\n', '[lr=0.002] Epoch 2: train_acc=0.9916 val_acc=0.9974', '\\n', '[lr=0.002]\nEpoch 3: train_acc=0.9982 val_acc=0.9996', '\\n', '[lr=0.002] Epoch 4:\ntrain_acc=1.0000 val_acc=0.9998', '\\n', '[lr=0.002] Epoch 5: train_acc=1.0000\nval_acc=0.9998', '\\n', '\\nBest lr selected: 0.002 with dev acc 0.9998', '\\n',\n'\\nTEST Acc: 0.7000 | SWA: 0.6522 | CWA: 0.7005 | ZSRTA: nan', '\\n', 'Results\nsaved to /home/zxl240011/AI-Scientist-v2/experiments/2025-07-27_23-49-\n14_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-\n7/working/experiment_data.npy', '\\n', 'Execution time: 19 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 383997.07\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 457204.65\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 536829.68\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize: 18', '\\n', '#seen rule labels: 2', '\\n', '\\n===== Training with batch size\n32 =====', '\\n', 'Epoch 1: train_acc=0.9637 val_acc=0.9878 val_loss=0.0337',\n'\\n', 'Epoch 2: train_acc=0.9957 val_acc=0.9984 val_loss=0.0088', '\\n', 'Epoch\n3: train_acc=0.9980 val_acc=0.9986 val_loss=0.0043', '\\n', 'Epoch 4:\ntrain_acc=0.9993 val_acc=0.9998 val_loss=0.0009', '\\n', 'Epoch 5:\ntrain_acc=1.0000 val_acc=0.9998 val_loss=0.0009', '\\n', 'TEST Acc: 0.7001 | SWA:\n0.6523 | CWA: 0.7006 | ZSRTA: nan', '\\n', '\\n===== Training with batch size 64\n=====', '\\n', 'Epoch 1: train_acc=0.9505 val_acc=0.9846 val_loss=0.0617', '\\n',\n'Epoch 2: train_acc=0.9897 val_acc=0.9924 val_loss=0.0209', '\\n', 'Epoch 3:\ntrain_acc=0.9966 val_acc=0.9978 val_loss=0.0077', '\\n', 'Epoch 4:\ntrain_acc=0.9995 val_acc=0.9998 val_loss=0.0020', '\\n', 'Epoch 5:\ntrain_acc=1.0000 val_acc=0.9998 val_loss=0.0017', '\\n', 'TEST Acc: 0.7000 | SWA:\n0.6523 | CWA: 0.7006 | ZSRTA: nan', '\\n', '\\n===== Training with batch size 128\n=====', '\\n', 'Epoch 1: train_acc=0.9396 val_acc=0.9734 val_loss=0.0823', '\\n',\n'Epoch 2: train_acc=0.9849 val_acc=0.9888 val_loss=0.0360', '\\n', 'Epoch 3:\ntrain_acc=0.9939 val_acc=0.9982 val_loss=0.0105', '\\n', 'Epoch 4:\ntrain_acc=0.9990 val_acc=0.9992 val_loss=0.0037', '\\n', 'Epoch 5:\ntrain_acc=0.9999 val_acc=0.9994 val_loss=0.0024', '\\n', 'TEST Acc: 0.6999 | SWA:\n0.6522 | CWA: 0.7004 | ZSRTA: nan', '\\n', '\\n===== Training with batch size 256\n=====', '\\n', 'Epoch 1: train_acc=0.9196 val_acc=0.9574 val_loss=0.1487', '\\n',\n'Epoch 2: train_acc=0.9640 val_acc=0.9756 val_loss=0.0878', '\\n', 'Epoch 3:\ntrain_acc=0.9814 val_acc=0.9882 val_loss=0.0370', '\\n', 'Epoch 4:\ntrain_acc=0.9928 val_acc=0.9932 val_loss=0.0190', '\\n', 'Epoch 5:\ntrain_acc=0.9974 val_acc=0.9980 val_loss=0.0097', '\\n', 'TEST Acc: 0.7011 | SWA:\n0.6538 | CWA: 0.7016 | ZSRTA: nan', '\\n', '\\n===== Training with batch size 512\n=====', '\\n', 'Epoch 1: train_acc=0.8943 val_acc=0.9508 val_loss=0.1659', '\\n',\n'Epoch 2: train_acc=0.9564 val_acc=0.9612 val_loss=0.1309', '\\n', 'Epoch 3:\ntrain_acc=0.9651 val_acc=0.9682 val_loss=0.1056', '\\n', 'Epoch 4:\ntrain_acc=0.9735 val_acc=0.9766 val_loss=0.0785', '\\n', 'Epoch 5:\ntrain_acc=0.9806 val_acc=0.9826 val_loss=0.0568', '\\n', 'TEST Acc: 0.6944 | SWA:\n0.6483 | CWA: 0.6949 | ZSRTA: nan', '\\n', '\\nAll experiment data serialized to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-07-27_23-49-\n14_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-\n8/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 461536.36\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 387600.64\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 508061.78\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize: 18', '\\n', '#seen rule labels: 2', '\\n', '\\n=== Training with dropout=0.0\n===', '\\n', '  Epoch 1: train_acc=0.9330 val_acc=0.9650 val_loss=0.1053', '\\n',\n'  Epoch 2: train_acc=0.9832 val_acc=0.9900 val_loss=0.0316', '\\n', '  Epoch 3:\ntrain_acc=0.9928 val_acc=0.9956 val_loss=0.0155', '\\n', '  Epoch 4:\ntrain_acc=0.9980 val_acc=0.9996 val_loss=0.0065', '\\n', '  Epoch 5:\ntrain_acc=0.9997 val_acc=0.9990 val_loss=0.0030', '\\n', '\\n=== Training with\ndropout=0.2 ===', '\\n', '  Epoch 1: train_acc=0.9322 val_acc=0.9690\nval_loss=0.1016', '\\n', '  Epoch 2: train_acc=0.9845 val_acc=0.9932\nval_loss=0.0249', '\\n', '  Epoch 3: train_acc=0.9956 val_acc=0.9976\nval_loss=0.0092', '\\n', '  Epoch 4: train_acc=0.9987 val_acc=0.9990\nval_loss=0.0042', '\\n', '  Epoch 5: train_acc=0.9999 val_acc=0.9998\nval_loss=0.0025', '\\n', '\\n=== Training with dropout=0.4 ===', '\\n', '  Epoch 1:\ntrain_acc=0.9337 val_acc=0.9678 val_loss=0.1053', '\\n', '  Epoch 2:\ntrain_acc=0.9812 val_acc=0.9878 val_loss=0.0391', '\\n', '  Epoch 3:\ntrain_acc=0.9913 val_acc=0.9956 val_loss=0.0137', '\\n', '  Epoch 4:\ntrain_acc=0.9971 val_acc=0.9984 val_loss=0.0056', '\\n', '  Epoch 5:\ntrain_acc=0.9993 val_acc=0.9990 val_loss=0.0032', '\\n', '\\n=== Training with\ndropout=0.6 ===', '\\n', '  Epoch 1: train_acc=0.9261 val_acc=0.9578\nval_loss=0.1354', '\\n', '  Epoch 2: train_acc=0.9659 val_acc=0.9766\nval_loss=0.0841', '\\n', '  Epoch 3: train_acc=0.9812 val_acc=0.9882\nval_loss=0.0373', '\\n', '  Epoch 4: train_acc=0.9909 val_acc=0.9954\nval_loss=0.0169', '\\n', '  Epoch 5: train_acc=0.9966 val_acc=0.9978\nval_loss=0.0074', '\\n', '\\nBest dropout according to dev accuracy: 0.2\n(0.9998)', '\\n', '\\nTEST Acc: 0.7001 | SWA: 0.6523 | CWA: 0.7006 | ZSRTA: nan',\n'\\n', 'Experiment data saved to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/0-\nrun/process_ForkProcess-9/working', '\\n', 'Execution time: 16 seconds seconds\n(time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Vocab size: 18', '\\n', '# train labels: 2', '\\n', '\\n===== Training with\nbatch size 32 =====', '\\n', 'Epoch 1: train_acc=0.9637 val_acc=0.9878\nval_loss=0.0337 HMA=0.9882', '\\n', 'Epoch 2: train_acc=0.9954 val_acc=0.9974\nval_loss=0.0107 HMA=0.9974', '\\n', 'Epoch 3: train_acc=0.9994 val_acc=0.9992\nval_loss=0.0032 HMA=0.9992', '\\n', 'Epoch 4: train_acc=1.0000 val_acc=0.9998\nval_loss=0.0018 HMA=0.9998', '\\n', 'Epoch 5: train_acc=1.0000 val_acc=0.9998\nval_loss=0.0017 HMA=0.9998', '\\n', 'TEST  acc=0.7001 SWA=0.6523 CWA=0.7006\nHMA=0.6756 ZSRTA=0.0000', '\\n', '\\n===== Training with batch size 64 =====',\n'\\n', 'Epoch 1: train_acc=0.9535 val_acc=0.9872 val_loss=0.0463 HMA=0.9874',\n'\\n', 'Epoch 2: train_acc=0.9912 val_acc=0.9968 val_loss=0.0144 HMA=0.9967',\n'\\n', 'Epoch 3: train_acc=0.9982 val_acc=0.9992 val_loss=0.0035 HMA=0.9993',\n'\\n', 'Epoch 4: train_acc=0.9999 val_acc=0.9998 val_loss=0.0016 HMA=0.9999',\n'\\n', 'Epoch 5: train_acc=1.0000 val_acc=0.9998 val_loss=0.0012 HMA=0.9999',\n'\\n', 'TEST  acc=0.7000 SWA=0.6522 CWA=0.7005 HMA=0.6755 ZSRTA=0.0000', '\\n',\n'\\n===== Training with batch size 128 =====', '\\n', 'Epoch 1: train_acc=0.9419\nval_acc=0.9744 val_loss=0.0734 HMA=0.9754', '\\n', 'Epoch 2: train_acc=0.9865\nval_acc=0.9898 val_loss=0.0344 HMA=0.9901', '\\n', 'Epoch 3: train_acc=0.9940\nval_acc=0.9966 val_loss=0.0126 HMA=0.9966', '\\n', 'Epoch 4: train_acc=0.9988\nval_acc=0.9986 val_loss=0.0057 HMA=0.9986', '\\n', 'Epoch 5: train_acc=1.0000\nval_acc=0.9990 val_loss=0.0031 HMA=0.9990', '\\n', 'TEST  acc=0.7003 SWA=0.6526\nCWA=0.7008 HMA=0.6758 ZSRTA=0.0000', '\\n', '\\n===== Training with batch size 256\n=====', '\\n', 'Epoch 1: train_acc=0.9247 val_acc=0.9548 val_loss=0.1483\nHMA=0.9568', '\\n', 'Epoch 2: train_acc=0.9639 val_acc=0.9766 val_loss=0.0891\nHMA=0.9771', '\\n', 'Epoch 3: train_acc=0.9811 val_acc=0.9908 val_loss=0.0390\nHMA=0.9910', '\\n', 'Epoch 4: train_acc=0.9927 val_acc=0.9912 val_loss=0.0210\nHMA=0.9913', '\\n', 'Epoch 5: train_acc=0.9970 val_acc=0.9974 val_loss=0.0102\nHMA=0.9974', '\\n', 'TEST  acc=0.6997 SWA=0.6523 CWA=0.7004 HMA=0.6755\nZSRTA=0.0000', '\\n', '\\n===== Training with batch size 512 =====', '\\n', 'Epoch\n1: train_acc=0.9010 val_acc=0.9530 val_loss=0.1712 HMA=0.9545', '\\n', 'Epoch 2:\ntrain_acc=0.9563 val_acc=0.9598 val_loss=0.1389 HMA=0.9613', '\\n', 'Epoch 3:\ntrain_acc=0.9616 val_acc=0.9616 val_loss=0.1100 HMA=0.9629', '\\n', 'Epoch 4:\ntrain_acc=0.9749 val_acc=0.9850 val_loss=0.0661 HMA=0.9854', '\\n', 'Epoch 5:\ntrain_acc=0.9853 val_acc=0.9872 val_loss=0.0371 HMA=0.9875', '\\n', 'TEST\nacc=0.6956 SWA=0.6494 CWA=0.6961 HMA=0.6720 ZSRTA=0.0000', '\\n', '\\nAll\nexperiment data saved to /home/zxl240011/AI-Scientist-v2/experiments/2025-07-\n27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/0-run/process_ForkProcess-\n9/working/experiment_data.npy', '\\n', 'Execution time: 31 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', '\\n=== Batch-size sweep: 64 ===', '\\n', 'Traceback\n(most recent call last):\\n  File \"runfile.py\", line 237, in <module>\\n\nval_loss, val_acc = run_epoch(model, dev_loader, criterion)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 145, in\nrun_epoch\\n    loss = criterion(logits, batch[\"label\"])\\n\n~~~~~^^^^^^^^^\\nKeyError: \\'label\\'\\n', 'Execution time: 3 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Vocab size: 18', '\\n', '# seen rule labels: 2', '\\n', '\\n=== Training\nwith hidden_dim=64 ===', '\\n', 'Epoch 1: train_acc=0.9258 val_acc=0.9614\nval_loss=0.1383', '\\n', 'Epoch 2: train_acc=0.9757 val_acc=0.9854\nval_loss=0.0432', '\\n', 'Epoch 3: train_acc=0.9917 val_acc=0.9952\nval_loss=0.0208', '\\n', 'Epoch 4: train_acc=0.9970 val_acc=0.9966\nval_loss=0.0118', '\\n', 'Epoch 5: train_acc=0.9982 val_acc=0.9986\nval_loss=0.0071', '\\n', 'TEST Acc=0.7014 | SWA=0.6538 | CWA=0.7020 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=128 ===', '\\n', 'Epoch 1: train_acc=0.9344\nval_acc=0.9622 val_loss=0.1232', '\\n', 'Epoch 2: train_acc=0.9768 val_acc=0.9886\nval_loss=0.0360', '\\n', 'Epoch 3: train_acc=0.9939 val_acc=0.9968\nval_loss=0.0181', '\\n', 'Epoch 4: train_acc=0.9981 val_acc=0.9980\nval_loss=0.0076', '\\n', 'Epoch 5: train_acc=0.9993 val_acc=0.9992\nval_loss=0.0039', '\\n', 'TEST Acc=0.7003 | SWA=0.6527 | CWA=0.7009 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=256 ===', '\\n', 'Epoch 1: train_acc=0.9455\nval_acc=0.9800 val_loss=0.0610', '\\n', 'Epoch 2: train_acc=0.9898 val_acc=0.9950\nval_loss=0.0159', '\\n', 'Epoch 3: train_acc=0.9968 val_acc=0.9934\nval_loss=0.0215', '\\n', 'Epoch 4: train_acc=0.9992 val_acc=1.0000\nval_loss=0.0011', '\\n', 'Epoch 5: train_acc=1.0000 val_acc=1.0000\nval_loss=0.0007', '\\n', 'TEST Acc=0.7001 | SWA=0.6523 | CWA=0.7006 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=512 ===', '\\n', 'Epoch 1: train_acc=0.9528\nval_acc=0.9832 val_loss=0.0609', '\\n', 'Epoch 2: train_acc=0.9882 val_acc=0.9910\nval_loss=0.0336', '\\n', 'Epoch 3: train_acc=0.9950 val_acc=1.0000\nval_loss=0.0026', '\\n', 'Epoch 4: train_acc=0.9999 val_acc=0.9998\nval_loss=0.0009', '\\n', 'Epoch 5: train_acc=1.0000 val_acc=1.0000\nval_loss=0.0005', '\\n', 'TEST Acc=0.7000 | SWA=0.6522 | CWA=0.7005 | ZSRTA=nan',\n'\\n', '\\nSaved experiment data to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/0-\nrun/process_ForkProcess-8/working/experiment_data.npy', '\\n', 'Execution time:\n44 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Vocab size: 18', '\\n', '#seen rule labels: 2', '\\n', '\\n===== Training\nwith weight_decay=0.0 =====', '\\n', 'Epoch 1: train_acc=0.9368 | val_acc=0.9644\n| val_loss=0.1083', '\\n', 'Epoch 2: train_acc=0.9837 | val_acc=0.9936 |\nval_loss=0.0291', '\\n', 'Epoch 3: train_acc=0.9954 | val_acc=0.9966 |\nval_loss=0.0106', '\\n', 'Epoch 4: train_acc=0.9987 | val_acc=0.9994 |\nval_loss=0.0043', '\\n', 'Epoch 5: train_acc=1.0000 | val_acc=0.9996 |\nval_loss=0.0021', '\\n', 'TEST Acc=0.7002 | SWA=0.6525 | CWA=0.7007 | ZSRTA=nan',\n'\\n', '\\n===== Training with weight_decay=1e-06 =====', '\\n', 'Epoch 1:\ntrain_acc=0.9391 | val_acc=0.9654 | val_loss=0.1101', '\\n', 'Epoch 2:\ntrain_acc=0.9795 | val_acc=0.9864 | val_loss=0.0417', '\\n', 'Epoch 3:\ntrain_acc=0.9923 | val_acc=0.9940 | val_loss=0.0205', '\\n', 'Epoch 4:\ntrain_acc=0.9972 | val_acc=0.9972 | val_loss=0.0084', '\\n', 'Epoch 5:\ntrain_acc=0.9990 | val_acc=0.9986 | val_loss=0.0055', '\\n', 'TEST Acc=0.7015 |\nSWA=0.6540 | CWA=0.7020 | ZSRTA=nan', '\\n', '\\n===== Training with\nweight_decay=1e-05 =====', '\\n', 'Epoch 1: train_acc=0.9396 | val_acc=0.9736 |\nval_loss=0.0828', '\\n', 'Epoch 2: train_acc=0.9849 | val_acc=0.9888 |\nval_loss=0.0364', '\\n', 'Epoch 3: train_acc=0.9938 | val_acc=0.9982 |\nval_loss=0.0109', '\\n', 'Epoch 4: train_acc=0.9987 | val_acc=0.9996 |\nval_loss=0.0039', '\\n', 'Epoch 5: train_acc=0.9999 | val_acc=0.9994 |\nval_loss=0.0025', '\\n', 'TEST Acc=0.7000 | SWA=0.6523 | CWA=0.7005 | ZSRTA=nan',\n'\\n', '\\n===== Training with weight_decay=0.0001 =====', '\\n', 'Epoch 1:\ntrain_acc=0.9362 | val_acc=0.9618 | val_loss=0.1226', '\\n', 'Epoch 2:\ntrain_acc=0.9791 | val_acc=0.9900 | val_loss=0.0333', '\\n', 'Epoch 3:\ntrain_acc=0.9933 | val_acc=0.9960 | val_loss=0.0159', '\\n', 'Epoch 4:\ntrain_acc=0.9977 | val_acc=0.9968 | val_loss=0.0104', '\\n', 'Epoch 5:\ntrain_acc=0.9988 | val_acc=0.9978 | val_loss=0.0069', '\\n', 'TEST Acc=0.7010 |\nSWA=0.6536 | CWA=0.7015 | ZSRTA=nan', '\\n', '\\n===== Training with\nweight_decay=0.001 =====', '\\n', 'Epoch 1: train_acc=0.9334 | val_acc=0.9554 |\nval_loss=0.1492', '\\n', 'Epoch 2: train_acc=0.9712 | val_acc=0.9860 |\nval_loss=0.0512', '\\n', 'Epoch 3: train_acc=0.9861 | val_acc=0.9864 |\nval_loss=0.0472', '\\n', 'Epoch 4: train_acc=0.9885 | val_acc=0.9890 |\nval_loss=0.0388', '\\n', 'Epoch 5: train_acc=0.9892 | val_acc=0.9886 |\nval_loss=0.0344', '\\n', 'TEST Acc=0.6971 | SWA=0.6509 | CWA=0.6976 | ZSRTA=nan',\n'\\n', '\\nAll experiment data saved in /home/zxl240011/AI-Scientist-\nv2/experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/0-\nrun/process_ForkProcess-6/working/experiment_data.npy', '\\n', 'Execution time:\n19 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Vocab size: 18', '\\n', '# seen rule labels: 2', '\\n', '\\n=== Training\nwith hidden_dim=64 ===', '\\n', 'Epoch 1: train_acc=0.9258 val_acc=0.9614\nval_loss=0.1383', '\\n', 'Epoch 2: train_acc=0.9757 val_acc=0.9854\nval_loss=0.0432', '\\n', 'Epoch 3: train_acc=0.9917 val_acc=0.9952\nval_loss=0.0208', '\\n', 'Epoch 4: train_acc=0.9970 val_acc=0.9966\nval_loss=0.0118', '\\n', 'Epoch 5: train_acc=0.9982 val_acc=0.9986\nval_loss=0.0071', '\\n', 'TEST Acc=0.7014 | SWA=0.6538 | CWA=0.7020 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=128 ===', '\\n', 'Epoch 1: train_acc=0.9344\nval_acc=0.9622 val_loss=0.1232', '\\n', 'Epoch 2: train_acc=0.9768 val_acc=0.9886\nval_loss=0.0360', '\\n', 'Epoch 3: train_acc=0.9939 val_acc=0.9968\nval_loss=0.0181', '\\n', 'Epoch 4: train_acc=0.9981 val_acc=0.9980\nval_loss=0.0076', '\\n', 'Epoch 5: train_acc=0.9993 val_acc=0.9992\nval_loss=0.0039', '\\n', 'TEST Acc=0.7003 | SWA=0.6527 | CWA=0.7009 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=256 ===', '\\n', 'Epoch 1: train_acc=0.9455\nval_acc=0.9800 val_loss=0.0610', '\\n', 'Epoch 2: train_acc=0.9898 val_acc=0.9950\nval_loss=0.0159', '\\n', 'Epoch 3: train_acc=0.9968 val_acc=0.9934\nval_loss=0.0215', '\\n', 'Epoch 4: train_acc=0.9992 val_acc=1.0000\nval_loss=0.0011', '\\n', 'Epoch 5: train_acc=1.0000 val_acc=1.0000\nval_loss=0.0007', '\\n', 'TEST Acc=0.7001 | SWA=0.6523 | CWA=0.7006 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=512 ===', '\\n', 'Epoch 1: train_acc=0.9528\nval_acc=0.9832 val_loss=0.0609', '\\n', 'Epoch 2: train_acc=0.9882 val_acc=0.9910\nval_loss=0.0336', '\\n', 'Epoch 3: train_acc=0.9950 val_acc=1.0000\nval_loss=0.0026', '\\n', 'Epoch 4: train_acc=0.9999 val_acc=0.9998\nval_loss=0.0009', '\\n', 'Epoch 5: train_acc=1.0000 val_acc=1.0000\nval_loss=0.0005', '\\n', 'TEST Acc=0.7000 | SWA=0.6522 | CWA=0.7005 | ZSRTA=nan',\n'\\n', '\\nSaved experiment data to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/0-\nrun/process_ForkProcess-7/working/experiment_data.npy', '\\n', 'Execution time:\n16 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Vocab size: 18', '\\n', '# seen rule labels: 2', '\\n', '\\n=== Training\nwith hidden_dim=64 ===', '\\n', 'Epoch 1: train_acc=0.9258 val_acc=0.9614\nval_loss=0.1383', '\\n', 'Epoch 2: train_acc=0.9757 val_acc=0.9854\nval_loss=0.0432', '\\n', 'Epoch 3: train_acc=0.9917 val_acc=0.9952\nval_loss=0.0208', '\\n', 'Epoch 4: train_acc=0.9970 val_acc=0.9966\nval_loss=0.0118', '\\n', 'Epoch 5: train_acc=0.9982 val_acc=0.9986\nval_loss=0.0071', '\\n', 'TEST Acc=0.7014 | SWA=0.6538 | CWA=0.7020 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=128 ===', '\\n', 'Epoch 1: train_acc=0.9344\nval_acc=0.9622 val_loss=0.1232', '\\n', 'Epoch 2: train_acc=0.9768 val_acc=0.9886\nval_loss=0.0360', '\\n', 'Epoch 3: train_acc=0.9939 val_acc=0.9968\nval_loss=0.0181', '\\n', 'Epoch 4: train_acc=0.9981 val_acc=0.9980\nval_loss=0.0076', '\\n', 'Epoch 5: train_acc=0.9993 val_acc=0.9992\nval_loss=0.0039', '\\n', 'TEST Acc=0.7003 | SWA=0.6527 | CWA=0.7009 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=256 ===', '\\n', 'Epoch 1: train_acc=0.9455\nval_acc=0.9800 val_loss=0.0610', '\\n', 'Epoch 2: train_acc=0.9898 val_acc=0.9950\nval_loss=0.0159', '\\n', 'Epoch 3: train_acc=0.9968 val_acc=0.9934\nval_loss=0.0215', '\\n', 'Epoch 4: train_acc=0.9992 val_acc=1.0000\nval_loss=0.0011', '\\n', 'Epoch 5: train_acc=1.0000 val_acc=1.0000\nval_loss=0.0007', '\\n', 'TEST Acc=0.7001 | SWA=0.6523 | CWA=0.7006 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=512 ===', '\\n', 'Epoch 1: train_acc=0.9528\nval_acc=0.9832 val_loss=0.0609', '\\n', 'Epoch 2: train_acc=0.9882 val_acc=0.9910\nval_loss=0.0336', '\\n', 'Epoch 3: train_acc=0.9950 val_acc=1.0000\nval_loss=0.0026', '\\n', 'Epoch 4: train_acc=0.9999 val_acc=0.9998\nval_loss=0.0009', '\\n', 'Epoch 5: train_acc=1.0000 val_acc=1.0000\nval_loss=0.0005', '\\n', 'TEST Acc=0.7000 | SWA=0.6522 | CWA=0.7005 | ZSRTA=nan',\n'\\n', '\\nSaved experiment data to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/0-\nrun/process_ForkProcess-6/working/experiment_data.npy', '\\n', 'Execution time:\n18 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Vocab size: 18', '\\n', '# seen rule labels: 2', '\\n', '\\n=== Training\nwith hidden_dim=64 ===', '\\n', 'Epoch 1: train_acc=0.9258 val_acc=0.9614\nval_loss=0.1383', '\\n', 'Epoch 2: train_acc=0.9757 val_acc=0.9854\nval_loss=0.0432', '\\n', 'Epoch 3: train_acc=0.9917 val_acc=0.9952\nval_loss=0.0208', '\\n', 'Epoch 4: train_acc=0.9970 val_acc=0.9966\nval_loss=0.0118', '\\n', 'Epoch 5: train_acc=0.9982 val_acc=0.9986\nval_loss=0.0071', '\\n', 'TEST Acc=0.7014 | SWA=0.6538 | CWA=0.7020 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=128 ===', '\\n', 'Epoch 1: train_acc=0.9344\nval_acc=0.9622 val_loss=0.1232', '\\n', 'Epoch 2: train_acc=0.9768 val_acc=0.9886\nval_loss=0.0360', '\\n', 'Epoch 3: train_acc=0.9939 val_acc=0.9968\nval_loss=0.0181', '\\n', 'Epoch 4: train_acc=0.9981 val_acc=0.9980\nval_loss=0.0076', '\\n', 'Epoch 5: train_acc=0.9993 val_acc=0.9992\nval_loss=0.0039', '\\n', 'TEST Acc=0.7003 | SWA=0.6527 | CWA=0.7009 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=256 ===', '\\n', 'Epoch 1: train_acc=0.9455\nval_acc=0.9800 val_loss=0.0610', '\\n', 'Epoch 2: train_acc=0.9898 val_acc=0.9950\nval_loss=0.0159', '\\n', 'Epoch 3: train_acc=0.9968 val_acc=0.9934\nval_loss=0.0215', '\\n', 'Epoch 4: train_acc=0.9992 val_acc=1.0000\nval_loss=0.0011', '\\n', 'Epoch 5: train_acc=1.0000 val_acc=1.0000\nval_loss=0.0007', '\\n', 'TEST Acc=0.7001 | SWA=0.6523 | CWA=0.7006 | ZSRTA=nan',\n'\\n', '\\n=== Training with hidden_dim=512 ===', '\\n', 'Epoch 1: train_acc=0.9528\nval_acc=0.9832 val_loss=0.0609', '\\n', 'Epoch 2: train_acc=0.9882 val_acc=0.9910\nval_loss=0.0336', '\\n', 'Epoch 3: train_acc=0.9950 val_acc=1.0000\nval_loss=0.0026', '\\n', 'Epoch 4: train_acc=0.9999 val_acc=0.9998\nval_loss=0.0009', '\\n', 'Epoch 5: train_acc=1.0000 val_acc=1.0000\nval_loss=0.0005', '\\n', 'TEST Acc=0.7000 | SWA=0.6522 | CWA=0.7005 | ZSRTA=nan',\n'\\n', '\\nSaved experiment data to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/0-\nrun/process_ForkProcess-8/working/experiment_data.npy', '\\n', 'Execution time:\n42 seconds seconds (time limit is 30 minutes).']", ""], "analysis": ["", "The execution was successful, and the model training proceeded without any\nerrors or bugs. The training and validation accuracies improved as the number of\nepochs increased, indicating that the model is learning effectively. However,\nthe test accuracy, Shape-Weighted Accuracy (SWA), and Color-Weighted Accuracy\n(CWA) remained relatively constant across different epoch settings, suggesting\nthat the model's performance on unseen data is not improving with more training.\nAdditionally, the Zero-Shot Rule Transfer Accuracy (ZSRTA) metric consistently\nreturned 'nan,' indicating that the model did not encounter any zero-shot\nexamples in the test set. This could be due to the absence of unseen labels in\nthe dataset or a limitation in the current experimental setup. Overall, while\nthe training and validation results are promising, the lack of improvement in\ntest metrics and the 'nan' ZSRTA values warrant further investigation.", "The training script executed successfully without any errors or bugs. The\nhyperparameter tuning identified the best learning rate as 0.002, achieving a\nvalidation accuracy of 99.98%. However, during testing, the overall test\naccuracy was 70.00%, with Shape-Weighted Accuracy (SWA) of 65.22% and Color-\nWeighted Accuracy (CWA) of 70.05%. The Zero-Shot Rule Transfer Accuracy (ZSRTA)\ncould not be computed (resulted in NaN) due to the absence of unseen rules in\nthe test set. The results have been saved correctly.", "The training script produced consistent results across different batch sizes,\nbut there is a critical issue with the ZSRTA (Zero-Shot Rule Transfer Accuracy)\nmetric. It consistently outputs 'nan' (not a number), indicating a bug in the\ncode or an issue with the data. This could be due to the absence of zero-shot\nexamples in the test set or a failure in identifying unseen rules during\nevaluation. To fix this, ensure that the test set contains examples with unseen\nrules and verify the logic for identifying zero-shot examples (zs_ids). Add\nchecks to handle cases where zs_ids is empty to avoid 'nan' results.", "", "The code executed successfully without any errors or bugs. The model trained on\nthe SPR_BENCH dataset with varying batch sizes and achieved high validation\naccuracy and low loss during training. However, the test results showed that the\nmodel struggled with zero-shot reasoning, as indicated by a ZSRTA score of 0.0\nacross all batch sizes. This suggests that while the model performs well on seen\ndata, it fails to generalize to unseen data, which is a key aspect of the\nresearch goal. Future work should focus on improving the model's zero-shot\nreasoning capabilities, possibly by introducing architectural changes or\nadditional training strategies.", "The script fails due to a KeyError: 'label' in the run_epoch function when\nprocessing the dev_loader. The issue arises because the dev dataset (used in\ndev_loader) is initialized with train=False in the SPRTorchDataset class, which\nomits the 'label' key from the dataset items. Instead, it includes 'label_str'\nfor evaluation purposes. To fix this, modify the run_epoch function to handle\ndatasets without 'label' keys by either skipping the evaluation or adapting the\nlogic to work with 'label_str' for non-training datasets.", "", "", "The training script exhibits a significant issue with zero-shot rule transfer\naccuracy (ZSRTA). The ZSRTA metric consistently returns 'nan' across all\nhyperparameter settings, indicating that the model is unable to handle unseen\nrules during testing. This suggests a critical flaw in the training or\nevaluation process, particularly in the handling of unseen rule labels. To fix\nthis, ensure that the test set contains examples with unseen labels that are not\npresent in the training set. Additionally, verify the logic used to identify and\nevaluate zero-shot indices (zs_idx) to ensure it correctly captures and\nevaluates zero-shot scenarios.", "The output indicates that the Zero-Shot Rule Transfer Accuracy (ZSRTA) is 'nan'\nacross all hidden dimensions tested. This suggests that the model is not\nperforming zero-shot reasoning, which is a critical objective of the experiment.\nThis issue may arise because the unseen rules in the test set are not being\nhandled properly, possibly due to a lack of generalization in the model or a\nproblem in the dataset or evaluation logic. To fix this, consider:  1. Verifying\nthat the test set contains unseen rules and that these are correctly identified\nduring evaluation. 2. Modifying the model architecture or training procedure to\nexplicitly encourage generalization to unseen rules. 3. Ensuring that the\nevaluation logic for ZSRTA correctly identifies and evaluates unseen rules.", "", ""], "exc_type": [null, null, null, null, null, null, "KeyError", null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, {"args": ["label"]}, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 237, "<module>", "val_loss, val_acc = run_epoch(model, dev_loader, criterion)"], ["runfile.py", 145, "run_epoch", "loss = criterion(logits, batch[\"label\"])"]], null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9999, "best_value": 0.9999}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0021, "best_value": 0.0021}]}, {"metric_name": "zero-shot rule transfer accuracy", "lower_is_better": false, "description": "Accuracy of the model in zero-shot rule transfer tasks.", "data": [{"dataset_name": "SPR_BENCH", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9996, "best_value": 0.9996}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.001, "best_value": 0.001}]}, {"metric_name": "zero-shot rule transfer accuracy", "lower_is_better": false, "description": "The accuracy of the model in a zero-shot rule transfer setting.", "data": [{"dataset_name": "SPR_BENCH", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0004, "best_value": 0.0004}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.001, "best_value": 0.001}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "The accuracy of the model on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7, "best_value": 0.7}]}, {"metric_name": "zero-shot rule transfer accuracy", "lower_is_better": false, "description": "The accuracy of the model in zero-shot rule transfer scenarios.", "data": [{"dataset_name": "SPR_BENCH", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH - Batch size 32", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "SPR_BENCH - Batch size 64", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "SPR_BENCH - Batch size 128", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "SPR_BENCH - Batch size 256", "final_value": 0.9974, "best_value": 0.9974}, {"dataset_name": "SPR_BENCH - Batch size 512", "final_value": 0.9806, "best_value": 0.9806}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH - Batch size 32", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH - Batch size 64", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH - Batch size 128", "final_value": 0.9994, "best_value": 0.9994}, {"dataset_name": "SPR_BENCH - Batch size 256", "final_value": 0.998, "best_value": 0.998}, {"dataset_name": "SPR_BENCH - Batch size 512", "final_value": 0.9826, "best_value": 0.9826}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH - Batch size 32", "final_value": 0.0009, "best_value": 0.0009}, {"dataset_name": "SPR_BENCH - Batch size 64", "final_value": 0.0017, "best_value": 0.0017}, {"dataset_name": "SPR_BENCH - Batch size 128", "final_value": 0.0024, "best_value": 0.0024}, {"dataset_name": "SPR_BENCH - Batch size 256", "final_value": 0.0097, "best_value": 0.0097}, {"dataset_name": "SPR_BENCH - Batch size 512", "final_value": 0.0568, "best_value": 0.0568}]}, {"metric_name": "zero-shot rule transfer accuracy", "lower_is_better": false, "description": "The accuracy of the model on zero-shot rule transfer tasks.", "data": [{"dataset_name": "SPR_BENCH - Batch size 32", "final_value": null, "best_value": null}, {"dataset_name": "SPR_BENCH - Batch size 64", "final_value": null, "best_value": null}, {"dataset_name": "SPR_BENCH - Batch size 128", "final_value": null, "best_value": null}, {"dataset_name": "SPR_BENCH - Batch size 256", "final_value": null, "best_value": null}, {"dataset_name": "SPR_BENCH - Batch size 512", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The proportion of correctly classified instances during training.", "data": [{"dataset_name": "dropout_0.0", "final_value": 0.9997, "best_value": 0.9997}, {"dataset_name": "dropout_0.2", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "dropout_0.4", "final_value": 0.9993, "best_value": 0.9993}, {"dataset_name": "dropout_0.6", "final_value": 0.9966, "best_value": 0.9966}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The proportion of correctly classified instances on the validation dataset.", "data": [{"dataset_name": "dropout_0.0", "final_value": 0.999, "best_value": 0.999}, {"dataset_name": "dropout_0.2", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "dropout_0.4", "final_value": 0.999, "best_value": 0.999}, {"dataset_name": "dropout_0.6", "final_value": 0.9978, "best_value": 0.9978}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset, indicating model performance.", "data": [{"dataset_name": "dropout_0.0", "final_value": 0.003, "best_value": 0.003}, {"dataset_name": "dropout_0.2", "final_value": 0.0025, "best_value": 0.0025}, {"dataset_name": "dropout_0.4", "final_value": 0.0032, "best_value": 0.0032}, {"dataset_name": "dropout_0.6", "final_value": 0.0074, "best_value": 0.0074}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0012, "best_value": 0.0012}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Weighted accuracy of the model based on shape.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "Weighted accuracy of the model based on color.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9999, "best_value": 0.9999}]}, {"metric_name": "harmonic mean accuracy", "lower_is_better": false, "description": "The harmonic mean of shape-weighted and color-weighted accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9999, "best_value": 0.9999}]}, {"metric_name": "zero-shot accuracy", "lower_is_better": false, "description": "The accuracy of the model in a zero-shot setting.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0002, "best_value": 0.0002}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0005, "best_value": 0.0005}]}, {"metric_name": "zero-shot rule transfer accuracy", "lower_is_better": false, "description": "Accuracy of the model in a zero-shot rule transfer scenario.", "data": [{"dataset_name": "SPR_BENCH", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy on the training set", "data": [{"dataset_name": "wd_0.0", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "wd_1e-06", "final_value": 0.999, "best_value": 0.999}, {"dataset_name": "wd_1e-05", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "wd_0.0001", "final_value": 0.9988, "best_value": 0.9988}, {"dataset_name": "wd_0.001", "final_value": 0.9892, "best_value": 0.9892}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy on the validation set", "data": [{"dataset_name": "wd_0.0", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "wd_1e-06", "final_value": 0.9986, "best_value": 0.9986}, {"dataset_name": "wd_1e-05", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "wd_0.0001", "final_value": 0.9978, "best_value": 0.9978}, {"dataset_name": "wd_0.001", "final_value": 0.989, "best_value": 0.989}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on the validation set", "data": [{"dataset_name": "wd_0.0", "final_value": 0.0021, "best_value": 0.0021}, {"dataset_name": "wd_1e-06", "final_value": 0.0055, "best_value": 0.0055}, {"dataset_name": "wd_1e-05", "final_value": 0.0025, "best_value": 0.0025}, {"dataset_name": "wd_0.0001", "final_value": 0.0069, "best_value": 0.0069}, {"dataset_name": "wd_0.001", "final_value": 0.0344, "best_value": 0.0344}]}, {"metric_name": "zero-shot rule transfer accuracy", "lower_is_better": false, "description": "Accuracy for zero-shot rule transfer task", "data": [{"dataset_name": "wd_0.0", "final_value": null, "best_value": null}, {"dataset_name": "wd_1e-06", "final_value": null, "best_value": null}, {"dataset_name": "wd_1e-05", "final_value": null, "best_value": null}, {"dataset_name": "wd_0.0001", "final_value": null, "best_value": null}, {"dataset_name": "wd_0.001", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Measures the accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Measures the accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0005, "best_value": 0.0005}]}, {"metric_name": "zero-shot rule transfer accuracy", "lower_is_better": false, "description": "Measures the model's zero-shot rule transfer performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0005, "best_value": 0.0005}]}, {"metric_name": "zero-shot rule transfer accuracy", "lower_is_better": false, "description": "Accuracy of the model in zero-shot rule transfer tasks.", "data": [{"dataset_name": "SPR_BENCH", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0005, "best_value": 0.0005}]}, {"metric_name": "zero-shot rule transfer accuracy", "lower_is_better": false, "description": "The accuracy of the model in zero-shot rule transfer scenarios.", "data": [{"dataset_name": "SPR_BENCH", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, false, false, false, true, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_5415ccb8abe04692a4f6c63f26d413a2_proc_310211/SPR_BENCH_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_5415ccb8abe04692a4f6c63f26d413a2_proc_310211/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_5415ccb8abe04692a4f6c63f26d413a2_proc_310211/SPR_BENCH_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_val_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_train_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_ZSRTA_bar.png"], ["../../logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_val_acc_vs_lr.png", "../../logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_test_metrics.png"], [], ["../../logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_dropout_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_dropout_loss_curves.png", "../../logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_final_val_accuracy_bar.png", "../../logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_zsrta_bar.png"], ["../../logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_hma_curve.png", "../../logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_weighted_accuracy.png", "../../logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_zeroshot_accuracy.png"], [], ["../../logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_hidden_dim_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_hidden_dim_loss_curves.png", "../../logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_final_val_accuracy_bar.png", "../../logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_ZSRTA_bar.png"], ["../../logs/0-run/experiment_results/experiment_615c2d14706d408d8da1d1a2381cc0f2_proc_312325/spr_bench_train_val_accuracy.png", "../../logs/0-run/experiment_results/experiment_615c2d14706d408d8da1d1a2381cc0f2_proc_312325/spr_bench_val_loss.png", "../../logs/0-run/experiment_results/experiment_615c2d14706d408d8da1d1a2381cc0f2_proc_312325/spr_bench_zsrta_bar.png"], [], [], ["../../logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_hidden_dim_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_hidden_dim_loss_curves.png", "../../logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_final_val_accuracy_bar.png", "../../logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_ZSRTA_bar.png"], []], "plot_paths": [["experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5415ccb8abe04692a4f6c63f26d413a2_proc_310211/SPR_BENCH_accuracy_curve.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5415ccb8abe04692a4f6c63f26d413a2_proc_310211/SPR_BENCH_loss_curve.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5415ccb8abe04692a4f6c63f26d413a2_proc_310211/SPR_BENCH_test_metrics.png"], ["experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_val_accuracy_curves.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_train_accuracy_curves.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_loss_curves.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_ZSRTA_bar.png"], ["experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_accuracy_curves.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_loss_curves.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_val_acc_vs_lr.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_test_metrics.png"], [], ["experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_dropout_accuracy_curves.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_dropout_loss_curves.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_final_val_accuracy_bar.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_zsrta_bar.png"], ["experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_accuracy_curve.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_loss_curve.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_hma_curve.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_weighted_accuracy.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_zeroshot_accuracy.png"], [], ["experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_hidden_dim_accuracy_curves.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_hidden_dim_loss_curves.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_final_val_accuracy_bar.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_ZSRTA_bar.png"], ["experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_615c2d14706d408d8da1d1a2381cc0f2_proc_312325/spr_bench_train_val_accuracy.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_615c2d14706d408d8da1d1a2381cc0f2_proc_312325/spr_bench_val_loss.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_615c2d14706d408d8da1d1a2381cc0f2_proc_312325/spr_bench_zsrta_bar.png"], [], [], ["experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_hidden_dim_accuracy_curves.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_hidden_dim_loss_curves.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_final_val_accuracy_bar.png", "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_ZSRTA_bar.png"], []], "plot_analyses": [[{"analysis": "The plot shows the accuracy trends for training and validation over epochs. Both training and validation accuracy increase steadily and converge close to 1.0, indicating that the model achieves near-perfect performance without signs of overfitting. The convergence of the two curves suggests a well-generalized model.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5415ccb8abe04692a4f6c63f26d413a2_proc_310211/SPR_BENCH_accuracy_curve.png"}, {"analysis": "This plot depicts the loss trends for training and validation over epochs. Both training and validation losses decrease steadily and approach zero, which is consistent with the high accuracy observed. The similar patterns between the two curves further support that the model is not overfitting and is learning effectively.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5415ccb8abe04692a4f6c63f26d413a2_proc_310211/SPR_BENCH_loss_curve.png"}, {"analysis": "The plot is empty and does not provide any meaningful information about the final test metrics. This could indicate missing or improperly recorded results for the zero-shot reasoning task (ZSRT). Further investigation is needed to understand the lack of data.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_5415ccb8abe04692a4f6c63f26d413a2_proc_310211/SPR_BENCH_test_metrics.png"}], [{"analysis": "The validation accuracy plot demonstrates that the model achieves near-perfect accuracy very quickly, regardless of the number of epochs. This suggests that the model is able to generalize well to the validation set after just a few epochs. However, the lack of significant improvement with additional epochs indicates that the model may be saturating in terms of performance on the validation set early in the training process.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_val_accuracy_curves.png"}, {"analysis": "The training accuracy plot shows that the model also achieves near-perfect accuracy very quickly, similar to the validation accuracy. This indicates that the model is effectively learning the training data. However, the rapid convergence might suggest that the task is relatively simple or that the model is overfitting to the training data, especially if the validation accuracy does not improve correspondingly.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_train_accuracy_curves.png"}, {"analysis": "The loss curves reveal a rapid decrease in both training and validation loss within the first few epochs, followed by a plateau. This behavior aligns with the accuracy plots, confirming that the model quickly reaches its optimal performance. The near-zero loss values further emphasize the ease with which the model is able to fit the training data and generalize to the validation set. However, the convergence to such low loss values might also indicate that the model is not being challenged sufficiently by the dataset.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_loss_curves.png"}, {"analysis": "The zero-shot rule transfer accuracy (ZSRTA) plot is empty, indicating that no data or results were recorded for this metric. This is a critical issue, as ZSRTA is a key metric for evaluating the model's ability to generalize to unseen rules. Without this data, it is impossible to assess the model's zero-shot reasoning capabilities, which is central to the research hypothesis.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_877a79691070434ab120dd02a54338ba_proc_312325/SPR_BENCH_ZSRTA_bar.png"}], [{"analysis": "The plot shows the training and validation accuracy for different learning rates across five epochs. Higher learning rates (0.001 and 0.002) converge faster and achieve higher validation accuracy compared to lower learning rates (0.0003 and 0.0005). The learning rate of 0.002 achieves nearly perfect accuracy, suggesting that it is well-suited for the model. However, overfitting should be monitored as the gap between training and validation accuracy is minimal for all learning rates.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_accuracy_curves.png"}, {"analysis": "This plot illustrates the training and validation loss for different learning rates across five epochs. Higher learning rates (0.001 and 0.002) result in faster convergence and lower final loss values, indicating better optimization. The loss curves for these learning rates are smooth and exhibit no significant fluctuations, suggesting stable training. Lower learning rates (0.0003 and 0.0005) show slower convergence and higher final loss values.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot highlights the relationship between the final validation accuracy and the learning rate. There is a clear positive correlation, with higher learning rates leading to better final validation accuracy. The learning rate of 0.002 achieves the highest accuracy, reinforcing its suitability for this experiment.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_val_acc_vs_lr.png"}, {"analysis": "This plot summarizes the test performance metrics, focusing on Overall Accuracy. The model achieves a moderately high overall accuracy, but further analysis of SWA (Shape-Weighted Accuracy), CWA (Color-Weighted Accuracy), and ZSRTA (Zero-Shot Rule Transfer Accuracy) metrics is necessary to evaluate the model's performance comprehensively. The results indicate room for improvement, particularly in specialized metrics.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_cb887e53a02140cd90d37579577d15a2_proc_312326/SPR_BENCH_test_metrics.png"}], [], [{"analysis": "The first pair of plots shows the train and validation accuracy for different dropout rates over epochs. Lower dropout rates (0.0 and 0.2) achieve higher accuracy more quickly and stabilize at around 1.0 accuracy by 5 epochs. Higher dropout rates (0.4 and 0.6) show slower convergence, with dropout_0.6 lagging significantly in the initial epochs. This indicates that higher dropout rates might be introducing too much regularization, negatively impacting learning efficiency.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_dropout_accuracy_curves.png"}, {"analysis": "The second pair of plots displays train and validation loss over epochs for different dropout rates. Lower dropout rates (0.0 and 0.2) result in faster loss reduction and lower final loss values. Higher dropout rates (0.4 and 0.6) show slower reduction in loss, with dropout_0.6 having the highest loss throughout. This further supports the observation that excessive dropout can hinder model learning.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_dropout_loss_curves.png"}, {"analysis": "The bar chart illustrates the final validation accuracy for each dropout rate. All dropout rates achieve similar final validation accuracy, close to 1.0, suggesting that while higher dropout rates slow down learning, they do not significantly impact the final performance in terms of accuracy.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_final_val_accuracy_bar.png"}, {"analysis": "The final plot, labeled as Zero-Shot Rule Transfer Accuracy (ZSRTA) for dropout_0.2, appears to lack meaningful data, as the value is zero or missing. This suggests that either the metric was not computed correctly, or the model failed to demonstrate any zero-shot transfer capability under the tested configuration.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_95834d15b4ba43bbace99a143e6135f9_proc_312328/SPR_BENCH_zsrta_bar.png"}], [{"analysis": "This plot shows the training and validation accuracy over epochs. Both training and validation accuracy are consistently high, indicating that the model is learning well. However, the validation accuracy occasionally surpasses the training accuracy, which could suggest some randomness or potential overfitting issues that might need further exploration. The periodic dips in accuracy may indicate instability in training or learning rate adjustments.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_accuracy_curve.png"}, {"analysis": "This plot illustrates the training and validation loss over epochs. The periodic spikes in loss suggest potential instability in training, possibly due to learning rate scheduling or batch-related variability. Despite this, the overall trend shows a reduction in both training and validation loss, which is a positive sign of convergence.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_loss_curve.png"}, {"analysis": "This plot represents the harmonic mean accuracy (HMA) per epoch. The HMA values are mostly high, indicating that the model performs well across metrics. However, the periodic dips in HMA align with the dips seen in the accuracy and loss plots, further confirming potential instability during training.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_hma_curve.png"}, {"analysis": "This plot compares Shape-Weighted Accuracy (SWA) and Color-Weighted Accuracy (CWA) over epochs. Both metrics remain closely aligned throughout training, which is a good indication that the model is not favoring one type of reasoning over the other. The periodic drops in both metrics align with the dips in other plots, suggesting instability that affects all performance metrics.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_weighted_accuracy.png"}, {"analysis": "This plot shows zero-shot accuracy over epochs, which remains consistently at 0. This indicates that the current model setup is not achieving any zero-shot learning capability, which is a critical issue given the research goal. This result suggests the need for significant modifications or enhancements to the model or training approach to address zero-shot learning.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e6c9f335553b47f38966ed9701d27082_proc_312328/SPR_BENCH_zeroshot_accuracy.png"}], [], [{"analysis": "In this plot, the training and validation accuracy for different hidden dimensions (hd64, hd128, hd256, hd512) are shown over five epochs. All configurations exhibit rapid convergence to near-perfect accuracy, with validation accuracy closely tracking training accuracy. The larger hidden dimensions (hd256 and hd512) achieve slightly higher accuracy earlier, but the differences are minimal by the final epoch. This suggests that the model's performance is robust to changes in hidden dimension size, and all configurations generalize well to the validation set.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_hidden_dim_accuracy_curves.png"}, {"analysis": "This plot depicts the training and validation loss for various hidden dimensions over five epochs. The loss decreases rapidly for all configurations, with minimal differences between training and validation losses, indicating no overfitting. Larger hidden dimensions (hd256 and hd512) show slightly faster convergence to lower loss values, but the differences are negligible by the fifth epoch. The results suggest efficient training and good alignment between the training and validation datasets.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_hidden_dim_loss_curves.png"}, {"analysis": "This plot shows the final validation accuracy at epoch 5 for different hidden dimensions. All configurations achieve nearly identical accuracy, indicating that the hidden dimension size does not significantly impact the final performance. The model appears to generalize well across all tested configurations, which suggests that the architecture and training process are robust to variations in this hyperparameter.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_final_val_accuracy_bar.png"}, {"analysis": "This plot aims to show the Zero-Shot Rule Transfer Accuracy (ZSRTA) for different hidden dimensions, but it is empty. This could indicate that the data for ZSRTA was not collected, the metric is not applicable, or there was an issue in the experiment setup. Further investigation is needed to determine the cause of the absence of results in this plot.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_2d2ef9d4cf08449ba8e6d7a8f5a36a88_proc_312327/SPR_BENCH_ZSRTA_bar.png"}], [{"analysis": "The first plot illustrates the training and validation accuracy across epochs for different weight decay settings. The results show that all configurations achieve high accuracy (close to or above 99%) by the end of 5 epochs. However, the learning dynamics vary: lower weight decay values (e.g., wd_0.0 and wd_1e-06) tend to converge faster and achieve slightly higher validation accuracy compared to higher weight decay values (e.g., wd_0.001). This suggests that lower weight decay may be more effective for this task, although the differences are minor.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_615c2d14706d408d8da1d1a2381cc0f2_proc_312325/spr_bench_train_val_accuracy.png"}, {"analysis": "The second plot shows the validation loss over epochs for different weight decay settings. The trends indicate that lower weight decay values (wd_0.0, wd_1e-06) lead to faster and more substantial loss reduction compared to higher weight decay values (e.g., wd_0.001). This aligns with the accuracy trends from the first plot, reinforcing the idea that lower weight decay facilitates better performance on this dataset. The validation loss for wd_0.001 remains noticeably higher throughout training, suggesting suboptimal generalization.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_615c2d14706d408d8da1d1a2381cc0f2_proc_312325/spr_bench_val_loss.png"}, {"analysis": "The third plot, depicting zero-shot rule transfer accuracy (ZSRTA) for weight decay wd_0.0, is empty and does not provide any data. This could be due to missing results or a failure in the experimental setup for this specific evaluation. Without data, no analysis can be performed for ZSRTA.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_615c2d14706d408d8da1d1a2381cc0f2_proc_312325/spr_bench_zsrta_bar.png"}], [], [], [{"analysis": "This plot shows the training and validation accuracy over epochs for different hidden dimensions (hd64, hd128, hd256, hd512). All configurations achieve rapid convergence, with accuracy stabilizing around epoch 4. Larger hidden dimensions (hd256 and hd512) slightly outperform smaller ones (hd64 and hd128) in early epochs but converge similarly by epoch 5. This suggests that increasing the hidden dimension does not significantly improve final accuracy but may accelerate initial learning.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_hidden_dim_accuracy_curves.png"}, {"analysis": "This plot depicts the cross-entropy loss for training and validation across epochs for various hidden dimensions. Loss decreases steadily and converges by epoch 4 for all configurations. Larger hidden dimensions (hd256 and hd512) exhibit slightly faster loss reduction in early epochs, but all configurations achieve nearly identical loss values by epoch 5. This indicates that the model learns effectively regardless of the hidden dimension, though larger dimensions might expedite early-stage learning.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_hidden_dim_loss_curves.png"}, {"analysis": "This bar plot illustrates the final validation accuracy (at epoch 5) for different hidden dimensions. The accuracy is nearly identical across all configurations, indicating that hidden dimension size has minimal impact on final performance. This suggests that the model is robust to changes in hidden dimension size for this task.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_final_val_accuracy_bar.png"}, {"analysis": "This plot attempts to show Zero-Shot Rule Transfer Accuracy (ZSRTA) for different hidden dimensions. However, the plot is empty, indicating no results were recorded or the metric was not computed. This could be due to a lack of implementation or an issue with the experimental setup. Addressing this is critical to evaluate the model's zero-shot capabilities.", "plot_path": "experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/SPR_BENCH_ZSRTA_bar.png"}], []], "vlm_feedback_summary": ["The first two plots demonstrate strong learning performance with high accuracy\nand low loss, indicating effective training and generalization. However, the\nfinal plot is empty, suggesting missing results for the test metrics. This\ndiscrepancy should be addressed to ensure comprehensive evaluation of the model.", "The plots indicate that the model achieves near-perfect accuracy and very low\nloss values quickly, suggesting effective learning but potentially limited\nchallenge from the dataset. The absence of results for the zero-shot rule\ntransfer accuracy metric is a significant gap in the evaluation, as it prevents\nassessment of the model's performance on its primary objective of zero-shot\nreasoning.", "The experimental results indicate that a learning rate of 0.002 performs best,\nachieving high accuracy and low loss. The training process appears stable across\nall learning rates, but higher learning rates converge faster and yield better\nperformance. The test metrics suggest decent overall accuracy, but further\nevaluation of SWA, CWA, and ZSRTA is needed to assess the model's generalization\ncapabilities.", "[]", "The analysis highlights that lower dropout rates (0.0 and 0.2) lead to faster\nconvergence and lower loss during training, while higher dropout rates (0.4 and\n0.6) slow down learning without impacting final validation accuracy. The Zero-\nShot Rule Transfer Accuracy plot lacks meaningful data, indicating issues in\neither computation or model capability in this aspect.", "The plots indicate generally strong performance in training and validation\nmetrics but reveal periodic instability during training. The model performs well\nin shape and color reasoning but fails entirely in zero-shot accuracy, which is\na critical shortcoming for the research objective. Further investigation into\ntraining stability and zero-shot learning capabilities is necessary.", "[]", "The plots demonstrate that the model achieves near-perfect accuracy and low loss\nacross various hidden dimensions, indicating robustness and effective training.\nHowever, the absence of data in the ZSRTA plot raises questions about the\nexperiment's coverage or setup.", "The plots provide insights into the impact of weight decay on training and\nvalidation performance. Lower weight decay values (wd_0.0, wd_1e-06) achieve\nbetter accuracy and lower validation loss, suggesting they are more suitable for\nthis task. However, the zero-shot rule transfer accuracy plot lacks data,\npreventing any conclusions about ZSRTA.", "[]", "[]", "The provided plots effectively demonstrate the model's performance in terms of\naccuracy and loss across different hidden dimensions. The results indicate that\nhidden dimension size minimally affects final performance but may influence\nearly-stage learning speed. However, the empty ZSRTA plot highlights a critical\ngap in assessing the model's zero-shot reasoning capabilities, which is a core\naspect of the research hypothesis.", "[]"], "exec_time": [6.4049906730651855, 54.12541747093201, 19.486166954040527, 77.0461118221283, 16.833813905715942, 31.345457315444946, 3.3452022075653076, 44.15459990501404, 19.226819276809692, 16.087505102157593, 18.36066174507141, 42.547410011291504, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[]"], ["[]"], ["[\"SPR_BENCH\"]"], [], ["['dropout_0.0'", "'dropout_0.2'", "'dropout_0.4'", "'dropout_0.6']"], ["[]"], [], ["[\"SPR_BENCH\"]"], ["['wd_0.0'", "'wd_1e-06']"], [], [], ["[\"SPR_BENCH\"]"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------- load data --------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    spr_data = experiment_data.get(\"SPR_BENCH\", {})\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    spr_data = {}\n\n\n# helper for safe fetch\ndef g(path, default=None):\n    cur = spr_data\n    for k in path:\n        if cur is None:\n            return default\n        cur = cur.get(k, None)\n    return cur if cur is not None else default\n\n\n# -------------------- Plot 1: Accuracy --------------------\ntry:\n    epochs = range(1, len(g([\"metrics\", \"train_acc\"], [])) + 1)\n    train_acc = g([\"metrics\", \"train_acc\"], [])\n    val_acc = g([\"metrics\", \"val_acc\"], [])\n    if train_acc and val_acc:\n        plt.figure()\n        plt.plot(epochs, train_acc, label=\"Train Acc\")\n        plt.plot(epochs, val_acc, label=\"Val Acc\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH Accuracy per Epoch\\nTrain vs. Validation\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_accuracy_curve.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy plot: {e}\")\n    plt.close()\n\n# -------------------- Plot 2: Loss --------------------\ntry:\n    train_loss = g([\"losses\", \"train\"], [])\n    val_loss = g([\"losses\", \"val\"], [])\n    if train_loss and val_loss:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train Loss\")\n        plt.plot(epochs, val_loss, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH Loss per Epoch\\nTrain vs. Validation\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curve.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# -------------------- Plot 3: Final Test Metrics --------------------\ntry:\n    overall_acc = g([\"metrics\", \"overall_acc\"], None)  # may not exist\n    swa = g([\"metrics\", \"SWA\"], None)\n    cwa = g([\"metrics\", \"CWA\"], None)\n    zs = g([\"metrics\", \"ZSRTA\"], [])\n    zs = zs[-1] if isinstance(zs, list) and zs else None\n    metrics = {\n        k: v\n        for k, v in zip(\n            [\"Overall Acc\", \"SWA\", \"CWA\", \"ZSRTA\"], [overall_acc, swa, cwa, zs]\n        )\n        if v is not None\n    }\n    if metrics:\n        plt.figure()\n        plt.bar(\n            range(len(metrics)), list(metrics.values()), tick_label=list(metrics.keys())\n        )\n        plt.ylim(0, 1)\n        plt.ylabel(\"Score\")\n        plt.title(\"SPR_BENCH Final Test Metrics\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_test_metrics.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating metrics plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    runs = experiment_data[\"EPOCHS_TUNING\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    runs = {}\n\n# Helper: get ordered epoch values (e.g., 5,10,15,...)\nepoch_settings = sorted(runs.keys())\n\n# ---------------------------------------------------------------------\n# 1) Validation accuracy curves\ntry:\n    plt.figure()\n    for ep in epoch_settings:\n        vals = runs[ep][\"metrics\"][\"val_acc\"]\n        plt.plot(range(1, len(vals) + 1), vals, label=f\"{ep} epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Validation Accuracy\")\n    plt.title(\"SPR_BENCH: Validation Accuracy vs Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_val_accuracy_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating validation accuracy plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 2) Training accuracy curves\ntry:\n    plt.figure()\n    for ep in epoch_settings:\n        tr = runs[ep][\"metrics\"][\"train_acc\"]\n        plt.plot(range(1, len(tr) + 1), tr, label=f\"{ep} epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Training Accuracy\")\n    plt.title(\"SPR_BENCH: Training Accuracy vs Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_train_accuracy_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating training accuracy plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 3) Loss curves (train & val) in two subplots\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for ep in epoch_settings:\n        tl = runs[ep][\"losses\"][\"train\"]\n        vl = runs[ep][\"losses\"][\"val\"]\n        axes[0].plot(range(1, len(tl) + 1), tl, label=f\"{ep} epochs\")\n        axes[1].plot(range(1, len(vl) + 1), vl, label=f\"{ep} epochs\")\n    axes[0].set_title(\"Left: Train Loss\")\n    axes[1].set_title(\"Right: Validation Loss\")\n    for ax in axes:\n        ax.set_xlabel(\"Epoch\")\n        ax.set_ylabel(\"Cross-Entropy Loss\")\n        ax.legend()\n    fig.suptitle(\"SPR_BENCH: Loss Curves Across Epochs\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close(fig)\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 4) Final ZSRTA bar chart\ntry:\n    zsrtas = [\n        (\n            np.nan\n            if len(runs[ep][\"metrics\"][\"ZSRTA\"]) == 0\n            else runs[ep][\"metrics\"][\"ZSRTA\"][-1]\n        )\n        for ep in epoch_settings\n    ]\n    plt.figure()\n    plt.bar([str(ep) for ep in epoch_settings], zsrtas, color=\"skyblue\")\n    plt.xlabel(\"Epochs Trained\")\n    plt.ylabel(\"ZSRTA\")\n    plt.title(\"SPR_BENCH: Zero-Shot Rule Transfer Accuracy (ZSRTA)\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_ZSRTA_bar.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating ZSRTA bar plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ----------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    ed = experiment_data[\"learning_rate\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    ed = None\n\nif ed:\n    lr_vals = ed[\"lr_values\"]\n    tr_acc_hist = ed[\"metrics\"][\"train_acc\"]  # list[list]\n    val_acc_hist = ed[\"metrics\"][\"val_acc\"]  # list[list]\n    tr_loss_hist = ed[\"losses\"][\"train\"]  # list[list]\n    val_loss_hist = ed[\"losses\"][\"val\"]  # list[list]\n    final_val_acc = [v[-1] for v in val_acc_hist] if val_acc_hist else []\n    test_metrics = {\n        \"Overall Acc\": (\n            np.mean(\n                np.array(ed.get(\"predictions\", []))\n                == np.array(ed.get(\"ground_truth\", []))\n            )\n            if ed.get(\"predictions\")\n            else None\n        ),\n        \"SWA\": ed.get(\"ZSRTA\", [None])[-1] if ed.get(\"ZSRTA\") else None,\n        \"CWA\": None,  # CWA stored per-test; not replicated here\n        \"ZSRTA\": ed.get(\"ZSRTA\", [None])[-1] if ed.get(\"ZSRTA\") else None,\n    }\n\n    # --------------------------------------------------------------\n    # 1) Accuracy curves\n    try:\n        plt.figure()\n        for lr, tr, va in zip(lr_vals, tr_acc_hist, val_acc_hist):\n            epochs = np.arange(1, len(tr) + 1)\n            plt.plot(epochs, tr, \"--\", label=f\"train lr={lr}\")\n            plt.plot(epochs, va, \"-\", label=f\"val lr={lr}\")\n        plt.title(\"SPR_BENCH: Train vs Validation Accuracy per Epoch\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_accuracy_curves.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot: {e}\")\n        plt.close()\n\n    # --------------------------------------------------------------\n    # 2) Loss curves\n    try:\n        plt.figure()\n        for lr, tr, va in zip(lr_vals, tr_loss_hist, val_loss_hist):\n            epochs = np.arange(1, len(tr) + 1)\n            plt.plot(epochs, tr, \"--\", label=f\"train lr={lr}\")\n            plt.plot(epochs, va, \"-\", label=f\"val lr={lr}\")\n        plt.title(\"SPR_BENCH: Train vs Validation Loss per Epoch\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # --------------------------------------------------------------\n    # 3) Final validation accuracy vs learning rate\n    try:\n        plt.figure()\n        plt.plot(lr_vals, final_val_acc, \"o-\")\n        plt.xscale(\"log\")\n        plt.title(\"SPR_BENCH: Final Validation Accuracy vs Learning Rate\")\n        plt.xlabel(\"Learning Rate\")\n        plt.ylabel(\"Final Validation Accuracy\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_val_acc_vs_lr.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating val-acc-vs-lr plot: {e}\")\n        plt.close()\n\n    # --------------------------------------------------------------\n    # 4) Test metrics bar chart (if metrics exist)\n    try:\n        metrics = {k: v for k, v in test_metrics.items() if v is not None}\n        if metrics:\n            plt.figure()\n            plt.bar(list(metrics.keys()), list(metrics.values()))\n            plt.ylim(0, 1)\n            plt.title(\"SPR_BENCH: Test Metrics (Overall, SWA, CWA, ZSRTA)\")\n            fname = os.path.join(working_dir, \"SPR_BENCH_test_metrics.png\")\n            plt.savefig(fname)\n            print(f\"Saved {fname}\")\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating test metrics plot: {e}\")\n        plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    dropout_dict = experiment_data.get(\"dropout_tuning\", {})\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    dropout_dict = {}\n\n\n# Helper to sort keys numerically by dropout value\ndef _num(k):\n    try:\n        return float(k.split(\"_\")[-1])\n    except Exception:\n        return 0.0\n\n\nkeys_sorted = sorted(dropout_dict.keys(), key=_num)\n\n# ---------------------------------------------------------\n# 1) Accuracy curves ----------------------------------------------------------\ntry:\n    plt.figure(figsize=(10, 4))\n    # Left: train acc\n    plt.subplot(1, 2, 1)\n    for k in keys_sorted:\n        acc = dropout_dict[k][\"metrics\"].get(\"train_acc\", [])\n        plt.plot(range(1, len(acc) + 1), acc, label=k)\n    plt.title(\"SPR_BENCH Train Accuracy vs Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n\n    # Right: val acc\n    plt.subplot(1, 2, 2)\n    for k in keys_sorted:\n        acc = dropout_dict[k][\"metrics\"].get(\"val_acc\", [])\n        plt.plot(range(1, len(acc) + 1), acc, label=k)\n    plt.title(\"SPR_BENCH Validation Accuracy vs Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n\n    plt.suptitle(\"Left: Train Acc, Right: Val Acc (Dropout Sweep)\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_dropout_accuracy_curves.png\")\n    plt.tight_layout(rect=[0, 0, 1, 0.95])\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------\n# 2) Loss curves ---------------------------------------------------------------\ntry:\n    plt.figure(figsize=(10, 4))\n    # Left: train loss\n    plt.subplot(1, 2, 1)\n    for k in keys_sorted:\n        loss = dropout_dict[k][\"losses\"].get(\"train\", [])\n        plt.plot(range(1, len(loss) + 1), loss, label=k)\n    plt.title(\"SPR_BENCH Train Loss vs Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n\n    # Right: val loss\n    plt.subplot(1, 2, 2)\n    for k in keys_sorted:\n        loss = dropout_dict[k][\"losses\"].get(\"val\", [])\n        plt.plot(range(1, len(loss) + 1), loss, label=k)\n    plt.title(\"SPR_BENCH Validation Loss vs Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n\n    plt.suptitle(\"Left: Train Loss, Right: Val Loss (Dropout Sweep)\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_dropout_loss_curves.png\")\n    plt.tight_layout(rect=[0, 0, 1, 0.95])\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------\n# 3) Final validation accuracy bar chart --------------------------------------\ntry:\n    final_val_acc = [\n        dropout_dict[k][\"metrics\"][\"val_acc\"][-1]\n        for k in keys_sorted\n        if dropout_dict[k][\"metrics\"][\"val_acc\"]\n    ]\n    labels = [k for k in keys_sorted if dropout_dict[k][\"metrics\"][\"val_acc\"]]\n    plt.figure()\n    plt.bar(labels, final_val_acc, color=\"skyblue\")\n    plt.ylabel(\"Validation Accuracy\")\n    plt.title(\"SPR_BENCH Final Validation Accuracy by Dropout\")\n    plt.xticks(rotation=45)\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_val_accuracy_bar.png\")\n    plt.tight_layout()\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final val acc bar: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------\n# 4) ZSRTA bar chart (if present) ---------------------------------------------\ntry:\n    zs_scores = []\n    zs_labels = []\n    for k in keys_sorted:\n        z = dropout_dict[k][\"metrics\"].get(\"ZSRTA\", [])\n        if z:  # ensure list not empty\n            zs_scores.append(z[-1])\n            zs_labels.append(k)\n    if zs_scores:\n        plt.figure()\n        plt.bar(zs_labels, zs_scores, color=\"salmon\")\n        plt.ylabel(\"ZSRTA\")\n        plt.title(\"SPR_BENCH Zero-Shot Rule Transfer Accuracy\")\n        plt.xticks(rotation=45)\n        fname = os.path.join(working_dir, \"SPR_BENCH_zsrta_bar.png\")\n        plt.tight_layout()\n        plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating ZSRTA bar: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------ #\n# load experiment data                                               #\n# ------------------------------------------------------------------ #\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    spr_metrics = experiment_data[\"SPR_BENCH\"][\"metrics\"]\n    spr_losses = experiment_data[\"SPR_BENCH\"][\"losses\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    spr_metrics, spr_losses = {}, {}\n\n\n# helper to get metric safely\ndef get(metric_dict, key):\n    return metric_dict.get(key, [])\n\n\nepochs = np.arange(1, len(get(spr_metrics, \"train_acc\")) + 1)\n\n# ------------------------------------------------------------------ #\n# 1) train & val accuracy                                            #\n# ------------------------------------------------------------------ #\ntry:\n    if len(epochs):\n        plt.figure()\n        plt.plot(epochs, spr_metrics[\"train_acc\"], label=\"Train Acc\")\n        plt.plot(epochs, spr_metrics[\"val_acc\"], label=\"Val Acc\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH: Training vs Validation Accuracy\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_accuracy_curve.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 2) train & val loss                                                #\n# ------------------------------------------------------------------ #\ntry:\n    if len(epochs):\n        plt.figure()\n        plt.plot(epochs, spr_losses[\"train\"], label=\"Train Loss\")\n        plt.plot(epochs, spr_losses[\"val\"], label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curve.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 3) Harmonic-mean accuracy (HMA)                                    #\n# ------------------------------------------------------------------ #\ntry:\n    hma = get(spr_metrics, \"hma\")\n    if len(hma):\n        plt.figure()\n        plt.plot(epochs, hma, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HMA\")\n        plt.title(\"SPR_BENCH: Harmonic-Mean Accuracy per Epoch\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_hma_curve.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HMA plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 4) Shape- vs Color-Weighted Accuracy                               #\n# ------------------------------------------------------------------ #\ntry:\n    swa, cwa = get(spr_metrics, \"swa\"), get(spr_metrics, \"cwa\")\n    if len(swa) and len(cwa):\n        plt.figure()\n        plt.plot(epochs, swa, label=\"SWA\")\n        plt.plot(epochs, cwa, label=\"CWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.title(\"SPR_BENCH: Shape vs Color Weighted Accuracy\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_weighted_accuracy.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating weighted accuracy plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 5) Zero-Shot Accuracy                                              #\n# ------------------------------------------------------------------ #\ntry:\n    zs = get(spr_metrics, \"zs_acc\")\n    if len(zs):\n        plt.figure()\n        plt.plot(epochs, zs, marker=\"x\", color=\"purple\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Zero-Shot Accuracy\")\n        plt.title(\"SPR_BENCH: Zero-Shot Accuracy per Epoch\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_zeroshot_accuracy.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating zero-shot plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# print final epoch summary                                          #\n# ------------------------------------------------------------------ #\nif len(epochs):\n    idx = -1  # last epoch\n    summary = {\n        \"Final Train Acc\": spr_metrics[\"train_acc\"][idx],\n        \"Final Val Acc\": spr_metrics[\"val_acc\"][idx],\n        \"Final Val Loss\": spr_losses[\"val\"][idx],\n        \"Final HMA\": spr_metrics[\"hma\"][idx],\n        \"Final ZS Acc\": spr_metrics[\"zs_acc\"][idx],\n    }\n    print(\"Final Epoch Metrics:\")\n    for k, v in summary.items():\n        print(f\"  {k}: {v:.4f}\")\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------ load data ------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data[\"hidden_dim_tuning\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = {}\n\n# Keys & helpers --------------------------------------------------------\nhidden_dims = sorted([int(k.split(\"_\")[-1]) for k in exp.keys()])\nepochs = list(range(1, 1 + len(next(iter(exp.values()))[\"metrics\"][\"train_acc\"])))\n\n# ------------------------ FIGURE 1 : accuracy curves ------------------\ntry:\n    plt.figure()\n    for k in sorted(exp.keys(), key=lambda x: int(x.split(\"_\")[-1])):\n        hd = int(k.split(\"_\")[-1])\n        tr_acc = exp[k][\"metrics\"][\"train_acc\"]\n        val_acc = exp[k][\"metrics\"][\"val_acc\"]\n        plt.plot(epochs, tr_acc, marker=\"o\", label=f\"train hd{hd}\")\n        plt.plot(epochs, val_acc, marker=\"x\", linestyle=\"--\", label=f\"val hd{hd}\")\n    plt.title(\"SPR_BENCH: Train & Val Accuracy vs Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hidden_dim_accuracy_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy curve plot: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 2 : loss curves ----------------------\ntry:\n    plt.figure()\n    for k in sorted(exp.keys(), key=lambda x: int(x.split(\"_\")[-1])):\n        hd = int(k.split(\"_\")[-1])\n        tr_loss = exp[k][\"losses\"][\"train\"]\n        val_loss = exp[k][\"losses\"][\"val\"]\n        plt.plot(epochs, tr_loss, marker=\"o\", label=f\"train hd{hd}\")\n        plt.plot(epochs, val_loss, marker=\"x\", linestyle=\"--\", label=f\"val hd{hd}\")\n    plt.title(\"SPR_BENCH: Train & Val Loss vs Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hidden_dim_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 3 : final val accuracy ---------------\ntry:\n    plt.figure()\n    finals = [exp[f\"hidden_{hd}\"][\"metrics\"][\"val_acc\"][-1] for hd in hidden_dims]\n    plt.bar([str(hd) for hd in hidden_dims], finals, color=\"skyblue\")\n    plt.title(\"SPR_BENCH: Final Validation Accuracy by Hidden Dim\")\n    plt.xlabel(\"Hidden Dimension\")\n    plt.ylabel(\"Validation Accuracy (Epoch 5)\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_val_accuracy_bar.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final val accuracy bar: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 4 : ZSRTA bar ------------------------\ntry:\n    plt.figure()\n    zsrtas = [exp[f\"hidden_{hd}\"][\"metrics\"][\"ZSRTA\"][0] for hd in hidden_dims]\n    plt.bar([str(hd) for hd in hidden_dims], zsrtas, color=\"salmon\")\n    plt.title(\"SPR_BENCH: Zero-Shot Rule Transfer Accuracy (ZSRTA)\")\n    plt.xlabel(\"Hidden Dimension\")\n    plt.ylabel(\"ZSRTA\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_ZSRTA_bar.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating ZSRTA bar: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------\n# load saved experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    runs = experiment_data.get(\"weight_decay\", {})\n\n    # --------------------------------------------------------\n    # 1) Train / Val accuracy curves\n    try:\n        plt.figure()\n        for run_key, run_val in runs.items():\n            epochs = range(1, len(run_val[\"metrics\"][\"train_acc\"]) + 1)\n            plt.plot(epochs, run_val[\"metrics\"][\"train_acc\"], label=f\"{run_key} train\")\n            plt.plot(\n                epochs,\n                run_val[\"metrics\"][\"val_acc\"],\n                linestyle=\"--\",\n                label=f\"{run_key} val\",\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR-BENCH: Train vs Val Accuracy\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_train_val_accuracy.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating accuracy plot: {e}\")\n        plt.close()\n\n    # --------------------------------------------------------\n    # 2) Validation loss curves\n    try:\n        plt.figure()\n        for run_key, run_val in runs.items():\n            epochs = range(1, len(run_val[\"metrics\"][\"val_loss\"]) + 1)\n            plt.plot(epochs, run_val[\"metrics\"][\"val_loss\"], label=run_key)\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Val Loss\")\n        plt.title(\"SPR-BENCH: Validation Loss Across Weight Decay Settings\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"spr_bench_val_loss.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating val-loss plot: {e}\")\n        plt.close()\n\n    # --------------------------------------------------------\n    # 3) ZSRTA bar chart\n    try:\n        plt.figure()\n        run_keys, zsrtas = [], []\n        for run_key, run_val in runs.items():\n            z_list = run_val[\"metrics\"].get(\"ZSRTA\", [])\n            if len(z_list) > 0:\n                run_keys.append(run_key)\n                zsrtas.append(z_list[-1])\n        if zsrtas:\n            plt.bar(run_keys, zsrtas)\n            plt.ylabel(\"ZSRTA\")\n            plt.title(\"SPR-BENCH: Zero-Shot Rule Transfer Accuracy by Weight Decay\")\n            plt.xticks(rotation=45)\n            fname = os.path.join(working_dir, \"spr_bench_zsrta_bar.png\")\n            plt.tight_layout()\n            plt.savefig(fname)\n            plt.close()\n            print(f\"Saved {fname}\")\n        else:\n            print(\"No ZSRTA data found; skipping bar chart.\")\n    except Exception as e:\n        print(f\"Error creating ZSRTA plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------ load data ------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data[\"hidden_dim_tuning\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = {}\n\n# Keys & helpers --------------------------------------------------------\nhidden_dims = sorted([int(k.split(\"_\")[-1]) for k in exp.keys()])\nepochs = list(range(1, 1 + len(next(iter(exp.values()))[\"metrics\"][\"train_acc\"])))\n\n# ------------------------ FIGURE 1 : accuracy curves ------------------\ntry:\n    plt.figure()\n    for k in sorted(exp.keys(), key=lambda x: int(x.split(\"_\")[-1])):\n        hd = int(k.split(\"_\")[-1])\n        tr_acc = exp[k][\"metrics\"][\"train_acc\"]\n        val_acc = exp[k][\"metrics\"][\"val_acc\"]\n        plt.plot(epochs, tr_acc, marker=\"o\", label=f\"train hd{hd}\")\n        plt.plot(epochs, val_acc, marker=\"x\", linestyle=\"--\", label=f\"val hd{hd}\")\n    plt.title(\"SPR_BENCH: Train & Val Accuracy vs Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hidden_dim_accuracy_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy curve plot: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 2 : loss curves ----------------------\ntry:\n    plt.figure()\n    for k in sorted(exp.keys(), key=lambda x: int(x.split(\"_\")[-1])):\n        hd = int(k.split(\"_\")[-1])\n        tr_loss = exp[k][\"losses\"][\"train\"]\n        val_loss = exp[k][\"losses\"][\"val\"]\n        plt.plot(epochs, tr_loss, marker=\"o\", label=f\"train hd{hd}\")\n        plt.plot(epochs, val_loss, marker=\"x\", linestyle=\"--\", label=f\"val hd{hd}\")\n    plt.title(\"SPR_BENCH: Train & Val Loss vs Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hidden_dim_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 3 : final val accuracy ---------------\ntry:\n    plt.figure()\n    finals = [exp[f\"hidden_{hd}\"][\"metrics\"][\"val_acc\"][-1] for hd in hidden_dims]\n    plt.bar([str(hd) for hd in hidden_dims], finals, color=\"skyblue\")\n    plt.title(\"SPR_BENCH: Final Validation Accuracy by Hidden Dim\")\n    plt.xlabel(\"Hidden Dimension\")\n    plt.ylabel(\"Validation Accuracy (Epoch 5)\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_val_accuracy_bar.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final val accuracy bar: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 4 : ZSRTA bar ------------------------\ntry:\n    plt.figure()\n    zsrtas = [exp[f\"hidden_{hd}\"][\"metrics\"][\"ZSRTA\"][0] for hd in hidden_dims]\n    plt.bar([str(hd) for hd in hidden_dims], zsrtas, color=\"salmon\")\n    plt.title(\"SPR_BENCH: Zero-Shot Rule Transfer Accuracy (ZSRTA)\")\n    plt.xlabel(\"Hidden Dimension\")\n    plt.ylabel(\"ZSRTA\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_ZSRTA_bar.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating ZSRTA bar: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------ load data ------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data[\"hidden_dim_tuning\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = {}\n\n# Keys & helpers --------------------------------------------------------\nhidden_dims = sorted([int(k.split(\"_\")[-1]) for k in exp.keys()])\nepochs = list(range(1, 1 + len(next(iter(exp.values()))[\"metrics\"][\"train_acc\"])))\n\n# ------------------------ FIGURE 1 : accuracy curves ------------------\ntry:\n    plt.figure()\n    for k in sorted(exp.keys(), key=lambda x: int(x.split(\"_\")[-1])):\n        hd = int(k.split(\"_\")[-1])\n        tr_acc = exp[k][\"metrics\"][\"train_acc\"]\n        val_acc = exp[k][\"metrics\"][\"val_acc\"]\n        plt.plot(epochs, tr_acc, marker=\"o\", label=f\"train hd{hd}\")\n        plt.plot(epochs, val_acc, marker=\"x\", linestyle=\"--\", label=f\"val hd{hd}\")\n    plt.title(\"SPR_BENCH: Train & Val Accuracy vs Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hidden_dim_accuracy_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy curve plot: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 2 : loss curves ----------------------\ntry:\n    plt.figure()\n    for k in sorted(exp.keys(), key=lambda x: int(x.split(\"_\")[-1])):\n        hd = int(k.split(\"_\")[-1])\n        tr_loss = exp[k][\"losses\"][\"train\"]\n        val_loss = exp[k][\"losses\"][\"val\"]\n        plt.plot(epochs, tr_loss, marker=\"o\", label=f\"train hd{hd}\")\n        plt.plot(epochs, val_loss, marker=\"x\", linestyle=\"--\", label=f\"val hd{hd}\")\n    plt.title(\"SPR_BENCH: Train & Val Loss vs Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hidden_dim_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 3 : final val accuracy ---------------\ntry:\n    plt.figure()\n    finals = [exp[f\"hidden_{hd}\"][\"metrics\"][\"val_acc\"][-1] for hd in hidden_dims]\n    plt.bar([str(hd) for hd in hidden_dims], finals, color=\"skyblue\")\n    plt.title(\"SPR_BENCH: Final Validation Accuracy by Hidden Dim\")\n    plt.xlabel(\"Hidden Dimension\")\n    plt.ylabel(\"Validation Accuracy (Epoch 5)\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_val_accuracy_bar.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final val accuracy bar: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 4 : ZSRTA bar ------------------------\ntry:\n    plt.figure()\n    zsrtas = [exp[f\"hidden_{hd}\"][\"metrics\"][\"ZSRTA\"][0] for hd in hidden_dims]\n    plt.bar([str(hd) for hd in hidden_dims], zsrtas, color=\"salmon\")\n    plt.title(\"SPR_BENCH: Zero-Shot Rule Transfer Accuracy (ZSRTA)\")\n    plt.xlabel(\"Hidden Dimension\")\n    plt.ylabel(\"ZSRTA\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_ZSRTA_bar.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating ZSRTA bar: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------ load data ------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data[\"hidden_dim_tuning\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = {}\n\n# Keys & helpers --------------------------------------------------------\nhidden_dims = sorted([int(k.split(\"_\")[-1]) for k in exp.keys()])\nepochs = list(range(1, 1 + len(next(iter(exp.values()))[\"metrics\"][\"train_acc\"])))\n\n# ------------------------ FIGURE 1 : accuracy curves ------------------\ntry:\n    plt.figure()\n    for k in sorted(exp.keys(), key=lambda x: int(x.split(\"_\")[-1])):\n        hd = int(k.split(\"_\")[-1])\n        tr_acc = exp[k][\"metrics\"][\"train_acc\"]\n        val_acc = exp[k][\"metrics\"][\"val_acc\"]\n        plt.plot(epochs, tr_acc, marker=\"o\", label=f\"train hd{hd}\")\n        plt.plot(epochs, val_acc, marker=\"x\", linestyle=\"--\", label=f\"val hd{hd}\")\n    plt.title(\"SPR_BENCH: Train & Val Accuracy vs Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hidden_dim_accuracy_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy curve plot: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 2 : loss curves ----------------------\ntry:\n    plt.figure()\n    for k in sorted(exp.keys(), key=lambda x: int(x.split(\"_\")[-1])):\n        hd = int(k.split(\"_\")[-1])\n        tr_loss = exp[k][\"losses\"][\"train\"]\n        val_loss = exp[k][\"losses\"][\"val\"]\n        plt.plot(epochs, tr_loss, marker=\"o\", label=f\"train hd{hd}\")\n        plt.plot(epochs, val_loss, marker=\"x\", linestyle=\"--\", label=f\"val hd{hd}\")\n    plt.title(\"SPR_BENCH: Train & Val Loss vs Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hidden_dim_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 3 : final val accuracy ---------------\ntry:\n    plt.figure()\n    finals = [exp[f\"hidden_{hd}\"][\"metrics\"][\"val_acc\"][-1] for hd in hidden_dims]\n    plt.bar([str(hd) for hd in hidden_dims], finals, color=\"skyblue\")\n    plt.title(\"SPR_BENCH: Final Validation Accuracy by Hidden Dim\")\n    plt.xlabel(\"Hidden Dimension\")\n    plt.ylabel(\"Validation Accuracy (Epoch 5)\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_val_accuracy_bar.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final val accuracy bar: {e}\")\n    plt.close()\n\n# ------------------------ FIGURE 4 : ZSRTA bar ------------------------\ntry:\n    plt.figure()\n    zsrtas = [exp[f\"hidden_{hd}\"][\"metrics\"][\"ZSRTA\"][0] for hd in hidden_dims]\n    plt.bar([str(hd) for hd in hidden_dims], zsrtas, color=\"salmon\")\n    plt.title(\"SPR_BENCH: Zero-Shot Rule Transfer Accuracy (ZSRTA)\")\n    plt.xlabel(\"Hidden Dimension\")\n    plt.ylabel(\"ZSRTA\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_ZSRTA_bar.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating ZSRTA bar: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------------------------------------------------------------------- #\n# basic setup\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------------------------- #\n# load ALL experiment_data.npy we can see in the Experiment Data Path   #\nexperiment_data_path_list = [\n    os.path.join(working_dir, \"experiment_data.npy\"),\n    \"experiments/2025-07-27_23-49-14_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_b8c645f9a8444983917cffd60b8ae015_proc_312327/experiment_data.npy\",\n]\nall_experiment_data = []\nfor p in experiment_data_path_list:\n    try:\n        if p is None or not os.path.isfile(p):\n            continue\n        d = np.load(p, allow_pickle=True).item()\n        all_experiment_data.append(d)\n    except Exception as e:\n        print(f\"Error loading {p}: {e}\")\n\n# concatenate experiments that match the study we care about ---------- #\nruns = []\nfor d in all_experiment_data:\n    try:\n        exp_dict = d[\"hidden_dim_tuning\"][\"SPR_BENCH\"]\n        for run_key, run_val in exp_dict.items():\n            runs.append(run_val)  # each element has .['metrics'] and .['losses']\n    except Exception as e:\n        # Skip anything that doesn't have this sub-dict\n        continue\n\nif not runs:\n    print(\"No runs found for aggregation; exiting early.\")\n    exit()\n\n\n# -------------------------------------------------------------------- #\n# Utilities to stack metrics\ndef stack_metric(metric_name, subkey=None):\n    \"\"\"Return 2-D array shape (n_runs, n_epochs)\"\"\"\n    vals = []\n    for r in runs:\n        if subkey is None:\n            vals.append(r[\"metrics\"][metric_name])\n        else:\n            vals.append(r[subkey][metric_name])\n    return np.array(vals)\n\n\n# Determine epoch count from first run\nn_epochs = len(runs[0][\"metrics\"][\"train_acc\"])\nepochs = np.arange(1, n_epochs + 1)\nn_runs = len(runs)\n\n# -------------------------------------------------------------------- #\n# FIGURE 1 : aggregated accuracy curves with stderr shading\ntry:\n    tr_acc_arr = stack_metric(\"train_acc\")\n    val_acc_arr = stack_metric(\"val_acc\")\n\n    tr_mean, tr_std = tr_acc_arr.mean(axis=0), tr_acc_arr.std(axis=0, ddof=1)\n    val_mean, val_std = val_acc_arr.mean(axis=0), val_acc_arr.std(axis=0, ddof=1)\n    tr_se, val_se = tr_std / np.sqrt(n_runs), val_std / np.sqrt(n_runs)\n\n    plt.figure()\n    plt.plot(epochs, tr_mean, color=\"blue\", label=\"Train (mean)\")\n    plt.fill_between(\n        epochs,\n        tr_mean - tr_se,\n        tr_mean + tr_se,\n        color=\"blue\",\n        alpha=0.2,\n        label=\"Train \u00b1 stderr\",\n    )\n    plt.plot(epochs, val_mean, color=\"orange\", label=\"Val (mean)\")\n    plt.fill_between(\n        epochs,\n        val_mean - val_se,\n        val_mean + val_se,\n        color=\"orange\",\n        alpha=0.2,\n        label=\"Val \u00b1 stderr\",\n    )\n    plt.title(\"SPR_BENCH: Aggregated Train & Val Accuracy\\n(mean \u00b1 standard error)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_aggregated_accuracy_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated accuracy plot: {e}\")\n    plt.close()\n\n# -------------------------------------------------------------------- #\n# FIGURE 2 : aggregated loss curves with stderr shading\ntry:\n    tr_loss_arr = stack_metric(\"train\", subkey=\"losses\")\n    val_loss_arr = stack_metric(\"val\", subkey=\"losses\")\n\n    tr_mean, tr_std = tr_loss_arr.mean(axis=0), tr_loss_arr.std(axis=0, ddof=1)\n    val_mean, val_std = val_loss_arr.mean(axis=0), val_loss_arr.std(axis=0, ddof=1)\n    tr_se, val_se = tr_std / np.sqrt(n_runs), val_std / np.sqrt(n_runs)\n\n    plt.figure()\n    plt.plot(epochs, tr_mean, color=\"green\", label=\"Train Loss (mean)\")\n    plt.fill_between(\n        epochs,\n        tr_mean - tr_se,\n        tr_mean + tr_se,\n        color=\"green\",\n        alpha=0.2,\n        label=\"Train \u00b1 stderr\",\n    )\n    plt.plot(epochs, val_mean, color=\"red\", label=\"Val Loss (mean)\")\n    plt.fill_between(\n        epochs,\n        val_mean - val_se,\n        val_mean + val_se,\n        color=\"red\",\n        alpha=0.2,\n        label=\"Val \u00b1 stderr\",\n    )\n    plt.title(\"SPR_BENCH: Aggregated Train & Val Loss\\n(mean \u00b1 standard error)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_aggregated_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated loss plot: {e}\")\n    plt.close()\n\n# -------------------------------------------------------------------- #\n# FIGURE 3 : final validation accuracy across runs with error bar\ntry:\n    final_val_acc = np.array([r[\"metrics\"][\"val_acc\"][-1] for r in runs])\n    mean_final = final_val_acc.mean()\n    se_final = final_val_acc.std(ddof=1) / np.sqrt(n_runs)\n\n    plt.figure()\n    plt.bar([\"Aggregated\"], [mean_final], yerr=[se_final], color=\"skyblue\", capsize=5)\n    plt.title(\"SPR_BENCH: Final Validation Accuracy\\n(mean \u00b1 standard error)\")\n    plt.ylabel(\"Accuracy (last epoch)\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_val_accuracy_aggregated.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated final val accuracy bar: {e}\")\n    plt.close()\n\n# -------------------------------------------------------------------- #\n# FIGURE 4 : ZSRTA aggregated bar\ntry:\n    zsrtas = np.array([r[\"metrics\"][\"ZSRTA\"][0] for r in runs])\n    mean_zs = zsrtas.mean()\n    se_zs = zsrtas.std(ddof=1) / np.sqrt(n_runs)\n\n    plt.figure()\n    plt.bar([\"Aggregated\"], [mean_zs], yerr=[se_zs], color=\"salmon\", capsize=5)\n    plt.title(\n        \"SPR_BENCH: Zero-Shot Rule Transfer Accuracy (ZSRTA)\\n(mean \u00b1 standard error)\"\n    )\n    plt.ylabel(\"ZSRTA\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_ZSRTA_aggregated.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated ZSRTA bar: {e}\")\n    plt.close()\n"], "plot_plan": ["We first load experiment_data.npy, safely handle any loading errors, and extract the dictionaries corresponding to the single dataset SPR_BENCH.  From the stored lists we retrieve per-epoch train/val accuracy and loss and, if present, ZSRTA values.  Three separate visualizations are created: (1) a line plot of train vs. validation accuracy across epochs, (2) a line plot of train vs. validation loss, and (3) a simple bar chart reporting the final test metrics (overall accuracy, SWA, CWA, ZSRTA).  Each figure is wrapped in its own try-except block to guarantee clean failure handling, saved to working_dir with descriptive filenames, and explicitly closed afterwards.  All plotting uses vanilla matplotlib with titles clearly specifying the dataset and the content of each subplot.  No synthetic data are generated; only what is present in the numpy file is touched.  The script limits itself to these three plots, well under the five-figure cap, and skips any figure whose required data are missing or empty.  Finally, the code prints a short confirmation message so a user immediately knows which figures were produced and where they were written.", "We will first load experiment_data.npy from the working directory and extract the dict experiment_data['EPOCHS_TUNING']['SPR_BENCH'].  \nFor every hyper-parameter trial (EPOCHS \u2208 {5,10,15,20,25}) we gather the per-epoch lists of train_acc, val_acc, train_loss and val_loss, as well as the final zero-shot rule transfer accuracy (ZSRTA).  \nFour figures will be produced, each wrapped in its own try-except block and saved in working_dir with clear, descriptive filenames:  \n1) Validation accuracy vs. epoch for every trial (all trials plotted together with one line per trial).  \n2) Training accuracy vs. epoch for every trial (same style as above).  \n3) Training and validation loss curves for all trials (two panels: left=train, right=val) so users can quickly spot overfitting.  \n4) Bar chart of final ZSRTA for each trial, showing how zero-shot performance changes with training length.  \nFigures are plotted using plain matplotlib, always closed after saving, and only data present in experiment_data.npy are used (no fabrication).  \nThis yields a concise yet comprehensive visual summary of the hyper-parameter search.", "We will first load experiment_data.npy, safely extracting the SPR_BENCH subsection. For every learning-rate trial we will gather per-epoch train/validation accuracy and loss, as well as the final validation accuracy, then generate up to four plots: (1) accuracy curves (train & val) across epochs with separate lines for each learning rate; (2) loss curves likewise; (3) final validation accuracy versus learning rate to highlight the sweep; (4) a bar chart comparing overall test metrics (overall acc, SWA, CWA, ZSRTA) if they exist. Each plotting block is wrapped in try\u2013except, figures are saved to working_dir with descriptive names, and closed immediately after saving. The code respects the developer guidelines: starts with required imports, uses only values present in experiment_data, adds titles/sub-titles, limits figures to \u22645, and never fabricates data. Finally, the script prints a brief confirmation after each successful save.", null, "We first load experiment_data.npy from the working directory and retrieve the \u201cdropout_tuning\u201d dictionary. For each dropout setting we gather epoch-wise train/val accuracy and train/val loss, plus the final validation accuracy and any ZSRTA values that exist. We then create up to four figures: (1) a two-panel plot showing training and validation accuracy curves across epochs for every dropout value; (2) a similar two-panel plot for training and validation loss; (3) a bar chart comparing the final validation accuracy achieved by each dropout value; and (4) if at least one ZSRTA list is non-empty, a bar chart of the available ZSRTA scores. Each figure is wrapped in its own try-except so that one failure does not stop subsequent plots, and every figure is saved to the working directory with descriptive filenames that include \u201cSPR_BENCH\u201d and the plot type. After saving we always close the figure to avoid memory leaks. We respect the instruction to never fabricate data by checking keys before plotting and skip anything missing. No more than four figures are produced, so we stay within the five-figure limit. The code below follows these steps using basic matplotlib only.", "We will load experiment_data.npy, extract metrics for the SPR_BENCH dataset, and create up to five key plots: (1) training vs. validation accuracy, (2) training vs. validation loss, (3) harmonic-mean accuracy (HMA), (4) shape-weighted vs. color-weighted accuracy, and (5) zero-shot accuracy across epochs. Each plot is generated inside its own try-except block to ensure robustness, saved with descriptive filenames in the working directory, and then the figure is closed. We handle any missing data gracefully and only plot if the corresponding arrays are non-empty. After plotting, a concise summary of the final epoch\u2019s primary metrics is printed. All code follows the required imports, path handling, and figure-saving conventions. No synthetic data are introduced; everything is derived directly from experiment_data.npy. The script can be run as-is to produce PNG files in the working directory.", null, "We first load experiment_data.npy, pull out the \u201chidden_dim_tuning/SPR_BENCH\u201d sub-dictionary and iterate over the four hidden-dimension settings.  For every setting we cache the per-epoch lists of train/val accuracy and train/val loss, as well as the final ZSRTA value.  Using these cached lists we build four compact plots: (1) train vs validation accuracy across epochs for every hidden size, (2) train vs validation loss across epochs for every hidden size, (3) a bar-chart of the final validation accuracy (epoch 5) versus hidden size, and (4) a bar-chart of the zero-shot rule transfer accuracy (ZSRTA) versus hidden size.  Each figure is wrapped in its own try-except block, given an explicit title that includes the dataset name, saved into working_dir with descriptive filenames, and then closed.  We limit ourselves to four figures, well under the five-plot ceiling.  The code starts with the required imports and creation of working_dir, uses only values that already exist in experiment_data.npy, and prints a short confirmation message after each save.  All plotting calls employ basic matplotlib API without any non-standard styles, and figures are closed in a finally-like manner even if errors occur.  No simulated data or additional epochs are introduced.", "We will load the stored numpy dict, iterate over each weight-decay run, gather the per-epoch metrics, and produce up to three simple figures: (1) train/validation accuracy curves, (2) validation loss curves, and (3) a bar chart of the final ZSRTA (zero-shot rule transfer accuracy).  Each figure is wrapped in its own try-except so failures in one plot don\u2019t affect the others, and every figure is closed after saving.  Curves from all weight-decay settings are drawn together in one panel for easy comparison, with legends identifying the run keys.  File names include \u201cspr_bench\u201d and a descriptive suffix to satisfy the naming guideline.  We save every figure in working_dir that is created at the top of the script.  The code never invents data; it only accesses keys that exist inside experiment_data.npy.  Epoch axes are constructed using the length of the metric lists so they adapt to any future change in epoch count.  Finally, the script prints a short confirmation for each plot to signal successful completion.  No external style libraries are used\u2014only plain matplotlib.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": [null, "EPOCHS", "learning_rate", "batch_size", "dropout_rate", null, null, "hidden_dim", "weight_decay", null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["Below is a tiny helper script that immediately loads the stored NumPy file,\nwalks through every dataset it finds, selects the best (max-imising accuracies,\nmin-imising losses) or final value for each recorded metric, and prints them\nwith clear, human-readable names. All logic is at global scope, so the file will\nrun straight away without any special entry point.", "The script will load the stored NumPy dictionary from the working directory,\nnavigate through its hierarchical structure (EPOCHS_TUNING \u2192 SPR_BENCH \u2192\nindividual epoch runs), and gather the last-epoch value of every recorded metric\nfor each run.   For every metric we then keep the single best value across all\nruns (highest for accuracies, lowest for loss).   Finally, we print the dataset\nname (\u2018SPR_BENCH\u2019) once, followed by clearly labelled lines for train accuracy,\nvalidation accuracy, validation loss, and zero-shot rule transfer accuracy\n(ZSRTA).", "The script will load the saved NumPy dictionary, locate the section\ncorresponding to the learning-rate sweep, and identify the index of the best\nlearning rate that was stored during training. For that index it will take the\nlast (i.e., final) epoch value for each stored history: train accuracy,\nvalidation accuracy, train loss, and validation loss. It will then calculate the\ntest accuracy from the saved predictions versus ground-truth labels and retrieve\nthe stored zero-shot rule transfer accuracy (ZSRTA). Finally, it prints all\nthese values with explicit metric names preceded by the dataset name.", "The script will first locate the working directory, load the saved NumPy\ndictionary, and then iterate through its hierarchical structure: sweep name \u2192\ndataset name \u2192 batch-size tag.   For each dataset (here only SPR_BENCH) it\nprints the dataset name once, and then\u2014for every batch-size\u2014prints the final\ntraining accuracy, the best validation accuracy, the best (i.e., lowest)\nvalidation loss, and the zero-shot rule-transfer accuracy (ZSRTA).   Metric\nnames are stated explicitly, values are formatted to four decimal places, and\nthe script runs immediately on execution without any special entry point.", "Below is a concise script that immediately loads the NumPy file, walks through\nthe stored results for every dropout configuration, and prints the final value\nof each recorded metric with clear naming. It follows the exact data structure\ncreated by the original training code.", "The script first locates the working directory created by the training script\nand loads the saved experiment_data.npy file.   It then iterates over every\ndataset stored inside, translating the raw metric keys into clear human-readable\nnames.   For each metric, it selects a \u201cbest\u201d value\u2014maximum for accuracy-type\nmetrics and minimum for losses\u2014and prints that single value.   All logic lives\nat the global scope so the file executes immediately when run, and no plots are\nproduced.", "", "Below is a compact script that immediately loads the saved numpy file, walks\nthrough the stored results, and prints the best (highest for accuracies, lowest\nfor losses) value of each tracked metric for every hyper-parameter setting. The\ndataset name is printed first, followed by clearly labelled metric values.", "The script will load the saved NumPy dictionary, iterate over every weight-decay\nexperiment (treated here as separate datasets), and for each one compute the\nbest training accuracy, best validation accuracy, lowest validation loss, and\nthe final zero-shot rule transfer accuracy. These values are then printed with\nexplicit, descriptive names so the output is self-explanatory. No plots are\ngenerated and all code runs immediately at import time.", "Below is a compact script that immediately loads the saved numpy file, walks\nthrough the stored results, and prints the best (highest for accuracies, lowest\nfor losses) value of each tracked metric for every hyper-parameter setting. The\ndataset name is printed first, followed by clearly labelled metric values.", "Below is a compact script that immediately loads the saved numpy file, walks\nthrough the stored results, and prints the best (highest for accuracies, lowest\nfor losses) value of each tracked metric for every hyper-parameter setting. The\ndataset name is printed first, followed by clearly labelled metric values.", "Below is a compact script that immediately loads the saved numpy file, walks\nthrough the stored results, and prints the best (highest for accuracies, lowest\nfor losses) value of each tracked metric for every hyper-parameter setting. The\ndataset name is printed first, followed by clearly labelled metric values.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate and load experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# helper: pick best or final value + generate pretty metric name\n# ------------------------------------------------------------------\ndef select_value(metric_key, values):\n    \"\"\"\n    Return the value to report for a metric list.\n    Accuracy-like metrics -> highest, loss-like -> lowest.\n    For single-element lists just return that element.\n    \"\"\"\n    if not values:  # empty safety-check\n        return None\n    if len(values) == 1:  # only one entry\n        return values[0]\n    if \"loss\" in metric_key.lower():  # minimise losses\n        return min(values)\n    return max(values)  # maximise accuracies, etc.\n\n\ndef pretty_name(metric_key):\n    \"\"\"\n    Convert internal metric keys to readable names.\n    \"\"\"\n    mapping = {\n        \"train_acc\": \"train accuracy\",\n        \"val_acc\": \"validation accuracy\",\n        \"val_loss\": \"validation loss\",\n        \"ZSRTA\": \"zero-shot rule transfer accuracy\",\n    }\n    return mapping.get(metric_key, metric_key.replace(\"_\", \" \"))\n\n\n# ------------------------------------------------------------------\n# print results\n# ------------------------------------------------------------------\nfor dset_name, dset_dict in experiment_data.items():\n    print(f\"{dset_name}:\")  # dataset header\n\n    metrics = dset_dict.get(\"metrics\", {})\n    for key, values in metrics.items():\n        best_val = select_value(key, values)\n        if best_val is None:\n            continue\n        print(f\"  {pretty_name(key)}: {best_val:.4f}\")\n\n    print()  # blank line between datasets\n", "import os\nimport numpy as np\nimport math\n\n# ----------------------------------------------------------------------\n# locate and load the stored results -----------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ----------------------------------------------------------------------\n# helper to update best values -----------------------------------------\ndef update_best(best_dict, metric_name, value, higher_is_better=True):\n    if math.isnan(value):\n        return  # skip nan values\n    if metric_name not in best_dict:\n        best_dict[metric_name] = value\n    else:\n        if (higher_is_better and value > best_dict[metric_name]) or (\n            not higher_is_better and value < best_dict[metric_name]\n        ):\n            best_dict[metric_name] = value\n\n\n# ----------------------------------------------------------------------\n# iterate and collect the best metric values ---------------------------\nfor tuning_name, datasets in experiment_data.items():  # EPOCHS_TUNING\n    for dataset_name, runs in datasets.items():  # SPR_BENCH\n        best_metrics = {}\n\n        for run_id, run_dict in runs.items():  # 5, 10, 15, 20, 25 epochs\n            m = run_dict[\"metrics\"]\n            # final values are at the end of the per-epoch lists\n            train_acc = m[\"train_acc\"][-1]\n            val_acc = m[\"val_acc\"][-1]\n            val_loss = m[\"val_loss\"][-1]\n            zsrta = m[\"ZSRTA\"][-1] if m[\"ZSRTA\"] else float(\"nan\")\n\n            update_best(best_metrics, \"train accuracy\", train_acc, True)\n            update_best(best_metrics, \"validation accuracy\", val_acc, True)\n            update_best(best_metrics, \"validation loss\", val_loss, False)\n            update_best(best_metrics, \"zero-shot rule transfer accuracy\", zsrta, True)\n\n        # ------------------------------------------------------------------\n        # print results for this dataset -----------------------------------\n        print(dataset_name)\n        print(f\"train accuracy: {best_metrics.get('train accuracy', float('nan')):.4f}\")\n        print(\n            f\"validation accuracy: {best_metrics.get('validation accuracy', float('nan')):.4f}\"\n        )\n        print(\n            f\"validation loss: {best_metrics.get('validation loss', float('nan')):.4f}\"\n        )\n        print(\n            f\"zero-shot rule transfer accuracy: \"\n            f\"{best_metrics.get('zero-shot rule transfer accuracy', float('nan')):.4f}\"\n        )\n", "import os\nimport numpy as np\n\n# ----------------------------------------------------------------------\n# locate and load the experiment data ---------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_path):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_path}\")\n\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ----------------------------------------------------------------------\n# iterate over recorded hyper-parameter groups -------------------------\nfor hp_group, datasets in experiment_data.items():  # e.g. \"learning_rate\"\n    for dataset_name, ds_entry in datasets.items():  # e.g. \"SPR_BENCH\"\n        print(f\"\\nDataset: {dataset_name}\")\n\n        # 1. best / selected learning rate\n        best_lr = ds_entry.get(\"best_lr\")\n        print(f\"Best learning rate: {best_lr}\")\n\n        # 2. locate index of best_lr in the sweep list\n        lr_values = ds_entry.get(\"lr_values\", [])\n        if best_lr in lr_values:\n            best_idx = lr_values.index(best_lr)\n        else:  # fall back to the last run if not found\n            best_idx = -1\n\n        # 3. pull final epoch values for each metric --------------------\n        # accuracy histories\n        train_acc_hist = ds_entry[\"metrics\"][\"train_acc\"][best_idx]\n        val_acc_hist = ds_entry[\"metrics\"][\"val_acc\"][best_idx]\n        # loss histories\n        train_loss_hist = ds_entry[\"losses\"][\"train\"][best_idx]\n        val_loss_hist = ds_entry[\"losses\"][\"val\"][best_idx]\n\n        # final (last epoch) values\n        final_train_acc = train_acc_hist[-1]\n        final_val_acc = val_acc_hist[-1]\n        final_train_loss = train_loss_hist[-1]\n        final_val_loss = val_loss_hist[-1]\n\n        print(f\"Final train accuracy: {final_train_acc:.4f}\")\n        print(f\"Final validation accuracy: {final_val_acc:.4f}\")\n        print(f\"Final train loss: {final_train_loss:.4f}\")\n        print(f\"Final validation loss: {final_val_loss:.4f}\")\n\n        # 4. test-set metrics ------------------------------------------\n        preds = ds_entry.get(\"predictions\", [])\n        gts = ds_entry.get(\"ground_truth\", [])\n        if preds and gts and len(preds) == len(gts):\n            test_acc = np.mean([p == t for p, t in zip(preds, gts)])\n            print(f\"Test accuracy: {test_acc:.4f}\")\n        else:\n            print(\"Test accuracy: N/A (predictions or ground-truth missing)\")\n\n        # 5. zero-shot rule transfer accuracy (ZSRTA) -------------------\n        zs_list = ds_entry.get(\"ZSRTA\", [])\n        if zs_list:\n            zsrta_val = zs_list[-1]  # last recorded value\n            print(f\"Zero-shot rule transfer accuracy: {zsrta_val:.4f}\")\n        else:\n            print(\"Zero-shot rule transfer accuracy: N/A\")\n", "import os\nimport re\nimport numpy as np\n\n# ----------------------------------------------------------------------\n# locate and load experiment data --------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# ----------------------------------------------------------------------\n# parse and print metrics ----------------------------------------------\nfor sweep_name, datasets in experiment_data.items():  # e.g. 'batch_size_tuning'\n    for dataset_name, tags in datasets.items():  # e.g. 'SPR_BENCH'\n        print(dataset_name)  # dataset heading\n        # sort tags numerically by batch size (bs32, bs64, ...)\n        for tag, data in sorted(\n            tags.items(), key=lambda kv: int(re.findall(r\"\\d+\", kv[0])[0])\n        ):\n            bs = re.findall(r\"\\d+\", tag)[0]  # extract batch size\n            metrics = data.get(\"metrics\", {})\n            # retrieve required metric values safely\n            train_accs = metrics.get(\"train_acc\", [])\n            val_accs = metrics.get(\"val_acc\", [])\n            val_losses = metrics.get(\"val_loss\", [])\n            zsrta_vals = metrics.get(\"ZSRTA\", [])\n\n            final_train_acc = train_accs[-1] if train_accs else float(\"nan\")\n            best_validation_acc = max(val_accs) if val_accs else float(\"nan\")\n            best_validation_loss = min(val_losses) if val_losses else float(\"nan\")\n            zsrta = zsrta_vals[0] if zsrta_vals else float(\"nan\")\n\n            # print metrics with explicit names\n            print(f\"  Batch size {bs} - final train accuracy: {final_train_acc:.4f}\")\n            print(\n                f\"  Batch size {bs} - best validation accuracy: {best_validation_acc:.4f}\"\n            )\n            print(\n                f\"  Batch size {bs} - best validation loss: {best_validation_loss:.4f}\"\n            )\n            print(f\"  Batch size {bs} - zero-shot rule transfer accuracy: {zsrta:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------\n# Load the saved experiment dictionary\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_file = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_file, allow_pickle=True).item()\n\n# ---------------------------------------------------------\n# Traverse every dropout configuration and print metrics\nfor dataset_name, dataset_info in experiment_data.get(\"dropout_tuning\", {}).items():\n    print(f\"Dataset: {dataset_name}\")  # dataset header\n\n    metrics = dataset_info.get(\"metrics\", {})\n\n    # Retrieve the last (i.e., final) entry for each recorded metric\n    train_acc_vals = metrics.get(\"train_acc\", [])\n    val_acc_vals = metrics.get(\"val_acc\", [])\n    val_loss_vals = metrics.get(\"val_loss\", [])\n    zsrta_vals = metrics.get(\"ZSRTA\", [])\n\n    if train_acc_vals:\n        print(f\"  train accuracy: {train_acc_vals[-1]:.4f}\")\n    if val_acc_vals:\n        print(f\"  validation accuracy: {val_acc_vals[-1]:.4f}\")\n    if val_loss_vals:\n        print(f\"  validation loss: {val_loss_vals[-1]:.4f}\")\n    if zsrta_vals:\n        print(f\"  zero-shot rule transfer accuracy: {zsrta_vals[-1]:.4f}\")\n\n    # Add a blank line between datasets for readability\n    print()\n", "import os\nimport numpy as np\n\n# ----------------------------------------------------------------------\n# locate and load the experiment data ----------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ----------------------------------------------------------------------\n# helpers ---------------------------------------------------------------\ndef choose_best(values, is_loss=False):\n    \"\"\"Return best value (min for losses, max otherwise).\"\"\"\n    if not values:\n        return None\n    return min(values) if is_loss else max(values)\n\n\n# pretty names for nicer printing\nMETRIC_LABELS = {\n    \"train_acc\": \"train accuracy\",\n    \"val_acc\": \"validation accuracy\",\n    \"val_loss\": \"validation loss\",\n    \"swa\": \"shape-weighted accuracy\",\n    \"cwa\": \"color-weighted accuracy\",\n    \"hma\": \"harmonic mean accuracy\",\n    \"zs_acc\": \"zero-shot accuracy\",\n}\nLOSS_LABELS = {\n    \"train\": \"training loss\",\n    \"val\": \"validation loss\",\n}\n\n# ----------------------------------------------------------------------\n# iterate over datasets and print best/final metrics --------------------\nfor ds_name, ds_blob in experiment_data.items():\n    print(f\"\\nDataset: {ds_name}\")\n    # metrics -----------------------------------------------------------\n    for key, values in ds_blob.get(\"metrics\", {}).items():\n        is_loss = \"loss\" in key\n        best_val = choose_best(values, is_loss=is_loss)\n        if best_val is not None:\n            label = METRIC_LABELS.get(key, key)\n            print(f\"{label}: {best_val:.4f}\")\n    # losses ------------------------------------------------------------\n    for key, values in ds_blob.get(\"losses\", {}).items():\n        best_val = choose_best(values, is_loss=True)  # losses => min is best\n        if best_val is not None:\n            label = LOSS_LABELS.get(key, key)\n            print(f\"{label}: {best_val:.4f}\")\n", "", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# locate and load the experiment data ---------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# iterate over datasets and hyper-parameter settings ------------------\nsearch_space = experiment_data.get(\"hidden_dim_tuning\", {})\nfor dataset_name, runs in search_space.items():\n    print(f\"\\nDataset: {dataset_name}\")  # requirement (3)\n\n    for run_name, mdata in runs.items():\n        # retrieve recorded metric sequences\n        train_accs = mdata[\"metrics\"].get(\"train_acc\", [])\n        val_accs = mdata[\"metrics\"].get(\"val_acc\", [])\n        val_losses = mdata[\"metrics\"].get(\"val_loss\", [])\n        zsrtas = mdata[\"metrics\"].get(\"ZSRTA\", [])\n\n        # derive best/final values as specified\n        best_train_acc = max(train_accs) if train_accs else float(\"nan\")\n        best_val_acc = max(val_accs) if val_accs else float(\"nan\")\n        best_val_loss = min(val_losses) if val_losses else float(\"nan\")\n        final_zsrta = zsrtas[-1] if zsrtas else float(\"nan\")\n\n        # output with explicit, descriptive labels --------------------\n        print(f\"  Hyper-parameter setting: {run_name}\")\n        print(f\"    Train accuracy: {best_train_acc:.4f}\")\n        print(f\"    Validation accuracy: {best_val_acc:.4f}\")\n        print(f\"    Validation loss: {best_val_loss:.4f}\")\n        print(f\"    Zero-shot rule transfer accuracy: {final_zsrta:.4f}\")\n", "import os\nimport numpy as np\n\n# ----------------------------------------------------------------------\n# Locate and load the saved results\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ----------------------------------------------------------------------\n# Helper to safely extract best / final values\ndef best_accuracy(acc_list):\n    return max(acc_list) if acc_list else float(\"nan\")\n\n\ndef lowest_loss(loss_list):\n    return min(loss_list) if loss_list else float(\"nan\")\n\n\ndef final_value(lst):\n    return lst[-1] if lst else float(\"nan\")\n\n\n# ----------------------------------------------------------------------\n# Iterate over each experiment (dataset) and print metrics\nfor run_name, run_data in experiment_data.get(\"weight_decay\", {}).items():\n    m = run_data.get(\"metrics\", {})\n\n    train_acc_best = best_accuracy(m.get(\"train_acc\", []))\n    val_acc_best = best_accuracy(m.get(\"val_acc\", []))\n    val_loss_low = lowest_loss(m.get(\"val_loss\", []))\n    zsrt_acc_final = final_value(m.get(\"ZSRTA\", []))\n\n    print(f\"\\nDataset: {run_name}\")\n    print(f\"best train accuracy: {train_acc_best:.4f}\")\n    print(f\"best validation accuracy: {val_acc_best:.4f}\")\n    print(f\"lowest validation loss: {val_loss_low:.4f}\")\n    print(f\"final zero-shot rule transfer accuracy: {zsrt_acc_final:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# locate and load the experiment data ---------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# iterate over datasets and hyper-parameter settings ------------------\nsearch_space = experiment_data.get(\"hidden_dim_tuning\", {})\nfor dataset_name, runs in search_space.items():\n    print(f\"\\nDataset: {dataset_name}\")  # requirement (3)\n\n    for run_name, mdata in runs.items():\n        # retrieve recorded metric sequences\n        train_accs = mdata[\"metrics\"].get(\"train_acc\", [])\n        val_accs = mdata[\"metrics\"].get(\"val_acc\", [])\n        val_losses = mdata[\"metrics\"].get(\"val_loss\", [])\n        zsrtas = mdata[\"metrics\"].get(\"ZSRTA\", [])\n\n        # derive best/final values as specified\n        best_train_acc = max(train_accs) if train_accs else float(\"nan\")\n        best_val_acc = max(val_accs) if val_accs else float(\"nan\")\n        best_val_loss = min(val_losses) if val_losses else float(\"nan\")\n        final_zsrta = zsrtas[-1] if zsrtas else float(\"nan\")\n\n        # output with explicit, descriptive labels --------------------\n        print(f\"  Hyper-parameter setting: {run_name}\")\n        print(f\"    Train accuracy: {best_train_acc:.4f}\")\n        print(f\"    Validation accuracy: {best_val_acc:.4f}\")\n        print(f\"    Validation loss: {best_val_loss:.4f}\")\n        print(f\"    Zero-shot rule transfer accuracy: {final_zsrta:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# locate and load the experiment data ---------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# iterate over datasets and hyper-parameter settings ------------------\nsearch_space = experiment_data.get(\"hidden_dim_tuning\", {})\nfor dataset_name, runs in search_space.items():\n    print(f\"\\nDataset: {dataset_name}\")  # requirement (3)\n\n    for run_name, mdata in runs.items():\n        # retrieve recorded metric sequences\n        train_accs = mdata[\"metrics\"].get(\"train_acc\", [])\n        val_accs = mdata[\"metrics\"].get(\"val_acc\", [])\n        val_losses = mdata[\"metrics\"].get(\"val_loss\", [])\n        zsrtas = mdata[\"metrics\"].get(\"ZSRTA\", [])\n\n        # derive best/final values as specified\n        best_train_acc = max(train_accs) if train_accs else float(\"nan\")\n        best_val_acc = max(val_accs) if val_accs else float(\"nan\")\n        best_val_loss = min(val_losses) if val_losses else float(\"nan\")\n        final_zsrta = zsrtas[-1] if zsrtas else float(\"nan\")\n\n        # output with explicit, descriptive labels --------------------\n        print(f\"  Hyper-parameter setting: {run_name}\")\n        print(f\"    Train accuracy: {best_train_acc:.4f}\")\n        print(f\"    Validation accuracy: {best_val_acc:.4f}\")\n        print(f\"    Validation loss: {best_val_loss:.4f}\")\n        print(f\"    Zero-shot rule transfer accuracy: {final_zsrta:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# locate and load the experiment data ---------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# iterate over datasets and hyper-parameter settings ------------------\nsearch_space = experiment_data.get(\"hidden_dim_tuning\", {})\nfor dataset_name, runs in search_space.items():\n    print(f\"\\nDataset: {dataset_name}\")  # requirement (3)\n\n    for run_name, mdata in runs.items():\n        # retrieve recorded metric sequences\n        train_accs = mdata[\"metrics\"].get(\"train_acc\", [])\n        val_accs = mdata[\"metrics\"].get(\"val_acc\", [])\n        val_losses = mdata[\"metrics\"].get(\"val_loss\", [])\n        zsrtas = mdata[\"metrics\"].get(\"ZSRTA\", [])\n\n        # derive best/final values as specified\n        best_train_acc = max(train_accs) if train_accs else float(\"nan\")\n        best_val_acc = max(val_accs) if val_accs else float(\"nan\")\n        best_val_loss = min(val_losses) if val_losses else float(\"nan\")\n        final_zsrta = zsrtas[-1] if zsrtas else float(\"nan\")\n\n        # output with explicit, descriptive labels --------------------\n        print(f\"  Hyper-parameter setting: {run_name}\")\n        print(f\"    Train accuracy: {best_train_acc:.4f}\")\n        print(f\"    Validation accuracy: {best_val_acc:.4f}\")\n        print(f\"    Validation loss: {best_val_loss:.4f}\")\n        print(f\"    Zero-shot rule transfer accuracy: {final_zsrta:.4f}\")\n", ""], "parse_term_out": ["['SPR_BENCH:', '\\n', '  train accuracy: 0.9999', '\\n', '  validation accuracy:\n0.9998', '\\n', '  validation loss: 0.0021', '\\n', '  zero-shot rule transfer\naccuracy: nan', '\\n', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['SPR_BENCH', '\\n', 'train accuracy: 1.0000', '\\n', 'validation accuracy:\n0.9996', '\\n', 'validation loss: 0.0010', '\\n', 'zero-shot rule transfer\naccuracy: nan', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'Best learning rate: 0.002', '\\n', 'Final train\naccuracy: 1.0000', '\\n', 'Final validation accuracy: 0.9998', '\\n', 'Final train\nloss: 0.0004', '\\n', 'Final validation loss: 0.0010', '\\n', 'Test accuracy:\n0.7000', '\\n', 'Zero-shot rule transfer accuracy: nan', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', '  Batch size 32 - final train accuracy: 1.0000', '\\n', '\nBatch size 32 - best validation accuracy: 0.9998', '\\n', '  Batch size 32 - best\nvalidation loss: 0.0009', '\\n', '  Batch size 32 - zero-shot rule transfer\naccuracy: nan', '\\n', '  Batch size 64 - final train accuracy: 1.0000', '\\n', '\nBatch size 64 - best validation accuracy: 0.9998', '\\n', '  Batch size 64 - best\nvalidation loss: 0.0017', '\\n', '  Batch size 64 - zero-shot rule transfer\naccuracy: nan', '\\n', '  Batch size 128 - final train accuracy: 0.9999', '\\n', '\nBatch size 128 - best validation accuracy: 0.9994', '\\n', '  Batch size 128 -\nbest validation loss: 0.0024', '\\n', '  Batch size 128 - zero-shot rule transfer\naccuracy: nan', '\\n', '  Batch size 256 - final train accuracy: 0.9974', '\\n', '\nBatch size 256 - best validation accuracy: 0.9980', '\\n', '  Batch size 256 -\nbest validation loss: 0.0097', '\\n', '  Batch size 256 - zero-shot rule transfer\naccuracy: nan', '\\n', '  Batch size 512 - final train accuracy: 0.9806', '\\n', '\nBatch size 512 - best validation accuracy: 0.9826', '\\n', '  Batch size 512 -\nbest validation loss: 0.0568', '\\n', '  Batch size 512 - zero-shot rule transfer\naccuracy: nan', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Dataset: dropout_0.0', '\\n', '  train accuracy: 0.9997', '\\n', '  validation\naccuracy: 0.9990', '\\n', '  validation loss: 0.0030', '\\n', '\\n', 'Dataset:\ndropout_0.2', '\\n', '  train accuracy: 0.9999', '\\n', '  validation accuracy:\n0.9998', '\\n', '  validation loss: 0.0025', '\\n', '  zero-shot rule transfer\naccuracy: nan', '\\n', '\\n', 'Dataset: dropout_0.4', '\\n', '  train accuracy:\n0.9993', '\\n', '  validation accuracy: 0.9990', '\\n', '  validation loss:\n0.0032', '\\n', '\\n', 'Dataset: dropout_0.6', '\\n', '  train accuracy: 0.9966',\n'\\n', '  validation accuracy: 0.9978', '\\n', '  validation loss: 0.0074', '\\n',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'train accuracy: 1.0000', '\\n', 'validation\naccuracy: 0.9998', '\\n', 'validation loss: 0.0012', '\\n', 'shape-weighted\naccuracy: 0.9998', '\\n', 'color-weighted accuracy: 0.9999', '\\n', 'harmonic mean\naccuracy: 0.9999', '\\n', 'zero-shot accuracy: 0.0000', '\\n', 'training loss:\n0.0002', '\\n', 'validation loss: 0.0012', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "", "['\\nDataset: SPR_BENCH', '\\n', '  Hyper-parameter setting: hidden_64', '\\n', '\nTrain accuracy: 0.9982', '\\n', '    Validation accuracy: 0.9986', '\\n', '\nValidation loss: 0.0071', '\\n', '    Zero-shot rule transfer accuracy: nan',\n'\\n', '  Hyper-parameter setting: hidden_128', '\\n', '    Train accuracy:\n0.9993', '\\n', '    Validation accuracy: 0.9992', '\\n', '    Validation loss:\n0.0039', '\\n', '    Zero-shot rule transfer accuracy: nan', '\\n', '  Hyper-\nparameter setting: hidden_256', '\\n', '    Train accuracy: 1.0000', '\\n', '\nValidation accuracy: 1.0000', '\\n', '    Validation loss: 0.0007', '\\n', '\nZero-shot rule transfer accuracy: nan', '\\n', '  Hyper-parameter setting:\nhidden_512', '\\n', '    Train accuracy: 1.0000', '\\n', '    Validation accuracy:\n1.0000', '\\n', '    Validation loss: 0.0005', '\\n', '    Zero-shot rule transfer\naccuracy: nan', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: wd_0.0', '\\n', 'best train accuracy: 1.0000', '\\n', 'best\nvalidation accuracy: 0.9996', '\\n', 'lowest validation loss: 0.0021', '\\n',\n'final zero-shot rule transfer accuracy: nan', '\\n', '\\nDataset: wd_1e-06',\n'\\n', 'best train accuracy: 0.9990', '\\n', 'best validation accuracy: 0.9986',\n'\\n', 'lowest validation loss: 0.0055', '\\n', 'final zero-shot rule transfer\naccuracy: nan', '\\n', '\\nDataset: wd_1e-05', '\\n', 'best train accuracy:\n0.9999', '\\n', 'best validation accuracy: 0.9996', '\\n', 'lowest validation\nloss: 0.0025', '\\n', 'final zero-shot rule transfer accuracy: nan', '\\n',\n'\\nDataset: wd_0.0001', '\\n', 'best train accuracy: 0.9988', '\\n', 'best\nvalidation accuracy: 0.9978', '\\n', 'lowest validation loss: 0.0069', '\\n',\n'final zero-shot rule transfer accuracy: nan', '\\n', '\\nDataset: wd_0.001',\n'\\n', 'best train accuracy: 0.9892', '\\n', 'best validation accuracy: 0.9890',\n'\\n', 'lowest validation loss: 0.0344', '\\n', 'final zero-shot rule transfer\naccuracy: nan', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Hyper-parameter setting: hidden_64', '\\n', '\nTrain accuracy: 0.9982', '\\n', '    Validation accuracy: 0.9986', '\\n', '\nValidation loss: 0.0071', '\\n', '    Zero-shot rule transfer accuracy: nan',\n'\\n', '  Hyper-parameter setting: hidden_128', '\\n', '    Train accuracy:\n0.9993', '\\n', '    Validation accuracy: 0.9992', '\\n', '    Validation loss:\n0.0039', '\\n', '    Zero-shot rule transfer accuracy: nan', '\\n', '  Hyper-\nparameter setting: hidden_256', '\\n', '    Train accuracy: 1.0000', '\\n', '\nValidation accuracy: 1.0000', '\\n', '    Validation loss: 0.0007', '\\n', '\nZero-shot rule transfer accuracy: nan', '\\n', '  Hyper-parameter setting:\nhidden_512', '\\n', '    Train accuracy: 1.0000', '\\n', '    Validation accuracy:\n1.0000', '\\n', '    Validation loss: 0.0005', '\\n', '    Zero-shot rule transfer\naccuracy: nan', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Hyper-parameter setting: hidden_64', '\\n', '\nTrain accuracy: 0.9982', '\\n', '    Validation accuracy: 0.9986', '\\n', '\nValidation loss: 0.0071', '\\n', '    Zero-shot rule transfer accuracy: nan',\n'\\n', '  Hyper-parameter setting: hidden_128', '\\n', '    Train accuracy:\n0.9993', '\\n', '    Validation accuracy: 0.9992', '\\n', '    Validation loss:\n0.0039', '\\n', '    Zero-shot rule transfer accuracy: nan', '\\n', '  Hyper-\nparameter setting: hidden_256', '\\n', '    Train accuracy: 1.0000', '\\n', '\nValidation accuracy: 1.0000', '\\n', '    Validation loss: 0.0007', '\\n', '\nZero-shot rule transfer accuracy: nan', '\\n', '  Hyper-parameter setting:\nhidden_512', '\\n', '    Train accuracy: 1.0000', '\\n', '    Validation accuracy:\n1.0000', '\\n', '    Validation loss: 0.0005', '\\n', '    Zero-shot rule transfer\naccuracy: nan', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Hyper-parameter setting: hidden_64', '\\n', '\nTrain accuracy: 0.9982', '\\n', '    Validation accuracy: 0.9986', '\\n', '\nValidation loss: 0.0071', '\\n', '    Zero-shot rule transfer accuracy: nan',\n'\\n', '  Hyper-parameter setting: hidden_128', '\\n', '    Train accuracy:\n0.9993', '\\n', '    Validation accuracy: 0.9992', '\\n', '    Validation loss:\n0.0039', '\\n', '    Zero-shot rule transfer accuracy: nan', '\\n', '  Hyper-\nparameter setting: hidden_256', '\\n', '    Train accuracy: 1.0000', '\\n', '\nValidation accuracy: 1.0000', '\\n', '    Validation loss: 0.0007', '\\n', '\nZero-shot rule transfer accuracy: nan', '\\n', '  Hyper-parameter setting:\nhidden_512', '\\n', '    Train accuracy: 1.0000', '\\n', '    Validation accuracy:\n1.0000', '\\n', '    Validation loss: 0.0005', '\\n', '    Zero-shot rule transfer\naccuracy: nan', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
