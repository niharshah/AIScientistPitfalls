[
  {
    "overall_plan": "Ablation name: Multi-Dataset Generalisation (3\u00d7 Synthetic SPR Variants).\nThe solution generates three biased variants of the original SPR\u2010BENCH training split (different shape/length biases and random seeds), builds loaders for the union of those variants, retrains the original HybridTransformer on the mixed data and finally evaluates on the untouched SPR-BENCH dev/test splits. All losses, metrics and predictions are logged in the required experiment_data structure and saved to \u201cexperiment_data.npy\u201d, together with a validation\u2013SWA curve.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "Training Loss",
            "lower_is_better": true,
            "description": "Loss during training phase",
            "data": [
              {
                "dataset_name": "SPR_BENCH_HELDOUT",
                "final_value": 0.0005,
                "best_value": 0.0005
              }
            ]
          },
          {
            "metric_name": "Validation Loss",
            "lower_is_better": true,
            "description": "Loss during validation phase",
            "data": [
              {
                "dataset_name": "SPR_BENCH_HELDOUT",
                "final_value": 0.0012,
                "best_value": 0.0012
              }
            ]
          },
          {
            "metric_name": "Validation Shape-Weighted Accuracy",
            "lower_is_better": false,
            "description": "Shape-weighted accuracy during validation phase",
            "data": [
              {
                "dataset_name": "SPR_BENCH_HELDOUT",
                "final_value": 0.9995,
                "best_value": 0.9995
              }
            ]
          },
          {
            "metric_name": "Test Loss",
            "lower_is_better": true,
            "description": "Loss during testing phase",
            "data": [
              {
                "dataset_name": "SPR_BENCH_HELDOUT",
                "final_value": 4.0157,
                "best_value": 4.0157
              }
            ]
          },
          {
            "metric_name": "Test Shape-Weighted Accuracy",
            "lower_is_better": false,
            "description": "Shape-weighted accuracy during testing phase",
            "data": [
              {
                "dataset_name": "SPR_BENCH_HELDOUT",
                "final_value": 0.6522,
                "best_value": 0.6522
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "# ----------------------------------------------------\n# Multi-Dataset Generalisation Ablation\n# ----------------------------------------------------\nimport os, pathlib, math, time, itertools, numpy as np, torch, random\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ---------------- housekeeping -----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Running on\", device)\n\n# --------------- experiment log ---------------------\nexperiment_data = {\n    \"MultiDataset\": {\n        \"SPR_BENCH_HELDOUT\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"MultiDataset\"][\"SPR_BENCH_HELDOUT\"]\n\n# --------------- load original SPR_BENCH ------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\nspr = load_spr_bench(DATA_PATH)\nprint(\"Original sizes:\", {k: len(v) for k, v in spr.items()})\n\n# --------------- utilities --------------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(chars_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(chars_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab, color_vocab = build_char_vocab(shape_chars), build_char_vocab(color_chars)\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# --------------- torch dataset ----------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, sequences, labels):\n        self.seqs, self.labels = sequences, labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids),\n            \"color_ids\": torch.tensor(cids),\n            \"sym_feats\": feats,\n            \"label\": torch.tensor(label2idx[self.labels[idx]]),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\n# --------------- variant creation -------------------\ndef create_variant(seed: int, bias: str):\n    random.seed(seed)\n    np.random.seed(seed)\n    seqs, labels = spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"]\n    if bias == \"shape_A\":\n        fav = [i for i, s in enumerate(seqs) if s.split()[0][0] == \"A\"]\n    elif bias == \"short\":\n        fav = [i for i, s in enumerate(seqs) if len(s.split()) <= 6]\n    elif bias == \"long\":\n        fav = [i for i, s in enumerate(seqs) if len(s.split()) >= 10]\n    else:\n        fav = list(range(len(seqs)))\n    prob = np.ones(len(seqs))\n    prob[fav] *= 5.0  # up-weight favourites\n    prob /= prob.sum()\n    idxs = np.random.choice(len(seqs), size=len(seqs), replace=True, p=prob)\n    return [seqs[i] for i in idxs], [labels[i] for i in idxs]\n\n\nvariant_specs = [(111, \"shape_A\"), (222, \"short\"), (333, \"long\")]\nvariant_datasets = []\nfor seed, bias in variant_specs:\n    v_seqs, v_labels = create_variant(seed, bias)\n    variant_datasets.append(SPRTorchDataset(v_seqs, v_labels))\nprint(\"Built {} variants.\".format(len(variant_datasets)))\n\n# --------------- loaders ----------------------------\ntrain_dataset = ConcatDataset(variant_datasets)\ntrain_loader = DataLoader(train_dataset, 128, shuffle=True, collate_fn=collate)\n\ndev_ds = SPRTorchDataset(spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"])\ntest_ds = SPRTorchDataset(spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"])\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# --------------- model ------------------------------\nclass HybridTransformer(nn.Module):\n    def __init__(self, s_vocab, c_vocab, num_labels, d_model=64, nhead=4, nlayers=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(512, d_model)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, 128, 0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n        self.feat_norm = nn.LayerNorm(3)\n        self.fc = nn.Linear(d_model + 3, num_labels)\n\n    def forward(self, shape_ids, color_ids, sym_feats):\n        seq_len = shape_ids.size(1)\n        pos = (\n            torch.arange(seq_len, device=shape_ids.device)\n            .unsqueeze(0)\n            .expand(shape_ids.size(0), -1)\n        )\n        x = self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        mask = shape_ids.eq(0)\n        h = self.encoder(x, src_key_padding_mask=mask)\n        pooled = h.masked_fill(mask.unsqueeze(-1), 0).sum(1) / (~mask).sum(\n            1, keepdim=True\n        ).clamp(min=1)\n        logits = self.fc(torch.cat([pooled, self.feat_norm(sym_feats)], dim=-1))\n        return logits\n\n\nmodel = HybridTransformer(len(shape_vocab), len(color_vocab), len(label_set)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# --------------- evaluation -------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            bt = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(bt[\"shape_ids\"], bt[\"color_ids\"], bt[\"sym_feats\"])\n            loss = criterion(logits, bt[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = bt[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(bt[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (tot_loss / total, shape_weighted_accuracy(all_seq, y_true, y_pred))\n\n\n# --------------- training loop ----------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = float(\"inf\"), 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        bt = {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()}\n        optimizer.zero_grad()\n        logits = model(bt[\"shape_ids\"], bt[\"color_ids\"], bt[\"sym_feats\"])\n        loss = criterion(logits, bt[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * bt[\"labels\"].size(0)\n    train_loss = running / len(train_dataset)\n    val_loss, val_swa = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d} | train {train_loss:.4f} | val {val_loss:.4f} | SWA {val_swa:.3f}\"\n    )\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# --------------- final test -------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa = evaluate(test_loader)\nprint(f\"\\nTEST \u2011 loss {test_loss:.4f} | SWA {test_swa:.3f}\")\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"SWA\"][\"test\"] = test_swa\n\n# --------------- predictions for saving -------------\nmodel.eval()\npreds, trues, seqs = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        bt = {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()}\n        out = model(bt[\"shape_ids\"], bt[\"color_ids\"], bt[\"sym_feats\"]).argmax(-1)\n        preds.extend(out.cpu().tolist())\n        trues.extend(bt[\"labels\"].cpu().tolist())\n        seqs.extend(batch[\"raw_seq\"])\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# --------------- save artefacts ---------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Plot saved.\")\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------- load experiment data ----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    rec = experiment_data[\"MultiDataset\"][\"SPR_BENCH_HELDOUT\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    rec = None\n\nif rec:\n    epochs = np.arange(1, len(rec[\"losses\"][\"train\"]) + 1)\n\n    # ------------- plot 1: loss curves -----------------\n    try:\n        plt.figure(figsize=(6, 4))\n        plt.plot(epochs, rec[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(epochs, rec[\"losses\"][\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH_HELDOUT Loss Curves\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_HELDOUT_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ------------- plot 2: validation SWA --------------\n    try:\n        plt.figure(figsize=(6, 4))\n        plt.plot(epochs, rec[\"SWA\"][\"val\"], marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(\"SPR_BENCH_HELDOUT Validation SWA\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_HELDOUT_val_SWA.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot: {e}\")\n        plt.close()\n\n    # ------------- plot 3: confusion matrix ------------\n    try:\n        y_true = np.array(rec[\"ground_truth\"])\n        y_pred = np.array(rec[\"predictions\"])\n        labels = np.unique(np.concatenate([y_true, y_pred]))\n        if len(labels) <= 20:  # keep plot readable\n            cm = np.zeros((len(labels), len(labels)), dtype=int)\n            for t, p in zip(y_true, y_pred):\n                cm[t, p] += 1\n            plt.figure(figsize=(6, 5))\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im, shrink=0.8)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(\"SPR_BENCH_HELDOUT Confusion Matrix\")\n            plt.xticks(labels)\n            plt.yticks(labels)\n            plt.tight_layout()\n            fname = os.path.join(working_dir, \"SPR_BENCH_HELDOUT_confusion_matrix.png\")\n            plt.savefig(fname)\n            plt.close()\n        else:\n            print(\"Too many labels for readable confusion matrix; skipping plot.\")\n    except Exception as e:\n        print(f\"Error creating confusion matrix plot: {e}\")\n        plt.close()\n",
    "plot_plan": "We first load the saved experiment_data.npy and extract the record for the \u2018SPR_BENCH_HELDOUT\u2019 split. From it we pull the epoch-wise training and validation losses as well as the validation SWA scores. These sequences are plotted against epoch indices (starting from 1). Next we compute a confusion matrix using the stored ground-truth and prediction indices; if the number of labels is reasonable (\u226420) we visualise it with imshow, otherwise we skip the plot. Each figure is wrapped in its own try-except block, stored in working_dir with descriptive filenames, given a clear title that includes the dataset name, and closed afterwards. We cap the total number of figures to three, satisfying the \u201c\u22645 figures\u201d rule. Only data present in experiment_data.npy are used; nothing is fabricated. Finally, no custom matplotlib styles are employed and all figures are saved in PNG format.",
    "plot_analyses": [
      {
        "analysis": "This plot shows the Validation Shape-Weighted Accuracy (SWA) over training epochs. The SWA starts at a relatively high value (~0.994) and shows a general upward trend, indicating improved performance as the training progresses. There is a noticeable dip at epoch 5, which could suggest instability or a temporary failure to generalize. Afterward, the SWA stabilizes and reaches a plateau near 0.999, suggesting that the model achieves near-perfect generalization on the validation set.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/swa_curve.png"
      },
      {
        "analysis": "The loss curves for both training and validation sets are depicted here. The training loss starts high and decreases rapidly, indicating effective learning. The validation loss also decreases but exhibits some fluctuations, particularly around epoch 6, which might correspond to overfitting or challenges in generalization. By the final epochs, both losses are close to zero, suggesting that the model fits the data well.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_loss_curves.png"
      },
      {
        "analysis": "This plot again shows Validation Shape-Weighted Accuracy (SWA) but emphasizes the individual points more clearly. The trend mirrors the earlier SWA plot, where the accuracy improves with epochs, stabilizes, and reaches a high value near 0.999. The dip at epoch 6 is also visible here, reinforcing the need to investigate potential model instability or hyperparameter adjustments to smooth the training process.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_val_SWA.png"
      },
      {
        "analysis": "The confusion matrix shows the performance of the model on a binary classification task. The true negatives and true positives are represented in the darker blue regions, indicating that the model correctly classifies the majority of examples. The lighter blue regions for false positives and false negatives are relatively smaller, suggesting that the model achieves high accuracy. However, the exact numerical values should be analyzed to assess class imbalance or specific areas for improvement.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_confusion_matrix.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/swa_curve.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_loss_curves.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_val_SWA.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/SPR_BENCH_HELDOUT_confusion_matrix.png"
    ],
    "vlm_feedback_summary": "The plots collectively indicate that the model performs well with high Shape-Weighted Accuracy (SWA) and low loss values, particularly in later epochs. There is a slight instability around epoch 6 that warrants further investigation. The confusion matrix confirms high classification accuracy, but potential class imbalance should be examined.",
    "exp_results_dir": "experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534",
    "ablation_name": "Multi-Dataset Generalisation (3\u00d7 Synthetic SPR Variants)",
    "exp_results_npy_files": [
      "experiment_results/experiment_e2b1e083178f40da9f26f13531fb5fa3_proc_2705534/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: CLS-Token Pooling.\nThis ablation keeps the architecture identical to the baseline except for the sequence-level summarisation: a learnable [CLS] token is prepended at every step, a suitable padding mask is built, and after the Transformer encoder only the hidden state of this first position is used (concatenated with the normalised symbolic features) for classification.  All data loading, training, logging and plotting routines stay unchanged, ensuring the study isolates the pooling strategy alone.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "loss",
            "lower_is_better": true,
            "description": "Measures the error of the model's predictions; lower values indicate better performance.",
            "data": [
              {
                "dataset_name": "Training",
                "final_value": 0.018,
                "best_value": 0.018
              },
              {
                "dataset_name": "Validation",
                "final_value": 0.0113,
                "best_value": 0.0113
              },
              {
                "dataset_name": "Test",
                "final_value": 2.3917,
                "best_value": 2.3917
              }
            ]
          },
          {
            "metric_name": "shape-weighted accuracy",
            "lower_is_better": false,
            "description": "Measures the accuracy of predictions, weighted by the shape of the data; higher values indicate better performance.",
            "data": [
              {
                "dataset_name": "Validation",
                "final_value": 0.9972,
                "best_value": 0.9972
              },
              {
                "dataset_name": "Test",
                "final_value": 0.6529,
                "best_value": 0.6529
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "# CLS-TOKEN POOLING ABLATION \u2013 self-contained script\nimport os, pathlib, math, time, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ------- bookkeeping & GPU ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------- experiment dict scaffold ----\nexperiment_data = {\n    \"CLS_Pooling\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"CLS_Pooling\"][\"SPR_BENCH\"]\n\n\n# ---------- dataset helpers ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# ---------- load data ----------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# ---------- vocabularies ------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab, color_vocab = build_char_vocab(shape_chars), build_char_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# ---------- encoding utilities -------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# ---------- torch datasets -----------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# ---------- model with CLS pooling ---\nclass HybridTransformerCLS(nn.Module):\n    def __init__(\n        self, s_vocab, c_vocab, num_labels, d_model=64, nhead=4, nlayers=2, max_len=512\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(max_len + 1, d_model)  # +1 for CLS position\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))  # learnable CLS\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n        self.feat_norm = nn.LayerNorm(3)\n        self.fc = nn.Linear(d_model + 3, num_labels)\n        nn.init.normal_(self.cls_token, std=0.02)\n\n    def forward(self, shape_ids, color_ids, sym_feats):\n        B, L = shape_ids.size()\n        device = shape_ids.device\n        tok_emb = self.shape_emb(shape_ids) + self.color_emb(color_ids)\n        pos_ids = torch.arange(1, L + 1, device=device).unsqueeze(0).expand(B, -1)\n        tok_emb = tok_emb + self.pos_emb(pos_ids)\n        cls_emb = self.cls_token.expand(B, -1, -1) + self.pos_emb(\n            torch.zeros(B, 1, dtype=torch.long, device=device)\n        )\n        x = torch.cat([cls_emb, tok_emb], dim=1)  # [B, L+1, d]\n        pad_mask = shape_ids.eq(0)  # [B, L]\n        src_mask = torch.cat(\n            [torch.zeros(B, 1, dtype=torch.bool, device=device), pad_mask], dim=1\n        )\n        h = self.encoder(x, src_key_padding_mask=src_mask)\n        pooled = h[:, 0]  # CLS state\n        logits = self.fc(torch.cat([pooled, self.feat_norm(sym_feats)], dim=-1))\n        return logits\n\n\nmodel = HybridTransformerCLS(len(shape_vocab), len(color_vocab), len(label_set)).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ---------- evaluation ---------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss = total = 0.0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# ---------- training loop ------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val, no_imp, best_state = math.inf, 0, None\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n    if val_loss < best_val - 1e-4:\n        best_val = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n    if no_imp >= PATIENCE:\n        print(\"Early stopping.\")\n        break\n\n# ---------- load best & test ----------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# ---------- save artefacts -----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- load data -----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    rec = experiment_data[\"CLS_Pooling\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    rec = None\n\n# ----------------- plot 1: loss curves -----------------\ntry:\n    if rec is None:\n        raise ValueError(\"Experiment record missing\")\n    train_loss = rec[\"losses\"][\"train\"]\n    val_loss = rec[\"losses\"][\"val\"]\n    epochs = np.arange(1, len(train_loss) + 1)\n\n    plt.figure()\n    plt.plot(epochs, train_loss, label=\"Train Loss\")\n    plt.plot(epochs, val_loss, label=\"Val Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH \u2013 Training vs Validation Loss\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ----------------- plot 2: validation SWA -----------------\ntry:\n    if rec is None:\n        raise ValueError(\"Experiment record missing\")\n    val_swa = rec[\"SWA\"][\"val\"]\n    epochs = np.arange(1, len(val_swa) + 1)\n\n    plt.figure()\n    plt.plot(epochs, val_swa, marker=\"o\", label=\"Val SWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Shape-Weighted Accuracy\")\n    plt.title(\"SPR_BENCH \u2013 Validation SWA Curve\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_validation_SWA.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA plot: {e}\")\n    plt.close()\n\n# ----------------- plot 3: confusion matrix -----------------\ntry:\n    if rec is None:\n        raise ValueError(\"Experiment record missing\")\n    y_pred = np.array(rec[\"predictions\"])\n    y_true = np.array(rec[\"ground_truth\"])\n    num_labels = int(max(y_true.max(), y_pred.max()) + 1)\n    cm = np.zeros((num_labels, num_labels), dtype=int)\n    for t, p in zip(y_true, y_pred):\n        cm[t, p] += 1\n\n    plt.figure(figsize=(6, 5))\n    plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n    plt.colorbar()\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(\n        \"SPR_BENCH \u2013 Confusion Matrix\\nLeft: Ground Truth, Right: Generated Predictions\"\n    )\n    # annotate cells\n    for i in range(num_labels):\n        for j in range(num_labels):\n            plt.text(\n                j,\n                i,\n                cm[i, j],\n                ha=\"center\",\n                va=\"center\",\n                color=\"white\" if cm[i, j] > cm.max() * 0.5 else \"black\",\n                fontsize=8,\n            )\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n",
    "plot_plan": "We first load experiment_data.npy and grab the single experiment record (CLS_Pooling\u2006/\u2006SPR_BENCH).  From it we extract the per-epoch training and validation losses, the per-epoch validation SWA scores, and the final test predictions/ground-truth arrays.  Three plots are generated, each wrapped in its own try-except block: (1) a line plot showing training vs. validation loss over epochs; (2) a line plot of the validation shape-weighted accuracy (SWA) curve; (3) a confusion-matrix heat-map comparing ground-truth labels to model predictions on the test set.  All figures are saved into working_dir with descriptive filenames that include the dataset name and plot type.  Each figure is titled clearly and closed after saving to free memory.  Only data present in experiment_data.npy are used\u2014no synthetic values are created.  The code follows the required imports/order and prints a confirmation for each saved plot as well as any caught errors.",
    "plot_analyses": [
      {
        "analysis": "The Validation SWA curve demonstrates a steady improvement in Shape-Weighted Accuracy over the epochs, reaching a plateau at around epoch 7. This indicates the model's ability to generalize well on the validation set and suggests that the integration of neural and symbolic reasoning is effective in achieving high accuracy.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/swa_curve.png"
      },
      {
        "analysis": "The Training vs. Validation Loss plot shows a consistent decrease in both training and validation loss over the epochs, with the training loss being slightly lower than the validation loss. This indicates that the model is learning effectively without significant overfitting, as the gap between the two losses remains small.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_loss_curves.png"
      },
      {
        "analysis": "The Validation SWA Curve corroborates the findings from the Validation SWA plot, showing a steady improvement in Shape-Weighted Accuracy over time. The curve stabilizes after epoch 7, suggesting that the model has reached its optimal performance.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_validation_SWA.png"
      },
      {
        "analysis": "The confusion matrix reveals that the model performs well overall but struggles slightly with false positives and false negatives. The misclassification rates suggest potential room for improvement in handling edge cases or ambiguous sequences.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_confusion_matrix.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/swa_curve.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_loss_curves.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_validation_SWA.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/SPR_BENCH_confusion_matrix.png"
    ],
    "vlm_feedback_summary": "The plots provide a comprehensive view of the model's performance. The Validation SWA and loss curves indicate effective learning and generalization, while the confusion matrix highlights areas for further refinement in classification accuracy.",
    "exp_results_dir": "experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536",
    "ablation_name": "CLS-Token Pooling",
    "exp_results_npy_files": [
      "experiment_results/experiment_bda3ae3819dc4248b321b28b654c6cc2_proc_2705536/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: No-Positional-Embedding.\nWe remove explicit position embeddings from HybridTransformer by omitting the pos_emb layer and its addition, leaving token encodings as the sum of shape + color embeddings only. Everything else (training loop, metrics, plotting, saving) remains identical, enabling a direct comparison with the baseline to assess how much SPR performance relies on positional information.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "The loss calculated on the training dataset during the final epoch.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.1701,
                "best_value": 0.1701
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "The lowest loss calculated on the validation dataset during training.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.1653,
                "best_value": 0.1653
              }
            ]
          },
          {
            "metric_name": "validation shape-weighted accuracy",
            "lower_is_better": false,
            "description": "The highest shape-weighted accuracy achieved on the validation dataset during training.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.9447,
                "best_value": 0.9447
              }
            ]
          },
          {
            "metric_name": "test loss",
            "lower_is_better": true,
            "description": "The loss calculated on the test dataset after training.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 1.263,
                "best_value": 1.263
              }
            ]
          },
          {
            "metric_name": "test shape-weighted accuracy",
            "lower_is_better": false,
            "description": "The shape-weighted accuracy calculated on the test dataset after training.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.65,
                "best_value": 0.65
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os, pathlib, math, time, itertools, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------- housekeeping & GPU ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# --------------- experiment log scaffold ------------\nexperiment_data = {\n    \"NoPositionalEmbedding\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"NoPositionalEmbedding\"][\"SPR_BENCH\"]\n\n\n# --------------- dataset helpers --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# --------------- load data --------------------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# --------------- vocabularies -----------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab = build_vocab(shape_chars)\ncolor_vocab = build_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# --------------- encoding utilities -----------------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# --------------- torch dataset ----------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# --------------- model ------------------------------\nclass HybridTransformerNoPos(nn.Module):\n    def __init__(self, s_vocab, c_vocab, num_labels, d_model=64, nhead=4, nlayers=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=128, dropout=0.1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n        self.feat_norm = nn.LayerNorm(3)\n        self.fc = nn.Linear(d_model + 3, num_labels)\n\n    def forward(self, shape_ids, color_ids, sym_feats):\n        x = self.shape_emb(shape_ids) + self.color_emb(\n            color_ids\n        )  # NO positional embedding\n        mask = shape_ids.eq(0)\n        h = self.encoder(x, src_key_padding_mask=mask)\n        pooled = h.masked_fill(mask.unsqueeze(-1), 0).sum(1) / (~mask).sum(\n            1, keepdim=True\n        ).clamp(min=1)\n        logits = self.fc(torch.cat([pooled, self.feat_norm(sym_feats)], dim=-1))\n        return logits\n\n\nmodel = HybridTransformerNoPos(len(shape_vocab), len(color_vocab), len(label_set)).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# --------------- evaluation -------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# --------------- training loop ----------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = math.inf, 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# --------------- final test -------------------------\nmodel.load_state_dict(best_state)\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# --------------- save artefacts ---------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA (No Pos Emb)\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nexp_key = \"NoPositionalEmbedding\"\ndset_key = \"SPR_BENCH\"\nrec = experiment_data.get(exp_key, {}).get(dset_key, {})\n\n\n# ---------- helper to close safely ----------\ndef safe_close():\n    if plt.get_fignums():\n        plt.close()\n\n\n# ---------- 1. Loss curve ----------\ntry:\n    train_loss = rec.get(\"losses\", {}).get(\"train\", [])\n    val_loss = rec.get(\"losses\", {}).get(\"val\", [])\n    if train_loss and val_loss:\n        plt.figure(figsize=(6, 4))\n        plt.plot(train_loss, label=\"Train Loss\")\n        plt.plot(val_loss, label=\"Val Loss\")\n        plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curve.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    safe_close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    safe_close()\n\n# ---------- 2. Validation SWA curve ----------\ntry:\n    val_swa = rec.get(\"SWA\", {}).get(\"val\", [])\n    if val_swa:\n        plt.figure(figsize=(6, 4))\n        plt.plot(val_swa, marker=\"o\")\n        plt.title(\"SPR_BENCH: Validation Shape-Weighted Accuracy\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SWA\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_swa_curve.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    safe_close()\nexcept Exception as e:\n    print(f\"Error creating SWA curve: {e}\")\n    safe_close()\n\n# ---------- 3. Confusion matrix ----------\ntry:\n    preds = rec.get(\"predictions\", [])\n    truths = rec.get(\"ground_truth\", [])\n    if preds and truths:\n        labels = sorted(set(truths + preds))\n        n_cls = len(labels)\n        conf = np.zeros((n_cls, n_cls), dtype=int)\n        idx = {l: i for i, l in enumerate(labels)}\n        for t, p in zip(truths, preds):\n            conf[idx[t], idx[p]] += 1\n        plt.figure(figsize=(6, 5))\n        im = plt.imshow(conf, cmap=\"Blues\")\n        plt.colorbar(im, fraction=0.046, pad=0.04)\n        plt.title(\"SPR_BENCH: Confusion Matrix\\nLeft: Ground Truth, Right: Predicted\")\n        plt.xlabel(\"Predicted Label\")\n        plt.ylabel(\"True Label\")\n        plt.xticks(range(n_cls), labels, rotation=90)\n        plt.yticks(range(n_cls), labels)\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    safe_close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    safe_close()\n",
    "plot_plan": "We first load experiment_data.npy from the working directory and probe its nested dictionaries to obtain arrays for training loss, validation loss, and validation SWA recorded across epochs, as well as the test-set predictions and ground-truth labels. Three independent plots are produced (each guarded by its own try/except): (1) a loss curve comparing train and validation losses per epoch; (2) a validation Shape-Weighted Accuracy (SWA) curve; (3) a confusion-matrix heat-map between ground-truth and predicted labels on the test set. Each figure has a clear title and axis labels, is saved to working_dir with descriptive names including the dataset (SPR_BENCH) and plot type, and the figure is always closed afterwards. The code opens at most these three plots, satisfying the five-figure limit. We limit data use strictly to what exists inside experiment_data.npy; no extra values are generated. Basic matplotlib is employed without custom style sheets, and every plot is wrapped in try/except to ensure robust execution even if some keys are missing. Finally, the script prints a short confirmation once all plots are saved.",
    "plot_analyses": [
      {
        "analysis": "This plot shows the validation Shape-Weighted Accuracy (SWA) over 7 epochs without the use of positional embeddings. The SWA improves significantly from epoch 0 to epoch 1, indicating that the model quickly learns to generalize to shape-related rules. After epoch 1, the SWA stabilizes with minor fluctuations, suggesting that the model has reached its performance plateau early in training.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/swa_curve.png"
      },
      {
        "analysis": "The training and validation loss curves for the SPR_BENCH dataset decrease steeply in the first few epochs, showing that the model is learning effectively. The gap between training and validation loss is minimal, indicating that the model generalizes well and is not overfitting. The convergence of both curves towards the end of training further supports this observation.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_loss_curve.png"
      },
      {
        "analysis": "This plot depicts the validation Shape-Weighted Accuracy (SWA) for the SPR_BENCH dataset across 7 epochs. The SWA increases rapidly between epochs 0 and 1, followed by a gradual improvement and stabilization. This trend indicates that the model quickly learns to generalize to shape-related rules and maintains consistent performance after initial training.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_swa_curve.png"
      },
      {
        "analysis": "The confusion matrix visualizes the model's performance on the test dataset. The high concentration of values along the diagonal indicates strong agreement between the predicted and true labels. However, there is some misclassification, as evidenced by the off-diagonal values. Further analysis could focus on the specific cases where the model struggles to differentiate between classes.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_confusion_matrix.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/swa_curve.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_loss_curve.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_swa_curve.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/SPR_BENCH_confusion_matrix.png"
    ],
    "vlm_feedback_summary": "The plots indicate that the model achieves rapid learning and generalization in terms of Shape-Weighted Accuracy (SWA). The training and validation loss curves confirm effective learning with minimal overfitting. The confusion matrix shows strong overall performance but highlights areas for improvement in misclassification handling.",
    "exp_results_dir": "experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537",
    "ablation_name": "No-Positional-Embedding",
    "exp_results_npy_files": [
      "experiment_results/experiment_f32622bc155c47da9ddf2fd2a24f5608_proc_2705537/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: No-Transformer (Bag-of-Embeddings).\nThe ablation replaces the Transformer encoder with a simple \u201cbag-of-embeddings\u201d reader that discards positional information. Shape and color token embeddings are summed, padded positions are ignored, and the mean vector across the sequence is concatenated with layer-normalised symbolic features before the final classifier. Training, evaluation, logging, early stopping and artefact saving all mirror the baseline so results are directly comparable.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "Measures the error during training. Lower values indicate better performance.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.539729,
                "best_value": 0.539729
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Measures the error during validation. Lower values indicate better performance.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.543899,
                "best_value": 0.543899
              }
            ]
          },
          {
            "metric_name": "validation SWA",
            "lower_is_better": false,
            "description": "Measures the Stochastic Weight Averaging performance on the validation set. Higher values indicate better performance.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.735903,
                "best_value": 0.735903
              }
            ]
          },
          {
            "metric_name": "test loss",
            "lower_is_better": true,
            "description": "Measures the error during testing. Lower values indicate better performance.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.685242,
                "best_value": 0.685242
              }
            ]
          },
          {
            "metric_name": "test SWA",
            "lower_is_better": false,
            "description": "Measures the Stochastic Weight Averaging performance on the test set. Higher values indicate better performance.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.58719,
                "best_value": 0.58719
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os, pathlib, math, time, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ---------------- housekeeping & GPU ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# --------------- experiment log scaffold ------------\nexperiment_data = {\n    \"BagOfEmbeddings\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": {}},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"SWA\": {\"val\": [], \"test\": None},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\nexp_rec = experiment_data[\"BagOfEmbeddings\"][\"SPR_BENCH\"]\n\n\n# --------------- dataset helpers --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / max(sum(weights), 1)\n\n\n# --------------- load data --------------------------\nDATA_PATH = pathlib.Path(\n    os.getenv(\"SPR_BENCH_PATH\", \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n)\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# --------------- vocabularies -----------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_char_vocab(char_iter):\n    vocab = {PAD: 0, UNK: 1}\n    for ch in sorted(set(char_iter)):\n        if ch not in vocab:\n            vocab[ch] = len(vocab)\n    return vocab\n\n\nshape_chars = (\n    tok[0]\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\ncolor_chars = (\n    tok[1] if len(tok) > 1 else \"_\"\n    for tok in itertools.chain.from_iterable(\n        seq.split() for seq in spr[\"train\"][\"sequence\"]\n    )\n)\nshape_vocab = build_char_vocab(shape_chars)\ncolor_vocab = build_char_vocab(color_chars)\nprint(f\"Shape vocab {len(shape_vocab)}, Color vocab {len(color_vocab)}\")\n\nlabel_set = sorted(set(spr[\"train\"][\"label\"]))\nlabel2idx = {l: i for i, l in enumerate(label_set)}\nidx2label = {i: l for l, i in label2idx.items()}\n\n\n# --------------- encoding utilities -----------------\ndef encode_seq(seq):\n    shape_ids = [shape_vocab.get(tok[0], shape_vocab[UNK]) for tok in seq.split()]\n    color_ids = [\n        color_vocab.get(tok[1] if len(tok) > 1 else \"_\", color_vocab[UNK])\n        for tok in seq.split()\n    ]\n    return shape_ids, color_ids\n\n\n# --------------- torch dataset ----------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = [label2idx[l] for l in hf_split[\"label\"]]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sids, cids = encode_seq(self.seqs[idx])\n        feats = torch.tensor(\n            [\n                count_shape_variety(self.seqs[idx]),\n                len(set(tok[1] for tok in self.seqs[idx].split() if len(tok) > 1)),\n                len(self.seqs[idx].split()),\n            ],\n            dtype=torch.float32,\n        )\n        return {\n            \"shape_ids\": torch.tensor(sids, dtype=torch.long),\n            \"color_ids\": torch.tensor(cids, dtype=torch.long),\n            \"sym_feats\": feats,\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    shp = [b[\"shape_ids\"] for b in batch]\n    col = [b[\"color_ids\"] for b in batch]\n    feats = torch.stack([b[\"sym_feats\"] for b in batch])\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    shp_pad = nn.utils.rnn.pad_sequence(\n        shp, batch_first=True, padding_value=shape_vocab[PAD]\n    )\n    col_pad = nn.utils.rnn.pad_sequence(\n        col, batch_first=True, padding_value=color_vocab[PAD]\n    )\n    return {\n        \"shape_ids\": shp_pad,\n        \"color_ids\": col_pad,\n        \"sym_feats\": feats,\n        \"labels\": labels,\n        \"raw_seq\": raw,\n    }\n\n\ntrain_ds, dev_ds, test_ds = (\n    SPRTorchDataset(spr[\"train\"]),\n    SPRTorchDataset(spr[\"dev\"]),\n    SPRTorchDataset(spr[\"test\"]),\n)\ntrain_loader = DataLoader(train_ds, 128, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, 256, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, 256, shuffle=False, collate_fn=collate)\n\n\n# --------------- Bag-of-Embeddings model ------------\nclass BagOfEmbeddings(nn.Module):\n    def __init__(self, s_vocab, c_vocab, num_labels, d_model=64):\n        super().__init__()\n        self.shape_emb = nn.Embedding(s_vocab, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(c_vocab, d_model, padding_idx=0)\n        self.feat_norm = nn.LayerNorm(3)\n        self.fc = nn.Sequential(nn.Linear(d_model + 3, num_labels))\n\n    def forward(self, shape_ids, color_ids, sym_feats):\n        emb = self.shape_emb(shape_ids) + self.color_emb(color_ids)\n        mask = shape_ids.eq(0)\n        emb = emb.masked_fill(mask.unsqueeze(-1), 0)\n        denom = (~mask).sum(dim=1, keepdim=True).clamp(min=1)\n        pooled = emb.sum(dim=1) / denom\n        sym_norm = self.feat_norm(sym_feats)\n        logits = self.fc(torch.cat([pooled, sym_norm], dim=-1))\n        return logits\n\n\nmodel = BagOfEmbeddings(len(shape_vocab), len(color_vocab), len(label_set)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# --------------- evaluation -------------------------\ndef evaluate(loader):\n    model.eval()\n    tot_loss, total = 0.0, 0\n    all_seq, y_true, y_pred = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            logits = model(\n                batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"]\n            )\n            loss = criterion(logits, batch_t[\"labels\"])\n            pred = logits.argmax(-1)\n            bs = batch_t[\"labels\"].size(0)\n            tot_loss += loss.item() * bs\n            total += bs\n            all_seq.extend(batch[\"raw_seq\"])\n            y_true.extend(batch_t[\"labels\"].cpu().tolist())\n            y_pred.extend(pred.cpu().tolist())\n    return (\n        tot_loss / total,\n        shape_weighted_accuracy(all_seq, y_true, y_pred),\n        y_pred,\n        y_true,\n        all_seq,\n    )\n\n\n# --------------- training loop ----------------------\nMAX_EPOCHS, PATIENCE = 20, 3\nbest_val_loss, no_imp = math.inf, 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    model.train()\n    running = 0.0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch_t[\"shape_ids\"], batch_t[\"color_ids\"], batch_t[\"sym_feats\"])\n        loss = criterion(logits, batch_t[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch_t[\"labels\"].size(0)\n    train_loss = running / len(train_ds)\n\n    val_loss, val_swa, *_ = evaluate(dev_loader)\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  SWA={val_swa:.3f}\"\n    )\n\n    exp_rec[\"losses\"][\"train\"].append(train_loss)\n    exp_rec[\"losses\"][\"val\"].append(val_loss)\n    exp_rec[\"SWA\"][\"val\"].append(val_swa)\n    exp_rec[\"timestamps\"].append(time.time())\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        no_imp = 0\n    else:\n        no_imp += 1\n        if no_imp >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\n# load best\nmodel.load_state_dict(best_state)\n\n# --------------- final test -------------------------\ntest_loss, test_swa, preds, trues, seqs = evaluate(test_loader)\nprint(f\"\\nTEST: loss={test_loss:.4f}  SWA={test_swa:.3f}\")\nexp_rec[\"SWA\"][\"test\"] = test_swa\nexp_rec[\"metrics\"][\"test\"] = {\"loss\": test_loss, \"SWA\": test_swa}\nexp_rec[\"predictions\"], exp_rec[\"ground_truth\"] = preds, trues\n\n# --------------- save artefacts ---------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n\nplt.figure(figsize=(6, 4))\nplt.plot(exp_rec[\"SWA\"][\"val\"], label=\"Val SWA\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SWA\")\nplt.title(\"Validation SWA (Bag-of-Embeddings)\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"swa_curve.png\"))\nprint(\"Saved plot to working/swa_curve.png\")\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------- setup --------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- load data ------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    rec = experiment_data[\"BagOfEmbeddings\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    rec = None\n\nif rec:\n    epochs = np.arange(1, len(rec[\"losses\"][\"train\"]) + 1)\n\n    # --------------- loss curves --------------------\n    try:\n        plt.figure(figsize=(6, 4))\n        plt.plot(epochs, rec[\"losses\"][\"train\"], label=\"Train Loss\")\n        plt.plot(epochs, rec[\"losses\"][\"val\"], label=\"Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"Loss Curves \u2014 SPR_BENCH (Bag-of-Embeddings)\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # --------------- SWA curve ----------------------\n    try:\n        plt.figure(figsize=(6, 4))\n        plt.plot(epochs, rec[\"SWA\"][\"val\"], label=\"Validation SWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Shape-Weighted Accuracy\")\n        plt.title(\"Validation SWA \u2014 SPR_BENCH (Bag-of-Embeddings)\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_swa_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA curve: {e}\")\n        plt.close()\n\n    # --------------- confusion matrix ---------------\n    try:\n        preds, trues = np.array(rec[\"predictions\"]), np.array(rec[\"ground_truth\"])\n        if preds.size and trues.size:\n            num_labels = int(max(preds.max(), trues.max()) + 1)\n            cm = np.zeros((num_labels, num_labels), dtype=int)\n            for t, p in zip(trues, preds):\n                cm[t, p] += 1\n            plt.figure(figsize=(6, 5))\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im, fraction=0.046, pad=0.04)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(\"Confusion Matrix \u2014 SPR_BENCH Test Set\")\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\n    # --------------- print metrics ------------------\n    print(\"Test metrics:\", rec.get(\"metrics\", {}).get(\"test\", {}))\n",
    "plot_plan": "The script loads the stored experiment_data.npy, extracts the BagOfEmbeddings results for the SPR_BENCH dataset, and then produces up to three standard visualisations. It first plots the training and validation loss curves across epochs, then the validation shape-weighted accuracy curve, and finally a confusion-matrix heat-map computed from the saved test predictions versus ground-truth labels. Each figure is created in its own try-except block, saved with a descriptive name to working_dir, and explicitly closed to avoid resource leaks. The code also prints the recorded test metrics (loss and SWA) so they appear in the execution log. Only data present in the numpy file are used\u2014no synthetic values are introduced. The whole routine respects the figure limit and uses only basic matplotlib functionalities.",
    "plot_analyses": [
      {
        "analysis": "This plot shows the validation Shape-Weighted Accuracy (SWA) across epochs for a Bag-of-Embeddings model. The SWA starts at around 0.7, peaks at 0.735 in the second epoch, and then drops significantly in the third epoch. It fluctuates moderately in subsequent epochs, with a final sharp increase to 0.735. These fluctuations suggest potential overfitting or instability in the model's learning process, indicating a need for further regularization or hyperparameter tuning.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/swa_curve.png"
      },
      {
        "analysis": "The loss curves depict the training and validation cross-entropy loss over epochs. Both losses decrease steadily in the first few epochs, with the training loss reducing more sharply. Afterward, the training loss continues to decline, while the validation loss plateaus around epoch 6. This divergence between training and validation loss suggests slight overfitting of the model to the training data, indicating that early stopping or stronger regularization might be beneficial.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_loss_curves.png"
      },
      {
        "analysis": "This plot again illustrates the validation Shape-Weighted Accuracy (SWA) over epochs for the Bag-of-Embeddings model. The trends are consistent with the earlier SWA plot, showing an initial increase, a sharp drop, and subsequent fluctuations. The final sharp increase to 0.735 suggests that the model retains some generalization ability, but the irregular trend highlights instability, possibly due to hyperparameter settings or insufficient training data.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_swa_curve.png"
      },
      {
        "analysis": "The confusion matrix for the SPR_BENCH test set shows the distribution of true versus predicted labels. The darker diagonal regions indicate correct predictions, while off-diagonal regions represent errors. The matrix suggests that the model achieves reasonable accuracy but struggles with certain classes, as evidenced by the lighter off-diagonal regions. This imbalance may be due to class distribution or model bias, warranting further investigation into class-specific performance.",
        "plot_path": "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_confusion_matrix.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/swa_curve.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_loss_curves.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_swa_curve.png",
      "experiments/2025-08-14_17-37-20_neural_symbolic_zero_shot_spr_attempt_0/logs/0-run/experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/SPR_BENCH_confusion_matrix.png"
    ],
    "vlm_feedback_summary": "The plots reveal that the Bag-of-Embeddings model exhibits instability in SWA trends, with fluctuations and potential overfitting. The loss curves show a divergence between training and validation loss, indicating overfitting. The confusion matrix highlights reasonable accuracy but also reveals class-specific performance issues. These findings suggest a need for regularization, hyperparameter tuning, and a closer examination of class distributions to improve model performance.",
    "exp_results_dir": "experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534",
    "ablation_name": "No-Transformer (Bag-of-Embeddings)",
    "exp_results_npy_files": [
      "experiment_results/experiment_81bc56ad91344cd093b471adc55aa4a1_proc_2705534/experiment_data.npy"
    ]
  }
]