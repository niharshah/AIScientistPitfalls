\documentclass{article} % For LaTeX2e
\usepackage{iclr2025,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% Custom
\usepackage{multirow}
\usepackage{color}
\usepackage{colortbl}
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{xspace}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\graphicspath{{../figures/}} % Do not remove or figures won't be found.

\begin{filecontents}{references.bib}
@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  year={2016},
  publisher={MIT Press}
}

@article{wagner2021neuralsymbolicif,
 author = {Benedikt Wagner and A. Garcez},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Neural-Symbolic Integration for Interactive Learning and Conceptual Grounding},
 volume = {abs/2112.11805},
 year = {2021}
}

@article{bortolotti2024anb,
 author = {Samuele Bortolotti and Emanuele Marconato and Tommaso Carraro and Paolo Morettin and Emile van Krieken and Antonio Vergari and Stefano Teso and Andrea Passerini},
 booktitle = {Neural Information Processing Systems},
 title = {A Neuro-Symbolic Benchmark Suite for Concept Quality and Reasoning Shortcuts},
 year = {2024}
}

@article{kodnongbua2024zeroshotsn,
 author = {Milin Kodnongbua and Lawrence H. Curtis and Adriana Schulz},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Zero-shot Sequential Neuro-symbolic Reasoning for Automatically Generating Architecture Schematic Designs},
 volume = {abs/2402.00052},
 year = {2024}
}

@article{hu2023codepa,
 author = {Y. Hu and Haotong Yang and Zhouchen Lin and Muhan Zhang},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large Language Models},
 volume = {abs/2305.18507},
 year = {2023}
}

@article{sir2024acp,
 author = {Gustav Šír},
 booktitle = {Neurosymbolic Artificial Intelligence},
 journal = {Neurosymbolic Artificial Intelligence},
 title = {A computational perspective on neural-symbolic integration},
 year = {2024}
}

@article{thakur2021beirah,
 author = {Nandan Thakur and Nils Reimers and Andreas Ruckl'e and Abhishek Srivastava and Iryna Gurevych},
 booktitle = {NeurIPS Datasets and Benchmarks},
 journal = {ArXiv},
 title = {BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models},
 volume = {abs/2104.08663},
 year = {2021}
}

@article{burghouts2024openworldvr,
 author = {G. Burghouts and Fieke Hillerstr\"om and Erwin Walraven and M. V. Bekkum and Frank Ruis and J. Sijs and Jelle van Mil and Judith Dijk},
 booktitle = {International Conferences on Pattern Recognition and Artificial Intelligence},
 pages = {62-75},
 title = {Open-World Visual Reasoning by a Neuro-Symbolic Program of Zero-Shot Symbols},
 year = {2024}
}
\end{filecontents}

\title{Zero-Shot Synthetic PolyRule Reasoning with Neural Symbolic Integration}

\author{Anonymous}

\begin{document}

\maketitle

\begin{abstract}
We propose a novel method for integrating neural networks with symbolic reasoning frameworks to enable zero-shot learning in Synthetic PolyRule Reasoning (SPR). Our approach leverages a neural-symbolic model that generalizes to previously unseen rules without additional training. We focus on evaluating performance on the SPR\_BENCH dataset, selectively measuring either Shape-Weighted Accuracy or Color-Weighted Accuracy in unseen scenarios. This method highlights key challenges in designing neuro-symbolic systems that can adapt to new rule sets without retraining, thus offering valuable insights for robust real-world reasoning pipelines.
\end{abstract}

\section{Introduction}\label{sec:intro}
Neural-symbolic integration aims to unify high-capacity learning models with explicit reasoning frameworks, potentially offering improved generalization in real-world scenarios~\citep{wagner2021neuralsymbolicif,hu2023codepa}. One particularly challenging setting is zero-shot reasoning, where models are expected to handle novel tasks or rules without further training~\citep{kodnongbua2024zeroshotsn}. In many domains, such as complex control systems or automated interpretation of abstract rules, updated models are difficult to deploy due to costly retraining or data deficiency.

We investigate Synthetic PolyRule Reasoning (SPR) tasks, which involve applying symbolic rules to sequences of shapes and colors. While neural models can recognize patterns, they typically fail to extrapolate to new rules without explicit training examples. We present a neural-symbolic method designed to address this pitfall. Our main contributions are: 
(1) an architecture combining neural feature extraction with rule-based symbolic inference, (2) an experimental study of zero-shot generalization on the SPR\_BENCH dataset, and (3) a flexible approach to measuring performance using either shape-based or color-based accuracy metrics. Despite promising preliminary results, we also describe potential limitations, including computational overheads and partial failures in adapting to complex rule variations.

\section{Related Work}\label{sec:related}
Zero-shot generalization has been explored in various contexts, including image-text retrieval benchmarks~\citep{thakur2021beirah} and open-world visual reasoning~\citep{burghouts2024openworldvr}. Earlier neuro-symbolic frameworks focus on concept quality and the mitigation of reasoning shortcuts~\citep{bortolotti2024anb}. However, many rely on domain-specific assumptions or require partial fine-tuning. In contrast, our work emphasizes a fully zero-shot approach to newly introduced rules, drawing from computational insights on combining symbolic logic and neural embeddings~\citep{sir2024acp}.

\section{Background}\label{sec:background}
Synthetic PolyRule Reasoning introduces sequences of tokens, each identifiable by shape and color. The classification target may be determined by shifting, merging, or otherwise transforming symbolic relationships embedded in the sequences. Although conventional neural architectures can memorize training patterns, they often struggle to apply newly invented symbolic rules at test time. This challenge motivates a hybrid solution involving symbolic engines for rule inference and neural networks for flexible feature extraction.

\section{Method}\label{sec:method}
We propose a model composed of a neural encoder and a symbolic inference module. The encoder (e.g., a feed-forward network or transformer) processes each token to produce dense representations. A symbolic layer then uses these representations to apply or infer rules, producing outputs without additional retraining when confronted with novel rule sets.

During training, we expose the system to a subset of SPR\_BENCH containing known rules. We optimize a joint loss on standard classification. At test time, the symbolic component is reconfigured to handle new rule definitions, and the neural component remains unchanged. If the symbolic rules are well-structured, the model can apply them in zero-shot mode.

\section{Experimental Setup}\label{sec:experimental_setup}
We use the provided Python code to load the SPR\_BENCH dataset, which includes \texttt{train}, \texttt{dev}, and \texttt{test}. Within the sequences, we examine shape or color variety as potential weighting for accuracy calculations. We measure performance using either shape-weighted or color-weighted accuracy, but never both in the same run. This restriction tests the system's ability to generalize under different rule emphasis. We also explore ablations by removing the symbolic component or the neural component to observe each module's effect on overall performance.

\section{Experiments}\label{sec:experiments}
Our main evaluation focuses on zero-shot generalization. After training on partial SPR\_BENCH rules, we measure performance on unseen rule classes in the test set. Early trials suggest that purely neural models fail to interpret novel class definitions accurately, while purely symbolic systems cannot learn initial features effectively. The hybrid approach finds partial success, although certain rule types (e.g., highly compositional or contradictory) remain challenging.

To illustrate our findings, \cref{fig:first_figure} shows a placeholder example: each bar represents performance on different rule sets. The neural-symbolic approach typically outperforms a pure neural baseline. However, we observed occasional drops in accuracy when the symbolic module's assumptions did not align with the newly introduced rules. These inconclusive or negative results underscore the need for improved rule representation strategies.

\begin{figure}[t]
\centering
\includegraphics[width=0.5\textwidth]{example-image-a}
\caption{Sample performance comparison on a subset of SPR\_BENCH unseen rules.}
\label{fig:first_figure}
\end{figure}

\section{Conclusion}\label{sec:conclusion}
We explored a neural-symbolic integration framework for zero-shot Synthetic PolyRule Reasoning. Our experiments reveal the model's partial success in extending learned representations to unseen rules, while also highlighting computational and representational pitfalls. Future work includes improving symbolic rule definitions to capture complex interactions and reducing the overhead of reconfiguring symbolic modules at inference time. These insights can guide more robust approaches to generalizing across novel symbolic tasks without retraining.

\bibliography{iclr2025}
\bibliographystyle{iclr2025}

\appendix

\section*{\LARGE Supplementary Material}
\label{sec:appendix}

\section{Additional Details}
We provide further implementation details in the supplementary code. Hyperparameters, including hidden-layer sizes and training epochs, are documented here. Developers are encouraged to consult the inline annotations in \texttt{SPR.py} for clarity on data loading.