<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 1], [0, 5], [0, 8], [0, 2], [0, 6], [0, 4], [0, 7], [0, 3], [6, 10], [6, 9], [6, 11], [6, 12]], "layout": [[0.5, 0.0], [0.0, 0.5], [0.14285714285714285, 0.5], [0.2857142857142857, 0.5], [0.42857142857142855, 0.5], [0.5714285714285714, 0.5], [0.7142857142857143, 0.5], [0.8571428571428571, 0.5], [1.0, 0.5], [0.5, 1.0], [0.6428571428571429, 1.0], [0.7857142857142857, 1.0], [0.9285714285714286, 1.0]], "plan": ["We load SPR_BENCH with the provided helper, treat every two-character glyph\n(\u201cshape\u201d letter + \u201ccolor\u201d digit) as a point in a 2-D categorical space (shape-\nidx , color-idx).  Unsupervised K-Means (k = 8) on these 2-D points yields\nlatent \u201cglyph clusters\u201d.  Each sequence is then represented by the histogram of\nits glyph-cluster memberships, giving a fixed-length k-dimensional vector.  A\ntiny feed-forward PyTorch network (cluster-histogram \u2192 32 ReLU \u2192 1) is trained\nto predict the sequence label.  During training we track validation loss and\nComplexity-Weighted Accuracy (CompWA), and at the end we also report Color-\nWeighted Accuracy (CWA) and Shape-Weighted Accuracy (SWA) on the dev set.  All\nmetrics, losses, predictions and ground-truth are stored under\n./working/experiment_data.npy.  The whole pipeline\u2014data loading, clustering,\nvectorisation, model training, evaluation and saving\u2014runs in a single file below\nand respects the GPU/CPU rules.", "Hyperparam tuning name: num_epochs. We sweep over several candidate training-\ndurations (5, 10 \u2026 50 epochs), re-initialising the model for every run.   Each\nrun logs per-epoch train/val losses and CompWA, applies simple early-stopping\n(patience = 5) to avoid wasting computation, and finally stores the best epoch\u2019s\npredictions and ground-truths.   All results are gathered in a single\n`experiment_data` dictionary under the key `\"num_epochs\"`, then saved to\n`experiment_data.npy`.   Apart from the outer hyper-parameter loop the inner\ntraining/validation code is identical to the baseline, guaranteeing functional\nequivalence while enabling longer training.", "Hyperparam tuning name: learning_rate. We loop over the candidate learning rates\n(5e-4, 1e-3, 3e-3); for each value we re-instantiate the model and optimizer,\ntrain for five epochs, evaluate on the dev split, and store per-epoch losses\nplus the final CompWA together with predictions/ground-truth in a nested\nexperiment_data structure keyed by the tuning type \u201clearning_rate\u201d. Finally, the\naggregated dictionary is saved to working/experiment_data.npy so it can be\nplotted later.", "Hyperparam tuning name: batch_size. The solution trains identical models\nmultiple times while varying the DataLoader mini-batch size (128, 256, 512,\n1024).   For every batch size we:   1. build a fresh model, optimizer and data\nloaders,   2. train for a few epochs, validating after each epoch,   3. record\nepoch-wise train/validation losses and Complexity-Weighted Accuracy, together\nwith the final predictions and ground-truth.   All results are stored in a\nsingle dictionary compliant with the required naming convention and saved to\n\u201cexperiment_data.npy\u201d.", "Hyperparam tuning name: hidden_dim (size of the hidden layer). Below is an\noutline of the solution followed by the complete self-contained script.\nOutline: we keep all original functionality, but wrap training/evaluation in a\nloop that sweeps hidden layer sizes (16 \u2192 256).  For every hidden_dim we train\nthe same 5-epoch SimpleFF network, log losses plus complexity-weighted accuracy\nfor train/validation, store final predictions/ground-truth, and save everything\ninto the required experiment_data structure under key \"hidden_dim_sweep\".  At\nthe end we dump experiment_data to working/experiment_data.npy.", "Hyperparam tuning name: weight_decay. We train separate models with identical\nsettings except for the Adam weight_decay coefficient taken from [0, 1e-5, 1e-4,\n1e-3, 1e-2].   For each coefficient we (1) build a fresh model/optimizer, (2)\ntrain for five epochs, (3) record train/validation losses and complexity-\nweighted accuracy, and (4) store predictions plus ground-truth.   Results for\nevery sweep value are saved under experiment_data[\"weight_decay\"][\"wd_<value>\"]\nand the whole dictionary is written to working/experiment_data.npy so it can be\nplotted later.", "Hyperparam tuning name: num_clusters_k. We loop over k \u2208 {4, 8, 16, 32}, refit\nK-Means each time, rebuild histogram features of the sequences, train a fresh\nfeed-forward network for 5 epochs, and log losses plus weighted accuracies. All\nresults (indexed by k) are collected in\nexperiment_data['num_clusters_k']['SPR_BENCH'] and finally saved to\nexperiment_data.npy.", "Hyperparam tuning name: pos_weight. We loop over candidate pos_weight values {1,\n2, 4, 8}. For every value we re-initialise the model, create\nBCEWithLogitsLoss(pos_weight=\u2026), train for five epochs, evaluate on the dev\nsplit and store per-epoch losses plus final weighted accuracies (CompWA, CWA,\nSWA) together with predictions/ground-truth in experiment_data under\nexperiment_data['pos_weight'][f'SPR_BENCH_pw{w}']. Finally, the whole dictionary\nis saved to experiment_data.npy.", "Hyperparam tuning name: dropout_prob. We extend SimpleFF by inserting an\nnn.Dropout layer after the hidden ReLU activation and sweep over four\nprobabilities (0 \u2192 0.1 \u2192 0.3 \u2192 0.5).   For every dropout setting we repeat the\noriginal 5-epoch training/validation routine, record losses plus CompWA, and\nfinally store predictions together with CWA/SWA for inspection.   Results for\neach probability are kept in experiment_data under keys \u201cdropout_prob_0.0\u201d,\n\u201cdropout_prob_0.1\u201d, \u2026, then persisted as experiment_data.npy.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import DatasetDict\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n\n# ---------------- Utility identical to snippet -----------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    from datasets import load_dataset\n\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ----------------------------- Data ----------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\n\n# extract glyph tokens\ntrain_sequences = spr[\"train\"][\"sequence\"]\ndev_sequences = spr[\"dev\"][\"sequence\"]\ntest_sequences = spr[\"test\"][\"sequence\"]  # unused baseline\n\n\ndef get_tokens(seqs):\n    tokens = []\n    for s in seqs:\n        tokens.extend(s.strip().split())\n    return tokens\n\n\nall_tokens = get_tokens(train_sequences)\nshapes = [t[0] for t in all_tokens]\ncolors = [t[1] for t in all_tokens]\nshape_le = LabelEncoder().fit(shapes)\ncolor_le = LabelEncoder().fit(colors)\n\ntoken_vectors = np.stack(\n    [shape_le.transform(shapes), color_le.transform(colors)], axis=1\n)\n\n# -------------------------- Clustering -------------------------------\nk = 8\nkmeans = KMeans(n_clusters=k, random_state=0, n_init=10)\nkmeans.fit(token_vectors)\n\n\ndef sequence_to_histogram(seq):\n    vec = np.zeros(k, dtype=np.float32)\n    for tok in seq.strip().split():\n        if len(tok) < 2:\n            continue\n        s_id = shape_le.transform([tok[0]])[0]\n        c_id = color_le.transform([tok[1]])[0]\n        label = kmeans.predict([[s_id, c_id]])[0]\n        vec[label] += 1.0\n    return vec\n\n\nX_train = np.stack([sequence_to_histogram(s) for s in train_sequences])\nX_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences])\n\ny_train = np.array(spr[\"train\"][\"label\"], dtype=np.float32)\ny_dev = np.array(spr[\"dev\"][\"label\"], dtype=np.float32)\n\n# -------------------------- Torch Model ------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\nclass SimpleFF(nn.Module):\n    def __init__(self, in_dim):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, 1))\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\n\nmodel = SimpleFF(k).to(device)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\nbatch_size = 512\ntrain_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ndev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\n\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=batch_size)\n\n# ----------------------------- Train ---------------------------------\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running_loss = 0.0\n    for xb, yb in train_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        out = model(xb)\n        loss = criterion(out, yb)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * xb.size(0)\n    train_loss = running_loss / len(train_loader.dataset)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n\n    # ---- validation ----\n    model.eval()\n    val_loss, preds, truths, seqs_collected = 0.0, [], [], []\n    with torch.no_grad():\n        for xb, yb in dev_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            out = model(xb)\n            loss = criterion(out, yb)\n            val_loss += loss.item() * xb.size(0)\n            preds.extend((torch.sigmoid(out) > 0.5).cpu().numpy().astype(int).tolist())\n            truths.extend(yb.cpu().numpy().astype(int).tolist())\n    val_loss /= len(dev_loader.dataset)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n\n    comp_wa = complexity_weighted_accuracy(dev_sequences, truths, preds)\n    train_comp_wa = 0.0  # quick estimate on last batch optional\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_CompWA\"].append(comp_wa)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train_CompWA\"].append(None)\n\n    print(\n        f\"Epoch {epoch}: validation_loss = {val_loss:.4f}, val_CompWA = {comp_wa:.4f}\"\n    )\n\n# ------------------ Final additional metrics -------------------------\ncwa = color_weighted_accuracy(dev_sequences, y_dev, preds)\nswa = shape_weighted_accuracy(dev_sequences, y_dev, preds)\nprint(f\"Dev CWA: {cwa:.4f}, Dev SWA: {swa:.4f}\")\n\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = truths\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import DatasetDict, load_dataset\n\n# ------------- where to save everything ------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------ Experiment dict -----\nexperiment_data = {\n    \"num_epochs\": {  # hyper-parameter being tuned\n        \"SPR_BENCH\": {\n            \"config_values\": [],  # list of epochs tried\n            \"losses\": {\"train\": [], \"val\": []},  # list-of-lists\n            \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n            \"predictions\": [],  # list of arrays\n            \"ground_truth\": [],  # list of arrays\n        }\n    }\n}\n\n\n# ---------------- Utility functions (unchanged) ----------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ----------------------------- Data ----------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\n\ntrain_sequences = spr[\"train\"][\"sequence\"]\ndev_sequences = spr[\"dev\"][\"sequence\"]\n\n\n# tokenise\ndef get_tokens(seqs):\n    toks = []\n    for s in seqs:\n        toks.extend(s.strip().split())\n    return toks\n\n\nall_tokens = get_tokens(train_sequences)\nshapes = [t[0] for t in all_tokens]\ncolors = [t[1] for t in all_tokens]\nshape_le = LabelEncoder().fit(shapes)\ncolor_le = LabelEncoder().fit(colors)\ntoken_vectors = np.stack(\n    [shape_le.transform(shapes), color_le.transform(colors)], axis=1\n)\n\n# clustering\nk = 8\nkmeans = KMeans(n_clusters=k, random_state=0, n_init=10).fit(token_vectors)\n\n\ndef sequence_to_histogram(seq):\n    vec = np.zeros(k, dtype=np.float32)\n    for tok in seq.strip().split():\n        if len(tok) < 2:\n            continue\n        sid = shape_le.transform([tok[0]])[0]\n        cid = color_le.transform([tok[1]])[0]\n        label = kmeans.predict([[sid, cid]])[0]\n        vec[label] += 1.0\n    return vec\n\n\nX_train = np.stack([sequence_to_histogram(s) for s in train_sequences])\nX_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences])\ny_train = np.array(spr[\"train\"][\"label\"], dtype=np.float32)\ny_dev = np.array(spr[\"dev\"][\"label\"], dtype=np.float32)\n\ntrain_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ndev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------- Model definition -----------------------------\nclass SimpleFF(nn.Module):\n    def __init__(self, in_dim):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, 1))\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\n\n# ---------------- Hyper-parameter sweep ------------------------------\nepoch_options = [5, 10, 20, 30, 40, 50]\nbatch_size = 512\npatience = 5  # early stopping\nfor max_epochs in epoch_options:\n    print(f\"\\n=== Training with max_epochs = {max_epochs} ===\")\n    experiment_data[\"num_epochs\"][\"SPR_BENCH\"][\"config_values\"].append(max_epochs)\n\n    model = SimpleFF(k).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.BCEWithLogitsLoss()\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    dev_loader = DataLoader(dev_ds, batch_size=batch_size)\n\n    best_val_loss = float(\"inf\")\n    best_pred, best_truth = None, None\n    best_train_losses, best_val_losses = [], []\n    best_train_cwa, best_val_cwa = [], []\n    epochs_without_improve = 0\n\n    per_epoch_train_loss, per_epoch_val_loss = [], []\n    per_epoch_train_compwa, per_epoch_val_compwa = [], []\n\n    for epoch in range(1, max_epochs + 1):\n        # --- train ---\n        model.train()\n        running_loss = 0.0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            out = model(xb)\n            loss = criterion(out, yb)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * xb.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n\n        # --- validation ---\n        model.eval()\n        val_loss, preds, truths = 0.0, [], []\n        with torch.no_grad():\n            for xb, yb in dev_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                out = model(xb)\n                loss = criterion(out, yb)\n                val_loss += loss.item() * xb.size(0)\n                preds.extend((torch.sigmoid(out) > 0.5).cpu().numpy().astype(int))\n                truths.extend(yb.cpu().numpy().astype(int))\n        val_loss /= len(dev_loader.dataset)\n\n        comp_wa = complexity_weighted_accuracy(dev_sequences, truths, preds)\n        per_epoch_train_loss.append(train_loss)\n        per_epoch_val_loss.append(val_loss)\n        per_epoch_val_compwa.append(comp_wa)\n        per_epoch_train_compwa.append(None)  # not evaluated\n\n        print(\n            f\"Epoch {epoch}/{max_epochs}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, val_CompWA={comp_wa:.4f}\"\n        )\n\n        # early stopping check\n        if val_loss < best_val_loss - 1e-4:\n            best_val_loss = val_loss\n            best_pred, best_truth = preds.copy(), truths.copy()\n            best_train_losses = per_epoch_train_loss.copy()\n            best_val_losses = per_epoch_val_loss.copy()\n            best_train_cwa = per_epoch_train_compwa.copy()\n            best_val_cwa = per_epoch_val_compwa.copy()\n            epochs_without_improve = 0\n        else:\n            epochs_without_improve += 1\n            if epochs_without_improve >= patience:\n                print(f\"Early stopping at epoch {epoch}\")\n                break\n\n    # ------------- record best run -----------------------------------\n    experiment_data[\"num_epochs\"][\"SPR_BENCH\"][\"losses\"][\"train\"].append(\n        best_train_losses\n    )\n    experiment_data[\"num_epochs\"][\"SPR_BENCH\"][\"losses\"][\"val\"].append(best_val_losses)\n    experiment_data[\"num_epochs\"][\"SPR_BENCH\"][\"metrics\"][\"train_CompWA\"].append(\n        best_train_cwa\n    )\n    experiment_data[\"num_epochs\"][\"SPR_BENCH\"][\"metrics\"][\"val_CompWA\"].append(\n        best_val_cwa\n    )\n    experiment_data[\"num_epochs\"][\"SPR_BENCH\"][\"predictions\"].append(best_pred)\n    experiment_data[\"num_epochs\"][\"SPR_BENCH\"][\"ground_truth\"].append(best_truth)\n\n    # optional auxiliary metrics\n    cwa = color_weighted_accuracy(dev_sequences, best_truth, best_pred)\n    swa = shape_weighted_accuracy(dev_sequences, best_truth, best_pred)\n    print(f\"Final Dev CWA: {cwa:.4f}, Dev SWA: {swa:.4f}\")\n\n# ---------------------- persist everything ---------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import DatasetDict\n\n# ------------------ experiment bookkeeping ---------------------------\nexperiment_data = {\n    \"learning_rate\": {\n        \"SPR_BENCH\": {\n            \"lrs\": [],\n            \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# ---------------- Utility identical to snippet -----------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    from datasets import load_dataset\n\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ----------------------------- Data ----------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\n\ntrain_sequences, dev_sequences = spr[\"train\"][\"sequence\"], spr[\"dev\"][\"sequence\"]\n\n\ndef get_tokens(seqs):\n    tk = []\n    for s in seqs:\n        tk.extend(s.strip().split())\n    return tk\n\n\nall_tokens = get_tokens(train_sequences)\nshapes, colors = [t[0] for t in all_tokens], [t[1] for t in all_tokens]\nshape_le, color_le = LabelEncoder().fit(shapes), LabelEncoder().fit(colors)\ntoken_vectors = np.stack([shape_le.transform(shapes), color_le.transform(colors)], 1)\n\nk = 8\nkmeans = KMeans(n_clusters=k, random_state=0, n_init=10).fit(token_vectors)\n\n\ndef sequence_to_histogram(seq):\n    vec = np.zeros(k, dtype=np.float32)\n    for tok in seq.strip().split():\n        if len(tok) < 2:\n            continue\n        s_id, c_id = shape_le.transform([tok[0]])[0], color_le.transform([tok[1]])[0]\n        label = kmeans.predict([[s_id, c_id]])[0]\n        vec[label] += 1.0\n    return vec\n\n\nX_train = np.stack([sequence_to_histogram(s) for s in train_sequences])\nX_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences])\ny_train = np.array(spr[\"train\"][\"label\"], dtype=np.float32)\ny_dev = np.array(spr[\"dev\"][\"label\"], dtype=np.float32)\n\n# -------------------------- Torch setup ------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\nclass SimpleFF(nn.Module):\n    def __init__(self, in_dim):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, 1))\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\n\nbatch_size, epochs = 512, 5\ntrain_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ndev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=batch_size)\n\nlr_grid = [5e-4, 1e-3, 3e-3]\n\nfor lr in lr_grid:\n    print(f\"\\n---- Training with learning_rate = {lr} ----\")\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"lrs\"].append(lr)\n\n    model = SimpleFF(k).to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    run_train_losses, run_val_losses = [], []\n    run_train_cwa, run_val_cwa = [], []\n\n    for epoch in range(1, epochs + 1):\n        # training\n        model.train()\n        total_loss = 0.0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            loss = criterion(model(xb), yb)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * xb.size(0)\n        train_loss = total_loss / len(train_loader.dataset)\n        run_train_losses.append(train_loss)\n\n        # validation\n        model.eval()\n        v_loss, preds, truths = 0.0, [], []\n        with torch.no_grad():\n            for xb, yb in dev_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                out = model(xb)\n                loss = criterion(out, yb)\n                v_loss += loss.item() * xb.size(0)\n                preds.extend(\n                    (torch.sigmoid(out) > 0.5).cpu().numpy().astype(int).tolist()\n                )\n                truths.extend(yb.cpu().numpy().astype(int).tolist())\n        v_loss /= len(dev_loader.dataset)\n        run_val_losses.append(v_loss)\n\n        comp_wa = complexity_weighted_accuracy(dev_sequences, truths, preds)\n        run_val_cwa.append(comp_wa)\n        run_train_cwa.append(None)  # placeholder for per-epoch train CompWA if desired\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={v_loss:.4f}, val_CompWA={comp_wa:.4f}\"\n        )\n\n    # aggregate per\u2010run statistics\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"losses\"][\"train\"].append(\n        run_train_losses\n    )\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"losses\"][\"val\"].append(\n        run_val_losses\n    )\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"metrics\"][\"train_CompWA\"].append(\n        run_train_cwa\n    )\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"metrics\"][\"val_CompWA\"].append(\n        run_val_cwa\n    )\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"predictions\"].append(preds)\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"ground_truth\"].append(truths)\n\n    # optional additional metrics on dev set\n    cwa = color_weighted_accuracy(dev_sequences, y_dev, preds)\n    swa = shape_weighted_accuracy(dev_sequences, y_dev, preds)\n    print(f\"Run summary (lr={lr}): Dev CWA={cwa:.4f}, Dev SWA={swa:.4f}\")\n\n# ------------------ Save all experiment data -------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import DatasetDict, load_dataset\n\n# ------------------------ experiment dict ----------------------------\nexperiment_data = {\n    \"batch_size\": {\n        \"SPR_BENCH\": {\n            \"hyperparams\": [],  # list of tried batch-sizes\n            \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],  # list-of-lists (per batch size)\n            \"ground_truth\": [],  # list-of-lists (per batch size)\n        }\n    }\n}\n\n\n# --------------------------- utils ----------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):  # tiny wrapper\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef _weighted_acc(weights, y_true, y_pred):\n    return sum((w if t == p else 0) for w, t, p in zip(weights, y_true, y_pred)) / max(\n        sum(weights), 1\n    )\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return _weighted_acc(w, y_true, y_pred)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return _weighted_acc(w, y_true, y_pred)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return _weighted_acc(w, y_true, y_pred)\n\n\n# ---------------------------- data ----------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\ntrain_sequences, dev_sequences = spr[\"train\"][\"sequence\"], spr[\"dev\"][\"sequence\"]\n\n\ndef get_tokens(seqs):\n    toks = []\n    for s in seqs:\n        toks.extend(s.split())\n    return toks\n\n\nall_tokens = get_tokens(train_sequences)\nshapes, colors = [t[0] for t in all_tokens], [t[1] for t in all_tokens]\nshape_le, color_le = LabelEncoder().fit(shapes), LabelEncoder().fit(colors)\ntoken_vecs = np.stack([shape_le.transform(shapes), color_le.transform(colors)], 1)\nk = 8\nkmeans = KMeans(n_clusters=k, random_state=0, n_init=10).fit(token_vecs)\n\n\ndef sequence_to_histogram(seq: str):\n    vec = np.zeros(k, dtype=np.float32)\n    for tok in seq.split():\n        if len(tok) < 2:\n            continue\n        lab = kmeans.predict(\n            [[shape_le.transform([tok[0]])[0], color_le.transform([tok[1]])[0]]]\n        )[0]\n        vec[lab] += 1.0\n    return vec\n\n\nX_train = np.stack([sequence_to_histogram(s) for s in train_sequences])\nX_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences])\ny_train = np.array(spr[\"train\"][\"label\"], np.float32)\ny_dev = np.array(spr[\"dev\"][\"label\"], np.float32)\n\n\n# ------------------------ model def ---------------------------------\nclass SimpleFF(nn.Module):\n    def __init__(self, in_dim):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, 1))\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# ------------------- hyper-parameter tuning loop --------------------\nbatch_sizes = [128, 256, 512, 1024]\nepochs = 5\nfor bs in batch_sizes:\n    print(f\"\\n=== Training with batch_size = {bs} ===\")\n    # data loaders\n    train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n    dev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\n    train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True)\n    dev_loader = DataLoader(dev_ds, batch_size=bs)\n    # model / optim\n    model = SimpleFF(k).to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n    per_epoch_train_loss, per_epoch_val_loss = [], []\n    per_epoch_train_cwa, per_epoch_val_cwa = [], []\n    # training loop\n    for epoch in range(1, epochs + 1):\n        model.train()\n        run_loss = 0.0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            loss = criterion(model(xb), yb)\n            loss.backward()\n            optimizer.step()\n            run_loss += loss.item() * xb.size(0)\n        train_loss = run_loss / len(train_loader.dataset)\n        # validation\n        model.eval()\n        val_loss, preds, truths = 0.0, [], []\n        with torch.no_grad():\n            for xb, yb in dev_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                out = model(xb)\n                loss = criterion(out, yb)\n                val_loss += loss.item() * xb.size(0)\n                preds.extend(\n                    (torch.sigmoid(out) > 0.5).cpu().numpy().astype(int).tolist()\n                )\n                truths.extend(yb.cpu().numpy().astype(int).tolist())\n        val_loss /= len(dev_loader.dataset)\n        comp_wa = complexity_weighted_accuracy(dev_sequences, truths, preds)\n        # record\n        per_epoch_train_loss.append(train_loss)\n        per_epoch_val_loss.append(val_loss)\n        per_epoch_val_cwa.append(comp_wa)\n        per_epoch_train_cwa.append(None)  # placeholder\n        print(f\"Epoch {epoch}: val_loss={val_loss:.4f}, val_CompWA={comp_wa:.4f}\")\n    # store results for this batch size\n    ed = experiment_data[\"batch_size\"][\"SPR_BENCH\"]\n    ed[\"hyperparams\"].append(bs)\n    ed[\"losses\"][\"train\"].append(per_epoch_train_loss)\n    ed[\"losses\"][\"val\"].append(per_epoch_val_loss)\n    ed[\"metrics\"][\"train_CompWA\"].append(per_epoch_train_cwa)\n    ed[\"metrics\"][\"val_CompWA\"].append(per_epoch_val_cwa)\n    ed[\"predictions\"].append(preds)\n    ed[\"ground_truth\"].append(truths)\n    # optional other metrics on dev\n    print(\n        f\"Final Dev CWA={color_weighted_accuracy(dev_sequences, y_dev, preds):.4f}, \"\n        f\"SWA={shape_weighted_accuracy(dev_sequences, y_dev, preds):.4f}\"\n    )\n# ------------------------- save results ------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved all experiment data to 'working/experiment_data.npy'\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import DatasetDict, load_dataset\n\n# ---------------------------- I/O dict --------------------------------\nexperiment_data = {\n    \"hidden_dim_sweep\": {}  # will be filled with one entry per hidden size\n}\n\n# --------------------------- Paths ------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nDATA_PATH = pathlib.Path(\n    \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\"\n)  # adapt if needed\n\n\n# ------------------------ Helper functions ----------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.strip().split() if len(tok) > 0))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ----------------------------- Data -----------------------------------\nspr = load_spr_bench(DATA_PATH)\ntrain_sequences, dev_sequences = spr[\"train\"][\"sequence\"], spr[\"dev\"][\"sequence\"]\n\n\ndef get_tokens(seqs):\n    tokens = []\n    for s in seqs:\n        tokens.extend(s.strip().split())\n    return tokens\n\n\nall_tokens = get_tokens(train_sequences)\nshapes = [t[0] for t in all_tokens]\ncolors = [t[1] for t in all_tokens]\nshape_le, color_le = LabelEncoder().fit(shapes), LabelEncoder().fit(colors)\ntoken_vectors = np.stack([shape_le.transform(shapes), color_le.transform(colors)], 1)\n\nk = 8\nkmeans = KMeans(n_clusters=k, random_state=0, n_init=10).fit(token_vectors)\n\n\ndef sequence_to_histogram(seq: str):\n    vec = np.zeros(k, dtype=np.float32)\n    for tok in seq.strip().split():\n        if len(tok) < 2:\n            continue\n        s_id = shape_le.transform([tok[0]])[0]\n        c_id = color_le.transform([tok[1]])[0]\n        label = kmeans.predict([[s_id, c_id]])[0]\n        vec[label] += 1.0\n    return vec\n\n\nX_train = np.stack([sequence_to_histogram(s) for s in train_sequences]).astype(\n    np.float32\n)\nX_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences]).astype(np.float32)\ny_train = np.array(spr[\"train\"][\"label\"], dtype=np.float32)\ny_dev = np.array(spr[\"dev\"][\"label\"], dtype=np.float32)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ------------------------- Model template -----------------------------\nclass SimpleFF(nn.Module):\n    def __init__(self, in_dim, hidden_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\n\n# ---------------------- Hyper-parameter sweep -------------------------\nhidden_dims = [16, 32, 64, 128, 256]\nepochs, batch_size, lr = 5, 512, 1e-3\ntrain_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ndev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\n\nfor hdim in hidden_dims:\n    key = f\"SPR_BENCH_h{hdim}\"\n    experiment_data[\"hidden_dim_sweep\"][key] = {\n        \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    # loaders (shuffle only for train)\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    dev_loader = DataLoader(dev_ds, batch_size=batch_size)\n    # model/optim\n    model = SimpleFF(k, hdim).to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    # ---- epochs loop ----\n    for ep in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            out = model(xb)\n            loss = criterion(out, yb)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * xb.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        experiment_data[\"hidden_dim_sweep\"][key][\"losses\"][\"train\"].append(train_loss)\n\n        # quick train CompWA (on last mini-batch predictions)\n        with torch.no_grad():\n            train_preds = (torch.sigmoid(out) > 0.5).cpu().numpy().astype(int).tolist()\n            train_truth = yb.cpu().numpy().astype(int).tolist()\n            train_comp_wa = complexity_weighted_accuracy(\n                train_sequences[-len(train_preds) :], train_truth, train_preds\n            )\n\n        # validation\n        model.eval()\n        val_loss, v_preds, v_truths = 0.0, [], []\n        with torch.no_grad():\n            for xb, yb in dev_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                out = model(xb)\n                val_loss += criterion(out, yb).item() * xb.size(0)\n                v_preds.extend(\n                    (torch.sigmoid(out) > 0.5).cpu().numpy().astype(int).tolist()\n                )\n                v_truths.extend(yb.cpu().numpy().astype(int).tolist())\n        val_loss /= len(dev_loader.dataset)\n        experiment_data[\"hidden_dim_sweep\"][key][\"losses\"][\"val\"].append(val_loss)\n\n        val_comp_wa = complexity_weighted_accuracy(dev_sequences, v_truths, v_preds)\n        experiment_data[\"hidden_dim_sweep\"][key][\"metrics\"][\"train_CompWA\"].append(\n            train_comp_wa\n        )\n        experiment_data[\"hidden_dim_sweep\"][key][\"metrics\"][\"val_CompWA\"].append(\n            val_comp_wa\n        )\n\n        print(\n            f\"[hdim {hdim}] Epoch {ep}: train_loss {train_loss:.4f}, \"\n            f\"val_loss {val_loss:.4f}, val_CompWA {val_comp_wa:.4f}\"\n        )\n\n    # store final preds/labels for this setting\n    experiment_data[\"hidden_dim_sweep\"][key][\"predictions\"] = v_preds\n    experiment_data[\"hidden_dim_sweep\"][key][\"ground_truth\"] = v_truths\n    # additional per-setting metrics\n    cwa = color_weighted_accuracy(dev_sequences, y_dev, v_preds)\n    swa = shape_weighted_accuracy(dev_sequences, y_dev, v_preds)\n    print(f\"[hdim {hdim}] Final Dev CWA {cwa:.4f}, SWA {swa:.4f}\")\n\n# ---------------------------- Save ------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import DatasetDict, load_dataset\n\n# ---------------------- Reproducibility ------------------------------\ntorch.manual_seed(0)\nnp.random.seed(0)\n# --------------------------- I/O -------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nexperiment_data = {\"weight_decay\": {}}\n\n\n# --------------------------- Data ------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\ntrain_sequences, dev_sequences = spr[\"train\"][\"sequence\"], spr[\"dev\"][\"sequence\"]\n\n\ndef get_tokens(seqs):  # flatten tokens\n    tokens = []\n    for s in seqs:\n        tokens.extend(s.strip().split())\n    return tokens\n\n\nall_tokens = get_tokens(train_sequences)\nshapes, colors = [t[0] for t in all_tokens], [t[1] for t in all_tokens]\nshape_le, color_le = LabelEncoder().fit(shapes), LabelEncoder().fit(colors)\ntoken_vectors = np.stack(\n    [shape_le.transform(shapes), color_le.transform(colors)], axis=1\n)\nk = 8\nkmeans = KMeans(n_clusters=k, random_state=0, n_init=10).fit(token_vectors)\n\n\ndef sequence_to_histogram(seq):\n    vec = np.zeros(k, dtype=np.float32)\n    for tok in seq.strip().split():\n        if len(tok) < 2:\n            continue\n        s_id, c_id = shape_le.transform([tok[0]])[0], color_le.transform([tok[1]])[0]\n        vec[kmeans.predict([[s_id, c_id]])[0]] += 1.0\n    return vec\n\n\nX_train = np.stack([sequence_to_histogram(s) for s in train_sequences])\nX_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences])\ny_train = np.array(spr[\"train\"][\"label\"], dtype=np.float32)\ny_dev = np.array(spr[\"dev\"][\"label\"], dtype=np.float32)\n\n\n# ----------------------- Metrics helpers -----------------------------\ndef count_color_variety(seq):\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------------------------- Model ----------------------------------\nclass SimpleFF(nn.Module):\n    def __init__(self, in_dim):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, 1))\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# --------------------- Hyperparameter sweep --------------------------\nweight_decays = [0.0, 1e-5, 1e-4, 1e-3, 1e-2]\nbatch_size, epochs, lr = 512, 5, 1e-3\ntrain_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ndev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=batch_size)\nfor wd in weight_decays:\n    run_key = f\"wd_{wd}\"\n    experiment_data[\"weight_decay\"][run_key] = {\n        \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    model = SimpleFF(k).to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n    for epoch in range(1, epochs + 1):\n        # -------- training ----------\n        model.train()\n        running_loss = 0.0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            loss = criterion(model(xb), yb)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * xb.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        # quick train CompWA\n        with torch.no_grad():\n            tr_logits = model(torch.from_numpy(X_train).to(device))\n            tr_preds = (torch.sigmoid(tr_logits) > 0.5).cpu().numpy().astype(int)\n            tr_comp = complexity_weighted_accuracy(\n                train_sequences, y_train.astype(int), tr_preds\n            )\n        # -------- validation ---------\n        model.eval()\n        val_loss, preds, truths = 0.0, [], []\n        with torch.no_grad():\n            for xb, yb in dev_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                out = model(xb)\n                val_loss += criterion(out, yb).item() * xb.size(0)\n                preds.extend(\n                    (torch.sigmoid(out) > 0.5).cpu().numpy().astype(int).tolist()\n                )\n                truths.extend(yb.cpu().numpy().astype(int).tolist())\n        val_loss /= len(dev_loader.dataset)\n        val_comp = complexity_weighted_accuracy(dev_sequences, truths, preds)\n        # -------- logging ------------\n        exp = experiment_data[\"weight_decay\"][run_key]\n        exp[\"losses\"][\"train\"].append(train_loss)\n        exp[\"losses\"][\"val\"].append(val_loss)\n        exp[\"metrics\"][\"train_CompWA\"].append(tr_comp)\n        exp[\"metrics\"][\"val_CompWA\"].append(val_comp)\n        if epoch == epochs:  # store final predictions only once\n            exp[\"predictions\"] = preds\n            exp[\"ground_truth\"] = truths\n        print(\n            f\"[wd={wd}] epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"val_CompWA={val_comp:.4f}\"\n        )\n    # per-run extra metrics\n    exp[\"CWA\"] = color_weighted_accuracy(dev_sequences, y_dev.astype(int), preds)\n    exp[\"SWA\"] = shape_weighted_accuracy(dev_sequences, y_dev.astype(int), preds)\n# ------------------------- Save to disk ------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import load_dataset, DatasetDict\n\n# -----------------------  set-up & bookkeeping  ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\"num_clusters_k\": {\"SPR_BENCH\": {}}}\n\n\n# --------------------------- utilities ------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------------------------- data ----------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\ntrain_sequences, dev_sequences = spr[\"train\"][\"sequence\"], spr[\"dev\"][\"sequence\"]\n\n\n# label encoders for glyph parts (keep fixed across k)\ndef get_tokens(seqs):\n    toks = []\n    for s in seqs:\n        toks.extend(s.strip().split())\n    return toks\n\n\nall_tokens = get_tokens(train_sequences)\nshape_le = LabelEncoder().fit([t[0] for t in all_tokens])\ncolor_le = LabelEncoder().fit([t[1] for t in all_tokens])\n\ntoken_vectors = np.stack(\n    [\n        shape_le.transform([t[0] for t in all_tokens]),\n        color_le.transform([t[1] for t in all_tokens]),\n    ],\n    axis=1,\n)\n\ny_train = np.array(spr[\"train\"][\"label\"], dtype=np.float32)\ny_dev = np.array(spr[\"dev\"][\"label\"], dtype=np.float32)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# --------------------- training function per k ----------------------\ndef run_experiment(k: int, epochs: int = 5, batch_size: int = 512):\n    print(f\"\\n===== Training with k = {k} clusters =====\")\n    # --- clustering ---\n    kmeans = KMeans(n_clusters=k, random_state=0, n_init=10).fit(token_vectors)\n\n    def sequence_to_histogram(seq: str):\n        vec = np.zeros(k, dtype=np.float32)\n        for tok in seq.strip().split():\n            if len(tok) < 2:  # skip malformed\n                continue\n            s_id = shape_le.transform([tok[0]])[0]\n            c_id = color_le.transform([tok[1]])[0]\n            label = kmeans.predict([[s_id, c_id]])[0]\n            vec[label] += 1.0\n        return vec\n\n    X_train = np.stack([sequence_to_histogram(s) for s in train_sequences])\n    X_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences])\n\n    train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n    dev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    dev_loader = DataLoader(dev_ds, batch_size=batch_size)\n\n    # --- model ---\n    class SimpleFF(nn.Module):\n        def __init__(self, in_dim):\n            super().__init__()\n            self.net = nn.Sequential(nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, 1))\n\n        def forward(self, x):\n            return self.net(x).squeeze(-1)\n\n    model = SimpleFF(k).to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n    # data containers\n    k_dict = {\n        \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, epochs + 1):\n        # ---- training ----\n        model.train()\n        running = 0.0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            loss = criterion(model(xb), yb)\n            loss.backward()\n            optimizer.step()\n            running += loss.item() * xb.size(0)\n        train_loss = running / len(train_loader.dataset)\n        k_dict[\"losses\"][\"train\"].append(train_loss)\n\n        # ---- validation ----\n        model.eval()\n        vloss, preds, truths = 0.0, [], []\n        with torch.no_grad():\n            for xb, yb in dev_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                vloss += loss.item() * xb.size(0)\n                preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy().astype(int))\n                truths.extend(yb.cpu().numpy().astype(int))\n        vloss /= len(dev_loader.dataset)\n        k_dict[\"losses\"][\"val\"].append(vloss)\n\n        comp_wa = complexity_weighted_accuracy(dev_sequences, truths, preds)\n        k_dict[\"metrics\"][\"train_CompWA\"].append(None)  # skipped for brevity\n        k_dict[\"metrics\"][\"val_CompWA\"].append(comp_wa)\n        print(f\"Epoch {epoch}: val_loss={vloss:.4f}, val_CompWA={comp_wa:.4f}\")\n\n    # ---- final predictions / metrics ----\n    k_dict[\"predictions\"] = preds\n    k_dict[\"ground_truth\"] = truths\n    cwa = color_weighted_accuracy(dev_sequences, truths, preds)\n    swa = shape_weighted_accuracy(dev_sequences, truths, preds)\n    print(f\"k={k} -> Dev CWA: {cwa:.4f}, Dev SWA: {swa:.4f}\")\n    return k_dict\n\n\n# ------------------------ hyper-parameter loop ----------------------\nfor k_val in [4, 8, 16, 32]:\n    experiment_data[\"num_clusters_k\"][\"SPR_BENCH\"][f\"k={k_val}\"] = run_experiment(k_val)\n\n# --------------------------- save -----------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nAll experiments finished and saved to 'experiment_data.npy'.\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import DatasetDict\n\n# --------------------------  Experiment dict -------------------------\nexperiment_data = {\"pos_weight\": {}}  # root key for this tuning type\n\n\n# --------------------------  Data utils ------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    from datasets import load_dataset\n\n    def _load(csv_file: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_file),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split()))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# --------------------------  Load data -------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\n\ntrain_sequences = spr[\"train\"][\"sequence\"]\ndev_sequences = spr[\"dev\"][\"sequence\"]\n\n\ndef get_tokens(seqs):\n    toks = []\n    for s in seqs:\n        toks.extend(s.strip().split())\n    return toks\n\n\nall_tokens = get_tokens(train_sequences)\nshapes = [t[0] for t in all_tokens]\ncolors = [t[1] for t in all_tokens]\nshape_le = LabelEncoder().fit(shapes)\ncolor_le = LabelEncoder().fit(colors)\n\ntoken_vectors = np.stack(\n    [shape_le.transform(shapes), color_le.transform(colors)], axis=1\n)\n\n# --------------------------  Clustering ------------------------------\nk = 8\nkmeans = KMeans(n_clusters=k, random_state=0, n_init=10)\nkmeans.fit(token_vectors)\n\n\ndef sequence_to_histogram(seq: str) -> np.ndarray:\n    vec = np.zeros(k, dtype=np.float32)\n    for tok in seq.strip().split():\n        if len(tok) < 2:\n            continue\n        s_id = shape_le.transform([tok[0]])[0]\n        c_id = color_le.transform([tok[1]])[0]\n        label = kmeans.predict([[s_id, c_id]])[0]\n        vec[label] += 1.0\n    return vec\n\n\nX_train = np.stack([sequence_to_histogram(s) for s in train_sequences])\nX_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences])\ny_train = np.array(spr[\"train\"][\"label\"], dtype=np.float32)\ny_dev = np.array(spr[\"dev\"][\"label\"], dtype=np.float32)\n\ntrain_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ndev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\n\nbatch_size = 512\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\ndev_loader = DataLoader(dev_ds, batch_size=batch_size)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# --------------------------  Model def -------------------------------\nclass SimpleFF(nn.Module):\n    def __init__(self, in_dim: int):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, 1))\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\n\n# ---------------------- Hyper-parameter sweep ------------------------\npos_weight_grid = [1, 2, 4, 8]\nepochs = 5\n\nfor pw in pos_weight_grid:\n    key = f\"SPR_BENCH_pw{pw}\"\n    experiment_data[\"pos_weight\"][key] = {\n        \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"val_CWA\": None,\n        \"val_SWA\": None,\n    }\n\n    model = SimpleFF(k).to(device)\n    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pw], device=device))\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n    for epoch in range(1, epochs + 1):\n        # ------- training -------\n        model.train()\n        running_loss = 0.0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            out = model(xb)\n            loss = criterion(out, yb)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * xb.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        experiment_data[\"pos_weight\"][key][\"losses\"][\"train\"].append(train_loss)\n\n        # ------- validation ------\n        model.eval()\n        val_loss, preds, truths = 0.0, [], []\n        with torch.no_grad():\n            for xb, yb in dev_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                out = model(xb)\n                loss = criterion(out, yb)\n                val_loss += loss.item() * xb.size(0)\n                probs = torch.sigmoid(out)\n                preds.extend((probs > 0.5).cpu().numpy().astype(int).tolist())\n                truths.extend(yb.cpu().numpy().astype(int).tolist())\n        val_loss /= len(dev_loader.dataset)\n        experiment_data[\"pos_weight\"][key][\"losses\"][\"val\"].append(val_loss)\n\n        comp_wa = complexity_weighted_accuracy(dev_sequences, truths, preds)\n        experiment_data[\"pos_weight\"][key][\"metrics\"][\"val_CompWA\"].append(comp_wa)\n        experiment_data[\"pos_weight\"][key][\"metrics\"][\"train_CompWA\"].append(None)\n\n        print(\n            f\"[pw={pw}] Epoch {epoch}: val_loss={val_loss:.4f}, val_CompWA={comp_wa:.4f}\"\n        )\n\n    # ---- store final predictions & extra metrics ----\n    experiment_data[\"pos_weight\"][key][\"predictions\"] = preds\n    experiment_data[\"pos_weight\"][key][\"ground_truth\"] = truths\n    experiment_data[\"pos_weight\"][key][\"val_CWA\"] = color_weighted_accuracy(\n        dev_sequences, y_dev, preds\n    )\n    experiment_data[\"pos_weight\"][key][\"val_SWA\"] = shape_weighted_accuracy(\n        dev_sequences, y_dev, preds\n    )\n    print(\n        f\"[pw={pw}] Final Dev CWA: {experiment_data['pos_weight'][key]['val_CWA']:.4f}, \"\n        f\"SWA: {experiment_data['pos_weight'][key]['val_SWA']:.4f}\"\n    )\n\n# ----------------------- Save experiment data ------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Experiment data saved to 'working/experiment_data.npy'\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import DatasetDict, load_dataset\n\n# --------------- experiment data container ---------------------------\nexperiment_data = {}\n\n\n# --------------- Utility fns (unchanged) -----------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ----------------------------- Data ----------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\n\ntrain_sequences, dev_sequences = spr[\"train\"][\"sequence\"], spr[\"dev\"][\"sequence\"]\n\n\ndef get_tokens(seqs):\n    tokens = []\n    for s in seqs:\n        tokens.extend(s.strip().split())\n    return tokens\n\n\nall_tokens = get_tokens(train_sequences)\nshapes = [t[0] for t in all_tokens]\ncolors = [t[1] for t in all_tokens]\nshape_le, color_le = LabelEncoder().fit(shapes), LabelEncoder().fit(colors)\n\ntoken_vectors = np.stack(\n    [shape_le.transform(shapes), color_le.transform(colors)], axis=1\n)\n\nk = 8\nkmeans = KMeans(n_clusters=k, random_state=0, n_init=10).fit(token_vectors)\n\n\ndef sequence_to_histogram(seq):\n    vec = np.zeros(k, np.float32)\n    for tok in seq.strip().split():\n        if len(tok) < 2:\n            continue\n        s_id = shape_le.transform([tok[0]])[0]\n        c_id = color_le.transform([tok[1]])[0]\n        label = kmeans.predict([[s_id, c_id]])[0]\n        vec[label] += 1.0\n    return vec\n\n\nX_train = np.stack([sequence_to_histogram(s) for s in train_sequences])\nX_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences])\ny_train = np.asarray(spr[\"train\"][\"label\"], np.float32)\ny_dev = np.asarray(spr[\"dev\"][\"label\"], np.float32)\n\ntrain_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ndev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# --------------------- model definition ------------------------------\nclass SimpleFF(nn.Module):\n    def __init__(self, in_dim: int, p: float):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, 32),\n            nn.ReLU(),\n            nn.Dropout(p),\n            nn.Linear(32, 1),\n        )\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\n\n# --------------------- training loop ---------------------------------\ndef run_experiment(p_drop: float, epochs: int = 5, batch_size: int = 512):\n    key = f\"dropout_prob_{p_drop}\"\n    experiment_data[key] = {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n    mdl = SimpleFF(k, p_drop).to(device)\n    crit = nn.BCEWithLogitsLoss()\n    opt = optim.Adam(mdl.parameters(), lr=1e-3)\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    dev_loader = DataLoader(dev_ds, batch_size=batch_size)\n\n    for ep in range(1, epochs + 1):\n        # ----- train -----\n        mdl.train()\n        running_loss = 0.0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            opt.zero_grad()\n            out = mdl(xb)\n            loss = crit(out, yb)\n            loss.backward()\n            opt.step()\n            running_loss += loss.item() * xb.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        experiment_data[key][\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n\n        # ----- validation -----\n        mdl.eval()\n        val_loss = 0.0\n        preds = []\n        truths = []\n        with torch.no_grad():\n            for xb, yb in dev_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                out = mdl(xb)\n                loss = crit(out, yb)\n                val_loss += loss.item() * xb.size(0)\n                preds.extend(\n                    (torch.sigmoid(out) > 0.5).cpu().numpy().astype(int).tolist()\n                )\n                truths.extend(yb.cpu().numpy().astype(int).tolist())\n        val_loss /= len(dev_loader.dataset)\n        cwa_val = complexity_weighted_accuracy(dev_sequences, truths, preds)\n        experiment_data[key][\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n        experiment_data[key][\"SPR_BENCH\"][\"metrics\"][\"val_CompWA\"].append(cwa_val)\n        experiment_data[key][\"SPR_BENCH\"][\"metrics\"][\"train_CompWA\"].append(None)\n        print(\n            f\"[p={p_drop}] Epoch {ep}: val_loss {val_loss:.4f}, val_CompWA {cwa_val:.4f}\"\n        )\n\n    # ----- final extra metrics -----\n    experiment_data[key][\"SPR_BENCH\"][\"predictions\"] = preds\n    experiment_data[key][\"SPR_BENCH\"][\"ground_truth\"] = truths\n    cwa = color_weighted_accuracy(dev_sequences, y_dev, preds)\n    swa = shape_weighted_accuracy(dev_sequences, y_dev, preds)\n    print(f\"[p={p_drop}] Dev CWA {cwa:.4f}, Dev SWA {swa:.4f}\")\n\n\n# --------------------- run sweeps ------------------------------------\nfor p in [0.0, 0.1, 0.3, 0.5]:\n    run_experiment(p)\n\n# --------------------- save results ----------------------------------\nos.makedirs(\"working\", exist_ok=True)\nnp.save(os.path.join(\"working\", \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import load_dataset, DatasetDict\n\n# -----------------------  set-up & bookkeeping  ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\"num_clusters_k\": {\"SPR_BENCH\": {}}}\n\n\n# --------------------------- utilities ------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------------------------- data ----------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\ntrain_sequences, dev_sequences = spr[\"train\"][\"sequence\"], spr[\"dev\"][\"sequence\"]\n\n\n# label encoders for glyph parts (keep fixed across k)\ndef get_tokens(seqs):\n    toks = []\n    for s in seqs:\n        toks.extend(s.strip().split())\n    return toks\n\n\nall_tokens = get_tokens(train_sequences)\nshape_le = LabelEncoder().fit([t[0] for t in all_tokens])\ncolor_le = LabelEncoder().fit([t[1] for t in all_tokens])\n\ntoken_vectors = np.stack(\n    [\n        shape_le.transform([t[0] for t in all_tokens]),\n        color_le.transform([t[1] for t in all_tokens]),\n    ],\n    axis=1,\n)\n\ny_train = np.array(spr[\"train\"][\"label\"], dtype=np.float32)\ny_dev = np.array(spr[\"dev\"][\"label\"], dtype=np.float32)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# --------------------- training function per k ----------------------\ndef run_experiment(k: int, epochs: int = 5, batch_size: int = 512):\n    print(f\"\\n===== Training with k = {k} clusters =====\")\n    # --- clustering ---\n    kmeans = KMeans(n_clusters=k, random_state=0, n_init=10).fit(token_vectors)\n\n    def sequence_to_histogram(seq: str):\n        vec = np.zeros(k, dtype=np.float32)\n        for tok in seq.strip().split():\n            if len(tok) < 2:  # skip malformed\n                continue\n            s_id = shape_le.transform([tok[0]])[0]\n            c_id = color_le.transform([tok[1]])[0]\n            label = kmeans.predict([[s_id, c_id]])[0]\n            vec[label] += 1.0\n        return vec\n\n    X_train = np.stack([sequence_to_histogram(s) for s in train_sequences])\n    X_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences])\n\n    train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n    dev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    dev_loader = DataLoader(dev_ds, batch_size=batch_size)\n\n    # --- model ---\n    class SimpleFF(nn.Module):\n        def __init__(self, in_dim):\n            super().__init__()\n            self.net = nn.Sequential(nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, 1))\n\n        def forward(self, x):\n            return self.net(x).squeeze(-1)\n\n    model = SimpleFF(k).to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n    # data containers\n    k_dict = {\n        \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, epochs + 1):\n        # ---- training ----\n        model.train()\n        running = 0.0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            loss = criterion(model(xb), yb)\n            loss.backward()\n            optimizer.step()\n            running += loss.item() * xb.size(0)\n        train_loss = running / len(train_loader.dataset)\n        k_dict[\"losses\"][\"train\"].append(train_loss)\n\n        # ---- validation ----\n        model.eval()\n        vloss, preds, truths = 0.0, [], []\n        with torch.no_grad():\n            for xb, yb in dev_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                vloss += loss.item() * xb.size(0)\n                preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy().astype(int))\n                truths.extend(yb.cpu().numpy().astype(int))\n        vloss /= len(dev_loader.dataset)\n        k_dict[\"losses\"][\"val\"].append(vloss)\n\n        comp_wa = complexity_weighted_accuracy(dev_sequences, truths, preds)\n        k_dict[\"metrics\"][\"train_CompWA\"].append(None)  # skipped for brevity\n        k_dict[\"metrics\"][\"val_CompWA\"].append(comp_wa)\n        print(f\"Epoch {epoch}: val_loss={vloss:.4f}, val_CompWA={comp_wa:.4f}\")\n\n    # ---- final predictions / metrics ----\n    k_dict[\"predictions\"] = preds\n    k_dict[\"ground_truth\"] = truths\n    cwa = color_weighted_accuracy(dev_sequences, truths, preds)\n    swa = shape_weighted_accuracy(dev_sequences, truths, preds)\n    print(f\"k={k} -> Dev CWA: {cwa:.4f}, Dev SWA: {swa:.4f}\")\n    return k_dict\n\n\n# ------------------------ hyper-parameter loop ----------------------\nfor k_val in [4, 8, 16, 32]:\n    experiment_data[\"num_clusters_k\"][\"SPR_BENCH\"][f\"k={k_val}\"] = run_experiment(k_val)\n\n# --------------------------- save -----------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nAll experiments finished and saved to 'experiment_data.npy'.\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import load_dataset, DatasetDict\n\n# -----------------------  set-up & bookkeeping  ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\"num_clusters_k\": {\"SPR_BENCH\": {}}}\n\n\n# --------------------------- utilities ------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------------------------- data ----------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\ntrain_sequences, dev_sequences = spr[\"train\"][\"sequence\"], spr[\"dev\"][\"sequence\"]\n\n\n# label encoders for glyph parts (keep fixed across k)\ndef get_tokens(seqs):\n    toks = []\n    for s in seqs:\n        toks.extend(s.strip().split())\n    return toks\n\n\nall_tokens = get_tokens(train_sequences)\nshape_le = LabelEncoder().fit([t[0] for t in all_tokens])\ncolor_le = LabelEncoder().fit([t[1] for t in all_tokens])\n\ntoken_vectors = np.stack(\n    [\n        shape_le.transform([t[0] for t in all_tokens]),\n        color_le.transform([t[1] for t in all_tokens]),\n    ],\n    axis=1,\n)\n\ny_train = np.array(spr[\"train\"][\"label\"], dtype=np.float32)\ny_dev = np.array(spr[\"dev\"][\"label\"], dtype=np.float32)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# --------------------- training function per k ----------------------\ndef run_experiment(k: int, epochs: int = 5, batch_size: int = 512):\n    print(f\"\\n===== Training with k = {k} clusters =====\")\n    # --- clustering ---\n    kmeans = KMeans(n_clusters=k, random_state=0, n_init=10).fit(token_vectors)\n\n    def sequence_to_histogram(seq: str):\n        vec = np.zeros(k, dtype=np.float32)\n        for tok in seq.strip().split():\n            if len(tok) < 2:  # skip malformed\n                continue\n            s_id = shape_le.transform([tok[0]])[0]\n            c_id = color_le.transform([tok[1]])[0]\n            label = kmeans.predict([[s_id, c_id]])[0]\n            vec[label] += 1.0\n        return vec\n\n    X_train = np.stack([sequence_to_histogram(s) for s in train_sequences])\n    X_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences])\n\n    train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n    dev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    dev_loader = DataLoader(dev_ds, batch_size=batch_size)\n\n    # --- model ---\n    class SimpleFF(nn.Module):\n        def __init__(self, in_dim):\n            super().__init__()\n            self.net = nn.Sequential(nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, 1))\n\n        def forward(self, x):\n            return self.net(x).squeeze(-1)\n\n    model = SimpleFF(k).to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n    # data containers\n    k_dict = {\n        \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, epochs + 1):\n        # ---- training ----\n        model.train()\n        running = 0.0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            loss = criterion(model(xb), yb)\n            loss.backward()\n            optimizer.step()\n            running += loss.item() * xb.size(0)\n        train_loss = running / len(train_loader.dataset)\n        k_dict[\"losses\"][\"train\"].append(train_loss)\n\n        # ---- validation ----\n        model.eval()\n        vloss, preds, truths = 0.0, [], []\n        with torch.no_grad():\n            for xb, yb in dev_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                vloss += loss.item() * xb.size(0)\n                preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy().astype(int))\n                truths.extend(yb.cpu().numpy().astype(int))\n        vloss /= len(dev_loader.dataset)\n        k_dict[\"losses\"][\"val\"].append(vloss)\n\n        comp_wa = complexity_weighted_accuracy(dev_sequences, truths, preds)\n        k_dict[\"metrics\"][\"train_CompWA\"].append(None)  # skipped for brevity\n        k_dict[\"metrics\"][\"val_CompWA\"].append(comp_wa)\n        print(f\"Epoch {epoch}: val_loss={vloss:.4f}, val_CompWA={comp_wa:.4f}\")\n\n    # ---- final predictions / metrics ----\n    k_dict[\"predictions\"] = preds\n    k_dict[\"ground_truth\"] = truths\n    cwa = color_weighted_accuracy(dev_sequences, truths, preds)\n    swa = shape_weighted_accuracy(dev_sequences, truths, preds)\n    print(f\"k={k} -> Dev CWA: {cwa:.4f}, Dev SWA: {swa:.4f}\")\n    return k_dict\n\n\n# ------------------------ hyper-parameter loop ----------------------\nfor k_val in [4, 8, 16, 32]:\n    experiment_data[\"num_clusters_k\"][\"SPR_BENCH\"][f\"k={k_val}\"] = run_experiment(k_val)\n\n# --------------------------- save -----------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nAll experiments finished and saved to 'experiment_data.npy'.\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import load_dataset, DatasetDict\n\n# -----------------------  set-up & bookkeeping  ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexperiment_data = {\"num_clusters_k\": {\"SPR_BENCH\": {}}}\n\n\n# --------------------------- utilities ------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return sum((wi if t == p else 0) for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------------------------- data ----------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\nspr = load_spr_bench(DATA_PATH)\ntrain_sequences, dev_sequences = spr[\"train\"][\"sequence\"], spr[\"dev\"][\"sequence\"]\n\n\n# label encoders for glyph parts (keep fixed across k)\ndef get_tokens(seqs):\n    toks = []\n    for s in seqs:\n        toks.extend(s.strip().split())\n    return toks\n\n\nall_tokens = get_tokens(train_sequences)\nshape_le = LabelEncoder().fit([t[0] for t in all_tokens])\ncolor_le = LabelEncoder().fit([t[1] for t in all_tokens])\n\ntoken_vectors = np.stack(\n    [\n        shape_le.transform([t[0] for t in all_tokens]),\n        color_le.transform([t[1] for t in all_tokens]),\n    ],\n    axis=1,\n)\n\ny_train = np.array(spr[\"train\"][\"label\"], dtype=np.float32)\ny_dev = np.array(spr[\"dev\"][\"label\"], dtype=np.float32)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# --------------------- training function per k ----------------------\ndef run_experiment(k: int, epochs: int = 5, batch_size: int = 512):\n    print(f\"\\n===== Training with k = {k} clusters =====\")\n    # --- clustering ---\n    kmeans = KMeans(n_clusters=k, random_state=0, n_init=10).fit(token_vectors)\n\n    def sequence_to_histogram(seq: str):\n        vec = np.zeros(k, dtype=np.float32)\n        for tok in seq.strip().split():\n            if len(tok) < 2:  # skip malformed\n                continue\n            s_id = shape_le.transform([tok[0]])[0]\n            c_id = color_le.transform([tok[1]])[0]\n            label = kmeans.predict([[s_id, c_id]])[0]\n            vec[label] += 1.0\n        return vec\n\n    X_train = np.stack([sequence_to_histogram(s) for s in train_sequences])\n    X_dev = np.stack([sequence_to_histogram(s) for s in dev_sequences])\n\n    train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n    dev_ds = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    dev_loader = DataLoader(dev_ds, batch_size=batch_size)\n\n    # --- model ---\n    class SimpleFF(nn.Module):\n        def __init__(self, in_dim):\n            super().__init__()\n            self.net = nn.Sequential(nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, 1))\n\n        def forward(self, x):\n            return self.net(x).squeeze(-1)\n\n    model = SimpleFF(k).to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n    # data containers\n    k_dict = {\n        \"metrics\": {\"train_CompWA\": [], \"val_CompWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, epochs + 1):\n        # ---- training ----\n        model.train()\n        running = 0.0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            loss = criterion(model(xb), yb)\n            loss.backward()\n            optimizer.step()\n            running += loss.item() * xb.size(0)\n        train_loss = running / len(train_loader.dataset)\n        k_dict[\"losses\"][\"train\"].append(train_loss)\n\n        # ---- validation ----\n        model.eval()\n        vloss, preds, truths = 0.0, [], []\n        with torch.no_grad():\n            for xb, yb in dev_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                vloss += loss.item() * xb.size(0)\n                preds.extend((torch.sigmoid(logits) > 0.5).cpu().numpy().astype(int))\n                truths.extend(yb.cpu().numpy().astype(int))\n        vloss /= len(dev_loader.dataset)\n        k_dict[\"losses\"][\"val\"].append(vloss)\n\n        comp_wa = complexity_weighted_accuracy(dev_sequences, truths, preds)\n        k_dict[\"metrics\"][\"train_CompWA\"].append(None)  # skipped for brevity\n        k_dict[\"metrics\"][\"val_CompWA\"].append(comp_wa)\n        print(f\"Epoch {epoch}: val_loss={vloss:.4f}, val_CompWA={comp_wa:.4f}\")\n\n    # ---- final predictions / metrics ----\n    k_dict[\"predictions\"] = preds\n    k_dict[\"ground_truth\"] = truths\n    cwa = color_weighted_accuracy(dev_sequences, truths, preds)\n    swa = shape_weighted_accuracy(dev_sequences, truths, preds)\n    print(f\"k={k} -> Dev CWA: {cwa:.4f}, Dev SWA: {swa:.4f}\")\n    return k_dict\n\n\n# ------------------------ hyper-parameter loop ----------------------\nfor k_val in [4, 8, 16, 32]:\n    experiment_data[\"num_clusters_k\"][\"SPR_BENCH\"][f\"k={k_val}\"] = run_experiment(k_val)\n\n# --------------------------- save -----------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nAll experiments finished and saved to 'experiment_data.npy'.\")\n", "# plotting aggregation code"], "term_out": ["['\\rGenerating train split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating\ntrain split: 20000 examples [00:00, 542460.42 examples/s]', '\\n', '\\rGenerating\ntrain split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating train split:\n5000 examples [00:00, 776665.43 examples/s]', '\\n', '\\rGenerating train split: 0\nexamples [00:00, ? examples/s]', '', '\\rGenerating train split: 10000 examples\n[00:00, 900084.55 examples/s]', '\\n', 'Using device: cuda', '\\n', 'Epoch 1:\nvalidation_loss = 0.6561, val_CompWA = 0.6778', '\\n', 'Epoch 2: validation_loss\n= 0.6169, val_CompWA = 0.6992', '\\n', 'Epoch 3: validation_loss = 0.5876,\nval_CompWA = 0.7083', '\\n', 'Epoch 4: validation_loss = 0.5720, val_CompWA =\n0.7120', '\\n', 'Epoch 5: validation_loss = 0.5610, val_CompWA = 0.7190', '\\n',\n'Dev CWA: 0.7158, Dev SWA: 0.7222', '\\n', 'Execution time: 47 seconds seconds\n(time limit is 30 minutes).']", "['\\rGenerating train split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating\ntrain split: 20000 examples [00:00, 522752.41 examples/s]', '\\n', '\\rGenerating\ntrain split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating train split:\n5000 examples [00:00, 502239.68 examples/s]', '\\n', '\\rGenerating train split: 0\nexamples [00:00, ? examples/s]', '', '\\rGenerating train split: 10000 examples\n[00:00, 583669.03 examples/s]', '\\n', 'Using device: cuda', '\\n', '\\n===\nTraining with max_epochs = 5 ===', '\\n', 'Epoch 1/5: train_loss=0.6759,\nval_loss=0.6561, val_CompWA=0.6778', '\\n', 'Epoch 2/5: train_loss=0.6382,\nval_loss=0.6169, val_CompWA=0.6992', '\\n', 'Epoch 3/5: train_loss=0.6036,\nval_loss=0.5876, val_CompWA=0.7083', '\\n', 'Epoch 4/5: train_loss=0.5822,\nval_loss=0.5720, val_CompWA=0.7120', '\\n', 'Epoch 5/5: train_loss=0.5694,\nval_loss=0.5610, val_CompWA=0.7190', '\\n', 'Final Dev CWA: 0.7158, Dev SWA:\n0.7222', '\\n', '\\n=== Training with max_epochs = 10 ===', '\\n', 'Epoch 1/10:\ntrain_loss=0.6794, val_loss=0.6542, val_CompWA=0.6789', '\\n', 'Epoch 2/10:\ntrain_loss=0.6400, val_loss=0.6174, val_CompWA=0.7065', '\\n', 'Epoch 3/10:\ntrain_loss=0.6051, val_loss=0.5872, val_CompWA=0.7118', '\\n', 'Epoch 4/10:\ntrain_loss=0.5821, val_loss=0.5706, val_CompWA=0.7214', '\\n', 'Epoch 5/10:\ntrain_loss=0.5684, val_loss=0.5600, val_CompWA=0.7229', '\\n', 'Epoch 6/10:\ntrain_loss=0.5587, val_loss=0.5515, val_CompWA=0.7284', '\\n', 'Epoch 7/10:\ntrain_loss=0.5507, val_loss=0.5439, val_CompWA=0.7305', '\\n', 'Epoch 8/10:\ntrain_loss=0.5433, val_loss=0.5370, val_CompWA=0.7338', '\\n', 'Epoch 9/10:\ntrain_loss=0.5365, val_loss=0.5301, val_CompWA=0.7371', '\\n', 'Epoch 10/10:\ntrain_loss=0.5302, val_loss=0.5236, val_CompWA=0.7383', '\\n', 'Final Dev CWA:\n0.7345, Dev SWA: 0.7420', '\\n', '\\n=== Training with max_epochs = 20 ===', '\\n',\n'Epoch 1/20: train_loss=0.6614, val_loss=0.6385, val_CompWA=0.6753', '\\n',\n'Epoch 2/20: train_loss=0.6259, val_loss=0.6065, val_CompWA=0.7073', '\\n',\n'Epoch 3/20: train_loss=0.5972, val_loss=0.5830, val_CompWA=0.7098', '\\n',\n'Epoch 4/20: train_loss=0.5779, val_loss=0.5674, val_CompWA=0.7301', '\\n',\n'Epoch 5/20: train_loss=0.5641, val_loss=0.5540, val_CompWA=0.7334', '\\n',\n'Epoch 6/20: train_loss=0.5513, val_loss=0.5412, val_CompWA=0.7344', '\\n',\n'Epoch 7/20: train_loss=0.5390, val_loss=0.5288, val_CompWA=0.7355', '\\n',\n'Epoch 8/20: train_loss=0.5274, val_loss=0.5176, val_CompWA=0.7357', '\\n',\n'Epoch 9/20: train_loss=0.5170, val_loss=0.5083, val_CompWA=0.7380', '\\n',\n'Epoch 10/20: train_loss=0.5089, val_loss=0.5008, val_CompWA=0.7445', '\\n',\n'Epoch 11/20: train_loss=0.5020, val_loss=0.4943, val_CompWA=0.7471', '\\n',\n'Epoch 12/20: train_loss=0.4967, val_loss=0.4889, val_CompWA=0.7493', '\\n',\n'Epoch 13/20: train_loss=0.4922, val_loss=0.4851, val_CompWA=0.7512', '\\n',\n'Epoch 14/20: train_loss=0.4887, val_loss=0.4811, val_CompWA=0.7527', '\\n',\n'Epoch 15/20: train_loss=0.4848, val_loss=0.4783, val_CompWA=0.7531', '\\n',\n'Epoch 16/20: train_loss=0.4820, val_loss=0.4756, val_CompWA=0.7545', '\\n',\n'Epoch 17/20: train_loss=0.4795, val_loss=0.4733, val_CompWA=0.7575', '\\n',\n'Epoch 18/20: train_loss=0.4774, val_loss=0.4717, val_CompWA=0.7611', '\\n',\n'Epoch 19/20: train_loss=0.4757, val_loss=0.4696, val_CompWA=0.7638', '\\n',\n'Epoch 20/20: train_loss=0.4737, val_loss=0.4681, val_CompWA=0.7641', '\\n',\n'Final Dev CWA: 0.7625, Dev SWA: 0.7657', '\\n', '\\n=== Training with max_epochs\n= 30 ===', '\\n', 'Epoch 1/30: train_loss=0.6857, val_loss=0.6616,\nval_CompWA=0.6503', '\\n', 'Epoch 2/30: train_loss=0.6478, val_loss=0.6268,\nval_CompWA=0.6953', '\\n', 'Epoch 3/30: train_loss=0.6153, val_loss=0.5981,\nval_CompWA=0.6965', '\\n', 'Epoch 4/30: train_loss=0.5912, val_loss=0.5807,\nval_CompWA=0.7121', '\\n', 'Epoch 5/30: train_loss=0.5768, val_loss=0.5690,\nval_CompWA=0.7225', '\\n', 'Epoch 6/30: train_loss=0.5657, val_loss=0.5579,\nval_CompWA=0.7267', '\\n', 'Epoch 7/30: train_loss=0.5551, val_loss=0.5466,\nval_CompWA=0.7294', '\\n', 'Epoch 8/30: train_loss=0.5448, val_loss=0.5361,\nval_CompWA=0.7328', '\\n', 'Epoch 9/30: train_loss=0.5352, val_loss=0.5266,\nval_CompWA=0.7355', '\\n', 'Epoch 10/30: train_loss=0.5264, val_loss=0.5177,\nval_CompWA=0.7393', '\\n', 'Epoch 11/30: train_loss=0.5178, val_loss=0.5095,\nval_CompWA=0.7393', '\\n', 'Epoch 12/30: train_loss=0.5102, val_loss=0.5020,\nval_CompWA=0.7426', '\\n', 'Epoch 13/30: train_loss=0.5036, val_loss=0.4956,\nval_CompWA=0.7436', '\\n', 'Epoch 14/30: train_loss=0.4981, val_loss=0.4902,\nval_CompWA=0.7482', '\\n', 'Epoch 15/30: train_loss=0.4931, val_loss=0.4861,\nval_CompWA=0.7513', '\\n', 'Epoch 16/30: train_loss=0.4891, val_loss=0.4822,\nval_CompWA=0.7514', '\\n', 'Epoch 17/30: train_loss=0.4858, val_loss=0.4788,\nval_CompWA=0.7567', '\\n', 'Epoch 18/30: train_loss=0.4827, val_loss=0.4762,\nval_CompWA=0.7570', '\\n', 'Epoch 19/30: train_loss=0.4801, val_loss=0.4738,\nval_CompWA=0.7582', '\\n', 'Epoch 20/30: train_loss=0.4777, val_loss=0.4718,\nval_CompWA=0.7562', '\\n', 'Epoch 21/30: train_loss=0.4759, val_loss=0.4697,\nval_CompWA=0.7573', '\\n', 'Epoch 22/30: train_loss=0.4739, val_loss=0.4689,\nval_CompWA=0.7597', '\\n', 'Epoch 23/30: train_loss=0.4726, val_loss=0.4670,\nval_CompWA=0.7609', '\\n', 'Epoch 24/30: train_loss=0.4710, val_loss=0.4663,\nval_CompWA=0.7650', '\\n', 'Epoch 25/30: train_loss=0.4695, val_loss=0.4638,\nval_CompWA=0.7600', '\\n', 'Epoch 26/30: train_loss=0.4683, val_loss=0.4622,\nval_CompWA=0.7608', '\\n', 'Epoch 27/30: train_loss=0.4668, val_loss=0.4622,\nval_CompWA=0.7659', '\\n', 'Epoch 28/30: train_loss=0.4656, val_loss=0.4600,\nval_CompWA=0.7666', '\\n', 'Epoch 29/30: train_loss=0.4645, val_loss=0.4591,\nval_CompWA=0.7679', '\\n', 'Epoch 30/30: train_loss=0.4635, val_loss=0.4580,\nval_CompWA=0.7680', '\\n', 'Final Dev CWA: 0.7671, Dev SWA: 0.7690', '\\n', '\\n===\nTraining with max_epochs = 40 ===', '\\n', 'Epoch 1/40: train_loss=0.6895,\nval_loss=0.6602, val_CompWA=0.6645', '\\n', 'Epoch 2/40: train_loss=0.6437,\nval_loss=0.6221, val_CompWA=0.7026', '\\n', 'Epoch 3/40: train_loss=0.6100,\nval_loss=0.5927, val_CompWA=0.7099', '\\n', 'Epoch 4/40: train_loss=0.5854,\nval_loss=0.5729, val_CompWA=0.7191', '\\n', 'Epoch 5/40: train_loss=0.5689,\nval_loss=0.5587, val_CompWA=0.7207', '\\n', 'Epoch 6/40: train_loss=0.5566,\nval_loss=0.5468, val_CompWA=0.7273', '\\n', 'Epoch 7/40: train_loss=0.5459,\nval_loss=0.5357, val_CompWA=0.7285', '\\n', 'Epoch 8/40: train_loss=0.5363,\nval_loss=0.5255, val_CompWA=0.7326', '\\n', 'Epoch 9/40: train_loss=0.5269,\nval_loss=0.5158, val_CompWA=0.7384', '\\n', 'Epoch 10/40: train_loss=0.5188,\nval_loss=0.5078, val_CompWA=0.7409', '\\n', 'Epoch 11/40: train_loss=0.5116,\nval_loss=0.5008, val_CompWA=0.7451', '\\n', 'Epoch 12/40: train_loss=0.5056,\nval_loss=0.4948, val_CompWA=0.7458', '\\n', 'Epoch 13/40: train_loss=0.4999,\nval_loss=0.4894, val_CompWA=0.7499', '\\n', 'Epoch 14/40: train_loss=0.4953,\nval_loss=0.4854, val_CompWA=0.7528', '\\n', 'Epoch 15/40: train_loss=0.4911,\nval_loss=0.4820, val_CompWA=0.7508', '\\n', 'Epoch 16/40: train_loss=0.4877,\nval_loss=0.4783, val_CompWA=0.7564', '\\n', 'Epoch 17/40: train_loss=0.4844,\nval_loss=0.4754, val_CompWA=0.7547', '\\n', 'Epoch 18/40: train_loss=0.4816,\nval_loss=0.4728, val_CompWA=0.7581', '\\n', 'Epoch 19/40: train_loss=0.4788,\nval_loss=0.4700, val_CompWA=0.7566', '\\n', 'Epoch 20/40: train_loss=0.4760,\nval_loss=0.4679, val_CompWA=0.7588', '\\n', 'Epoch 21/40: train_loss=0.4737,\nval_loss=0.4655, val_CompWA=0.7589', '\\n', 'Epoch 22/40: train_loss=0.4717,\nval_loss=0.4638, val_CompWA=0.7573', '\\n', 'Epoch 23/40: train_loss=0.4698,\nval_loss=0.4623, val_CompWA=0.7627', '\\n', 'Epoch 24/40: train_loss=0.4685,\nval_loss=0.4606, val_CompWA=0.7569', '\\n', 'Epoch 25/40: train_loss=0.4668,\nval_loss=0.4591, val_CompWA=0.7630', '\\n', 'Epoch 26/40: train_loss=0.4653,\nval_loss=0.4580, val_CompWA=0.7629', '\\n', 'Epoch 27/40: train_loss=0.4640,\nval_loss=0.4566, val_CompWA=0.7635', '\\n', 'Epoch 28/40: train_loss=0.4629,\nval_loss=0.4553, val_CompWA=0.7676', '\\n', 'Epoch 29/40: train_loss=0.4614,\nval_loss=0.4559, val_CompWA=0.7675', '\\n', 'Epoch 30/40: train_loss=0.4610,\nval_loss=0.4535, val_CompWA=0.7651', '\\n', 'Epoch 31/40: train_loss=0.4597,\nval_loss=0.4528, val_CompWA=0.7637', '\\n', 'Epoch 32/40: train_loss=0.4589,\nval_loss=0.4519, val_CompWA=0.7668', '\\n', 'Epoch 33/40: train_loss=0.4578,\nval_loss=0.4531, val_CompWA=0.7699', '\\n', 'Epoch 34/40: train_loss=0.4580,\nval_loss=0.4506, val_CompWA=0.7650', '\\n', 'Epoch 35/40: train_loss=0.4569,\nval_loss=0.4496, val_CompWA=0.7700', '\\n', 'Epoch 36/40: train_loss=0.4563,\nval_loss=0.4492, val_CompWA=0.7661', '\\n', 'Epoch 37/40: train_loss=0.4558,\nval_loss=0.4484, val_CompWA=0.7672', '\\n', 'Epoch 38/40: train_loss=0.4550,\nval_loss=0.4481, val_CompWA=0.7735', '\\n', 'Epoch 39/40: train_loss=0.4542,\nval_loss=0.4473, val_CompWA=0.7661', '\\n', 'Epoch 40/40: train_loss=0.4538,\nval_loss=0.4470, val_CompWA=0.7732', '\\n', 'Final Dev CWA: 0.7714, Dev SWA:\n0.7749', '\\n', '\\n=== Training with max_epochs = 50 ===', '\\n', 'Epoch 1/50:\ntrain_loss=0.6720, val_loss=0.6493, val_CompWA=0.6618', '\\n', 'Epoch 2/50:\ntrain_loss=0.6329, val_loss=0.6136, val_CompWA=0.6877', '\\n', 'Epoch 3/50:\ntrain_loss=0.6021, val_loss=0.5880, val_CompWA=0.6987', '\\n', 'Epoch 4/50:\ntrain_loss=0.5826, val_loss=0.5743, val_CompWA=0.7174', '\\n', 'Epoch 5/50:\ntrain_loss=0.5712, val_loss=0.5643, val_CompWA=0.7227', '\\n', 'Epoch 6/50:\ntrain_loss=0.5620, val_loss=0.5556, val_CompWA=0.7283', '\\n', 'Epoch 7/50:\ntrain_loss=0.5535, val_loss=0.5470, val_CompWA=0.7245', '\\n', 'Epoch 8/50:\ntrain_loss=0.5452, val_loss=0.5382, val_CompWA=0.7309', '\\n', 'Epoch 9/50:\ntrain_loss=0.5367, val_loss=0.5292, val_CompWA=0.7341', '\\n', 'Epoch 10/50:\ntrain_loss=0.5280, val_loss=0.5204, val_CompWA=0.7353', '\\n', 'Epoch 11/50:\ntrain_loss=0.5193, val_loss=0.5117, val_CompWA=0.7397', '\\n', 'Epoch 12/50:\ntrain_loss=0.5112, val_loss=0.5033, val_CompWA=0.7416', '\\n', 'Epoch 13/50:\ntrain_loss=0.5036, val_loss=0.4960, val_CompWA=0.7441', '\\n', 'Epoch 14/50:\ntrain_loss=0.4974, val_loss=0.4902, val_CompWA=0.7470', '\\n', 'Epoch 15/50:\ntrain_loss=0.4920, val_loss=0.4850, val_CompWA=0.7488', '\\n', 'Epoch 16/50:\ntrain_loss=0.4878, val_loss=0.4808, val_CompWA=0.7542', '\\n', 'Epoch 17/50:\ntrain_loss=0.4839, val_loss=0.4778, val_CompWA=0.7563', '\\n', 'Epoch 18/50:\ntrain_loss=0.4812, val_loss=0.4745, val_CompWA=0.7569', '\\n', 'Epoch 19/50:\ntrain_loss=0.4781, val_loss=0.4718, val_CompWA=0.7565', '\\n', 'Epoch 20/50:\ntrain_loss=0.4758, val_loss=0.4694, val_CompWA=0.7582', '\\n', 'Epoch 21/50:\ntrain_loss=0.4737, val_loss=0.4676, val_CompWA=0.7570', '\\n', 'Epoch 22/50:\ntrain_loss=0.4718, val_loss=0.4661, val_CompWA=0.7666', '\\n', 'Epoch 23/50:\ntrain_loss=0.4704, val_loss=0.4644, val_CompWA=0.7611', '\\n', 'Epoch 24/50:\ntrain_loss=0.4685, val_loss=0.4633, val_CompWA=0.7666', '\\n', 'Epoch 25/50:\ntrain_loss=0.4678, val_loss=0.4616, val_CompWA=0.7677', '\\n', 'Epoch 26/50:\ntrain_loss=0.4667, val_loss=0.4604, val_CompWA=0.7679', '\\n', 'Epoch 27/50:\ntrain_loss=0.4653, val_loss=0.4591, val_CompWA=0.7686', '\\n', 'Epoch 28/50:\ntrain_loss=0.4643, val_loss=0.4584, val_CompWA=0.7694', '\\n', 'Epoch 29/50:\ntrain_loss=0.4634, val_loss=0.4575, val_CompWA=0.7679', '\\n', 'Epoch 30/50:\ntrain_loss=0.4625, val_loss=0.4565, val_CompWA=0.7681', '\\n', 'Epoch 31/50:\ntrain_loss=0.4622, val_loss=0.4558, val_CompWA=0.7667', '\\n', 'Epoch 32/50:\ntrain_loss=0.4612, val_loss=0.4550, val_CompWA=0.7694', '\\n', 'Epoch 33/50:\ntrain_loss=0.4602, val_loss=0.4541, val_CompWA=0.7682', '\\n', 'Epoch 34/50:\ntrain_loss=0.4599, val_loss=0.4534, val_CompWA=0.7669', '\\n', 'Epoch 35/50:\ntrain_loss=0.4586, val_loss=0.4526, val_CompWA=0.7677', '\\n', 'Epoch 36/50:\ntrain_loss=0.4580, val_loss=0.4518, val_CompWA=0.7680', '\\n', 'Epoch 37/50:\ntrain_loss=0.4571, val_loss=0.4514, val_CompWA=0.7690', '\\n', 'Epoch 38/50:\ntrain_loss=0.4563, val_loss=0.4508, val_CompWA=0.7698', '\\n', 'Epoch 39/50:\ntrain_loss=0.4560, val_loss=0.4500, val_CompWA=0.7694', '\\n', 'Epoch 40/50:\ntrain_loss=0.4553, val_loss=0.4490, val_CompWA=0.7688', '\\n', 'Epoch 41/50:\ntrain_loss=0.4545, val_loss=0.4486, val_CompWA=0.7691', '\\n', 'Epoch 42/50:\ntrain_loss=0.4541, val_loss=0.4484, val_CompWA=0.7685', '\\n', 'Epoch 43/50:\ntrain_loss=0.4535, val_loss=0.4475, val_CompWA=0.7676', '\\n', 'Epoch 44/50:\ntrain_loss=0.4529, val_loss=0.4470, val_CompWA=0.7681', '\\n', 'Epoch 45/50:\ntrain_loss=0.4523, val_loss=0.4466, val_CompWA=0.7679', '\\n', 'Epoch 46/50:\ntrain_loss=0.4517, val_loss=0.4461, val_CompWA=0.7693', '\\n', 'Epoch 47/50:\ntrain_loss=0.4513, val_loss=0.4458, val_CompWA=0.7695', '\\n', 'Epoch 48/50:\ntrain_loss=0.4506, val_loss=0.4451, val_CompWA=0.7719', '\\n', 'Epoch 49/50:\ntrain_loss=0.4503, val_loss=0.4446, val_CompWA=0.7707', '\\n', 'Epoch 50/50:\ntrain_loss=0.4498, val_loss=0.4441, val_CompWA=0.7711', '\\n', 'Final Dev CWA:\n0.7698, Dev SWA: 0.7723', '\\n', 'Saved experiment_data.npy', '\\n', 'Execution\ntime: a minute seconds (time limit is 30 minutes).']", "['\\rGenerating train split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating\ntrain split: 20000 examples [00:00, 533657.02 examples/s]', '\\n', '\\rGenerating\ntrain split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating train split:\n5000 examples [00:00, 571228.72 examples/s]', '\\n', '\\rGenerating train split: 0\nexamples [00:00, ? examples/s]', '', '\\rGenerating train split: 10000 examples\n[00:00, 670048.72 examples/s]', '\\n', 'Using device:', ' ', 'cuda', '\\n',\n'\\n---- Training with learning_rate = 0.0005 ----', '\\n', 'Epoch 1:\ntrain_loss=0.6852, val_loss=0.6761, val_CompWA=0.6422', '\\n', 'Epoch 2:\ntrain_loss=0.6660, val_loss=0.6562, val_CompWA=0.6842', '\\n', 'Epoch 3:\ntrain_loss=0.6465, val_loss=0.6357, val_CompWA=0.6985', '\\n', 'Epoch 4:\ntrain_loss=0.6271, val_loss=0.6157, val_CompWA=0.7007', '\\n', 'Epoch 5:\ntrain_loss=0.6092, val_loss=0.5990, val_CompWA=0.7006', '\\n', 'Run summary\n(lr=0.0005): Dev CWA=0.6972, Dev SWA=0.7039', '\\n', '\\n---- Training with\nlearning_rate = 0.001 ----', '\\n', 'Epoch 1: train_loss=0.6794, val_loss=0.6542,\nval_CompWA=0.6789', '\\n', 'Epoch 2: train_loss=0.6400, val_loss=0.6174,\nval_CompWA=0.7065', '\\n', 'Epoch 3: train_loss=0.6051, val_loss=0.5872,\nval_CompWA=0.7118', '\\n', 'Epoch 4: train_loss=0.5821, val_loss=0.5706,\nval_CompWA=0.7214', '\\n', 'Epoch 5: train_loss=0.5684, val_loss=0.5600,\nval_CompWA=0.7229', '\\n', 'Run summary (lr=0.001): Dev CWA=0.7202, Dev\nSWA=0.7256', '\\n', '\\n---- Training with learning_rate = 0.003 ----', '\\n',\n'Epoch 1: train_loss=0.6591, val_loss=0.6107, val_CompWA=0.6834', '\\n', 'Epoch\n2: train_loss=0.5830, val_loss=0.5564, val_CompWA=0.7225', '\\n', 'Epoch 3:\ntrain_loss=0.5440, val_loss=0.5241, val_CompWA=0.7314', '\\n', 'Epoch 4:\ntrain_loss=0.5163, val_loss=0.5009, val_CompWA=0.7397', '\\n', 'Epoch 5:\ntrain_loss=0.4996, val_loss=0.4855, val_CompWA=0.7496', '\\n', 'Run summary\n(lr=0.003): Dev CWA=0.7473, Dev SWA=0.7518', '\\n', '\\nSaved experiment data to',\n' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_14-12-\n13_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n7/working/experiment_data.npy', '\\n', 'Execution time: 49 seconds seconds (time\nlimit is 30 minutes).']", "['\\rGenerating train split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating\ntrain split: 20000 examples [00:00, 204463.55 examples/s]', '\\n', '\\rGenerating\ntrain split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating train split:\n5000 examples [00:00, 426493.13 examples/s]', '\\n', '\\rGenerating train split: 0\nexamples [00:00, ? examples/s]', '', '\\rGenerating train split: 10000 examples\n[00:00, 262638.09 examples/s]', '\\n', '\\n=== Training with batch_size = 128\n===', '\\n', 'Epoch 1: val_loss=0.5803, val_CompWA=0.6958', '\\n', 'Epoch 2:\nval_loss=0.5455, val_CompWA=0.7239', '\\n', 'Epoch 3: val_loss=0.5225,\nval_CompWA=0.7322', '\\n', 'Epoch 4: val_loss=0.5035, val_CompWA=0.7383', '\\n',\n'Epoch 5: val_loss=0.4896, val_CompWA=0.7481', '\\n', 'Final Dev CWA=0.7457,\nSWA=0.7504', '\\n', '\\n=== Training with batch_size = 256 ===', '\\n', 'Epoch 1:\nval_loss=0.6212, val_CompWA=0.6990', '\\n', 'Epoch 2: val_loss=0.5732,\nval_CompWA=0.7181', '\\n', 'Epoch 3: val_loss=0.5542, val_CompWA=0.7255', '\\n',\n'Epoch 4: val_loss=0.5404, val_CompWA=0.7310', '\\n', 'Epoch 5: val_loss=0.5284,\nval_CompWA=0.7344', '\\n', 'Final Dev CWA=0.7308, SWA=0.7379', '\\n', '\\n===\nTraining with batch_size = 512 ===', '\\n', 'Epoch 1: val_loss=0.6686,\nval_CompWA=0.6343', '\\n', 'Epoch 2: val_loss=0.6368, val_CompWA=0.6775', '\\n',\n'Epoch 3: val_loss=0.6035, val_CompWA=0.6958', '\\n', 'Epoch 4: val_loss=0.5793,\nval_CompWA=0.7110', '\\n', 'Epoch 5: val_loss=0.5630, val_CompWA=0.7153', '\\n',\n'Final Dev CWA=0.7128, SWA=0.7178', '\\n', '\\n=== Training with batch_size = 1024\n===', '\\n', 'Epoch 1: val_loss=0.6712, val_CompWA=0.5905', '\\n', 'Epoch 2:\nval_loss=0.6513, val_CompWA=0.6323', '\\n', 'Epoch 3: val_loss=0.6318,\nval_CompWA=0.6664', '\\n', 'Epoch 4: val_loss=0.6127, val_CompWA=0.6819', '\\n',\n'Epoch 5: val_loss=0.5953, val_CompWA=0.6946', '\\n', 'Final Dev CWA=0.6920,\nSWA=0.6970', '\\n', \"\\nSaved all experiment data to\n'working/experiment_data.npy'\", '\\n', 'Execution time: 51 seconds seconds (time\nlimit is 30 minutes).']", "['\\rGenerating train split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating\ntrain split: 20000 examples [00:00, 610342.47 examples/s]', '\\n', '\\rGenerating\ntrain split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating train split:\n5000 examples [00:00, 310606.36 examples/s]', '\\n', '\\rGenerating train split: 0\nexamples [00:00, ? examples/s]', '', '\\rGenerating train split: 10000 examples\n[00:00, 545182.10 examples/s]', '\\n', 'Using device:', ' ', 'cuda', '\\n', '[hdim\n16] Epoch 1: train_loss 0.6843, val_loss 0.6757, val_CompWA 0.5881', '\\n',\n'[hdim 16] Epoch 2: train_loss 0.6687, val_loss 0.6578, val_CompWA 0.6386',\n'\\n', '[hdim 16] Epoch 3: train_loss 0.6480, val_loss 0.6332, val_CompWA\n0.6733', '\\n', '[hdim 16] Epoch 4: train_loss 0.6223, val_loss 0.6065,\nval_CompWA 0.6970', '\\n', '[hdim 16] Epoch 5: train_loss 0.5981, val_loss\n0.5856, val_CompWA 0.7066', '\\n', '[hdim 16] Final Dev CWA 0.7033, SWA 0.7098',\n'\\n', '[hdim 32] Epoch 1: train_loss 0.6673, val_loss 0.6434, val_CompWA\n0.6816', '\\n', '[hdim 32] Epoch 2: train_loss 0.6234, val_loss 0.6042,\nval_CompWA 0.7064', '\\n', '[hdim 32] Epoch 3: train_loss 0.5920, val_loss\n0.5802, val_CompWA 0.6987', '\\n', '[hdim 32] Epoch 4: train_loss 0.5748,\nval_loss 0.5659, val_CompWA 0.7144', '\\n', '[hdim 32] Epoch 5: train_loss\n0.5623, val_loss 0.5537, val_CompWA 0.7230', '\\n', '[hdim 32] Final Dev CWA\n0.7194, SWA 0.7265', '\\n', '[hdim 64] Epoch 1: train_loss 0.6817, val_loss\n0.6486, val_CompWA 0.6797', '\\n', '[hdim 64] Epoch 2: train_loss 0.6262,\nval_loss 0.6062, val_CompWA 0.7174', '\\n', '[hdim 64] Epoch 3: train_loss\n0.5935, val_loss 0.5817, val_CompWA 0.7117', '\\n', '[hdim 64] Epoch 4:\ntrain_loss 0.5755, val_loss 0.5678, val_CompWA 0.7171', '\\n', '[hdim 64] Epoch\n5: train_loss 0.5638, val_loss 0.5563, val_CompWA 0.7195', '\\n', '[hdim 64]\nFinal Dev CWA 0.7172, SWA 0.7217', '\\n', '[hdim 128] Epoch 1: train_loss 0.6367,\nval_loss 0.6011, val_CompWA 0.6994', '\\n', '[hdim 128] Epoch 2: train_loss\n0.5894, val_loss 0.5756, val_CompWA 0.7104', '\\n', '[hdim 128] Epoch 3:\ntrain_loss 0.5687, val_loss 0.5594, val_CompWA 0.7197', '\\n', '[hdim 128] Epoch\n4: train_loss 0.5515, val_loss 0.5412, val_CompWA 0.7285', '\\n', '[hdim 128]\nEpoch 5: train_loss 0.5332, val_loss 0.5216, val_CompWA 0.7329', '\\n', '[hdim\n128] Final Dev CWA 0.7297, SWA 0.7358', '\\n', '[hdim 256] Epoch 1: train_loss\n0.6300, val_loss 0.5857, val_CompWA 0.7024', '\\n', '[hdim 256] Epoch 2:\ntrain_loss 0.5715, val_loss 0.5575, val_CompWA 0.7303', '\\n', '[hdim 256] Epoch\n3: train_loss 0.5462, val_loss 0.5310, val_CompWA 0.7368', '\\n', '[hdim 256]\nEpoch 4: train_loss 0.5213, val_loss 0.5071, val_CompWA 0.7448', '\\n', '[hdim\n256] Epoch 5: train_loss 0.5005, val_loss 0.4884, val_CompWA 0.7510', '\\n',\n'[hdim 256] Final Dev CWA 0.7494, SWA 0.7526', '\\n', 'Saved experiment data to',\n' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_14-12-\n13_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n9/working/experiment_data.npy', '\\n', 'Execution time: 54 seconds seconds (time\nlimit is 30 minutes).']", "['[wd=0.0] epoch 1: train_loss=0.6729 val_loss=0.6578 val_CompWA=0.6810', '\\n',\n'[wd=0.0] epoch 2: train_loss=0.6470 val_loss=0.6312 val_CompWA=0.6778', '\\n',\n'[wd=0.0] epoch 3: train_loss=0.6195 val_loss=0.6033 val_CompWA=0.6834', '\\n',\n'[wd=0.0] epoch 4: train_loss=0.5961 val_loss=0.5841 val_CompWA=0.6913', '\\n',\n'[wd=0.0] epoch 5: train_loss=0.5797 val_loss=0.5696 val_CompWA=0.7213', '\\n',\n'[wd=1e-05] epoch 1: train_loss=0.6940 val_loss=0.6703 val_CompWA=0.5684', '\\n',\n'[wd=1e-05] epoch 2: train_loss=0.6560 val_loss=0.6339 val_CompWA=0.6865', '\\n',\n'[wd=1e-05] epoch 3: train_loss=0.6205 val_loss=0.5999 val_CompWA=0.7067', '\\n',\n'[wd=1e-05] epoch 4: train_loss=0.5902 val_loss=0.5755 val_CompWA=0.7101', '\\n',\n'[wd=1e-05] epoch 5: train_loss=0.5702 val_loss=0.5603 val_CompWA=0.7200', '\\n',\n'[wd=0.0001] epoch 1: train_loss=0.6914 val_loss=0.6740 val_CompWA=0.6010',\n'\\n', '[wd=0.0001] epoch 2: train_loss=0.6558 val_loss=0.6377\nval_CompWA=0.6825', '\\n', '[wd=0.0001] epoch 3: train_loss=0.6197\nval_loss=0.6038 val_CompWA=0.7062', '\\n', '[wd=0.0001] epoch 4:\ntrain_loss=0.5919 val_loss=0.5818 val_CompWA=0.7105', '\\n', '[wd=0.0001] epoch\n5: train_loss=0.5760 val_loss=0.5699 val_CompWA=0.7212', '\\n', '[wd=0.001] epoch\n1: train_loss=0.6717 val_loss=0.6548 val_CompWA=0.6752', '\\n', '[wd=0.001] epoch\n2: train_loss=0.6425 val_loss=0.6254 val_CompWA=0.6928', '\\n', '[wd=0.001] epoch\n3: train_loss=0.6152 val_loss=0.6011 val_CompWA=0.6999', '\\n', '[wd=0.001] epoch\n4: train_loss=0.5956 val_loss=0.5869 val_CompWA=0.7086', '\\n', '[wd=0.001] epoch\n5: train_loss=0.5836 val_loss=0.5775 val_CompWA=0.7104', '\\n', '[wd=0.01] epoch\n1: train_loss=0.6672 val_loss=0.6478 val_CompWA=0.6844', '\\n', '[wd=0.01] epoch\n2: train_loss=0.6338 val_loss=0.6163 val_CompWA=0.6988', '\\n', '[wd=0.01] epoch\n3: train_loss=0.6068 val_loss=0.5935 val_CompWA=0.7018', '\\n', '[wd=0.01] epoch\n4: train_loss=0.5888 val_loss=0.5802 val_CompWA=0.7150', '\\n', '[wd=0.01] epoch\n5: train_loss=0.5776 val_loss=0.5701 val_CompWA=0.7148', '\\n', 'Execution time:\n55 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\n===== Training with k = 4 clusters =====', '\\n',\n'Epoch 1: val_loss=0.6708, val_CompWA=0.6322', '\\n', 'Epoch 2: val_loss=0.6421,\nval_CompWA=0.6511', '\\n', 'Epoch 3: val_loss=0.6224, val_CompWA=0.6689', '\\n',\n'Epoch 4: val_loss=0.6099, val_CompWA=0.6475', '\\n', 'Epoch 5: val_loss=0.6003,\nval_CompWA=0.6435', '\\n', 'k=4 -> Dev CWA: 0.6449, Dev SWA: 0.6423', '\\n',\n'\\n===== Training with k = 8 clusters =====', '\\n', 'Epoch 1: val_loss=0.6637,\nval_CompWA=0.6428', '\\n', 'Epoch 2: val_loss=0.6244, val_CompWA=0.7079', '\\n',\n'Epoch 3: val_loss=0.5940, val_CompWA=0.7121', '\\n', 'Epoch 4: val_loss=0.5761,\nval_CompWA=0.7142', '\\n', 'Epoch 5: val_loss=0.5646, val_CompWA=0.7220', '\\n',\n'k=8 -> Dev CWA: 0.7185, Dev SWA: 0.7254', '\\n', '\\n===== Training with k = 16\nclusters =====', '\\n', 'Epoch 1: val_loss=0.6489, val_CompWA=0.7023', '\\n',\n'Epoch 2: val_loss=0.5952, val_CompWA=0.7319', '\\n', 'Epoch 3: val_loss=0.5489,\nval_CompWA=0.7409', '\\n', 'Epoch 4: val_loss=0.5231, val_CompWA=0.7461', '\\n',\n'Epoch 5: val_loss=0.5100, val_CompWA=0.7455', '\\n', 'k=16 -> Dev CWA: 0.7436,\nDev SWA: 0.7472', '\\n', '\\n===== Training with k = 32 clusters =====', '\\n',\n'Epoch 1: val_loss=0.6477, val_CompWA=0.6767', '\\n', 'Epoch 2: val_loss=0.5969,\nval_CompWA=0.7293', '\\n', 'Epoch 3: val_loss=0.5400, val_CompWA=0.7311', '\\n',\n'Epoch 4: val_loss=0.4944, val_CompWA=0.7677', '\\n', 'Epoch 5: val_loss=0.4630,\nval_CompWA=0.7960', '\\n', 'k=32 -> Dev CWA: 0.7951, Dev SWA: 0.7968', '\\n',\n\"\\nAll experiments finished and saved to 'experiment_data.npy'.\", '\\n',\n'Execution time: 3 minutes seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '[pw=1] Epoch 1: val_loss=0.6561,\nval_CompWA=0.6778', '\\n', '[pw=1] Epoch 2: val_loss=0.6169, val_CompWA=0.6992',\n'\\n', '[pw=1] Epoch 3: val_loss=0.5876, val_CompWA=0.7083', '\\n', '[pw=1] Epoch\n4: val_loss=0.5720, val_CompWA=0.7120', '\\n', '[pw=1] Epoch 5: val_loss=0.5610,\nval_CompWA=0.7190', '\\n', '[pw=1] Final Dev CWA: 0.7158, SWA: 0.7222', '\\n',\n'[pw=2] Epoch 1: val_loss=0.9005, val_CompWA=0.5133', '\\n', '[pw=2] Epoch 2:\nval_loss=0.8474, val_CompWA=0.5934', '\\n', '[pw=2] Epoch 3: val_loss=0.8011,\nval_CompWA=0.6780', '\\n', '[pw=2] Epoch 4: val_loss=0.7749, val_CompWA=0.7029',\n'\\n', '[pw=2] Epoch 5: val_loss=0.7592, val_CompWA=0.7204', '\\n', '[pw=2] Final\nDev CWA: 0.7174, SWA: 0.7233', '\\n', '[pw=4] Epoch 1: val_loss=1.4184,\nval_CompWA=0.5111', '\\n', '[pw=4] Epoch 2: val_loss=1.2532, val_CompWA=0.5111',\n'\\n', '[pw=4] Epoch 3: val_loss=1.1850, val_CompWA=0.5111', '\\n', '[pw=4] Epoch\n4: val_loss=1.1118, val_CompWA=0.5174', '\\n', '[pw=4] Epoch 5: val_loss=1.0535,\nval_CompWA=0.5809', '\\n', '[pw=4] Final Dev CWA: 0.5757, SWA: 0.5858', '\\n',\n'[pw=8] Epoch 1: val_loss=2.2118, val_CompWA=0.5111', '\\n', '[pw=8] Epoch 2:\nval_loss=1.7102, val_CompWA=0.5111', '\\n', '[pw=8] Epoch 3: val_loss=1.5820,\nval_CompWA=0.5111', '\\n', '[pw=8] Epoch 4: val_loss=1.5067, val_CompWA=0.5111',\n'\\n', '[pw=8] Epoch 5: val_loss=1.4198, val_CompWA=0.5112', '\\n', '[pw=8] Final\nDev CWA: 0.5012, SWA: 0.5207', '\\n', \"Experiment data saved to\n'working/experiment_data.npy'\", '\\n', 'Execution time: 49 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '[p=0.0] Epoch 1: val_loss 0.6561,\nval_CompWA 0.6778', '\\n', '[p=0.0] Epoch 2: val_loss 0.6169, val_CompWA 0.6992',\n'\\n', '[p=0.0] Epoch 3: val_loss 0.5876, val_CompWA 0.7083', '\\n', '[p=0.0]\nEpoch 4: val_loss 0.5720, val_CompWA 0.7120', '\\n', '[p=0.0] Epoch 5: val_loss\n0.5610, val_CompWA 0.7190', '\\n', '[p=0.0] Dev CWA 0.7158, Dev SWA 0.7222',\n'\\n', '[p=0.1] Epoch 1: val_loss 0.6545, val_CompWA 0.6772', '\\n', '[p=0.1]\nEpoch 2: val_loss 0.6183, val_CompWA 0.7047', '\\n', '[p=0.1] Epoch 3: val_loss\n0.5884, val_CompWA 0.7090', '\\n', '[p=0.1] Epoch 4: val_loss 0.5716, val_CompWA\n0.7207', '\\n', '[p=0.1] Epoch 5: val_loss 0.5606, val_CompWA 0.7232', '\\n',\n'[p=0.1] Dev CWA 0.7204, Dev SWA 0.7258', '\\n', '[p=0.3] Epoch 1: val_loss\n0.6697, val_CompWA 0.6316', '\\n', '[p=0.3] Epoch 2: val_loss 0.6408, val_CompWA\n0.6774', '\\n', '[p=0.3] Epoch 3: val_loss 0.6102, val_CompWA 0.6906', '\\n',\n'[p=0.3] Epoch 4: val_loss 0.5857, val_CompWA 0.7007', '\\n', '[p=0.3] Epoch 5:\nval_loss 0.5686, val_CompWA 0.7099', '\\n', '[p=0.3] Dev CWA 0.7075, Dev SWA\n0.7122', '\\n', '[p=0.5] Epoch 1: val_loss 0.6565, val_CompWA 0.6230', '\\n',\n'[p=0.5] Epoch 2: val_loss 0.6263, val_CompWA 0.6634', '\\n', '[p=0.5] Epoch 3:\nval_loss 0.6005, val_CompWA 0.6905', '\\n', '[p=0.5] Epoch 4: val_loss 0.5776,\nval_CompWA 0.7066', '\\n', '[p=0.5] Epoch 5: val_loss 0.5607, val_CompWA 0.7198',\n'\\n', '[p=0.5] Dev CWA 0.7173, Dev SWA 0.7222', '\\n', 'Saved\nexperiment_data.npy', '\\n', 'Execution time: 51 seconds seconds (time limit is\n30 minutes).']", "['Using device: cuda', '\\n', '\\n===== Training with k = 4 clusters =====', '\\n',\n'Epoch 1: val_loss=0.6793, val_CompWA=0.5711', '\\n', 'Epoch 2: val_loss=0.6468,\nval_CompWA=0.6717', '\\n', 'Epoch 3: val_loss=0.6254, val_CompWA=0.6456', '\\n',\n'Epoch 4: val_loss=0.6092, val_CompWA=0.6645', '\\n', 'Epoch 5: val_loss=0.5948,\nval_CompWA=0.6448', '\\n', 'k=4 -> Dev CWA: 0.6469, Dev SWA: 0.6429', '\\n',\n'\\n===== Training with k = 8 clusters =====', '\\n', 'Epoch 1: val_loss=0.6772,\nval_CompWA=0.5802', '\\n', 'Epoch 2: val_loss=0.6377, val_CompWA=0.6823', '\\n',\n'Epoch 3: val_loss=0.6017, val_CompWA=0.6992', '\\n', 'Epoch 4: val_loss=0.5789,\nval_CompWA=0.7056', '\\n', 'Epoch 5: val_loss=0.5653, val_CompWA=0.7157', '\\n',\n'k=8 -> Dev CWA: 0.7131, Dev SWA: 0.7181', '\\n', '\\n===== Training with k = 16\nclusters =====', '\\n', 'Epoch 1: val_loss=0.6508, val_CompWA=0.7102', '\\n',\n'Epoch 2: val_loss=0.5981, val_CompWA=0.7379', '\\n', 'Epoch 3: val_loss=0.5418,\nval_CompWA=0.7579', '\\n', 'Epoch 4: val_loss=0.5019, val_CompWA=0.7802', '\\n',\n'Epoch 5: val_loss=0.4762, val_CompWA=0.7927', '\\n', 'k=16 -> Dev CWA: 0.7924,\nDev SWA: 0.7929', '\\n', '\\n===== Training with k = 32 clusters =====', '\\n',\n'Epoch 1: val_loss=0.6622, val_CompWA=0.7267', '\\n', 'Epoch 2: val_loss=0.6036,\nval_CompWA=0.7532', '\\n', 'Epoch 3: val_loss=0.5430, val_CompWA=0.7595', '\\n',\n'Epoch 4: val_loss=0.5049, val_CompWA=0.7737', '\\n', 'Epoch 5: val_loss=0.4795,\nval_CompWA=0.7908', '\\n', 'k=32 -> Dev CWA: 0.7901, Dev SWA: 0.7914', '\\n',\n\"\\nAll experiments finished and saved to 'experiment_data.npy'.\", '\\n',\n'Execution time: 3 minutes seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\n===== Training with k = 4 clusters =====', '\\n',\n'Epoch 1: val_loss=0.6629, val_CompWA=0.6492', '\\n', 'Epoch 2: val_loss=0.6361,\nval_CompWA=0.6471', '\\n', 'Epoch 3: val_loss=0.6226, val_CompWA=0.6432', '\\n',\n'Epoch 4: val_loss=0.6163, val_CompWA=0.6525', '\\n', 'Epoch 5: val_loss=0.6110,\nval_CompWA=0.6525', '\\n', 'k=4 -> Dev CWA: 0.6533, Dev SWA: 0.6518', '\\n',\n'\\n===== Training with k = 8 clusters =====', '\\n', 'Epoch 1: val_loss=0.6605,\nval_CompWA=0.6525', '\\n', 'Epoch 2: val_loss=0.6267, val_CompWA=0.7032', '\\n',\n'Epoch 3: val_loss=0.5955, val_CompWA=0.7100', '\\n', 'Epoch 4: val_loss=0.5740,\nval_CompWA=0.7199', '\\n', 'Epoch 5: val_loss=0.5574, val_CompWA=0.7221', '\\n',\n'k=8 -> Dev CWA: 0.7197, Dev SWA: 0.7243', '\\n', '\\n===== Training with k = 16\nclusters =====', '\\n', 'Epoch 1: val_loss=0.6437, val_CompWA=0.7125', '\\n',\n'Epoch 2: val_loss=0.5953, val_CompWA=0.7381', '\\n', 'Epoch 3: val_loss=0.5453,\nval_CompWA=0.7592', '\\n', 'Epoch 4: val_loss=0.5069, val_CompWA=0.7612', '\\n',\n'Epoch 5: val_loss=0.4813, val_CompWA=0.7827', '\\n', 'k=16 -> Dev CWA: 0.7818,\nDev SWA: 0.7835', '\\n', '\\n===== Training with k = 32 clusters =====', '\\n',\n'Epoch 1: val_loss=0.6565, val_CompWA=0.6876', '\\n', 'Epoch 2: val_loss=0.6050,\nval_CompWA=0.7335', '\\n', 'Epoch 3: val_loss=0.5512, val_CompWA=0.7549', '\\n',\n'Epoch 4: val_loss=0.5125, val_CompWA=0.7670', '\\n', 'Epoch 5: val_loss=0.4824,\nval_CompWA=0.7786', '\\n', 'k=32 -> Dev CWA: 0.7784, Dev SWA: 0.7788', '\\n',\n\"\\nAll experiments finished and saved to 'experiment_data.npy'.\", '\\n',\n'Execution time: 3 minutes seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\n===== Training with k = 4 clusters =====', '\\n',\n'Epoch 1: val_loss=0.6565, val_CompWA=0.6437', '\\n', 'Epoch 2: val_loss=0.6313,\nval_CompWA=0.6411', '\\n', 'Epoch 3: val_loss=0.6150, val_CompWA=0.6438', '\\n',\n'Epoch 4: val_loss=0.6035, val_CompWA=0.6793', '\\n', 'Epoch 5: val_loss=0.5936,\nval_CompWA=0.6811', '\\n', 'k=4 -> Dev CWA: 0.6804, Dev SWA: 0.6818', '\\n',\n'\\n===== Training with k = 8 clusters =====', '\\n', 'Epoch 1: val_loss=0.6448,\nval_CompWA=0.6709', '\\n', 'Epoch 2: val_loss=0.6117, val_CompWA=0.6881', '\\n',\n'Epoch 3: val_loss=0.5855, val_CompWA=0.6992', '\\n', 'Epoch 4: val_loss=0.5675,\nval_CompWA=0.7185', '\\n', 'Epoch 5: val_loss=0.5532, val_CompWA=0.7272', '\\n',\n'k=8 -> Dev CWA: 0.7238, Dev SWA: 0.7305', '\\n', '\\n===== Training with k = 16\nclusters =====', '\\n', 'Epoch 1: val_loss=0.6494, val_CompWA=0.6907', '\\n',\n'Epoch 2: val_loss=0.6017, val_CompWA=0.7250', '\\n', 'Epoch 3: val_loss=0.5489,\nval_CompWA=0.7485', '\\n', 'Epoch 4: val_loss=0.5059, val_CompWA=0.7674', '\\n',\n'Epoch 5: val_loss=0.4779, val_CompWA=0.7829', '\\n', 'k=16 -> Dev CWA: 0.7829,\nDev SWA: 0.7829', '\\n', '\\n===== Training with k = 32 clusters =====', '\\n',\n'Epoch 1: val_loss=0.6553, val_CompWA=0.6772', '\\n', 'Epoch 2: val_loss=0.6034,\nval_CompWA=0.7259', '\\n', 'Epoch 3: val_loss=0.5524, val_CompWA=0.7464', '\\n',\n'Epoch 4: val_loss=0.5193, val_CompWA=0.7507', '\\n', 'Epoch 5: val_loss=0.4978,\nval_CompWA=0.7761', '\\n', 'k=32 -> Dev CWA: 0.7755, Dev SWA: 0.7768', '\\n',\n\"\\nAll experiments finished and saved to 'experiment_data.npy'.\", '\\n',\n'Execution time: 3 minutes seconds (time limit is 30 minutes).']", ""], "analysis": ["", "", "The execution output demonstrates successful training of the model with varying\nlearning rates. The training and validation losses decrease consistently across\nepochs, and the Complexity-Weighted Accuracy (CompWA) improves with each\nlearning rate. The final results surpass the stated SOTA metrics for both Color-\nWeighted Accuracy (CWA) and Shape-Weighted Accuracy (SWA), achieving 74.73% and\n75.18% respectively for the best learning rate (0.003). There are no errors or\nbugs in the implementation, and the experiment data is saved correctly for\nfurther analysis.", "", "The execution output shows that the training script ran successfully without any\nerrors or bugs. The script performed a hyperparameter sweep over different\nhidden dimensions for the neural network. The metrics, including train and\nvalidation losses, as well as complexity-weighted accuracy (CompWA), were logged\nand improved over epochs. Final metrics for color-weighted accuracy (CWA) and\nshape-weighted accuracy (SWA) surpassed the stated SOTA thresholds of 70% and\n65%, respectively. The results were saved successfully, and the execution\ncompleted within the time limit. No issues were detected.", "", "The execution of the code was successful with no bugs. The training process\niterated over different values of k (number of clusters) and showed steady\nimprovements in the evaluation metrics (CWA and SWA) as k increased. The final\nresults exceeded the State-of-the-Art (SOTA) performance benchmarks, achieving a\nCWA of 0.7951 and SWA of 0.7968 for k=32 clusters. The output was saved\nsuccessfully to 'experiment_data.npy'. No issues were detected in the\nimplementation or execution.", "The execution output shows that the training script ran successfully without any\nerrors or bugs. The model was trained with different values of the 'pos_weight'\nhyperparameter, and the performance was evaluated using the given metrics. The\nresults indicate that the best performance was achieved with 'pos_weight=2',\nyielding a Color-Weighted Accuracy (CWA) of 71.74% and Shape-Weighted Accuracy\n(SWA) of 72.33%, which surpasses the stated SOTA benchmarks. The experiment data\nwas successfully saved to 'working/experiment_data.npy'. No issues were found in\nthe execution.", "The training script executed successfully without any bugs. The experiments\ntested different dropout probabilities (0.0, 0.1, 0.3, 0.5) to evaluate the\nimpact on validation loss, Complexity-Weighted Accuracy (CompWA), Color-Weighted\nAccuracy (CWA), and Shape-Weighted Accuracy (SWA). The results showed\nimprovement in metrics, especially for dropout values 0.0 and 0.1. The best\nperformance was achieved with a dropout of 0.1, yielding a Dev CWA of 0.7204 and\nDev SWA of 0.7258, surpassing the stated SOTA benchmarks (CWA: 70.0%, SWA:\n65.0%). Results were saved successfully.", "", "", "The execution output indicates that the training script ran successfully without\nany errors or bugs. The model was trained with different values of k (number of\nclusters) and achieved progressively better results for Color-Weighted Accuracy\n(CWA) and Shape-Weighted Accuracy (SWA) as k increased up to 16 clusters. The\nresults surpassed the stated SOTA performance thresholds (70.0% for CWA and\n65.0% for SWA) for k=8, k=16, and k=32, with the best performance observed at\nk=16 (CWA = 78.29%, SWA = 78.29%). The results were saved to\n'experiment_data.npy', and execution completed within the time limit. No issues\nwere found.", ""], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.569368, "best_value": 0.569368}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.561002, "best_value": 0.561002}]}, {"metric_name": "validation complexity weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during validation. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.719049, "best_value": 0.719049}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4498, "best_value": 0.4498}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4441, "best_value": 0.4441}]}, {"metric_name": "validation complexity weighted accuracy", "lower_is_better": false, "description": "The complexity weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7711, "best_value": 0.7711}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.499577, "best_value": 0.499577}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.485472, "best_value": 0.485472}]}, {"metric_name": "validation CompWA", "lower_is_better": false, "description": "The CompWA metric calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.74962, "best_value": 0.74962}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model fits the training data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.502, "best_value": 0.502}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset, indicating how well the model generalizes.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4896, "best_value": 0.4896}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "The accuracy on the validation dataset, adjusted for task complexity.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7481, "best_value": 0.7481}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated on the training dataset.", "data": [{"dataset_name": "SPR_BENCH_h16", "final_value": 0.5981, "best_value": 0.5981}, {"dataset_name": "SPR_BENCH_h32", "final_value": 0.5623, "best_value": 0.5623}, {"dataset_name": "SPR_BENCH_h64", "final_value": 0.5638, "best_value": 0.5638}, {"dataset_name": "SPR_BENCH_h128", "final_value": 0.5332, "best_value": 0.5332}, {"dataset_name": "SPR_BENCH_h256", "final_value": 0.5005, "best_value": 0.5005}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH_h16", "final_value": 0.5856, "best_value": 0.5856}, {"dataset_name": "SPR_BENCH_h32", "final_value": 0.5537, "best_value": 0.5537}, {"dataset_name": "SPR_BENCH_h64", "final_value": 0.5563, "best_value": 0.5563}, {"dataset_name": "SPR_BENCH_h128", "final_value": 0.5216, "best_value": 0.5216}, {"dataset_name": "SPR_BENCH_h256", "final_value": 0.4884, "best_value": 0.4884}]}, {"metric_name": "training complexity weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy achieved on the training dataset.", "data": [{"dataset_name": "SPR_BENCH_h16", "final_value": 0.788, "best_value": 0.788}, {"dataset_name": "SPR_BENCH_h32", "final_value": 0.5438, "best_value": 0.5438}, {"dataset_name": "SPR_BENCH_h64", "final_value": 0.7788, "best_value": 0.7788}, {"dataset_name": "SPR_BENCH_h128", "final_value": 0.788, "best_value": 0.788}, {"dataset_name": "SPR_BENCH_h256", "final_value": 0.871, "best_value": 0.871}]}, {"metric_name": "validation complexity weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy achieved on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH_h16", "final_value": 0.7066, "best_value": 0.7066}, {"dataset_name": "SPR_BENCH_h32", "final_value": 0.723, "best_value": 0.723}, {"dataset_name": "SPR_BENCH_h64", "final_value": 0.7195, "best_value": 0.7195}, {"dataset_name": "SPR_BENCH_h128", "final_value": 0.7329, "best_value": 0.7329}, {"dataset_name": "SPR_BENCH_h256", "final_value": 0.751, "best_value": 0.751}]}]}, {"metric_names": [{"metric_name": "complexity weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of predictions weighted by complexity.", "data": [{"dataset_name": "train", "final_value": 0.7122, "best_value": 0.7212}, {"dataset_name": "validation", "final_value": 0.7148, "best_value": 0.7213}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of color predictions weighted by their importance.", "data": [{"dataset_name": "validation", "final_value": 0.7123, "best_value": 0.7187}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of shape predictions weighted by their importance.", "data": [{"dataset_name": "validation", "final_value": 0.7172, "best_value": 0.7242}]}, {"metric_name": "loss", "lower_is_better": true, "description": "Measures the error rate during training or validation.", "data": [{"dataset_name": "train", "final_value": 0.5776, "best_value": 0.5702}, {"dataset_name": "validation", "final_value": 0.5701, "best_value": 0.5603}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.479093, "best_value": 0.479093}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.462989, "best_value": 0.462989}]}, {"metric_name": "validation Complexity-Weighted Accuracy", "lower_is_better": false, "description": "Measures the weighted accuracy on the validation dataset, considering complexity.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.795999, "best_value": 0.795999}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, which measures how well the model is performing on the training data.", "data": [{"dataset_name": "SPR_BENCH_pw1", "final_value": 0.569368, "best_value": 0.569368}, {"dataset_name": "SPR_BENCH_pw2", "final_value": 0.771132, "best_value": 0.771132}, {"dataset_name": "SPR_BENCH_pw4", "final_value": 1.085838, "best_value": 1.085838}, {"dataset_name": "SPR_BENCH_pw8", "final_value": 1.471439, "best_value": 1.471439}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset, which measures how well the model is performing on unseen data.", "data": [{"dataset_name": "SPR_BENCH_pw1", "final_value": 0.561002, "best_value": 0.561002}, {"dataset_name": "SPR_BENCH_pw2", "final_value": 0.759222, "best_value": 0.759222}, {"dataset_name": "SPR_BENCH_pw4", "final_value": 1.05345, "best_value": 1.05345}, {"dataset_name": "SPR_BENCH_pw8", "final_value": 1.419839, "best_value": 1.419839}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "The accuracy on the validation dataset, weighted by the complexity of the data.", "data": [{"dataset_name": "SPR_BENCH_pw1", "final_value": 0.719049, "best_value": 0.719049}, {"dataset_name": "SPR_BENCH_pw2", "final_value": 0.720418, "best_value": 0.720418}, {"dataset_name": "SPR_BENCH_pw4", "final_value": 0.580895, "best_value": 0.580895}, {"dataset_name": "SPR_BENCH_pw8", "final_value": 0.511178, "best_value": 0.511178}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The accuracy on the validation dataset, weighted by the color distribution of the data.", "data": [{"dataset_name": "SPR_BENCH_pw1", "final_value": 0.715759, "best_value": 0.715759}, {"dataset_name": "SPR_BENCH_pw2", "final_value": 0.717406, "best_value": 0.717406}, {"dataset_name": "SPR_BENCH_pw4", "final_value": 0.575743, "best_value": 0.575743}, {"dataset_name": "SPR_BENCH_pw8", "final_value": 0.50119, "best_value": 0.50119}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy on the validation dataset, weighted by the shape distribution of the data.", "data": [{"dataset_name": "SPR_BENCH_pw1", "final_value": 0.722183, "best_value": 0.722183}, {"dataset_name": "SPR_BENCH_pw2", "final_value": 0.723288, "best_value": 0.723288}, {"dataset_name": "SPR_BENCH_pw4", "final_value": 0.585804, "best_value": 0.585804}, {"dataset_name": "SPR_BENCH_pw8", "final_value": 0.520695, "best_value": 0.520695}]}]}, {"metric_names": [{"metric_name": "Training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is learning.", "data": [{"dataset_name": "dropout_prob_0.0", "final_value": 0.5694, "best_value": 0.5694}, {"dataset_name": "dropout_prob_0.1", "final_value": 0.5731, "best_value": 0.5731}, {"dataset_name": "dropout_prob_0.3", "final_value": 0.5897, "best_value": 0.5897}, {"dataset_name": "dropout_prob_0.5", "final_value": 0.587, "best_value": 0.587}]}, {"metric_name": "Validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset, used to evaluate model performance.", "data": [{"dataset_name": "dropout_prob_0.0", "final_value": 0.561, "best_value": 0.561}, {"dataset_name": "dropout_prob_0.1", "final_value": 0.5606, "best_value": 0.5606}, {"dataset_name": "dropout_prob_0.3", "final_value": 0.5686, "best_value": 0.5686}, {"dataset_name": "dropout_prob_0.5", "final_value": 0.5607, "best_value": 0.5607}]}, {"metric_name": "Validation CompWA", "lower_is_better": false, "description": "The composite weighted average metric on the validation dataset, indicating overall performance.", "data": [{"dataset_name": "dropout_prob_0.0", "final_value": 0.719, "best_value": 0.719}, {"dataset_name": "dropout_prob_0.1", "final_value": 0.7232, "best_value": 0.7232}, {"dataset_name": "dropout_prob_0.3", "final_value": 0.7099, "best_value": 0.7099}, {"dataset_name": "dropout_prob_0.5", "final_value": 0.7198, "best_value": 0.7198}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.492543, "best_value": 0.488327}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.479506, "best_value": 0.476166}]}, {"metric_name": "validation Complexity-Weighted Accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.79076, "best_value": 0.792665}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The final training loss value.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.496689, "best_value": 0.494483}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The final validation loss value.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.482353, "best_value": 0.481305}]}, {"metric_name": "validation Complexity-Weighted Accuracy", "lower_is_better": false, "description": "The final validation Complexity-Weighted Accuracy value.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.778585, "best_value": 0.782663}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.507956, "best_value": 0.492729}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.497764, "best_value": 0.477935}]}, {"metric_name": "validation Complexity-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy on the validation dataset, weighted by complexity.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.776144, "best_value": 0.782871}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, false, false, true, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_ab0939aeea334aedb175b8dee5242363_proc_1723257/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_ab0939aeea334aedb175b8dee5242363_proc_1723257/SPR_BENCH_val_CompWA.png", "../../logs/0-run/experiment_results/experiment_ab0939aeea334aedb175b8dee5242363_proc_1723257/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_455152317493461facc409c6e528e1d7_proc_1726538/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_455152317493461facc409c6e528e1d7_proc_1726538/SPR_BENCH_val_compwa_curves.png", "../../logs/0-run/experiment_results/experiment_455152317493461facc409c6e528e1d7_proc_1726538/SPR_BENCH_best_metrics_bar.png"], ["../../logs/0-run/experiment_results/experiment_3ae66d73bd69466991266d735ac7829c_proc_1726539/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_3ae66d73bd69466991266d735ac7829c_proc_1726539/SPR_BENCH_compwa_curves.png", "../../logs/0-run/experiment_results/experiment_3ae66d73bd69466991266d735ac7829c_proc_1726539/SPR_BENCH_lr_performance.png"], ["../../logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs128_loss.png", "../../logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs256_loss.png", "../../logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs512_loss.png", "../../logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs1024_loss.png", "../../logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_val_CompWA_aggregated.png"], ["../../logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h16_loss_and_CompWA.png", "../../logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h32_loss_and_CompWA.png", "../../logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h64_loss_and_CompWA.png", "../../logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h128_loss_and_CompWA.png", "../../logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h256_loss_and_CompWA.png", "../../logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_final_val_CompWA_bar.png"], ["../../logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_loss_curves.png", "../../logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_compwa_curves.png", "../../logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_final_compwa.png", "../../logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_cwa_swa.png"], ["../../logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_val_loss_curves.png", "../../logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_val_CompWA_curves.png", "../../logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_final_CWA.png", "../../logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_final_SWA.png"], ["../../logs/0-run/experiment_results/experiment_216b948c43eb40979a7441acb811fe20_proc_1726539/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_216b948c43eb40979a7441acb811fe20_proc_1726539/SPR_BENCH_val_CompWA.png", "../../logs/0-run/experiment_results/experiment_216b948c43eb40979a7441acb811fe20_proc_1726539/SPR_BENCH_final_weighted_accs.png"], ["../../logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.0_loss_compwa.png", "../../logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.1_loss_compwa.png", "../../logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.3_loss_compwa.png", "../../logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.5_loss_compwa.png"], ["../../logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_val_loss_curves.png", "../../logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_val_CompWA_curves.png", "../../logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_final_CWA.png", "../../logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_final_SWA.png"], ["../../logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_val_loss_curves.png", "../../logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_val_CompWA_curves.png", "../../logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_final_CWA.png", "../../logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_final_SWA.png"], ["../../logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_val_loss_curves.png", "../../logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_val_CompWA_curves.png", "../../logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_final_CWA.png", "../../logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_final_SWA.png"], ["../../logs/0-run/experiment_results/seed_aggregation_417c797bb66f4cdab06ac2a5d7d7e324/SPR_BENCH_val_loss_mean_se.png", "../../logs/0-run/experiment_results/seed_aggregation_417c797bb66f4cdab06ac2a5d7d7e324/SPR_BENCH_val_CompWA_mean_se.png", "../../logs/0-run/experiment_results/seed_aggregation_417c797bb66f4cdab06ac2a5d7d7e324/SPR_BENCH_final_CWA_mean_se.png", "../../logs/0-run/experiment_results/seed_aggregation_417c797bb66f4cdab06ac2a5d7d7e324/SPR_BENCH_final_SWA_mean_se.png"]], "plot_paths": [["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_ab0939aeea334aedb175b8dee5242363_proc_1723257/SPR_BENCH_loss_curve.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_ab0939aeea334aedb175b8dee5242363_proc_1723257/SPR_BENCH_val_CompWA.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_ab0939aeea334aedb175b8dee5242363_proc_1723257/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_455152317493461facc409c6e528e1d7_proc_1726538/SPR_BENCH_loss_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_455152317493461facc409c6e528e1d7_proc_1726538/SPR_BENCH_val_compwa_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_455152317493461facc409c6e528e1d7_proc_1726538/SPR_BENCH_best_metrics_bar.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3ae66d73bd69466991266d735ac7829c_proc_1726539/SPR_BENCH_loss_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3ae66d73bd69466991266d735ac7829c_proc_1726539/SPR_BENCH_compwa_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3ae66d73bd69466991266d735ac7829c_proc_1726539/SPR_BENCH_lr_performance.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs128_loss.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs256_loss.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs512_loss.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs1024_loss.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_val_CompWA_aggregated.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h16_loss_and_CompWA.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h32_loss_and_CompWA.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h64_loss_and_CompWA.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h128_loss_and_CompWA.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h256_loss_and_CompWA.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_final_val_CompWA_bar.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_loss_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_compwa_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_final_compwa.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_cwa_swa.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_val_loss_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_val_CompWA_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_final_CWA.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_final_SWA.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_216b948c43eb40979a7441acb811fe20_proc_1726539/SPR_BENCH_loss_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_216b948c43eb40979a7441acb811fe20_proc_1726539/SPR_BENCH_val_CompWA.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_216b948c43eb40979a7441acb811fe20_proc_1726539/SPR_BENCH_final_weighted_accs.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.0_loss_compwa.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.1_loss_compwa.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.3_loss_compwa.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.5_loss_compwa.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_val_loss_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_val_CompWA_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_final_CWA.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_final_SWA.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_val_loss_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_val_CompWA_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_final_CWA.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_final_SWA.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_val_loss_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_val_CompWA_curves.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_final_CWA.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_final_SWA.png"], ["experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/seed_aggregation_417c797bb66f4cdab06ac2a5d7d7e324/SPR_BENCH_val_loss_mean_se.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/seed_aggregation_417c797bb66f4cdab06ac2a5d7d7e324/SPR_BENCH_val_CompWA_mean_se.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/seed_aggregation_417c797bb66f4cdab06ac2a5d7d7e324/SPR_BENCH_final_CWA_mean_se.png", "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/seed_aggregation_417c797bb66f4cdab06ac2a5d7d7e324/SPR_BENCH_final_SWA_mean_se.png"]], "plot_analyses": [[{"analysis": "This plot shows the loss curves for both the training and validation datasets over five epochs. The training loss decreases steadily, indicating that the model is learning from the training data. Similarly, the validation loss also decreases, which suggests that the model is not overfitting and is generalizing well to unseen data. The convergence of the two curves is a positive sign, as it indicates that the model's performance on the validation set is improving alongside the training set.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_ab0939aeea334aedb175b8dee5242363_proc_1723257/SPR_BENCH_loss_curve.png"}, {"analysis": "This plot represents the Complexity-Weighted Accuracy (CompWA) on the validation dataset over five epochs. The accuracy starts at a relatively high value and exhibits a slight increase over time, eventually stabilizing. This trend indicates that the model is improving in its ability to correctly classify more complex sequences but has reached a plateau, suggesting that further performance gains might require additional techniques or tuning.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_ab0939aeea334aedb175b8dee5242363_proc_1723257/SPR_BENCH_val_CompWA.png"}, {"analysis": "The confusion matrix provides a breakdown of the model's classification performance. It shows that the model correctly predicts class 0 for 32.6% of the samples and class 1 for 39.7% of the samples. However, there is still a notable proportion of misclassifications, with 17.4% of class 0 samples being classified as class 1 and 10.3% of class 1 samples being classified as class 0. This suggests that while the model performs reasonably well, there is room for improvement in distinguishing between the two classes.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_ab0939aeea334aedb175b8dee5242363_proc_1723257/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "This plot shows the training and validation loss (Binary Cross-Entropy Loss) over epochs for different max_epochs settings. The loss consistently decreases for both training and validation sets, indicating that the model is learning effectively. However, the validation loss stabilizes and slightly diverges from the training loss as epochs increase, suggesting potential overfitting after a certain number of epochs. The learning curves for different max_epochs settings are closely aligned, indicating that the learning rate and batch size are likely well-tuned and consistent across configurations.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_455152317493461facc409c6e528e1d7_proc_1726538/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot depicts the Validation Complexity-Weighted Accuracy (CompWA) across epochs for different max_epochs settings. The accuracy improves steadily for all configurations, with most reaching a plateau around 40 epochs. The results suggest that the model is learning to generalize well, as the accuracy stabilizes without significant drops. The variations in accuracy improvement rates across epochs might indicate differences in how the model learns patterns of varying complexity.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_455152317493461facc409c6e528e1d7_proc_1726538/SPR_BENCH_val_compwa_curves.png"}, {"analysis": "This bar chart compares the best validation loss and best validation Complexity-Weighted Accuracy (CompWA) achieved for different max_epochs settings. While longer training (e.g., 50 epochs) results in slightly better CompWA, the validation loss does not show a proportional improvement, reinforcing the observation of potential overfitting at higher epochs. The trade-off between loss minimization and accuracy improvement should be considered when deciding on the optimal number of epochs.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_455152317493461facc409c6e528e1d7_proc_1726538/SPR_BENCH_best_metrics_bar.png"}], [{"analysis": "This plot shows the loss curves for both training and validation sets across different learning rates (0.0005, 0.001, 0.003). The training loss (dashed lines) and validation loss (solid lines) consistently decrease over epochs for all learning rates, indicating effective learning. Among the tested learning rates, 0.003 achieves the lowest loss values for both training and validation, suggesting it is the most effective in this scenario. However, the gap between training and validation losses at learning rate 0.003 is slightly larger, which could indicate a slight overfitting tendency.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3ae66d73bd69466991266d735ac7829c_proc_1726539/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the Complexity-Weighted Accuracy (CompWA) on the validation set for different learning rates. The learning rate of 0.003 demonstrates the highest CompWA, steadily improving over epochs and surpassing the other learning rates. The learning rate of 0.001 also shows good performance, stabilizing after epoch 3. The learning rate of 0.0005, while improving, lags behind the others in terms of accuracy, suggesting it might be too low to fully optimize the model within the given epochs.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3ae66d73bd69466991266d735ac7829c_proc_1726539/SPR_BENCH_compwa_curves.png"}, {"analysis": "This bar chart compares the final loss and Complexity-Weighted Accuracy (CompWA) across different learning rates. The learning rate of 0.003 achieves the lowest loss and highest CompWA, confirming it as the optimal choice among the tested values. The learning rate of 0.001 performs moderately well, while 0.0005 exhibits the highest loss and lowest accuracy, reinforcing its suboptimal performance.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3ae66d73bd69466991266d735ac7829c_proc_1726539/SPR_BENCH_lr_performance.png"}], [{"analysis": "This plot shows the loss curves for training and validation when using a batch size of 128. Both the training and validation loss decrease steadily over epochs, indicating that the model is learning. The gap between the training and validation loss is relatively small, suggesting minimal overfitting. This batch size seems to provide stable training dynamics.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs128_loss.png"}, {"analysis": "The plot depicts the loss curves for training and validation with a batch size of 256. Similar to the previous case, both losses decrease steadily, but the validation loss shows a slightly better trend compared to the training loss. This indicates that the model generalizes well with this batch size.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs256_loss.png"}, {"analysis": "Here, the loss curves for batch size 512 are shown. Both training and validation losses decrease, but the validation loss remains slightly higher than the training loss. This suggests that while the model is learning, there might be a slight overfitting tendency at this batch size.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs512_loss.png"}, {"analysis": "This plot illustrates the loss curves for batch size 1024. The losses decrease over epochs, but the gap between training and validation losses is more pronounced compared to smaller batch sizes. This could indicate underfitting or difficulty in capturing patterns effectively with such a large batch size.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_bs1024_loss.png"}, {"analysis": "This plot compares the Complexity-Weighted Accuracy (CompWA) across different batch sizes over epochs. Smaller batch sizes (128 and 256) consistently achieve higher CompWA, indicating better generalization and learning. Larger batch sizes (512 and 1024) show slower improvements and lower final accuracy, suggesting that smaller batch sizes are more effective for this task.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_478433ecb54649a88af35d761d8bed21_proc_1726540/SPR_BENCH_val_CompWA_aggregated.png"}], [{"analysis": "The plot shows the loss and CompWA curves for a hidden dimension of 16. The training and validation losses decrease steadily, indicating effective learning. However, the validation CompWA stabilizes earlier than the training CompWA, suggesting a potential overfitting issue as the training CompWA continues to improve. The final validation CompWA reaches approximately 0.71.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h16_loss_and_CompWA.png"}, {"analysis": "For the hidden dimension of 32, the training and validation losses decrease consistently, but the training CompWA exhibits a sharp fluctuation before stabilizing. The validation CompWA shows a slow but steady increase, suggesting that a hidden dimension of 32 may offer better generalization than dimension 16. The final validation CompWA reaches approximately 0.72.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h32_loss_and_CompWA.png"}, {"analysis": "The plot for a hidden dimension of 64 shows smooth and consistent decreases in both training and validation losses. The training CompWA rises steadily, while the validation CompWA stabilizes at around 0.72. This indicates that a hidden dimension of 64 achieves comparable performance to dimension 32 but with reduced fluctuations.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h64_loss_and_CompWA.png"}, {"analysis": "With a hidden dimension of 128, the training and validation losses decrease steadily. The training CompWA rises sharply, while the validation CompWA improves at a slower rate, stabilizing around 0.73. This suggests that increasing the hidden dimension to 128 enhances the model's capacity to generalize.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h128_loss_and_CompWA.png"}, {"analysis": "For a hidden dimension of 256, the training loss decreases rapidly, and the training CompWA rises sharply, reaching the highest level among all configurations. However, the validation CompWA stabilizes at around 0.75, indicating diminishing returns in validation performance despite the increased model capacity. This suggests that further increasing the hidden dimension may not yield significant improvements in generalization.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_h256_loss_and_CompWA.png"}, {"analysis": "The bar plot summarizes the final validation CompWA across different hidden dimensions. It shows a clear improvement in validation performance as the hidden dimension increases, with the highest CompWA of 0.75 achieved at a hidden dimension of 256. This indicates that larger hidden dimensions enhance the model's ability to capture complex patterns, but the gains diminish at higher dimensions.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_e3cfa129cc2348eaad68785285157d10_proc_1726541/SPR_BENCH_final_val_CompWA_bar.png"}], [{"analysis": "The loss curves for both training and validation datasets show a consistent decrease over epochs for all weight decay values. Lower weight decay values (0 and 1e-5) exhibit slightly slower convergence compared to higher values (0.001 and 0.01). However, there is no significant overfitting observed as the validation loss closely follows the training loss for all cases.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_loss_curves.png"}, {"analysis": "The comparison of training and validation Color-Weighted Accuracy (CompWA) reveals that higher weight decay values (0.001 and 0.01) lead to faster improvements in CompWA during the initial epochs. However, all weight decay values converge to a similar CompWA by the end of training, suggesting that weight decay has a limited impact on the final performance.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_compwa_curves.png"}, {"analysis": "The final validation CompWA across different weight decay values shows minimal variation, indicating that the choice of weight decay does not significantly affect the final model performance. This suggests that the model is robust to changes in this hyperparameter.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_final_compwa.png"}, {"analysis": "The comparison of Color-Weighted Accuracy (CWA) and Shape-Weighted Accuracy (SWA) shows that both metrics are nearly identical across all weight decay values. This implies that the model performs equally well in identifying patterns based on both color and shape, and weight decay does not favor one metric over the other.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_3c3f96ef8cfd4cd9b2825179f601e915_proc_1726540/weight_decay_cwa_swa.png"}], [{"analysis": "The first plot shows the validation loss curves for different values of k (4, 8, 16, 32). As the number of epochs increases, the validation loss consistently decreases for all values of k. The rate of decrease is more pronounced for higher values of k, with k=32 achieving the lowest validation loss by the end of the training. This indicates that larger k values are leading to better optimization and possibly better generalization.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_val_loss_curves.png"}, {"analysis": "The second plot illustrates the Complexity-Weighted Accuracy (CompWA) across epochs for different values of k. Similar to the validation loss, higher values of k (particularly k=32) show superior performance, achieving the highest CompWA by the fourth epoch. The performance improvement is less significant for smaller k values, with k=4 showing a decline in accuracy after an initial increase. This suggests that higher k values are better at capturing the complexity of the data.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_val_CompWA_curves.png"}, {"analysis": "The third plot is intended to show the final Color-Weighted Accuracy (CWA) for k=4, but it appears to be empty. This suggests that either the data for this metric was not computed or there was an issue in generating the plot.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_final_CWA.png"}, {"analysis": "The fourth plot is meant to display the final Shape-Weighted Accuracy (SWA) for k=4, but it is also empty. Similar to the CWA plot, this indicates a potential issue with data computation or visualization for this metric.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5e1b6ce02b5449919e7a139666ec8c6b_proc_1726541/SPR_BENCH_final_SWA.png"}], [{"analysis": "The loss curves indicate that training loss decreases consistently across all configurations (pw1, pw2, pw4, and pw8) over the epochs, showing effective learning by the models. Validation loss also decreases, but the rate of decrease varies across configurations. For instance, configurations pw1 and pw2 show a more stable decline in validation loss, while pw4 and pw8 exhibit higher initial losses and slower convergence. This suggests that pw4 and pw8 may require further tuning for better generalization.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_216b948c43eb40979a7441acb811fe20_proc_1726539/SPR_BENCH_loss_curves.png"}, {"analysis": "The Validation Complexity-Weighted Accuracy (CompWA) plot reveals that pw1 and pw2 achieve strong performance, with pw1 slightly outperforming pw2 by the final epoch. Configuration pw4 shows delayed improvement but eventually catches up to a reasonable level, while pw8 struggles, maintaining a flat trajectory with no significant improvement. This indicates that pw8 may not be well-suited for the task or requires substantial adjustment to hyperparameters or training strategy.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_216b948c43eb40979a7441acb811fe20_proc_1726539/SPR_BENCH_val_CompWA.png"}, {"analysis": "The final weighted accuracy bar chart highlights that configurations pw1 and pw2 achieve the highest CWA and SWA, both surpassing the SOTA thresholds of 70.0% CWA and 65.0% SWA. Configuration pw4 performs moderately, achieving acceptable but lower accuracies, while pw8 underperforms significantly in both metrics. This confirms that pw1 and pw2 are the most effective configurations, with pw1 slightly leading in overall performance.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_216b948c43eb40979a7441acb811fe20_proc_1726539/SPR_BENCH_final_weighted_accs.png"}], [{"analysis": "The training and validation loss curves show a consistent downward trend as the number of epochs increases, indicating that the model is learning effectively. The gap between training and validation loss remains small, suggesting that the model is not overfitting. However, the Complexity Weighted Accuracy (CompWA) remains relatively constant across epochs, indicating that the improvements in loss do not directly translate to better performance on the metric of interest. This could imply that the loss function may not be fully aligned with the metric or that further tuning of hyperparameters is needed.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.0_loss_compwa.png"}, {"analysis": "The trends observed are similar to the previous plot. Both training and validation losses decrease steadily, with no signs of overfitting. The Complexity Weighted Accuracy remains constant, which again suggests that while the model is learning to reduce loss, it may not be improving in terms of the task-specific performance metric. This highlights the need for exploring alternative loss functions or additional regularization techniques.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.1_loss_compwa.png"}, {"analysis": "The loss curves continue to show a downward trend, and the gap between training and validation loss remains minimal, indicating stable learning. However, the Complexity Weighted Accuracy remains unchanged, pointing to a potential misalignment between the loss function and the evaluation metric. This could also suggest that the model's capacity to generalize to the task-specific metric may be limited under the current setup.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.3_loss_compwa.png"}, {"analysis": "Similar to the previous plots, the loss curves indicate effective learning without overfitting. The Complexity Weighted Accuracy shows a slight upward trend but remains largely stable, suggesting that the model's performance on the metric of interest is not significantly improving. This warrants further investigation into whether the current model architecture or hyperparameter settings are optimal for the task.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_96557a25d854462a98b2d32f3143cc04_proc_1726538/SPR_BENCH_dropout_prob_0.5_loss_compwa.png"}], [{"analysis": "The validation loss curves show a consistent decrease with increasing epochs across all values of k (number of clusters). The models with higher k values (e.g., k=16 and k=32) achieve lower validation loss compared to those with lower k values (e.g., k=4 and k=8). This indicates that increasing the number of clusters improves the model's ability to generalize and reduce error. However, the rate of improvement diminishes as k increases, suggesting a potential saturation point.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_val_loss_curves.png"}, {"analysis": "The Complexity-Weighted Accuracy (CompWA) curves demonstrate that models with higher k values achieve better accuracy over time. The k=32 configuration consistently outperforms others, achieving the highest CompWA by the end of the training. This trend highlights the benefit of using a larger number of clusters for capturing complex patterns in the dataset. The performance of the k=4 model plateaus early, indicating its limited capacity to handle the complexity of the task.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_val_CompWA_curves.png"}, {"analysis": "The Color-Weighted Accuracy (CWA) plot is empty, indicating no results were recorded for this metric. This could be due to an issue in the experimental setup or a lack of implementation for this metric. Further investigation is needed to understand why this metric is not being reported.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_final_CWA.png"}, {"analysis": "The Shape-Weighted Accuracy (SWA) plot is also empty, similar to the CWA plot. This suggests a potential problem with the evaluation pipeline for these metrics. Addressing this issue is crucial for a comprehensive evaluation of the model's performance.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/SPR_BENCH_final_SWA.png"}], [{"analysis": "The plot shows the validation loss (Binary Cross-Entropy Loss) across epochs for different values of k (k=4, 8, 16, 32). As the number of epochs increases, the validation loss decreases for all values of k, indicating improved model performance during training. Higher values of k (e.g., k=16 and k=32) result in a faster and more significant reduction in validation loss compared to lower values of k. This suggests that increasing k improves the model's ability to learn meaningful patterns from the data.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_val_loss_curves.png"}, {"analysis": "The plot displays the validation Complexity-Weighted Accuracy (CompWA) across epochs for different values of k. Higher values of k (k=16 and k=32) achieve better CompWA scores, demonstrating that the model performs better when k is increased. The curve for k=4 shows minimal improvement over epochs, indicating that a small k might not be sufficient to capture the complexity of the patterns in the data. The performance gap between k=8 and higher values (k=16, k=32) highlights the importance of selecting an appropriate k for optimal performance.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_val_CompWA_curves.png"}, {"analysis": "This plot appears blank, with no data points or trends visible for Color-Weighted Accuracy (CWA). This could be due to incomplete or missing experimental results for this metric. Further investigation is needed to determine whether the issue lies in the experimental setup, data processing, or visualization step.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_final_CWA.png"}, {"analysis": "Similar to the previous plot, this one is also blank, showing no data points or trends for Shape-Weighted Accuracy (SWA). This might indicate missing or incomplete results for this metric. It would be important to ensure that the SWA metric is being calculated and logged correctly during the experiments.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/SPR_BENCH_final_SWA.png"}], [{"analysis": "This plot shows the validation loss versus epochs for different values of k (number of clusters). As the number of epochs increases, the validation loss decreases for all values of k, indicating that the model is learning effectively. Higher values of k (k=16 and k=32) result in lower validation loss compared to smaller k values (k=4 and k=8), suggesting that increasing the number of clusters improves the model's ability to generalize and reduce loss.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_val_loss_curves.png"}, {"analysis": "This plot illustrates the validation Complexity-Weighted Accuracy (CompWA) versus epochs for different values of k. The accuracy improves with increasing epochs for all k values, with higher k values (k=16 and k=32) achieving better accuracy than smaller k values (k=4 and k=8). This trend suggests that increasing the number of clusters enhances the model's ability to reason effectively and achieve higher accuracy.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_val_CompWA_curves.png"}, {"analysis": "This plot is supposed to display the final Color-Weighted Accuracy (CWA) for k=4. However, it appears to be empty, indicating that no meaningful data or results were recorded for this metric. This could be due to a processing error or a lack of relevant evaluation outputs for this specific configuration.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_final_CWA.png"}, {"analysis": "This plot is intended to show the final Shape-Weighted Accuracy (SWA) for k=4. Similar to the CWA plot, it is empty and does not provide any data or insights. This could indicate an issue with metric computation or result recording for this specific setting.", "plot_path": "experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/SPR_BENCH_final_SWA.png"}], []], "vlm_feedback_summary": ["The results demonstrate steady improvements in training and validation loss,\nindicating effective learning and generalization. Complexity-Weighted Accuracy\nshows slight gains, stabilizing over epochs, which implies that the model's\nreasoning on complex sequences has reached a plateau. The confusion matrix\nhighlights reasonable classification performance but also reveals areas for\nimprovement in reducing misclassification rates.", "The plots provide insights into the model's learning dynamics and performance\ntrade-offs. The training and validation loss curves indicate effective learning\nbut potential overfitting at higher epochs. The validation CompWA trends show\nsteady improvement and stabilization, highlighting the model's ability to\ngeneralize. The comparison of best metrics across epochs suggests that while\nlonger training improves accuracy, it may not significantly enhance loss\nminimization, warranting careful consideration of epoch settings.", "The analysis highlights the effectiveness of different learning rates on the\nSPR_BENCH dataset. The learning rate of 0.003 consistently outperforms the\nothers, achieving the lowest loss and highest Complexity-Weighted Accuracy\n(CompWA). The results suggest that this learning rate is optimal for the current\nexperimental setup, while 0.0005 is less effective due to slower convergence and\nlower accuracy.", "The analysis highlights that smaller batch sizes (128 and 256) yield better\ntraining dynamics and generalization, as evidenced by lower losses and higher\nComplexity-Weighted Accuracy. Larger batch sizes, while reducing computational\noverhead, may lead to underfitting or slower learning.", "The plots illustrate the impact of varying hidden dimensions on model\nperformance. Training and validation losses decrease consistently across all\nconfigurations, while the validation CompWA improves with increasing hidden\ndimensions. However, the gain in validation performance diminishes at higher\ndimensions, suggesting a trade-off between model capacity and generalization.\nThe highest validation CompWA of 0.75 is achieved with a hidden dimension of\n256, indicating this configuration's superior generalization ability.", "The plots provide insights into the impact of weight decay on model performance.\nWhile weight decay influences the convergence rate during training, it has\nminimal effect on the final weighted accuracy metrics (CWA and SWA). The model\ndemonstrates robust performance across different weight decay values, with\nbalanced accuracy in both color and shape reasoning tasks.", "The results indicate that increasing the value of k leads to better performance\nin both validation loss and Complexity-Weighted Accuracy. However, there are\nissues with the final CWA and SWA plots, as they are empty and do not provide\nany insights.", "The experiments demonstrate that configurations pw1 and pw2 are highly\neffective, achieving SOTA performance on both CWA and SWA metrics.\nConfigurations pw4 and pw8 show room for improvement, with pw8 requiring\nsignificant adjustments. Further tuning of hyperparameters for pw4 and pw8 may\nhelp improve their performance.", "The plots demonstrate consistent learning as evidenced by decreasing loss\ncurves, but the lack of significant improvement in Complexity Weighted Accuracy\nsuggests that the model's performance on the task-specific metric is not\nimproving substantially. This indicates a potential misalignment between the\nloss function and the evaluation metric, or limitations in the current model\nsetup.", "The results indicate that increasing the number of clusters (k) improves both\nvalidation loss and complexity-weighted accuracy, with diminishing returns at\nhigher k values. However, the absence of results for color-weighted and shape-\nweighted accuracy metrics highlights a critical gap in the evaluation.\nAddressing this issue is essential for a complete analysis of the model's\nperformance.", "The analysis highlights that increasing k improves the model's performance in\nboth validation loss and Complexity-Weighted Accuracy. However, the absence of\ndata for Color-Weighted Accuracy (CWA) and Shape-Weighted Accuracy (SWA)\nsuggests potential issues in the experimental setup or result logging, which\nneed to be addressed for a comprehensive evaluation.", "The results demonstrate that increasing the number of clusters (k) improves\nmodel performance both in terms of validation loss and Complexity-Weighted\nAccuracy. However, the absence of data in the final CWA and SWA plots suggests\npotential issues in result recording or metric computation for k=4. Further\ninvestigation is needed to address these gaps and ensure comprehensive\nevaluation.", "[]"], "exec_time": [47.78489708900452, 90.68074750900269, 49.8571879863739, 51.539326906204224, 54.09060215950012, 55.87485456466675, 180.61476278305054, 49.519381284713745, 51.91351819038391, 191.38084506988525, 186.68583726882935, 188.46232652664185, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], ["['batch_size_128'", "'batch_size_256']"], ["['SPR_BENCH_h16'", "'SPR_BENCH_h32'", "'SPR_BENCH_h64'", "'SPR_BENCH_h128'", "'SPR_BENCH_h256']"], ["[\"weight_decay\"]"], ["[\"SPR_BENCH\"]"], ["['pw1'", "'pw2']"], ["[]"], ["[]"], ["['SPR_BENCH']"], ["['SPR_BENCH']"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------- Load experiment data -------------------------\ntry:\n    exp_path = os.path.join(working_dir, \"experiment_data.npy\")\n    experiment_data = np.load(exp_path, allow_pickle=True).item()\n    data = experiment_data.get(\"SPR_BENCH\", {})\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data = {}\n\nepochs = range(1, len(data.get(\"losses\", {}).get(\"train\", [])) + 1)\n\n\n# ---------------------- Helper: safe close ---------------------------\ndef close_fig():\n    if plt.get_fignums():\n        plt.close()\n\n\n# --------------------------- Plot 1 ----------------------------------\ntry:\n    plt.figure()\n    plt.plot(epochs, data[\"losses\"][\"train\"], label=\"Train Loss\")\n    plt.plot(epochs, data[\"losses\"][\"val\"], label=\"Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"BCE Loss\")\n    plt.title(\"SPR_BENCH Loss Curve\\nLeft: Train, Right: Validation\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curve.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\nfinally:\n    close_fig()\n\n# --------------------------- Plot 2 ----------------------------------\ntry:\n    val_compwa = data[\"metrics\"][\"val_CompWA\"]\n    plt.figure()\n    plt.plot(epochs, val_compwa, marker=\"o\", color=\"green\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.ylim(0, 1)\n    plt.title(\"SPR_BENCH Validation Complexity-Weighted Accuracy\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_val_CompWA.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\nexcept Exception as e:\n    print(f\"Error creating CompWA plot: {e}\")\nfinally:\n    close_fig()\n\n# --------------------------- Plot 3 ----------------------------------\ntry:\n    gt = np.array(data[\"ground_truth\"])\n    pred = np.array(data[\"predictions\"])\n    TP = np.sum((gt == 1) & (pred == 1))\n    TN = np.sum((gt == 0) & (pred == 0))\n    FP = np.sum((gt == 0) & (pred == 1))\n    FN = np.sum((gt == 1) & (pred == 0))\n    cm = np.array([[TN, FP], [FN, TP]], dtype=float)\n    cm_pct = 100 * cm / max(cm.sum(), 1)\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm_pct, cmap=\"Blues\")\n    for i in range(2):\n        for j in range(2):\n            ax.text(\n                j, i, f\"{cm_pct[i, j]:.1f}%\", va=\"center\", ha=\"center\", color=\"black\"\n            )\n    ax.set_xticks([0, 1])\n    ax.set_yticks([0, 1])\n    ax.set_xticklabels([\"Pred 0\", \"Pred 1\"])\n    ax.set_yticklabels([\"True 0\", \"True 1\"])\n    plt.title(\"SPR_BENCH Confusion Matrix (%)\")\n    plt.colorbar(im, fraction=0.046)\n    fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    acc = (TP + TN) / max(len(gt), 1)\n    print(f\"Validation Accuracy: {acc:.4f}\")\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\nfinally:\n    close_fig()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    exp = experiment_data[\"num_epochs\"][\"SPR_BENCH\"]\n    cfg_vals = exp[\"config_values\"]\n    train_losses_all = exp[\"losses\"][\"train\"]\n    val_losses_all = exp[\"losses\"][\"val\"]\n    val_cwa_all = exp[\"metrics\"][\"val_CompWA\"]\n\n    # helper to pad lists with np.nan so they align in length\n    def pad(seq, L):\n        return np.array(seq + [np.nan] * (L - len(seq)))\n\n    max_len = max(len(x) for x in val_losses_all)\n\n    # -------- Plot 1: Loss curves ----------\n    try:\n        plt.figure()\n        for cfg, tr, va in zip(cfg_vals, train_losses_all, val_losses_all):\n            x = np.arange(1, len(tr) + 1)\n            plt.plot(x, tr, \"--\", label=f\"train (E{cfg})\")\n            plt.plot(x, va, \"-\", label=f\"val (E{cfg})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"BCE Loss\")\n        plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n        plt.legend(fontsize=7)\n        save_path = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(save_path, dpi=200)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curves: {e}\")\n        plt.close()\n\n    # -------- Plot 2: Validation CompWA ----------\n    try:\n        plt.figure()\n        for cfg, cwa in zip(cfg_vals, val_cwa_all):\n            x = np.arange(1, len(cwa) + 1)\n            plt.plot(x, cwa, label=f\"val_CompWA (E{cfg})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(\"SPR_BENCH: Validation CompWA across Epochs\")\n        plt.legend(fontsize=7)\n        save_path = os.path.join(working_dir, \"SPR_BENCH_val_compwa_curves.png\")\n        plt.savefig(save_path, dpi=200)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CompWA curves: {e}\")\n        plt.close()\n\n    # -------- Plot 3: Best metrics vs hyper-parameter ----------\n    try:\n        best_val_losses = [min(v) if len(v) else np.nan for v in val_losses_all]\n        best_val_cwas = [max(c) if len(c) else np.nan for c in val_cwa_all]\n\n        x = np.arange(len(cfg_vals))\n        width = 0.35\n\n        plt.figure()\n        plt.bar(x - width / 2, best_val_losses, width, label=\"Best Val Loss\")\n        plt.bar(x + width / 2, best_val_cwas, width, label=\"Best Val CompWA\")\n        plt.xticks(ticks=x, labels=cfg_vals)\n        plt.xlabel(\"max_epochs\")\n        plt.title(\"SPR_BENCH: Best Metrics per max_epochs Setting\")\n        plt.legend()\n        save_path = os.path.join(working_dir, \"SPR_BENCH_best_metrics_bar.png\")\n        plt.savefig(save_path, dpi=200)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating best metric bar plot: {e}\")\n        plt.close()\n\n    # -------- Console summary ----------\n    print(\"\\n=== Best validation metrics per max_epochs ===\")\n    for cfg, bl, bcwa in zip(cfg_vals, best_val_losses, best_val_cwas):\n        print(\n            f\"max_epochs={cfg:<3} | best_val_loss={bl:0.4f} | best_val_CompWA={bcwa:0.4f}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    data = experiment_data[\"learning_rate\"][\"SPR_BENCH\"]\n    lrs = data[\"lrs\"]\n    train_losses_runs = data[\"losses\"][\"train\"]\n    val_losses_runs = data[\"losses\"][\"val\"]\n    val_cwa_runs = data[\"metrics\"][\"val_CompWA\"]\n\n    # ---------- Plot 1: Loss curves ----------\n    try:\n        plt.figure()\n        for lr, tr_ls, va_ls in zip(lrs, train_losses_runs, val_losses_runs):\n            epochs = np.arange(1, len(tr_ls) + 1)\n            plt.plot(epochs, tr_ls, \"--\", label=f\"Train (lr={lr})\")\n            plt.plot(epochs, va_ls, \"-\", label=f\"Val (lr={lr})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"BCE Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\\nLeft: Train (--), Right: Val (-)\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ---------- Plot 2: CompWA curves ----------\n    try:\n        plt.figure()\n        for lr, cwa_ls in zip(lrs, val_cwa_runs):\n            epochs = np.arange(1, len(cwa_ls) + 1)\n            plt.plot(epochs, cwa_ls, label=f\"Val CompWA (lr={lr})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Complexity-Weighted Accuracy\")\n        plt.title(\"SPR_BENCH Validation CompWA Curves\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_compwa_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating CompWA curve plot: {e}\")\n        plt.close()\n\n    # ---------- Plot 3: Final metrics per LR ----------\n    try:\n        final_val_losses = [ls[-1] for ls in val_losses_runs]\n        final_val_cwas = [cw[-1] for cw in val_cwa_runs]\n        x = np.arange(len(lrs))\n\n        fig, ax1 = plt.subplots()\n        ax2 = ax1.twinx()\n        ax1.bar(\n            x - 0.2,\n            final_val_losses,\n            width=0.4,\n            color=\"tab:blue\",\n            label=\"Final Val Loss\",\n        )\n        ax2.bar(\n            x + 0.2,\n            final_val_cwas,\n            width=0.4,\n            color=\"tab:orange\",\n            label=\"Final Val CompWA\",\n        )\n\n        ax1.set_xlabel(\"Learning Rate Index\")\n        ax1.set_xticks(x)\n        ax1.set_xticklabels([str(lr) for lr in lrs])\n        ax1.set_ylabel(\"Loss\")\n        ax2.set_ylabel(\"CompWA\")\n        plt.title(\n            \"SPR_BENCH Final Metrics vs Learning Rate\\nLeft: Loss (blue), Right: CompWA (orange)\"\n        )\n        fig.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_lr_performance.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating LR performance plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nsaved_files = []\n\n# ---------------- load data -----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    ed = experiment_data[\"batch_size\"][\"SPR_BENCH\"]\n    hyperparams = ed[\"hyperparams\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    hyperparams = []\n\n# ------------- per-batch-size loss plots -------------\nfor idx, bs in enumerate(hyperparams[:5]):  # ensure \u22644 here\n    try:\n        train_l = ed[\"losses\"][\"train\"][idx]\n        val_l = ed[\"losses\"][\"val\"][idx]\n        epochs = np.arange(1, len(train_l) + 1)\n        plt.figure()\n        plt.plot(epochs, train_l, label=\"Train Loss\")\n        plt.plot(epochs, val_l, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"BCE Loss\")\n        plt.title(f\"SPR_BENCH Loss Curves - Batch Size {bs}\")\n        plt.legend()\n        fname = f\"SPR_BENCH_bs{bs}_loss.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        saved_files.append(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for bs={bs}: {e}\")\n        plt.close()\n\n# ------------- aggregated CompWA plot -------------\ntry:\n    plt.figure()\n    for idx, bs in enumerate(hyperparams[:5]):\n        val_cwa = ed[\"metrics\"][\"val_CompWA\"][idx]\n        epochs = np.arange(1, len(val_cwa) + 1)\n        plt.plot(epochs, val_cwa, label=f\"bs={bs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.title(\"SPR_BENCH Validation Complexity-Weighted Accuracy\")\n    plt.legend()\n    fname = \"SPR_BENCH_val_CompWA_aggregated.png\"\n    plt.savefig(os.path.join(working_dir, fname))\n    saved_files.append(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CompWA plot: {e}\")\n    plt.close()\n\nprint(\"Saved figures:\", saved_files)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# Set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# Helper to parse hidden size from key \"SPR_BENCH_h{hdim}\"\ndef get_hdim(key):\n    try:\n        return int(key.split(\"_h\")[-1])\n    except Exception:\n        return None\n\n\nhidden_dict = experiment_data.get(\"hidden_dim_sweep\", {})\nkeys_sorted = sorted(hidden_dict.keys(), key=get_hdim)[:5]  # ensure at most 5\n\nfinal_val_scores = []\nfinal_hdims = []\n\n# One plot per hidden dim\nfor k in keys_sorted:\n    data = hidden_dict[k]\n    hdim = get_hdim(k)\n    train_loss = data[\"losses\"][\"train\"]\n    val_loss = data[\"losses\"][\"val\"]\n    train_cwa = data[\"metrics\"][\"train_CompWA\"]\n    val_cwa = data[\"metrics\"][\"val_CompWA\"]\n    epochs = range(1, len(train_loss) + 1)\n\n    # Save final CompWA for summary plot\n    if val_cwa:\n        final_val_scores.append(val_cwa[-1])\n        final_hdims.append(hdim)\n\n    # Plot losses and CompWA\n    try:\n        fig, ax1 = plt.subplots()\n        ax1.plot(epochs, train_loss, label=\"Train Loss\", color=\"tab:blue\")\n        ax1.plot(epochs, val_loss, label=\"Val Loss\", color=\"tab:cyan\")\n        ax1.set_xlabel(\"Epoch\")\n        ax1.set_ylabel(\"BCE Loss\", color=\"tab:blue\")\n        ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n\n        ax2 = ax1.twinx()\n        ax2.plot(epochs, train_cwa, label=\"Train CompWA\", color=\"tab:red\")\n        ax2.plot(epochs, val_cwa, label=\"Val CompWA\", color=\"tab:orange\")\n        ax2.set_ylabel(\"CompWA\", color=\"tab:red\")\n        ax2.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n\n        lines, labels = ax1.get_legend_handles_labels()\n        lines2, labels2 = ax2.get_legend_handles_labels()\n        ax1.legend(lines + lines2, labels + labels2, loc=\"best\")\n\n        plt.title(f\"SPR_BENCH Hidden {hdim}: Loss & CompWA Curves\")\n\n        fname = f\"SPR_BENCH_h{hdim}_loss_and_CompWA.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating plot for hidden {hdim}: {e}\")\n        plt.close()\n\n# Summary bar chart of final Val CompWA\ntry:\n    plt.figure()\n    plt.bar([str(h) for h in final_hdims], final_val_scores, color=\"tab:green\")\n    plt.xlabel(\"Hidden Dimension\")\n    plt.ylabel(\"Final Val CompWA\")\n    plt.title(\"SPR_BENCH: Final Validation CompWA vs Hidden Dim\")\n    for i, v in enumerate(final_val_scores):\n        plt.text(i, v + 0.01, f\"{v:.2f}\", ha=\"center\", va=\"bottom\")\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_val_CompWA_bar.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating summary bar chart: {e}\")\n    plt.close()\n\n# Print best hidden dim based on final Val CompWA\nif final_val_scores:\n    best_idx = int(np.argmax(final_val_scores))\n    print(\n        f\"Best hidden_dim: {final_hdims[best_idx]} with Val CompWA = {final_val_scores[best_idx]:.4f}\"\n    )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport re\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\ndef _num(wd_key):\n    try:\n        return float(wd_key.split(\"_\")[1])\n    except Exception:\n        # fallback: extract with regex\n        return float(re.findall(r\"[-+e0-9.]+\", wd_key)[0])\n\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    runs = experiment_data[\"weight_decay\"]\n    wd_keys = sorted(runs.keys(), key=_num)\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    runs, wd_keys = {}, []\n\n# Figure 1: loss curves --------------------------------------------------------\ntry:\n    plt.figure()\n    for k in wd_keys:\n        epochs = range(1, len(runs[k][\"losses\"][\"train\"]) + 1)\n        plt.plot(epochs, runs[k][\"losses\"][\"train\"], label=f\"train wd={_num(k):g}\")\n        plt.plot(\n            epochs,\n            runs[k][\"losses\"][\"val\"],\n            linestyle=\"--\",\n            label=f\"val wd={_num(k):g}\",\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"weight_decay: Train vs Val Loss\")\n    plt.legend(fontsize=\"small\")\n    fname = os.path.join(working_dir, \"weight_decay_loss_curves.png\")\n    plt.savefig(fname, dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# Figure 2: CompWA curves ------------------------------------------------------\ntry:\n    plt.figure()\n    for k in wd_keys:\n        epochs = range(1, len(runs[k][\"metrics\"][\"train_CompWA\"]) + 1)\n        plt.plot(\n            epochs, runs[k][\"metrics\"][\"train_CompWA\"], label=f\"train wd={_num(k):g}\"\n        )\n        plt.plot(\n            epochs,\n            runs[k][\"metrics\"][\"val_CompWA\"],\n            linestyle=\"--\",\n            label=f\"val wd={_num(k):g}\",\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.title(\"weight_decay: Train vs Val CompWA\")\n    plt.legend(fontsize=\"small\")\n    fname = os.path.join(working_dir, \"weight_decay_compwa_curves.png\")\n    plt.savefig(fname, dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CompWA curves: {e}\")\n    plt.close()\n\n# Figure 3: final val CompWA bar chart ----------------------------------------\ntry:\n    plt.figure()\n    vals = [runs[k][\"metrics\"][\"val_CompWA\"][-1] for k in wd_keys]\n    plt.bar(range(len(wd_keys)), vals, tick_label=[f\"{_num(k):g}\" for k in wd_keys])\n    plt.xlabel(\"Weight Decay\")\n    plt.ylabel(\"Final Val CompWA\")\n    plt.title(\"weight_decay: Final Validation CompWA per WD\")\n    fname = os.path.join(working_dir, \"weight_decay_final_compwa.png\")\n    plt.savefig(fname, dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final CompWA bar chart: {e}\")\n    plt.close()\n\n# Figure 4: CWA & SWA comparison ----------------------------------------------\ntry:\n    plt.figure()\n    x = np.arange(len(wd_keys))\n    width = 0.35\n    cwa = [runs[k][\"CWA\"] for k in wd_keys]\n    swa = [runs[k][\"SWA\"] for k in wd_keys]\n    plt.bar(x - width / 2, cwa, width=width, label=\"CWA\")\n    plt.bar(x + width / 2, swa, width=width, label=\"SWA\")\n    plt.xticks(x, [f\"{_num(k):g}\" for k in wd_keys])\n    plt.xlabel(\"Weight Decay\")\n    plt.ylabel(\"Weighted Accuracy\")\n    plt.title(\"weight_decay: CWA vs SWA\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"weight_decay_cwa_swa.png\")\n    plt.savefig(fname, dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CWA/SWA comparison: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nbench = experiment_data.get(\"num_clusters_k\", {}).get(\"SPR_BENCH\", {})\nk_vals = sorted(bench.keys(), key=lambda s: int(s.split(\"=\")[1]))  # ['k=4', 'k=8', ...]\n\n\n# helpers to gather series\ndef get_series(key_path):\n    out = {}\n    for k in k_vals:\n        d = bench[k]\n        tmp = d\n        for kp in key_path:\n            tmp = tmp.get(kp, [])\n        out[k] = tmp\n    return out\n\n\nloss_train = get_series([\"losses\", \"train\"])\nloss_val = get_series([\"losses\", \"val\"])\ncompwa_val = get_series([\"metrics\", \"val_CompWA\"])\n\n\n# final CWA/SWA were printed, we recompute from stored preds/gt\ndef final_weighted(metric_fn):\n    res = {}\n    for k in k_vals:\n        seqs = (\n            experiment_data[\"num_clusters_k\"][\"SPR_BENCH_SEQ_CACHE\"] if False else []\n        )  # placeholder\n        preds = np.array(bench[k][\"predictions\"])\n        gts = np.array(bench[k][\"ground_truth\"])\n        res[k] = metric_fn(seqs, gts, preds) if preds.size else 0.0\n    return res\n\n\n# Because the metric functions need sequences, quickly fetch them\nseqs = experiment_data.get(\"SPR_BENCH_SEQS\", None)\nif seqs is None:\n    # fall back to loading dev sequences directly stored in each k dict\n    # they were not kept, so metrics already in stdout; skip recalculation\n    cwa_final = swa_final = {k: np.nan for k in k_vals}\nelse:\n    from __main__ import color_weighted_accuracy, shape_weighted_accuracy\n\n    cwa_final = final_weighted(color_weighted_accuracy)\n    swa_final = final_weighted(shape_weighted_accuracy)\n\n# ---------- PLOTS ----------\n# 1) Validation loss curves\ntry:\n    plt.figure()\n    for k in k_vals:\n        plt.plot(loss_val[k], label=k)\n    plt.title(\"SPR_BENCH Validation Loss vs Epoch\\nLeft: Validation Loss curves\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Binary-Cross-Entropy Loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# 2) Validation CompWA curves\ntry:\n    plt.figure()\n    for k in k_vals:\n        plt.plot(compwa_val[k], label=k)\n    plt.title(\"SPR_BENCH Validation Complexity-Weighted-Accuracy\\nRight: CompWA curves\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_CompWA_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CompWA plot: {e}\")\n    plt.close()\n\n# 3) Final CWA bar chart\ntry:\n    plt.figure()\n    vals = [cwa_final[k] for k in k_vals]\n    plt.bar(k_vals, vals)\n    plt.title(\"SPR_BENCH Final Color-Weighted-Accuracy\")\n    plt.ylabel(\"CWA\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_CWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CWA bar plot: {e}\")\n    plt.close()\n\n# 4) Final SWA bar chart\ntry:\n    plt.figure()\n    vals = [swa_final[k] for k in k_vals]\n    plt.bar(k_vals, vals)\n    plt.title(\"SPR_BENCH Final Shape-Weighted-Accuracy\")\n    plt.ylabel(\"SWA\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_SWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA bar plot: {e}\")\n    plt.close()\n\n# ---------- print summary ----------\nprint(\"Final metrics:\")\nfor k in k_vals:\n    print(f\"{k}: CWA={cwa_final.get(k, 'N/A'):.4f}, SWA={swa_final.get(k, 'N/A'):.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------- Load experiment results ----------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    runs = experiment_data.get(\"pos_weight\", {})\n    keys = sorted(runs.keys(), key=lambda k: int(k.split(\"pw\")[-1]))  # pw1, pw2, ...\n    epochs = len(next(iter(runs.values()))[\"losses\"][\"train\"])\n\n    # ----------------------- Figure 1 ------------------------------\n    try:\n        plt.figure(figsize=(10, 5))\n        for k in keys:\n            plt.plot(\n                range(1, epochs + 1), runs[k][\"losses\"][\"train\"], label=f\"{k}_train\"\n            )\n            plt.plot(\n                range(1, epochs + 1),\n                runs[k][\"losses\"][\"val\"],\n                linestyle=\"--\",\n                label=f\"{k}_val\",\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"BCE Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\\nLeft: Train, Right: Validation\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        print(\"Saved\", fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ----------------------- Figure 2 ------------------------------\n    try:\n        plt.figure(figsize=(8, 5))\n        for k in keys:\n            comp_wa = runs[k][\"metrics\"][\"val_CompWA\"]\n            plt.plot(range(1, epochs + 1), comp_wa, label=k)\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation CompWA\")\n        plt.title(\"SPR_BENCH Validation Complexity-Weighted Accuracy\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_val_CompWA.png\")\n        plt.savefig(fname)\n        print(\"Saved\", fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CompWA plot: {e}\")\n        plt.close()\n\n    # ----------------------- Figure 3 ------------------------------\n    try:\n        cwa = [runs[k][\"val_CWA\"] for k in keys]\n        swa = [runs[k][\"val_SWA\"] for k in keys]\n        x = np.arange(len(keys))\n        width = 0.35\n        plt.figure(figsize=(8, 5))\n        plt.bar(x - width / 2, cwa, width, label=\"CWA\")\n        plt.bar(x + width / 2, swa, width, label=\"SWA\")\n        plt.xticks(x, keys)\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.title(\"SPR_BENCH Final Weighted Accuracies\\nLeft: CWA, Right: SWA\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_final_weighted_accs.png\")\n        plt.savefig(fname)\n        print(\"Saved\", fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating final accuracy plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------- paths -------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------- load data ----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ------------------- plotting -----------------\nfor key in experiment_data:  # e.g. 'dropout_prob_0.1'\n    try:\n        data = experiment_data[key][\"SPR_BENCH\"]\n        train_loss = data[\"losses\"][\"train\"]\n        val_loss = data[\"losses\"][\"val\"]\n        comp_wa = data[\"metrics\"][\"val_CompWA\"]\n        epochs = np.arange(1, len(train_loss) + 1)\n\n        plt.figure(figsize=(10, 4))\n\n        # Left subplot: Loss curves\n        plt.subplot(1, 2, 1)\n        plt.plot(epochs, train_loss, \"o-\", label=\"Train Loss\")\n        plt.plot(epochs, val_loss, \"s-\", label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"BCE Loss\")\n        plt.title(\"Loss\")\n        plt.legend()\n\n        # Right subplot: CompWA curve\n        plt.subplot(1, 2, 2)\n        plt.plot(epochs, comp_wa, \"d-\", color=\"green\", label=\"Val CompWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CompWA\")\n        plt.ylim(0, 1)\n        plt.title(\"Complexity Weighted Accuracy\")\n        plt.legend()\n\n        plt.suptitle(\n            f\"SPR_BENCH \u2013 {key}\\nLeft: Loss Curves, Right: Complexity Weighted Accuracy\"\n        )\n        fname = f\"SPR_BENCH_{key}_loss_compwa.png\".replace(\" \", \"\")\n        plt.tight_layout(rect=[0, 0.03, 1, 0.90])\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating plot for {key}: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nbench = experiment_data.get(\"num_clusters_k\", {}).get(\"SPR_BENCH\", {})\nk_vals = sorted(bench.keys(), key=lambda s: int(s.split(\"=\")[1]))  # ['k=4', 'k=8', ...]\n\n\n# helpers to gather series\ndef get_series(key_path):\n    out = {}\n    for k in k_vals:\n        d = bench[k]\n        tmp = d\n        for kp in key_path:\n            tmp = tmp.get(kp, [])\n        out[k] = tmp\n    return out\n\n\nloss_train = get_series([\"losses\", \"train\"])\nloss_val = get_series([\"losses\", \"val\"])\ncompwa_val = get_series([\"metrics\", \"val_CompWA\"])\n\n\n# final CWA/SWA were printed, we recompute from stored preds/gt\ndef final_weighted(metric_fn):\n    res = {}\n    for k in k_vals:\n        seqs = (\n            experiment_data[\"num_clusters_k\"][\"SPR_BENCH_SEQ_CACHE\"] if False else []\n        )  # placeholder\n        preds = np.array(bench[k][\"predictions\"])\n        gts = np.array(bench[k][\"ground_truth\"])\n        res[k] = metric_fn(seqs, gts, preds) if preds.size else 0.0\n    return res\n\n\n# Because the metric functions need sequences, quickly fetch them\nseqs = experiment_data.get(\"SPR_BENCH_SEQS\", None)\nif seqs is None:\n    # fall back to loading dev sequences directly stored in each k dict\n    # they were not kept, so metrics already in stdout; skip recalculation\n    cwa_final = swa_final = {k: np.nan for k in k_vals}\nelse:\n    from __main__ import color_weighted_accuracy, shape_weighted_accuracy\n\n    cwa_final = final_weighted(color_weighted_accuracy)\n    swa_final = final_weighted(shape_weighted_accuracy)\n\n# ---------- PLOTS ----------\n# 1) Validation loss curves\ntry:\n    plt.figure()\n    for k in k_vals:\n        plt.plot(loss_val[k], label=k)\n    plt.title(\"SPR_BENCH Validation Loss vs Epoch\\nLeft: Validation Loss curves\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Binary-Cross-Entropy Loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# 2) Validation CompWA curves\ntry:\n    plt.figure()\n    for k in k_vals:\n        plt.plot(compwa_val[k], label=k)\n    plt.title(\"SPR_BENCH Validation Complexity-Weighted-Accuracy\\nRight: CompWA curves\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_CompWA_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CompWA plot: {e}\")\n    plt.close()\n\n# 3) Final CWA bar chart\ntry:\n    plt.figure()\n    vals = [cwa_final[k] for k in k_vals]\n    plt.bar(k_vals, vals)\n    plt.title(\"SPR_BENCH Final Color-Weighted-Accuracy\")\n    plt.ylabel(\"CWA\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_CWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CWA bar plot: {e}\")\n    plt.close()\n\n# 4) Final SWA bar chart\ntry:\n    plt.figure()\n    vals = [swa_final[k] for k in k_vals]\n    plt.bar(k_vals, vals)\n    plt.title(\"SPR_BENCH Final Shape-Weighted-Accuracy\")\n    plt.ylabel(\"SWA\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_SWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA bar plot: {e}\")\n    plt.close()\n\n# ---------- print summary ----------\nprint(\"Final metrics:\")\nfor k in k_vals:\n    print(f\"{k}: CWA={cwa_final.get(k, 'N/A'):.4f}, SWA={swa_final.get(k, 'N/A'):.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nbench = experiment_data.get(\"num_clusters_k\", {}).get(\"SPR_BENCH\", {})\nk_vals = sorted(bench.keys(), key=lambda s: int(s.split(\"=\")[1]))  # ['k=4', 'k=8', ...]\n\n\n# helpers to gather series\ndef get_series(key_path):\n    out = {}\n    for k in k_vals:\n        d = bench[k]\n        tmp = d\n        for kp in key_path:\n            tmp = tmp.get(kp, [])\n        out[k] = tmp\n    return out\n\n\nloss_train = get_series([\"losses\", \"train\"])\nloss_val = get_series([\"losses\", \"val\"])\ncompwa_val = get_series([\"metrics\", \"val_CompWA\"])\n\n\n# final CWA/SWA were printed, we recompute from stored preds/gt\ndef final_weighted(metric_fn):\n    res = {}\n    for k in k_vals:\n        seqs = (\n            experiment_data[\"num_clusters_k\"][\"SPR_BENCH_SEQ_CACHE\"] if False else []\n        )  # placeholder\n        preds = np.array(bench[k][\"predictions\"])\n        gts = np.array(bench[k][\"ground_truth\"])\n        res[k] = metric_fn(seqs, gts, preds) if preds.size else 0.0\n    return res\n\n\n# Because the metric functions need sequences, quickly fetch them\nseqs = experiment_data.get(\"SPR_BENCH_SEQS\", None)\nif seqs is None:\n    # fall back to loading dev sequences directly stored in each k dict\n    # they were not kept, so metrics already in stdout; skip recalculation\n    cwa_final = swa_final = {k: np.nan for k in k_vals}\nelse:\n    from __main__ import color_weighted_accuracy, shape_weighted_accuracy\n\n    cwa_final = final_weighted(color_weighted_accuracy)\n    swa_final = final_weighted(shape_weighted_accuracy)\n\n# ---------- PLOTS ----------\n# 1) Validation loss curves\ntry:\n    plt.figure()\n    for k in k_vals:\n        plt.plot(loss_val[k], label=k)\n    plt.title(\"SPR_BENCH Validation Loss vs Epoch\\nLeft: Validation Loss curves\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Binary-Cross-Entropy Loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# 2) Validation CompWA curves\ntry:\n    plt.figure()\n    for k in k_vals:\n        plt.plot(compwa_val[k], label=k)\n    plt.title(\"SPR_BENCH Validation Complexity-Weighted-Accuracy\\nRight: CompWA curves\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_CompWA_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CompWA plot: {e}\")\n    plt.close()\n\n# 3) Final CWA bar chart\ntry:\n    plt.figure()\n    vals = [cwa_final[k] for k in k_vals]\n    plt.bar(k_vals, vals)\n    plt.title(\"SPR_BENCH Final Color-Weighted-Accuracy\")\n    plt.ylabel(\"CWA\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_CWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CWA bar plot: {e}\")\n    plt.close()\n\n# 4) Final SWA bar chart\ntry:\n    plt.figure()\n    vals = [swa_final[k] for k in k_vals]\n    plt.bar(k_vals, vals)\n    plt.title(\"SPR_BENCH Final Shape-Weighted-Accuracy\")\n    plt.ylabel(\"SWA\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_SWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA bar plot: {e}\")\n    plt.close()\n\n# ---------- print summary ----------\nprint(\"Final metrics:\")\nfor k in k_vals:\n    print(f\"{k}: CWA={cwa_final.get(k, 'N/A'):.4f}, SWA={swa_final.get(k, 'N/A'):.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nbench = experiment_data.get(\"num_clusters_k\", {}).get(\"SPR_BENCH\", {})\nk_vals = sorted(bench.keys(), key=lambda s: int(s.split(\"=\")[1]))  # ['k=4', 'k=8', ...]\n\n\n# helpers to gather series\ndef get_series(key_path):\n    out = {}\n    for k in k_vals:\n        d = bench[k]\n        tmp = d\n        for kp in key_path:\n            tmp = tmp.get(kp, [])\n        out[k] = tmp\n    return out\n\n\nloss_train = get_series([\"losses\", \"train\"])\nloss_val = get_series([\"losses\", \"val\"])\ncompwa_val = get_series([\"metrics\", \"val_CompWA\"])\n\n\n# final CWA/SWA were printed, we recompute from stored preds/gt\ndef final_weighted(metric_fn):\n    res = {}\n    for k in k_vals:\n        seqs = (\n            experiment_data[\"num_clusters_k\"][\"SPR_BENCH_SEQ_CACHE\"] if False else []\n        )  # placeholder\n        preds = np.array(bench[k][\"predictions\"])\n        gts = np.array(bench[k][\"ground_truth\"])\n        res[k] = metric_fn(seqs, gts, preds) if preds.size else 0.0\n    return res\n\n\n# Because the metric functions need sequences, quickly fetch them\nseqs = experiment_data.get(\"SPR_BENCH_SEQS\", None)\nif seqs is None:\n    # fall back to loading dev sequences directly stored in each k dict\n    # they were not kept, so metrics already in stdout; skip recalculation\n    cwa_final = swa_final = {k: np.nan for k in k_vals}\nelse:\n    from __main__ import color_weighted_accuracy, shape_weighted_accuracy\n\n    cwa_final = final_weighted(color_weighted_accuracy)\n    swa_final = final_weighted(shape_weighted_accuracy)\n\n# ---------- PLOTS ----------\n# 1) Validation loss curves\ntry:\n    plt.figure()\n    for k in k_vals:\n        plt.plot(loss_val[k], label=k)\n    plt.title(\"SPR_BENCH Validation Loss vs Epoch\\nLeft: Validation Loss curves\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Binary-Cross-Entropy Loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# 2) Validation CompWA curves\ntry:\n    plt.figure()\n    for k in k_vals:\n        plt.plot(compwa_val[k], label=k)\n    plt.title(\"SPR_BENCH Validation Complexity-Weighted-Accuracy\\nRight: CompWA curves\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_CompWA_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CompWA plot: {e}\")\n    plt.close()\n\n# 3) Final CWA bar chart\ntry:\n    plt.figure()\n    vals = [cwa_final[k] for k in k_vals]\n    plt.bar(k_vals, vals)\n    plt.title(\"SPR_BENCH Final Color-Weighted-Accuracy\")\n    plt.ylabel(\"CWA\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_CWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CWA bar plot: {e}\")\n    plt.close()\n\n# 4) Final SWA bar chart\ntry:\n    plt.figure()\n    vals = [swa_final[k] for k in k_vals]\n    plt.bar(k_vals, vals)\n    plt.title(\"SPR_BENCH Final Shape-Weighted-Accuracy\")\n    plt.ylabel(\"SWA\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_SWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA bar plot: {e}\")\n    plt.close()\n\n# ---------- print summary ----------\nprint(\"Final metrics:\")\nfor k in k_vals:\n    print(f\"{k}: CWA={cwa_final.get(k, 'N/A'):.4f}, SWA={swa_final.get(k, 'N/A'):.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------ #\n# Basic setup\n# ------------------------------------------------------------------ #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------ #\n# Load every experiment result\n# ------------------------------------------------------------------ #\ntry:\n    experiment_data_path_list = [\n        \"experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_748b0a4076e041fe8e209a1755bd446f_proc_1726539/experiment_data.npy\",\n        \"experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16a435c724444e22a993563045411103_proc_1726540/experiment_data.npy\",\n        \"experiments/2025-08-31_14-12-13_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b4be1286cf56420e96e1703b31ca4671_proc_1726538/experiment_data.npy\",\n    ]\n    all_experiment_data = []\n    for pth in experiment_data_path_list:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), pth)\n        all_experiment_data.append(np.load(full_path, allow_pickle=True).item())\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    all_experiment_data = []\n\n\n# ------------------------------------------------------------------ #\n# Helper functions\n# ------------------------------------------------------------------ #\ndef collect_series(all_runs, key_path):\n    \"\"\"returns dict[k] -> list_of_arrays  (one array per run, maybe length diff)\"\"\"\n    series = {}\n    for run in all_runs:\n        bench = run.get(\"num_clusters_k\", {}).get(\"SPR_BENCH\", {})\n        for k, kd in bench.items():\n            tmp = kd\n            for kp in key_path:\n                tmp = tmp.get(kp, [])\n            series.setdefault(k, []).append(np.asarray(tmp, dtype=float))\n    return series\n\n\ndef align_and_stat(list_of_arr):\n    \"\"\"Trim to shortest length, return mean and stderr along axis 0.\"\"\"\n    if not list_of_arr:\n        return np.array([]), np.array([])\n    min_len = min(len(a) for a in list_of_arr)\n    clipped = np.stack([a[:min_len] for a in list_of_arr], axis=0)  # shape (runs, T)\n    mean = np.nanmean(clipped, axis=0)\n    stderr = np.nanstd(clipped, axis=0, ddof=1) / np.sqrt(clipped.shape[0])\n    return mean, stderr\n\n\ndef collect_scalar(all_runs, key_path):\n    out = {}\n    for run in all_runs:\n        bench = run.get(\"num_clusters_k\", {}).get(\"SPR_BENCH\", {})\n        for k, kd in bench.items():\n            tmp = kd\n            for kp in key_path:\n                tmp = tmp.get(kp, np.nan)\n            out.setdefault(k, []).append(float(tmp))\n    return out\n\n\n# ------------------------------------------------------------------ #\n# Collect curves\n# ------------------------------------------------------------------ #\nloss_val_series = collect_series(all_experiment_data, [\"losses\", \"val\"])\ncompwa_val_series = collect_series(all_experiment_data, [\"metrics\", \"val_CompWA\"])\ncwa_final_series = collect_scalar(all_experiment_data, [\"metrics\", \"final_CWA\"])\nswa_final_series = collect_scalar(all_experiment_data, [\"metrics\", \"final_SWA\"])\n\nk_vals = sorted(\n    loss_val_series.keys(), key=lambda s: int(s.split(\"=\")[1])\n)  # keep numeric order\n\n# ------------------------------------------------------------------ #\n# 1) Validation Loss mean \u00b1 SE\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    for k in k_vals:\n        mean, se = align_and_stat(loss_val_series.get(k, []))\n        if mean.size == 0:\n            continue\n        epochs = np.arange(len(mean))\n        plt.plot(epochs, mean, label=f\"{k} mean\")\n        plt.fill_between(epochs, mean - se, mean + se, alpha=0.3, label=f\"{k} \u00b1SE\")\n    plt.title(\n        \"SPR_BENCH Validation Loss (mean \u00b1 SE)\\nLeft: Ground Truth, Right: Generated Samples\"\n    )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Binary-Cross-Entropy Loss\")\n    plt.legend(fontsize=8)\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_loss_mean_se.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated loss plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 2) Validation CompWA mean \u00b1 SE\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    for k in k_vals:\n        mean, se = align_and_stat(compwa_val_series.get(k, []))\n        if mean.size == 0:\n            continue\n        epochs = np.arange(len(mean))\n        plt.plot(epochs, mean, label=f\"{k} mean\")\n        plt.fill_between(epochs, mean - se, mean + se, alpha=0.3, label=f\"{k} \u00b1SE\")\n    plt.title(\n        \"SPR_BENCH Validation CompWA (mean \u00b1 SE)\\nLeft: Ground Truth, Right: Generated Samples\"\n    )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CompWA\")\n    plt.legend(fontsize=8)\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_CompWA_mean_se.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated CompWA plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 3) Final CWA Bar chart with error bars\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    means = [np.nanmean(cwa_final_series.get(k, [np.nan])) for k in k_vals]\n    ses = [\n        np.nanstd(cwa_final_series.get(k, [np.nan]), ddof=1)\n        / np.sqrt(len(cwa_final_series.get(k, [])))\n        for k in k_vals\n    ]\n    plt.bar(k_vals, means, yerr=ses, capsize=5)\n    plt.title(\"SPR_BENCH Final Color-Weighted-Accuracy (mean \u00b1 SE)\")\n    plt.ylabel(\"CWA\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_CWA_mean_se.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated CWA bar plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# 4) Final SWA Bar chart with error bars\n# ------------------------------------------------------------------ #\ntry:\n    plt.figure()\n    means = [np.nanmean(swa_final_series.get(k, [np.nan])) for k in k_vals]\n    ses = [\n        np.nanstd(swa_final_series.get(k, [np.nan]), ddof=1)\n        / np.sqrt(len(swa_final_series.get(k, [])))\n        for k in k_vals\n    ]\n    plt.bar(k_vals, means, yerr=ses, capsize=5)\n    plt.title(\"SPR_BENCH Final Shape-Weighted-Accuracy (mean \u00b1 SE)\")\n    plt.ylabel(\"SWA\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_SWA_mean_se.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated SWA bar plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# Print summary\n# ------------------------------------------------------------------ #\nprint(\"Aggregated Final Metrics (mean \u00b1 SE):\")\nfor k in k_vals:\n    cwa_arr = np.array(cwa_final_series.get(k, []), dtype=float)\n    swa_arr = np.array(swa_final_series.get(k, []), dtype=float)\n    if cwa_arr.size:\n        cwa_mean = np.nanmean(cwa_arr)\n        cwa_se = np.nanstd(cwa_arr, ddof=1) / np.sqrt(cwa_arr.size)\n    else:\n        cwa_mean = cwa_se = np.nan\n    if swa_arr.size:\n        swa_mean = np.nanmean(swa_arr)\n        swa_se = np.nanstd(swa_arr, ddof=1) / np.sqrt(swa_arr.size)\n    else:\n        swa_mean = swa_se = np.nan\n    print(f\"{k}: CWA={cwa_mean:.4f}\u00b1{cwa_se:.4f}, SWA={swa_mean:.4f}\u00b1{swa_se:.4f}\")\n"], "plot_plan": ["We first load experiment_data.npy and safely extract the entry for the single dataset \u201cSPR_BENCH\u201d.  We prepare three canonical visualisations that are guaranteed to exist in the file: (1) training vs validation loss across epochs, (2) validation CompWA across epochs (the training list is entirely None, so we plot only validation), and (3) a 2 \u00d7 2 confusion-matrix heat-map comparing final predictions with ground-truth.  Each plot lives in its own try-except so a failure in one does not stop the others, every figure gets a descriptive title/sub-title and is saved to working_dir with informative filenames.  We restrict ourselves to the five recorded epochs so no thinning is necessary.  For the confusion matrix we compute TP, FP, FN, TN directly from the stored arrays, normalise to percentages for readability, annotate each cell, and print overall accuracy after plotting.  All figures are closed in a finally-style manner even when an exception is raised.  The script finishes by printing summary metrics (final val loss and CompWA, plus accuracy) so users can read them in logs without opening the plots.  The whole solution is self-contained, concise, and respects the provided plotting guidelines.", "We will load experiment_data.npy, extract the hyper-parameter sweep stored under experiment_data['num_epochs']['SPR_BENCH'], and gather (i) per-epoch training/validation losses, (ii) per-epoch validation CompWA, and (iii) the max-epoch value tried for every run.  Using this information we will create three plots, each wrapped in its own try\u2013except block: (1) a single figure overlaying training and validation loss curves for every max_epochs setting, (2) a figure overlaying validation CompWA curves for every setting, and (3) a bar plot that compares the best (minimum) validation loss and the best (maximum) validation CompWA achieved by each hyper-parameter value.  If any plot fails we log the error and still close the figure.  The figures are saved to working_dir with descriptive filenames that include the dataset name and plot type.  After plotting we iterate through the configs to print a concise table that lists max_epochs together with the best validation loss and best validation CompWA so the user can read key results in the console.  We rely exclusively on the arrays stored in experiment_data.npy\u2014no synthetic data are generated.  All figures are closed after saving and matplotlib is used with its default style only.", "We first load experiment_data.npy to retrieve results for the SPR_BENCH dataset and its three learning-rate runs. For each run we extract per-epoch training and validation losses as well as validation CompWA, keeping note of the corresponding LR value. We then generate three figures: (1) a line plot overlaying training and validation loss curves for all LRs, (2) a line plot of validation CompWA for all LRs, and (3) a bar chart comparing the final (last epoch) validation loss and CompWA across learning rates. Each figure is wrapped in its own try-except block, titled clearly, saved to working_dir with descriptive filenames, and the figure is closed afterward. We limit ourselves to these three summary plots to stay within the five-figure maximum and give the most informative view of the experiment without redundancy. All plotting code lives in one concise, self-contained script that starts with the required imports and ensures working_dir exists. If experiment_data.npy is missing or corrupted, a helpful message is printed and plotting is skipped gracefully. Finally, the script prints a short confirmation of which plots were successfully written.", "We will load the serialized experiment dictionary, safely extract the SPR-BENCH section, and loop through the (at most four) tried batch-sizes. For each batch size we plot the per-epoch training and validation losses, storing each figure inside the working directory with a descriptive filename. After that we produce a single summary figure that overlays the validation CompWA curves for all batch sizes, thus keeping the total number of figures \u2264 5. Every plotting step sits in its own try-except so that the script never crashes mid-way; figures are always closed. Paths are handled via os.path.join, and all filenames include the dataset name plus the kind of plot. At the end the script prints the list of saved files so the user can confirm everything ran correctly.", "We will first load experiment_data.npy and extract the hidden-dimensionality sweep stored under hidden_dim_sweep.  \nFor every hidden size we will read the recorded training/validation losses and the training/validation complexity-weighted accuracy (CompWA).  \nA line plot will be produced per hidden size showing loss (left y-axis) and CompWA (right y-axis) across epochs; because we have exactly five settings we stay within the 5-figure limit.  \nTo give an overall comparison, we will also create a sixth figure\u2014a bar chart\u2014summarising the final validation CompWA for all hidden dimensions and printing the best one.  \nEach figure is wrapped in its own try-except block, saved in working_dir with descriptive names like \u201cSPR_BENCH_h32_loss_and_CompWA.png\u201d, titled appropriately, and finally closed.  \nNo synthetic data are generated; we only use values present in experiment_data.npy.  \nAfter plotting, the script prints the hidden dimension with the highest final validation CompWA and the corresponding score so users can quickly see the best model.", "We first load experiment_data.npy, focus on the entries stored under the \u201cweight_decay\u201d sweep, and sort runs by their numerical wd value. From each run we extract per-epoch lists for train/val loss and train/val complexity-weighted accuracy (CompWA), together with the final CWA and SWA scores already provided. Four figures are created, each wrapped in an independent try-except so that a failure in one does not affect the others. Fig-1 overlays train/val loss curves across epochs for every weight-decay value, while Fig-2 overlays train/val CompWA curves. Fig-3 is a bar chart of the final validation CompWA vs weight decay and Fig-4 is a grouped bar chart comparing CWA and SWA vs weight decay. All figures include explicit titles that mention the \u201cweight_decay\u201d dataset and the plot type, are saved with descriptive filenames in working_dir, and are closed immediately after saving.", "We will first load experiment_data.npy and extract the \u201cnum_clusters_k / SPR_BENCH / k=*\u201d dictionaries.  \nFor each k we read the per-epoch lists under losses[\"train\"], losses[\"val\"] and metrics[\"val_CompWA\"]; these will let us draw learning curves.  \nFigure 1 will show the validation loss vs. epoch with a separate line for each k, letting us compare convergence speed.  \nFigure 2 will show the validation Complexity-Weighted-Accuracy (CompWA) vs. epoch, again one line per k, limited to at most 5 epochs so the x-axis stays clear.  \nTo summarize final results we\u2019ll compute the last-epoch Color-Weighted-Accuracy (CWA) and Shape-Weighted-Accuracy (SWA) that were printed during training; we plot them as bar charts in Figures 3 and 4, respectively.  \nAll figures are enclosed in individual try-except blocks, saved to \u201cworking/SPR_BENCH_[plotname].png\u201d, titled clearly, then closed.  \nFinally, the script prints a small table of the final CWA/SWA values for quick inspection.", "We will load experiment_data.npy, enumerate the four \u201cSPR_BENCH_pwX\u201d runs and extract per-epoch training/validation losses plus validation Complexity-Weighted Accuracy (CompWA).  Figure 1 will show, for each pos-weight, the train/val loss curves (two subplots) so that the influence of the hyper-parameter is visible.  Figure 2 will plot the val_CompWA curves for the same runs, letting us see which weight yields the best accuracy.  Finally, Figure 3 will be a grouped bar chart comparing the final validation Color-Weighted Accuracy (CWA) and Shape-Weighted Accuracy (SWA) across pos_weight settings.  All figures are wrapped in independent try-except blocks, saved to working_dir with descriptive names, explicitly closed, and carry clear titles/subtitles that mention \u201cSPR_BENCH\u201d.  No made-up data are introduced; everything is taken from the numpy file.  The script also creates working_dir if it does not yet exist and prints the location of each saved plot.", "The script first loads the saved experiment_data.npy from the working directory and discovers each dropout sweep recorded in the dictionary. For every dropout value it extracts (i) the per-epoch training and validation losses and (ii) the per-epoch validation Complexity-Weighted Accuracy (CompWA). Inside a try-except block it produces one figure per dropout containing two side-by-side subplots: the left subplot shows training vs. validation loss curves, while the right subplot shows the CompWA curve. Each figure is titled with the dataset name and dropout value, given a descriptive subtitle (\u201cLeft: Loss Curves, Right: Complexity-Weighted Accuracy\u201d), saved to working_dir with a meaningful name, and immediately closed to free resources. If any error arises during loading or plotting, the script reports it but still ensures figures are closed. The code follows all style and safety requirements, uses only information present in experiment_data.npy, and limits output to the four figures corresponding to the four dropout settings.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": [null, "num_epochs", "learning_rate", "batch_size", "hidden_dim (size of the hidden layer)", "weight_decay", "num_clusters_k", "pos_weight", "dropout_prob", null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["Below is a small utility that loads the stored numpy dictionary, looks up the\nlosses and metric histories, selects the final training value and the best (min\nfor losses, max for scores) validation value, and prints them with clear labels\nfor each dataset.", "The script will load the serialized experiment dictionary from the working\ndirectory, iterate over each dataset (only \u201cSPR_BENCH\u201d here), and locate the\nepoch/run that achieved the lowest validation loss. For that best epoch it will\ncollect the corresponding training loss, validation loss, and complexity-\nweighted accuracies. It then prints the dataset name followed by clearly\nlabelled metrics such as \u201ctraining loss,\u201d \u201cvalidation loss,\u201d and \u201cvalidation\ncomplexity weighted accuracy.\u201d Metrics that are absent or `None` are skipped.\nThe code runs immediately without requiring an entry-point guard.", "The script will load the stored numpy file from the working directory, pull out\nthe results that were recorded for the SPR-BENCH dataset, locate the run that\nachieved the lowest (best) final validation loss, and then print three clearly-\nlabelled metrics for that best run: the final training loss, the final\nvalidation loss, and the best observed validation CompWA. All code is executed\nat import time\u2014no special entry-point guards are used.", "The script will load the serialized dictionary, access the nested section that\ncorresponds to the single dataset (\u201cSPR_BENCH\u201d), and iterate over the stored\nruns (one per batch-size).   For every run it will read the last (i.e. final)\nelement of each metric list: training loss, validation loss, and validation\ncomplexity-weighted accuracy.   It then prints the dataset name once, followed\nby one line per batch size that clearly labels each printed metric.", "We will load the serialized dictionary from working/experiment_data.npy, iterate\nthrough the \u201chidden_dim_sweep\u201d section, and for every hyper-parameter setting\n(treated here as a \u201cdataset name\u201d) extract the last element of each recorded\nlist: training loss, validation loss, training complexity-weighted accuracy, and\nvalidation complexity-weighted accuracy. These values represent the final epoch\nand fulfil the \u201cbest or final\u201d requirement. Each dataset name will be printed\nfirst, followed by clearly labelled metric values rounded to four decimal\nplaces. The code is placed directly in the global scope so it runs immediately\non execution.", "The script will load the saved NumPy dictionary, iterate over each weight-decay\nrun, and for every run print two datasets\u2014train and validation\u2014along with the\nfinal values (last epoch) of all recorded metrics. For the training set we\noutput the final complexity-weighted accuracy and loss, while for the validation\nset we output the final complexity-, color-, and shape-weighted accuracies plus\nthe final validation loss. All printing follows the required \u201cDataset: \u2026\u201d then\n\u201cmetric name: value\u201d formatting and the code executes immediately upon running.", "We will load the saved numpy file from the working directory, navigate its\nnested dictionary structure, and, for every cluster-size experiment stored under\nthe dataset key (\u201cSPR_BENCH\u201d), print the final epoch\u2019s training loss, validation\nloss, and validation Complexity-Weighted Accuracy (CompWA). Each metric is\nclearly labelled, and the dataset name is printed before its metrics. The script\nexecutes immediately when run and contains no `__main__` guard.", "The script will load the experiment data saved in working/experiment_data.npy,\niterate over every sub-experiment (one per pos_weight), and print clearly\nlabelled final values for training loss, validation loss, validation complexity-\nweighted accuracy, validation color-weighted accuracy, and validation shape-\nweighted accuracy. If any training CompWA values are present, the last non-None\nvalue will also be reported. All code is executed at the global scope so that\nthe results appear immediately when the file is run.", "The script will load the saved experiment_data.npy, iterate over every\nexperiment sweep, and\u2014for each dataset\u2014print the best (minimum for losses,\nmaximum for accuracies) values recorded across epochs.  Metrics are printed with\nexplicit labels like \u201cTraining loss\u201d or \u201cValidation CompWA\u201d immediately after\nthe dataset\u2019s name, complying with the formatting rules and avoiding any plots\nor special entry-point guards.  The code executes on import because everything\nis in the global scope.", "We will load the saved numpy file from the working directory, navigate its\nnested dictionary structure, and, for every cluster-size experiment stored under\nthe dataset key (\u201cSPR_BENCH\u201d), print the final epoch\u2019s training loss, validation\nloss, and validation Complexity-Weighted Accuracy (CompWA). Each metric is\nclearly labelled, and the dataset name is printed before its metrics. The script\nexecutes immediately when run and contains no `__main__` guard.", "We will load the saved numpy file from the working directory, navigate its\nnested dictionary structure, and, for every cluster-size experiment stored under\nthe dataset key (\u201cSPR_BENCH\u201d), print the final epoch\u2019s training loss, validation\nloss, and validation Complexity-Weighted Accuracy (CompWA). Each metric is\nclearly labelled, and the dataset name is printed before its metrics. The script\nexecutes immediately when run and contains no `__main__` guard.", "We will load the saved numpy file from the working directory, navigate its\nnested dictionary structure, and, for every cluster-size experiment stored under\nthe dataset key (\u201cSPR_BENCH\u201d), print the final epoch\u2019s training loss, validation\nloss, and validation Complexity-Weighted Accuracy (CompWA). Each metric is\nclearly labelled, and the dataset name is printed before its metrics. The script\nexecutes immediately when run and contains no `__main__` guard.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# 0. Locate and load the saved results\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# 1. Helper functions\n# ---------------------------------------------------------------------\ndef last_valid(values):\n    \"\"\"Return the last non-None entry in a list (or None if absent).\"\"\"\n    for v in reversed(values):\n        if v is not None:\n            return v\n    return None\n\n\ndef best(values, larger_is_better=True):\n    \"\"\"Return the best (min or max) non-None entry from a list.\"\"\"\n    vals = [v for v in values if v is not None]\n    if not vals:\n        return None\n    return max(vals) if larger_is_better else min(vals)\n\n\n# ---------------------------------------------------------------------\n# 2. Iterate over all stored datasets and print metrics\n# ---------------------------------------------------------------------\nfor ds_name, ds_dict in experiment_data.items():\n    print(ds_name)  # dataset header\n\n    # ---------------- Losses ----------------\n    if \"losses\" in ds_dict:\n        losses = ds_dict[\"losses\"]\n\n        # Training loss  : final value\n        if losses.get(\"train\"):\n            tr_final_loss = last_valid(losses[\"train\"])\n            if tr_final_loss is not None:\n                print(f\"training loss: {tr_final_loss:.6f}\")\n\n        # Validation loss: best (minimum) value\n        if losses.get(\"val\"):\n            val_best_loss = best(losses[\"val\"], larger_is_better=False)\n            if val_best_loss is not None:\n                print(f\"validation loss: {val_best_loss:.6f}\")\n\n    # --------------- Other metrics ---------------\n    if \"metrics\" in ds_dict:\n        metrics = ds_dict[\"metrics\"]\n\n        # Training Complexity-Weighted Accuracy : final value\n        if metrics.get(\"train_CompWA\"):\n            tr_final_cwa = last_valid(metrics[\"train_CompWA\"])\n            if tr_final_cwa is not None:\n                print(f\"training complexity weighted accuracy: {tr_final_cwa:.6f}\")\n\n        # Validation Complexity-Weighted Accuracy: best (maximum) value\n        if metrics.get(\"val_CompWA\"):\n            val_best_cwa = best(metrics[\"val_CompWA\"], larger_is_better=True)\n            if val_best_cwa is not None:\n                print(f\"validation complexity weighted accuracy: {val_best_cwa:.6f}\")\n\n    # --------------- Optional newlines ----------\n    print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ---------- Load data -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- Helper to fetch best epoch across runs -------------------\ndef get_best_metrics(dset_dict):\n    \"\"\"\n    Given the dict that stores metrics for a particular dataset, return\n    the metrics corresponding to the epoch that achieved the lowest\n    validation loss across all hyper-parameter runs.\n    \"\"\"\n    train_losses_runs = dset_dict[\"losses\"][\"train\"]\n    val_losses_runs = dset_dict[\"losses\"][\"val\"]\n    train_cwa_runs = dset_dict[\"metrics\"][\"train_CompWA\"]\n    val_cwa_runs = dset_dict[\"metrics\"][\"val_CompWA\"]\n\n    best_val_loss = float(\"inf\")\n    best_metrics = {}\n\n    # iterate over hyper-parameter runs\n    for run_idx, val_losses in enumerate(val_losses_runs):\n        if not val_losses:  # empty run (should not happen)\n            continue\n        min_val = min(val_losses)\n        if min_val < best_val_loss:\n            best_val_loss = min_val\n            epoch_idx = val_losses.index(min_val)\n\n            # fetch corresponding metrics\n            train_loss = train_losses_runs[run_idx][epoch_idx]\n            val_cwa_list = val_cwa_runs[run_idx]\n            train_cwa_list = train_cwa_runs[run_idx]\n\n            best_metrics = {\n                \"training loss\": train_loss,\n                \"validation loss\": min_val,\n                \"validation complexity weighted accuracy\": (\n                    val_cwa_list[epoch_idx] if epoch_idx < len(val_cwa_list) else None\n                ),\n                \"training complexity weighted accuracy\": (\n                    train_cwa_list[epoch_idx]\n                    if epoch_idx < len(train_cwa_list)\n                    else None\n                ),\n            }\n            best_val_loss = min_val  # update best\n\n    return best_metrics\n\n\n# ---------- Extract and print metrics --------------------------------\nfor dataset_name, dataset_dict in experiment_data[\"num_epochs\"].items():\n    print(dataset_name)\n    metrics = get_best_metrics(dataset_dict)\n\n    for metric_name, value in metrics.items():\n        if value is not None:\n            print(f\"{metric_name}: {value:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# 0. locate and load the experiment data\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# 1. iterate over datasets (only 'SPR_BENCH' in the stored structure)\n# ---------------------------------------------------------------------\nfor dataset_name, data_dict in experiment_data[\"learning_rate\"].items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    lrs = data_dict[\"lrs\"]\n    train_losses = data_dict[\"losses\"][\"train\"]  # list[run][epoch]\n    val_losses = data_dict[\"losses\"][\"val\"]  # list[run][epoch]\n    val_compwas = data_dict[\"metrics\"][\"val_CompWA\"]  # list[run][epoch]\n\n    # -----------------------------------------------------------------\n    # 2. choose the run with the best (lowest) final validation loss\n    # -----------------------------------------------------------------\n    final_val_losses = [run_losses[-1] for run_losses in val_losses]\n    best_run_idx = int(np.argmin(final_val_losses))\n\n    best_lr = lrs[best_run_idx]\n    best_final_tr_ls = train_losses[best_run_idx][-1]\n    best_final_val_ls = final_val_losses[best_run_idx]\n    best_val_cwa = max(val_compwas[best_run_idx])  # best over epochs\n\n    # -----------------------------------------------------------------\n    # 3. print clearly-named metrics for the selected best run\n    # -----------------------------------------------------------------\n    print(f\"learning rate: {best_lr}\")\n    print(f\"final training loss: {best_final_tr_ls:.6f}\")\n    print(f\"final validation loss: {best_final_val_ls:.6f}\")\n    print(f\"best validation CompWA: {best_val_cwa:.6f}\")\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------\n# Load the experiment data ------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# --------------------------------------------------------------------\n# Helper to print the final metric values -----------------------------\ndef print_final_metrics():\n    batch_section = experiment_data.get(\"batch_size\", {})\n    for dataset_name, content in batch_section.items():\n        print(f\"\\nDataset: {dataset_name}\")  # requirement #3\n        hparams = content[\"hyperparams\"]\n        train_ls = content[\"losses\"][\"train\"]\n        val_ls = content[\"losses\"][\"val\"]\n        val_cwas = content[\"metrics\"][\"val_CompWA\"]\n\n        for idx, bs in enumerate(hparams):\n            final_train_loss = train_ls[idx][-1] if train_ls[idx] else None\n            final_val_loss = val_ls[idx][-1] if val_ls[idx] else None\n            final_val_cwa = val_cwas[idx][-1] if val_cwas[idx] else None\n\n            # requirement #4: metric names must be explicit\n            print(\n                f\"batch_size={bs} | \"\n                f\"final training loss: {final_train_loss:.4f} | \"\n                f\"final validation loss: {final_val_loss:.4f} | \"\n                f\"final validation complexity-weighted accuracy: {final_val_cwa:.4f}\"\n            )\n\n\n# --------------------------------------------------------------------\n# Execute immediately -------------------------------------------------\nprint_final_metrics()\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# Locate and load the experiment data\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# Extract and print final metrics for every dataset\n# ---------------------------------------------------------------------\nfor dataset_name, data in experiment_data.get(\"hidden_dim_sweep\", {}).items():\n    # Safeguard: ensure expected keys exist\n    losses = data.get(\"losses\", {})\n    metrics = data.get(\"metrics\", {})\n    train_losses = losses.get(\"train\", [])\n    val_losses = losses.get(\"val\", [])\n    train_cwa = metrics.get(\"train_CompWA\", [])\n    val_cwa = metrics.get(\"val_CompWA\", [])\n\n    # Skip if any list is empty\n    if not (train_losses and val_losses and train_cwa and val_cwa):\n        continue\n\n    # Final (last-epoch) values\n    final_train_loss = train_losses[-1]\n    final_val_loss = val_losses[-1]\n    final_train_cwa = train_cwa[-1]\n    final_val_cwa = val_cwa[-1]\n\n    # -----------------------------------------------------------------\n    # Print results\n    # -----------------------------------------------------------------\n    print(f\"\\n{dataset_name}\")\n    print(f\"training loss: {final_train_loss:.4f}\")\n    print(f\"validation loss: {final_val_loss:.4f}\")\n    print(f\"training complexity weighted accuracy: {final_train_cwa:.4f}\")\n    print(f\"validation complexity weighted accuracy: {final_val_cwa:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# 0. Locate and load the experiment data\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# 1. Iterate over runs and print the final / best metrics\n# ---------------------------------------------------------------------\nweight_decay_runs = experiment_data.get(\"weight_decay\", {})\n\n# Sort runs by the numeric weight-decay value for readability\nsorted_runs = sorted(\n    weight_decay_runs.items(), key=lambda item: float(item[0].split(\"_\")[1])\n)\n\nfor run_name, run_data in sorted_runs:\n    # Extract final values (last epoch recorded)\n    final_train_cwa = run_data[\"metrics\"][\"train_CompWA\"][-1]\n    final_val_cwa = run_data[\"metrics\"][\"val_CompWA\"][-1]\n    final_color_wa = run_data.get(\"CWA\", None)\n    final_shape_wa = run_data.get(\"SWA\", None)\n    final_train_loss = run_data[\"losses\"][\"train\"][-1]\n    final_val_loss = run_data[\"losses\"][\"val\"][-1]\n\n    weight_decay_value = run_name.split(\"_\")[1]\n    print(f\"Run weight_decay = {weight_decay_value}\")\n\n    # ---- Train dataset metrics ----\n    print(\"Dataset: train\")\n    print(f\"train complexity weighted accuracy: {final_train_cwa:.4f}\")\n    print(f\"train loss: {final_train_loss:.4f}\")\n\n    # ---- Validation dataset metrics ----\n    print(\"Dataset: validation\")\n    print(f\"validation complexity weighted accuracy: {final_val_cwa:.4f}\")\n    if final_color_wa is not None:\n        print(f\"validation color weighted accuracy: {final_color_wa:.4f}\")\n    if final_shape_wa is not None:\n        print(f\"validation shape weighted accuracy: {final_shape_wa:.4f}\")\n    print(f\"validation loss: {final_val_loss:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------\n# 0. Locate and load the experiment data\n# --------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# --------------------------------------------------------------------\n# 1. Iterate through datasets and print final metrics\n# --------------------------------------------------------------------\nnum_clusters_section = experiment_data.get(\"num_clusters_k\", {})\n\nfor dataset_name, runs in num_clusters_section.items():\n    print(f\"\\nDataset: {dataset_name}\")\n    # runs is a dict like {\"k=4\": {...}, \"k=8\": {...}, ...}\n    # Sort by the numeric value of k for neat output\n    sorted_runs = sorted(runs.items(), key=lambda kv: int(kv[0].split(\"=\")[1]))\n    for k_label, run_data in sorted_runs:\n        k_val = int(k_label.split(\"=\")[1])\n        train_losses = run_data[\"losses\"][\"train\"]\n        val_losses = run_data[\"losses\"][\"val\"]\n        val_compwa = run_data[\"metrics\"][\"val_CompWA\"]\n\n        # Safeguard against empty lists\n        if not (train_losses and val_losses and val_compwa):\n            print(f\"  k = {k_val}: No recorded metrics.\")\n            continue\n\n        print(f\"  Number of clusters (k): {k_val}\")\n        print(f\"    Final training loss: {train_losses[-1]:.6f}\")\n        print(f\"    Final validation loss: {val_losses[-1]:.6f}\")\n        print(\n            f\"    Final validation Complexity-Weighted Accuracy: {val_compwa[-1]:.6f}\"\n        )\n", "import os\nimport numpy as np\n\n# ----------------- Load experiment data -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ----------------- Extract & print metrics --------------\npos_weight_results = experiment_data.get(\"pos_weight\", {})\n\nfor dataset_name, data in pos_weight_results.items():\n    print(f\"\\n{dataset_name}\")  # Dataset header\n\n    # Losses ------------------------------------------------\n    train_losses = data[\"losses\"].get(\"train\", [])\n    val_losses = data[\"losses\"].get(\"val\", [])\n\n    if train_losses:\n        print(f\"Final training loss: {train_losses[-1]:.6f}\")\n    if val_losses:\n        print(f\"Final validation loss: {val_losses[-1]:.6f}\")\n\n    # Complexity-weighted accuracy (CompWA) -----------------\n    val_comp_wa = data[\"metrics\"].get(\"val_CompWA\", [])\n    if val_comp_wa:\n        print(f\"Final validation complexity-weighted accuracy: {val_comp_wa[-1]:.6f}\")\n\n    # If any training CompWA values exist (ignore None) ----\n    train_comp_wa = data[\"metrics\"].get(\"train_CompWA\", [])\n    train_comp_wa = [v for v in train_comp_wa if v is not None]\n    if train_comp_wa:\n        print(f\"Final training complexity-weighted accuracy: {train_comp_wa[-1]:.6f}\")\n\n    # Additional weighted accuracies -----------------------\n    if \"val_CWA\" in data and data[\"val_CWA\"] is not None:\n        print(f\"Validation color-weighted accuracy: {data['val_CWA']:.6f}\")\n    if \"val_SWA\" in data and data[\"val_SWA\"] is not None:\n        print(f\"Validation shape-weighted accuracy: {data['val_SWA']:.6f}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------------------------\n# 0.  Locate and load the experiment data\n# -------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy at {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------------------------\n# 1.  Helper to pick \"best\" value in a list\n# -------------------------------------------------------------------\ndef best_value(values, maximize=True):\n    \"\"\"\n    Return the best (max or min) non-None value from a list.\n    If every entry is None, return None.\n    \"\"\"\n    vals = [v for v in values if v is not None]\n    if not vals:\n        return None\n    return max(vals) if maximize else min(vals)\n\n\n# -------------------------------------------------------------------\n# 2.  Iterate through experiments and print required metrics\n# -------------------------------------------------------------------\nfor exp_name, exp_content in experiment_data.items():  # e.g., 'dropout_prob_0.1'\n    for dataset_name, ds_content in exp_content.items():  # e.g., 'SPR_BENCH'\n        print(f\"{dataset_name}   (experiment: {exp_name})\")\n\n        # ----- losses -----\n        train_losses = ds_content.get(\"losses\", {}).get(\"train\", [])\n        val_losses = ds_content.get(\"losses\", {}).get(\"val\", [])\n\n        best_train_loss = best_value(train_losses, maximize=False)\n        best_val_loss = best_value(val_losses, maximize=False)\n\n        if best_train_loss is not None:\n            print(f\"  Training loss: {best_train_loss:.4f}\")\n        if best_val_loss is not None:\n            print(f\"  Validation loss: {best_val_loss:.4f}\")\n\n        # ----- CompWA metrics -----\n        train_comp = ds_content.get(\"metrics\", {}).get(\"train_CompWA\", [])\n        val_comp = ds_content.get(\"metrics\", {}).get(\"val_CompWA\", [])\n\n        best_train_comp = best_value(train_comp, maximize=True)\n        best_val_comp = best_value(val_comp, maximize=True)\n\n        if best_train_comp is not None:\n            print(f\"  Training CompWA: {best_train_comp:.4f}\")\n        if best_val_comp is not None:\n            print(f\"  Validation CompWA: {best_val_comp:.4f}\")\n\n        print()  # blank line for readability between experiments\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------\n# 0. Locate and load the experiment data\n# --------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# --------------------------------------------------------------------\n# 1. Iterate through datasets and print final metrics\n# --------------------------------------------------------------------\nnum_clusters_section = experiment_data.get(\"num_clusters_k\", {})\n\nfor dataset_name, runs in num_clusters_section.items():\n    print(f\"\\nDataset: {dataset_name}\")\n    # runs is a dict like {\"k=4\": {...}, \"k=8\": {...}, ...}\n    # Sort by the numeric value of k for neat output\n    sorted_runs = sorted(runs.items(), key=lambda kv: int(kv[0].split(\"=\")[1]))\n    for k_label, run_data in sorted_runs:\n        k_val = int(k_label.split(\"=\")[1])\n        train_losses = run_data[\"losses\"][\"train\"]\n        val_losses = run_data[\"losses\"][\"val\"]\n        val_compwa = run_data[\"metrics\"][\"val_CompWA\"]\n\n        # Safeguard against empty lists\n        if not (train_losses and val_losses and val_compwa):\n            print(f\"  k = {k_val}: No recorded metrics.\")\n            continue\n\n        print(f\"  Number of clusters (k): {k_val}\")\n        print(f\"    Final training loss: {train_losses[-1]:.6f}\")\n        print(f\"    Final validation loss: {val_losses[-1]:.6f}\")\n        print(\n            f\"    Final validation Complexity-Weighted Accuracy: {val_compwa[-1]:.6f}\"\n        )\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------\n# 0. Locate and load the experiment data\n# --------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# --------------------------------------------------------------------\n# 1. Iterate through datasets and print final metrics\n# --------------------------------------------------------------------\nnum_clusters_section = experiment_data.get(\"num_clusters_k\", {})\n\nfor dataset_name, runs in num_clusters_section.items():\n    print(f\"\\nDataset: {dataset_name}\")\n    # runs is a dict like {\"k=4\": {...}, \"k=8\": {...}, ...}\n    # Sort by the numeric value of k for neat output\n    sorted_runs = sorted(runs.items(), key=lambda kv: int(kv[0].split(\"=\")[1]))\n    for k_label, run_data in sorted_runs:\n        k_val = int(k_label.split(\"=\")[1])\n        train_losses = run_data[\"losses\"][\"train\"]\n        val_losses = run_data[\"losses\"][\"val\"]\n        val_compwa = run_data[\"metrics\"][\"val_CompWA\"]\n\n        # Safeguard against empty lists\n        if not (train_losses and val_losses and val_compwa):\n            print(f\"  k = {k_val}: No recorded metrics.\")\n            continue\n\n        print(f\"  Number of clusters (k): {k_val}\")\n        print(f\"    Final training loss: {train_losses[-1]:.6f}\")\n        print(f\"    Final validation loss: {val_losses[-1]:.6f}\")\n        print(\n            f\"    Final validation Complexity-Weighted Accuracy: {val_compwa[-1]:.6f}\"\n        )\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------\n# 0. Locate and load the experiment data\n# --------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# --------------------------------------------------------------------\n# 1. Iterate through datasets and print final metrics\n# --------------------------------------------------------------------\nnum_clusters_section = experiment_data.get(\"num_clusters_k\", {})\n\nfor dataset_name, runs in num_clusters_section.items():\n    print(f\"\\nDataset: {dataset_name}\")\n    # runs is a dict like {\"k=4\": {...}, \"k=8\": {...}, ...}\n    # Sort by the numeric value of k for neat output\n    sorted_runs = sorted(runs.items(), key=lambda kv: int(kv[0].split(\"=\")[1]))\n    for k_label, run_data in sorted_runs:\n        k_val = int(k_label.split(\"=\")[1])\n        train_losses = run_data[\"losses\"][\"train\"]\n        val_losses = run_data[\"losses\"][\"val\"]\n        val_compwa = run_data[\"metrics\"][\"val_CompWA\"]\n\n        # Safeguard against empty lists\n        if not (train_losses and val_losses and val_compwa):\n            print(f\"  k = {k_val}: No recorded metrics.\")\n            continue\n\n        print(f\"  Number of clusters (k): {k_val}\")\n        print(f\"    Final training loss: {train_losses[-1]:.6f}\")\n        print(f\"    Final validation loss: {val_losses[-1]:.6f}\")\n        print(\n            f\"    Final validation Complexity-Weighted Accuracy: {val_compwa[-1]:.6f}\"\n        )\n", ""], "parse_term_out": ["['SPR_BENCH', '\\n', 'training loss: 0.569368', '\\n', 'validation loss:\n0.561002', '\\n', 'validation complexity weighted accuracy: 0.719049', '\\n',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'training loss: 0.4498', '\\n', 'validation loss: 0.4441',\n'\\n', 'validation complexity weighted accuracy: 0.7711', '\\n', 'Execution time:\na moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'learning rate: 0.003', '\\n', 'final training\nloss: 0.499577', '\\n', 'final validation loss: 0.485472', '\\n', 'best validation\nCompWA: 0.749620', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'batch_size=128 | final training loss: 0.5020 |\nfinal validation loss: 0.4896 | final validation complexity-weighted accuracy:\n0.7481', '\\n', 'batch_size=256 | final training loss: 0.5379 | final validation\nloss: 0.5284 | final validation complexity-weighted accuracy: 0.7344', '\\n',\n'batch_size=512 | final training loss: 0.5735 | final validation loss: 0.5630 |\nfinal validation complexity-weighted accuracy: 0.7153', '\\n', 'batch_size=1024 |\nfinal training loss: 0.6069 | final validation loss: 0.5953 | final validation\ncomplexity-weighted accuracy: 0.6946', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['\\nSPR_BENCH_h16', '\\n', 'training loss: 0.5981', '\\n', 'validation loss:\n0.5856', '\\n', 'training complexity weighted accuracy: 0.7880', '\\n',\n'validation complexity weighted accuracy: 0.7066', '\\n', '\\nSPR_BENCH_h32',\n'\\n', 'training loss: 0.5623', '\\n', 'validation loss: 0.5537', '\\n', 'training\ncomplexity weighted accuracy: 0.5438', '\\n', 'validation complexity weighted\naccuracy: 0.7230', '\\n', '\\nSPR_BENCH_h64', '\\n', 'training loss: 0.5638', '\\n',\n'validation loss: 0.5563', '\\n', 'training complexity weighted accuracy:\n0.7788', '\\n', 'validation complexity weighted accuracy: 0.7195', '\\n',\n'\\nSPR_BENCH_h128', '\\n', 'training loss: 0.5332', '\\n', 'validation loss:\n0.5216', '\\n', 'training complexity weighted accuracy: 0.7880', '\\n',\n'validation complexity weighted accuracy: 0.7329', '\\n', '\\nSPR_BENCH_h256',\n'\\n', 'training loss: 0.5005', '\\n', 'validation loss: 0.4884', '\\n', 'training\ncomplexity weighted accuracy: 0.8710', '\\n', 'validation complexity weighted\naccuracy: 0.7510', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Run weight_decay = 0.0', '\\n', 'Dataset: train', '\\n', 'train complexity\nweighted accuracy: 0.7162', '\\n', 'train loss: 0.5797', '\\n', 'Dataset:\nvalidation', '\\n', 'validation complexity weighted accuracy: 0.7213', '\\n',\n'validation color weighted accuracy: 0.7183', '\\n', 'validation shape weighted\naccuracy: 0.7242', '\\n', 'validation loss: 0.5696\\n', '\\n', 'Run weight_decay =\n1e-05', '\\n', 'Dataset: train', '\\n', 'train complexity weighted accuracy:\n0.7174', '\\n', 'train loss: 0.5702', '\\n', 'Dataset: validation', '\\n',\n'validation complexity weighted accuracy: 0.7200', '\\n', 'validation color\nweighted accuracy: 0.7172', '\\n', 'validation shape weighted accuracy: 0.7227',\n'\\n', 'validation loss: 0.5603\\n', '\\n', 'Run weight_decay = 0.0001', '\\n',\n'Dataset: train', '\\n', 'train complexity weighted accuracy: 0.7212', '\\n',\n'train loss: 0.5760', '\\n', 'Dataset: validation', '\\n', 'validation complexity\nweighted accuracy: 0.7212', '\\n', 'validation color weighted accuracy: 0.7187',\n'\\n', 'validation shape weighted accuracy: 0.7236', '\\n', 'validation loss:\n0.5699\\n', '\\n', 'Run weight_decay = 0.001', '\\n', 'Dataset: train', '\\n',\n'train complexity weighted accuracy: 0.7087', '\\n', 'train loss: 0.5836', '\\n',\n'Dataset: validation', '\\n', 'validation complexity weighted accuracy: 0.7104',\n'\\n', 'validation color weighted accuracy: 0.7080', '\\n', 'validation shape\nweighted accuracy: 0.7126', '\\n', 'validation loss: 0.5775\\n', '\\n', 'Run\nweight_decay = 0.01', '\\n', 'Dataset: train', '\\n', 'train complexity weighted\naccuracy: 0.7122', '\\n', 'train loss: 0.5776', '\\n', 'Dataset: validation',\n'\\n', 'validation complexity weighted accuracy: 0.7148', '\\n', 'validation color\nweighted accuracy: 0.7123', '\\n', 'validation shape weighted accuracy: 0.7172',\n'\\n', 'validation loss: 0.5701\\n', '\\n', 'Execution time: a moment seconds (time\nlimit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Number of clusters (k): 4', '\\n', '    Final\ntraining loss: 0.604170', '\\n', '    Final validation loss: 0.600313', '\\n', '\nFinal validation Complexity-Weighted Accuracy: 0.643527', '\\n', '  Number of\nclusters (k): 8', '\\n', '    Final training loss: 0.572452', '\\n', '    Final\nvalidation loss: 0.564627', '\\n', '    Final validation Complexity-Weighted\nAccuracy: 0.722025', '\\n', '  Number of clusters (k): 16', '\\n', '    Final\ntraining loss: 0.516886', '\\n', '    Final validation loss: 0.509978', '\\n', '\nFinal validation Complexity-Weighted Accuracy: 0.745453', '\\n', '  Number of\nclusters (k): 32', '\\n', '    Final training loss: 0.479093', '\\n', '    Final\nvalidation loss: 0.462989', '\\n', '    Final validation Complexity-Weighted\nAccuracy: 0.795999', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nSPR_BENCH_pw1', '\\n', 'Final training loss: 0.569368', '\\n', 'Final\nvalidation loss: 0.561002', '\\n', 'Final validation complexity-weighted\naccuracy: 0.719049', '\\n', 'Validation color-weighted accuracy: 0.715759', '\\n',\n'Validation shape-weighted accuracy: 0.722183', '\\n', '\\nSPR_BENCH_pw2', '\\n',\n'Final training loss: 0.771132', '\\n', 'Final validation loss: 0.759222', '\\n',\n'Final validation complexity-weighted accuracy: 0.720418', '\\n', 'Validation\ncolor-weighted accuracy: 0.717406', '\\n', 'Validation shape-weighted accuracy:\n0.723288', '\\n', '\\nSPR_BENCH_pw4', '\\n', 'Final training loss: 1.085838', '\\n',\n'Final validation loss: 1.053450', '\\n', 'Final validation complexity-weighted\naccuracy: 0.580895', '\\n', 'Validation color-weighted accuracy: 0.575743', '\\n',\n'Validation shape-weighted accuracy: 0.585804', '\\n', '\\nSPR_BENCH_pw8', '\\n',\n'Final training loss: 1.471439', '\\n', 'Final validation loss: 1.419839', '\\n',\n'Final validation complexity-weighted accuracy: 0.511178', '\\n', 'Validation\ncolor-weighted accuracy: 0.501190', '\\n', 'Validation shape-weighted accuracy:\n0.520695', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH   (experiment: dropout_prob_0.0)', '\\n', '  Training loss: 0.5694',\n'\\n', '  Validation loss: 0.5610', '\\n', '  Validation CompWA: 0.7190', '\\n',\n'\\n', 'SPR_BENCH   (experiment: dropout_prob_0.1)', '\\n', '  Training loss:\n0.5731', '\\n', '  Validation loss: 0.5606', '\\n', '  Validation CompWA: 0.7232',\n'\\n', '\\n', 'SPR_BENCH   (experiment: dropout_prob_0.3)', '\\n', '  Training\nloss: 0.5897', '\\n', '  Validation loss: 0.5686', '\\n', '  Validation CompWA:\n0.7099', '\\n', '\\n', 'SPR_BENCH   (experiment: dropout_prob_0.5)', '\\n', '\nTraining loss: 0.5870', '\\n', '  Validation loss: 0.5607', '\\n', '  Validation\nCompWA: 0.7198', '\\n', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Number of clusters (k): 4', '\\n', '    Final\ntraining loss: 0.600720', '\\n', '    Final validation loss: 0.594806', '\\n', '\nFinal validation Complexity-Weighted Accuracy: 0.644837', '\\n', '  Number of\nclusters (k): 8', '\\n', '    Final training loss: 0.573325', '\\n', '    Final\nvalidation loss: 0.565339', '\\n', '    Final validation Complexity-Weighted\nAccuracy: 0.715655', '\\n', '  Number of clusters (k): 16', '\\n', '    Final\ntraining loss: 0.488327', '\\n', '    Final validation loss: 0.476166', '\\n', '\nFinal validation Complexity-Weighted Accuracy: 0.792665', '\\n', '  Number of\nclusters (k): 32', '\\n', '    Final training loss: 0.492543', '\\n', '    Final\nvalidation loss: 0.479506', '\\n', '    Final validation Complexity-Weighted\nAccuracy: 0.790760', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Number of clusters (k): 4', '\\n', '    Final\ntraining loss: 0.612615', '\\n', '    Final validation loss: 0.610957', '\\n', '\nFinal validation Complexity-Weighted Accuracy: 0.652547', '\\n', '  Number of\nclusters (k): 8', '\\n', '    Final training loss: 0.568756', '\\n', '    Final\nvalidation loss: 0.557369', '\\n', '    Final validation Complexity-Weighted\nAccuracy: 0.722055', '\\n', '  Number of clusters (k): 16', '\\n', '    Final\ntraining loss: 0.494483', '\\n', '    Final validation loss: 0.481305', '\\n', '\nFinal validation Complexity-Weighted Accuracy: 0.782663', '\\n', '  Number of\nclusters (k): 32', '\\n', '    Final training loss: 0.496689', '\\n', '    Final\nvalidation loss: 0.482353', '\\n', '    Final validation Complexity-Weighted\nAccuracy: 0.778585', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Number of clusters (k): 4', '\\n', '    Final\ntraining loss: 0.597031', '\\n', '    Final validation loss: 0.593619', '\\n', '\nFinal validation Complexity-Weighted Accuracy: 0.681094', '\\n', '  Number of\nclusters (k): 8', '\\n', '    Final training loss: 0.562448', '\\n', '    Final\nvalidation loss: 0.553195', '\\n', '    Final validation Complexity-Weighted\nAccuracy: 0.727205', '\\n', '  Number of clusters (k): 16', '\\n', '    Final\ntraining loss: 0.492729', '\\n', '    Final validation loss: 0.477935', '\\n', '\nFinal validation Complexity-Weighted Accuracy: 0.782871', '\\n', '  Number of\nclusters (k): 32', '\\n', '    Final training loss: 0.507956', '\\n', '    Final\nvalidation loss: 0.497764', '\\n', '    Final validation Complexity-Weighted\nAccuracy: 0.776144', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
