
% This paper provides foundational insights into Lloyd's algorithm for K-means clustering, including methods for its acceleration. It is directly relevant to the clustering step in the proposed symbolic glyph clustering method for SPR, where K-means plays a key role in grouping glyphs based on latent features. This citation will be used to support the 'Clustering' section of the methodology.
@inproceedings{hamerly2015acceleratingla,
 author = {Greg Hamerly and Jonathan Drake},
 pages = {41-78},
 title = {Accelerating Lloydâ€™s Algorithm for k -Means Clustering},
 year = {2015}
}

% The selected paper introduces BERT, a pre-trained transformer-based language model designed for deep bidirectional representation learning. It is used in the Data Preprocessing step of our methodology to extract latent features from symbolic glyph sequences, which are later clustered for symbolic reasoning. This citation supports the use of BERT as a foundational method for feature extraction and highlights its wide-ranging effectiveness in natural language processing tasks.
@article{devlin2019bertpo,
 author = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
 booktitle = {North American Chapter of the Association for Computational Linguistics},
 pages = {4171-4186},
 title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
 year = {2019}
}

% The selected paper introduces the Differentiable Symbolic Reasoning (DSR-LM) framework for improving logical reasoning in pre-trained language models. It emphasizes the integration of symbolic reasoning to enhance model performance on deductive reasoning benchmarks. This citation is relevant to our work as it provides context for employing symbolic reasoning techniques and evaluation strategies in machine learning, supporting the evaluation methodology in our study.
@article{zhang2023improvedlr,
 author = {Hanlin Zhang and Jiani Huang and Ziyang Li and M. Naik and Eric P. Xing},
 booktitle = {Annual Meeting of the Association for Computational Linguistics},
 pages = {3062-3077},
 title = {Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming},
 year = {2023}
}
