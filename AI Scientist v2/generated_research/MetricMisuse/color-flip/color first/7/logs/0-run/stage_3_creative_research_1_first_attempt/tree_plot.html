<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 4], [0, 1], [0, 3], [0, 2], [1, 8], [1, 10], [1, 5], [1, 11], [1, 12], [1, 9], [4, 7], [4, 6]], "layout": [[0.6071428571428571, 0.0], [0.35714285714285715, 0.5], [0.5, 0.5], [0.6428571428571429, 0.5], [0.9285714285714286, 0.5], [0.0, 1.0], [0.8571428571428571, 1.0], [1.0, 1.0], [0.14285714285714285, 1.0], [0.2857142857142857, 1.0], [0.42857142857142855, 1.0], [0.5714285714285714, 1.0], [0.7142857142857143, 1.0]], "plan": ["Hyperparam tuning name: EPOCHS (Number of training epochs). We extend training\nto up to 30 epochs and add a simple early-stopping mechanism (patience = 5) that\nmonitors validation complexity-weighted accuracy; training halts when the metric\nstops improving. All metrics/losses are recorded in the prescribed\nexperiment_data structure and saved to disk, together with a learning-curve\nplot.", "We add an explicit \u201cglyph-clustering\u201d preprocessing layer: learn a tiny auto-\nencoder on one-hot glyphs, extract its 8-dim latent vectors, cluster them with\nK-means (K=8).   Each glyph is thus mapped to a cluster id that should capture\nlatent similarity (e.g. same shape across colours).   The classifier receives\ntwo parallel symbol streams \u2013 the original glyph tokens and the new cluster\ntokens \u2013 embeds both, sums the embeddings, then feeds a bidirectional GRU\nfollowed by an MLP.   Training still uses cross-entropy, but we evaluate at\nevery epoch on CWA/SWA and the stricter Complexity-Weighted Accuracy, with\nearly-stopping on the latter.   If SPR_BENCH is missing we fall back to\nsynthetic data so the script is runnable everywhere.   All metrics, losses and\npredictions are stored in experiment_data.npy and the validation curves are\nplotted into the ./working folder.   This simple unsupervised clustering already\ngives the network higher-level symbolic hints and is a first creative step\ntowards the paper\u2019s full pipeline.", "We will first derive a latent grouping of glyphs: every unique symbol (e.g.\n\u201cA3\u201d) is converted into a simple 2-dimensional feature vector (shape-index,\ncolour-index).  A lightweight K-means (k = min(10, |V|)) is run on these\nvectors; each glyph is assigned a \u201ccluster-id\u201d.   Each sequence is then\nrepresented by two parallel streams: the original token-ids and their cluster-\nids.  A Dual-Embedding model learns one embedding table for raw tokens and one\nfor clusters; their sum is averaged over the sequence and passed to an MLP\nclassifier.  Because rare tokens now share parameters through their cluster\nembeddings, we expect better generalisation, especially on high-complexity\nsequences, hence higher CWA/SWA/CompWA.  Training uses early stopping on\nvalidation CompWA, and all requested metrics are logged into experiment_data and\nsaved.  The whole script runs in <30 min on CPU/GPU and falls back to synthetic\ndata if the real corpus is absent.", "We cluster glyphs before modeling by turning each token \u201cS C\u201d into a two-dim\nvector (shape index, color index) and applying K-Means to obtain a reduced\nlatent-cluster vocabulary. Sequences are then rewritten as cluster-id strings,\ngreatly shrinking the symbol space while grouping visually/semantically similar\nglyphs. A lightweight average-embedding classifier is trained on these clustered\nsequences; because the embedding now captures glyph similarity at the cluster\nlevel, the model can generalize rules that depend on shared latent properties\nrather than individual tokens. We monitor Color-, Shape- and Complexity-Weighted\naccuracies on dev each epoch with early stopping. All metrics, losses and\npredictions are stored in experiment_data and saved to ./working. If sklearn is\nunavailable, the script gracefully falls back to an identity \u201ccluster\u201d (no worse\nthan baseline). The entire pipeline\u2014data load, clustering, training,\nevaluation\u2014runs on GPU when available and completes quickly. Below is a self-\ncontained implementation (\u224815 min on CPU, faster on GPU).", "We first mine structure at the glyph level: every glyph has two discrete\nfactors, Shape (A-Z) and Color (0-9).  From all glyph types that occur in the\ntraining split we build a simple 2-D numeric feature (shape-index, colour-index)\nand run MiniBatch-KMeans to obtain K latent \u201cglyph clusters\u201d.  Each original\nglyph is then mapped to the id of its closest cluster; sequences are rewritten\nas sequences of cluster-ids, dramatically shrinking the vocabulary and\n(hypothetically) exposing shared latent regularities.  A light\u2010weight neural\nclassifier (embedding \u2192 average pooling \u2192 MLP) is trained on these clustered\nsequences.  We monitor standard loss plus color-, shape-, and complexity-\nweighted accuracies on dev at every epoch, keep the best model w.r.t.\ncomplexity-weighted accuracy, and employ early stopping.  All metrics, losses,\npredictions, and ground-truth are stored in the required experiment_data\nstructure and written to ./working.  The whole pipeline is self-contained, uses\nGPU if available, and falls back to a synthetic toy dataset when the real\nbenchmark is not present so that execution always succeeds.", "We replace the costly auto-encoder with a light-weight \u201cstructural\u201d embedding:\nfor every glyph we use its (shape-id , color-id) as a 2-D feature and cluster\nthem with K-means (K=12).   The cluster id is appended to the input so the model\nsees both the ordinary glyph embedding and a learnable cluster embedding.   A\nsmall Transformer encoder (2 layers, 4 heads) with mean pooling replaces the\nGRU, giving the model more capacity to capture long-range symbolic dependencies.\nTraining uses early stopping on the new Complexity-Weighted Accuracy (CompWA);\nCWA and SWA are tracked as well.   We keep a synthetic-data fallback, rigorous\nGPU handling, full metric logging and save everything into\n./working/experiment_data.npy.   Because clustering is now deterministic and\nfast, the whole script runs comfortably within the 30-minute limit.   The code\nbelow is fully self-contained and starts executing immediately; it prints epoch-\nwise validation loss and all weighted accuracies, then stores results and a\nplot.", "The error occurs because the previous implementation assumes the colour part of\na glyph is always a digit (int(tok[1])), yet the real SPR_BENCH tokens can carry\narbitrary alphanumerical colour IDs such as \u201cAb\u201d, \u201cAq\u201d, \u201cA10\u201d, etc.   We fix\nthis by (1) parsing the full colour substring token[1:] and mapping every\ndistinct colour string to a unique integer ID via a dictionary, and (2) shifting\nevery true cluster index by +1 so that 0 is reserved exclusively for padding\n(avoiding collisions with a real cluster). The rest of the pipeline (clustering,\npadding, masking, metrics, early-stopping, saving) stays untouched but is\nupdated to work with the new mappings and to record validation loss each epoch.", "The crash occurred because `token_to_vec` assumed that every glyph was one\nuppercase letter followed by a single-digit colour (`int(tok[1])`).  In the real\nSPR_BENCH data the colour symbol can be one or more alphanumerical characters\n(e.g. \u201cAb\u201d, \u201cA12\u201d, \u201cAd\u201d), so the attempted `int()` conversion fails.   Fix:\nbuild two separate vocabularies \u2013 one for shapes (first character) and one for\ncolour strings (everything after the first character) \u2013 then convert each token\nto a numeric 2-D vector `[shape_idx, colour_idx]`.  While touching the code we\nalso give the padding token its own id (so it no longer collides with cluster id\n0).", "We will first cluster glyphs using a lightweight auto-encoder + K-Means exactly\nonce, then feed both token IDs and their cluster IDs into a compact Transformer\nencoder.  Each glyph is represented by the sum of a token embedding, a cluster\nembedding and a sinusoidal positional vector, allowing the network to reason\njointly over raw symbols and their latent groups.  A learnable [CLS] vector is\nprepended so that the sequence can be pooled by simply reading its final hidden\nstate, which is passed to a two-layer MLP classifier.  We train with Adam,\nearly-stopping on complexity-weighted accuracy, and print/record CWA, SWA and\nCompWA every epoch.  All tensors, models and optimizers are moved to GPU when\navailable, and every metric is stored in the experiment_data dictionary and\nsaved to the ./working directory together with a convergence plot.  This\narchitecture should capture longer-range compositional rules better than the\nprevious GRU baseline while still remaining light enough to finish in <30 min on\nCPU.  The complete, self-contained script is below.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, random, time, copy\nfrom typing import List, Dict\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------------------------------------------------------------\n# working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# ---------- Dataset loading helpers (adapted from SPR.py) ------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) * count_color_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------------------------------------------------------------------\n# -------------------- Synthetic fallback -----------------------------\ndef make_synthetic_split(\n    n: int, vocab_shapes=5, vocab_colors=4, max_len=8, num_labels=3\n):\n    rng = random.Random(42 + n)\n    data = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = []\n        for _ in range(L):\n            s = chr(ord(\"A\") + rng.randint(0, vocab_shapes - 1))\n            c = str(rng.randint(0, vocab_colors - 1))\n            seq.append(s + c)\n        data[\"id\"].append(str(i))\n        data[\"sequence\"].append(\" \".join(seq))\n        data[\"label\"].append(rng.randint(0, num_labels - 1))\n    return data\n\n\ndef load_data():\n    spr_root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    try:\n        if not spr_root.exists():\n            raise FileNotFoundError\n        dset = load_spr_bench(spr_root)\n    except Exception:\n        print(\"SPR_BENCH not found \u2013 using synthetic data.\")\n        train = make_synthetic_split(3000)\n        dev = make_synthetic_split(600)\n        test = make_synthetic_split(600)\n        dset = DatasetDict(\n            {\n                \"train\": load_dataset(\n                    \"json\", data_files={\"train\": train}, split=\"train\"\n                ),\n                \"dev\": load_dataset(\"json\", data_files={\"train\": dev}, split=\"train\"),\n                \"test\": load_dataset(\"json\", data_files={\"train\": test}, split=\"train\"),\n            }\n        )\n    return dset\n\n\ndset = load_data()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Classes: {num_classes}, Train size: {len(dset['train'])}\")\n\n\n# ---------------------------------------------------------------------\n# --------------------- Tokenisation & Vocab --------------------------\ndef build_vocab(sequences: List[str]) -> Dict[str, int]:\n    vocab = {}\n    for seq in sequences:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab) + 1  # reserve 0 for padding\n    return vocab\n\n\nvocab = build_vocab(dset[\"train\"][\"sequence\"])\nvocab_size = len(vocab) + 1\nprint(f\"Vocab size: {vocab_size}\")\n\n\ndef encode_sequence(sequence: str) -> List[int]:\n    return [vocab.get(tok, 0) for tok in sequence.split()]\n\n\n# ---------------------------------------------------------------------\n# -------------------- Torch Dataset wrapper --------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.hf_split = hf_split\n        self.ids = hf_split[\"id\"]\n        self.seqs = [encode_sequence(s) for s in hf_split[\"sequence\"]]\n        self.labels = hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"seq\": torch.tensor(self.seqs[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate_fn(batch):\n    lengths = [len(b[\"seq\"]) for b in batch]\n    max_len = max(lengths)\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    for i, b in enumerate(batch):\n        padded[i, : lengths[i]] = b[\"seq\"]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    return {\"seq\": padded, \"lengths\": torch.tensor(lengths), \"label\": labels}\n\n\ntrain_ds = SPRTorchDataset(dset[\"train\"])\ndev_ds = SPRTorchDataset(dset[\"dev\"])\n\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate_fn)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate_fn)\n\n\n# ---------------------------------------------------------------------\n# -------------------------- Model ------------------------------------\nclass AvgEmbClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.fc = nn.Sequential(\n            nn.Linear(emb_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        mask = (x != 0).float().unsqueeze(-1)\n        summed = (self.embed(x) * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1e-6)\n        avg = summed / lengths\n        return self.fc(avg)\n\n\nmodel = AvgEmbClassifier(vocab_size, 32, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------------------------------------------------------------------\n# -------------- Experiment data tracking structure -------------------\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---------------------------------------------------------------------\n# ------------------------- Training loop with tuning -----------------\nMAX_EPOCHS = 30\npatience = 5\nbest_val_cpx = -1.0\nno_improve = 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    t_start = time.time()\n    model.train()\n    total_loss = 0.0\n    n = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"seq\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch[\"label\"].size(0)\n        n += batch[\"label\"].size(0)\n    train_loss = total_loss / n\n\n    # ----- Evaluation helper\n    def evaluate(loader):\n        model.eval()\n        preds, labels = [], []\n        with torch.no_grad():\n            for batch in loader:\n                batch = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"seq\"])\n                preds.extend(logits.argmax(1).cpu().tolist())\n                labels.extend(batch[\"label\"].cpu().tolist())\n        return preds, labels\n\n    train_preds, train_labels = evaluate(train_loader)\n    val_preds, val_labels = evaluate(dev_loader)\n\n    train_raw = dset[\"train\"][\"sequence\"]\n    val_raw = dset[\"dev\"][\"sequence\"]\n\n    train_cwa = color_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cwa = color_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_swa = shape_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_swa = shape_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_cpx = complexity_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cpx = complexity_weighted_accuracy(val_raw, val_labels, val_preds)\n\n    # Logging\n    exp_ref = experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"]\n    exp_ref[\"metrics\"][\"train\"].append(\n        {\"cwa\": train_cwa, \"swa\": train_swa, \"cpx\": train_cpx}\n    )\n    exp_ref[\"metrics\"][\"val\"].append({\"cwa\": val_cwa, \"swa\": val_swa, \"cpx\": val_cpx})\n    exp_ref[\"losses\"][\"train\"].append(train_loss)\n    exp_ref[\"losses\"][\"val\"].append(None)\n    exp_ref[\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch:02d} | TrainLoss {train_loss:.4f} | Val CpxWA {val_cpx:.4f} | Time {(time.time()-t_start):.1f}s\"\n    )\n\n    # Early stopping logic\n    if val_cpx > best_val_cpx + 1e-6:\n        best_val_cpx = val_cpx\n        no_improve = 0\n        exp_ref[\"predictions\"] = val_preds\n        exp_ref[\"ground_truth\"] = val_labels\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(\n                f\"No improvement for {patience} epochs \u2013 early stopping at epoch {epoch}.\"\n            )\n            break\n\n# ---------------------------------------------------------------------\n# -------------------- Save metrics & plot ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\ncpx_vals = [\n    m[\"cpx\"] for m in experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"metrics\"][\"val\"]\n]\nplt.figure()\nplt.plot(experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"epochs\"], cpx_vals, marker=\"o\")\nplt.title(\"Validation Complexity-Weighted Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CpxWA\")\nplt.savefig(os.path.join(working_dir, \"cpxwa_curve.png\"))\nprint(\"Finished. Results saved in working/.\")\n", "import os, time, random, pathlib, math, copy, numpy as np\nfrom collections import defaultdict\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom datasets import load_dataset, DatasetDict\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------------\n# ===== 1.  HELPERS (metrics + IO) =================================\ndef count_color_variety(seq):  # token = ShapeChar + ColorChar\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef color_weighted_acc(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_acc(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef complexity_weighted_acc(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# ------------------------------------------------------------------\n# ===== 2.  DATA  ===================================================\ndef load_spr(root):\n    def _l(name):\n        return load_dataset(\n            \"csv\", data_files=str(root / name), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(train=_l(\"train.csv\"), dev=_l(\"dev.csv\"), test=_l(\"test.csv\"))\n\n\ndef make_synth(n, shapes=6, colors=5, max_len=8, num_labels=4, seed=123):\n    rng = random.Random(seed)\n    data = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = \" \".join(\n            chr(ord(\"A\") + rng.randint(0, shapes - 1)) + str(rng.randint(0, colors - 1))\n            for _ in range(L)\n        )\n        data[\"id\"].append(str(i))\n        data[\"sequence\"].append(seq)\n        data[\"label\"].append(rng.randint(0, num_labels - 1))\n    return data\n\n\ndef get_dataset():\n    root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    try:\n        if not root.exists():\n            raise FileNotFoundError\n        print(\"Using real SPR_BENCH\")\n        return load_spr(root)\n    except Exception:\n        print(\"SPR_BENCH not found \u2013 generating synthetic.\")\n        train = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(4000)]}, split=\"train\"\n        )\n        dev = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(800, seed=999)]}, split=\"train\"\n        )\n        test = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(1000, seed=555)]}, split=\"train\"\n        )\n        return DatasetDict(train=train, dev=dev, test=test)\n\n\ndset = get_dataset()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Num classes={num_classes}\")\n\n# ------------------------------------------------------------------\n# ===== 3.  TOKEN VOCAB & GLYPH CLUSTERING ==========================\nall_tokens = set(tok for seq in dset[\"train\"][\"sequence\"] for tok in seq.split())\nvocab = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}  # 0=pad\nvocab_size = len(vocab) + 1\nprint(f\"Vocab size={vocab_size}\")\n\n# --- build one-hot glyph matrix for clustering\nonehots = np.eye(vocab_size - 1, dtype=np.float32)  # index order matches sorted tokens\n# simple autoencoder to get dense rep\nae_dim = 4\nae = nn.Sequential(\n    nn.Linear(vocab_size - 1, ae_dim), nn.Tanh(), nn.Linear(ae_dim, vocab_size - 1)\n)\noptim_ae = torch.optim.Adam(ae.parameters(), lr=1e-2)\ncriterion = nn.MSELoss()\nonehots_t = torch.tensor(onehots)\nfor epoch in range(200):\n    optim_ae.zero_grad()\n    out = ae(onehots_t)\n    loss = criterion(out, onehots_t)\n    loss.backward()\n    optim_ae.step()\n    if epoch % 50 == 0:\n        print(f\"AE epoch {epoch} loss {loss.item():.4f}\")\nwith torch.no_grad():\n    latents = ae[:2](onehots_t).numpy()  # 4-dim latent\n\n# ---- KMeans\nK = 8\nkm = KMeans(n_clusters=K, random_state=0, n_init=\"auto\").fit(latents)\ncluster_ids = km.labels_  # len = vocab_size-1\ncluster_map = {tok: cluster_ids[i] for i, tok in enumerate(sorted(all_tokens))}\nprint(\"Cluster counts:\", np.bincount(cluster_ids))\n\n\n# ------------------------------------------------------------------\n# ===== 4.  TORCH DATA WRAPPER ======================================\ndef encode_seq(seq):\n    ids = [vocab.get(tok, 0) for tok in seq.split()]\n    clust = [cluster_map.get(tok, 0) for tok in seq.split()]\n    return ids, clust\n\n\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        enc = [encode_seq(s) for s in split[\"sequence\"]]\n        self.ids = [e[0] for e in enc]\n        self.clust = [e[1] for e in enc]\n        self.labels = split[\"label\"]\n        self.raw = split[\"sequence\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"tok\": torch.tensor(self.ids[idx], dtype=torch.long),\n            \"clu\": torch.tensor(self.clust[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"tok\"]) for b in batch)\n    pad = torch.zeros((len(batch), maxlen), dtype=torch.long)\n    padc = torch.zeros((len(batch), maxlen), dtype=torch.long)\n    lens = []\n    labs = []\n    for i, b in enumerate(batch):\n        L = len(b[\"tok\"])\n        pad[i, :L] = b[\"tok\"]\n        padc[i, :L] = b[\"clu\"]\n        lens.append(L)\n        labs.append(b[\"label\"])\n    return {\n        \"tok\": pad,\n        \"clu\": padc,\n        \"len\": torch.tensor(lens),\n        \"label\": torch.stack(labs),\n    }\n\n\ntrain_ds = SPRTorch(dset[\"train\"])\ndev_ds = SPRTorch(dset[\"dev\"])\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate)\n\n\n# ------------------------------------------------------------------\n# ===== 5.  MODEL ====================================================\nclass ClusterAwareClassifier(nn.Module):\n    def __init__(self, vocab_sz, cluster_k, emb=32, hid=64, classes=3):\n        super().__init__()\n        self.emb_tok = nn.Embedding(vocab_sz, emb, padding_idx=0)\n        self.emb_clu = nn.Embedding(cluster_k, emb, padding_idx=0)\n        self.rnn = nn.GRU(emb, hid, batch_first=True, bidirectional=True)\n        self.fc = nn.Sequential(\n            nn.Linear(hid * 2, 128), nn.ReLU(), nn.Linear(128, classes)\n        )\n\n    def forward(self, tok, clu, len_):\n        x = self.emb_tok(tok) + self.emb_clu(clu)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            x, len_.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.rnn(packed)\n        h = torch.cat([h[0], h[1]], dim=1)\n        return self.fc(h)\n\n\nmodel = ClusterAwareClassifier(vocab_size, K, classes=num_classes).to(device)\ncriterion_cls = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ------------------------------------------------------------------\n# ===== 6.  EXPERIMENT DATA STORE ===================================\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n\n# ------------------------------------------------------------------\n# ===== 7.  TRAIN / EVAL ============================================\ndef eval_loader(loader, raw_seqs):\n    model.eval()\n    preds, labels = [], []\n    with torch.no_grad():\n        for b in loader:\n            b = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in b.items()\n            }\n            logits = model(b[\"tok\"], b[\"clu\"], b[\"len\"])\n            preds.extend(logits.argmax(1).cpu().tolist())\n            labels.extend(b[\"label\"].cpu().tolist())\n    cwa = color_weighted_acc(raw_seqs, labels, preds)\n    swa = shape_weighted_acc(raw_seqs, labels, preds)\n    cpx = complexity_weighted_acc(raw_seqs, labels, preds)\n    return preds, labels, (cwa, swa, cpx)\n\n\nMAX_EPOCHS = 25\npatience = 5\nbest_val = -1\nstall = 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    t0 = time.time()\n    model.train()\n    total = 0\n    n = 0\n    for b in train_loader:\n        b = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in b.items()\n        }\n        optimizer.zero_grad()\n        out = model(b[\"tok\"], b[\"clu\"], b[\"len\"])\n        loss = criterion_cls(out, b[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total += loss.item() * b[\"label\"].size(0)\n        n += b[\"label\"].size(0)\n    train_loss = total / n\n    train_preds, train_labels, (tr_cwa, tr_swa, tr_cpx) = eval_loader(\n        train_loader, train_ds.raw\n    )\n    val_preds, val_labels, (v_cwa, v_swa, v_cpx) = eval_loader(dev_loader, dev_ds.raw)\n\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"epochs\"].append(epoch)\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"metrics\"][\"train\"].append({\"cwa\": tr_cwa, \"swa\": tr_swa, \"cpx\": tr_cpx})\n    ed[\"metrics\"][\"val\"].append({\"cwa\": v_cwa, \"swa\": v_swa, \"cpx\": v_cpx})\n\n    print(\n        f\"Epoch {epoch:02d} loss={train_loss:.4f}  ValCpx={v_cpx:.4f}  (CWA {v_cwa:.3f} SWA {v_swa:.3f})  time {time.time()-t0:.1f}s\"\n    )\n\n    if v_cpx > best_val + 1e-6:\n        best_val = v_cpx\n        stall = 0\n        ed[\"predictions\"] = val_preds\n        ed[\"ground_truth\"] = val_labels\n    else:\n        stall += 1\n        if stall >= patience:\n            print(\"Early stop.\")\n            break\n\n# ------------------------------------------------------------------\n# ===== 8.  SAVE / PLOT =============================================\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nval_cpx = [m[\"cpx\"] for m in experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"]]\nplt.figure()\nplt.plot(experiment_data[\"SPR_BENCH\"][\"epochs\"], val_cpx, marker=\"o\")\nplt.title(\"Val Complexity-Weighted Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CpxWA\")\nplt.savefig(os.path.join(working_dir, \"val_cpxwa.png\"))\nprint(\"Finished; artefacts saved in ./working\")\n", "import os, pathlib, random, time, copy, warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# ---------------------------------------------------------------------\n# working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# device handling\nimport torch, numpy as np\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------------------------------------------------------------\n# Dataset utilities  (light version of SPR.py)\nfrom datasets import load_dataset, DatasetDict\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef color_weighted_accuracy(seqs, y, p):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wi if yt == pt else 0 for wi, yt, pt in zip(w, y, p)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0\n\n\ndef shape_weighted_accuracy(seqs, y, p):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wi if yt == pt else 0 for wi, yt, pt in zip(w, y, p)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0\n\n\ndef complexity_weighted_accuracy(seqs, y, p):\n    w = [count_shape_variety(s) * count_color_variety(s) for s in seqs]\n    c = [wi if yt == pt else 0 for wi, yt, pt in zip(w, y, p)]\n    return sum(c) / sum(w) if sum(w) > 0 else 0\n\n\n# ---------------------------------------------------------------------\n# Synthetic fallback if benchmark not present\ndef make_synthetic(n, shapes=5, colors=4, max_len=8, num_labels=3):\n    rng = random.Random(123 + n)\n    return {\n        \"id\": [str(i) for i in range(n)],\n        \"sequence\": [\n            \" \".join(\n                chr(65 + rng.randint(0, shapes - 1)) + str(rng.randint(0, colors - 1))\n                for _ in range(rng.randint(3, max_len))\n            )\n            for i in range(n)\n        ],\n        \"label\": [rng.randint(0, num_labels - 1) for _ in range(n)],\n    }\n\n\ndef load_data():\n    root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    try:\n        if not root.exists():\n            raise FileNotFoundError\n        return load_spr_bench(root)\n    except Exception:\n        print(\"SPR_BENCH not found, generating synthetic data.\")\n        return DatasetDict(\n            {\n                \"train\": load_dataset(\n                    \"json\", data_files={\"train\": [make_synthetic(3000)]}, split=\"train\"\n                ),\n                \"dev\": load_dataset(\n                    \"json\", data_files={\"train\": [make_synthetic(600)]}, split=\"train\"\n                ),\n                \"test\": load_dataset(\n                    \"json\", data_files={\"train\": [make_synthetic(600)]}, split=\"train\"\n                ),\n            }\n        )\n\n\ndset = load_data()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Train size: {len(dset['train'])}, classes: {num_classes}\")\n\n# ---------------------------------------------------------------------\n# Build vocab\nvocab = {}\nfor seq in dset[\"train\"][\"sequence\"]:\n    for tok in seq.split():\n        if tok not in vocab:\n            vocab[tok] = len(vocab) + 1  # 0 reserved for padding\nvocab_size = len(vocab) + 1\nprint(\"Vocab size:\", vocab_size)\n\n\ndef encode_sequence(seq):\n    return [vocab[tok] for tok in seq.split()]\n\n\n# ---------------------------------------------------------------------\n# Glyph clustering  (feature: [shape_idx, colour_idx])\nfrom sklearn.cluster import KMeans\n\ntok_features = []\ntokens = []\nfor tok, idx in vocab.items():\n    if len(tok) >= 2:\n        shape_idx = ord(tok[0]) - 65\n        color_idx = int(tok[1])\n    else:\n        shape_idx, color_idx = 0, 0\n    tok_features.append([shape_idx, color_idx])\n    tokens.append(tok)\nk = min(10, len(tokens))\nkmeans = KMeans(n_clusters=k, n_init=\"auto\", random_state=42).fit(tok_features)\ncluster_ids = {tok: (kmeans.labels_[i] + 1) for i, tok in enumerate(tokens)}  # 0 pad\ncluster_vocab_size = k + 1\nprint(\"Cluster count:\", k)\n\n\ndef clusters_for_sequence(seq):\n    return [cluster_ids[tok] for tok in seq.split()]\n\n\n# ---------------------------------------------------------------------\n# Torch dataset\nfrom torch.utils.data import Dataset, DataLoader\n\n\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = [encode_sequence(s) for s in hf_split[\"sequence\"]]\n        self.clus = [clusters_for_sequence(s) for s in hf_split[\"sequence\"]]\n        self.labels = hf_split[\"label\"]\n        self.raw = hf_split[\"sequence\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"seq\": torch.tensor(self.seqs[idx], dtype=torch.long),\n            \"clus\": torch.tensor(self.clus[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw\": self.raw[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"seq\"]) for b in batch)\n    seqs = torch.zeros(len(batch), maxlen, dtype=torch.long)\n    clus = torch.zeros(len(batch), maxlen, dtype=torch.long)\n    for i, b in enumerate(batch):\n        l = len(b[\"seq\"])\n        seqs[i, :l] = b[\"seq\"]\n        clus[i, :l] = b[\"clus\"]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raws = [b[\"raw\"] for b in batch]\n    return {\"seq\": seqs, \"clus\": clus, \"label\": labels, \"raw\": raws}\n\n\ntrain_loader = DataLoader(\n    SPRTorchDataset(dset[\"train\"]), batch_size=64, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(dset[\"dev\"]), batch_size=128, shuffle=False, collate_fn=collate\n)\n\n# ---------------------------------------------------------------------\n# Model\nimport torch.nn as nn\n\n\nclass DualEmbClassifier(nn.Module):\n    def __init__(self, vocab_sz, cluster_sz, emb_dim, num_classes):\n        super().__init__()\n        self.tok_emb = nn.Embedding(vocab_sz, emb_dim, padding_idx=0)\n        self.clu_emb = nn.Embedding(cluster_sz, emb_dim, padding_idx=0)\n        self.fc = nn.Sequential(\n            nn.Linear(emb_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n\n    def forward(self, tok, clu):\n        mask = (tok != 0).float().unsqueeze(-1)\n        emb = self.tok_emb(tok) + self.clu_emb(clu)\n        summed = (emb * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1e-6)\n        avg = summed / lengths\n        return self.fc(avg)\n\n\nmodel = DualEmbClassifier(vocab_size, cluster_vocab_size, 32, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------------------------------------------------------------------\n# experiment data structure\nexperiment_data = {\n    \"glyph_clustering\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---------------------------------------------------------------------\n# training loop\nMAX_EPOCHS = 20\npatience = 4\nbest_val_cpx = -1\nno_imp = 0\n\n\ndef evaluate(loader):\n    model.eval()\n    preds, labels, raws = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch_t[\"seq\"], batch_t[\"clus\"])\n            preds.extend(logits.argmax(1).cpu().tolist())\n            labels.extend(batch_t[\"label\"].cpu().tolist())\n            raws.extend(batch_t[\"raw\"])\n    return preds, labels, raws\n\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    t0 = time.time()\n    model.train()\n    running_loss, n_total = 0, 0\n    for batch in train_loader:\n        batch_t = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        out = model(batch_t[\"seq\"], batch_t[\"clus\"])\n        loss = criterion(out, batch_t[\"label\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch_t[\"label\"].size(0)\n        n_total += batch_t[\"label\"].size(0)\n    train_loss = running_loss / n_total\n\n    train_preds, train_labels, train_raw = evaluate(train_loader)\n    val_preds, val_labels, val_raw = evaluate(dev_loader)\n\n    train_cwa = color_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cwa = color_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_swa = shape_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_swa = shape_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_cpx = complexity_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cpx = complexity_weighted_accuracy(val_raw, val_labels, val_preds)\n\n    rec = experiment_data[\"glyph_clustering\"][\"SPR_BENCH\"]\n    rec[\"epochs\"].append(epoch)\n    rec[\"losses\"][\"train\"].append(train_loss)\n    rec[\"losses\"][\"val\"].append(None)\n    rec[\"metrics\"][\"train\"].append(\n        {\"cwa\": train_cwa, \"swa\": train_swa, \"cpx\": train_cpx}\n    )\n    rec[\"metrics\"][\"val\"].append({\"cwa\": val_cwa, \"swa\": val_swa, \"cpx\": val_cpx})\n\n    print(\n        f\"Epoch {epoch:02d} | TrainLoss {train_loss:.4f} | Val CompWA {val_cpx:.4f} | Time {time.time()-t0:.1f}s\"\n    )\n\n    if val_cpx > best_val_cpx + 1e-6:\n        best_val_cpx = val_cpx\n        no_imp = 0\n        rec[\"predictions\"] = val_preds\n        rec[\"ground_truth\"] = val_labels\n    else:\n        no_imp += 1\n        if no_imp >= patience:\n            print(\"Early stopping\")\n            break\n\n# ---------------------------------------------------------------------\n# save metrics\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All metrics saved to working/experiment_data.npy\")\n", "import os, pathlib, random, time\nfrom typing import List, Dict\nimport numpy as np\nimport torch, math\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- helper: load official or synthetic SPR ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    d = DatasetDict()\n    d[\"train\"] = _load(\"train.csv\")\n    d[\"dev\"] = _load(\"dev.csv\")\n    d[\"test\"] = _load(\"test.csv\")\n    return d\n\n\ndef make_synth(n: int, rng_seed: int = 0):\n    rng = random.Random(rng_seed)\n    data = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, 8)\n        seq = []\n        for _ in range(L):\n            shape = chr(ord(\"A\") + rng.randint(0, 5))\n            color = str(rng.randint(0, 3))\n            seq.append(shape + color)\n        data[\"id\"].append(str(i))\n        data[\"sequence\"].append(\" \".join(seq))\n        data[\"label\"].append(rng.randint(0, 2))\n    return data\n\n\ndef load_data():\n    root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    if root.exists():\n        try:\n            return load_spr_bench(root)\n        except Exception as e:\n            print(\"Load failed, using synthetic. Err:\", e)\n    print(\"SPR_BENCH not found, using synthetic dataset.\")\n    tr, dv, te = make_synth(4000, 1), make_synth(800, 2), make_synth(800, 3)\n    return DatasetDict(\n        {\n            \"train\": load_dataset(\"json\", data_files={\"train\": tr}, split=\"train\"),\n            \"dev\": load_dataset(\"json\", data_files={\"train\": dv}, split=\"train\"),\n            \"test\": load_dataset(\"json\", data_files={\"train\": te}, split=\"train\"),\n        }\n    )\n\n\ndset = load_data()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(\"Num classes:\", num_classes)\n\n\n# ---------- metrics ----------\ndef count_color_variety(seq: str) -> int:\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef color_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef shape_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef complexity_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_shape_variety(s) * count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\n# ---------- clustering ----------\nsequences_train = dset[\"train\"][\"sequence\"]\nall_tokens = set()\nfor s in sequences_train:\n    all_tokens.update(s.split())\nall_tokens = sorted(all_tokens)\n# feature: [shape_idx, color_idx]\nfeat = []\nfor tok in all_tokens:\n    shape_idx = ord(tok[0]) - ord(\"A\")\n    color_idx = int(tok[1]) if len(tok) > 1 and tok[1].isdigit() else 0\n    feat.append([shape_idx, color_idx])\nfeat = np.array(feat, dtype=np.float32)\n\ntry:\n    from sklearn.cluster import KMeans\n\n    k = min(max(8, int(math.sqrt(len(all_tokens)) + 5)), len(all_tokens))\n    print(\"Clustering glyphs into\", k, \"clusters\")\n    km = KMeans(n_clusters=k, n_init=\"auto\", random_state=0)\n    cluster_ids = km.fit_predict(feat)\n    tok2cluster = {\n        tok: int(cid) + 1 for tok, cid in zip(all_tokens, cluster_ids)\n    }  # +1 reserve 0 padding\nexcept Exception as e:\n    print(\"sklearn not available, using identity mapping.\", e)\n    tok2cluster = {tok: i + 1 for i, tok in enumerate(all_tokens)}\nk = max(tok2cluster.values()) + 1\nprint(\"Effective cluster vocab size:\", k)\n\n\ndef encode_seq(seq: str) -> List[int]:\n    return [tok2cluster.get(tok, 0) for tok in seq.split()]\n\n\n# ---------- torch dataset ----------\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.seq_enc = [encode_seq(s) for s in split[\"sequence\"]]\n        self.labels = split[\"label\"]\n        self.raw = split[\"sequence\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"seq\": torch.tensor(self.seq_enc[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw\": self.raw[idx],\n        }\n\n\ndef collate(batch):\n    lens = [len(b[\"seq\"]) for b in batch]\n    maxlen = max(lens)\n    padded = torch.zeros(len(batch), maxlen, dtype=torch.long)\n    for i, b in enumerate(batch):\n        padded[i, : lens[i]] = b[\"seq\"]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raws = [b[\"raw\"] for b in batch]\n    return {\"seq\": padded, \"lengths\": torch.tensor(lens), \"label\": labels, \"raw\": raws}\n\n\ntrain_dl = DataLoader(\n    SPRTorch(dset[\"train\"]), batch_size=64, shuffle=True, collate_fn=collate\n)\ndev_dl = DataLoader(\n    SPRTorch(dset[\"dev\"]), batch_size=128, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass AvgEmbClassifier(nn.Module):\n    def __init__(self, vocab, dim, num_cls):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, dim, padding_idx=0)\n        self.fc = nn.Sequential(nn.Linear(dim, 128), nn.ReLU(), nn.Linear(128, num_cls))\n\n    def forward(self, x):\n        mask = (x != 0).unsqueeze(-1)\n        summed = (self.emb(x) * mask).sum(1)\n        denom = mask.sum(1).clamp(min=1e-6)\n        avg = summed / denom\n        return self.fc(avg)\n\n\nmodel = AvgEmbClassifier(k, 32, num_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\n# ---------- tracking ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# ---------- train ----------\nmax_epochs = 20\npatience = 5\nbest_val = -1\nnoimp = 0\nfor epoch in range(1, max_epochs + 1):\n    t0 = time.time()\n    model.train()\n    tot_loss = 0\n    n = 0\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"seq\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        tot_loss += loss.item() * batch[\"label\"].size(0)\n        n += batch[\"label\"].size(0)\n    train_loss = tot_loss / n\n\n    # evaluation function\n    def run(dl):\n        model.eval()\n        preds = []\n        labels = []\n        raws = []\n        with torch.no_grad():\n            for b in dl:\n                tb = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in b.items()\n                }\n                out = model(tb[\"seq\"]).argmax(1).cpu().tolist()\n                preds.extend(out)\n                labels.extend(tb[\"label\"].cpu().tolist())\n                raws.extend(tb[\"raw\"])\n        return preds, labels, raws\n\n    tr_pred, tr_lab, tr_raw = run(train_dl)\n    dv_pred, dv_lab, dv_raw = run(dev_dl)\n\n    tr_cwa = color_weighted_accuracy(tr_raw, tr_lab, tr_pred)\n    dv_cwa = color_weighted_accuracy(dv_raw, dv_lab, dv_pred)\n    tr_swa = shape_weighted_accuracy(tr_raw, tr_lab, tr_pred)\n    dv_swa = shape_weighted_accuracy(dv_raw, dv_lab, dv_pred)\n    tr_cpx = complexity_weighted_accuracy(tr_raw, tr_lab, tr_pred)\n    dv_cpx = complexity_weighted_accuracy(dv_raw, dv_lab, dv_pred)\n\n    ref = experiment_data[\"SPR_BENCH\"]\n    ref[\"epochs\"].append(epoch)\n    ref[\"losses\"][\"train\"].append(train_loss)\n    ref[\"losses\"][\"val\"].append(None)\n    ref[\"metrics\"][\"train\"].append({\"cwa\": tr_cwa, \"swa\": tr_swa, \"cpx\": tr_cpx})\n    ref[\"metrics\"][\"val\"].append({\"cwa\": dv_cwa, \"swa\": dv_swa, \"cpx\": dv_cpx})\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f} | Val CpxWA={dv_cpx:.4f} | time={time.time()-t0:.1f}s\"\n    )\n\n    if dv_cpx > best_val + 1e-6:\n        best_val = dv_cpx\n        noimp = 0\n        ref[\"predictions\"] = dv_pred\n        ref[\"ground_truth\"] = dv_lab\n    else:\n        noimp += 1\n        if noimp >= patience:\n            print(\"Early stopping.\")\n            break\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Experiment data saved to working/.\")\n", "import os, pathlib, random, time, copy, json, math, warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# ------------------------------------------------------------------\n# Working dir (for figures / npy dumps etc.)\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\n# Torch / device\nimport torch, numpy as np\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------------------------------------------------------\n# HF datasets helper (taken from baseline SPR.py)\nfrom datasets import load_dataset, DatasetDict\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\n# ---------- metrics ------------------------------------------------\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if len(tok) > 0))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\n# ------------------------------------------------------------------\n# Fallback synthetic data (so code always runs)\ndef make_synth(n, shapes=6, colors=5, max_len=8, num_labels=3, seed=0):\n    rng = random.Random(seed)\n    rows = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = \" \".join(\n            chr(ord(\"A\") + rng.randint(0, shapes - 1)) + str(rng.randint(0, colors - 1))\n            for _ in range(L)\n        )\n        rows[\"id\"].append(str(i))\n        rows[\"sequence\"].append(seq)\n        rows[\"label\"].append(rng.randint(0, num_labels - 1))\n    return rows\n\n\ndef load_data():\n    root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    if root.exists():\n        print(\"Loading real SPR_BENCH \u2026\")\n        return load_spr_bench(root)\n    print(\"SPR_BENCH not found \u2013 using synthetic mock data.\")\n    train, dev, test = (\n        make_synth(4000, seed=1),\n        make_synth(800, seed=2),\n        make_synth(800, seed=3),\n    )\n    return DatasetDict(\n        {\n            \"train\": load_dataset(\"json\", data_files=train, split=\"train\"),\n            \"dev\": load_dataset(\"json\", data_files=dev, split=\"train\"),\n            \"test\": load_dataset(\"json\", data_files=test, split=\"train\"),\n        }\n    )\n\n\ndset = load_data()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Train size {len(dset['train'])}, num_classes {num_classes}\")\n\n# ------------------------------------------------------------------\n# Step 1: Glyph clustering ------------------------------------------\nfrom sklearn.cluster import MiniBatchKMeans\n\n\ndef token_to_vec(tok: str):\n    # simple 2-dim (shape_idx, color_idx)\n    return np.array([ord(tok[0]) - ord(\"A\"), int(tok[1])], dtype=np.float32)\n\n\nunique_tokens = set()\nfor s in dset[\"train\"][\"sequence\"]:\n    unique_tokens.update(s.split())\ntok_list = sorted(list(unique_tokens))\nX = np.stack([token_to_vec(t) for t in tok_list])\nK = min(20, len(tok_list))  # cap clusters to 20\nkmeans = MiniBatchKMeans(\n    n_clusters=K, random_state=0, batch_size=K * 3, n_init=10, max_no_improvement=5\n).fit(X)\ntoken2cluster = {tok: int(kmeans.predict([token_to_vec(tok)])[0]) for tok in tok_list}\nUNK_ID = K  # for unseen glyphs\ncluster_vocab_size = K + 1  # +1 for UNK\n\n\ndef encode_sequence(seq: str):\n    return [token2cluster.get(tok, UNK_ID) for tok in seq.split()]\n\n\n# ------------------------------------------------------------------\n# PyTorch dataset\nclass SPRClusterDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = [encode_sequence(s) for s in hf_split[\"sequence\"]]\n        self.labels = hf_split[\"label\"]\n        self.raw_seqs = hf_split[\"sequence\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"seq\": torch.tensor(self.seqs[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw\": self.raw_seqs[idx],\n        }\n\n\ndef collate(batch):\n    lengths = [len(b[\"seq\"]) for b in batch]\n    maxL = max(lengths)\n    padded = torch.zeros(len(batch), maxL, dtype=torch.long)\n    for i, b in enumerate(batch):\n        padded[i, : lengths[i]] = b[\"seq\"]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raws = [b[\"raw\"] for b in batch]\n    return {\n        \"seq\": padded,\n        \"lengths\": torch.tensor(lengths),\n        \"label\": labels,\n        \"raw\": raws,\n    }\n\n\ntrain_ds, dev_ds = SPRClusterDataset(dset[\"train\"]), SPRClusterDataset(dset[\"dev\"])\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate)\n\n\n# ------------------------------------------------------------------\n# Model: embedding avg + MLP\nclass AvgEmbClassifier(nn.Module):\n    def __init__(self, vocab, emb_dim, out_dim):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb_dim, padding_idx=0)\n        self.mlp = nn.Sequential(\n            nn.Linear(emb_dim, 128), nn.ReLU(), nn.Linear(128, out_dim)\n        )\n\n    def forward(self, x):\n        mask = (x != 0).float().unsqueeze(-1)\n        summed = (self.emb(x) * mask).sum(1)\n        avg = summed / mask.sum(1).clamp(min=1e-6)\n        return self.mlp(avg)\n\n\nmodel = AvgEmbClassifier(cluster_vocab_size, 32, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ------------------------------------------------------------------\n# Experiment tracking dict\nexperiment_data = {\n    \"SPR_Cluster\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# ------------------------------------------------------------------\n# Train loop with early stopping on complexity-WA\nbest_val_cpx = -1\npatience, no_improve = 5, 0\nMAX_EPOCHS = 30\n\n\ndef evaluate(loader):\n    model.eval()\n    all_preds, all_labels, all_raws = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"seq\"])\n            all_preds.extend(logits.argmax(1).cpu().tolist())\n            all_labels.extend(batch[\"label\"].cpu().tolist())\n            all_raws.extend(batch[\"raw\"])\n    return all_preds, all_labels, all_raws\n\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    tic = time.time()\n    # ---- train\n    model.train()\n    running_loss, n = 0, 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"seq\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch[\"label\"].size(0)\n        n += batch[\"label\"].size(0)\n    train_loss = running_loss / n\n\n    # ---- evaluate\n    train_preds, train_labels, train_raws = evaluate(train_loader)\n    val_preds, val_labels, val_raws = evaluate(dev_loader)\n\n    tr_cwa = color_weighted_accuracy(train_raws, train_labels, train_preds)\n    va_cwa = color_weighted_accuracy(val_raws, val_labels, val_preds)\n    tr_swa = shape_weighted_accuracy(train_raws, train_labels, train_preds)\n    va_swa = shape_weighted_accuracy(val_raws, val_labels, val_preds)\n    tr_cpx = complexity_weighted_accuracy(train_raws, train_labels, train_preds)\n    va_cpx = complexity_weighted_accuracy(val_raws, val_labels, val_preds)\n\n    # ---- bookkeeping\n    ref = experiment_data[\"SPR_Cluster\"]\n    ref[\"metrics\"][\"train\"].append({\"cwa\": tr_cwa, \"swa\": tr_swa, \"cpx\": tr_cpx})\n    ref[\"metrics\"][\"val\"].append({\"cwa\": va_cwa, \"swa\": va_swa, \"cpx\": va_cpx})\n    ref[\"losses\"][\"train\"].append(train_loss)\n    ref[\"losses\"][\"val\"].append(None)\n    ref[\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_cpxWA={va_cpx:.4f}  time={time.time()-tic:.1f}s\"\n    )\n\n    if va_cpx > best_val_cpx + 1e-6:\n        best_val_cpx = va_cpx\n        no_improve = 0\n        ref[\"predictions\"] = val_preds\n        ref[\"ground_truth\"] = val_labels\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(f\"Early stopping (no val improvement for {patience} epochs).\")\n            break\n\n# ------------------------------------------------------------------\n# Save all experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All metrics saved to working/experiment_data.npy\")\n", "import os, time, random, pathlib, math, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.cluster import KMeans\nfrom datasets import load_dataset, DatasetDict\nimport matplotlib.pyplot as plt\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------------\n# ========== metric helpers ========================================\ndef _shape_id(tok):  # first char\n    return ord(tok[0].upper()) - ord(\"A\")\n\n\ndef _color_id(tok):  # rest is colour numeric if any\n    try:\n        return int(tok[1:])\n    except ValueError:\n        return 0\n\n\ndef count_color_variety(sequence):\n    return len(set(_color_id(t) for t in sequence.split() if t))\n\n\ndef count_shape_variety(sequence):\n    return len(set(_shape_id(t) for t in sequence.split() if t))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, yt, yp in zip(w, y_true, y_pred) if yt == yp) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, yt, yp in zip(w, y_true, y_pred) if yt == yp) / max(sum(w), 1)\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, yt, yp in zip(w, y_true, y_pred) if yt == yp) / max(sum(w), 1)\n\n\n# ------------------------------------------------------------------\n# ========== data ===================================================\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef synth_dataset(n_rows, seed=42, shapes=6, colors=6, max_len=8, n_labels=4):\n    rnd = random.Random(seed)\n    rows = []\n    for idx in range(n_rows):\n        L = rnd.randint(3, max_len)\n        seq = \" \".join(\n            chr(ord(\"A\") + rnd.randint(0, shapes - 1)) + str(rnd.randint(0, colors - 1))\n            for _ in range(L)\n        )\n        rows.append(\n            {\"id\": str(idx), \"sequence\": seq, \"label\": rnd.randint(0, n_labels - 1)}\n        )\n    return rows\n\n\ndef get_dataset():\n    root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    if root.exists() and (root / \"train.csv\").exists():\n        print(\"Loaded real SPR_BENCH dataset.\")\n        return load_spr_bench(root)\n    # fallback\n    print(\"Real dataset not found \u2013 using synthetic data.\")\n    return DatasetDict(\n        train=load_dataset(\n            \"json\", data_files={\"train\": [synth_dataset(4000)]}, split=\"train\"\n        ),\n        dev=load_dataset(\n            \"json\", data_files={\"train\": [synth_dataset(800, seed=1)]}, split=\"train\"\n        ),\n        test=load_dataset(\n            \"json\", data_files={\"train\": [synth_dataset(1000, seed=2)]}, split=\"train\"\n        ),\n    )\n\n\ndset = get_dataset()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Number of classes: {num_classes}\")\n\n# ------------------------------------------------------------------\n# ========== vocabulary & clustering ===============================\ntokens = set(tok for seq in dset[\"train\"][\"sequence\"] for tok in seq.split())\ntok2idx = {tok: i + 1 for i, tok in enumerate(sorted(tokens))}  # 0 is PAD\nvocab_size = len(tok2idx) + 1\n\n# 2-dim structural feature per glyph\nfeatures = np.array(\n    [[_shape_id(tok), _color_id(tok)] for tok in sorted(tokens)], dtype=np.float32\n)\nK = 12\nkmeans = KMeans(n_clusters=K, n_init=20, random_state=0).fit(features)\ncluster_ids = kmeans.labels_\ncluster_map = {tok: cluster_ids[i] for i, tok in enumerate(sorted(tokens))}\n\nprint(\"Cluster distribution:\", np.bincount(cluster_ids))\n\n\n# ------------------------------------------------------------------\n# ========== torch dataset =========================================\ndef encode_sequence(seq):\n    toks = seq.split()\n    ids = [tok2idx.get(t, 0) for t in toks]\n    clus = [cluster_map.get(t, 0) for t in toks]\n    return ids, clus\n\n\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        self.raw = split[\"sequence\"]\n        enc = [encode_sequence(s) for s in self.raw]\n        self.ids = [e[0] for e in enc]\n        self.clu = [e[1] for e in enc]\n        self.labels = split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"tok\": torch.tensor(self.ids[idx], dtype=torch.long),\n            \"clu\": torch.tensor(self.clu[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate(batch):\n    max_len = max(len(b[\"tok\"]) for b in batch)\n    tok = torch.zeros((len(batch), max_len), dtype=torch.long)\n    clu = torch.zeros((len(batch), max_len), dtype=torch.long)\n    length = []\n    labels = []\n    for i, b in enumerate(batch):\n        L = len(b[\"tok\"])\n        tok[i, :L] = b[\"tok\"]\n        clu[i, :L] = b[\"clu\"]\n        length.append(L)\n        labels.append(b[\"label\"])\n    return {\n        \"tok\": tok,\n        \"clu\": clu,\n        \"len\": torch.tensor(length),\n        \"label\": torch.stack(labels),\n    }\n\n\ntrain_ds = SPRTorch(dset[\"train\"])\ndev_ds = SPRTorch(dset[\"dev\"])\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate)\n\n\n# ------------------------------------------------------------------\n# ========== model ==================================================\nclass ClusterAwareTransformer(nn.Module):\n    def __init__(\n        self, vocab_sz, cluster_k, emb_dim=64, n_heads=4, n_layers=2, n_classes=3\n    ):\n        super().__init__()\n        self.tok_emb = nn.Embedding(vocab_sz, emb_dim, padding_idx=0)\n        self.clu_emb = nn.Embedding(cluster_k, emb_dim, padding_idx=0)\n        self.pos_emb = nn.Embedding(128, emb_dim)  # assume seq len <128\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=emb_dim, nhead=n_heads, dim_feedforward=256, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n        self.fc = nn.Sequential(\n            nn.Linear(emb_dim, 128), nn.ReLU(), nn.Linear(128, n_classes)\n        )\n\n    def forward(self, tok, clu, length):\n        B, L = tok.shape\n        pos = torch.arange(L, device=tok.device).unsqueeze(0).repeat(B, 1)\n        x = self.tok_emb(tok) + self.clu_emb(clu) + self.pos_emb(pos)\n        mask = tok == 0\n        z = self.encoder(x, src_key_padding_mask=mask)\n        # mean pool ignoring padding\n        mask_f = (~mask).unsqueeze(-1)\n        pooled = (z * mask_f).sum(1) / mask_f.sum(1).clamp(min=1)\n        return self.fc(pooled)\n\n\nmodel = ClusterAwareTransformer(vocab_size, K, n_classes=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-5)\n\n# ------------------------------------------------------------------\n# ========== experiment logger =====================================\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n\n# ------------------------------------------------------------------\n# ========== training ==============================================\ndef evaluate(loader, raw_sequences):\n    model.eval()\n    preds, lbls = [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"tok\"], batch[\"clu\"], batch[\"len\"])\n            preds.extend(logits.argmax(1).cpu().tolist())\n            lbls.extend(batch[\"label\"].cpu().tolist())\n    cwa = color_weighted_accuracy(raw_sequences, lbls, preds)\n    swa = shape_weighted_accuracy(raw_sequences, lbls, preds)\n    cpx = complexity_weighted_accuracy(raw_sequences, lbls, preds)\n    return preds, lbls, (cwa, swa, cpx)\n\n\nbest_val_cpx = -1\npatience, wait = 5, 0\nEPOCHS = 20\nfor epoch in range(1, EPOCHS + 1):\n    t0 = time.time()\n    model.train()\n    total_loss, seen = 0.0, 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        out = model(batch[\"tok\"], batch[\"clu\"], batch[\"len\"])\n        loss = criterion(out, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch[\"label\"].size(0)\n        seen += batch[\"label\"].size(0)\n    train_loss = total_loss / seen\n\n    tr_preds, tr_lbls, (tr_cwa, tr_swa, tr_cpx) = evaluate(train_loader, train_ds.raw)\n    val_preds, val_lbls, (v_cwa, v_swa, v_cpx) = evaluate(dev_loader, dev_ds.raw)\n\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"epochs\"].append(epoch)\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"metrics\"][\"train\"].append({\"cwa\": tr_cwa, \"swa\": tr_swa, \"cpx\": tr_cpx})\n    ed[\"metrics\"][\"val\"].append({\"cwa\": v_cwa, \"swa\": v_swa, \"cpx\": v_cpx})\n\n    print(\n        f\"Epoch {epoch:02d}: validation_loss = {v_cpx:.4f}  | Val CWA {v_cwa:.3f} SWA {v_swa:.3f} Cpx {v_cpx:.3f}\"\n    )\n\n    if v_cpx > best_val_cpx + 1e-6:\n        best_val_cpx = v_cpx\n        wait = 0\n        ed[\"predictions\"] = val_preds\n        ed[\"ground_truth\"] = val_lbls\n        torch.save(model.state_dict(), os.path.join(working_dir, \"best_model.pt\"))\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n# ------------------------------------------------------------------\n# ========== save artefacts ========================================\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nval_cpx_curve = [m[\"cpx\"] for m in experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"]]\nplt.figure()\nplt.plot(experiment_data[\"SPR_BENCH\"][\"epochs\"], val_cpx_curve, marker=\"o\")\nplt.title(\"Validation Complexity-Weighted Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CompWA\")\nplt.savefig(os.path.join(working_dir, \"val_compwa.png\"))\nprint(\"Finished. Data saved to ./working/\")\n", "import os, pathlib, random, time, json, math, warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# -------------------------------------------------------------\n# Working directory for all outputs / plots / npy dumps\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------------------\n# Torch / device\nimport torch, numpy as np\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# -------------------------------------------------------------\n# HF datasets helper (baseline SPR.py loader)\nfrom datasets import load_dataset, DatasetDict\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",  # treat csv as single split\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\n# ----------------------- metrics ---------------------------------\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1:] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.strip().split() if len(tok) > 0))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\n# ------------------- fallback synthetic data ---------------------\ndef make_synth(n, shapes=6, colors=6, max_len=8, num_labels=3, seed=0):\n    rng = random.Random(seed)\n    rows = []\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = \" \".join(\n            chr(ord(\"A\") + rng.randint(0, shapes - 1))\n            + rng.choice(\n                [\n                    str(rng.randint(0, colors - 1)),\n                    chr(ord(\"a\") + rng.randint(0, colors - 1)),\n                ]\n            )\n            for _ in range(L)\n        )\n        rows.append(\n            {\"id\": str(i), \"sequence\": seq, \"label\": rng.randint(0, num_labels - 1)}\n        )\n    return rows\n\n\ndef load_data():\n    root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    if root.exists():\n        print(\"Loading real SPR_BENCH \u2026\")\n        return load_spr_bench(root)\n    print(\"SPR_BENCH not found \u2013 using synthetic mock data.\")\n    train, dev, test = (\n        make_synth(4000, seed=1),\n        make_synth(800, seed=2),\n        make_synth(800, seed=3),\n    )\n    return DatasetDict(\n        {\n            \"train\": load_dataset(\"json\", data_files={\"train\": train}, split=\"train\"),\n            \"dev\": load_dataset(\"json\", data_files={\"dev\": dev}, split=\"train\"),\n            \"test\": load_dataset(\"json\", data_files={\"test\": test}, split=\"train\"),\n        }\n    )\n\n\ndset = load_data()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Train size {len(dset['train'])}, num_classes {num_classes}\")\n\n# -------------------------------------------------------------\n# Step 1 : robust glyph \u2192 feature vector  ----------------------\n# Build colour and shape vocabularies\nshape_to_idx = {chr(ord(\"A\") + i): i for i in range(26)}  # support A-Z\ncolour_to_idx = {}  # built dynamically\n\n\ndef token_to_vec(tok: str):\n    # Shape part\n    shape_char = tok[0]\n    s_id = shape_to_idx.get(shape_char, 0)\n    # Colour part (could be digits or letters)\n    colour_str = tok[1:]\n    if colour_str not in colour_to_idx:\n        colour_to_idx[colour_str] = len(colour_to_idx)\n    c_id = colour_to_idx[colour_str]\n    return np.array([s_id, c_id], dtype=np.float32)\n\n\n# Collect unique tokens from training data\nunique_tokens = set()\nfor s in dset[\"train\"][\"sequence\"]:\n    unique_tokens.update(s.split())\ntok_list = sorted(list(unique_tokens))\nX = np.stack([token_to_vec(tok) for tok in tok_list])\n\n# ----------------- K-Means clustering on glyphs -----------------\nfrom sklearn.cluster import MiniBatchKMeans\n\nK = min(20, len(tok_list))  # cap clusters\nkmeans = MiniBatchKMeans(\n    n_clusters=K,\n    random_state=0,\n    batch_size=max(1, K * 3),\n    n_init=10,\n    max_no_improvement=5,\n).fit(X)\n\n# token \u2192 cluster id (shifted by +1 so 0 is PAD)\ntoken2cluster = {\n    tok: int(kmeans.predict([token_to_vec(tok)])[0]) + 1 for tok in tok_list\n}\nPAD_ID = 0\nUNK_ID = K + 1  # unseen glyphs\ncluster_vocab_size = K + 2  # +1 for UNK, +1 for PAD\n\n\ndef encode_sequence(seq: str):\n    return [token2cluster.get(tok, UNK_ID) for tok in seq.split()]\n\n\n# -------------------------------------------------------------\n# PyTorch dataset\nclass SPRClusterDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = [encode_sequence(s) for s in hf_split[\"sequence\"]]\n        self.labels = hf_split[\"label\"]\n        self.raw_seqs = hf_split[\"sequence\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"seq\": torch.tensor(self.seqs[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw\": self.raw_seqs[idx],\n        }\n\n\ndef collate(batch):\n    lengths = [len(b[\"seq\"]) for b in batch]\n    maxL = max(lengths)\n    padded = torch.full((len(batch), maxL), PAD_ID, dtype=torch.long)\n    for i, b in enumerate(batch):\n        padded[i, : lengths[i]] = b[\"seq\"]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raws = [b[\"raw\"] for b in batch]\n    return {\n        \"seq\": padded,\n        \"lengths\": torch.tensor(lengths),\n        \"label\": labels,\n        \"raw\": raws,\n    }\n\n\ntrain_ds, dev_ds = SPRClusterDataset(dset[\"train\"]), SPRClusterDataset(dset[\"dev\"])\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate)\n\n\n# -------------------------------------------------------------\n# Model definition: average embedding \u2192 MLP\nclass AvgEmbClassifier(nn.Module):\n    def __init__(self, vocab, emb_dim, out_dim):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb_dim, padding_idx=PAD_ID)\n        self.mlp = nn.Sequential(\n            nn.Linear(emb_dim, 128), nn.ReLU(), nn.Linear(128, out_dim)\n        )\n\n    def forward(self, x):\n        mask = (x != PAD_ID).float().unsqueeze(-1)  # (B,L,1)\n        summed = (self.emb(x) * mask).sum(1)  # (B,emb)\n        avg = summed / mask.sum(1).clamp(min=1e-6)\n        return self.mlp(avg)\n\n\nmodel = AvgEmbClassifier(cluster_vocab_size, 32, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# -------------------------------------------------------------\n# Experiment tracking dict\nexperiment_data = {\n    \"SPR_Cluster\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n\n# ---------------------- helper: evaluation ----------------------\ndef evaluate(loader):\n    model.eval()\n    all_preds, all_labels, all_raws = [], [], []\n    running_loss, n = 0.0, 0\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"seq\"])\n            loss = criterion(logits, batch[\"label\"])\n            running_loss += loss.item() * batch[\"label\"].size(0)\n            n += batch[\"label\"].size(0)\n            all_preds.extend(logits.argmax(1).cpu().tolist())\n            all_labels.extend(batch[\"label\"].cpu().tolist())\n            all_raws.extend(batch[\"raw\"])\n    return all_preds, all_labels, all_raws, running_loss / max(1, n)\n\n\n# ------------------- training loop with early stop --------------\nbest_val_cpx = -1\npatience, no_improve = 5, 0\nMAX_EPOCHS = 30\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    tic = time.time()\n    # -------- training phase\n    model.train()\n    running_loss, n = 0.0, 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"seq\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch[\"label\"].size(0)\n        n += batch[\"label\"].size(0)\n    train_loss = running_loss / max(1, n)\n\n    # -------- evaluation phase\n    train_preds, train_labels, train_raws, _ = evaluate(train_loader)\n    val_preds, val_labels, val_raws, val_loss = evaluate(dev_loader)\n\n    tr_cwa = color_weighted_accuracy(train_raws, train_labels, train_preds)\n    va_cwa = color_weighted_accuracy(val_raws, val_labels, val_preds)\n    tr_swa = shape_weighted_accuracy(train_raws, train_labels, train_preds)\n    va_swa = shape_weighted_accuracy(val_raws, val_labels, val_preds)\n    tr_cpx = complexity_weighted_accuracy(train_raws, train_labels, train_preds)\n    va_cpx = complexity_weighted_accuracy(val_raws, val_labels, val_preds)\n\n    # -------- bookkeeping\n    ref = experiment_data[\"SPR_Cluster\"]\n    ref[\"metrics\"][\"train\"].append({\"cwa\": tr_cwa, \"swa\": tr_swa, \"cpx\": tr_cpx})\n    ref[\"metrics\"][\"val\"].append({\"cwa\": va_cwa, \"swa\": va_swa, \"cpx\": va_cpx})\n    ref[\"losses\"][\"train\"].append(train_loss)\n    ref[\"losses\"][\"val\"].append(val_loss)\n    ref[\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n        f\"val_cpxWA={va_cpx:.4f}  time={time.time()-tic:.1f}s\"\n    )\n\n    # early stopping on Complexity-WA\n    if va_cpx > best_val_cpx + 1e-6:\n        best_val_cpx = va_cpx\n        no_improve = 0\n        ref[\"predictions\"] = val_preds\n        ref[\"ground_truth\"] = val_labels\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(f\"Early stopping (no val improvement for {patience} epochs).\")\n            break\n\n# -------------------------------------------------------------\n# Save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"All metrics saved to working/experiment_data.npy\")\n", "import os, pathlib, random, time, json, math, warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# ------------------------------------------------------------------\n# Working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\nimport torch, numpy as np\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import MiniBatchKMeans\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------------\n# ------------------------- Dataset helpers -------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef make_synth(n, shapes=6, colors=5, max_len=8, num_labels=3, seed=0):\n    rng = random.Random(seed)\n    rows = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = \" \".join(\n            chr(ord(\"A\") + rng.randint(0, shapes - 1))\n            + chr(ord(\"a\") + rng.randint(0, colors - 1))\n            for _ in range(L)\n        )\n        rows[\"id\"].append(str(i))\n        rows[\"sequence\"].append(seq)\n        rows[\"label\"].append(rng.randint(0, num_labels - 1))\n    # save to tmp jsonl so HF can read\n    fp = os.path.join(working_dir, f\"synth_{seed}.jsonl\")\n    with open(fp, \"w\") as f:\n        for idx in range(n):\n            f.write(\n                json.dumps(\n                    {\n                        \"id\": rows[\"id\"][idx],\n                        \"sequence\": rows[\"sequence\"][idx],\n                        \"label\": rows[\"label\"][idx],\n                    }\n                )\n                + \"\\n\"\n            )\n    return fp\n\n\ndef load_data():\n    root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    if root.exists():\n        print(\"Loading real SPR_BENCH \u2026\")\n        return load_spr_bench(root)\n    print(\"SPR_BENCH not found \u2013 using synthetic mock data.\")\n    train_fp = make_synth(4000, seed=1)\n    dev_fp = make_synth(800, seed=2)\n    test_fp = make_synth(800, seed=3)\n    return DatasetDict(\n        {\n            \"train\": load_dataset(\"json\", data_files=train_fp, split=\"train\"),\n            \"dev\": load_dataset(\"json\", data_files=dev_fp, split=\"train\"),\n            \"test\": load_dataset(\"json\", data_files=test_fp, split=\"train\"),\n        }\n    )\n\n\ndset = load_data()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Train size {len(dset['train'])}, #classes {num_classes}\")\n\n\n# ------------------------------------------------------------------\n# ------------------ Metrics ---------------------------------------\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1:] for tok in seq.split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.split() if len(tok) > 0))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(1, sum(w))\n\n\n# ------------------------------------------------------------------\n# ------------------ Glyph clustering ------------------------------\n# Build vocabularies for shapes and colours\nunique_shapes, unique_colours = set(), set()\nfor s in dset[\"train\"][\"sequence\"]:\n    for tok in s.split():\n        if not tok:\n            continue\n        unique_shapes.add(tok[0])\n        unique_colours.add(tok[1:])\n\nshape2idx = {s: i for i, s in enumerate(sorted(unique_shapes))}\ncolour2idx = {c: i for i, c in enumerate(sorted(unique_colours))}\n\n\ndef token_to_vec(tok: str):\n    \"\"\"2-dim vector: (shape_idx, colour_idx)\"\"\"\n    shape_idx = shape2idx[tok[0]]\n    colour_idx = colour2idx[tok[1:]]\n    return np.array([shape_idx, colour_idx], dtype=np.float32)\n\n\nunique_tokens = set()\nfor s in dset[\"train\"][\"sequence\"]:\n    unique_tokens.update(s.split())\n\ntok_list = sorted(list(unique_tokens))\nX = np.stack([token_to_vec(t) for t in tok_list])\nK = min(20, len(tok_list))\nkmeans = MiniBatchKMeans(\n    n_clusters=K, random_state=0, batch_size=max(100, K * 3), n_init=10\n).fit(X)\ntoken2cluster = {tok: int(kmeans.predict([token_to_vec(tok)])[0]) for tok in tok_list}\n\nUNK_ID = K  # unseen glyphs\ncluster_vocab_size = K + 1\nPAD_ID = cluster_vocab_size  # unique padding id\nvocab_size = cluster_vocab_size + 1  # include PAD\n\n\ndef encode_sequence(seq: str):\n    return [token2cluster.get(tok, UNK_ID) for tok in seq.split()]\n\n\n# ------------------------------------------------------------------\n# ------------------ Torch dataset ---------------------------------\nclass SPRClusterDataset(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = [encode_sequence(s) for s in hf_split[\"sequence\"]]\n        self.labels = hf_split[\"label\"]\n        self.raw_seqs = hf_split[\"sequence\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"seq\": torch.tensor(self.seqs[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw\": self.raw_seqs[idx],\n        }\n\n\ndef collate(batch):\n    lengths = [len(b[\"seq\"]) for b in batch]\n    max_len = max(lengths)\n    padded = torch.full((len(batch), max_len), PAD_ID, dtype=torch.long)\n    for i, b in enumerate(batch):\n        padded[i, : lengths[i]] = b[\"seq\"]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raws = [b[\"raw\"] for b in batch]\n    return {\n        \"seq\": padded,\n        \"lengths\": torch.tensor(lengths),\n        \"label\": labels,\n        \"raw\": raws,\n    }\n\n\ntrain_ds, dev_ds = SPRClusterDataset(dset[\"train\"]), SPRClusterDataset(dset[\"dev\"])\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate)\n\n\n# ------------------------------------------------------------------\n# ------------------ Model -----------------------------------------\nclass AvgEmbClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, n_classes, pad_id):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n        self.mlp = nn.Sequential(\n            nn.Linear(emb_dim, 128), nn.ReLU(), nn.Linear(128, n_classes)\n        )\n\n    def forward(self, x):\n        mask = (x != self.emb.padding_idx).unsqueeze(-1).float()\n        summed = (self.emb(x) * mask).sum(1)\n        avg = summed / mask.sum(1).clamp(min=1e-6)\n        return self.mlp(avg)\n\n\nmodel = AvgEmbClassifier(vocab_size, 32, num_classes, PAD_ID).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ------------------------------------------------------------------\n# ------------------ Experiment tracking ---------------------------\nexperiment_data = {\n    \"SPR_Cluster\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# ------------------------------------------------------------------\n# ------------------ Training loop ---------------------------------\nbest_val_cpx = -1\npatience, no_improve = 5, 0\nMAX_EPOCHS = 30\n\n\ndef evaluate(loader):\n    model.eval()\n    all_preds, all_labels, all_raws, total_loss, total_n = [], [], [], 0.0, 0\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"seq\"])\n            loss = criterion(logits, batch[\"label\"])\n            total_loss += loss.item() * batch[\"label\"].size(0)\n            total_n += batch[\"label\"].size(0)\n            all_preds.extend(logits.argmax(1).cpu().tolist())\n            all_labels.extend(batch[\"label\"].cpu().tolist())\n            all_raws.extend(batch[\"raw\"])\n    return (\n        all_preds,\n        all_labels,\n        all_raws,\n        total_loss / max(total_n, 1),\n    )\n\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    tic = time.time()\n    # Training\n    model.train()\n    running_loss, seen = 0.0, 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"seq\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch[\"label\"].size(0)\n        seen += batch[\"label\"].size(0)\n    train_loss = running_loss / seen\n\n    # Evaluation\n    train_preds, train_labels, train_raws, _ = evaluate(train_loader)\n    val_preds, val_labels, val_raws, val_loss = evaluate(dev_loader)\n\n    tr_cwa = color_weighted_accuracy(train_raws, train_labels, train_preds)\n    va_cwa = color_weighted_accuracy(val_raws, val_labels, val_preds)\n    tr_swa = shape_weighted_accuracy(train_raws, train_labels, train_preds)\n    va_swa = shape_weighted_accuracy(val_raws, val_labels, val_preds)\n    tr_cpx = complexity_weighted_accuracy(train_raws, train_labels, train_preds)\n    va_cpx = complexity_weighted_accuracy(val_raws, val_labels, val_preds)\n\n    # Record\n    ref = experiment_data[\"SPR_Cluster\"]\n    ref[\"metrics\"][\"train\"].append(\n        {\"epoch\": epoch, \"cwa\": tr_cwa, \"swa\": tr_swa, \"cpx\": tr_cpx}\n    )\n    ref[\"metrics\"][\"val\"].append(\n        {\"epoch\": epoch, \"cwa\": va_cwa, \"swa\": va_swa, \"cpx\": va_cpx}\n    )\n    ref[\"losses\"][\"train\"].append(train_loss)\n    ref[\"losses\"][\"val\"].append(val_loss)\n    ref[\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n        f\"val_CompWA={va_cpx:.4f}  time={time.time()-tic:.1f}s\"\n    )\n\n    # Early stopping on complexity-weighted accuracy\n    if va_cpx > best_val_cpx + 1e-6:\n        best_val_cpx = va_cpx\n        no_improve = 0\n        ref[\"predictions\"] = val_preds\n        ref[\"ground_truth\"] = val_labels\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(f\"Early stopping after {patience} epochs without improvement.\")\n            break\n\n# ------------------------------------------------------------------\n# ------------------ Save experiment data --------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics & predictions \u2192 working/experiment_data.npy\")\n", "import os, time, random, pathlib, math, copy, numpy as np\nfrom collections import defaultdict\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom datasets import load_dataset, DatasetDict\n\n# -------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------------------------------------------------------\n# 1.  Metric helpers\ndef count_color_variety(seq):\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef color_weighted_acc(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_acc(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef complexity_weighted_acc(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# -------------------------------------------------------------\n# 2.  Load dataset (fallback to synthetic if missing)\ndef load_spr(root: pathlib.Path):\n    def _l(name):\n        return load_dataset(\n            \"csv\", data_files=str(root / name), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(train=_l(\"train.csv\"), dev=_l(\"dev.csv\"), test=_l(\"test.csv\"))\n\n\ndef make_synth(n, shapes=6, colors=5, max_len=8, num_labels=4, seed=0):\n    rng = random.Random(seed)\n    data = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = \" \".join(\n            chr(ord(\"A\") + rng.randint(0, shapes - 1)) + str(rng.randint(0, colors - 1))\n            for _ in range(L)\n        )\n        data[\"id\"].append(str(i))\n        data[\"sequence\"].append(seq)\n        data[\"label\"].append(rng.randint(0, num_labels - 1))\n    return load_dataset(\"json\", data_files={\"train\": [data]}, split=\"train\")\n\n\nroot_path = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\ntry:\n    dset = load_spr(root_path)\n    print(\"Loaded real SPR_BENCH\")\nexcept Exception:\n    print(\"Using synthetic dataset\")\n    dset = DatasetDict(\n        train=make_synth(6000),\n        dev=make_synth(1200, seed=1),\n        test=make_synth(1500, seed=2),\n    )\n\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(\"Num classes:\", num_classes)\n\n# -------------------------------------------------------------\n# 3.  Build vocab + cluster glyphs\nall_tokens = sorted({tok for seq in dset[\"train\"][\"sequence\"] for tok in seq.split()})\nvocab = {tok: i + 2 for i, tok in enumerate(all_tokens)}  # 0 PAD, 1 CLS\nPAD_ID, CLS_ID = 0, 1\nvocab_size = len(vocab) + 2\nprint(\"Vocab size\", vocab_size)\n\n# Auto-encoder for glyph latent space\nonehots = np.eye(len(all_tokens), dtype=np.float32)\nae = nn.Sequential(\n    nn.Linear(len(all_tokens), 8), nn.Tanh(), nn.Linear(8, len(all_tokens))\n)\nae.to(device)\nopt_ae = torch.optim.Adam(ae.parameters(), lr=1e-2)\ncrit = nn.MSELoss()\nx = torch.tensor(onehots, device=device)\nfor ep in range(150):\n    opt_ae.zero_grad()\n    out = ae(x)\n    loss = crit(out, x)\n    loss.backward()\n    opt_ae.step()\n    if ep % 50 == 0:\n        print(f\"AE {ep} loss {loss.item():.4f}\")\nwith torch.no_grad():\n    lat = ae[:2](x).cpu().numpy()\n\nK = 10\nkm = KMeans(n_clusters=K, random_state=0, n_init=\"auto\").fit(lat)\ncluster_ids = km.labels_\ncluster_map = {tok: cluster_ids[i] for i, tok in enumerate(all_tokens)}\nprint(\"Cluster distribution:\", np.bincount(cluster_ids))\n\n\n# -------------------------------------------------------------\n# 4.  Torch dataset\ndef encode(seq):\n    toks = seq.split()\n    ids = [CLS_ID] + [vocab[t] for t in toks]\n    clus = [K] + [cluster_map[t] for t in toks]  # treat CLS as its own cluster id = K\n    return ids, clus, len(ids)\n\n\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        enc = [encode(s) for s in split[\"sequence\"]]\n        self.ids = [e[0] for e in enc]\n        self.clu = [e[1] for e in enc]\n        self.len = [e[2] for e in enc]\n        self.labels = split[\"label\"]\n        self.raw = split[\"sequence\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"tok\": torch.tensor(self.ids[idx], dtype=torch.long),\n            \"clu\": torch.tensor(self.clu[idx], dtype=torch.long),\n            \"len\": self.len[idx],\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate(batch):\n    maxlen = max(b[\"tok\"].size(0) for b in batch)\n    tok = torch.full((len(batch), maxlen), PAD_ID, dtype=torch.long)\n    clu = torch.full((len(batch), maxlen), K, dtype=torch.long)\n    mask = torch.zeros(len(batch), maxlen, dtype=torch.bool)\n    labels = []\n    raw = []\n    for i, b in enumerate(batch):\n        l = b[\"tok\"].size(0)\n        tok[i, :l] = b[\"tok\"]\n        clu[i, :l] = b[\"clu\"]\n        mask[i, :l] = 1\n        labels.append(b[\"label\"])\n        raw.append(b.get(\"raw\", \"\"))\n    return {\n        \"tok\": tok,\n        \"clu\": clu,\n        \"mask\": mask,\n        \"label\": torch.stack(labels),\n        \"raw\": raw,\n    }\n\n\nbatch_size = 64\ntrain_loader = DataLoader(\n    SPRTorch(dset[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorch(dset[\"dev\"]), batch_size=batch_size * 2, shuffle=False, collate_fn=collate\n)\n\n\n# -------------------------------------------------------------\n# 5.  Transformer model\nclass ClusterTransformer(nn.Module):\n    def __init__(\n        self,\n        vocab_sz,\n        cluster_k,\n        emb_dim=64,\n        num_layers=2,\n        nhead=4,\n        num_cls=num_classes,\n    ):\n        super().__init__()\n        self.tok_emb = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.clu_emb = nn.Embedding(cluster_k + 1, emb_dim)  # +1 for CLS cluster\n        self.pos_emb = nn.Parameter(torch.zeros(512, emb_dim))  # enough for max len\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=emb_dim, nhead=nhead, dim_feedforward=128, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n        self.fc = nn.Sequential(\n            nn.LayerNorm(emb_dim),\n            nn.Linear(emb_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, num_cls),\n        )\n\n    def forward(self, tok, clu, mask):\n        seq_len = tok.size(1)\n        pos = self.pos_emb[:seq_len]\n        x = self.tok_emb(tok) + self.clu_emb(clu) + pos\n        x = self.encoder(x, src_key_padding_mask=~mask)\n        cls_vec = x[:, 0]  # CLS position\n        return self.fc(cls_vec)\n\n\nmodel = ClusterTransformer(vocab_size, K).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\n# -------------------------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n\n# -------------------------------------------------------------\ndef evaluate(loader, raw_seqs):\n    model.eval()\n    total_loss = 0\n    n = 0\n    preds = []\n    labels = []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"tok\"], batch[\"clu\"], batch[\"mask\"])\n            loss = criterion(logits, batch[\"label\"])\n            total_loss += loss.item() * batch[\"label\"].size(0)\n            n += batch[\"label\"].size(0)\n            p = logits.argmax(1).cpu().tolist()\n            preds.extend(p)\n            labels.extend(batch[\"label\"].cpu().tolist())\n    cwa = color_weighted_acc(raw_seqs, labels, preds)\n    swa = shape_weighted_acc(raw_seqs, labels, preds)\n    cpx = complexity_weighted_acc(raw_seqs, labels, preds)\n    return total_loss / n, preds, labels, (cwa, swa, cpx)\n\n\n# -------------------------------------------------------------\nmax_epochs = 20\nbest_cpx = -1\npatience = 5\nwait = 0\nfor epoch in range(1, max_epochs + 1):\n    t0 = time.time()\n    model.train()\n    tot = 0\n    n = 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"tok\"], batch[\"clu\"], batch[\"mask\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        tot += loss.item() * batch[\"label\"].size(0)\n        n += batch[\"label\"].size(0)\n    train_loss = tot / n\n    tr_loss, tr_preds, tr_labels, (tr_cwa, tr_swa, tr_cpx) = evaluate(\n        train_loader, train_loader.dataset.raw\n    )\n    val_loss, val_preds, val_labels, (v_cwa, v_swa, v_cpx) = evaluate(\n        dev_loader, dev_loader.dataset.raw\n    )\n\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"epochs\"].append(epoch)\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train\"].append({\"cwa\": tr_cwa, \"swa\": tr_swa, \"cpx\": tr_cpx})\n    ed[\"metrics\"][\"val\"].append({\"cwa\": v_cwa, \"swa\": v_swa, \"cpx\": v_cpx})\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n        f\"CWA={v_cwa:.3f} SWA={v_swa:.3f} CompWA={v_cpx:.3f} time={time.time()-t0:.1f}s\"\n    )\n\n    if v_cpx > best_cpx + 1e-6:\n        best_cpx = v_cpx\n        wait = 0\n        ed[\"predictions\"] = val_preds\n        ed[\"ground_truth\"] = val_labels\n        best_state = copy.deepcopy(model.state_dict())\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping\")\n            break\n\n# -------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nvals = [m[\"cpx\"] for m in experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"]]\nplt.figure()\nplt.plot(experiment_data[\"SPR_BENCH\"][\"epochs\"], vals, \"o-\")\nplt.title(\"Validation Complexity-Weighted Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CompWA\")\nplt.savefig(os.path.join(working_dir, \"val_compwa.png\"))\nprint(\"Artifacts saved in ./working\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, time, random, pathlib, math, copy, numpy as np\nfrom collections import defaultdict\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom datasets import load_dataset, DatasetDict\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------------\n# ===== 1.  HELPERS (metrics + IO) =================================\ndef count_color_variety(seq):  # token = ShapeChar + ColorChar\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef color_weighted_acc(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_acc(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef complexity_weighted_acc(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# ------------------------------------------------------------------\n# ===== 2.  DATA  ===================================================\ndef load_spr(root):\n    def _l(name):\n        return load_dataset(\n            \"csv\", data_files=str(root / name), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(train=_l(\"train.csv\"), dev=_l(\"dev.csv\"), test=_l(\"test.csv\"))\n\n\ndef make_synth(n, shapes=6, colors=5, max_len=8, num_labels=4, seed=123):\n    rng = random.Random(seed)\n    data = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = \" \".join(\n            chr(ord(\"A\") + rng.randint(0, shapes - 1)) + str(rng.randint(0, colors - 1))\n            for _ in range(L)\n        )\n        data[\"id\"].append(str(i))\n        data[\"sequence\"].append(seq)\n        data[\"label\"].append(rng.randint(0, num_labels - 1))\n    return data\n\n\ndef get_dataset():\n    root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    try:\n        if not root.exists():\n            raise FileNotFoundError\n        print(\"Using real SPR_BENCH\")\n        return load_spr(root)\n    except Exception:\n        print(\"SPR_BENCH not found \u2013 generating synthetic.\")\n        train = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(4000)]}, split=\"train\"\n        )\n        dev = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(800, seed=999)]}, split=\"train\"\n        )\n        test = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(1000, seed=555)]}, split=\"train\"\n        )\n        return DatasetDict(train=train, dev=dev, test=test)\n\n\ndset = get_dataset()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Num classes={num_classes}\")\n\n# ------------------------------------------------------------------\n# ===== 3.  TOKEN VOCAB & GLYPH CLUSTERING ==========================\nall_tokens = set(tok for seq in dset[\"train\"][\"sequence\"] for tok in seq.split())\nvocab = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}  # 0=pad\nvocab_size = len(vocab) + 1\nprint(f\"Vocab size={vocab_size}\")\n\n# --- build one-hot glyph matrix for clustering\nonehots = np.eye(vocab_size - 1, dtype=np.float32)  # index order matches sorted tokens\n# simple autoencoder to get dense rep\nae_dim = 4\nae = nn.Sequential(\n    nn.Linear(vocab_size - 1, ae_dim), nn.Tanh(), nn.Linear(ae_dim, vocab_size - 1)\n)\noptim_ae = torch.optim.Adam(ae.parameters(), lr=1e-2)\ncriterion = nn.MSELoss()\nonehots_t = torch.tensor(onehots)\nfor epoch in range(200):\n    optim_ae.zero_grad()\n    out = ae(onehots_t)\n    loss = criterion(out, onehots_t)\n    loss.backward()\n    optim_ae.step()\n    if epoch % 50 == 0:\n        print(f\"AE epoch {epoch} loss {loss.item():.4f}\")\nwith torch.no_grad():\n    latents = ae[:2](onehots_t).numpy()  # 4-dim latent\n\n# ---- KMeans\nK = 8\nkm = KMeans(n_clusters=K, random_state=0, n_init=\"auto\").fit(latents)\ncluster_ids = km.labels_  # len = vocab_size-1\ncluster_map = {tok: cluster_ids[i] for i, tok in enumerate(sorted(all_tokens))}\nprint(\"Cluster counts:\", np.bincount(cluster_ids))\n\n\n# ------------------------------------------------------------------\n# ===== 4.  TORCH DATA WRAPPER ======================================\ndef encode_seq(seq):\n    ids = [vocab.get(tok, 0) for tok in seq.split()]\n    clust = [cluster_map.get(tok, 0) for tok in seq.split()]\n    return ids, clust\n\n\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        enc = [encode_seq(s) for s in split[\"sequence\"]]\n        self.ids = [e[0] for e in enc]\n        self.clust = [e[1] for e in enc]\n        self.labels = split[\"label\"]\n        self.raw = split[\"sequence\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"tok\": torch.tensor(self.ids[idx], dtype=torch.long),\n            \"clu\": torch.tensor(self.clust[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"tok\"]) for b in batch)\n    pad = torch.zeros((len(batch), maxlen), dtype=torch.long)\n    padc = torch.zeros((len(batch), maxlen), dtype=torch.long)\n    lens = []\n    labs = []\n    for i, b in enumerate(batch):\n        L = len(b[\"tok\"])\n        pad[i, :L] = b[\"tok\"]\n        padc[i, :L] = b[\"clu\"]\n        lens.append(L)\n        labs.append(b[\"label\"])\n    return {\n        \"tok\": pad,\n        \"clu\": padc,\n        \"len\": torch.tensor(lens),\n        \"label\": torch.stack(labs),\n    }\n\n\ntrain_ds = SPRTorch(dset[\"train\"])\ndev_ds = SPRTorch(dset[\"dev\"])\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate)\n\n\n# ------------------------------------------------------------------\n# ===== 5.  MODEL ====================================================\nclass ClusterAwareClassifier(nn.Module):\n    def __init__(self, vocab_sz, cluster_k, emb=32, hid=64, classes=3):\n        super().__init__()\n        self.emb_tok = nn.Embedding(vocab_sz, emb, padding_idx=0)\n        self.emb_clu = nn.Embedding(cluster_k, emb, padding_idx=0)\n        self.rnn = nn.GRU(emb, hid, batch_first=True, bidirectional=True)\n        self.fc = nn.Sequential(\n            nn.Linear(hid * 2, 128), nn.ReLU(), nn.Linear(128, classes)\n        )\n\n    def forward(self, tok, clu, len_):\n        x = self.emb_tok(tok) + self.emb_clu(clu)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            x, len_.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.rnn(packed)\n        h = torch.cat([h[0], h[1]], dim=1)\n        return self.fc(h)\n\n\nmodel = ClusterAwareClassifier(vocab_size, K, classes=num_classes).to(device)\ncriterion_cls = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ------------------------------------------------------------------\n# ===== 6.  EXPERIMENT DATA STORE ===================================\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n\n# ------------------------------------------------------------------\n# ===== 7.  TRAIN / EVAL ============================================\ndef eval_loader(loader, raw_seqs):\n    model.eval()\n    preds, labels = [], []\n    with torch.no_grad():\n        for b in loader:\n            b = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in b.items()\n            }\n            logits = model(b[\"tok\"], b[\"clu\"], b[\"len\"])\n            preds.extend(logits.argmax(1).cpu().tolist())\n            labels.extend(b[\"label\"].cpu().tolist())\n    cwa = color_weighted_acc(raw_seqs, labels, preds)\n    swa = shape_weighted_acc(raw_seqs, labels, preds)\n    cpx = complexity_weighted_acc(raw_seqs, labels, preds)\n    return preds, labels, (cwa, swa, cpx)\n\n\nMAX_EPOCHS = 25\npatience = 5\nbest_val = -1\nstall = 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    t0 = time.time()\n    model.train()\n    total = 0\n    n = 0\n    for b in train_loader:\n        b = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in b.items()\n        }\n        optimizer.zero_grad()\n        out = model(b[\"tok\"], b[\"clu\"], b[\"len\"])\n        loss = criterion_cls(out, b[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total += loss.item() * b[\"label\"].size(0)\n        n += b[\"label\"].size(0)\n    train_loss = total / n\n    train_preds, train_labels, (tr_cwa, tr_swa, tr_cpx) = eval_loader(\n        train_loader, train_ds.raw\n    )\n    val_preds, val_labels, (v_cwa, v_swa, v_cpx) = eval_loader(dev_loader, dev_ds.raw)\n\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"epochs\"].append(epoch)\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"metrics\"][\"train\"].append({\"cwa\": tr_cwa, \"swa\": tr_swa, \"cpx\": tr_cpx})\n    ed[\"metrics\"][\"val\"].append({\"cwa\": v_cwa, \"swa\": v_swa, \"cpx\": v_cpx})\n\n    print(\n        f\"Epoch {epoch:02d} loss={train_loss:.4f}  ValCpx={v_cpx:.4f}  (CWA {v_cwa:.3f} SWA {v_swa:.3f})  time {time.time()-t0:.1f}s\"\n    )\n\n    if v_cpx > best_val + 1e-6:\n        best_val = v_cpx\n        stall = 0\n        ed[\"predictions\"] = val_preds\n        ed[\"ground_truth\"] = val_labels\n    else:\n        stall += 1\n        if stall >= patience:\n            print(\"Early stop.\")\n            break\n\n# ------------------------------------------------------------------\n# ===== 8.  SAVE / PLOT =============================================\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nval_cpx = [m[\"cpx\"] for m in experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"]]\nplt.figure()\nplt.plot(experiment_data[\"SPR_BENCH\"][\"epochs\"], val_cpx, marker=\"o\")\nplt.title(\"Val Complexity-Weighted Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CpxWA\")\nplt.savefig(os.path.join(working_dir, \"val_cpxwa.png\"))\nprint(\"Finished; artefacts saved in ./working\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, time, random, pathlib, math, copy, numpy as np\nfrom collections import defaultdict\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom datasets import load_dataset, DatasetDict\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------------\n# ===== 1.  HELPERS (metrics + IO) =================================\ndef count_color_variety(seq):  # token = ShapeChar + ColorChar\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef color_weighted_acc(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_acc(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef complexity_weighted_acc(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# ------------------------------------------------------------------\n# ===== 2.  DATA  ===================================================\ndef load_spr(root):\n    def _l(name):\n        return load_dataset(\n            \"csv\", data_files=str(root / name), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(train=_l(\"train.csv\"), dev=_l(\"dev.csv\"), test=_l(\"test.csv\"))\n\n\ndef make_synth(n, shapes=6, colors=5, max_len=8, num_labels=4, seed=123):\n    rng = random.Random(seed)\n    data = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = \" \".join(\n            chr(ord(\"A\") + rng.randint(0, shapes - 1)) + str(rng.randint(0, colors - 1))\n            for _ in range(L)\n        )\n        data[\"id\"].append(str(i))\n        data[\"sequence\"].append(seq)\n        data[\"label\"].append(rng.randint(0, num_labels - 1))\n    return data\n\n\ndef get_dataset():\n    root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    try:\n        if not root.exists():\n            raise FileNotFoundError\n        print(\"Using real SPR_BENCH\")\n        return load_spr(root)\n    except Exception:\n        print(\"SPR_BENCH not found \u2013 generating synthetic.\")\n        train = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(4000)]}, split=\"train\"\n        )\n        dev = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(800, seed=999)]}, split=\"train\"\n        )\n        test = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(1000, seed=555)]}, split=\"train\"\n        )\n        return DatasetDict(train=train, dev=dev, test=test)\n\n\ndset = get_dataset()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Num classes={num_classes}\")\n\n# ------------------------------------------------------------------\n# ===== 3.  TOKEN VOCAB & GLYPH CLUSTERING ==========================\nall_tokens = set(tok for seq in dset[\"train\"][\"sequence\"] for tok in seq.split())\nvocab = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}  # 0=pad\nvocab_size = len(vocab) + 1\nprint(f\"Vocab size={vocab_size}\")\n\n# --- build one-hot glyph matrix for clustering\nonehots = np.eye(vocab_size - 1, dtype=np.float32)  # index order matches sorted tokens\n# simple autoencoder to get dense rep\nae_dim = 4\nae = nn.Sequential(\n    nn.Linear(vocab_size - 1, ae_dim), nn.Tanh(), nn.Linear(ae_dim, vocab_size - 1)\n)\noptim_ae = torch.optim.Adam(ae.parameters(), lr=1e-2)\ncriterion = nn.MSELoss()\nonehots_t = torch.tensor(onehots)\nfor epoch in range(200):\n    optim_ae.zero_grad()\n    out = ae(onehots_t)\n    loss = criterion(out, onehots_t)\n    loss.backward()\n    optim_ae.step()\n    if epoch % 50 == 0:\n        print(f\"AE epoch {epoch} loss {loss.item():.4f}\")\nwith torch.no_grad():\n    latents = ae[:2](onehots_t).numpy()  # 4-dim latent\n\n# ---- KMeans\nK = 8\nkm = KMeans(n_clusters=K, random_state=0, n_init=\"auto\").fit(latents)\ncluster_ids = km.labels_  # len = vocab_size-1\ncluster_map = {tok: cluster_ids[i] for i, tok in enumerate(sorted(all_tokens))}\nprint(\"Cluster counts:\", np.bincount(cluster_ids))\n\n\n# ------------------------------------------------------------------\n# ===== 4.  TORCH DATA WRAPPER ======================================\ndef encode_seq(seq):\n    ids = [vocab.get(tok, 0) for tok in seq.split()]\n    clust = [cluster_map.get(tok, 0) for tok in seq.split()]\n    return ids, clust\n\n\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        enc = [encode_seq(s) for s in split[\"sequence\"]]\n        self.ids = [e[0] for e in enc]\n        self.clust = [e[1] for e in enc]\n        self.labels = split[\"label\"]\n        self.raw = split[\"sequence\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"tok\": torch.tensor(self.ids[idx], dtype=torch.long),\n            \"clu\": torch.tensor(self.clust[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"tok\"]) for b in batch)\n    pad = torch.zeros((len(batch), maxlen), dtype=torch.long)\n    padc = torch.zeros((len(batch), maxlen), dtype=torch.long)\n    lens = []\n    labs = []\n    for i, b in enumerate(batch):\n        L = len(b[\"tok\"])\n        pad[i, :L] = b[\"tok\"]\n        padc[i, :L] = b[\"clu\"]\n        lens.append(L)\n        labs.append(b[\"label\"])\n    return {\n        \"tok\": pad,\n        \"clu\": padc,\n        \"len\": torch.tensor(lens),\n        \"label\": torch.stack(labs),\n    }\n\n\ntrain_ds = SPRTorch(dset[\"train\"])\ndev_ds = SPRTorch(dset[\"dev\"])\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate)\n\n\n# ------------------------------------------------------------------\n# ===== 5.  MODEL ====================================================\nclass ClusterAwareClassifier(nn.Module):\n    def __init__(self, vocab_sz, cluster_k, emb=32, hid=64, classes=3):\n        super().__init__()\n        self.emb_tok = nn.Embedding(vocab_sz, emb, padding_idx=0)\n        self.emb_clu = nn.Embedding(cluster_k, emb, padding_idx=0)\n        self.rnn = nn.GRU(emb, hid, batch_first=True, bidirectional=True)\n        self.fc = nn.Sequential(\n            nn.Linear(hid * 2, 128), nn.ReLU(), nn.Linear(128, classes)\n        )\n\n    def forward(self, tok, clu, len_):\n        x = self.emb_tok(tok) + self.emb_clu(clu)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            x, len_.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.rnn(packed)\n        h = torch.cat([h[0], h[1]], dim=1)\n        return self.fc(h)\n\n\nmodel = ClusterAwareClassifier(vocab_size, K, classes=num_classes).to(device)\ncriterion_cls = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ------------------------------------------------------------------\n# ===== 6.  EXPERIMENT DATA STORE ===================================\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n\n# ------------------------------------------------------------------\n# ===== 7.  TRAIN / EVAL ============================================\ndef eval_loader(loader, raw_seqs):\n    model.eval()\n    preds, labels = [], []\n    with torch.no_grad():\n        for b in loader:\n            b = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in b.items()\n            }\n            logits = model(b[\"tok\"], b[\"clu\"], b[\"len\"])\n            preds.extend(logits.argmax(1).cpu().tolist())\n            labels.extend(b[\"label\"].cpu().tolist())\n    cwa = color_weighted_acc(raw_seqs, labels, preds)\n    swa = shape_weighted_acc(raw_seqs, labels, preds)\n    cpx = complexity_weighted_acc(raw_seqs, labels, preds)\n    return preds, labels, (cwa, swa, cpx)\n\n\nMAX_EPOCHS = 25\npatience = 5\nbest_val = -1\nstall = 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    t0 = time.time()\n    model.train()\n    total = 0\n    n = 0\n    for b in train_loader:\n        b = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in b.items()\n        }\n        optimizer.zero_grad()\n        out = model(b[\"tok\"], b[\"clu\"], b[\"len\"])\n        loss = criterion_cls(out, b[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total += loss.item() * b[\"label\"].size(0)\n        n += b[\"label\"].size(0)\n    train_loss = total / n\n    train_preds, train_labels, (tr_cwa, tr_swa, tr_cpx) = eval_loader(\n        train_loader, train_ds.raw\n    )\n    val_preds, val_labels, (v_cwa, v_swa, v_cpx) = eval_loader(dev_loader, dev_ds.raw)\n\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"epochs\"].append(epoch)\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"metrics\"][\"train\"].append({\"cwa\": tr_cwa, \"swa\": tr_swa, \"cpx\": tr_cpx})\n    ed[\"metrics\"][\"val\"].append({\"cwa\": v_cwa, \"swa\": v_swa, \"cpx\": v_cpx})\n\n    print(\n        f\"Epoch {epoch:02d} loss={train_loss:.4f}  ValCpx={v_cpx:.4f}  (CWA {v_cwa:.3f} SWA {v_swa:.3f})  time {time.time()-t0:.1f}s\"\n    )\n\n    if v_cpx > best_val + 1e-6:\n        best_val = v_cpx\n        stall = 0\n        ed[\"predictions\"] = val_preds\n        ed[\"ground_truth\"] = val_labels\n    else:\n        stall += 1\n        if stall >= patience:\n            print(\"Early stop.\")\n            break\n\n# ------------------------------------------------------------------\n# ===== 8.  SAVE / PLOT =============================================\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nval_cpx = [m[\"cpx\"] for m in experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"]]\nplt.figure()\nplt.plot(experiment_data[\"SPR_BENCH\"][\"epochs\"], val_cpx, marker=\"o\")\nplt.title(\"Val Complexity-Weighted Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CpxWA\")\nplt.savefig(os.path.join(working_dir, \"val_cpxwa.png\"))\nprint(\"Finished; artefacts saved in ./working\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, time, random, pathlib, math, copy, numpy as np\nfrom collections import defaultdict\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom datasets import load_dataset, DatasetDict\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------------\n# ===== 1.  HELPERS (metrics + IO) =================================\ndef count_color_variety(seq):  # token = ShapeChar + ColorChar\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef color_weighted_acc(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_acc(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef complexity_weighted_acc(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# ------------------------------------------------------------------\n# ===== 2.  DATA  ===================================================\ndef load_spr(root):\n    def _l(name):\n        return load_dataset(\n            \"csv\", data_files=str(root / name), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(train=_l(\"train.csv\"), dev=_l(\"dev.csv\"), test=_l(\"test.csv\"))\n\n\ndef make_synth(n, shapes=6, colors=5, max_len=8, num_labels=4, seed=123):\n    rng = random.Random(seed)\n    data = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = \" \".join(\n            chr(ord(\"A\") + rng.randint(0, shapes - 1)) + str(rng.randint(0, colors - 1))\n            for _ in range(L)\n        )\n        data[\"id\"].append(str(i))\n        data[\"sequence\"].append(seq)\n        data[\"label\"].append(rng.randint(0, num_labels - 1))\n    return data\n\n\ndef get_dataset():\n    root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    try:\n        if not root.exists():\n            raise FileNotFoundError\n        print(\"Using real SPR_BENCH\")\n        return load_spr(root)\n    except Exception:\n        print(\"SPR_BENCH not found \u2013 generating synthetic.\")\n        train = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(4000)]}, split=\"train\"\n        )\n        dev = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(800, seed=999)]}, split=\"train\"\n        )\n        test = load_dataset(\n            \"json\", data_files={\"train\": [make_synth(1000, seed=555)]}, split=\"train\"\n        )\n        return DatasetDict(train=train, dev=dev, test=test)\n\n\ndset = get_dataset()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Num classes={num_classes}\")\n\n# ------------------------------------------------------------------\n# ===== 3.  TOKEN VOCAB & GLYPH CLUSTERING ==========================\nall_tokens = set(tok for seq in dset[\"train\"][\"sequence\"] for tok in seq.split())\nvocab = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}  # 0=pad\nvocab_size = len(vocab) + 1\nprint(f\"Vocab size={vocab_size}\")\n\n# --- build one-hot glyph matrix for clustering\nonehots = np.eye(vocab_size - 1, dtype=np.float32)  # index order matches sorted tokens\n# simple autoencoder to get dense rep\nae_dim = 4\nae = nn.Sequential(\n    nn.Linear(vocab_size - 1, ae_dim), nn.Tanh(), nn.Linear(ae_dim, vocab_size - 1)\n)\noptim_ae = torch.optim.Adam(ae.parameters(), lr=1e-2)\ncriterion = nn.MSELoss()\nonehots_t = torch.tensor(onehots)\nfor epoch in range(200):\n    optim_ae.zero_grad()\n    out = ae(onehots_t)\n    loss = criterion(out, onehots_t)\n    loss.backward()\n    optim_ae.step()\n    if epoch % 50 == 0:\n        print(f\"AE epoch {epoch} loss {loss.item():.4f}\")\nwith torch.no_grad():\n    latents = ae[:2](onehots_t).numpy()  # 4-dim latent\n\n# ---- KMeans\nK = 8\nkm = KMeans(n_clusters=K, random_state=0, n_init=\"auto\").fit(latents)\ncluster_ids = km.labels_  # len = vocab_size-1\ncluster_map = {tok: cluster_ids[i] for i, tok in enumerate(sorted(all_tokens))}\nprint(\"Cluster counts:\", np.bincount(cluster_ids))\n\n\n# ------------------------------------------------------------------\n# ===== 4.  TORCH DATA WRAPPER ======================================\ndef encode_seq(seq):\n    ids = [vocab.get(tok, 0) for tok in seq.split()]\n    clust = [cluster_map.get(tok, 0) for tok in seq.split()]\n    return ids, clust\n\n\nclass SPRTorch(Dataset):\n    def __init__(self, split):\n        enc = [encode_seq(s) for s in split[\"sequence\"]]\n        self.ids = [e[0] for e in enc]\n        self.clust = [e[1] for e in enc]\n        self.labels = split[\"label\"]\n        self.raw = split[\"sequence\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"tok\": torch.tensor(self.ids[idx], dtype=torch.long),\n            \"clu\": torch.tensor(self.clust[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"tok\"]) for b in batch)\n    pad = torch.zeros((len(batch), maxlen), dtype=torch.long)\n    padc = torch.zeros((len(batch), maxlen), dtype=torch.long)\n    lens = []\n    labs = []\n    for i, b in enumerate(batch):\n        L = len(b[\"tok\"])\n        pad[i, :L] = b[\"tok\"]\n        padc[i, :L] = b[\"clu\"]\n        lens.append(L)\n        labs.append(b[\"label\"])\n    return {\n        \"tok\": pad,\n        \"clu\": padc,\n        \"len\": torch.tensor(lens),\n        \"label\": torch.stack(labs),\n    }\n\n\ntrain_ds = SPRTorch(dset[\"train\"])\ndev_ds = SPRTorch(dset[\"dev\"])\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate)\n\n\n# ------------------------------------------------------------------\n# ===== 5.  MODEL ====================================================\nclass ClusterAwareClassifier(nn.Module):\n    def __init__(self, vocab_sz, cluster_k, emb=32, hid=64, classes=3):\n        super().__init__()\n        self.emb_tok = nn.Embedding(vocab_sz, emb, padding_idx=0)\n        self.emb_clu = nn.Embedding(cluster_k, emb, padding_idx=0)\n        self.rnn = nn.GRU(emb, hid, batch_first=True, bidirectional=True)\n        self.fc = nn.Sequential(\n            nn.Linear(hid * 2, 128), nn.ReLU(), nn.Linear(128, classes)\n        )\n\n    def forward(self, tok, clu, len_):\n        x = self.emb_tok(tok) + self.emb_clu(clu)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            x, len_.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.rnn(packed)\n        h = torch.cat([h[0], h[1]], dim=1)\n        return self.fc(h)\n\n\nmodel = ClusterAwareClassifier(vocab_size, K, classes=num_classes).to(device)\ncriterion_cls = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ------------------------------------------------------------------\n# ===== 6.  EXPERIMENT DATA STORE ===================================\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n\n# ------------------------------------------------------------------\n# ===== 7.  TRAIN / EVAL ============================================\ndef eval_loader(loader, raw_seqs):\n    model.eval()\n    preds, labels = [], []\n    with torch.no_grad():\n        for b in loader:\n            b = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in b.items()\n            }\n            logits = model(b[\"tok\"], b[\"clu\"], b[\"len\"])\n            preds.extend(logits.argmax(1).cpu().tolist())\n            labels.extend(b[\"label\"].cpu().tolist())\n    cwa = color_weighted_acc(raw_seqs, labels, preds)\n    swa = shape_weighted_acc(raw_seqs, labels, preds)\n    cpx = complexity_weighted_acc(raw_seqs, labels, preds)\n    return preds, labels, (cwa, swa, cpx)\n\n\nMAX_EPOCHS = 25\npatience = 5\nbest_val = -1\nstall = 0\nfor epoch in range(1, MAX_EPOCHS + 1):\n    t0 = time.time()\n    model.train()\n    total = 0\n    n = 0\n    for b in train_loader:\n        b = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in b.items()\n        }\n        optimizer.zero_grad()\n        out = model(b[\"tok\"], b[\"clu\"], b[\"len\"])\n        loss = criterion_cls(out, b[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total += loss.item() * b[\"label\"].size(0)\n        n += b[\"label\"].size(0)\n    train_loss = total / n\n    train_preds, train_labels, (tr_cwa, tr_swa, tr_cpx) = eval_loader(\n        train_loader, train_ds.raw\n    )\n    val_preds, val_labels, (v_cwa, v_swa, v_cpx) = eval_loader(dev_loader, dev_ds.raw)\n\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"epochs\"].append(epoch)\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"metrics\"][\"train\"].append({\"cwa\": tr_cwa, \"swa\": tr_swa, \"cpx\": tr_cpx})\n    ed[\"metrics\"][\"val\"].append({\"cwa\": v_cwa, \"swa\": v_swa, \"cpx\": v_cpx})\n\n    print(\n        f\"Epoch {epoch:02d} loss={train_loss:.4f}  ValCpx={v_cpx:.4f}  (CWA {v_cwa:.3f} SWA {v_swa:.3f})  time {time.time()-t0:.1f}s\"\n    )\n\n    if v_cpx > best_val + 1e-6:\n        best_val = v_cpx\n        stall = 0\n        ed[\"predictions\"] = val_preds\n        ed[\"ground_truth\"] = val_labels\n    else:\n        stall += 1\n        if stall >= patience:\n            print(\"Early stop.\")\n            break\n\n# ------------------------------------------------------------------\n# ===== 8.  SAVE / PLOT =============================================\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nval_cpx = [m[\"cpx\"] for m in experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"]]\nplt.figure()\nplt.plot(experiment_data[\"SPR_BENCH\"][\"epochs\"], val_cpx, marker=\"o\")\nplt.title(\"Val Complexity-Weighted Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CpxWA\")\nplt.savefig(os.path.join(working_dir, \"val_cpxwa.png\"))\nprint(\"Finished; artefacts saved in ./working\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 533453.40\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 780655.15\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 790811.12\nexamples/s]', '\\n', 'Classes: 2, Train size: 20000', '\\n', 'Vocab size: 17',\n'\\n', 'Epoch 01 | TrainLoss 0.4531 | Val CpxWA 0.9027 | Time 1.5s', '\\n', 'Epoch\n02 | TrainLoss 0.2438 | Val CpxWA 0.9250 | Time 0.9s', '\\n', 'Epoch 03 |\nTrainLoss 0.2035 | Val CpxWA 0.9396 | Time 0.9s', '\\n', 'Epoch 04 | TrainLoss\n0.1883 | Val CpxWA 0.9399 | Time 0.9s', '\\n', 'Epoch 05 | TrainLoss 0.1808 | Val\nCpxWA 0.9402 | Time 4.0s', '\\n', 'Epoch 06 | TrainLoss 0.1762 | Val CpxWA 0.9416\n| Time 2.7s', '\\n', 'Epoch 07 | TrainLoss 0.1730 | Val CpxWA 0.9428 | Time\n1.0s', '\\n', 'Epoch 08 | TrainLoss 0.1705 | Val CpxWA 0.9422 | Time 2.1s', '\\n',\n'Epoch 09 | TrainLoss 0.1688 | Val CpxWA 0.9430 | Time 2.0s', '\\n', 'Epoch 10 |\nTrainLoss 0.1669 | Val CpxWA 0.9429 | Time 2.1s', '\\n', 'Epoch 11 | TrainLoss\n0.1661 | Val CpxWA 0.9432 | Time 1.5s', '\\n', 'Epoch 12 | TrainLoss 0.1651 | Val\nCpxWA 0.9432 | Time 1.4s', '\\n', 'Epoch 13 | TrainLoss 0.1647 | Val CpxWA 0.9432\n| Time 0.9s', '\\n', 'Epoch 14 | TrainLoss 0.1637 | Val CpxWA 0.9432 | Time\n3.3s', '\\n', 'Epoch 15 | TrainLoss 0.1631 | Val CpxWA 0.9432 | Time 2.6s', '\\n',\n'Epoch 16 | TrainLoss 0.1629 | Val CpxWA 0.9429 | Time 2.9s', '\\n', 'No\nimprovement for 5 epochs \u2013 early stopping at epoch 16.', '\\n', 'Finished.\nResults saved in working/.', '\\n', 'Execution time: 33 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Using real SPR_BENCH', '\\n', '\\rGenerating train\nsplit: 0 examples [00:00, ? examples/s]', '', '\\rGenerating train split: 20000\nexamples [00:00, 565277.70 examples/s]', '\\n', '\\rGenerating train split: 0\nexamples [00:00, ? examples/s]', '', '\\rGenerating train split: 5000 examples\n[00:00, 494319.86 examples/s]', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 10000 examples [00:00,\n712626.20 examples/s]', '\\n', 'Num classes=2', '\\n', 'Vocab size=17', '\\n', 'AE\nepoch 0 loss 0.1657', '\\n', 'AE epoch 50 loss 0.0436', '\\n', 'AE epoch 100 loss\n0.0430', '\\n', 'AE epoch 150 loss 0.0430', '\\n', 'Cluster counts:', ' ', '[1 1 3\n2 2 3 2 2]', '\\n', 'Epoch 01 loss=0.1489  ValCpx=0.9898  (CWA 0.990 SWA 0.989)\ntime 10.6s', '\\n', 'Epoch 02 loss=0.0405  ValCpx=0.9910  (CWA 0.991 SWA 0.991)\ntime 2.0s', '\\n', 'Epoch 03 loss=0.0255  ValCpx=0.9950  (CWA 0.995 SWA 0.995)\ntime 3.2s', '\\n', 'Epoch 04 loss=0.0141  ValCpx=0.9980  (CWA 0.998 SWA 0.998)\ntime 3.3s', '\\n', 'Epoch 05 loss=0.0073  ValCpx=0.9997  (CWA 1.000 SWA 1.000)\ntime 8.5s', '\\n', 'Epoch 06 loss=0.0020  ValCpx=0.9990  (CWA 0.999 SWA 0.999)\ntime 6.3s', '\\n', 'Epoch 07 loss=0.0003  ValCpx=0.9997  (CWA 1.000 SWA 1.000)\ntime 6.6s', '\\n', 'Epoch 08 loss=0.0001  ValCpx=0.9996  (CWA 1.000 SWA 1.000)\ntime 9.9s', '\\n', 'Epoch 09 loss=0.0001  ValCpx=0.9997  (CWA 1.000 SWA 1.000)\ntime 5.4s', '\\n', 'Epoch 10 loss=0.0001  ValCpx=0.9997  (CWA 1.000 SWA 1.000)\ntime 2.7s', '\\n', 'Early stop.', '\\n', 'Finished; artefacts saved in ./working',\n'\\n', 'Execution time: a minute seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 323276.62\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 250858.50\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 642726.41\nexamples/s]', '\\n', 'Train size: 20000, classes: 2', '\\n', 'Vocab size:', ' ',\n'17', '\\n', 'Traceback (most recent call last):\\n  File \"runfile.py\", line 134,\nin <module>\\n    color_idx = int(tok[1])\\n\n^^^^^^^^^^^\\nValueError: invalid literal for int() with base 10: \\'y\\'\\n',\n'Execution time: a second seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 484459.38\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 584898.06\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 720398.47\nexamples/s]', '\\n', 'Num classes:', ' ', '2', '\\n', 'Clustering glyphs into', '\n', '9', ' ', 'clusters', '\\n', 'Effective cluster vocab size:', ' ', '5', '\\n',\n'Epoch 01: train_loss=0.3597 | Val CpxWA=0.9071 | time=1.2s', '\\n', 'Epoch 02:\ntrain_loss=0.2470 | Val CpxWA=0.9071 | time=0.9s', '\\n', 'Epoch 03:\ntrain_loss=0.2414 | Val CpxWA=0.9071 | time=0.9s', '\\n', 'Epoch 04:\ntrain_loss=0.2395 | Val CpxWA=0.9071 | time=0.9s', '\\n', 'Epoch 05:\ntrain_loss=0.2387 | Val CpxWA=0.9071 | time=0.9s', '\\n', 'Epoch 06:\ntrain_loss=0.2381 | Val CpxWA=0.9071 | time=0.9s', '\\n', 'Early stopping.',\n'\\n', 'Experiment data saved to working/.', '\\n', 'Execution time: 8 seconds\nseconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loading real SPR_BENCH \u2026', '\\n', '\\rGenerating\ntrain split: 0 examples [00:00, ? examples/s]', '', '\\rGenerating train split:\n20000 examples [00:00, 476173.63 examples/s]', '\\n', '\\rGenerating train split:\n0 examples [00:00, ? examples/s]', '', '\\rGenerating train split: 5000 examples\n[00:00, 642962.87 examples/s]', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 10000 examples [00:00,\n741698.32 examples/s]', '\\n', 'Train size 20000, num_classes 2', '\\n',\n'Traceback (most recent call last):\\n  File \"runfile.py\", line 118, in\n<module>\\n    X = np.stack([token_to_vec(t) for t in tok_list])\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 118, in\n<listcomp>\\n    X = np.stack([token_to_vec(t) for t in tok_list])\\n\n^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 111, in token_to_vec\\n    return\nnp.array([ord(tok[0]) - ord(\"A\"), int(tok[1])], dtype=np.float32)\\n\n^^^^^^^^^^^\\nValueError: invalid literal for int() with base 10: \\'b\\'\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded real SPR_BENCH dataset.', '\\n', 'Number of\nclasses: 2', '\\n', 'Cluster distribution:', ' ', '[4 4 4 4]', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 01: validation_loss = 0.9706\n| Val CWA 0.969 SWA 0.971 Cpx 0.971', '\\n', 'Epoch 02: validation_loss = 0.9819\n| Val CWA 0.981 SWA 0.982 Cpx 0.982', '\\n', 'Epoch 03: validation_loss = 0.9942\n| Val CWA 0.995 SWA 0.994 Cpx 0.994', '\\n', 'Epoch 04: validation_loss = 0.9948\n| Val CWA 0.995 SWA 0.995 Cpx 0.995', '\\n', 'Epoch 05: validation_loss = 0.9950\n| Val CWA 0.996 SWA 0.995 Cpx 0.995', '\\n', 'Epoch 06: validation_loss = 0.9923\n| Val CWA 0.993 SWA 0.992 Cpx 0.992', '\\n', 'Epoch 07: validation_loss = 0.9955\n| Val CWA 0.996 SWA 0.995 Cpx 0.995', '\\n', 'Epoch 08: validation_loss = 0.9963\n| Val CWA 0.997 SWA 0.996 Cpx 0.996', '\\n', 'Epoch 09: validation_loss = 0.9950\n| Val CWA 0.996 SWA 0.995 Cpx 0.995', '\\n', 'Epoch 10: validation_loss = 0.9903\n| Val CWA 0.990 SWA 0.990 Cpx 0.990', '\\n', 'Epoch 11: validation_loss = 0.9958\n| Val CWA 0.996 SWA 0.996 Cpx 0.996', '\\n', 'Epoch 12: validation_loss = 0.9963\n| Val CWA 0.997 SWA 0.996 Cpx 0.996', '\\n', 'Epoch 13: validation_loss = 0.9970\n| Val CWA 0.997 SWA 0.997 Cpx 0.997', '\\n', 'Epoch 14: validation_loss = 0.9936\n| Val CWA 0.994 SWA 0.994 Cpx 0.994', '\\n', 'Epoch 15: validation_loss = 0.9954\n| Val CWA 0.996 SWA 0.995 Cpx 0.995', '\\n', 'Epoch 16: validation_loss = 0.9963\n| Val CWA 0.997 SWA 0.996 Cpx 0.996', '\\n', 'Epoch 17: validation_loss = 0.9961\n| Val CWA 0.996 SWA 0.996 Cpx 0.996', '\\n', 'Epoch 18: validation_loss = 0.9824\n| Val CWA 0.983 SWA 0.982 Cpx 0.982', '\\n', 'Early stopping triggered.', '\\n',\n'Finished. Data saved to ./working/', '\\n', 'Execution time: 2 minutes seconds\n(time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loading real SPR_BENCH \u2026', '\\n', 'Train size\n20000, num_classes 2', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 148, in <module>\\n    token2cluster = {\\n\n^\\n  File \"runfile.py\", line 149, in <dictcomp>\\n    tok:\nint(kmeans.predict([token_to_vec(tok)])[0]) + 1 for tok in tok_list\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/sklearn/cluster/_kmeans.py\", line 1090, in predict\\n    labels =\n_labels_inertia_threadpool_limit(\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/sklearn/utils/parallel.py\", line 165, in wrapper\\n    return\nfunc(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/sklearn/cluster/_kmeans.py\", line 806, in _labels_inertia\\n\n_labels(\\n  File \"_k_means_lloyd.pyx\", line 26, in\nsklearn.cluster._k_means_lloyd.lloyd_iter_chunked_dense\\nValueError: Buffer\ndtype mismatch, expected \\'const double\\' but got \\'float\\'\\n', 'Execution time:\n2 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loading real SPR_BENCH \u2026', '\\n', 'Train size\n20000, #classes 2', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 148, in <module>\\n    token2cluster = {tok:\nint(kmeans.predict([token_to_vec(tok)])[0]) for tok in tok_list}\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"runfile.py\", line 148, in <dictcomp>\\n    token2cluster = {tok:\nint(kmeans.predict([token_to_vec(tok)])[0]) for tok in tok_list}\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/sklearn/cluster/_kmeans.py\", line 1090, in predict\\n    labels =\n_labels_inertia_threadpool_limit(\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/sklearn/utils/parallel.py\", line 165, in wrapper\\n    return\nfunc(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/sklearn/cluster/_kmeans.py\", line 806, in _labels_inertia\\n\n_labels(\\n  File \"_k_means_lloyd.pyx\", line 26, in\nsklearn.cluster._k_means_lloyd.lloyd_iter_chunked_dense\\nValueError: Buffer\ndtype mismatch, expected \\'const double\\' but got \\'float\\'\\n', 'Execution time:\n5 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded real SPR_BENCH', '\\n', 'Num classes:', ' ',\n'2', '\\n', 'Vocab size', ' ', '18', '\\n', 'AE 0 loss 0.1086', '\\n', 'AE 50 loss\n0.0277', '\\n', 'AE 100 loss 0.0273', '\\n', 'Cluster distribution:', ' ', '[2 2 2\n2 2 1 2 1 1 1]', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: train_loss=0.2303\nval_loss=0.0678 CWA=0.982 SWA=0.983 CompWA=0.983 time=10.8s', '\\n', 'Epoch 2:\ntrain_loss=0.0765 val_loss=0.0619 CWA=0.985 SWA=0.986 CompWA=0.986 time=8.5s',\n'\\n', 'Epoch 3: train_loss=0.0681 val_loss=0.0610 CWA=0.985 SWA=0.986\nCompWA=0.986 time=9.3s', '\\n', 'Epoch 4: train_loss=0.0609 val_loss=0.0482\nCWA=0.989 SWA=0.989 CompWA=0.989 time=9.1s', '\\n', 'Epoch 5: train_loss=0.0507\nval_loss=0.0534 CWA=0.985 SWA=0.983 CompWA=0.983 time=11.3s', '\\n', 'Epoch 6:\ntrain_loss=0.0402 val_loss=0.0321 CWA=0.994 SWA=0.994 CompWA=0.994 time=3.8s',\n'\\n', 'Epoch 7: train_loss=0.0353 val_loss=0.0341 CWA=0.993 SWA=0.992\nCompWA=0.992 time=11.4s', '\\n', 'Epoch 8: train_loss=0.0355 val_loss=0.0355\nCWA=0.993 SWA=0.992 CompWA=0.992 time=7.9s', '\\n', 'Epoch 9: train_loss=0.0413\nval_loss=0.1101 CWA=0.960 SWA=0.960 CompWA=0.959 time=11.2s', '\\n', 'Epoch 10:\ntrain_loss=0.0383 val_loss=0.0309 CWA=0.995 SWA=0.994 CompWA=0.994 time=8.1s',\n'\\n', 'Epoch 11: train_loss=0.0303 val_loss=0.0307 CWA=0.995 SWA=0.994\nCompWA=0.994 time=9.7s', '\\n', 'Epoch 12: train_loss=0.0326 val_loss=0.0302\nCWA=0.995 SWA=0.994 CompWA=0.994 time=11.8s', '\\n', 'Epoch 13: train_loss=0.0291\nval_loss=0.0302 CWA=0.995 SWA=0.994 CompWA=0.994 time=10.0s', '\\n', 'Epoch 14:\ntrain_loss=0.0374 val_loss=0.0313 CWA=0.994 SWA=0.994 CompWA=0.994 time=9.7s',\n'\\n', 'Epoch 15: train_loss=0.0368 val_loss=0.0323 CWA=0.994 SWA=0.993\nCompWA=0.994 time=9.4s', '\\n', 'Early stopping', '\\n', 'Artifacts saved in\n./working', '\\n', 'Execution time: 2 minutes seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', 'Using real SPR_BENCH', '\\n', 'Num classes=2',\n'\\n', 'Vocab size=17', '\\n', 'AE epoch 0 loss 0.1416', '\\n', 'AE epoch 50 loss\n0.0434', '\\n', 'AE epoch 100 loss 0.0430', '\\n', 'AE epoch 150 loss 0.0430',\n'\\n', 'Cluster counts:', ' ', '[3 3 4 1 1 1 2 1]', '\\n', 'Epoch 01 loss=0.1602\nValCpx=0.9882  (CWA 0.988 SWA 0.988)  time 5.1s', '\\n', 'Epoch 02 loss=0.0328\nValCpx=0.9971  (CWA 0.997 SWA 0.997)  time 2.9s', '\\n', 'Epoch 03 loss=0.0116\nValCpx=0.9980  (CWA 0.998 SWA 0.998)  time 4.4s', '\\n', 'Epoch 04 loss=0.0044\nValCpx=0.9995  (CWA 1.000 SWA 1.000)  time 5.2s', '\\n', 'Epoch 05 loss=0.0005\nValCpx=0.9998  (CWA 1.000 SWA 1.000)  time 2.6s', '\\n', 'Epoch 06 loss=0.0002\nValCpx=0.9998  (CWA 1.000 SWA 1.000)  time 3.5s', '\\n', 'Epoch 07 loss=0.0001\nValCpx=0.9998  (CWA 1.000 SWA 1.000)  time 2.8s', '\\n', 'Epoch 08 loss=0.0001\nValCpx=0.9998  (CWA 1.000 SWA 1.000)  time 3.2s', '\\n', 'Epoch 09 loss=0.0000\nValCpx=0.9998  (CWA 1.000 SWA 1.000)  time 3.2s', '\\n', 'Epoch 10 loss=0.0000\nValCpx=0.9998  (CWA 1.000 SWA 1.000)  time 3.4s', '\\n', 'Early stop.', '\\n',\n'Finished; artefacts saved in ./working', '\\n', 'Execution time: 40 seconds\nseconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Using real SPR_BENCH', '\\n', 'Num classes=2',\n'\\n', 'Vocab size=17', '\\n', 'AE epoch 0 loss 0.1409', '\\n', 'AE epoch 50 loss\n0.0433', '\\n', 'AE epoch 100 loss 0.0430', '\\n', 'AE epoch 150 loss 0.0430',\n'\\n', 'Cluster counts:', ' ', '[2 1 2 2 3 1 2 3]', '\\n', 'Epoch 01 loss=0.1702\nValCpx=0.9823  (CWA 0.981 SWA 0.982)  time 2.1s', '\\n', 'Epoch 02 loss=0.0494\nValCpx=0.9763  (CWA 0.976 SWA 0.976)  time 2.7s', '\\n', 'Epoch 03 loss=0.0245\nValCpx=0.9963  (CWA 0.996 SWA 0.996)  time 3.0s', '\\n', 'Epoch 04 loss=0.0070\nValCpx=0.9993  (CWA 0.999 SWA 0.999)  time 3.0s', '\\n', 'Epoch 05 loss=0.0015\nValCpx=0.9985  (CWA 0.999 SWA 0.998)  time 3.6s', '\\n', 'Epoch 06 loss=0.0004\nValCpx=0.9994  (CWA 0.999 SWA 0.999)  time 2.8s', '\\n', 'Epoch 07 loss=0.0002\nValCpx=0.9994  (CWA 0.999 SWA 0.999)  time 2.2s', '\\n', 'Epoch 08 loss=0.0001\nValCpx=0.9994  (CWA 0.999 SWA 0.999)  time 1.9s', '\\n', 'Epoch 09 loss=0.0001\nValCpx=0.9994  (CWA 0.999 SWA 0.999)  time 2.4s', '\\n', 'Epoch 10 loss=0.0000\nValCpx=0.9994  (CWA 0.999 SWA 0.999)  time 2.5s', '\\n', 'Epoch 11 loss=0.0000\nValCpx=0.9994  (CWA 0.999 SWA 0.999)  time 2.2s', '\\n', 'Early stop.', '\\n',\n'Finished; artefacts saved in ./working', '\\n', 'Execution time: 32 seconds\nseconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Using real SPR_BENCH', '\\n', 'Num classes=2',\n'\\n', 'Vocab size=17', '\\n', 'AE epoch 0 loss 0.1899', '\\n', 'AE epoch 50 loss\n0.0443', '\\n', 'AE epoch 100 loss 0.0430', '\\n', 'AE epoch 150 loss 0.0430',\n'\\n', 'Cluster counts:', ' ', '[1 4 2 2 3 2 1 1]', '\\n', 'Epoch 01 loss=0.1641\nValCpx=0.9838  (CWA 0.983 SWA 0.984)  time 2.2s', '\\n', 'Epoch 02 loss=0.0410\nValCpx=0.9928  (CWA 0.993 SWA 0.993)  time 2.7s', '\\n', 'Epoch 03 loss=0.0157\nValCpx=0.9964  (CWA 0.997 SWA 0.996)  time 2.8s', '\\n', 'Epoch 04 loss=0.0051\nValCpx=0.9968  (CWA 0.997 SWA 0.997)  time 3.2s', '\\n', 'Epoch 05 loss=0.0008\nValCpx=0.9997  (CWA 1.000 SWA 1.000)  time 3.1s', '\\n', 'Epoch 06 loss=0.0001\nValCpx=0.9994  (CWA 1.000 SWA 1.000)  time 3.4s', '\\n', 'Epoch 07 loss=0.0001\nValCpx=0.9994  (CWA 1.000 SWA 1.000)  time 2.0s', '\\n', 'Epoch 08 loss=0.0001\nValCpx=0.9994  (CWA 1.000 SWA 1.000)  time 2.1s', '\\n', 'Epoch 09 loss=0.0000\nValCpx=0.9994  (CWA 1.000 SWA 1.000)  time 2.0s', '\\n', 'Epoch 10 loss=0.0000\nValCpx=0.9994  (CWA 1.000 SWA 1.000)  time 2.1s', '\\n', 'Early stop.', '\\n',\n'Finished; artefacts saved in ./working', '\\n', 'Execution time: 29 seconds\nseconds (time limit is 30 minutes).']", ""], "analysis": ["", "", "The execution failed due to a ValueError in the glyph clustering section.\nSpecifically, the code attempts to convert the second character of a token to an\ninteger (int(tok[1])), but encountered a non-numeric character ('y'). This\nindicates that the dataset contains tokens that do not conform to the expected\nformat of a single letter followed by a numeric digit. To fix this, the code\nshould validate the token format before attempting the conversion. For example,\nadding a check like 'if len(tok) > 1 and tok[1].isdigit()' before the conversion\nwould handle such cases appropriately.", "The execution output reveals a bug in the clustering process. The effective\ncluster vocab size is unexpectedly reduced to 5, despite the clustering\nalgorithm being set to group glyphs into 9 clusters. This discrepancy suggests\nthat the clustering algorithm (K-means) might not have been able to effectively\ngroup the glyphs into the intended number of clusters, possibly due to\ninsufficient variability in the input features or a bug in the feature\nextraction process. To fix this, ensure that the feature extraction for glyphs\nprovides meaningful and distinguishable features for clustering. Additionally,\nverify the clustering implementation and consider experimenting with different\nclustering algorithms or parameters to achieve the desired number of clusters.", "The execution encountered a bug in the token_to_vec function. Specifically, it\nattempts to convert the second character of a token to an integer using\nint(tok[1]), but the token contains a character 'b' which cannot be converted to\nan integer. This suggests that the input tokens may not conform to the expected\nformat of a single letter followed by a digit.   To fix this issue, add\nvalidation to ensure the token format is correct before processing.\nAlternatively, handle the exception when the conversion fails and log the\nproblematic tokens for debugging. For example:  ```python def token_to_vec(tok:\nstr):     try:         return np.array([ord(tok[0]) - ord(\"A\"), int(tok[1])],\ndtype=np.float32)     except (IndexError, ValueError):         print(f\"Invalid\ntoken: {tok}\")         return np.array([0, 0], dtype=np.float32)  # Default or\ndummy vector ```", "", "The execution failed due to a data type mismatch error in the K-Means clustering\nstep. Specifically, the buffer dtype mismatch error occurred because the K-Means\nmodel expects data of type 'const double', but the input data provided was of\ntype 'float'.  To fix this issue, you should ensure that the input data for the\nK-Means model is explicitly converted to the 'double' data type before passing\nit to the model. This can be done by modifying the definition of the\n'token_to_vec' function to return numpy arrays with dtype 'float64' instead of\n'float32'. For example:  ```python def token_to_vec(tok: str):     # Shape part\nshape_char = tok[0]     s_id = shape_to_idx.get(shape_char, 0)     # Colour part\n(could be digits or letters)     colour_str = tok[1:]     if colour_str not in\ncolour_to_idx:         colour_to_idx[colour_str] = len(colour_to_idx)     c_id =\ncolour_to_idx[colour_str]     return np.array([s_id, c_id], dtype=np.float64)  #\nEnsure dtype is float64 ```", "The execution failed due to a data type mismatch in the buffer when using\nMiniBatchKMeans for clustering. Specifically, the `kmeans.predict` method\nexpected input data of type 'const double', but the provided data was of type\n'float'.  Proposed Fix: Ensure that the input data to the `kmeans.predict`\nmethod is explicitly converted to the expected data type ('double'). This can be\nachieved by modifying the `token_to_vec` function or converting the data before\npassing it to `kmeans.predict`. For example, use `np.array([shape_idx,\ncolour_idx], dtype=np.float64)` in `token_to_vec` to ensure the correct data\ntype.", "", "", "", "", ""], "exc_type": [null, null, "ValueError", null, "ValueError", null, "ValueError", "ValueError", null, null, null, null, null], "exc_info": [null, null, {"args": ["invalid literal for int() with base 10: 'y'"]}, null, {"args": ["invalid literal for int() with base 10: 'b'"]}, null, {"args": ["Buffer dtype mismatch, expected 'const double' but got 'float'"]}, {"args": ["Buffer dtype mismatch, expected 'const double' but got 'float'"]}, null, null, null, null, null], "exc_stack": [null, null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 134, "<module>", "color_idx = int(tok[1])"]], null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 118, "<module>", "X = np.stack([token_to_vec(t) for t in tok_list])"], ["runfile.py", 118, "<listcomp>", "X = np.stack([token_to_vec(t) for t in tok_list])"], ["runfile.py", 111, "token_to_vec", "return np.array([ord(tok[0]) - ord(\"A\"), int(tok[1])], dtype=np.float32)"]], null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 148, "<module>", "token2cluster = {"], ["runfile.py", 149, "<dictcomp>", "tok: int(kmeans.predict([token_to_vec(tok)])[0]) + 1 for tok in tok_list"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py", 1090, "predict", "labels = _labels_inertia_threadpool_limit("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/sklearn/utils/parallel.py", 165, "wrapper", "return func(*args, **kwargs)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py", 806, "_labels_inertia", "_labels("], ["_k_means_lloyd.pyx", 26, "sklearn.cluster._k_means_lloyd.lloyd_iter_chunked_dense", ""]], [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 148, "<module>", "token2cluster = {tok: int(kmeans.predict([token_to_vec(tok)])[0]) for tok in tok_list}"], ["runfile.py", 148, "<dictcomp>", "token2cluster = {tok: int(kmeans.predict([token_to_vec(tok)])[0]) for tok in tok_list}"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py", 1090, "predict", "labels = _labels_inertia_threadpool_limit("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/sklearn/utils/parallel.py", 165, "wrapper", "return func(*args, **kwargs)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py", 806, "_labels_inertia", "_labels("], ["_k_means_lloyd.pyx", 26, "sklearn.cluster._k_means_lloyd.lloyd_iter_chunked_dense", ""]], null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1661, "best_value": 0.1661}]}, {"metric_name": "training color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9485, "best_value": 0.9485}]}, {"metric_name": "training shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9482, "best_value": 0.9482}]}, {"metric_name": "training complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9481, "best_value": 0.9481}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9477, "best_value": 0.9477}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9447, "best_value": 0.9447}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "The complexity-weighted accuracy during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9432, "best_value": 0.9432}]}]}, {"metric_names": [{"metric_name": "training color-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset with color-weighted scoring.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "training shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset with shape-weighted scoring.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "training complexity-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset with complexity-weighted scoring.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset with color-weighted scoring.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset with shape-weighted scoring.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "validation complexity-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset with complexity-weighted scoring.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9997, "best_value": 0.9997}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 5.1e-05, "best_value": 5.1e-05}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.2381, "best_value": 0.2381}]}, {"metric_name": "training CWA", "lower_is_better": false, "description": "Training metric for Correct Weighted Accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9152, "best_value": 0.9152}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "Validation metric for Correct Weighted Accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9145, "best_value": 0.9145}]}, {"metric_name": "training SWA", "lower_is_better": false, "description": "Training metric for Smooth Weighted Accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.908, "best_value": 0.908}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "Validation metric for Smooth Weighted Accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9064, "best_value": 0.9064}]}, {"metric_name": "training CPX", "lower_is_better": false, "description": "Training metric for Complex Accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9083, "best_value": 0.9083}]}, {"metric_name": "validation CPX", "lower_is_better": false, "description": "Validation metric for Complex Accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9071, "best_value": 0.9071}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "The weighted accuracy for color classification.", "data": [{"dataset_name": "training", "final_value": 0.9841, "best_value": 0.9841}, {"dataset_name": "validation", "final_value": 0.9828, "best_value": 0.9828}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "The weighted accuracy for shape classification.", "data": [{"dataset_name": "training", "final_value": 0.984, "best_value": 0.984}, {"dataset_name": "validation", "final_value": 0.9824, "best_value": 0.9824}]}, {"metric_name": "complexity weighted accuracy", "lower_is_better": false, "description": "The weighted accuracy for complexity classification.", "data": [{"dataset_name": "training", "final_value": 0.984, "best_value": 0.984}, {"dataset_name": "validation", "final_value": 0.9824, "best_value": 0.9824}]}, {"metric_name": "loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "training", "final_value": 0.0228, "best_value": 0.0228}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is fitting the training data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0383, "best_value": 0.0383}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, indicating how well the model generalizes to unseen data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0309, "best_value": 0.0309}]}, {"metric_name": "train Color-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy during training, weighted by color classification performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.995, "best_value": 0.995}]}, {"metric_name": "validation Color-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy during validation, weighted by color classification performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9946, "best_value": 0.9946}]}, {"metric_name": "train Shape-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy during training, weighted by shape classification performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9948, "best_value": 0.9948}]}, {"metric_name": "validation Shape-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy during validation, weighted by shape classification performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9938, "best_value": 0.9938}]}, {"metric_name": "train Complexity-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy during training, weighted by complexity classification performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.995, "best_value": 0.995}]}, {"metric_name": "validation Complexity-Weighted Accuracy", "lower_is_better": false, "description": "The accuracy during validation, weighted by complexity classification performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.994, "best_value": 0.994}]}]}, {"metric_names": [{"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model when weighted by color features.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model when weighted by shape features.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "complexity-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model when weighted by complexity features.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 3.1e-05, "best_value": 3.1e-05}]}]}, {"metric_names": [{"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "Accuracy considering color weighting.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy considering shape weighting.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy considering complexity weighting.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9994, "best_value": 0.9994}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 3.2e-05, "best_value": 3.2e-05}]}]}, {"metric_names": [{"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by color attributes in the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9995, "best_value": 0.9995}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by shape attributes in the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9995, "best_value": 0.9995}]}, {"metric_name": "complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by complexity attributes in the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9994, "best_value": 0.9997}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Loss during the training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 3e-05, "best_value": 3e-05}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, true, false, false, false, false, false, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/cpxwa_curve.png", "../../logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_train_loss_curve.png", "../../logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_cpxwa_train_val_curve.png", "../../logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_val_weighted_accuracy_comparison.png"], ["../../logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/val_cpxwa.png", "../../logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/SPR_BENCH_train_loss_curve.png", "../../logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/SPR_BENCH_cpxwa_train_val_curve.png", "../../logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/SPR_BENCH_val_weighted_accuracy_comparison.png"], [], [], [], ["../../logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/val_compwa.png", "../../logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_train_loss_curve.png", "../../logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_cpxwa_train_val_curve.png", "../../logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_val_weighted_accuracy_comparison.png", "../../logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_confusion_matrix.png"], [], [], ["../../logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/val_compwa.png", "../../logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_train_loss_curve.png", "../../logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_cpxwa_train_val_curve.png", "../../logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_val_weighted_accuracy_cmp.png", "../../logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/val_cpxwa.png", "../../logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/SPR_BENCH_train_loss_curve.png", "../../logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/SPR_BENCH_cpxwa_train_val_curve.png", "../../logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/SPR_BENCH_val_weighted_accuracy_comparison.png"], ["../../logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/val_cpxwa.png", "../../logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/SPR_BENCH_train_loss_curve.png", "../../logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/SPR_BENCH_cpxwa_train_val_curve.png", "../../logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/SPR_BENCH_val_weighted_accuracy_comparison.png"], ["../../logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/val_cpxwa.png", "../../logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/SPR_BENCH_train_loss_curve.png", "../../logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/SPR_BENCH_cpxwa_train_val_curve.png", "../../logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/SPR_BENCH_val_weighted_accuracy_comparison.png"], ["../../logs/0-run/experiment_results/seed_aggregation_33273edd772d49d59cd022c50f5e8305/SPR_BENCH_aggregated_train_loss.png", "../../logs/0-run/experiment_results/seed_aggregation_33273edd772d49d59cd022c50f5e8305/SPR_BENCH_aggregated_cpxwa_train_val.png", "../../logs/0-run/experiment_results/seed_aggregation_33273edd772d49d59cd022c50f5e8305/SPR_BENCH_aggregated_val_weighted_accuracy.png"]], "plot_paths": [["experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/cpxwa_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_train_loss_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_cpxwa_train_val_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_val_weighted_accuracy_comparison.png"], ["experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/val_cpxwa.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/SPR_BENCH_train_loss_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/SPR_BENCH_cpxwa_train_val_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/SPR_BENCH_val_weighted_accuracy_comparison.png"], [], [], [], ["experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/val_compwa.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_train_loss_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_cpxwa_train_val_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_val_weighted_accuracy_comparison.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_confusion_matrix.png"], [], [], ["experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/val_compwa.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_train_loss_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_cpxwa_train_val_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_val_weighted_accuracy_cmp.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/val_cpxwa.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/SPR_BENCH_train_loss_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/SPR_BENCH_cpxwa_train_val_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/SPR_BENCH_val_weighted_accuracy_comparison.png"], ["experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/val_cpxwa.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/SPR_BENCH_train_loss_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/SPR_BENCH_cpxwa_train_val_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/SPR_BENCH_val_weighted_accuracy_comparison.png"], ["experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/val_cpxwa.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/SPR_BENCH_train_loss_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/SPR_BENCH_cpxwa_train_val_curve.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/SPR_BENCH_val_weighted_accuracy_comparison.png"], ["experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/seed_aggregation_33273edd772d49d59cd022c50f5e8305/SPR_BENCH_aggregated_train_loss.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/seed_aggregation_33273edd772d49d59cd022c50f5e8305/SPR_BENCH_aggregated_cpxwa_train_val.png", "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/seed_aggregation_33273edd772d49d59cd022c50f5e8305/SPR_BENCH_aggregated_val_weighted_accuracy.png"]], "plot_analyses": [[{"analysis": "The plot shows the validation complexity-weighted accuracy (CpxWA) improving significantly during the initial epochs and stabilizing around 0.94 after epoch 6. This indicates that the model quickly learns meaningful patterns in the data but does not show further improvement with additional epochs. This suggests the model may have reached its generalization capacity for this configuration.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/cpxwa_curve.png"}, {"analysis": "The training loss decreases rapidly in the first few epochs and stabilizes at a low value after epoch 6, indicating that the model converges well. The consistent decrease without oscillations suggests stable training dynamics, and the final low loss value aligns with the high validation accuracy observed in other plots.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_train_loss_curve.png"}, {"analysis": "The training and validation complexity-weighted accuracies (CpxWA) both improve rapidly in the initial epochs, with training accuracy slightly outperforming validation accuracy. The gap between the two curves remains small, suggesting minimal overfitting. Both curves stabilize after epoch 6, indicating that the model achieves consistent performance across training and validation sets.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_cpxwa_train_val_curve.png"}, {"analysis": "The weighted accuracy metrics (CWA, SWA, and CpxWA) for validation show similar trends, with rapid improvement in the first few epochs followed by stabilization. CWA consistently outperforms SWA and CpxWA, suggesting that the model is better at leveraging color features for accurate predictions. The close alignment of the three metrics indicates that the model is performing well across different evaluation criteria and is not biased toward any specific metric.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_val_weighted_accuracy_comparison.png"}], [{"analysis": "This plot demonstrates the validation Complexity-Weighted Accuracy (CpxWA) over 10 epochs. The accuracy improves steadily during the initial epochs, reaching a plateau close to 1.0 after epoch 4. This indicates that the model generalizes well on the validation data, achieving near-perfect performance. The rapid convergence suggests that the model effectively learns the patterns in the data early in training.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/val_cpxwa.png"}, {"analysis": "The training loss decreases sharply in the first few epochs and approaches zero by epoch 6, indicating that the model fits the training data very well. The consistent decline without any increase suggests the absence of overfitting during this stage, but this should be corroborated with validation performance to rule out potential issues.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/SPR_BENCH_train_loss_curve.png"}, {"analysis": "Both training and validation Complexity-Weighted Accuracy (CpxWA) exhibit similar trends, with rapid improvement in early epochs and convergence near 1.0. The close alignment between training and validation curves indicates that the model generalizes effectively without overfitting. The slight lag in validation performance compared to training during early epochs is expected and normal.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/SPR_BENCH_cpxwa_train_val_curve.png"}, {"analysis": "The weighted accuracy metrics (CWA, SWA, and CpxWA) for validation data show nearly identical trends, with all metrics converging close to 1.0 by epoch 6. This consistency across metrics indicates that the model performs well across different evaluation criteria, suggesting robustness in its reasoning capabilities.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7b59a1d4a01046c38a17d5b3f7e1911d_proc_1743796/SPR_BENCH_val_weighted_accuracy_comparison.png"}], [], [], [], [{"analysis": "The validation Complexity-Weighted Accuracy (CompWA) shows a rapid improvement during the initial epochs, stabilizing around 0.995. This indicates that the model learns effectively early on and maintains high accuracy with minimal fluctuations, except for the last epoch where there is a significant drop. This may suggest overfitting or instability in the final stages of training.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/val_compwa.png"}, {"analysis": "The training loss decreases sharply in the first few epochs and stabilizes at a very low value. This indicates that the model converges quickly and achieves a minimal loss, demonstrating effective learning. The slight increase in loss around epoch 12 might indicate a momentary instability or adaptation to a challenging pattern in the data.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_train_loss_curve.png"}, {"analysis": "Both training and validation Complexity-Weighted Accuracy (CpxWA) closely follow each other, indicating good generalization. The metrics stabilize at a high value (around 0.995), with minor deviations. The final epoch shows a noticeable drop in both, which could suggest overfitting or an issue with the training process towards the end.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_cpxwa_train_val_curve.png"}, {"analysis": "The weighted accuracy metrics (CWA, SWA, and CpxWA) for validation are nearly identical and consistently high, reflecting the robustness of the model across different evaluation criteria. The metrics exhibit stability with minor fluctuations, further confirming the model's strong performance and generalization ability.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_val_weighted_accuracy_comparison.png"}, {"analysis": "The confusion matrix for the validation set shows a strong diagonal dominance, indicating that the model predicts the correct labels with high accuracy. The off-diagonal elements are minimal, which confirms the effectiveness of the clustering and reasoning model in correctly classifying the sequences.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_419031a6c3a1447c8587f3b0ea6f6430_proc_1743797/SPR_BENCH_confusion_matrix.png"}], [], [], [{"analysis": "This plot depicts the Validation Complexity-Weighted Accuracy (CompWA) over epochs. The accuracy starts high and shows minor fluctuations before stabilizing at approximately 0.995. However, there is a significant drop in accuracy at epoch 8, which is likely due to a temporary issue such as model instability or a learning rate adjustment. The recovery after epoch 8 indicates the model's robustness and ability to regain performance.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/val_compwa.png"}, {"analysis": "This plot shows the Training Loss per epoch. The loss decreases sharply in the initial few epochs and then gradually stabilizes. This indicates effective learning and convergence of the model during training.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_train_loss_curve.png"}, {"analysis": "This plot compares Complexity-Weighted Accuracy (CpxWA) for both training and validation sets over epochs. Both curves exhibit similar trends, with a noticeable dip at epoch 8, suggesting a shared issue during that epoch. The recovery and alignment of the curves afterward indicate consistent performance across both sets.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_cpxwa_train_val_curve.png"}, {"analysis": "This plot compares Weighted Accuracy metrics (CWA, SWA, and CpxWA) for validation. All metrics follow a similar trend, with a significant drop at epoch 8 and subsequent recovery. The close alignment of these metrics suggests that the model is performing consistently across different accuracy metrics.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_val_weighted_accuracy_cmp.png"}, {"analysis": "This confusion matrix represents the model's performance during its best epoch. The high intensity along the diagonal indicates excellent classification accuracy, with minimal misclassifications. This supports the high accuracy observed in the other plots.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_18b108ca9c8948f79d7fdd8572151f93_proc_1743796/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The plot shows the validation Complexity-Weighted Accuracy (CpxWA) per epoch. The accuracy improves rapidly during the first few epochs, reaching near-perfect performance by epoch 4 and remaining stable thereafter. This indicates that the model is effectively learning the patterns in the data and converging quickly. The near-constant accuracy beyond epoch 4 suggests that the model has achieved optimal performance and is no longer improving with additional training.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/val_cpxwa.png"}, {"analysis": "This plot illustrates the training loss over epochs. The loss decreases sharply in the initial epochs, indicating effective learning and optimization. By epoch 4, the loss approaches zero and remains stable, signifying that the model has successfully minimized the error on the training data. This trend aligns with the rapid accuracy improvement observed in the validation metrics.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/SPR_BENCH_train_loss_curve.png"}, {"analysis": "This plot compares the Complexity-Weighted Accuracy (CpxWA) for both training and validation sets. The curves are almost identical, with both reaching near-perfect accuracy by epoch 4 and remaining stable thereafter. This close alignment between training and validation performance demonstrates that the model generalizes well to unseen data and is not overfitting.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/SPR_BENCH_cpxwa_train_val_curve.png"}, {"analysis": "This plot compares different weighted accuracy metrics (Color-Weighted Accuracy, Shape-Weighted Accuracy, and Complexity-Weighted Accuracy) for the validation set over epochs. All metrics exhibit a similar trend, with rapid improvement in the initial epochs and convergence to near-perfect performance by epoch 4. The consistency across metrics suggests that the model performs uniformly well across different evaluation criteria, highlighting its robustness and effectiveness in capturing the underlying patterns in the data.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/SPR_BENCH_val_weighted_accuracy_comparison.png"}], [{"analysis": "The plot shows the validation Complexity-Weighted Accuracy (CpxWA) across epochs. Initially, the accuracy starts at a lower value, dips slightly, and then rapidly improves, plateauing at nearly 100% by the 4th epoch. This indicates that the model quickly learns the underlying patterns and generalizes well to the validation data. The stabilization of accuracy after the 4th epoch suggests that the model has converged and further training does not lead to significant improvements.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/val_cpxwa.png"}, {"analysis": "This plot depicts the training loss across epochs. The loss starts relatively high, decreases sharply within the first few epochs, and approaches near-zero values by the 6th epoch. This rapid decline in loss indicates effective learning and optimization during training. The near-zero loss in later epochs suggests that the model fits the training data almost perfectly.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/SPR_BENCH_train_loss_curve.png"}, {"analysis": "This plot compares the Complexity-Weighted Accuracy (CpxWA) for both training and validation sets across epochs. Both curves exhibit a similar trend, starting with lower accuracy, followed by a rapid improvement, and plateauing at nearly 100% by the 4th epoch. The close alignment of the training and validation curves indicates minimal overfitting and strong generalization to unseen data.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/SPR_BENCH_cpxwa_train_val_curve.png"}, {"analysis": "The plot compares different weighted accuracies (CWA, SWA, and CpxWA) on the validation set across epochs. All three metrics follow a similar trend, with a slight dip early on, followed by a rapid increase and stabilization at nearly 100%. The close alignment of these metrics suggests that the model performs consistently well across different evaluation criteria, highlighting its robustness and effectiveness in handling the symbolic reasoning tasks.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/SPR_BENCH_val_weighted_accuracy_comparison.png"}], [{"analysis": "This plot demonstrates that the validation complexity-weighted accuracy (CpxWA) improves consistently over the first few epochs, reaching near-perfect accuracy by epoch 6. The plateau observed from epoch 6 onward suggests convergence of the model's learning. The steady increase indicates effective learning and generalization on the validation data.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/val_cpxwa.png"}, {"analysis": "The training loss decreases rapidly in the initial epochs and approaches zero by epoch 6, remaining flat thereafter. This indicates efficient learning during training and suggests that the model has effectively minimized the loss function. The absence of oscillations or increases in later epochs suggests no overfitting issues.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/SPR_BENCH_train_loss_curve.png"}, {"analysis": "This plot compares the training and validation complexity-weighted accuracy (CpxWA). Both curves follow a similar trend, with the training accuracy slightly ahead of the validation accuracy. Convergence occurs around epoch 6, with both metrics stabilizing at near-perfect values. This alignment indicates good generalization and minimal overfitting.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/SPR_BENCH_cpxwa_train_val_curve.png"}, {"analysis": "This plot compares validation metrics (CWA, SWA, and CpxWA). All three metrics follow almost identical trends, reaching near-perfect accuracy by epoch 6 and stabilizing thereafter. The strong alignment between these metrics suggests that the model performs well across different evaluation criteria, confirming its robustness.", "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/SPR_BENCH_val_weighted_accuracy_comparison.png"}], []], "vlm_feedback_summary": ["The results demonstrate that the model achieves rapid and stable convergence for\nboth training and validation metrics, with minimal overfitting. The different\nweighted accuracy metrics show consistent trends, and the model appears to\nleverage color features more effectively for predictions. These insights suggest\nthat the current hyperparameter tuning is effective and the model is well-\noptimized for the task.", "The plots indicate strong model performance, with rapid convergence in both\ntraining and validation metrics. The model achieves near-perfect accuracy across\nmultiple evaluation criteria, demonstrating effective learning and robust\ngeneralization. There is no evidence of overfitting, and the alignment between\ntraining and validation metrics is excellent.", "[]", "[]", "[]", "The experimental results demonstrate strong model performance, with high\naccuracy and low loss across metrics. The model generalizes well between\ntraining and validation sets, as shown by the alignment of metrics. The\nconfusion matrix further confirms the model's effectiveness in classification,\nthough the drop in performance in the final epoch warrants further\ninvestigation.", "[]", "[]", "The plots demonstrate excellent model performance, with high accuracy and low\ntraining loss. The temporary drop at epoch 8 is an outlier, and the model's\nrecovery afterward showcases its robustness. All accuracy metrics align closely,\nindicating consistent performance across different evaluation criteria.", "The plots demonstrate that the model achieves near-perfect accuracy across all\nevaluated metrics (CWA, SWA, and CpxWA) within the first few epochs, with stable\nperformance thereafter. The rapid convergence and alignment between training and\nvalidation metrics indicate effective learning and generalization. These results\nstrongly support the hypothesis that symbolic glyph clustering enhances model\nperformance in Synthetic PolyRule Reasoning.", "The experimental results demonstrate strong performance of the proposed model,\nwith all metrics (CpxWA, CWA, and SWA) converging to nearly 100% accuracy. The\nrapid convergence and alignment between training and validation metrics indicate\neffective learning and generalization. The results suggest that the symbolic\nglyph clustering approach significantly enhances the model's ability to reason\nand generalize in the SPR task.", "The plots indicate consistent and effective learning, with the model achieving\nnear-perfect accuracy across all metrics by epoch 6. Training loss decreases\nsteadily without signs of overfitting, and the alignment between training and\nvalidation metrics demonstrates strong generalization. The results highlight the\nmodel's robustness and its ability to generalize well to unseen data.", "[]"], "exec_time": [33.42556643486023, 61.90988636016846, 1.3758981227874756, 8.739858627319336, 0.9903717041015625, 166.4673810005188, 2.5020456314086914, 5.277468681335449, 146.03116035461426, 40.480628490448, 32.30580544471741, 29.79670524597168, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[\"SPR_BENCH\"]"], ["dataset_names"], [], [], [], ["All datasets successfully tested."], [], [], ["['All datasets in experiment_data']"], ["\"\""], ["<list(dataset_names)>"], ["<list(dataset_names)>"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\nexp = experiment_data.get(\"epochs_tuning\", {}).get(\"SPR_BENCH\", None)\nif exp is None:\n    print(\"SPR_BENCH results not found in experiment_data.\")\n    raise SystemExit\n\nepochs = np.array(exp[\"epochs\"])\ntrain_losses = np.array(exp[\"losses\"][\"train\"])\nval_metrics = exp[\"metrics\"][\"val\"]\ntrain_metrics = exp[\"metrics\"][\"train\"]\n\nval_cwa = np.array([m[\"cwa\"] for m in val_metrics])\nval_swa = np.array([m[\"swa\"] for m in val_metrics])\nval_cpx = np.array([m[\"cpx\"] for m in val_metrics])\ntrain_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n\nbest_epoch = int(epochs[np.argmax(val_cpx)])\nbest_val_cpx = float(val_cpx.max())\n\nprint(f\"Best Validation CpxWA: {best_val_cpx:.4f} @ epoch {best_epoch}\")\n\n# ---------------------------------------------------------------------\n# 1) Training loss curve\ntry:\n    plt.figure()\n    plt.plot(epochs, train_losses, marker=\"o\", label=\"Train Loss\")\n    plt.title(\"SPR_BENCH: Training Loss per Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_train_loss_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating train loss plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 2) Training vs. Validation Complexity-Weighted Accuracy\ntry:\n    plt.figure()\n    plt.plot(epochs, train_cpx, marker=\"o\", label=\"Train CpxWA\")\n    plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n    plt.title(\"SPR_BENCH: Complexity-Weighted Accuracy\\nLeft: Train, Right: Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CpxWA\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_cpxwa_train_val_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CpxWA curve: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 3) Validation weighted-accuracy comparison\ntry:\n    plt.figure()\n    plt.plot(epochs, val_cwa, marker=\"o\", label=\"Val CWA\")\n    plt.plot(epochs, val_swa, marker=\"^\", label=\"Val SWA\")\n    plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n    plt.title(\"SPR_BENCH: Weighted Accuracy Comparison (Validation)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Weighted Accuracy\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_val_weighted_accuracy_comparison.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating weighted accuracy comparison plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------\n# Load stored experiment results\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\ndataset_names = list(experiment_data.keys())\ncross_val_cpx = {}\n\n# ---------------------------------------------------------------\nfor dname in dataset_names:\n    ed = experiment_data[dname]\n    epochs = np.array(ed.get(\"epochs\", []))\n    if epochs.size == 0:  # skip empty entries\n        continue\n    train_losses = np.array(ed[\"losses\"][\"train\"])\n    train_metrics = ed[\"metrics\"][\"train\"]\n    val_metrics = ed[\"metrics\"][\"val\"]\n\n    train_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n    val_cpx = np.array([m[\"cpx\"] for m in val_metrics])\n    val_cwa = np.array([m[\"cwa\"] for m in val_metrics])\n    val_swa = np.array([m[\"swa\"] for m in val_metrics])\n    cross_val_cpx[dname] = (epochs, val_cpx)\n\n    # 1) Training loss curve\n    try:\n        plt.figure()\n        plt.plot(epochs, train_losses, marker=\"o\", label=\"Train Loss\")\n        plt.title(f\"{dname}: Training Loss per Epoch\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_train_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {dname}: {e}\")\n        plt.close()\n\n    # 2) Train vs. Validation Complexity-Weighted Accuracy\n    try:\n        plt.figure()\n        plt.plot(epochs, train_cpx, marker=\"o\", label=\"Train CpxWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(\n            f\"{dname}: Complexity-Weighted Accuracy\\nLeft: Train, Right: Validation\"\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CpxWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_cpxwa_train_val_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CpxWA curve for {dname}: {e}\")\n        plt.close()\n\n    # 3) Validation weighted-accuracy comparison\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, marker=\"o\", label=\"Val CWA\")\n        plt.plot(epochs, val_swa, marker=\"^\", label=\"Val SWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(f\"{dname}: Weighted Accuracy Comparison (Validation)\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dname}_val_weighted_accuracy_comparison.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating weighted accuracy plot for {dname}: {e}\")\n        plt.close()\n\n# ---------------------------------------------------------------\n# 4) Cross-dataset comparison of validation CpxWA (only if >1 dataset)\nif len(cross_val_cpx) > 1:\n    try:\n        plt.figure()\n        for dname, (ep, vcpx) in cross_val_cpx.items():\n            plt.plot(ep, vcpx, marker=\"o\", label=f\"{dname}\")\n        plt.title(\"Validation Complexity-Weighted Accuracy Across Datasets\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CpxWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"cross_dataset_val_cpxwa_comparison.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating cross-dataset plot: {e}\")\n        plt.close()\n", null, null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\n# ---------------------------------------------------------------------\nfor dname, exp in experiment_data.items():\n    try:\n        epochs = np.array(exp[\"epochs\"])\n        train_losses = np.array(exp[\"losses\"][\"train\"])\n        val_metrics = exp[\"metrics\"][\"val\"]\n        train_metrics = exp[\"metrics\"][\"train\"]\n    except KeyError as e:\n        print(f\"Dataset {dname} missing key {e}, skipping.\")\n        continue\n\n    val_cwa = np.array([m[\"cwa\"] for m in val_metrics])\n    val_swa = np.array([m[\"swa\"] for m in val_metrics])\n    val_cpx = np.array([m[\"cpx\"] for m in val_metrics])\n    train_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n\n    best_epoch = int(epochs[np.argmax(val_cpx)])\n    best_val_cpx = float(val_cpx.max())\n    print(f\"{dname}: Best Validation CpxWA = {best_val_cpx:.4f} @ epoch {best_epoch}\")\n\n    # -------------------------- Plot 1 -------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_losses, marker=\"o\", label=\"Train Loss\")\n        plt.title(f\"{dname}: Training Loss per Epoch\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_train_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating train loss plot for {dname}: {e}\")\n        plt.close()\n\n    # -------------------------- Plot 2 -------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_cpx, marker=\"o\", label=\"Train CpxWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(\n            f\"{dname}: Complexity-Weighted Accuracy\\nLeft: Train, Right: Validation\"\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CpxWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_cpxwa_train_val_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CpxWA curve for {dname}: {e}\")\n        plt.close()\n\n    # -------------------------- Plot 3 -------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, marker=\"o\", label=\"Val CWA\")\n        plt.plot(epochs, val_swa, marker=\"^\", label=\"Val SWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(f\"{dname}: Weighted Accuracy Comparison (Validation)\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dname}_val_weighted_accuracy_comparison.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating weighted accuracy comparison plot for {dname}: {e}\")\n        plt.close()\n\n    # -------------------------- Plot 4 -------------------------------\n    try:\n        preds = np.array(exp.get(\"predictions\", []))\n        gts = np.array(exp.get(\"ground_truth\", []))\n        if preds.size and preds.size == gts.size:\n            num_cls = len(np.unique(np.concatenate([preds, gts])))\n            cm = np.zeros((num_cls, num_cls), dtype=int)\n            for t, p in zip(gts, preds):\n                cm[t, p] += 1\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.title(f\"{dname}: Confusion Matrix (Validation)\")\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.colorbar()\n            plt.savefig(os.path.join(working_dir, f\"{dname}_confusion_matrix.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dname}: {e}\")\n        plt.close()\n", null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\n# -------------------------------------------------------------\nfor ds_name, ds in experiment_data.items():\n    epochs = np.array(ds[\"epochs\"])\n    tr_losses = np.array(ds[\"losses\"][\"train\"])\n    tr_metrics = ds[\"metrics\"][\"train\"]\n    val_metrics = ds[\"metrics\"][\"val\"]\n\n    val_cwa = np.array([m[\"cwa\"] for m in val_metrics])\n    val_swa = np.array([m[\"swa\"] for m in val_metrics])\n    val_cpx = np.array([m[\"cpx\"] for m in val_metrics])\n    tr_cpx = np.array([m[\"cpx\"] for m in tr_metrics])\n\n    best_ep_idx = int(np.argmax(val_cpx))\n    best_ep = int(epochs[best_ep_idx])\n    best_val_cpx = float(val_cpx[best_ep_idx])\n    print(f\"{ds_name}: Best Validation CpxWA {best_val_cpx:.4f} @ epoch {best_ep}\")\n\n    # 1) Training loss curve\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_losses, marker=\"o\", label=\"Train Loss\")\n        plt.title(f\"{ds_name}: Training Loss per Epoch\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_train_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating train loss plot for {ds_name}: {e}\")\n        plt.close()\n\n    # 2) Train vs Val CpxWA\n    try:\n        plt.figure()\n        plt.plot(epochs, tr_cpx, marker=\"o\", label=\"Train CpxWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(f\"{ds_name}: Complexity-Weighted Accuracy\\nLeft: Train, Right: Val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CpxWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_cpxwa_train_val_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CpxWA curve for {ds_name}: {e}\")\n        plt.close()\n\n    # 3) Validation weighted-accuracy comparison\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, marker=\"o\", label=\"Val CWA\")\n        plt.plot(epochs, val_swa, marker=\"^\", label=\"Val SWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(f\"{ds_name}: Weighted Accuracy Comparison (Validation)\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{ds_name}_val_weighted_accuracy_cmp.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating weighted accuracy comparison for {ds_name}: {e}\")\n        plt.close()\n\n    # 4) Confusion matrix of best epoch predictions\n    try:\n        preds = np.array(ds.get(\"predictions\", []))\n        gts = np.array(ds.get(\"ground_truth\", []))\n        if preds.size and gts.size:\n            num_classes = int(max(preds.max(), gts.max()) + 1)\n            cm = np.zeros((num_classes, num_classes), dtype=int)\n            for t, p in zip(gts, preds):\n                cm[t, p] += 1\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.title(f\"{ds_name}: Confusion Matrix (Best Epoch)\")\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.savefig(os.path.join(working_dir, f\"{ds_name}_confusion_matrix.png\"))\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {ds_name}: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------\n# Load stored experiment results\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\ndataset_names = list(experiment_data.keys())\ncross_val_cpx = {}\n\n# ---------------------------------------------------------------\nfor dname in dataset_names:\n    ed = experiment_data[dname]\n    epochs = np.array(ed.get(\"epochs\", []))\n    if epochs.size == 0:  # skip empty entries\n        continue\n    train_losses = np.array(ed[\"losses\"][\"train\"])\n    train_metrics = ed[\"metrics\"][\"train\"]\n    val_metrics = ed[\"metrics\"][\"val\"]\n\n    train_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n    val_cpx = np.array([m[\"cpx\"] for m in val_metrics])\n    val_cwa = np.array([m[\"cwa\"] for m in val_metrics])\n    val_swa = np.array([m[\"swa\"] for m in val_metrics])\n    cross_val_cpx[dname] = (epochs, val_cpx)\n\n    # 1) Training loss curve\n    try:\n        plt.figure()\n        plt.plot(epochs, train_losses, marker=\"o\", label=\"Train Loss\")\n        plt.title(f\"{dname}: Training Loss per Epoch\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_train_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {dname}: {e}\")\n        plt.close()\n\n    # 2) Train vs. Validation Complexity-Weighted Accuracy\n    try:\n        plt.figure()\n        plt.plot(epochs, train_cpx, marker=\"o\", label=\"Train CpxWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(\n            f\"{dname}: Complexity-Weighted Accuracy\\nLeft: Train, Right: Validation\"\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CpxWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_cpxwa_train_val_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CpxWA curve for {dname}: {e}\")\n        plt.close()\n\n    # 3) Validation weighted-accuracy comparison\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, marker=\"o\", label=\"Val CWA\")\n        plt.plot(epochs, val_swa, marker=\"^\", label=\"Val SWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(f\"{dname}: Weighted Accuracy Comparison (Validation)\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dname}_val_weighted_accuracy_comparison.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating weighted accuracy plot for {dname}: {e}\")\n        plt.close()\n\n# ---------------------------------------------------------------\n# 4) Cross-dataset comparison of validation CpxWA (only if >1 dataset)\nif len(cross_val_cpx) > 1:\n    try:\n        plt.figure()\n        for dname, (ep, vcpx) in cross_val_cpx.items():\n            plt.plot(ep, vcpx, marker=\"o\", label=f\"{dname}\")\n        plt.title(\"Validation Complexity-Weighted Accuracy Across Datasets\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CpxWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"cross_dataset_val_cpxwa_comparison.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating cross-dataset plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------\n# Load stored experiment results\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\ndataset_names = list(experiment_data.keys())\ncross_val_cpx = {}\n\n# ---------------------------------------------------------------\nfor dname in dataset_names:\n    ed = experiment_data[dname]\n    epochs = np.array(ed.get(\"epochs\", []))\n    if epochs.size == 0:  # skip empty entries\n        continue\n    train_losses = np.array(ed[\"losses\"][\"train\"])\n    train_metrics = ed[\"metrics\"][\"train\"]\n    val_metrics = ed[\"metrics\"][\"val\"]\n\n    train_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n    val_cpx = np.array([m[\"cpx\"] for m in val_metrics])\n    val_cwa = np.array([m[\"cwa\"] for m in val_metrics])\n    val_swa = np.array([m[\"swa\"] for m in val_metrics])\n    cross_val_cpx[dname] = (epochs, val_cpx)\n\n    # 1) Training loss curve\n    try:\n        plt.figure()\n        plt.plot(epochs, train_losses, marker=\"o\", label=\"Train Loss\")\n        plt.title(f\"{dname}: Training Loss per Epoch\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_train_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {dname}: {e}\")\n        plt.close()\n\n    # 2) Train vs. Validation Complexity-Weighted Accuracy\n    try:\n        plt.figure()\n        plt.plot(epochs, train_cpx, marker=\"o\", label=\"Train CpxWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(\n            f\"{dname}: Complexity-Weighted Accuracy\\nLeft: Train, Right: Validation\"\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CpxWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_cpxwa_train_val_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CpxWA curve for {dname}: {e}\")\n        plt.close()\n\n    # 3) Validation weighted-accuracy comparison\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, marker=\"o\", label=\"Val CWA\")\n        plt.plot(epochs, val_swa, marker=\"^\", label=\"Val SWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(f\"{dname}: Weighted Accuracy Comparison (Validation)\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dname}_val_weighted_accuracy_comparison.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating weighted accuracy plot for {dname}: {e}\")\n        plt.close()\n\n# ---------------------------------------------------------------\n# 4) Cross-dataset comparison of validation CpxWA (only if >1 dataset)\nif len(cross_val_cpx) > 1:\n    try:\n        plt.figure()\n        for dname, (ep, vcpx) in cross_val_cpx.items():\n            plt.plot(ep, vcpx, marker=\"o\", label=f\"{dname}\")\n        plt.title(\"Validation Complexity-Weighted Accuracy Across Datasets\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CpxWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"cross_dataset_val_cpxwa_comparison.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating cross-dataset plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------\n# Load stored experiment results\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\ndataset_names = list(experiment_data.keys())\ncross_val_cpx = {}\n\n# ---------------------------------------------------------------\nfor dname in dataset_names:\n    ed = experiment_data[dname]\n    epochs = np.array(ed.get(\"epochs\", []))\n    if epochs.size == 0:  # skip empty entries\n        continue\n    train_losses = np.array(ed[\"losses\"][\"train\"])\n    train_metrics = ed[\"metrics\"][\"train\"]\n    val_metrics = ed[\"metrics\"][\"val\"]\n\n    train_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n    val_cpx = np.array([m[\"cpx\"] for m in val_metrics])\n    val_cwa = np.array([m[\"cwa\"] for m in val_metrics])\n    val_swa = np.array([m[\"swa\"] for m in val_metrics])\n    cross_val_cpx[dname] = (epochs, val_cpx)\n\n    # 1) Training loss curve\n    try:\n        plt.figure()\n        plt.plot(epochs, train_losses, marker=\"o\", label=\"Train Loss\")\n        plt.title(f\"{dname}: Training Loss per Epoch\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_train_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {dname}: {e}\")\n        plt.close()\n\n    # 2) Train vs. Validation Complexity-Weighted Accuracy\n    try:\n        plt.figure()\n        plt.plot(epochs, train_cpx, marker=\"o\", label=\"Train CpxWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(\n            f\"{dname}: Complexity-Weighted Accuracy\\nLeft: Train, Right: Validation\"\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CpxWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{dname}_cpxwa_train_val_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CpxWA curve for {dname}: {e}\")\n        plt.close()\n\n    # 3) Validation weighted-accuracy comparison\n    try:\n        plt.figure()\n        plt.plot(epochs, val_cwa, marker=\"o\", label=\"Val CWA\")\n        plt.plot(epochs, val_swa, marker=\"^\", label=\"Val SWA\")\n        plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n        plt.title(f\"{dname}: Weighted Accuracy Comparison (Validation)\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"{dname}_val_weighted_accuracy_comparison.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating weighted accuracy plot for {dname}: {e}\")\n        plt.close()\n\n# ---------------------------------------------------------------\n# 4) Cross-dataset comparison of validation CpxWA (only if >1 dataset)\nif len(cross_val_cpx) > 1:\n    try:\n        plt.figure()\n        for dname, (ep, vcpx) in cross_val_cpx.items():\n            plt.plot(ep, vcpx, marker=\"o\", label=f\"{dname}\")\n        plt.title(\"Validation Complexity-Weighted Accuracy Across Datasets\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CpxWA\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"cross_dataset_val_cpxwa_comparison.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating cross-dataset plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\n# Load every experiment_data.npy that was listed by the user\nexperiment_data_path_list = [\n    \"experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_a8d888f085a848f3b005d703fb497747_proc_1743799/experiment_data.npy\",\n    \"experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7bcef6703ce24a41944b4335f9ea802b_proc_1743798/experiment_data.npy\",\n    \"experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2e38fbaae2f444c5bac62db2aa0eb740_proc_1743796/experiment_data.npy\",\n]\nall_experiment_data = []\ntry:\n    for p in experiment_data_path_list:\n        full_p = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \".\"), p)\n        if not os.path.isfile(full_p):\n            print(f\"Warning: file not found -> {full_p}\")\n            continue\n        d = np.load(full_p, allow_pickle=True).item()\n        all_experiment_data.append(d)\n    if not all_experiment_data:\n        raise RuntimeError(\"No experiment_data.npy files could be loaded.\")\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\n# ------------------------------------------------------------------\n# Aggregate metrics across runs\naggregated = {}  # {dataset_name: {metric_name: [runs x epochs ndarray] ...}}\nfor run_data in all_experiment_data:\n    for dname, ed in run_data.items():\n        if \"epochs\" not in ed or len(ed[\"epochs\"]) == 0:\n            continue\n        epochs = np.array(ed[\"epochs\"])\n        losses = np.array(ed[\"losses\"][\"train\"])\n        train_metrics = ed[\"metrics\"][\"train\"]\n        val_metrics = ed[\"metrics\"][\"val\"]\n\n        # Extract metric arrays\n        train_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n        val_cpx = np.array([m[\"cpx\"] for m in val_metrics])\n        val_cwa = np.array([m[\"cwa\"] for m in val_metrics])\n        val_swa = np.array([m[\"swa\"] for m in val_metrics])\n\n        if dname not in aggregated:\n            aggregated[dname] = {\n                \"epochs\": epochs,\n                \"train_loss\": [],\n                \"train_cpx\": [],\n                \"val_cpx\": [],\n                \"val_cwa\": [],\n                \"val_swa\": [],\n            }\n\n        # Make sure epochs align; if not, skip this run for that dataset\n        if len(aggregated[dname][\"epochs\"]) != len(epochs) or not np.allclose(\n            aggregated[dname][\"epochs\"], epochs\n        ):\n            print(f\"Epoch mismatch for {dname} in one run; skipping that run.\")\n            continue\n\n        aggregated[dname][\"train_loss\"].append(losses)\n        aggregated[dname][\"train_cpx\"].append(train_cpx)\n        aggregated[dname][\"val_cpx\"].append(val_cpx)\n        aggregated[dname][\"val_cwa\"].append(val_cwa)\n        aggregated[dname][\"val_swa\"].append(val_swa)\n\n# Convert lists to numpy arrays for easier math\nfor dname, dct in aggregated.items():\n    for k, v in dct.items():\n        if k == \"epochs\":\n            continue\n        dct[k] = np.array(v)  # shape -> [runs, epochs]\n\n\n# ------------------------------------------------------------------\ndef mean_sem(arr):\n    \"\"\"Return mean and standard error along axis 0.\"\"\"\n    mean = np.mean(arr, axis=0)\n    sem = (\n        np.std(arr, axis=0, ddof=1) / np.sqrt(arr.shape[0])\n        if arr.shape[0] > 1\n        else np.zeros_like(mean)\n    )\n    return mean, sem\n\n\n# ------------------------------------------------------------------\n# Plot per-dataset aggregates\nfor dname, dct in aggregated.items():\n    ep = dct[\"epochs\"]\n\n    # 1) Aggregated Training Loss\n    try:\n        if dct[\"train_loss\"].size > 0:\n            mean_loss, sem_loss = mean_sem(dct[\"train_loss\"])\n            plt.figure()\n            plt.plot(ep, mean_loss, label=\"Mean Train Loss\", color=\"tab:red\")\n            plt.fill_between(\n                ep,\n                mean_loss - sem_loss,\n                mean_loss + sem_loss,\n                alpha=0.3,\n                color=\"tab:red\",\n                label=\"\u00b1 SEM\",\n            )\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(\n                f\"{dname}: Aggregated Training Loss per Epoch\\nMean \u00b1 SEM across runs\"\n            )\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dname}_aggregated_train_loss.png\")\n            plt.savefig(fname)\n            plt.close()\n            print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating aggregated train loss plot for {dname}: {e}\")\n        plt.close()\n\n    # 2) Aggregated Train vs Val CpxWA\n    try:\n        if dct[\"train_cpx\"].size > 0 and dct[\"val_cpx\"].size > 0:\n            m_tr, s_tr = mean_sem(dct[\"train_cpx\"])\n            m_val, s_val = mean_sem(dct[\"val_cpx\"])\n            plt.figure()\n            plt.plot(ep, m_tr, label=\"Train CpxWA (mean)\", color=\"tab:blue\")\n            plt.fill_between(\n                ep,\n                m_tr - s_tr,\n                m_tr + s_tr,\n                alpha=0.3,\n                color=\"tab:blue\",\n                label=\"Train \u00b1 SEM\",\n            )\n            plt.plot(ep, m_val, label=\"Val CpxWA (mean)\", color=\"tab:green\")\n            plt.fill_between(\n                ep,\n                m_val - s_val,\n                m_val + s_val,\n                alpha=0.3,\n                color=\"tab:green\",\n                label=\"Val \u00b1 SEM\",\n            )\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"CpxWA\")\n            plt.title(f\"{dname}: Complexity-Weighted Accuracy\\nMean \u00b1 SEM across runs\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dname}_aggregated_cpxwa_train_val.png\")\n            plt.savefig(fname)\n            plt.close()\n            print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating aggregated CpxWA plot for {dname}: {e}\")\n        plt.close()\n\n    # 3) Aggregated Validation Weighted-Accuracy variants\n    try:\n        if (\n            dct[\"val_cwa\"].size > 0\n            and dct[\"val_swa\"].size > 0\n            and dct[\"val_cpx\"].size > 0\n        ):\n            m_cwa, s_cwa = mean_sem(dct[\"val_cwa\"])\n            m_swa, s_swa = mean_sem(dct[\"val_swa\"])\n            m_cpx, s_cpx = mean_sem(dct[\"val_cpx\"])\n            plt.figure()\n            plt.plot(ep, m_cwa, marker=\"o\", label=\"Val CWA (mean)\")\n            plt.fill_between(ep, m_cwa - s_cwa, m_cwa + s_cwa, alpha=0.3)\n            plt.plot(ep, m_swa, marker=\"^\", label=\"Val SWA (mean)\")\n            plt.fill_between(ep, m_swa - s_swa, m_swa + s_swa, alpha=0.3)\n            plt.plot(ep, m_cpx, marker=\"s\", label=\"Val CpxWA (mean)\")\n            plt.fill_between(ep, m_cpx - s_cpx, m_cpx + s_cpx, alpha=0.3)\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Weighted Accuracy\")\n            plt.title(\n                f\"{dname}: Validation Weighted Accuracies\\nMean \u00b1 SEM across runs\"\n            )\n            plt.legend()\n            fname = os.path.join(\n                working_dir, f\"{dname}_aggregated_val_weighted_accuracy.png\"\n            )\n            plt.savefig(fname)\n            plt.close()\n            print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating aggregated weighted accuracy plot for {dname}: {e}\")\n        plt.close()\n\n# ------------------------------------------------------------------\n# Cross-dataset comparison of aggregated validation CpxWA\nif len(aggregated) > 1:\n    try:\n        plt.figure()\n        for dname, dct in aggregated.items():\n            if dct[\"val_cpx\"].size == 0:\n                continue\n            m_val, s_val = mean_sem(dct[\"val_cpx\"])\n            ep = dct[\"epochs\"]\n            plt.plot(ep, m_val, label=f\"{dname} (mean)\")\n            plt.fill_between(ep, m_val - s_val, m_val + s_val, alpha=0.2)\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CpxWA\")\n        plt.title(\"Validation CpxWA Across Datasets\\nMean \u00b1 SEM across runs\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"cross_dataset_aggregated_val_cpxwa.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating cross-dataset aggregated plot: {e}\")\n        plt.close()\n"], "plot_plan": ["We will load experiment_data.npy from the working directory, extract the epoch list, train losses, and weighted\u2013accuracy metrics for the \u201cSPR_BENCH\u201d split, and then create up to three concise plots: (1) train-loss curve, (2) training vs. validation complexity-weighted accuracy, and (3) a side-by-side comparison of the three validation weighted accuracies (CWA, SWA, CPX).  Each plot is wrapped in its own try-except block, given a clear title/sub-title, saved with a descriptive name that includes the dataset and plot type, and the figure is always closed.  We also compute and print the best validation complexity-weighted accuracy and the epoch at which it occurs so the user immediately sees the key result.  All plots are saved in the predefined working directory, and no synthetic or fabricated data are introduced\u2014everything comes directly from the stored experiment_data structure.  The code relies only on NumPy and Matplotlib, follows the developer plotting guidelines, and respects the five-figure limit by generating just three essential visuals.  It can be run as-is after the training script finishes because it assumes experiment_data.npy already exists.  The implementation is concise, readable, and robust to missing keys or absent files, exiting gracefully with informative messages when necessary.  Finally, the script prints the best metric values to standard output so users can verify performance without opening the plots.", "We need to load the saved experiment_data.npy, iterate over every dataset key it contains (e.g. \u2018SPR_BENCH\u2019, or more if present), and for each dataset extract epochs, training losses, and the three weighted-accuracy metrics for train/val. For each dataset we generate three independent plots inside separate try-except blocks: \u2460 training-loss curve, \u2461 train vs. validation complexity-weighted accuracy, and \u2462 validation comparison of CWA/SWA/CpxWA. We title every figure clearly, include axes labels and legends, and save to working_dir with descriptive filenames that embed dataset name and plot type. After saving we always close the figure to free memory. If experiment_data holds results for more than one dataset, we additionally create one cross-dataset comparison plot of validation CpxWA; this is also wrapped in try-except and skipped if only a single dataset is found. All plotting respects the \u201cat most 5 figures per dataset\u201d rule. The code begins with the required imports and working_dir definition and uses only data already stored in experiment_data.npy.", null, null, null, "We first load the serialized numpy dictionary and iterate over every dataset entry that actually exists. For each dataset we recover epoch numbers, training losses, and the three weighted\u2013accuracy curves that were logged during the experiment, plus predictions and labels if present. We then compute the best epoch according to the maximum validation complexity-weighted accuracy and print that value. Inside separate try-except blocks we draw up to four figures: (1) training-loss curve, (2) train vs. validation complexity-weighted accuracy, (3) validation CWA/SWA/CpxWA comparison, and (4) a confusion-matrix heat-map (only if predictions are available). Each figure is properly titled, saved with a descriptive name that contains the dataset and plot type, and then immediately closed. All plots are written to the pre-defined \u201cworking\u201d directory, and no artificial data are generated\u2014everything comes straight from experiment_data.npy. The code is compact, uses only basic matplotlib, and respects the five-figure limit. Finally, the script prints the main evaluation metric (best validation CpxWA) for every dataset processed.", null, null, "We will load the saved experiment_data.npy, iterate over every dataset entry (e.g. \u201cSPR_BENCH\u201d), and extract epochs, train losses, and the three weighted-accuracy metrics for train/validation splits.  For each dataset we will create up to four separate figures wrapped in try-except blocks: (1) training loss curve, (2) train vs. validation Complexity-Weighted Accuracy, (3) validation CWA/SWA/CpxWA comparison, and (4) a confusion-matrix style heat-map of ground-truth vs. best-epoch predictions (only if those arrays are non-empty).  All plots are titled clearly and saved under working_dir with descriptive filenames that include the dataset name and plot type.  We respect the five-figure limit and always close figures after saving.  The script begins with the required imports, guarantees working_dir exists, and prints the best CpxWA for quick reference.  Only data actually present in experiment_data.npy are used\u2014no synthetic values are invented.  The final code block is concise, self-contained, and prints out the computed best validation metric for each dataset.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": ["EPOCHS (Number of training epochs)", null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["The script will load the saved NumPy dictionary, iterate through each dataset\nstored under the \u201cepochs_tuning\u201d key, pick the epoch that achieved the highest\nvalidation complexity-weighted accuracy, and then print the corresponding best\ntraining and validation metrics with explicit names. All logic is in the global\nscope so the file runs immediately when executed.", "The script below loads the saved NumPy dictionary, iterates over every dataset\nit contains, and prints the final values of all recorded metrics and losses in a\nclear, self-describing format. It relies on the data structure defined in the\noriginal training script and executes immediately when run.", "", "The script will load the saved NumPy file from the \u201cworking\u201d directory, retrieve\nthe single top-level key (\u201cSPR_BENCH\u201d), and collect all stored lists of metrics\nand losses.   For every metric that grows with performance (CWA, SWA, CPX) it\nwill report the best (maximum) value observed during training; for every loss it\nwill report the minimum value.   Results are printed in a readable form that\nfirst states the dataset name and then clearly labels every reported quantity\n(e.g., \u201ctraining CWA,\u201d \u201cvalidation loss\u201d).", "", "The script will load the NumPy file from the working directory, retrieve the\nstored dictionary, and for every dataset inside it (only \u201cSPR_BENCH\u201d here) print\nthe most recent (final\u2013epoch) value for each stored metric and loss. This\nsatisfies the \u201cbest or final\u201d requirement while ensuring we clearly label each\nprinted figure.", "", "Below is a short script outline: it loads the NumPy file from the \u201cworking\u201d\ndirectory, pulls out the stored dictionaries, finds the final-epoch training\nvalues and the best (max accuracy / min loss) validation values, and prints them\nwith explicit metric names for every dataset it finds.", "The script will locate the \u201cworking\u201d directory, load experiment_data.npy, and\nloop over every dataset stored inside.   For each dataset, it finds the epoch\nthat achieved the best validation Complexity-Weighted Accuracy (CompWA).   It\nthen prints the dataset name followed by clearly labeled best-epoch metrics:\ntrain loss, validation loss, train CWA, validation CWA, train SWA, validation\nSWA, train CompWA, and validation CompWA.   No plots are created and the code\nruns immediately at the global scope.", "The script below loads the saved NumPy dictionary, iterates over every dataset\nit contains, and prints the final values of all recorded metrics and losses in a\nclear, self-describing format. It relies on the data structure defined in the\noriginal training script and executes immediately when run.", "The script below loads the saved NumPy dictionary, iterates over every dataset\nit contains, and prints the final values of all recorded metrics and losses in a\nclear, self-describing format. It relies on the data structure defined in the\noriginal training script and executes immediately when run.", "The script below loads the saved NumPy dictionary, iterates over every dataset\nit contains, and prints the final values of all recorded metrics and losses in a\nclear, self-describing format. It relies on the data structure defined in the\noriginal training script and executes immediately when run.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# Locate and load the stored experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# Helper to print metrics cleanly\ndef print_metric(label: str, value):\n    if value is None:\n        return\n    if isinstance(value, float):\n        print(f\"{label}: {value:.4f}\")\n    else:\n        print(f\"{label}: {value}\")\n\n\n# ---------------------------------------------------------------------\n# Extract and display the best (highest validation cpx-weighted accuracy) metrics\nfor dataset_name, data in experiment_data[\"epochs_tuning\"].items():\n    metrics_train = data[\"metrics\"][\"train\"]\n    metrics_val = data[\"metrics\"][\"val\"]\n    train_losses = data[\"losses\"][\"train\"]\n    epochs_list = data[\"epochs\"]\n\n    # Identify the best epoch based on validation complexity-weighted accuracy\n    best_idx = max(\n        range(len(metrics_val)),\n        key=lambda i: metrics_val[i][\"cpx\"] if metrics_val[i] is not None else -1.0,\n    )\n\n    best_epoch = epochs_list[best_idx]\n    best_train_m = metrics_train[best_idx]\n    best_val_m = metrics_val[best_idx]\n    best_train_loss = train_losses[best_idx]\n\n    # -----------------------------------------------------------------\n    # Print results\n    print(dataset_name)  # Dataset name\n    print_metric(\"best epoch\", best_epoch)\n    print_metric(\"training loss\", best_train_loss)\n    print_metric(\"training color-weighted accuracy\", best_train_m[\"cwa\"])\n    print_metric(\"training shape-weighted accuracy\", best_train_m[\"swa\"])\n    print_metric(\"training complexity-weighted accuracy\", best_train_m[\"cpx\"])\n    print_metric(\"validation color-weighted accuracy\", best_val_m[\"cwa\"])\n    print_metric(\"validation shape-weighted accuracy\", best_val_m[\"swa\"])\n    print_metric(\"validation complexity-weighted accuracy\", best_val_m[\"cpx\"])\n    print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 1. Locate and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy in {working_dir}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# 2. Extract and print the final metric values for every dataset\nfor dataset_name, data in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # Safeguard against missing keys or empty lists\n    train_metrics = data.get(\"metrics\", {}).get(\"train\", [])\n    val_metrics = data.get(\"metrics\", {}).get(\"val\", [])\n    train_losses = data.get(\"losses\", {}).get(\"train\", [])\n    val_losses = data.get(\"losses\", {}).get(\"val\", [])\n\n    if train_metrics:\n        last_train = train_metrics[-1]\n        print(\n            f\"final training color-weighted accuracy: {last_train.get('cwa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final training shape-weighted  accuracy: {last_train.get('swa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final training complexity-weighted accuracy: {last_train.get('cpx', 'N/A'):.4f}\"\n        )\n\n    if val_metrics:\n        last_val = val_metrics[-1]\n        best_cpx = max(m.get(\"cpx\", float(\"-inf\")) for m in val_metrics)\n        print(\n            f\"final validation color-weighted accuracy: {last_val.get('cwa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final validation shape-weighted  accuracy: {last_val.get('swa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final validation complexity-weighted accuracy: {last_val.get('cpx', 'N/A'):.4f}\"\n        )\n        print(f\"best validation complexity-weighted accuracy: {best_cpx:.4f}\")\n\n    if train_losses:\n        print(f\"final training loss: {train_losses[-1]:.6f}\")\n    if val_losses:\n        print(f\"final validation loss: {val_losses[-1]:.6f}\")\n", "", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ---------- helper ----------\ndef best(values, higher_is_better=True):\n    \"\"\"Return the best (max or min) element of a list; ignore None.\"\"\"\n    clean = [v for v in values if v is not None]\n    if not clean:\n        return None\n    return max(clean) if higher_is_better else min(clean)\n\n\n# ---------- iterate datasets ----------\nfor dset_name, d in experiment_data.items():\n    print(f\"{dset_name}\")\n\n    # losses\n    train_losses = d[\"losses\"].get(\"train\", [])\n    val_losses = d[\"losses\"].get(\"val\", [])\n    best_train_loss = best(train_losses, higher_is_better=False)\n    best_val_loss = best(val_losses, higher_is_better=False)\n\n    if best_train_loss is not None:\n        print(f\"training loss: {best_train_loss:.4f}\")\n    if best_val_loss is not None:\n        print(f\"validation loss: {best_val_loss:.4f}\")\n\n    # metric names (assumed same for train/val)\n    metric_names = []\n    if d[\"metrics\"][\"train\"]:\n        metric_names = list(d[\"metrics\"][\"train\"][0].keys())\n\n    for m in metric_names:\n        train_series = [epoch_dict[m] for epoch_dict in d[\"metrics\"][\"train\"]]\n        val_series = [epoch_dict[m] for epoch_dict in d[\"metrics\"][\"val\"]]\n\n        best_train = best(train_series, higher_is_better=True)\n        best_val = best(val_series, higher_is_better=True)\n\n        if best_train is not None:\n            print(f\"training {m.upper()}: {best_train:.4f}\")\n        if best_val is not None:\n            print(f\"validation {m.upper()}: {best_val:.4f}\")\n", "", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# automatically locate the saved NumPy dictionary\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\ndef print_final_metrics(exp_dict):\n    \"\"\"\n    exp_dict follows the structure:\n        {\n            \"metrics\": {\"train\": [dict_per_epoch], \"val\": [...]},\n            \"losses\":  {\"train\": [float],          \"val\": [...]},\n            ...\n        }\n    We print the *final* value recorded for each metric / loss.\n    \"\"\"\n    # Final epoch index\n    last_idx = -1\n\n    # ----- TRAINING METRICS -----\n    train_metrics = exp_dict[\"metrics\"][\"train\"][last_idx]\n    print(f\"training color weighted accuracy: {train_metrics['cwa']:.4f}\")\n    print(f\"training shape weighted accuracy: {train_metrics['swa']:.4f}\")\n    print(f\"training complexity weighted accuracy: {train_metrics['cpx']:.4f}\")\n\n    train_loss = exp_dict[\"losses\"][\"train\"][last_idx]\n    print(f\"training loss: {train_loss:.4f}\")\n\n    # ----- VALIDATION METRICS -----\n    val_metrics = exp_dict[\"metrics\"][\"val\"][last_idx]\n    print(f\"validation color weighted accuracy: {val_metrics['cwa']:.4f}\")\n    print(f\"validation shape weighted accuracy: {val_metrics['swa']:.4f}\")\n    print(f\"validation complexity weighted accuracy: {val_metrics['cpx']:.4f}\")\n\n    val_loss = (\n        exp_dict[\"losses\"][\"val\"][last_idx] if exp_dict[\"losses\"][\"val\"] else None\n    )\n    if val_loss is not None:\n        print(f\"validation loss: {val_loss:.4f}\")\n\n\n# ------------------------------------------------------------------\n# iterate through all datasets stored in the dictionary\nfor dataset_name, dataset_info in experiment_data.items():\n    print(dataset_name)  # Requirement: print dataset name first\n    print_final_metrics(dataset_info)\n", "", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load the experiment file\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\ndef best_val(metric_list, higher_is_better=True):\n    \"\"\"Return the best value from a list of scalars.\"\"\"\n    return max(metric_list) if higher_is_better else min(metric_list)\n\n\n# ------------------------------------------------------------------\nfor dataset_name, data in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # --- losses ---\n    train_loss_final = data[\"losses\"][\"train\"][-1]\n    val_loss_best = best_val(data[\"losses\"][\"val\"], higher_is_better=False)\n\n    # --- weighted accuracies ---\n    train_cwa_final = data[\"metrics\"][\"train\"][-1][\"cwa\"]\n    train_swa_final = data[\"metrics\"][\"train\"][-1][\"swa\"]\n    train_cpx_final = data[\"metrics\"][\"train\"][-1][\"cpx\"]\n\n    val_cwa_best = best_val([m[\"cwa\"] for m in data[\"metrics\"][\"val\"]])\n    val_swa_best = best_val([m[\"swa\"] for m in data[\"metrics\"][\"val\"]])\n    val_cpx_best = best_val([m[\"cpx\"] for m in data[\"metrics\"][\"val\"]])\n\n    # --- plain validation accuracy from stored predictions (if present) ---\n    val_acc = None\n    if data.get(\"predictions\") and data.get(\"ground_truth\"):\n        preds = np.array(data[\"predictions\"])\n        gts = np.array(data[\"ground_truth\"])\n        if len(preds) == len(gts) and len(preds) > 0:\n            val_acc = (preds == gts).mean()\n\n    # --------------------- printing ---------------------\n    print(f\"train loss (final epoch): {train_loss_final:.4f}\")\n    print(f\"validation loss (best):  {val_loss_best:.4f}\")\n\n    print(f\"train color-weighted accuracy (final epoch):        {train_cwa_final:.4f}\")\n    print(f\"train shape-weighted accuracy (final epoch):        {train_swa_final:.4f}\")\n    print(f\"train complexity-weighted accuracy (final epoch):   {train_cpx_final:.4f}\")\n\n    print(f\"validation color-weighted accuracy (best):          {val_cwa_best:.4f}\")\n    print(f\"validation shape-weighted accuracy (best):          {val_swa_best:.4f}\")\n    print(f\"validation complexity-weighted accuracy (best):     {val_cpx_best:.4f}\")\n\n    if val_acc is not None:\n        print(f\"validation accuracy (best):                        {val_acc:.4f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 0. Locate working directory and load the numpy file\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\ndef best_epoch_index(val_metrics_list):\n    \"\"\"\n    Return the index of the epoch with the highest validation\n    Complexity-Weighted Accuracy (key 'cpx').\n    \"\"\"\n    best_idx = 0\n    best_cpx = -float(\"inf\")\n    for idx, m in enumerate(val_metrics_list):\n        if m[\"cpx\"] > best_cpx:\n            best_cpx = m[\"cpx\"]\n            best_idx = idx\n    return best_idx\n\n\nfloat_fmt = \"{:.4f}\".format\n\n# ------------------------------------------------------------------\nfor dataset_name, data in experiment_data.items():\n    # Determine best epoch based on validation CompWA\n    idx = best_epoch_index(data[\"metrics\"][\"val\"])\n\n    # Gather losses\n    train_loss = data[\"losses\"][\"train\"][idx]\n    val_loss = data[\"losses\"][\"val\"][idx]\n\n    # Gather metric dictionaries\n    train_metrics = data[\"metrics\"][\"train\"][idx]\n    val_metrics = data[\"metrics\"][\"val\"][idx]\n\n    # ------------------------------------------------------------------\n    # 3 & 4. Print results with explicit metric names\n    print(f\"{dataset_name}\")\n    print(f\"  train loss: {float_fmt(train_loss)}\")\n    print(f\"  validation loss: {float_fmt(val_loss)}\")\n\n    print(f\"  train Color-Weighted Accuracy: {float_fmt(train_metrics['cwa'])}\")\n    print(f\"  validation Color-Weighted Accuracy: {float_fmt(val_metrics['cwa'])}\")\n\n    print(f\"  train Shape-Weighted Accuracy: {float_fmt(train_metrics['swa'])}\")\n    print(f\"  validation Shape-Weighted Accuracy: {float_fmt(val_metrics['swa'])}\")\n\n    print(f\"  train Complexity-Weighted Accuracy: {float_fmt(train_metrics['cpx'])}\")\n    print(f\"  validation Complexity-Weighted Accuracy: {float_fmt(val_metrics['cpx'])}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 1. Locate and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy in {working_dir}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# 2. Extract and print the final metric values for every dataset\nfor dataset_name, data in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # Safeguard against missing keys or empty lists\n    train_metrics = data.get(\"metrics\", {}).get(\"train\", [])\n    val_metrics = data.get(\"metrics\", {}).get(\"val\", [])\n    train_losses = data.get(\"losses\", {}).get(\"train\", [])\n    val_losses = data.get(\"losses\", {}).get(\"val\", [])\n\n    if train_metrics:\n        last_train = train_metrics[-1]\n        print(\n            f\"final training color-weighted accuracy: {last_train.get('cwa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final training shape-weighted  accuracy: {last_train.get('swa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final training complexity-weighted accuracy: {last_train.get('cpx', 'N/A'):.4f}\"\n        )\n\n    if val_metrics:\n        last_val = val_metrics[-1]\n        best_cpx = max(m.get(\"cpx\", float(\"-inf\")) for m in val_metrics)\n        print(\n            f\"final validation color-weighted accuracy: {last_val.get('cwa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final validation shape-weighted  accuracy: {last_val.get('swa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final validation complexity-weighted accuracy: {last_val.get('cpx', 'N/A'):.4f}\"\n        )\n        print(f\"best validation complexity-weighted accuracy: {best_cpx:.4f}\")\n\n    if train_losses:\n        print(f\"final training loss: {train_losses[-1]:.6f}\")\n    if val_losses:\n        print(f\"final validation loss: {val_losses[-1]:.6f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 1. Locate and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy in {working_dir}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# 2. Extract and print the final metric values for every dataset\nfor dataset_name, data in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # Safeguard against missing keys or empty lists\n    train_metrics = data.get(\"metrics\", {}).get(\"train\", [])\n    val_metrics = data.get(\"metrics\", {}).get(\"val\", [])\n    train_losses = data.get(\"losses\", {}).get(\"train\", [])\n    val_losses = data.get(\"losses\", {}).get(\"val\", [])\n\n    if train_metrics:\n        last_train = train_metrics[-1]\n        print(\n            f\"final training color-weighted accuracy: {last_train.get('cwa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final training shape-weighted  accuracy: {last_train.get('swa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final training complexity-weighted accuracy: {last_train.get('cpx', 'N/A'):.4f}\"\n        )\n\n    if val_metrics:\n        last_val = val_metrics[-1]\n        best_cpx = max(m.get(\"cpx\", float(\"-inf\")) for m in val_metrics)\n        print(\n            f\"final validation color-weighted accuracy: {last_val.get('cwa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final validation shape-weighted  accuracy: {last_val.get('swa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final validation complexity-weighted accuracy: {last_val.get('cpx', 'N/A'):.4f}\"\n        )\n        print(f\"best validation complexity-weighted accuracy: {best_cpx:.4f}\")\n\n    if train_losses:\n        print(f\"final training loss: {train_losses[-1]:.6f}\")\n    if val_losses:\n        print(f\"final validation loss: {val_losses[-1]:.6f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 1. Locate and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy in {working_dir}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# 2. Extract and print the final metric values for every dataset\nfor dataset_name, data in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # Safeguard against missing keys or empty lists\n    train_metrics = data.get(\"metrics\", {}).get(\"train\", [])\n    val_metrics = data.get(\"metrics\", {}).get(\"val\", [])\n    train_losses = data.get(\"losses\", {}).get(\"train\", [])\n    val_losses = data.get(\"losses\", {}).get(\"val\", [])\n\n    if train_metrics:\n        last_train = train_metrics[-1]\n        print(\n            f\"final training color-weighted accuracy: {last_train.get('cwa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final training shape-weighted  accuracy: {last_train.get('swa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final training complexity-weighted accuracy: {last_train.get('cpx', 'N/A'):.4f}\"\n        )\n\n    if val_metrics:\n        last_val = val_metrics[-1]\n        best_cpx = max(m.get(\"cpx\", float(\"-inf\")) for m in val_metrics)\n        print(\n            f\"final validation color-weighted accuracy: {last_val.get('cwa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final validation shape-weighted  accuracy: {last_val.get('swa', 'N/A'):.4f}\"\n        )\n        print(\n            f\"final validation complexity-weighted accuracy: {last_val.get('cpx', 'N/A'):.4f}\"\n        )\n        print(f\"best validation complexity-weighted accuracy: {best_cpx:.4f}\")\n\n    if train_losses:\n        print(f\"final training loss: {train_losses[-1]:.6f}\")\n    if val_losses:\n        print(f\"final validation loss: {val_losses[-1]:.6f}\")\n", ""], "parse_term_out": ["['SPR_BENCH', '\\n', 'best epoch: 11', '\\n', 'training loss: 0.1661', '\\n',\n'training color-weighted accuracy: 0.9485', '\\n', 'training shape-weighted\naccuracy: 0.9482', '\\n', 'training complexity-weighted accuracy: 0.9481', '\\n',\n'validation color-weighted accuracy: 0.9477', '\\n', 'validation shape-weighted\naccuracy: 0.9447', '\\n', 'validation complexity-weighted accuracy: 0.9432',\n'\\n', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'final training color-weighted accuracy: 1.0000',\n'\\n', 'final training shape-weighted  accuracy: 1.0000', '\\n', 'final training\ncomplexity-weighted accuracy: 1.0000', '\\n', 'final validation color-weighted\naccuracy: 0.9998', '\\n', 'final validation shape-weighted  accuracy: 0.9998',\n'\\n', 'final validation complexity-weighted accuracy: 0.9997', '\\n', 'best\nvalidation complexity-weighted accuracy: 0.9997', '\\n', 'final training loss:\n0.000051', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "", "['SPR_BENCH', '\\n', 'training loss: 0.2381', '\\n', 'training CWA: 0.9152', '\\n',\n'validation CWA: 0.9145', '\\n', 'training SWA: 0.9080', '\\n', 'validation SWA:\n0.9064', '\\n', 'training CPX: 0.9083', '\\n', 'validation CPX: 0.9071', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "", "['SPR_BENCH', '\\n', 'training color weighted accuracy: 0.9841', '\\n', 'training\nshape weighted accuracy: 0.9840', '\\n', 'training complexity weighted accuracy:\n0.9840', '\\n', 'training loss: 0.0228', '\\n', 'validation color weighted\naccuracy: 0.9828', '\\n', 'validation shape weighted accuracy: 0.9824', '\\n',\n'validation complexity weighted accuracy: 0.9824', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "", "['\\nDataset: SPR_BENCH', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 23, in <module>\\n    val_loss_best =\nbest_val(data[\"losses\"][\"val\"], higher_is_better=False)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\",\nline 14, in best_val\\n    return max(metric_list) if higher_is_better else\nmin(metric_list)\\n\n^^^^^^^^^^^^^^^^\\nTypeError: \\'<\\' not supported between instances of\n\\'NoneType\\' and \\'NoneType\\'\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['SPR_BENCH', '\\n', '  train loss: 0.0383', '\\n', '  validation loss: 0.0309',\n'\\n', '  train Color-Weighted Accuracy: 0.9950', '\\n', '  validation Color-\nWeighted Accuracy: 0.9946', '\\n', '  train Shape-Weighted Accuracy: 0.9948',\n'\\n', '  validation Shape-Weighted Accuracy: 0.9938', '\\n', '  train Complexity-\nWeighted Accuracy: 0.9950', '\\n', '  validation Complexity-Weighted Accuracy:\n0.9940', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'final training color-weighted accuracy: 1.0000',\n'\\n', 'final training shape-weighted  accuracy: 1.0000', '\\n', 'final training\ncomplexity-weighted accuracy: 1.0000', '\\n', 'final validation color-weighted\naccuracy: 0.9998', '\\n', 'final validation shape-weighted  accuracy: 0.9998',\n'\\n', 'final validation complexity-weighted accuracy: 0.9998', '\\n', 'best\nvalidation complexity-weighted accuracy: 0.9998', '\\n', 'final training loss:\n0.000031', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'final training color-weighted accuracy: 1.0000',\n'\\n', 'final training shape-weighted  accuracy: 1.0000', '\\n', 'final training\ncomplexity-weighted accuracy: 1.0000', '\\n', 'final validation color-weighted\naccuracy: 0.9995', '\\n', 'final validation shape-weighted  accuracy: 0.9993',\n'\\n', 'final validation complexity-weighted accuracy: 0.9994', '\\n', 'best\nvalidation complexity-weighted accuracy: 0.9994', '\\n', 'final training loss:\n0.000032', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'final training color-weighted accuracy: 1.0000',\n'\\n', 'final training shape-weighted  accuracy: 1.0000', '\\n', 'final training\ncomplexity-weighted accuracy: 1.0000', '\\n', 'final validation color-weighted\naccuracy: 0.9995', '\\n', 'final validation shape-weighted  accuracy: 0.9995',\n'\\n', 'final validation complexity-weighted accuracy: 0.9994', '\\n', 'best\nvalidation complexity-weighted accuracy: 0.9997', '\\n', 'final training loss:\n0.000030', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, "TypeError", null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, {"args": ["'<' not supported between instances of 'NoneType' and 'NoneType'"]}, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 23, "<module>", "val_loss_best = best_val(data[\"losses\"][\"val\"], higher_is_better=False)"], ["runfile.py", 14, "best_val", "return max(metric_list) if higher_is_better else min(metric_list)"]], null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
