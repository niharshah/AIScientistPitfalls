{
  "best node": {
    "overall_plan": "Hyperparam tuning name: EPOCHS (Number of training epochs).\nWe extend training to up to 30 epochs and add a simple early-stopping mechanism (patience = 5) that monitors validation complexity-weighted accuracy; training halts when the metric stops improving. All metrics/losses are recorded in the prescribed experiment_data structure and saved to disk, together with a learning-curve plot.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "The loss value during training.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.1661,
                "best_value": 0.1661
              }
            ]
          },
          {
            "metric_name": "training color-weighted accuracy",
            "lower_is_better": false,
            "description": "The color-weighted accuracy during training.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.9485,
                "best_value": 0.9485
              }
            ]
          },
          {
            "metric_name": "training shape-weighted accuracy",
            "lower_is_better": false,
            "description": "The shape-weighted accuracy during training.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.9482,
                "best_value": 0.9482
              }
            ]
          },
          {
            "metric_name": "training complexity-weighted accuracy",
            "lower_is_better": false,
            "description": "The complexity-weighted accuracy during training.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.9481,
                "best_value": 0.9481
              }
            ]
          },
          {
            "metric_name": "validation color-weighted accuracy",
            "lower_is_better": false,
            "description": "The color-weighted accuracy during validation.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.9477,
                "best_value": 0.9477
              }
            ]
          },
          {
            "metric_name": "validation shape-weighted accuracy",
            "lower_is_better": false,
            "description": "The shape-weighted accuracy during validation.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.9447,
                "best_value": 0.9447
              }
            ]
          },
          {
            "metric_name": "validation complexity-weighted accuracy",
            "lower_is_better": false,
            "description": "The complexity-weighted accuracy during validation.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.9432,
                "best_value": 0.9432
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os, pathlib, random, time, copy\nfrom typing import List, Dict\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------------------------------------------------------------\n# working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# ---------- Dataset loading helpers (adapted from SPR.py) ------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) * count_color_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------------------------------------------------------------------\n# -------------------- Synthetic fallback -----------------------------\ndef make_synthetic_split(\n    n: int, vocab_shapes=5, vocab_colors=4, max_len=8, num_labels=3\n):\n    rng = random.Random(42 + n)\n    data = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = []\n        for _ in range(L):\n            s = chr(ord(\"A\") + rng.randint(0, vocab_shapes - 1))\n            c = str(rng.randint(0, vocab_colors - 1))\n            seq.append(s + c)\n        data[\"id\"].append(str(i))\n        data[\"sequence\"].append(\" \".join(seq))\n        data[\"label\"].append(rng.randint(0, num_labels - 1))\n    return data\n\n\ndef load_data():\n    spr_root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    try:\n        if not spr_root.exists():\n            raise FileNotFoundError\n        dset = load_spr_bench(spr_root)\n    except Exception:\n        print(\"SPR_BENCH not found \u2013 using synthetic data.\")\n        train = make_synthetic_split(3000)\n        dev = make_synthetic_split(600)\n        test = make_synthetic_split(600)\n        dset = DatasetDict(\n            {\n                \"train\": load_dataset(\n                    \"json\", data_files={\"train\": train}, split=\"train\"\n                ),\n                \"dev\": load_dataset(\"json\", data_files={\"train\": dev}, split=\"train\"),\n                \"test\": load_dataset(\"json\", data_files={\"train\": test}, split=\"train\"),\n            }\n        )\n    return dset\n\n\ndset = load_data()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Classes: {num_classes}, Train size: {len(dset['train'])}\")\n\n\n# ---------------------------------------------------------------------\n# --------------------- Tokenisation & Vocab --------------------------\ndef build_vocab(sequences: List[str]) -> Dict[str, int]:\n    vocab = {}\n    for seq in sequences:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab) + 1  # reserve 0 for padding\n    return vocab\n\n\nvocab = build_vocab(dset[\"train\"][\"sequence\"])\nvocab_size = len(vocab) + 1\nprint(f\"Vocab size: {vocab_size}\")\n\n\ndef encode_sequence(sequence: str) -> List[int]:\n    return [vocab.get(tok, 0) for tok in sequence.split()]\n\n\n# ---------------------------------------------------------------------\n# -------------------- Torch Dataset wrapper --------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.hf_split = hf_split\n        self.ids = hf_split[\"id\"]\n        self.seqs = [encode_sequence(s) for s in hf_split[\"sequence\"]]\n        self.labels = hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"seq\": torch.tensor(self.seqs[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate_fn(batch):\n    lengths = [len(b[\"seq\"]) for b in batch]\n    max_len = max(lengths)\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    for i, b in enumerate(batch):\n        padded[i, : lengths[i]] = b[\"seq\"]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    return {\"seq\": padded, \"lengths\": torch.tensor(lengths), \"label\": labels}\n\n\ntrain_ds = SPRTorchDataset(dset[\"train\"])\ndev_ds = SPRTorchDataset(dset[\"dev\"])\n\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate_fn)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate_fn)\n\n\n# ---------------------------------------------------------------------\n# -------------------------- Model ------------------------------------\nclass AvgEmbClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.fc = nn.Sequential(\n            nn.Linear(emb_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        mask = (x != 0).float().unsqueeze(-1)\n        summed = (self.embed(x) * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1e-6)\n        avg = summed / lengths\n        return self.fc(avg)\n\n\nmodel = AvgEmbClassifier(vocab_size, 32, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------------------------------------------------------------------\n# -------------- Experiment data tracking structure -------------------\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---------------------------------------------------------------------\n# ------------------------- Training loop with tuning -----------------\nMAX_EPOCHS = 30\npatience = 5\nbest_val_cpx = -1.0\nno_improve = 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    t_start = time.time()\n    model.train()\n    total_loss = 0.0\n    n = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"seq\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch[\"label\"].size(0)\n        n += batch[\"label\"].size(0)\n    train_loss = total_loss / n\n\n    # ----- Evaluation helper\n    def evaluate(loader):\n        model.eval()\n        preds, labels = [], []\n        with torch.no_grad():\n            for batch in loader:\n                batch = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"seq\"])\n                preds.extend(logits.argmax(1).cpu().tolist())\n                labels.extend(batch[\"label\"].cpu().tolist())\n        return preds, labels\n\n    train_preds, train_labels = evaluate(train_loader)\n    val_preds, val_labels = evaluate(dev_loader)\n\n    train_raw = dset[\"train\"][\"sequence\"]\n    val_raw = dset[\"dev\"][\"sequence\"]\n\n    train_cwa = color_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cwa = color_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_swa = shape_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_swa = shape_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_cpx = complexity_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cpx = complexity_weighted_accuracy(val_raw, val_labels, val_preds)\n\n    # Logging\n    exp_ref = experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"]\n    exp_ref[\"metrics\"][\"train\"].append(\n        {\"cwa\": train_cwa, \"swa\": train_swa, \"cpx\": train_cpx}\n    )\n    exp_ref[\"metrics\"][\"val\"].append({\"cwa\": val_cwa, \"swa\": val_swa, \"cpx\": val_cpx})\n    exp_ref[\"losses\"][\"train\"].append(train_loss)\n    exp_ref[\"losses\"][\"val\"].append(None)\n    exp_ref[\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch:02d} | TrainLoss {train_loss:.4f} | Val CpxWA {val_cpx:.4f} | Time {(time.time()-t_start):.1f}s\"\n    )\n\n    # Early stopping logic\n    if val_cpx > best_val_cpx + 1e-6:\n        best_val_cpx = val_cpx\n        no_improve = 0\n        exp_ref[\"predictions\"] = val_preds\n        exp_ref[\"ground_truth\"] = val_labels\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(\n                f\"No improvement for {patience} epochs \u2013 early stopping at epoch {epoch}.\"\n            )\n            break\n\n# ---------------------------------------------------------------------\n# -------------------- Save metrics & plot ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\ncpx_vals = [\n    m[\"cpx\"] for m in experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"metrics\"][\"val\"]\n]\nplt.figure()\nplt.plot(experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"epochs\"], cpx_vals, marker=\"o\")\nplt.title(\"Validation Complexity-Weighted Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CpxWA\")\nplt.savefig(os.path.join(working_dir, \"cpxwa_curve.png\"))\nprint(\"Finished. Results saved in working/.\")\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\nexp = experiment_data.get(\"epochs_tuning\", {}).get(\"SPR_BENCH\", None)\nif exp is None:\n    print(\"SPR_BENCH results not found in experiment_data.\")\n    raise SystemExit\n\nepochs = np.array(exp[\"epochs\"])\ntrain_losses = np.array(exp[\"losses\"][\"train\"])\nval_metrics = exp[\"metrics\"][\"val\"]\ntrain_metrics = exp[\"metrics\"][\"train\"]\n\nval_cwa = np.array([m[\"cwa\"] for m in val_metrics])\nval_swa = np.array([m[\"swa\"] for m in val_metrics])\nval_cpx = np.array([m[\"cpx\"] for m in val_metrics])\ntrain_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n\nbest_epoch = int(epochs[np.argmax(val_cpx)])\nbest_val_cpx = float(val_cpx.max())\n\nprint(f\"Best Validation CpxWA: {best_val_cpx:.4f} @ epoch {best_epoch}\")\n\n# ---------------------------------------------------------------------\n# 1) Training loss curve\ntry:\n    plt.figure()\n    plt.plot(epochs, train_losses, marker=\"o\", label=\"Train Loss\")\n    plt.title(\"SPR_BENCH: Training Loss per Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_train_loss_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating train loss plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 2) Training vs. Validation Complexity-Weighted Accuracy\ntry:\n    plt.figure()\n    plt.plot(epochs, train_cpx, marker=\"o\", label=\"Train CpxWA\")\n    plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n    plt.title(\"SPR_BENCH: Complexity-Weighted Accuracy\\nLeft: Train, Right: Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CpxWA\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_cpxwa_train_val_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CpxWA curve: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 3) Validation weighted-accuracy comparison\ntry:\n    plt.figure()\n    plt.plot(epochs, val_cwa, marker=\"o\", label=\"Val CWA\")\n    plt.plot(epochs, val_swa, marker=\"^\", label=\"Val SWA\")\n    plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n    plt.title(\"SPR_BENCH: Weighted Accuracy Comparison (Validation)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Weighted Accuracy\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_val_weighted_accuracy_comparison.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating weighted accuracy comparison plot: {e}\")\n    plt.close()\n",
    "plot_plan": "We will load experiment_data.npy from the working directory, extract the epoch list, train losses, and weighted\u2013accuracy metrics for the \u201cSPR_BENCH\u201d split, and then create up to three concise plots: (1) train-loss curve, (2) training vs. validation complexity-weighted accuracy, and (3) a side-by-side comparison of the three validation weighted accuracies (CWA, SWA, CPX).  Each plot is wrapped in its own try-except block, given a clear title/sub-title, saved with a descriptive name that includes the dataset and plot type, and the figure is always closed.  We also compute and print the best validation complexity-weighted accuracy and the epoch at which it occurs so the user immediately sees the key result.  All plots are saved in the predefined working directory, and no synthetic or fabricated data are introduced\u2014everything comes directly from the stored experiment_data structure.  The code relies only on NumPy and Matplotlib, follows the developer plotting guidelines, and respects the five-figure limit by generating just three essential visuals.  It can be run as-is after the training script finishes because it assumes experiment_data.npy already exists.  The implementation is concise, readable, and robust to missing keys or absent files, exiting gracefully with informative messages when necessary.  Finally, the script prints the best metric values to standard output so users can verify performance without opening the plots.",
    "plot_analyses": [
      {
        "analysis": "The plot shows the validation complexity-weighted accuracy (CpxWA) improving significantly during the initial epochs and stabilizing around 0.94 after epoch 6. This indicates that the model quickly learns meaningful patterns in the data but does not show further improvement with additional epochs. This suggests the model may have reached its generalization capacity for this configuration.",
        "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/cpxwa_curve.png"
      },
      {
        "analysis": "The training loss decreases rapidly in the first few epochs and stabilizes at a low value after epoch 6, indicating that the model converges well. The consistent decrease without oscillations suggests stable training dynamics, and the final low loss value aligns with the high validation accuracy observed in other plots.",
        "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_train_loss_curve.png"
      },
      {
        "analysis": "The training and validation complexity-weighted accuracies (CpxWA) both improve rapidly in the initial epochs, with training accuracy slightly outperforming validation accuracy. The gap between the two curves remains small, suggesting minimal overfitting. Both curves stabilize after epoch 6, indicating that the model achieves consistent performance across training and validation sets.",
        "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_cpxwa_train_val_curve.png"
      },
      {
        "analysis": "The weighted accuracy metrics (CWA, SWA, and CpxWA) for validation show similar trends, with rapid improvement in the first few epochs followed by stabilization. CWA consistently outperforms SWA and CpxWA, suggesting that the model is better at leveraging color features for accurate predictions. The close alignment of the three metrics indicates that the model is performing well across different evaluation criteria and is not biased toward any specific metric.",
        "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_val_weighted_accuracy_comparison.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/cpxwa_curve.png",
      "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_train_loss_curve.png",
      "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_cpxwa_train_val_curve.png",
      "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/SPR_BENCH_val_weighted_accuracy_comparison.png"
    ],
    "vlm_feedback_summary": "The results demonstrate that the model achieves rapid and stable convergence for both training and validation metrics, with minimal overfitting. The different weighted accuracy metrics show consistent trends, and the model appears to leverage color features more effectively for predictions. These insights suggest that the current hyperparameter tuning is effective and the model is well-optimized for the task.",
    "exp_results_dir": "experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837",
    "exp_results_npy_files": [
      "experiment_results/experiment_58776df0d3084187852c5ee56edd0b03_proc_1730837/experiment_data.npy"
    ]
  },
  "best node with different seeds": [
    {
      "overall_plan": "The previous overall plan focused on hyperparameter tuning, specifically extending training up to 30 epochs with the implementation of an early-stopping mechanism (patience = 5) to monitor validation complexity-weighted accuracy. The goal was to enhance model performance while preventing overfitting. This approach included detailed tracking of metrics and losses, saving them to disk, and visualizing them through a learning-curve plot to facilitate analysis. The current plan, being a seed node, establishes the foundational experiment setup, serving as a baseline for future iterations and modifications without introducing new ideas or changes. This comprehensive plan sets the stage for efficient and well-documented exploration of model training improvements.",
      "analysis": "",
      "metric": {
        "value": {
          "metric_names": [
            {
              "metric_name": "training loss",
              "lower_is_better": true,
              "description": "Measures the error during training.",
              "data": [
                {
                  "dataset_name": "SPR_BENCH",
                  "final_value": 0.1698,
                  "best_value": 0.1698
                }
              ]
            },
            {
              "metric_name": "color-weighted accuracy",
              "lower_is_better": false,
              "description": "Accuracy weighted by color information.",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 0.9489,
                  "best_value": 0.9489
                },
                {
                  "dataset_name": "validation",
                  "final_value": 0.9477,
                  "best_value": 0.9477
                }
              ]
            },
            {
              "metric_name": "shape-weighted accuracy",
              "lower_is_better": false,
              "description": "Accuracy weighted by shape information.",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 0.9486,
                  "best_value": 0.9486
                },
                {
                  "dataset_name": "validation",
                  "final_value": 0.9447,
                  "best_value": 0.9447
                }
              ]
            },
            {
              "metric_name": "complexity-weighted accuracy",
              "lower_is_better": false,
              "description": "Accuracy weighted by complexity information.",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 0.9489,
                  "best_value": 0.9489
                },
                {
                  "dataset_name": "validation",
                  "final_value": 0.9432,
                  "best_value": 0.9432
                }
              ]
            }
          ]
        },
        "maximize": null,
        "name": null,
        "description": null
      },
      "code": "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, copy\nfrom typing import List, Dict\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------------------------------------------------------------\n# working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# ---------- Dataset loading helpers (adapted from SPR.py) ------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) * count_color_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------------------------------------------------------------------\n# -------------------- Synthetic fallback -----------------------------\ndef make_synthetic_split(\n    n: int, vocab_shapes=5, vocab_colors=4, max_len=8, num_labels=3\n):\n    rng = random.Random(42 + n)\n    data = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = []\n        for _ in range(L):\n            s = chr(ord(\"A\") + rng.randint(0, vocab_shapes - 1))\n            c = str(rng.randint(0, vocab_colors - 1))\n            seq.append(s + c)\n        data[\"id\"].append(str(i))\n        data[\"sequence\"].append(\" \".join(seq))\n        data[\"label\"].append(rng.randint(0, num_labels - 1))\n    return data\n\n\ndef load_data():\n    spr_root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    try:\n        if not spr_root.exists():\n            raise FileNotFoundError\n        dset = load_spr_bench(spr_root)\n    except Exception:\n        print(\"SPR_BENCH not found \u2013 using synthetic data.\")\n        train = make_synthetic_split(3000)\n        dev = make_synthetic_split(600)\n        test = make_synthetic_split(600)\n        dset = DatasetDict(\n            {\n                \"train\": load_dataset(\n                    \"json\", data_files={\"train\": train}, split=\"train\"\n                ),\n                \"dev\": load_dataset(\"json\", data_files={\"train\": dev}, split=\"train\"),\n                \"test\": load_dataset(\"json\", data_files={\"train\": test}, split=\"train\"),\n            }\n        )\n    return dset\n\n\ndset = load_data()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Classes: {num_classes}, Train size: {len(dset['train'])}\")\n\n\n# ---------------------------------------------------------------------\n# --------------------- Tokenisation & Vocab --------------------------\ndef build_vocab(sequences: List[str]) -> Dict[str, int]:\n    vocab = {}\n    for seq in sequences:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab) + 1  # reserve 0 for padding\n    return vocab\n\n\nvocab = build_vocab(dset[\"train\"][\"sequence\"])\nvocab_size = len(vocab) + 1\nprint(f\"Vocab size: {vocab_size}\")\n\n\ndef encode_sequence(sequence: str) -> List[int]:\n    return [vocab.get(tok, 0) for tok in sequence.split()]\n\n\n# ---------------------------------------------------------------------\n# -------------------- Torch Dataset wrapper --------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.hf_split = hf_split\n        self.ids = hf_split[\"id\"]\n        self.seqs = [encode_sequence(s) for s in hf_split[\"sequence\"]]\n        self.labels = hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"seq\": torch.tensor(self.seqs[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate_fn(batch):\n    lengths = [len(b[\"seq\"]) for b in batch]\n    max_len = max(lengths)\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    for i, b in enumerate(batch):\n        padded[i, : lengths[i]] = b[\"seq\"]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    return {\"seq\": padded, \"lengths\": torch.tensor(lengths), \"label\": labels}\n\n\ntrain_ds = SPRTorchDataset(dset[\"train\"])\ndev_ds = SPRTorchDataset(dset[\"dev\"])\n\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate_fn)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate_fn)\n\n\n# ---------------------------------------------------------------------\n# -------------------------- Model ------------------------------------\nclass AvgEmbClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.fc = nn.Sequential(\n            nn.Linear(emb_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        mask = (x != 0).float().unsqueeze(-1)\n        summed = (self.embed(x) * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1e-6)\n        avg = summed / lengths\n        return self.fc(avg)\n\n\nmodel = AvgEmbClassifier(vocab_size, 32, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------------------------------------------------------------------\n# -------------- Experiment data tracking structure -------------------\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---------------------------------------------------------------------\n# ------------------------- Training loop with tuning -----------------\nMAX_EPOCHS = 30\npatience = 5\nbest_val_cpx = -1.0\nno_improve = 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    t_start = time.time()\n    model.train()\n    total_loss = 0.0\n    n = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"seq\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch[\"label\"].size(0)\n        n += batch[\"label\"].size(0)\n    train_loss = total_loss / n\n\n    # ----- Evaluation helper\n    def evaluate(loader):\n        model.eval()\n        preds, labels = [], []\n        with torch.no_grad():\n            for batch in loader:\n                batch = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"seq\"])\n                preds.extend(logits.argmax(1).cpu().tolist())\n                labels.extend(batch[\"label\"].cpu().tolist())\n        return preds, labels\n\n    train_preds, train_labels = evaluate(train_loader)\n    val_preds, val_labels = evaluate(dev_loader)\n\n    train_raw = dset[\"train\"][\"sequence\"]\n    val_raw = dset[\"dev\"][\"sequence\"]\n\n    train_cwa = color_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cwa = color_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_swa = shape_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_swa = shape_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_cpx = complexity_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cpx = complexity_weighted_accuracy(val_raw, val_labels, val_preds)\n\n    # Logging\n    exp_ref = experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"]\n    exp_ref[\"metrics\"][\"train\"].append(\n        {\"cwa\": train_cwa, \"swa\": train_swa, \"cpx\": train_cpx}\n    )\n    exp_ref[\"metrics\"][\"val\"].append({\"cwa\": val_cwa, \"swa\": val_swa, \"cpx\": val_cpx})\n    exp_ref[\"losses\"][\"train\"].append(train_loss)\n    exp_ref[\"losses\"][\"val\"].append(None)\n    exp_ref[\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch:02d} | TrainLoss {train_loss:.4f} | Val CpxWA {val_cpx:.4f} | Time {(time.time()-t_start):.1f}s\"\n    )\n\n    # Early stopping logic\n    if val_cpx > best_val_cpx + 1e-6:\n        best_val_cpx = val_cpx\n        no_improve = 0\n        exp_ref[\"predictions\"] = val_preds\n        exp_ref[\"ground_truth\"] = val_labels\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(\n                f\"No improvement for {patience} epochs \u2013 early stopping at epoch {epoch}.\"\n            )\n            break\n\n# ---------------------------------------------------------------------\n# -------------------- Save metrics & plot ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\ncpx_vals = [\n    m[\"cpx\"] for m in experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"metrics\"][\"val\"]\n]\nplt.figure()\nplt.plot(experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"epochs\"], cpx_vals, marker=\"o\")\nplt.title(\"Validation Complexity-Weighted Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CpxWA\")\nplt.savefig(os.path.join(working_dir, \"cpxwa_curve.png\"))\nprint(\"Finished. Results saved in working/.\")\n",
      "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\nexp = experiment_data.get(\"epochs_tuning\", {}).get(\"SPR_BENCH\", None)\nif exp is None:\n    print(\"SPR_BENCH results not found in experiment_data.\")\n    raise SystemExit\n\nepochs = np.array(exp[\"epochs\"])\ntrain_losses = np.array(exp[\"losses\"][\"train\"])\nval_metrics = exp[\"metrics\"][\"val\"]\ntrain_metrics = exp[\"metrics\"][\"train\"]\n\nval_cwa = np.array([m[\"cwa\"] for m in val_metrics])\nval_swa = np.array([m[\"swa\"] for m in val_metrics])\nval_cpx = np.array([m[\"cpx\"] for m in val_metrics])\ntrain_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n\nbest_epoch = int(epochs[np.argmax(val_cpx)])\nbest_val_cpx = float(val_cpx.max())\n\nprint(f\"Best Validation CpxWA: {best_val_cpx:.4f} @ epoch {best_epoch}\")\n\n# ---------------------------------------------------------------------\n# 1) Training loss curve\ntry:\n    plt.figure()\n    plt.plot(epochs, train_losses, marker=\"o\", label=\"Train Loss\")\n    plt.title(\"SPR_BENCH: Training Loss per Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_train_loss_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating train loss plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 2) Training vs. Validation Complexity-Weighted Accuracy\ntry:\n    plt.figure()\n    plt.plot(epochs, train_cpx, marker=\"o\", label=\"Train CpxWA\")\n    plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n    plt.title(\"SPR_BENCH: Complexity-Weighted Accuracy\\nLeft: Train, Right: Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CpxWA\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_cpxwa_train_val_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CpxWA curve: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 3) Validation weighted-accuracy comparison\ntry:\n    plt.figure()\n    plt.plot(epochs, val_cwa, marker=\"o\", label=\"Val CWA\")\n    plt.plot(epochs, val_swa, marker=\"^\", label=\"Val SWA\")\n    plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n    plt.title(\"SPR_BENCH: Weighted Accuracy Comparison (Validation)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Weighted Accuracy\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_val_weighted_accuracy_comparison.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating weighted accuracy comparison plot: {e}\")\n    plt.close()\n",
      "plot_analyses": [
        {
          "analysis": "The plot shows the validation complexity-weighted accuracy (CpxWA) over epochs. The accuracy improves significantly in the first few epochs and plateaus around epoch 4, achieving a high and stable performance level of approximately 0.94. This indicates that the model converges quickly and maintains consistent performance during training.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_164c9f42a8ae4e2f8f602fece4d44d02_proc_1730837/cpxwa_curve.png"
        },
        {
          "analysis": "The training loss decreases rapidly in the initial epochs and then gradually stabilizes around epoch 6, reaching a minimum value near 0.15. This suggests effective learning and convergence. The smooth decline without sudden spikes implies stable training without overfitting or divergence.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_164c9f42a8ae4e2f8f602fece4d44d02_proc_1730837/SPR_BENCH_train_loss_curve.png"
        },
        {
          "analysis": "The plot compares training and validation complexity-weighted accuracy (CpxWA) over epochs. Both metrics improve quickly in the first few epochs and stabilize after epoch 4. Training accuracy is slightly higher than validation accuracy, which is expected but indicates minimal overfitting. The consistent gap suggests that the model generalizes well on the validation set.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_164c9f42a8ae4e2f8f602fece4d44d02_proc_1730837/SPR_BENCH_cpxwa_train_val_curve.png"
        },
        {
          "analysis": "The plot compares weighted accuracy metrics (CWA, SWA, CpxWA) on the validation set. All metrics exhibit similar trends, improving rapidly in the early epochs and stabilizing after epoch 4. The close alignment of these metrics highlights the balanced performance of the model across different evaluation criteria. The high and consistent values indicate robust model performance.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_164c9f42a8ae4e2f8f602fece4d44d02_proc_1730837/SPR_BENCH_val_weighted_accuracy_comparison.png"
        }
      ],
      "plot_paths": [
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_164c9f42a8ae4e2f8f602fece4d44d02_proc_1730837/cpxwa_curve.png",
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_164c9f42a8ae4e2f8f602fece4d44d02_proc_1730837/SPR_BENCH_train_loss_curve.png",
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_164c9f42a8ae4e2f8f602fece4d44d02_proc_1730837/SPR_BENCH_cpxwa_train_val_curve.png",
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_164c9f42a8ae4e2f8f602fece4d44d02_proc_1730837/SPR_BENCH_val_weighted_accuracy_comparison.png"
      ],
      "vlm_feedback_summary": "The experimental plots demonstrate effective training and validation performance. The rapid convergence of metrics such as complexity-weighted accuracy (CpxWA), color-weighted accuracy (CWA), and shape-weighted accuracy (SWA) indicates that the model achieves high accuracy and generalizes well. Training loss aligns well with accuracy improvements, confirming stable and efficient learning.",
      "exp_results_dir": "experiment_results/experiment_164c9f42a8ae4e2f8f602fece4d44d02_proc_1730837",
      "exp_results_npy_files": [
        "experiment_results/experiment_164c9f42a8ae4e2f8f602fece4d44d02_proc_1730837/experiment_data.npy"
      ]
    },
    {
      "overall_plan": "The overarching plan involves a systematic approach to hyperparameter tuning with a focus on extending training epochs up to 30, complemented by an early-stopping mechanism to optimize model performance based on validation complexity-weighted accuracy. The intention is to prevent overfitting while ensuring optimal model performance. All relevant metrics and losses are recorded, and learning-curve plots are generated to support analysis. The current designation of the plan as a seed node indicates the establishment of a foundational framework, serving as a starting point for further explorations and refinements in future research endeavors.",
      "analysis": "",
      "metric": {
        "value": {
          "metric_names": [
            {
              "metric_name": "loss",
              "lower_is_better": true,
              "description": "Measures how well the model's predictions align with the actual values. Lower is better.",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 0.169,
                  "best_value": 0.169
                }
              ]
            },
            {
              "metric_name": "color-weighted accuracy",
              "lower_is_better": false,
              "description": "Accuracy weighted by color features.",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 0.9482,
                  "best_value": 0.9482
                },
                {
                  "dataset_name": "validation",
                  "final_value": 0.9477,
                  "best_value": 0.9477
                }
              ]
            },
            {
              "metric_name": "shape-weighted accuracy",
              "lower_is_better": false,
              "description": "Accuracy weighted by shape features.",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 0.9491,
                  "best_value": 0.9491
                },
                {
                  "dataset_name": "validation",
                  "final_value": 0.9447,
                  "best_value": 0.9447
                }
              ]
            },
            {
              "metric_name": "complexity-weighted accuracy",
              "lower_is_better": false,
              "description": "Accuracy weighted by complexity features.",
              "data": [
                {
                  "dataset_name": "training",
                  "final_value": 0.9487,
                  "best_value": 0.9487
                },
                {
                  "dataset_name": "validation",
                  "final_value": 0.9432,
                  "best_value": 0.9432
                }
              ]
            }
          ]
        },
        "maximize": null,
        "name": null,
        "description": null
      },
      "code": "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, copy\nfrom typing import List, Dict\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------------------------------------------------------------\n# working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# ---------- Dataset loading helpers (adapted from SPR.py) ------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) * count_color_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------------------------------------------------------------------\n# -------------------- Synthetic fallback -----------------------------\ndef make_synthetic_split(\n    n: int, vocab_shapes=5, vocab_colors=4, max_len=8, num_labels=3\n):\n    rng = random.Random(42 + n)\n    data = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = []\n        for _ in range(L):\n            s = chr(ord(\"A\") + rng.randint(0, vocab_shapes - 1))\n            c = str(rng.randint(0, vocab_colors - 1))\n            seq.append(s + c)\n        data[\"id\"].append(str(i))\n        data[\"sequence\"].append(\" \".join(seq))\n        data[\"label\"].append(rng.randint(0, num_labels - 1))\n    return data\n\n\ndef load_data():\n    spr_root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    try:\n        if not spr_root.exists():\n            raise FileNotFoundError\n        dset = load_spr_bench(spr_root)\n    except Exception:\n        print(\"SPR_BENCH not found \u2013 using synthetic data.\")\n        train = make_synthetic_split(3000)\n        dev = make_synthetic_split(600)\n        test = make_synthetic_split(600)\n        dset = DatasetDict(\n            {\n                \"train\": load_dataset(\n                    \"json\", data_files={\"train\": train}, split=\"train\"\n                ),\n                \"dev\": load_dataset(\"json\", data_files={\"train\": dev}, split=\"train\"),\n                \"test\": load_dataset(\"json\", data_files={\"train\": test}, split=\"train\"),\n            }\n        )\n    return dset\n\n\ndset = load_data()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Classes: {num_classes}, Train size: {len(dset['train'])}\")\n\n\n# ---------------------------------------------------------------------\n# --------------------- Tokenisation & Vocab --------------------------\ndef build_vocab(sequences: List[str]) -> Dict[str, int]:\n    vocab = {}\n    for seq in sequences:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab) + 1  # reserve 0 for padding\n    return vocab\n\n\nvocab = build_vocab(dset[\"train\"][\"sequence\"])\nvocab_size = len(vocab) + 1\nprint(f\"Vocab size: {vocab_size}\")\n\n\ndef encode_sequence(sequence: str) -> List[int]:\n    return [vocab.get(tok, 0) for tok in sequence.split()]\n\n\n# ---------------------------------------------------------------------\n# -------------------- Torch Dataset wrapper --------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.hf_split = hf_split\n        self.ids = hf_split[\"id\"]\n        self.seqs = [encode_sequence(s) for s in hf_split[\"sequence\"]]\n        self.labels = hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"seq\": torch.tensor(self.seqs[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate_fn(batch):\n    lengths = [len(b[\"seq\"]) for b in batch]\n    max_len = max(lengths)\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    for i, b in enumerate(batch):\n        padded[i, : lengths[i]] = b[\"seq\"]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    return {\"seq\": padded, \"lengths\": torch.tensor(lengths), \"label\": labels}\n\n\ntrain_ds = SPRTorchDataset(dset[\"train\"])\ndev_ds = SPRTorchDataset(dset[\"dev\"])\n\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate_fn)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate_fn)\n\n\n# ---------------------------------------------------------------------\n# -------------------------- Model ------------------------------------\nclass AvgEmbClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.fc = nn.Sequential(\n            nn.Linear(emb_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        mask = (x != 0).float().unsqueeze(-1)\n        summed = (self.embed(x) * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1e-6)\n        avg = summed / lengths\n        return self.fc(avg)\n\n\nmodel = AvgEmbClassifier(vocab_size, 32, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------------------------------------------------------------------\n# -------------- Experiment data tracking structure -------------------\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---------------------------------------------------------------------\n# ------------------------- Training loop with tuning -----------------\nMAX_EPOCHS = 30\npatience = 5\nbest_val_cpx = -1.0\nno_improve = 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    t_start = time.time()\n    model.train()\n    total_loss = 0.0\n    n = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"seq\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch[\"label\"].size(0)\n        n += batch[\"label\"].size(0)\n    train_loss = total_loss / n\n\n    # ----- Evaluation helper\n    def evaluate(loader):\n        model.eval()\n        preds, labels = [], []\n        with torch.no_grad():\n            for batch in loader:\n                batch = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"seq\"])\n                preds.extend(logits.argmax(1).cpu().tolist())\n                labels.extend(batch[\"label\"].cpu().tolist())\n        return preds, labels\n\n    train_preds, train_labels = evaluate(train_loader)\n    val_preds, val_labels = evaluate(dev_loader)\n\n    train_raw = dset[\"train\"][\"sequence\"]\n    val_raw = dset[\"dev\"][\"sequence\"]\n\n    train_cwa = color_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cwa = color_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_swa = shape_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_swa = shape_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_cpx = complexity_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cpx = complexity_weighted_accuracy(val_raw, val_labels, val_preds)\n\n    # Logging\n    exp_ref = experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"]\n    exp_ref[\"metrics\"][\"train\"].append(\n        {\"cwa\": train_cwa, \"swa\": train_swa, \"cpx\": train_cpx}\n    )\n    exp_ref[\"metrics\"][\"val\"].append({\"cwa\": val_cwa, \"swa\": val_swa, \"cpx\": val_cpx})\n    exp_ref[\"losses\"][\"train\"].append(train_loss)\n    exp_ref[\"losses\"][\"val\"].append(None)\n    exp_ref[\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch:02d} | TrainLoss {train_loss:.4f} | Val CpxWA {val_cpx:.4f} | Time {(time.time()-t_start):.1f}s\"\n    )\n\n    # Early stopping logic\n    if val_cpx > best_val_cpx + 1e-6:\n        best_val_cpx = val_cpx\n        no_improve = 0\n        exp_ref[\"predictions\"] = val_preds\n        exp_ref[\"ground_truth\"] = val_labels\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(\n                f\"No improvement for {patience} epochs \u2013 early stopping at epoch {epoch}.\"\n            )\n            break\n\n# ---------------------------------------------------------------------\n# -------------------- Save metrics & plot ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\ncpx_vals = [\n    m[\"cpx\"] for m in experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"metrics\"][\"val\"]\n]\nplt.figure()\nplt.plot(experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"epochs\"], cpx_vals, marker=\"o\")\nplt.title(\"Validation Complexity-Weighted Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CpxWA\")\nplt.savefig(os.path.join(working_dir, \"cpxwa_curve.png\"))\nprint(\"Finished. Results saved in working/.\")\n",
      "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\nexp = experiment_data.get(\"epochs_tuning\", {}).get(\"SPR_BENCH\", None)\nif exp is None:\n    print(\"SPR_BENCH results not found in experiment_data.\")\n    raise SystemExit\n\nepochs = np.array(exp[\"epochs\"])\ntrain_losses = np.array(exp[\"losses\"][\"train\"])\nval_metrics = exp[\"metrics\"][\"val\"]\ntrain_metrics = exp[\"metrics\"][\"train\"]\n\nval_cwa = np.array([m[\"cwa\"] for m in val_metrics])\nval_swa = np.array([m[\"swa\"] for m in val_metrics])\nval_cpx = np.array([m[\"cpx\"] for m in val_metrics])\ntrain_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n\nbest_epoch = int(epochs[np.argmax(val_cpx)])\nbest_val_cpx = float(val_cpx.max())\n\nprint(f\"Best Validation CpxWA: {best_val_cpx:.4f} @ epoch {best_epoch}\")\n\n# ---------------------------------------------------------------------\n# 1) Training loss curve\ntry:\n    plt.figure()\n    plt.plot(epochs, train_losses, marker=\"o\", label=\"Train Loss\")\n    plt.title(\"SPR_BENCH: Training Loss per Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_train_loss_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating train loss plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 2) Training vs. Validation Complexity-Weighted Accuracy\ntry:\n    plt.figure()\n    plt.plot(epochs, train_cpx, marker=\"o\", label=\"Train CpxWA\")\n    plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n    plt.title(\"SPR_BENCH: Complexity-Weighted Accuracy\\nLeft: Train, Right: Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CpxWA\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_cpxwa_train_val_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CpxWA curve: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 3) Validation weighted-accuracy comparison\ntry:\n    plt.figure()\n    plt.plot(epochs, val_cwa, marker=\"o\", label=\"Val CWA\")\n    plt.plot(epochs, val_swa, marker=\"^\", label=\"Val SWA\")\n    plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n    plt.title(\"SPR_BENCH: Weighted Accuracy Comparison (Validation)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Weighted Accuracy\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_val_weighted_accuracy_comparison.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating weighted accuracy comparison plot: {e}\")\n    plt.close()\n",
      "plot_analyses": [
        {
          "analysis": "The plot demonstrates a rapid improvement in validation complexity-weighted accuracy (CpxWA) within the first few epochs, stabilizing around 0.94 after epoch 4. The model converges quickly, indicating that the chosen hyperparameters, such as learning rate and batch size, are effective. However, the lack of further improvement beyond epoch 4 suggests that the model might have reached its performance ceiling for this configuration.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7d353d62cbb649a0bcb941e6164dff22_proc_1730838/cpxwa_curve.png"
        },
        {
          "analysis": "This plot shows a consistent decrease in training loss, with a steep drop in the first few epochs followed by a gradual decline. The final loss stabilizes around 0.15, indicating effective learning and minimal overfitting. The convergence pattern aligns well with the observed accuracy improvements, confirming that the model is optimizing effectively.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7d353d62cbb649a0bcb941e6164dff22_proc_1730838/SPR_BENCH_train_loss_curve.png"
        },
        {
          "analysis": "Both training and validation complexity-weighted accuracy (CpxWA) increase rapidly at the beginning, with training accuracy slightly outperforming validation accuracy throughout. The gap between the two curves remains small, indicating minimal overfitting. This suggests that the model generalizes well to unseen data, and the hyperparameter tuning is effective.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7d353d62cbb649a0bcb941e6164dff22_proc_1730838/SPR_BENCH_cpxwa_train_val_curve.png"
        },
        {
          "analysis": "The plot compares validation metrics for color-weighted accuracy (CWA), shape-weighted accuracy (SWA), and complexity-weighted accuracy (CpxWA). All metrics show a similar trend, with rapid improvement in the first few epochs followed by stabilization around 0.94. The close alignment of the three metrics suggests that the model is performing consistently across different evaluation criteria, indicating robustness in its reasoning capabilities.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7d353d62cbb649a0bcb941e6164dff22_proc_1730838/SPR_BENCH_val_weighted_accuracy_comparison.png"
        }
      ],
      "plot_paths": [
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7d353d62cbb649a0bcb941e6164dff22_proc_1730838/cpxwa_curve.png",
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7d353d62cbb649a0bcb941e6164dff22_proc_1730838/SPR_BENCH_train_loss_curve.png",
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7d353d62cbb649a0bcb941e6164dff22_proc_1730838/SPR_BENCH_cpxwa_train_val_curve.png",
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7d353d62cbb649a0bcb941e6164dff22_proc_1730838/SPR_BENCH_val_weighted_accuracy_comparison.png"
      ],
      "vlm_feedback_summary": "The plots collectively indicate that the model is converging effectively and achieving strong performance across multiple weighted accuracy metrics. The rapid stabilization of metrics suggests that the chosen hyperparameters are optimal for this stage, and there is minimal overfitting. The results demonstrate consistent and robust performance, aligning with the research goal of improving accuracy in symbolic glyph clustering and reasoning.",
      "exp_results_dir": "experiment_results/experiment_7d353d62cbb649a0bcb941e6164dff22_proc_1730838",
      "exp_results_npy_files": [
        "experiment_results/experiment_7d353d62cbb649a0bcb941e6164dff22_proc_1730838/experiment_data.npy"
      ]
    },
    {
      "overall_plan": "The overall plan involves extending the training of the model up to 30 epochs with the inclusion of an early-stopping mechanism (patience = 5) to optimize model performance by monitoring validation complexity-weighted accuracy. All metrics and losses are recorded and saved, along with a learning-curve plot, to provide comprehensive insights into the training process. The current node acts as a seed node, indicating the foundational stage for a new phase or experiment, setting the groundwork for further exploration and potential new directions.",
      "analysis": "",
      "metric": {
        "value": {
          "metric_names": [
            {
              "metric_name": "training loss",
              "lower_is_better": true,
              "description": "The loss value during training phase.",
              "data": [
                {
                  "dataset_name": "SPR_BENCH",
                  "final_value": 0.1674,
                  "best_value": 0.1674
                }
              ]
            },
            {
              "metric_name": "training color-weighted accuracy",
              "lower_is_better": false,
              "description": "The color-weighted accuracy during training phase.",
              "data": [
                {
                  "dataset_name": "SPR_BENCH",
                  "final_value": 0.9483,
                  "best_value": 0.9483
                }
              ]
            },
            {
              "metric_name": "training shape-weighted accuracy",
              "lower_is_better": false,
              "description": "The shape-weighted accuracy during training phase.",
              "data": [
                {
                  "dataset_name": "SPR_BENCH",
                  "final_value": 0.9487,
                  "best_value": 0.9487
                }
              ]
            },
            {
              "metric_name": "training complexity-weighted accuracy",
              "lower_is_better": false,
              "description": "The complexity-weighted accuracy during training phase.",
              "data": [
                {
                  "dataset_name": "SPR_BENCH",
                  "final_value": 0.9484,
                  "best_value": 0.9484
                }
              ]
            },
            {
              "metric_name": "validation color-weighted accuracy",
              "lower_is_better": false,
              "description": "The color-weighted accuracy during validation phase.",
              "data": [
                {
                  "dataset_name": "SPR_BENCH",
                  "final_value": 0.9477,
                  "best_value": 0.9477
                }
              ]
            },
            {
              "metric_name": "validation shape-weighted accuracy",
              "lower_is_better": false,
              "description": "The shape-weighted accuracy during validation phase.",
              "data": [
                {
                  "dataset_name": "SPR_BENCH",
                  "final_value": 0.9447,
                  "best_value": 0.9447
                }
              ]
            },
            {
              "metric_name": "validation complexity-weighted accuracy",
              "lower_is_better": false,
              "description": "The complexity-weighted accuracy during validation phase.",
              "data": [
                {
                  "dataset_name": "SPR_BENCH",
                  "final_value": 0.9432,
                  "best_value": 0.9432
                }
              ]
            }
          ]
        },
        "maximize": null,
        "name": null,
        "description": null
      },
      "code": "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, copy\nfrom typing import List, Dict\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------------------------------------------------------------\n# working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# ---------- Dataset loading helpers (adapted from SPR.py) ------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) * count_color_variety(s) for s in seqs]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------------------------------------------------------------------\n# -------------------- Synthetic fallback -----------------------------\ndef make_synthetic_split(\n    n: int, vocab_shapes=5, vocab_colors=4, max_len=8, num_labels=3\n):\n    rng = random.Random(42 + n)\n    data = {\"id\": [], \"sequence\": [], \"label\": []}\n    for i in range(n):\n        L = rng.randint(3, max_len)\n        seq = []\n        for _ in range(L):\n            s = chr(ord(\"A\") + rng.randint(0, vocab_shapes - 1))\n            c = str(rng.randint(0, vocab_colors - 1))\n            seq.append(s + c)\n        data[\"id\"].append(str(i))\n        data[\"sequence\"].append(\" \".join(seq))\n        data[\"label\"].append(rng.randint(0, num_labels - 1))\n    return data\n\n\ndef load_data():\n    spr_root = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    try:\n        if not spr_root.exists():\n            raise FileNotFoundError\n        dset = load_spr_bench(spr_root)\n    except Exception:\n        print(\"SPR_BENCH not found \u2013 using synthetic data.\")\n        train = make_synthetic_split(3000)\n        dev = make_synthetic_split(600)\n        test = make_synthetic_split(600)\n        dset = DatasetDict(\n            {\n                \"train\": load_dataset(\n                    \"json\", data_files={\"train\": train}, split=\"train\"\n                ),\n                \"dev\": load_dataset(\"json\", data_files={\"train\": dev}, split=\"train\"),\n                \"test\": load_dataset(\"json\", data_files={\"train\": test}, split=\"train\"),\n            }\n        )\n    return dset\n\n\ndset = load_data()\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nprint(f\"Classes: {num_classes}, Train size: {len(dset['train'])}\")\n\n\n# ---------------------------------------------------------------------\n# --------------------- Tokenisation & Vocab --------------------------\ndef build_vocab(sequences: List[str]) -> Dict[str, int]:\n    vocab = {}\n    for seq in sequences:\n        for tok in seq.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab) + 1  # reserve 0 for padding\n    return vocab\n\n\nvocab = build_vocab(dset[\"train\"][\"sequence\"])\nvocab_size = len(vocab) + 1\nprint(f\"Vocab size: {vocab_size}\")\n\n\ndef encode_sequence(sequence: str) -> List[int]:\n    return [vocab.get(tok, 0) for tok in sequence.split()]\n\n\n# ---------------------------------------------------------------------\n# -------------------- Torch Dataset wrapper --------------------------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, hf_split):\n        self.hf_split = hf_split\n        self.ids = hf_split[\"id\"]\n        self.seqs = [encode_sequence(s) for s in hf_split[\"sequence\"]]\n        self.labels = hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"seq\": torch.tensor(self.seqs[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate_fn(batch):\n    lengths = [len(b[\"seq\"]) for b in batch]\n    max_len = max(lengths)\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    for i, b in enumerate(batch):\n        padded[i, : lengths[i]] = b[\"seq\"]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    return {\"seq\": padded, \"lengths\": torch.tensor(lengths), \"label\": labels}\n\n\ntrain_ds = SPRTorchDataset(dset[\"train\"])\ndev_ds = SPRTorchDataset(dset[\"dev\"])\n\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate_fn)\ndev_loader = DataLoader(dev_ds, batch_size=128, shuffle=False, collate_fn=collate_fn)\n\n\n# ---------------------------------------------------------------------\n# -------------------------- Model ------------------------------------\nclass AvgEmbClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.fc = nn.Sequential(\n            nn.Linear(emb_dim, 128), nn.ReLU(), nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        mask = (x != 0).float().unsqueeze(-1)\n        summed = (self.embed(x) * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1e-6)\n        avg = summed / lengths\n        return self.fc(avg)\n\n\nmodel = AvgEmbClassifier(vocab_size, 32, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------------------------------------------------------------------\n# -------------- Experiment data tracking structure -------------------\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"epochs\": [],\n        }\n    }\n}\n\n# ---------------------------------------------------------------------\n# ------------------------- Training loop with tuning -----------------\nMAX_EPOCHS = 30\npatience = 5\nbest_val_cpx = -1.0\nno_improve = 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    t_start = time.time()\n    model.train()\n    total_loss = 0.0\n    n = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"seq\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch[\"label\"].size(0)\n        n += batch[\"label\"].size(0)\n    train_loss = total_loss / n\n\n    # ----- Evaluation helper\n    def evaluate(loader):\n        model.eval()\n        preds, labels = [], []\n        with torch.no_grad():\n            for batch in loader:\n                batch = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"seq\"])\n                preds.extend(logits.argmax(1).cpu().tolist())\n                labels.extend(batch[\"label\"].cpu().tolist())\n        return preds, labels\n\n    train_preds, train_labels = evaluate(train_loader)\n    val_preds, val_labels = evaluate(dev_loader)\n\n    train_raw = dset[\"train\"][\"sequence\"]\n    val_raw = dset[\"dev\"][\"sequence\"]\n\n    train_cwa = color_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cwa = color_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_swa = shape_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_swa = shape_weighted_accuracy(val_raw, val_labels, val_preds)\n    train_cpx = complexity_weighted_accuracy(train_raw, train_labels, train_preds)\n    val_cpx = complexity_weighted_accuracy(val_raw, val_labels, val_preds)\n\n    # Logging\n    exp_ref = experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"]\n    exp_ref[\"metrics\"][\"train\"].append(\n        {\"cwa\": train_cwa, \"swa\": train_swa, \"cpx\": train_cpx}\n    )\n    exp_ref[\"metrics\"][\"val\"].append({\"cwa\": val_cwa, \"swa\": val_swa, \"cpx\": val_cpx})\n    exp_ref[\"losses\"][\"train\"].append(train_loss)\n    exp_ref[\"losses\"][\"val\"].append(None)\n    exp_ref[\"epochs\"].append(epoch)\n\n    print(\n        f\"Epoch {epoch:02d} | TrainLoss {train_loss:.4f} | Val CpxWA {val_cpx:.4f} | Time {(time.time()-t_start):.1f}s\"\n    )\n\n    # Early stopping logic\n    if val_cpx > best_val_cpx + 1e-6:\n        best_val_cpx = val_cpx\n        no_improve = 0\n        exp_ref[\"predictions\"] = val_preds\n        exp_ref[\"ground_truth\"] = val_labels\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(\n                f\"No improvement for {patience} epochs \u2013 early stopping at epoch {epoch}.\"\n            )\n            break\n\n# ---------------------------------------------------------------------\n# -------------------- Save metrics & plot ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n\ncpx_vals = [\n    m[\"cpx\"] for m in experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"metrics\"][\"val\"]\n]\nplt.figure()\nplt.plot(experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"epochs\"], cpx_vals, marker=\"o\")\nplt.title(\"Validation Complexity-Weighted Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CpxWA\")\nplt.savefig(os.path.join(working_dir, \"cpxwa_curve.png\"))\nprint(\"Finished. Results saved in working/.\")\n",
      "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\nexp = experiment_data.get(\"epochs_tuning\", {}).get(\"SPR_BENCH\", None)\nif exp is None:\n    print(\"SPR_BENCH results not found in experiment_data.\")\n    raise SystemExit\n\nepochs = np.array(exp[\"epochs\"])\ntrain_losses = np.array(exp[\"losses\"][\"train\"])\nval_metrics = exp[\"metrics\"][\"val\"]\ntrain_metrics = exp[\"metrics\"][\"train\"]\n\nval_cwa = np.array([m[\"cwa\"] for m in val_metrics])\nval_swa = np.array([m[\"swa\"] for m in val_metrics])\nval_cpx = np.array([m[\"cpx\"] for m in val_metrics])\ntrain_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n\nbest_epoch = int(epochs[np.argmax(val_cpx)])\nbest_val_cpx = float(val_cpx.max())\n\nprint(f\"Best Validation CpxWA: {best_val_cpx:.4f} @ epoch {best_epoch}\")\n\n# ---------------------------------------------------------------------\n# 1) Training loss curve\ntry:\n    plt.figure()\n    plt.plot(epochs, train_losses, marker=\"o\", label=\"Train Loss\")\n    plt.title(\"SPR_BENCH: Training Loss per Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_train_loss_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating train loss plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 2) Training vs. Validation Complexity-Weighted Accuracy\ntry:\n    plt.figure()\n    plt.plot(epochs, train_cpx, marker=\"o\", label=\"Train CpxWA\")\n    plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n    plt.title(\"SPR_BENCH: Complexity-Weighted Accuracy\\nLeft: Train, Right: Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CpxWA\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_cpxwa_train_val_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CpxWA curve: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 3) Validation weighted-accuracy comparison\ntry:\n    plt.figure()\n    plt.plot(epochs, val_cwa, marker=\"o\", label=\"Val CWA\")\n    plt.plot(epochs, val_swa, marker=\"^\", label=\"Val SWA\")\n    plt.plot(epochs, val_cpx, marker=\"s\", label=\"Val CpxWA\")\n    plt.title(\"SPR_BENCH: Weighted Accuracy Comparison (Validation)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Weighted Accuracy\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_val_weighted_accuracy_comparison.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating weighted accuracy comparison plot: {e}\")\n    plt.close()\n",
      "plot_analyses": [
        {
          "analysis": "This plot shows the validation complexity-weighted accuracy (CpxWA) across 16 epochs. The model quickly improves its accuracy in the first few epochs, reaching a plateau at around epoch 6. The stabilization of the curve after the initial rapid growth suggests that the model converged effectively and no longer benefits significantly from additional training. The final accuracy is approximately 0.94, indicating strong performance on the validation set.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b9824fcac00641be8326a28518756696_proc_1730839/cpxwa_curve.png"
        },
        {
          "analysis": "This plot depicts the training loss over 16 epochs. The loss decreases rapidly in the first few epochs, reaching a steady minimum value by epoch 6. The smooth decline without oscillations or irregularities indicates stable training and effective optimization. The final training loss stabilizes around 0.15, suggesting that the model has been trained efficiently without signs of underfitting or overfitting.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b9824fcac00641be8326a28518756696_proc_1730839/SPR_BENCH_train_loss_curve.png"
        },
        {
          "analysis": "This plot compares the complexity-weighted accuracy (CpxWA) for both training and validation sets over 16 epochs. Both curves demonstrate a similar trend, with rapid improvement in the early epochs and stabilization around epoch 6. The training accuracy is slightly higher than the validation accuracy, which is expected and indicates a well-tuned model. The consistent gap between the two curves suggests no significant overfitting, as the validation performance remains strong.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b9824fcac00641be8326a28518756696_proc_1730839/SPR_BENCH_cpxwa_train_val_curve.png"
        },
        {
          "analysis": "This plot compares the validation performances of three metrics: color-weighted accuracy (CWA), shape-weighted accuracy (SWA), and complexity-weighted accuracy (CpxWA). All three metrics show a rapid improvement in the early epochs, followed by stabilization around epoch 6. The CWA consistently outperforms SWA and CpxWA, which may indicate that the model is better at capturing color-based patterns compared to shape-based or complexity-based patterns. The consistent trends across all metrics reflect the robustness of the model's performance.",
          "plot_path": "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b9824fcac00641be8326a28518756696_proc_1730839/SPR_BENCH_val_weighted_accuracy_comparison.png"
        }
      ],
      "plot_paths": [
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b9824fcac00641be8326a28518756696_proc_1730839/cpxwa_curve.png",
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b9824fcac00641be8326a28518756696_proc_1730839/SPR_BENCH_train_loss_curve.png",
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b9824fcac00641be8326a28518756696_proc_1730839/SPR_BENCH_cpxwa_train_val_curve.png",
        "experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b9824fcac00641be8326a28518756696_proc_1730839/SPR_BENCH_val_weighted_accuracy_comparison.png"
      ],
      "vlm_feedback_summary": "The plots demonstrate stable and effective training with rapid convergence of metrics and minimal overfitting. Validation performances across all metrics reach high values, showcasing the model's robustness and strong generalization capabilities.",
      "exp_results_dir": "experiment_results/experiment_b9824fcac00641be8326a28518756696_proc_1730839",
      "exp_results_npy_files": [
        "experiment_results/experiment_b9824fcac00641be8326a28518756696_proc_1730839/experiment_data.npy"
      ]
    }
  ],
  "aggregated results of nodes with different seeds": {
    "overall_plan": "The overarching plan involves a two-pronged approach: optimization of the training process and robust post-training evaluation. Initially, hyperparameter tuning focused on extending training to up to 30 epochs, with an early-stopping mechanism monitoring validation complexity-weighted accuracy to prevent overfitting. Metrics and losses are meticulously recorded and visualized. The current plan complements this by aggregating results from multiple seeds, crucial for assessing the model's robustness and reliability across different initial conditions. This comprehensive strategy ensures both effective model optimization and reliable performance evaluation.",
    "metric": {
      "value": null,
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "# plotting aggregation code",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------------------------------------------------------------\n# Initial setup\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# List of experiment_data paths (relative to AI_SCIENTIST_ROOT env var)\nexperiment_data_path_list = [\n    \"experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_7d353d62cbb649a0bcb941e6164dff22_proc_1730838/experiment_data.npy\",\n    \"experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b9824fcac00641be8326a28518756696_proc_1730839/experiment_data.npy\",\n    \"experiments/2025-08-31_14-11-51_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_164c9f42a8ae4e2f8f602fece4d44d02_proc_1730837/experiment_data.npy\",\n]\n\n# ---------------------------------------------------------------------\n# Load all experiment data\nall_runs = []\nfor exp_path in experiment_data_path_list:\n    try:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), exp_path)\n        exp_data = np.load(full_path, allow_pickle=True).item()\n        all_runs.append(exp_data)\n    except Exception as e:\n        print(f\"Error loading experiment data from {exp_path}: {e}\")\n\nif len(all_runs) == 0:\n    print(\"No experiment files could be loaded; aborting.\")\n    raise SystemExit\n\n# ---------------------------------------------------------------------\n# Extract metrics for SPR_BENCH from each run\nepochs_list, train_loss_list = [], []\ntrain_cpx_list, val_cpx_list = [], []\nval_cwa_list, val_swa_list = [], []\nbest_val_cpx_each = []\n\nfor idx, exp in enumerate(all_runs):\n    try:\n        spr = exp.get(\"epochs_tuning\", {}).get(\"SPR_BENCH\", None)\n        if spr is None:\n            print(f\"Run {idx}: SPR_BENCH not found; skipping.\")\n            continue\n\n        epochs = np.array(spr[\"epochs\"])\n        train_loss = np.array(spr[\"losses\"][\"train\"])\n\n        train_metrics = spr[\"metrics\"][\"train\"]\n        val_metrics = spr[\"metrics\"][\"val\"]\n\n        train_cpx = np.array([m[\"cpx\"] for m in train_metrics])\n        val_cpx = np.array([m[\"cpx\"] for m in val_metrics])\n        val_cwa = np.array([m[\"cwa\"] for m in val_metrics])\n        val_swa = np.array([m[\"swa\"] for m in val_metrics])\n\n        # Align lengths just in case\n        min_len = min(\n            len(epochs),\n            len(train_loss),\n            len(train_cpx),\n            len(val_cpx),\n            len(val_cwa),\n            len(val_swa),\n        )\n        epochs_list.append(epochs[:min_len])\n        train_loss_list.append(train_loss[:min_len])\n        train_cpx_list.append(train_cpx[:min_len])\n        val_cpx_list.append(val_cpx[:min_len])\n        val_cwa_list.append(val_cwa[:min_len])\n        val_swa_list.append(val_swa[:min_len])\n\n        # Record best val CpxWA for this run\n        best_val_cpx_each.append(float(val_cpx.max()))\n        print(\n            f\"Run {idx}: Best Val CpxWA = {val_cpx.max():.4f} \"\n            f\"@ epoch {epochs[np.argmax(val_cpx)]}\"\n        )\n    except Exception as e:\n        print(f\"Error processing run {idx}: {e}\")\n\n# Sanity-check we have at least one successful run\nif len(train_loss_list) == 0:\n    print(\"No valid SPR_BENCH data found across runs; aborting.\")\n    raise SystemExit\n\n\n# ---------------------------------------------------------------------\ndef stack_and_stats(lst):\n    arr = np.stack(lst, axis=0)  # shape (n_runs, n_epochs)\n    mean = np.nanmean(arr, axis=0)\n    sem = np.nanstd(arr, axis=0, ddof=1) / np.sqrt(arr.shape[0])\n    return mean, sem\n\n\nmean_train_loss, sem_train_loss = stack_and_stats(train_loss_list)\nmean_train_cpx, sem_train_cpx = stack_and_stats(train_cpx_list)\nmean_val_cpx, sem_val_cpx = stack_and_stats(val_cpx_list)\nmean_val_cwa, sem_val_cwa = stack_and_stats(val_cwa_list)\nmean_val_swa, sem_val_swa = stack_and_stats(val_swa_list)\nepochs = epochs_list[0]  # assume aligned as enforced above\n\n# Overall aggregated best Val CpxWA (per-run bests)\noverall_mean_best = np.mean(best_val_cpx_each)\noverall_sem_best = np.std(best_val_cpx_each, ddof=1) / np.sqrt(len(best_val_cpx_each))\nprint(\n    f\"Aggregated Best Val CpxWA across runs: {overall_mean_best:.4f} \u00b1 {overall_sem_best:.4f}\"\n)\n\n# ---------------------------------------------------------------------\n# 1) Mean training loss curve\ntry:\n    plt.figure()\n    plt.plot(epochs, mean_train_loss, label=\"Mean Train Loss\")\n    plt.fill_between(\n        epochs,\n        mean_train_loss - sem_train_loss,\n        mean_train_loss + sem_train_loss,\n        alpha=0.3,\n        label=\"\u00b1 SEM\",\n    )\n    plt.title(\"SPR_BENCH: Mean Training Loss per Epoch\\nShaded: \u00b1SEM\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_mean_train_loss_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating mean train loss plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 2) Mean Train vs. Val CpxWA\ntry:\n    plt.figure()\n    plt.plot(epochs, mean_train_cpx, label=\"Train CpxWA (mean)\")\n    plt.fill_between(\n        epochs,\n        mean_train_cpx - sem_train_cpx,\n        mean_train_cpx + sem_train_cpx,\n        alpha=0.3,\n        label=\"Train \u00b1 SEM\",\n    )\n    plt.plot(epochs, mean_val_cpx, label=\"Val CpxWA (mean)\")\n    plt.fill_between(\n        epochs,\n        mean_val_cpx - sem_val_cpx,\n        mean_val_cpx + sem_val_cpx,\n        alpha=0.3,\n        label=\"Val \u00b1 SEM\",\n    )\n    plt.title(\"SPR_BENCH: Complexity-Weighted Accuracy\\nLeft: Train, Right: Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CpxWA\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_mean_cpxwa_train_val_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating mean CpxWA plot: {e}\")\n    plt.close()\n\n# ---------------------------------------------------------------------\n# 3) Mean Validation weighted accuracy comparison\ntry:\n    plt.figure()\n    # Use error bars here for clarity\n    plt.errorbar(\n        epochs, mean_val_cwa, yerr=sem_val_cwa, marker=\"o\", label=\"Val CWA (mean \u00b1 SEM)\"\n    )\n    plt.errorbar(\n        epochs, mean_val_swa, yerr=sem_val_swa, marker=\"^\", label=\"Val SWA (mean \u00b1 SEM)\"\n    )\n    plt.errorbar(\n        epochs,\n        mean_val_cpx,\n        yerr=sem_val_cpx,\n        marker=\"s\",\n        label=\"Val CpxWA (mean \u00b1 SEM)\",\n    )\n    plt.title(\"SPR_BENCH: Weighted Accuracy Comparison (Validation)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Weighted Accuracy\")\n    plt.legend()\n    fname = os.path.join(\n        working_dir, \"SPR_BENCH_mean_val_weighted_accuracy_comparison.png\"\n    )\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating mean weighted accuracy comparison plot: {e}\")\n    plt.close()\n",
    "plot_analyses": [],
    "plot_paths": [],
    "vlm_feedback_summary": [],
    "exp_results_dir": "experiment_results/seed_aggregation_bf42901e4b8c4777b6bbb1770e7608f3",
    "exp_results_npy_files": []
  }
}