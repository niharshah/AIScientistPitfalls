\documentclass{article} % For LaTeX2e
\usepackage{iclr2025,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% Custom
\usepackage{multirow}
\usepackage{color}
\usepackage{colortbl}
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{xspace}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\graphicspath{{../figures/}} % DO NOT CHANGE THIS.

\begin{filecontents}{references.bib}
@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  year={2016},
  publisher={MIT Press}
}

@inproceedings{hamerly2017acceleratingla,
 author = {Greg Hamerly and Jonathan Drake},
 title = {Accelerating Lloyd's Algorithm for k-Means Clustering},
 year = {2017}
}

@article{devlin2019bertpo,
 author = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
 booktitle = {North American Chapter of the Association for Computational Linguistics},
 pages = {4171-4186},
 title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
 year = {2019}
}

@article{shahapure2020clusterqa,
 author = {K. Shahapure and Charles K. Nicholas},
 booktitle = {International Conference on Data Science and Advanced Analytics},
 journal = {2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)},
 pages = {747-748},
 title = {Cluster Quality Analysis Using Silhouette Score},
 year = {2020}
}

@article{weis2020benchmarkinguo,
 author = {Marissa A. Weis and Kashyap Chitta and Yash Sharma and Wieland Brendel and M. Bethge and Andreas Geiger and Alexander S. Ecker},
 booktitle = {Journal of machine learning research},
 journal = {J. Mach. Learn. Res.},
 pages = {183:1-183:61},
 title = {Benchmarking Unsupervised Object Representations for Video Sequences},
 volume = {22},
 year = {2020}
}

@article{rajotia2025principalca,
 author = {Meghana Singh Rajotia and D. Vart and A. Dashora and Rao Pankaj and Harshdeep and Jyoti , Neeraj Kharor and S. K. Pahuja},
 booktitle = {Ecology, environment & conservation},
 journal = {Ecology, Environment and Conservation},
 title = {Principal Component Analysis approach for Rancidity and Grain Yield Traits in Pearl Millet},
 year = {2025}
}

@article{snell2017prototypicalnf,
 author = {Jake Snell and Kevin Swersky and R. Zemel},
 booktitle = {Neural Information Processing Systems},
 pages = {4077-4087},
 title = {Prototypical Networks for Few-shot Learning},
 year = {2017}
}

@article{barbiero2023interpretablenc,
 author = {Pietro Barbiero and Gabriele Ciravegna and Francesco Giannini and Mateo Espinosa Zarlenga and Lucie Charlotte Magister and A. Tonda and Pietro Lio' and F. Precioso and M. Jamnik and G. Marra},
 booktitle = {International Workshop on Neural-Symbolic Learning and Reasoning},
 journal = {ArXiv},
 title = {Interpretable Neural-Symbolic Concept Reasoning},
 volume = {abs/2304.14068},
 year = {2023}
}

@article{jeong2025symbolnetbl,
 author = {SungHeon Jeong and Hyungjoon Kim and Yoojeong Song},
 booktitle = {IEEE Access},
 journal = {IEEE Access},
 pages = {78221-78230},
 title = {SymbolNet: Bridging Latent Neural Representations and Symbolic Reasoning via Intermediate Feature Interpretation},
 volume = {13},
 year = {2025}
}

@article{morishita2024enhancingrc,
 author = {Terufumi Morishita and Gaku Morio and Atsuki Yamaguchi and Yasuhiro Sogawa},
 booktitle = {Neural Information Processing Systems},
 journal = {ArXiv},
 title = {Enhancing Reasoning Capabilities of LLMs via Principled Synthetic Logic Corpus},
 volume = {abs/2411.12498},
 year = {2024}
}

@article{bereta2025theso,
 author = {Pola Bereta and Ioannis Diamantis},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {The Shape of Consumer Behavior: A Symbolic and Topological Analysis of Time Series},
 volume = {abs/2506.19759},
 year = {2025}
}
\end{filecontents}

\title{Unveiling Hidden Patterns: Symbolic Glyph Clustering for Enhanced PolyRule Reasoning}

\author{Anonymous}

\begin{document}

\maketitle

\begin{abstract}
Symbolic Pattern Recognition (SPR) often involves deciphering latent rules from sequences of abstract glyphs. We investigate whether clustering glyphs based on latent feature representations can reveal hidden structure and improve reasoning performance. We propose a pipeline that uses pre-trained embeddings, clusters glyphs using K-means, then feeds the clustered representations into a neural reasoning model. Experiments on a synthetic SPR benchmark show partial improvements, particularly for shape-focused metrics, yet fail to surpass the state of the art on color-based tasks. The findings highlight the challenges and potential pitfalls in applying clustering to symbolic reasoning.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Many real-world tasks involve abstract, symbolic manipulations, but neural models often struggle when symbols do not follow conventional text distributions. Synthetic datasets such as SPR\_BENCH facilitate controlled evaluation \citep{morishita2024enhancingrc}. Our focus is symbol clustering for improved reasoning. We hypothesize that grouping glyphs by shared features can reveal interpretable patterns. This can have implications for neural-symbolic integration \citep{barbiero2023interpretablenc, jeong2025symbolnetbl} and for bridging latent representations with more explicit structure \citep{goodfellow2016deep}.

We present a clustering-based approach for PolyRule reasoning: (1) latent feature extraction, (2) glyph grouping, and (3) aggregated reasoning. Despite strong performance on shape-dependent metrics, our approach underperforms on color-weighted tasks. These mixed results underscore the challenges of balancing multiple symbolic attributes.

\section{Related Work}
\label{sec:related}
Symbolic clustering has been explored in few-shot learning \citep{snell2017prototypicalnf} and unsupervised object representation tasks \citep{weis2020benchmarkinguo}, though prior studies primarily evaluated natural images or text rather than abstract glyphs. Dimensionality reduction (e.g., PCA) is often applied to mitigate computational costs when clustering large feature sets \citep{rajotia2025principalca}. We rely on K-means \citep{hamerly2017acceleratingla} and validate cluster quality using silhouette scores \citep{shahapure2020clusterqa}. Our work expands on neural-symbolic methodologies \citep{barbiero2023interpretablenc, jeong2025symbolnetbl} by focusing on a novel symbolic domain with color and shape attributes. Clustering high-entropy symbols can be ambiguous \citep{bereta2025theso}, leading to pitfalls in practice.

\section{Method}
\label{sec:method}
We load sequences from SPR\_BENCH, each symbol composed of shape and color tags, then tokenize them with a pre-trained model (e.g., BERT) \citep{devlin2019bertpo} or simple ID lookups. We optionally reduce dimensionality \citep{rajotia2025principalca} before clustering. K-means assigns each symbol to a cluster, producing a label used alongside the raw shape and color embeddings. A neural reasoning module (e.g., a BiLSTM) sums or concatenates embeddings, averages token representations, and classifies the rule. We train with cross-entropy on the labeled sequence, selecting the best checkpoint by validation loss.

\section{Experiments}
\label{sec:experiments}
We first compare a baseline model with embedding dimensions of 4--64. Validation scores increase slightly for higher dimensions, but final test metrics remain around 0.63--0.68 for color and shape. We then incorporate clustering. Shape-weighted accuracy (SWA) improves from 0.65 to 0.70, but color-weighted accuracy (CWA) remains at 0.635, short of the 0.70 state of the art. These differences suggest that simplistic clustering pipelines can more effectively capture shape cues than subtle color variations.

\begin{figure}[t!]
\centering
\subfigure[Baseline Dimension Tuning]{\includegraphics[width=0.33\textwidth]{baseline_embedding_dimension.png}\label{fig:baseline}}
\hfill
\subfigure[Enhanced BiLSTM + Clustering]{\includegraphics[width=0.33\textwidth]{research_enhanced_model.png}\label{fig:research}}
\caption{\textbf{Figure 1: Key experiment results on SPR\_BENCH.} (a) Minor gains from higher embedding dimensions. (b) BiLSTM plus glyph clustering improves shape-based metrics but struggles with color attributes. Overall, the right subfigure highlights how clustering is beneficial for certain attributes (e.g., shape) yet fails to strengthen color reasoning, indicating difficulties in multi-attribute symbolic tasks.}
\end{figure}

We used the Adam optimizer (learning rate 2e-4), batch size 32, and early stopping with patience of 5. In practice, we found that random initialization of cluster centroids sometimes produced local minima, suggesting that more careful cluster initialization or specialized distances may be required to fully capture color nuances.

\section{Conclusion}
\label{sec:conclusion}
Symbolic glyph clustering for reasoning reveals latent shape structure but fares worse on color attributes. This partially successful result underscores the complexity of symbolic tasks that incorporate multiple attributes. Future work might explore alternative distance metrics or specialized clustering. These findings encourage the community to share both promising and inconclusive directions, echoing the workshop's emphasis on real-world challenges and negative results in deep learning.

\bibliography{iclr2025}
\bibliographystyle{iclr2025}

\appendix

\section*{\LARGE Supplementary Material}
\label{sec:appendix}
Here, we provide ablation studies that demonstrate the effects of various design decisions, such as removing color embeddings, introducing random clusters, and altering the embedding fusion method. We show that each factor can meaningfully affect performance. Specifically, removing color embeddings or relying on random clustering degrades results, particularly on color-based tasks, while alternative embedding fusion (summation vs.\ concatenation) introduces trade-offs between shape focus and color fidelity. These comprehensive ablations underscore how subtle implementation details matter for symbolic pattern recognition pipelines.

\begin{figure}[h]
\centering
\subfigure[Atomic glyph embeddings]{\includegraphics[width=0.24\textwidth]{ablation_atomic_glyph_embedding.png}\label{fig:ablations1}}
\subfigure[Bag-of-glyph approach]{\includegraphics[width=0.24\textwidth]{ablation_bag_of_glyph.png}\label{fig:ablations2}}
\subfigure[Multi-synth training]{\includegraphics[width=0.24\textwidth]{ablation_multi_synth_training.png}\label{fig:ablations3}}
\subfigure[No cluster embedding]{\includegraphics[width=0.24\textwidth]{ablation_no_cluster_embedding.png}\label{fig:ablations4}}
\subfigure[No color embedding]{\includegraphics[width=0.24\textwidth]{ablation_no_color_embedding.png}\label{fig:ablations5}}
\subfigure[Random clustering]{\includegraphics[width=0.24\textwidth]{ablation_random_cluster.png}\label{fig:ablations6}}
\subfigure[Sum-fusion embeddings]{\includegraphics[width=0.24\textwidth]{ablation_sum_fusion_embeddings.png}\label{fig:ablations7}}
\subfigure[Unidirectional LSTM]{\includegraphics[width=0.24\textwidth]{ablation_uni_lstm.png}\label{fig:ablations8}}
\caption{\textbf{Figure 2: Ablation studies with various configurations.} Each subfigure highlights how a specific design change (e.g., removing color embeddings or applying random clustering) impacts shape and color performance. Removing color embeddings (e) severely diminishes color-based accuracy, while random clustering (f) degrades both shape and color metrics, illustrating the sensitivity of symbolic reasoning to clustering initialization.}
\label{fig:allablations}
\end{figure}