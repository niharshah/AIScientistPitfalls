{"edges": [[1, 4], [3, 8], [3, 11], [3, 9], [3, 10]], "layout": [[0.0, 0.0], [0.15384615384615385, 0.0], [0.3076923076923077, 0.0], [0.5384615384615384, 0.0], [0.15384615384615385, 1.0], [0.6923076923076923, 0.0], [0.8461538461538461, 0.0], [1.0, 0.0], [0.3076923076923077, 1.0], [0.46153846153846156, 1.0], [0.6153846153846154, 1.0], [0.7692307692307693, 1.0]], "plan": ["Hyperparam tuning name: epochs. The solution raises the maximum training epochs\nto 30 and adds a simple early-stopping mechanism that monitors the validation\nGCWA; training halts if no improvement is observed for five consecutive epochs.\nThe best-performing model (highest GCWA) is checkpointed in memory and later\nused for the final test evaluation. All per-epoch losses and metrics are logged\ninside the mandated `experiment_data` dictionary and saved to\n`experiment_data.npy`.", "Hyperparam tuning name: learning_rate. A logarithmic grid-search is added around\nAdam\u2019s learning-rate.   For every candidate rate we re-seed, build a fresh\nmodel, train for a fixed number of epochs, evaluate on the dev and test splits,\nand log losses/accuracies.   All per-run results are collected in\nexperiment_data['learning_rate']['SPR_BENCH']; after the sweep the learning-rate\nthat yields the highest final-epoch GCWA on the dev set is reported and its test\nperformance stored.   Everything (including predictions) is saved as\n\u201cexperiment_data.npy\u201d so it can be plotted later without rerunning the sweep.", "Hyperparam tuning name: batch_size. The solution simply wraps the existing\ntraining / evaluation logic inside a loop that iterates over the candidate mini-\nbatch sizes {32, 64, 128, 256}.   For every batch size we rebuild the\nDataLoaders, instantiate a fresh model, train for a few epochs, store per-epoch\ntrain / validation losses and metrics, run a final test evaluation, and record\neverything in `experiment_data['batch_size']['SPR_BENCH'][<bs>]`.   After all\nsweeps, the complete `experiment_data` structure is saved to\n`experiment_data.npy`, ready for later plotting or analysis.", "Hyperparam tuning name: embedding_dim. We reuse the baseline pipeline but wrap\nmodel creation and training in a loop that iterates over different embedding\ndimensions (4, 8, 16, 32, 64).   For every emb_dim we (1) build a fresh\nGlyphModel, (2) train for 5 epochs, (3) record train/val losses and metric\ntraces, and (4) finally test on the hold-out set.   Results for each value are\nstored under experiment_data['embedding_dim_tuning']['SPR_BENCH']['emb_dim_X']\nwhere X is the dimension.   All recorded arrays are saved in the mandatory file\nexperiment_data.npy so they can later be plotted or compared.", "Pooling bug fixed by ensuring the mask\u2019s summed length has a singleton dimension\nso broadcasting matches the pooled embedding tensor.   Specifically, in\nGlyphModel.forward we now compute    lengths = mask.sum(1,\nkeepdim=True).clamp(min=1e-6)    and divide by lengths, eliminating the shape\nmismatch that produced the runtime error.   No architectural changes were made;\nonly the pooling operation was corrected and GPU/metric-tracking guidelines\nincorporated.", "Hyperparam tuning name: hidden_dim (size of the intermediate fully-connected\nlayer). The solution trains one model per hidden-layer size (32, 64, 128, 256).\nFor every hidden_dim value we:   1. build a fresh model/optimizer;   2. run five\nepochs of training;   3. record train/validation losses and CWA/SWA/GCWA scores;\n4. keep the final test predictions;   5. store everything in the experiment_data\ndict under the \u201chidden_dim\u201d key.   After the sweep the whole experiment_data\nstructure is saved to experiment_data.npy.", "Hyperparam tuning name: weight_decay. The solution trains a fresh GlyphModel for\neach weight-decay value in {0, 1e-5, 1e-4, 1e-3}.   For every setting we store\nepoch-wise train/validation losses, validation CWA/SWA/GCWA, and final test-set\npredictions/metrics in the experiment_data dictionary under\nexperiment_data['weight_decay'][str(wd)]['SPR_BENCH'].   After all sweeps the\ndictionary is saved to working/experiment_data.npy for later analysis.", "Hyperparam tuning name: dropout_rate. The solution introduces an adjustable\n`dropout_rate` in `GlyphModel` (added as `nn.Dropout`) and performs a simple\ngrid-search over p \u2208 {0.1, 0.2, 0.3, 0.4, 0.5}.   For each rate the script (i)\nbuilds a fresh model, (ii) trains for a few epochs, (iii) evaluates on the dev\nsplit, and (iv) stores losses, CWA/SWA/GCWA and predictions inside a unified\n`experiment_data` dictionary keyed by the dropout value.   After finishing the\nsweep it prints test-set results for the best rate (highest dev GCWA) and saves\nthe whole `experiment_data` structure to `experiment_data.npy`, ready for later\nplotting or analysis.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, random, json, time\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# ------------- experiment data container ---------------- #\nexperiment_data = {\n    \"epochs_tuning\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"best_epoch\": None,\n        }\n    }\n}\n\n# ------------- paths & device --------------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------- metrics ---------------------------------- #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ------------- data loading ----------------------------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path) -> DatasetDict | None:\n    if root.exists():\n\n        def _load(csv_name):  # helper\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synthetic() -> DatasetDict:\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen(n):\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    d = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        d[split] = load_dataset(\n            \"json\", data_files={\"train\": [json.dumps(r) for r in gen(n)]}, split=\"train\"\n        )\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# ------------- vocab & clustering ----------------------- #\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 reserved for PAD\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in token_set], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(token_vecs)\ntok2cluster = {tok: int(c) + 1 for tok, c in zip(token_set, kmeans.labels_)}\n\n\n# ------------- Dataset & Dataloader --------------------- #\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        return {\n            \"shape\": [shape2id[t[0]] for t in seq],\n            \"color\": [color2id[t[1]] for t in seq],\n            \"cluster\": [tok2cluster[t] for t in seq],\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ------------- model ------------------------------------ #\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        pooled = (e * mask.unsqueeze(-1)).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\nmodel = GlyphModel(len(shapes), len(colors), n_clusters, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\n# ------------- helpers ---------------------------------- #\ndef evaluate(loader):\n    model.eval()\n    total_loss, all_preds, all_tgts, all_seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            shapes, colors, clusters = (\n                batch[\"shape\"].to(device),\n                batch[\"color\"].to(device),\n                batch[\"cluster\"].to(device),\n            )\n            mask, labels = batch[\"mask\"].to(device), batch[\"labels\"].to(device)\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            total_loss += loss.item() * labels.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_tgts.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seqs\"])\n    avg_loss = total_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    swa = shape_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    gcwa = glyph_complexity_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    return avg_loss, {\"CWA\": cwa, \"SWA\": swa, \"GCWA\": gcwa}, all_preds, all_tgts\n\n\n# ------------- training with early stopping ------------- #\nmax_epochs = 30\npatience = 5\nbest_gcwa = -1.0\npat_wait = 0\nbest_state = None\n\nfor epoch in range(1, max_epochs + 1):\n    model.train()\n    running_loss = 0.0\n    for batch in train_loader:\n        shapes, colors, clusters = (\n            batch[\"shape\"].to(device),\n            batch[\"color\"].to(device),\n            batch[\"cluster\"].to(device),\n        )\n        mask, labels = batch[\"mask\"].to(device), batch[\"labels\"].to(device)\n        optimizer.zero_grad()\n        logits = model(shapes, colors, clusters, mask)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * labels.size(0)\n    train_loss = running_loss / len(train_loader.dataset)\n    val_loss, val_metrics, _, _ = evaluate(dev_loader)\n\n    # log\n    experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"metrics\"][\"val\"].append(val_metrics)\n\n    print(\n        f\"Epoch {epoch:02d}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n        f\"CWA={val_metrics['CWA']:.3f} | SWA={val_metrics['SWA']:.3f} | GCWA={val_metrics['GCWA']:.3f}\"\n    )\n\n    # early stopping based on GCWA\n    current_gcwa = val_metrics[\"GCWA\"]\n    if current_gcwa > best_gcwa:\n        best_gcwa, pat_wait = current_gcwa, 0\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        experiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"best_epoch\"] = epoch\n    else:\n        pat_wait += 1\n        if pat_wait >= patience:\n            print(\n                f\"Early stopping triggered at epoch {epoch}. Best GCWA = {best_gcwa:.3f}\"\n            )\n            break\n\n# ------------- load best model & final test ------------- #\nmodel.load_state_dict(best_state)\ntest_loss, test_metrics, test_preds, test_tgts = evaluate(test_loader)\nexperiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"metrics\"][\"test\"] = test_metrics\nexperiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"predictions\"] = test_preds\nexperiment_data[\"epochs_tuning\"][\"SPR_BENCH\"][\"ground_truth\"] = test_tgts\nprint(\n    f\"Test: loss={test_loss:.4f} | CWA={test_metrics['CWA']:.3f} | \"\n    f\"SWA={test_metrics['SWA']:.3f} | GCWA={test_metrics['GCWA']:.3f}\"\n)\n\n# ------------- save ------------------------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, random, time, json, warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# -------- basic setup -------- #\nimport numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# -------- reproducibility helper -------- #\ndef set_seed(sd=0):\n    random.seed(sd)\n    np.random.seed(sd)\n    torch.manual_seed(sd)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(sd)\n\n\n# -------- metrics ---------- #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# -------- data loading ---------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path) -> DatasetDict:\n    if root.exists():\n\n        def _load(split_csv):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / split_csv),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synthetic() -> DatasetDict:\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen_split(n):\n        return [\n            {\n                \"id\": i,\n                \"sequence\": \" \".join(\n                    random.choice(shapes) + random.choice(colors)\n                    for _ in range(random.randint(3, 9))\n                ),\n                \"label\": random.randint(0, 3),\n            }\n            for i in range(n)\n        ]\n\n    d = DatasetDict()\n    for sp, n in zip([\"train\", \"dev\", \"test\"], [500, 100, 100]):\n        d[sp] = load_dataset(\n            \"json\",\n            data_files={\"train\": [json.dumps(r) for r in gen_split(n)]},\n            split=\"train\",\n        )\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# -------- vocab & clustering ---------- #\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 pad\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array([[shape2id[t[0]], color2id[t[1]]] for t in token_set], float)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\ntok2cluster = {\n    tok: int(c) + 1\n    for tok, c in zip(\n        token_set, KMeans(n_clusters, random_state=0).fit(token_vecs).labels_\n    )\n}\n\n\n# -------- Torch Dataset ---------- #\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = spr[split][\"sequence\"], spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        return {\n            \"shape\": [shape2id[t[0]] for t in seq],\n            \"color\": [color2id[t[1]] for t in seq],\n            \"cluster\": [tok2cluster[t] for t in seq],\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": [b[\"seq_str\"] for b in batch],\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# -------- model ---------- #\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        pooled = (e * mask.unsqueeze(-1)).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\n# -------- evaluation helper -------- #\ndef evaluate(model, loader, criterion):\n    model.eval()\n    total_loss, all_preds, all_tgts, all_seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for b in loader:\n            s, c, l = (\n                b[\"shape\"].to(device),\n                b[\"color\"].to(device),\n                b[\"cluster\"].to(device),\n            )\n            m, labels = b[\"mask\"].to(device), b[\"labels\"].to(device)\n            logits = model(s, c, l, m)\n            loss = criterion(logits, labels)\n            total_loss += loss.item() * labels.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_tgts.extend(labels.cpu().tolist())\n            all_seqs.extend(b[\"seqs\"])\n    avg_loss = total_loss / len(loader.dataset)\n    return (\n        avg_loss,\n        {\n            \"CWA\": color_weighted_accuracy(all_seqs, all_tgts, all_preds),\n            \"SWA\": shape_weighted_accuracy(all_seqs, all_tgts, all_preds),\n            \"GCWA\": glyph_complexity_weighted_accuracy(all_seqs, all_tgts, all_preds),\n        },\n        all_preds,\n        all_tgts,\n    )\n\n\n# -------- hyperparameter sweep -------- #\nlearning_rates = [3e-4, 1e-4, 3e-5, 1e-5]\nepochs = 5\nexperiment_data = {\n    \"learning_rate\": {\n        \"SPR_BENCH\": {\n            \"lrs\": learning_rates,\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": []},\n            \"losses\": {\"train\": [], \"val\": [], \"test\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nbest_idx, best_gcwa = -1, -1.0\n\nfor run_idx, lr in enumerate(learning_rates):\n    print(f\"\\n===== training with lr={lr:.1e} =====\")\n    set_seed(run_idx)\n    model = GlyphModel(len(shapes), len(colors), n_clusters, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    run_train_losses, run_val_losses = [], []\n    run_val_metrics = []\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            s, c, l = (\n                batch[\"shape\"].to(device),\n                batch[\"color\"].to(device),\n                batch[\"cluster\"].to(device),\n            )\n            mask, labels = batch[\"mask\"].to(device), batch[\"labels\"].to(device)\n            optimizer.zero_grad()\n            logits = model(s, c, l, mask)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * labels.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        val_loss, val_m, _, _ = evaluate(model, dev_loader, criterion)\n        run_train_losses.append(train_loss)\n        run_val_losses.append(val_loss)\n        run_val_metrics.append(val_m)\n        print(\n            f\"Epoch {epoch}/{epochs} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n            f\"CWA={val_m['CWA']:.3f} | SWA={val_m['SWA']:.3f} | GCWA={val_m['GCWA']:.3f}\"\n        )\n    # dev performance after final epoch decides best lr\n    final_gcwa = run_val_metrics[-1][\"GCWA\"]\n    if final_gcwa > best_gcwa:\n        best_gcwa, best_idx = final_gcwa, run_idx\n    # test evaluation\n    test_loss, test_m, test_preds, test_tgts = evaluate(model, test_loader, criterion)\n    print(\n        f\"Test | loss={test_loss:.4f} | CWA={test_m['CWA']:.3f} | SWA={test_m['SWA']:.3f} | GCWA={test_m['GCWA']:.3f}\"\n    )\n    # store\n    ed = experiment_data[\"learning_rate\"][\"SPR_BENCH\"]\n    ed[\"metrics\"][\"train\"].append([])  # placeholder, not computed per batch\n    ed[\"metrics\"][\"val\"].append(run_val_metrics)\n    ed[\"metrics\"][\"test\"].append(test_m)\n    ed[\"losses\"][\"train\"].append(run_train_losses)\n    ed[\"losses\"][\"val\"].append(run_val_losses)\n    ed[\"losses\"][\"test\"].append(test_loss)\n    ed[\"predictions\"].append(test_preds)\n    ed[\"ground_truth\"].append(test_tgts)\n\nprint(\n    f\"\\nBest learning rate: {learning_rates[best_idx]:.1e} with dev GCWA {best_gcwa:.3f}\"\n)\n# -------- persist -------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n", "import os, pathlib, random, json, time\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# ---------- experiment dictionary ---------- #\nexperiment_data = {\n    \"batch_size\": {\"SPR_BENCH\": {}}  # will hold results keyed by batch size\n}\n\n# ---------- device ---------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- metrics utilities ---------- #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\n# ---------- data loading ---------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path) -> DatasetDict:\n    if root.exists():\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synthetic() -> DatasetDict:\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen_split(n):\n        rows = []\n        for i in range(n):\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors)\n                for _ in range(random.randint(3, 9))\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    d = DatasetDict()\n    d[\"train\"] = load_dataset(\n        \"json\",\n        data_files={\"train\": [json.dumps(r) for r in gen_split(500)]},\n        split=\"train\",\n    )\n    d[\"dev\"] = load_dataset(\n        \"json\",\n        data_files={\"train\": [json.dumps(r) for r in gen_split(100)]},\n        split=\"train\",\n    )\n    d[\"test\"] = load_dataset(\n        \"json\",\n        data_files={\"train\": [json.dumps(r) for r in gen_split(100)]},\n        split=\"train\",\n    )\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# ---------- vocab & clustering ---------- #\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 reserved for PAD\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\n\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in token_set], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(token_vecs)\ntok2cluster = {tok: int(c) + 1 for tok, c in zip(token_set, kmeans.labels_)}  # 0 pad\n\n\n# ---------- dataset class ---------- #\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = spr[split][\"sequence\"], spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        shape_ids = [shape2id[t[0]] for t in seq]\n        color_ids = [color2id[t[1]] for t in seq]\n        cluster_ids = [tok2cluster[t] for t in seq]\n        return {\n            \"shape\": shape_ids,\n            \"color\": color_ids,\n            \"cluster\": cluster_ids,\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(x[\"shape\"]) for x in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\n# ---------- model ---------- #\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            -1,\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\n# ---------- evaluation helper ---------- #\ndef evaluate(model, loader, criterion):\n    model.eval()\n    all_preds, all_tgts, all_seqs = [], [], []\n    total_loss = 0.0\n    with torch.no_grad():\n        for batch in loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            total_loss += loss.item() * labels.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_tgts.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seqs\"])\n    avg_loss = total_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    swa = shape_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    gcwa = glyph_complexity_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    return avg_loss, {\"CWA\": cwa, \"SWA\": swa, \"GCWA\": gcwa}, all_preds, all_tgts\n\n\n# ---------- hyper-parameter sweep ---------- #\nbatch_sizes = [32, 64, 128, 256]\nepochs = 5\n\nfor bs in batch_sizes:\n    print(f\"\\n=== Training with batch size {bs} ===\")\n    # data loaders\n    train_loader = DataLoader(\n        SPRTorchDataset(\"train\"), batch_size=bs, shuffle=True, collate_fn=collate\n    )\n    dev_loader = DataLoader(\n        SPRTorchDataset(\"dev\"), batch_size=bs, shuffle=False, collate_fn=collate\n    )\n    test_loader = DataLoader(\n        SPRTorchDataset(\"test\"), batch_size=bs, shuffle=False, collate_fn=collate\n    )\n\n    # model / optim\n    model = GlyphModel(len(shapes), len(colors), n_clusters, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    # storage dict\n    exp_dict = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            optimizer.zero_grad()\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * labels.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        val_loss, val_metrics, _, _ = evaluate(model, dev_loader, criterion)\n\n        exp_dict[\"losses\"][\"train\"].append(train_loss)\n        exp_dict[\"losses\"][\"val\"].append(val_loss)\n        exp_dict[\"metrics\"][\"val\"].append(val_metrics)\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n            f\"CWA={val_metrics['CWA']:.3f} | SWA={val_metrics['SWA']:.3f} | GCWA={val_metrics['GCWA']:.3f}\"\n        )\n\n    # final test\n    test_loss, test_metrics, preds, tgts = evaluate(model, test_loader, criterion)\n    print(\n        f\"Test: loss={test_loss:.4f} | CWA={test_metrics['CWA']:.3f} | \"\n        f\"SWA={test_metrics['SWA']:.3f} | GCWA={test_metrics['GCWA']:.3f}\"\n    )\n\n    exp_dict[\"predictions\"] = preds\n    exp_dict[\"ground_truth\"] = tgts\n    exp_dict[\"metrics\"][\"test\"] = test_metrics\n\n    experiment_data[\"batch_size\"][\"SPR_BENCH\"][str(bs)] = exp_dict\n\n    # clean up\n    del model\n    torch.cuda.empty_cache()\n\n# ---------- persist all results ---------- #\nnp.save(\"experiment_data.npy\", experiment_data)\nprint(\"\\nSaved experiment data to experiment_data.npy\")\n", "import os, pathlib, random, json, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# --------------------------------- misc / folders -------------------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --------------------------------- device ---------------------------------------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ----------------------------- metrics utilities --------------------------------- #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# ------------------------------ data loading ------------------------------------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path):\n    if root.exists():\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synthetic():\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen(n):\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    d = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        d[split] = load_dataset(\n            \"json\", data_files={\"train\": [json.dumps(r) for r in gen(n)]}, split=\"train\"\n        )\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# ----------------------------- vocab & clustering ------------------------------- #\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in token_set], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(token_vecs)\ntok2cluster = {tok: int(cl) + 1 for tok, cl in zip(token_set, kmeans.labels_)}\n\n\n# -------------------------------- Dataset / Loader ------------------------------ #\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        shape_ids = [shape2id[t[0]] for t in seq]\n        color_ids = [color2id[t[1]] for t in seq]\n        cluster_ids = [tok2cluster[t] for t in seq]\n        return {\n            \"shape\": shape_ids,\n            \"color\": color_ids,\n            \"cluster\": cluster_ids,\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------------------------------- model --------------------------------------- #\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\n# -------------------------- training / evaluation utils ------------------------- #\ndef evaluate(model, loader, criterion):\n    model.eval()\n    all_preds, all_tgts, all_seqs = [], [], []\n    loss_sum = 0.0\n    with torch.no_grad():\n        for batch in loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss_sum += loss.item() * labels.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_tgts.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seqs\"])\n    avg_loss = loss_sum / len(loader.dataset)\n    metrics = {\n        \"CWA\": color_weighted_accuracy(all_seqs, all_tgts, all_preds),\n        \"SWA\": shape_weighted_accuracy(all_seqs, all_tgts, all_preds),\n        \"GCWA\": glyph_complexity_weighted_accuracy(all_seqs, all_tgts, all_preds),\n    }\n    return avg_loss, metrics, all_preds, all_tgts\n\n\n# ------------------------------ experiment dict --------------------------------- #\nexperiment_data = {\"embedding_dim_tuning\": {\"SPR_BENCH\": {}}}\n\n# ----------------------------- hyperparam search -------------------------------- #\nfor emb_dim in [4, 8, 16, 32, 64]:\n    print(f\"\\n=== Training with emb_dim={emb_dim} ===\")\n    model = GlyphModel(\n        len(shapes), len(colors), n_clusters, num_classes, emb_dim=emb_dim\n    ).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    subdict = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    epochs = 5\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            optimizer.zero_grad()\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * labels.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        val_loss, val_metrics, _, _ = evaluate(model, dev_loader, criterion)\n        subdict[\"losses\"][\"train\"].append(train_loss)\n        subdict[\"losses\"][\"val\"].append(val_loss)\n        subdict[\"metrics\"][\"train\"].append(\n            {}\n        )  # placeholders (train metrics not computed)\n        subdict[\"metrics\"][\"val\"].append(val_metrics)\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n            f\"CWA={val_metrics['CWA']:.3f} | SWA={val_metrics['SWA']:.3f} | GCWA={val_metrics['GCWA']:.3f}\"\n        )\n    # final test evaluation\n    test_loss, test_metrics, test_preds, test_tgts = evaluate(\n        model, test_loader, criterion\n    )\n    subdict[\"losses\"][\"test\"] = test_loss\n    subdict[\"metrics\"][\"test\"] = test_metrics\n    subdict[\"predictions\"] = test_preds\n    subdict[\"ground_truth\"] = test_tgts\n    experiment_data[\"embedding_dim_tuning\"][\"SPR_BENCH\"][f\"emb_dim_{emb_dim}\"] = subdict\n    # cleanup\n    del model\n    torch.cuda.empty_cache()\n    print(\n        f\"Test (emb_dim={emb_dim}): loss={test_loss:.4f} | \"\n        f\"CWA={test_metrics['CWA']:.3f} | SWA={test_metrics['SWA']:.3f} | GCWA={test_metrics['GCWA']:.3f}\"\n    )\n\n# ---------------------------------- persist ------------------------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, json, warnings, time\n\nwarnings.filterwarnings(\"ignore\")\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- basic imports ----------\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- reproducibility ----------\ndef set_seed(sd=0):\n    random.seed(sd)\n    np.random.seed(sd)\n    torch.manual_seed(sd)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(sd)\n\n\nset_seed(0)\n\n\n# ---------- metric helpers ----------\ndef count_color_variety(sequence: str) -> int:\n    return len({tok[1] for tok in sequence.strip().split() if len(tok) > 1})\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len({tok[0] for tok in sequence.strip().split() if tok})\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# ---------- data loading ----------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path) -> DatasetDict | None:\n    if root.exists():\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synthetic() -> DatasetDict:\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen_split(n):\n        return [\n            {\n                \"id\": i,\n                \"sequence\": \" \".join(\n                    random.choice(shapes) + random.choice(colors)\n                    for _ in range(random.randint(3, 9))\n                ),\n                \"label\": random.randint(0, 3),\n            }\n            for i in range(n)\n        ]\n\n    d = DatasetDict()\n    for sp, n in zip([\"train\", \"dev\", \"test\"], [2000, 400, 400]):\n        tmp_json_path = working_dir + f\"/tmp_{sp}.jsonl\"\n        with open(tmp_json_path, \"w\") as f:\n            for rec in gen_split(n):\n                f.write(json.dumps(rec) + \"\\n\")\n        d[sp] = load_dataset(\"json\", data_files=tmp_json_path, split=\"train\")\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# ---------- token \u2192 id maps & clustering ----------\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 reserved for pad\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array([[shape2id[t[0]], color2id[t[1]]] for t in token_set], float)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\ntok2cluster = {\n    tok: int(c) + 1\n    for tok, c in zip(\n        token_set, KMeans(n_clusters, random_state=0).fit(token_vecs).labels_\n    )\n}\n\n\n# ---------- torch dataset ----------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        parts = self.seqs[idx].split()\n        return {\n            \"shape\": [shape2id[p[0]] for p in parts],\n            \"color\": [color2id[p[1]] for p in parts],\n            \"cluster\": [tok2cluster[p] for p in parts],\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ----------\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )  # (B,L,3*emb)\n        masked_sum = (e * mask.unsqueeze(-1)).sum(1)  # (B,3*emb)\n        lengths = mask.sum(1, keepdim=True).clamp(min=1e-6)  # (B,1)\n        pooled = masked_sum / lengths  # (B,3*emb)\n        return self.ff(pooled)\n\n\n# ---------- evaluation ----------\n@torch.no_grad()\ndef evaluate(model, loader, criterion):\n    model.eval()\n    tot_loss, preds, tgts, seqs = 0.0, [], [], []\n    for batch in loader:\n        # move to device\n        tensor_batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        logits = model(\n            tensor_batch[\"shape\"],\n            tensor_batch[\"color\"],\n            tensor_batch[\"cluster\"],\n            tensor_batch[\"mask\"],\n        )\n        loss = criterion(logits, tensor_batch[\"labels\"])\n        tot_loss += loss.item() * tensor_batch[\"labels\"].size(0)\n        pred = logits.argmax(1).cpu().tolist()\n        preds.extend(pred)\n        tgts.extend(tensor_batch[\"labels\"].cpu().tolist())\n        seqs.extend(batch[\"seqs\"])\n    avg_loss = tot_loss / len(loader.dataset)\n    metrics = {\n        \"CWA\": color_weighted_accuracy(seqs, tgts, preds),\n        \"SWA\": shape_weighted_accuracy(seqs, tgts, preds),\n        \"GCWA\": glyph_complexity_weighted_accuracy(seqs, tgts, preds),\n    }\n    return avg_loss, metrics, preds, tgts\n\n\n# ---------- experiment data ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": [], \"test\": []},\n        \"losses\": {\"train\": [], \"val\": [], \"test\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"hyperparams\": [],\n    }\n}\n\n# ---------- hyperparameter sweep ----------\nlearning_rates = [3e-4, 1e-4, 3e-5]  # reduced for runtime\nepochs = 3\nbest_idx, best_gcwa = -1, -1.0\n\nfor run_idx, lr in enumerate(learning_rates):\n    print(f\"\\n===== training run {run_idx+1} | lr={lr:.1e} =====\")\n    set_seed(run_idx)\n    model = GlyphModel(len(shapes), len(colors), n_clusters, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    train_losses, val_losses, val_metrics_hist = [], [], []\n    for epoch in range(1, epochs + 1):\n        model.train()\n        ep_loss = 0.0\n        for batch in train_loader:\n            tensor_batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(\n                tensor_batch[\"shape\"],\n                tensor_batch[\"color\"],\n                tensor_batch[\"cluster\"],\n                tensor_batch[\"mask\"],\n            )\n            loss = criterion(logits, tensor_batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            ep_loss += loss.item() * tensor_batch[\"labels\"].size(0)\n        train_loss = ep_loss / len(train_loader.dataset)\n\n        val_loss, val_m, _, _ = evaluate(model, dev_loader, criterion)\n        print(\n            f\"Epoch {epoch}/{epochs} | train_loss={train_loss:.4f} | \"\n            f\"val_loss={val_loss:.4f} | CWA={val_m['CWA']:.3f} | \"\n            f\"SWA={val_m['SWA']:.3f} | GCWA={val_m['GCWA']:.3f}\"\n        )\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        val_metrics_hist.append(val_m)\n\n    # choose best by dev GCWA after final epoch\n    final_gcwa = val_metrics_hist[-1][\"GCWA\"]\n    if final_gcwa > best_gcwa:\n        best_gcwa, best_idx = final_gcwa, run_idx\n\n    # evaluate on test set\n    test_loss, test_m, test_preds, test_tgts = evaluate(model, test_loader, criterion)\n    print(\n        f\"Test | loss={test_loss:.4f} | CWA={test_m['CWA']:.3f} | \"\n        f\"SWA={test_m['SWA']:.3f} | GCWA={test_m['GCWA']:.3f}\"\n    )\n\n    # store experiment data\n    ed = experiment_data[\"SPR_BENCH\"]\n    ed[\"metrics\"][\"train\"].append([])  # train metrics per-batch omitted\n    ed[\"metrics\"][\"val\"].append(val_metrics_hist)\n    ed[\"metrics\"][\"test\"].append(test_m)\n    ed[\"losses\"][\"train\"].append(train_losses)\n    ed[\"losses\"][\"val\"].append(val_losses)\n    ed[\"losses\"][\"test\"].append(test_loss)\n    ed[\"predictions\"].append(test_preds)\n    ed[\"ground_truth\"].append(test_tgts)\n    ed[\"hyperparams\"].append({\"learning_rate\": lr, \"epochs\": epochs})\n\nprint(\n    f\"\\nBest learning rate: {learning_rates[best_idx]:.1e} \"\n    f\"with dev GCWA {best_gcwa:.3f}\"\n)\n\n# ---------- persist ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", working_dir)\n", "import os, pathlib, random, json, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# -------------------- misc / reproducibility -------------------- #\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# -------------------- helper metrics -------------------- #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wt for wt, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wt for wt, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wt for wt, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# -------------------- data loading (official or synthetic) -------------------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path):\n    if root.exists():\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synthetic():\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen(n):\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    return DatasetDict(\n        {\n            sp: load_dataset(\n                \"json\",\n                data_files={\n                    \"train\": [json.dumps(r) for r in gen(500 if sp == \"train\" else 100)]\n                },\n                split=\"train\",\n            )\n            for sp in [\"train\", \"dev\", \"test\"]\n        }\n    )\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# -------------------- vocab & clustering -------------------- #\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in sorted(set(all_tokens))], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(token_vecs)\ntok2cluster = {\n    tok: int(c) + 1 for tok, c in zip(sorted(set(all_tokens)), kmeans.labels_)\n}\n\n\n# -------------------- torch dataset -------------------- #\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        return {\n            \"shape\": [shape2id[t[0]] for t in seq],\n            \"color\": [color2id[t[1]] for t in seq],\n            \"cluster\": [tok2cluster[t] for t in seq],\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nbatch_size = 128\ntrain_loader = lambda: DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# -------------------- model def -------------------- #\nclass GlyphModel(nn.Module):\n    def __init__(\n        self, n_shape, n_color, n_cluster, num_classes, emb_dim=8, hidden_dim=64\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, num_classes),\n        )\n\n    def forward(self, s, c, k, mask):\n        e = torch.cat(\n            [self.shape_emb(s), self.color_emb(c), self.cluster_emb(k)], dim=-1\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\n# -------------------- train / eval helpers -------------------- #\ndef evaluate(model, loader, criterion):\n    model.eval()\n    tot_loss, all_p, all_t, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for b in loader:\n            s, c, k = (\n                b[\"shape\"].to(device),\n                b[\"color\"].to(device),\n                b[\"cluster\"].to(device),\n            )\n            m = b[\"mask\"].to(device)\n            labels = b[\"labels\"].to(device)\n            logits = model(s, c, k, m)\n            loss = criterion(logits, labels)\n            tot_loss += loss.item() * labels.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_p.extend(preds)\n            all_t.extend(labels.cpu().tolist())\n            seqs.extend(b[\"seqs\"])\n    l = tot_loss / len(loader.dataset)\n    return (\n        l,\n        {\n            \"CWA\": color_weighted_accuracy(seqs, all_t, all_p),\n            \"SWA\": shape_weighted_accuracy(seqs, all_t, all_p),\n            \"GCWA\": glyph_complexity_weighted_accuracy(seqs, all_t, all_p),\n        },\n        all_p,\n        all_t,\n    )\n\n\n# -------------------- hyperparameter sweep -------------------- #\nhidden_dims = [32, 64, 128, 256]\nepochs = 5\nexperiment_data = {\n    \"hidden_dim\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": {}, \"val\": {}, \"test\": {}},\n            \"losses\": {\"train\": {}, \"val\": {}, \"test\": {}},\n            \"predictions\": {},\n            \"ground_truth\": {},\n        }\n    }\n}\n\nfor hd in hidden_dims:\n    print(f\"\\n----- Training with hidden_dim={hd} -----\")\n    model = GlyphModel(\n        len(shapes), len(colors), n_clusters, num_classes, hidden_dim=hd\n    ).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n\n    tr_losses, val_losses, train_metrics, val_metrics = [], [], [], []\n    for epoch in range(1, epochs + 1):\n        model.train()\n        run_loss = 0.0\n        for batch in train_loader():\n            s, c, k = (\n                batch[\"shape\"].to(device),\n                batch[\"color\"].to(device),\n                batch[\"cluster\"].to(device),\n            )\n            m = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            optimizer.zero_grad()\n            logits = model(s, c, k, m)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n            run_loss += loss.item() * labels.size(0)\n        train_loss = run_loss / len(spr[\"train\"])\n        val_loss, val_metric, _, _ = evaluate(model, dev_loader, criterion)\n        tr_losses.append(train_loss)\n        val_losses.append(val_loss)\n        train_metrics.append(val_metric)  # storing same type for consistency\n        val_metrics.append(val_metric)\n        print(\n            f\"Epoch {epoch}/{epochs}  train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n            f\"CWA={val_metric['CWA']:.3f} SWA={val_metric['SWA']:.3f} GCWA={val_metric['GCWA']:.3f}\"\n        )\n\n    # final test\n    test_loss, test_metric, test_preds, test_gts = evaluate(\n        model, test_loader, criterion\n    )\n    print(\n        f\"TEST  loss={test_loss:.4f}  CWA={test_metric['CWA']:.3f}  \"\n        f\"SWA={test_metric['SWA']:.3f}  GCWA={test_metric['GCWA']:.3f}\"\n    )\n\n    # store\n    ed = experiment_data[\"hidden_dim\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"][hd] = tr_losses\n    ed[\"losses\"][\"val\"][hd] = val_losses\n    ed[\"metrics\"][\"train\"][hd] = train_metrics\n    ed[\"metrics\"][\"val\"][hd] = val_metrics\n    ed[\"metrics\"][\"test\"][hd] = test_metric\n    ed[\"losses\"][\"test\"][hd] = test_loss\n    ed[\"predictions\"][hd] = test_preds\n    ed[\"ground_truth\"][hd] = test_gts\n\n# -------------------- save all -------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nAll results saved to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, json, time\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# ---------- paths ---------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- global exp dict ---------- #\nexperiment_data = {\"weight_decay\": {}}  # will fill per wd value\n\n# ---------- utils ---------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Running on\", device)\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)) / max(\n        sum(w), 1\n    )\n\n\n# ---------- data ---------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path) -> DatasetDict | None:\n    if root.exists():\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        out = DatasetDict()\n        for sp in [\"train\", \"dev\", \"test\"]:\n            out[sp] = _load(f\"{sp}.csv\")\n        return out\n    return None\n\n\ndef build_synthetic() -> DatasetDict:\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen(n):\n        rows = []\n        for i in range(n):\n            ln = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(ln)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    d = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        txt = [json.dumps(r) for r in gen(n)]\n        d[split] = load_dataset(\"json\", data_files={\"train\": txt}, split=\"train\")\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# vocab & clustering (shared across runs)\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in token_set], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\ntok2cluster = {\n    tok: int(c) + 1\n    for tok, c in zip(\n        token_set, KMeans(n_clusters, random_state=0).fit(token_vecs).labels_\n    )\n}\n\n\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seq, self.lab = spr[split][\"sequence\"], spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.lab)\n\n    def __getitem__(self, idx):\n        seq = self.seq[idx].split()\n        return {\n            \"shape\": [shape2id[t[0]] for t in seq],\n            \"color\": [color2id[t[1]] for t in seq],\n            \"cluster\": [tok2cluster[t] for t in seq],\n            \"label\": self.lab[idx],\n            \"seq_str\": self.seq[idx],\n        }\n\n\ndef collate(batch):\n    L = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (L - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    out = {\n        \"shape\": pad(\"shape\"),\n        \"color\": pad(\"color\"),\n        \"cluster\": pad(\"cluster\"),\n        \"mask\": (pad(\"shape\") != 0).float(),\n        \"labels\": torch.tensor([b[\"label\"] for b in batch], dtype=torch.long),\n        \"seqs\": [b[\"seq_str\"] for b in batch],\n    }\n    return out\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size, True, collate_fn=collate\n)\ndev_loader = DataLoader(SPRTorchDataset(\"dev\"), batch_size, False, collate_fn=collate)\ntest_loader = DataLoader(SPRTorchDataset(\"test\"), batch_size, False, collate_fn=collate)\n\n\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, n_cls, emb=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb, padding_idx=0)\n        self.ff = nn.Sequential(nn.Linear(emb * 3, 64), nn.ReLU(), nn.Linear(64, n_cls))\n\n    def forward(self, shp, clr, clust, mask):\n        e = torch.cat(\n            [self.shape_emb(shp), self.color_emb(clr), self.cluster_emb(clust)], dim=-1\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\ndef evaluate(mod, loader, criterion):\n    mod.eval()\n    tot_loss, preds, tgts, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for b in loader:\n            shp, clr, clu, msk = (\n                b[\"shape\"].to(device),\n                b[\"color\"].to(device),\n                b[\"cluster\"].to(device),\n                b[\"mask\"].to(device),\n            )\n            lbl = b[\"labels\"].to(device)\n            logit = mod(shp, clr, clu, msk)\n            loss = criterion(logit, lbl)\n            tot_loss += loss.item() * lbl.size(0)\n            p = logit.argmax(1).cpu().tolist()\n            preds += p\n            tgts += lbl.cpu().tolist()\n            seqs += b[\"seqs\"]\n    avg = tot_loss / len(loader.dataset)\n    return (\n        avg,\n        {\n            \"CWA\": color_weighted_accuracy(seqs, tgts, preds),\n            \"SWA\": shape_weighted_accuracy(seqs, tgts, preds),\n            \"GCWA\": glyph_complexity_weighted_accuracy(seqs, tgts, preds),\n        },\n        preds,\n        tgts,\n    )\n\n\n# ---------- sweep ---------- #\nweight_decays = [0.0, 1e-5, 1e-4, 1e-3]\nepochs = 5\n\nfor wd in weight_decays:\n    key = str(wd)\n    print(f\"\\n=== Training with weight_decay={wd} ===\")\n    experiment_data[\"weight_decay\"][key] = {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n    model = GlyphModel(len(shapes), len(colors), n_clusters, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=wd)\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        run_loss = 0.0\n        for b in train_loader:\n            shp, clr, clu, msk = (\n                b[\"shape\"].to(device),\n                b[\"color\"].to(device),\n                b[\"cluster\"].to(device),\n                b[\"mask\"].to(device),\n            )\n            lbl = b[\"labels\"].to(device)\n            optimizer.zero_grad()\n            logit = model(shp, clr, clu, msk)\n            loss = criterion(logit, lbl)\n            loss.backward()\n            optimizer.step()\n            run_loss += loss.item() * lbl.size(0)\n        train_loss = run_loss / len(train_loader.dataset)\n\n        val_loss, val_metrics, _, _ = evaluate(model, dev_loader, criterion)\n        ed = experiment_data[\"weight_decay\"][key][\"SPR_BENCH\"]\n        ed[\"losses\"][\"train\"].append(train_loss)\n        ed[\"losses\"][\"val\"].append(val_loss)\n        ed[\"metrics\"][\"val\"].append(val_metrics)\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n            f\"CWA={val_metrics['CWA']:.3f} | SWA={val_metrics['SWA']:.3f} | GCWA={val_metrics['GCWA']:.3f}\"\n        )\n\n    # final test\n    test_loss, test_metrics, preds, tgts = evaluate(model, test_loader, criterion)\n    ed[\"metrics\"][\"test\"] = test_metrics\n    ed[\"predictions\"], ed[\"ground_truth\"] = preds, tgts\n    print(\n        f\"Test: loss={test_loss:.4f} | CWA={test_metrics['CWA']:.3f} | \"\n        f\"SWA={test_metrics['SWA']:.3f} | GCWA={test_metrics['GCWA']:.3f}\"\n    )\n\n# ---------- save ---------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, random, json, time, warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# ---------------- basic setup ---------------- #\nimport numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n\n# --------------- metrics utils --------------- #\ndef count_color_variety(sequence: str):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef cwa(seqs, y, p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum([wt if t == pr else 0 for wt, t, pr in zip(w, y, p)]) / max(sum(w), 1)\n\n\ndef swa(seqs, y, p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum([wt if t == pr else 0 for wt, t, pr in zip(w, y, p)]) / max(sum(w), 1)\n\n\ndef gcwa(seqs, y, p):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum([wt if t == pr else 0 for wt, t, pr in zip(w, y, p)]) / max(sum(w), 1)\n\n\n# --------------- data ------------------------ #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path):\n    if root.exists():\n\n        def _load(csv):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synth():\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen(n):\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    d = DatasetDict()\n    for sp, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        d[sp] = load_dataset(\n            \"json\", data_files={sp: [json.dumps(r) for r in gen(n)]}, split=\"train\"\n        )\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synth()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# vocab & clustering\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in sorted(set(all_tokens))], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=SEED).fit(token_vecs)\ntok2cluster = {\n    tok: int(c) + 1 for tok, c in zip(sorted(set(all_tokens)), kmeans.labels_)\n}\n\n\n# dataset class\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        sid = [shape2id[t[0]] for t in seq]\n        cid = [color2id[t[1]] for t in seq]\n        clid = [tok2cluster[t] for t in seq]\n        return {\n            \"shape\": sid,\n            \"color\": cid,\n            \"cluster\": clid,\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    L = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (L - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch])\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nbatch_size = 128\ntrain_loader = lambda: DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# --------------- model ----------------------- #\nclass GlyphModel(nn.Module):\n    def __init__(\n        self, n_shape, n_color, n_cluster, num_classes, emb_dim=8, dropout_rate=0.3\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        pooled = self.dropout(pooled)\n        return self.ff(pooled)\n\n\n# -------------- training / eval utils ------- #\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    all_preds, all_tgts, all_seqs = [], [], []\n    total_loss = 0.0\n    with torch.no_grad():\n        for batch in loader:\n            shp, col, clu, msk = [\n                batch[k].to(device) for k in [\"shape\", \"color\", \"cluster\", \"mask\"]\n            ]\n            lbl = batch[\"labels\"].to(device)\n            logits = model(shp, col, clu, msk)\n            loss = criterion(logits, lbl)\n            total_loss += loss.item() * lbl.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_tgts.extend(lbl.cpu().tolist())\n            all_seqs.extend(batch[\"seqs\"])\n    avg_loss = total_loss / len(loader.dataset)\n    return (\n        avg_loss,\n        {\n            \"CWA\": cwa(all_seqs, all_tgts, all_preds),\n            \"SWA\": swa(all_seqs, all_tgts, all_preds),\n            \"GCWA\": gcwa(all_seqs, all_tgts, all_preds),\n        },\n        all_preds,\n        all_tgts,\n    )\n\n\n# -------------- hyper-parameter sweep -------- #\ndropout_grid = [0.1, 0.2, 0.3, 0.4, 0.5]\nexperiment_data = {\"dropout_rate\": {}}\nbest_gcwa, best_rate = -1.0, None\n\nfor p in dropout_grid:\n    print(f\"\\n=== training with dropout={p} ===\")\n    model = GlyphModel(\n        len(shapes), len(colors), n_clusters, num_classes, dropout_rate=p\n    ).to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n    edict = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for epoch in range(1, 6):\n        model.train()\n        running = 0.0\n        for batch in train_loader():\n            shp, col, clu, msk = [\n                batch[k].to(device) for k in [\"shape\", \"color\", \"cluster\", \"mask\"]\n            ]\n            lbl = batch[\"labels\"].to(device)\n            optim.zero_grad()\n            loss = criterion(model(shp, col, clu, msk), lbl)\n            loss.backward()\n            optim.step()\n            running += loss.item() * lbl.size(0)\n        train_loss = running / len(spr[\"train\"])\n        val_loss, val_m, _, _ = evaluate(model, dev_loader)\n        edict[\"losses\"][\"train\"].append(train_loss)\n        edict[\"losses\"][\"val\"].append(val_loss)\n        edict[\"metrics\"][\"val\"].append(val_m)\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"CWA={val_m['CWA']:.3f} SWA={val_m['SWA']:.3f} GCWA={val_m['GCWA']:.3f}\"\n        )\n    # final test with this dropout\n    t_loss, t_metrics, t_preds, t_tgts = evaluate(model, test_loader)\n    edict[\"predictions\"] = t_preds\n    edict[\"ground_truth\"] = t_tgts\n    edict[\"metrics\"][\"test\"] = t_metrics\n    experiment_data[\"dropout_rate\"][p] = {\"SPR_BENCH\": edict}\n    if val_m[\"GCWA\"] > best_gcwa:\n        best_gcwa = val_m[\"GCWA\"]\n        best_rate = p\n        best_test = t_metrics\n\nprint(f\"\\nBest dropout={best_rate:.2f} | Dev GCWA={best_gcwa:.3f}\")\nprint(\n    f\"Test metrics @ best dropout: CWA={best_test['CWA']:.3f} SWA={best_test['SWA']:.3f} GCWA={best_test['GCWA']:.3f}\"\n)\n\n# -------------- persist ---------------------- #\nnp.save(\"experiment_data.npy\", experiment_data)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, json, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# --------------------------------- misc / folders -------------------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --------------------------------- device ---------------------------------------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ----------------------------- metrics utilities --------------------------------- #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# ------------------------------ data loading ------------------------------------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path):\n    if root.exists():\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synthetic():\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen(n):\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    d = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        d[split] = load_dataset(\n            \"json\", data_files={\"train\": [json.dumps(r) for r in gen(n)]}, split=\"train\"\n        )\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# ----------------------------- vocab & clustering ------------------------------- #\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in token_set], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(token_vecs)\ntok2cluster = {tok: int(cl) + 1 for tok, cl in zip(token_set, kmeans.labels_)}\n\n\n# -------------------------------- Dataset / Loader ------------------------------ #\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        shape_ids = [shape2id[t[0]] for t in seq]\n        color_ids = [color2id[t[1]] for t in seq]\n        cluster_ids = [tok2cluster[t] for t in seq]\n        return {\n            \"shape\": shape_ids,\n            \"color\": color_ids,\n            \"cluster\": cluster_ids,\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------------------------------- model --------------------------------------- #\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\n# -------------------------- training / evaluation utils ------------------------- #\ndef evaluate(model, loader, criterion):\n    model.eval()\n    all_preds, all_tgts, all_seqs = [], [], []\n    loss_sum = 0.0\n    with torch.no_grad():\n        for batch in loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss_sum += loss.item() * labels.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_tgts.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seqs\"])\n    avg_loss = loss_sum / len(loader.dataset)\n    metrics = {\n        \"CWA\": color_weighted_accuracy(all_seqs, all_tgts, all_preds),\n        \"SWA\": shape_weighted_accuracy(all_seqs, all_tgts, all_preds),\n        \"GCWA\": glyph_complexity_weighted_accuracy(all_seqs, all_tgts, all_preds),\n    }\n    return avg_loss, metrics, all_preds, all_tgts\n\n\n# ------------------------------ experiment dict --------------------------------- #\nexperiment_data = {\"embedding_dim_tuning\": {\"SPR_BENCH\": {}}}\n\n# ----------------------------- hyperparam search -------------------------------- #\nfor emb_dim in [4, 8, 16, 32, 64]:\n    print(f\"\\n=== Training with emb_dim={emb_dim} ===\")\n    model = GlyphModel(\n        len(shapes), len(colors), n_clusters, num_classes, emb_dim=emb_dim\n    ).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    subdict = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    epochs = 5\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            optimizer.zero_grad()\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * labels.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        val_loss, val_metrics, _, _ = evaluate(model, dev_loader, criterion)\n        subdict[\"losses\"][\"train\"].append(train_loss)\n        subdict[\"losses\"][\"val\"].append(val_loss)\n        subdict[\"metrics\"][\"train\"].append(\n            {}\n        )  # placeholders (train metrics not computed)\n        subdict[\"metrics\"][\"val\"].append(val_metrics)\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n            f\"CWA={val_metrics['CWA']:.3f} | SWA={val_metrics['SWA']:.3f} | GCWA={val_metrics['GCWA']:.3f}\"\n        )\n    # final test evaluation\n    test_loss, test_metrics, test_preds, test_tgts = evaluate(\n        model, test_loader, criterion\n    )\n    subdict[\"losses\"][\"test\"] = test_loss\n    subdict[\"metrics\"][\"test\"] = test_metrics\n    subdict[\"predictions\"] = test_preds\n    subdict[\"ground_truth\"] = test_tgts\n    experiment_data[\"embedding_dim_tuning\"][\"SPR_BENCH\"][f\"emb_dim_{emb_dim}\"] = subdict\n    # cleanup\n    del model\n    torch.cuda.empty_cache()\n    print(\n        f\"Test (emb_dim={emb_dim}): loss={test_loss:.4f} | \"\n        f\"CWA={test_metrics['CWA']:.3f} | SWA={test_metrics['SWA']:.3f} | GCWA={test_metrics['GCWA']:.3f}\"\n    )\n\n# ---------------------------------- persist ------------------------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, json, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# --------------------------------- misc / folders -------------------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --------------------------------- device ---------------------------------------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ----------------------------- metrics utilities --------------------------------- #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# ------------------------------ data loading ------------------------------------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path):\n    if root.exists():\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synthetic():\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen(n):\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    d = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        d[split] = load_dataset(\n            \"json\", data_files={\"train\": [json.dumps(r) for r in gen(n)]}, split=\"train\"\n        )\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# ----------------------------- vocab & clustering ------------------------------- #\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in token_set], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(token_vecs)\ntok2cluster = {tok: int(cl) + 1 for tok, cl in zip(token_set, kmeans.labels_)}\n\n\n# -------------------------------- Dataset / Loader ------------------------------ #\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        shape_ids = [shape2id[t[0]] for t in seq]\n        color_ids = [color2id[t[1]] for t in seq]\n        cluster_ids = [tok2cluster[t] for t in seq]\n        return {\n            \"shape\": shape_ids,\n            \"color\": color_ids,\n            \"cluster\": cluster_ids,\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------------------------------- model --------------------------------------- #\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\n# -------------------------- training / evaluation utils ------------------------- #\ndef evaluate(model, loader, criterion):\n    model.eval()\n    all_preds, all_tgts, all_seqs = [], [], []\n    loss_sum = 0.0\n    with torch.no_grad():\n        for batch in loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss_sum += loss.item() * labels.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_tgts.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seqs\"])\n    avg_loss = loss_sum / len(loader.dataset)\n    metrics = {\n        \"CWA\": color_weighted_accuracy(all_seqs, all_tgts, all_preds),\n        \"SWA\": shape_weighted_accuracy(all_seqs, all_tgts, all_preds),\n        \"GCWA\": glyph_complexity_weighted_accuracy(all_seqs, all_tgts, all_preds),\n    }\n    return avg_loss, metrics, all_preds, all_tgts\n\n\n# ------------------------------ experiment dict --------------------------------- #\nexperiment_data = {\"embedding_dim_tuning\": {\"SPR_BENCH\": {}}}\n\n# ----------------------------- hyperparam search -------------------------------- #\nfor emb_dim in [4, 8, 16, 32, 64]:\n    print(f\"\\n=== Training with emb_dim={emb_dim} ===\")\n    model = GlyphModel(\n        len(shapes), len(colors), n_clusters, num_classes, emb_dim=emb_dim\n    ).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    subdict = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    epochs = 5\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            optimizer.zero_grad()\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * labels.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        val_loss, val_metrics, _, _ = evaluate(model, dev_loader, criterion)\n        subdict[\"losses\"][\"train\"].append(train_loss)\n        subdict[\"losses\"][\"val\"].append(val_loss)\n        subdict[\"metrics\"][\"train\"].append(\n            {}\n        )  # placeholders (train metrics not computed)\n        subdict[\"metrics\"][\"val\"].append(val_metrics)\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n            f\"CWA={val_metrics['CWA']:.3f} | SWA={val_metrics['SWA']:.3f} | GCWA={val_metrics['GCWA']:.3f}\"\n        )\n    # final test evaluation\n    test_loss, test_metrics, test_preds, test_tgts = evaluate(\n        model, test_loader, criterion\n    )\n    subdict[\"losses\"][\"test\"] = test_loss\n    subdict[\"metrics\"][\"test\"] = test_metrics\n    subdict[\"predictions\"] = test_preds\n    subdict[\"ground_truth\"] = test_tgts\n    experiment_data[\"embedding_dim_tuning\"][\"SPR_BENCH\"][f\"emb_dim_{emb_dim}\"] = subdict\n    # cleanup\n    del model\n    torch.cuda.empty_cache()\n    print(\n        f\"Test (emb_dim={emb_dim}): loss={test_loss:.4f} | \"\n        f\"CWA={test_metrics['CWA']:.3f} | SWA={test_metrics['SWA']:.3f} | GCWA={test_metrics['GCWA']:.3f}\"\n    )\n\n# ---------------------------------- persist ------------------------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, json, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# --------------------------------- misc / folders -------------------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --------------------------------- device ---------------------------------------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ----------------------------- metrics utilities --------------------------------- #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# ------------------------------ data loading ------------------------------------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path):\n    if root.exists():\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synthetic():\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen(n):\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    d = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        d[split] = load_dataset(\n            \"json\", data_files={\"train\": [json.dumps(r) for r in gen(n)]}, split=\"train\"\n        )\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# ----------------------------- vocab & clustering ------------------------------- #\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in token_set], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(token_vecs)\ntok2cluster = {tok: int(cl) + 1 for tok, cl in zip(token_set, kmeans.labels_)}\n\n\n# -------------------------------- Dataset / Loader ------------------------------ #\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        shape_ids = [shape2id[t[0]] for t in seq]\n        color_ids = [color2id[t[1]] for t in seq]\n        cluster_ids = [tok2cluster[t] for t in seq]\n        return {\n            \"shape\": shape_ids,\n            \"color\": color_ids,\n            \"cluster\": cluster_ids,\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------------------------------- model --------------------------------------- #\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\n# -------------------------- training / evaluation utils ------------------------- #\ndef evaluate(model, loader, criterion):\n    model.eval()\n    all_preds, all_tgts, all_seqs = [], [], []\n    loss_sum = 0.0\n    with torch.no_grad():\n        for batch in loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss_sum += loss.item() * labels.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_tgts.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seqs\"])\n    avg_loss = loss_sum / len(loader.dataset)\n    metrics = {\n        \"CWA\": color_weighted_accuracy(all_seqs, all_tgts, all_preds),\n        \"SWA\": shape_weighted_accuracy(all_seqs, all_tgts, all_preds),\n        \"GCWA\": glyph_complexity_weighted_accuracy(all_seqs, all_tgts, all_preds),\n    }\n    return avg_loss, metrics, all_preds, all_tgts\n\n\n# ------------------------------ experiment dict --------------------------------- #\nexperiment_data = {\"embedding_dim_tuning\": {\"SPR_BENCH\": {}}}\n\n# ----------------------------- hyperparam search -------------------------------- #\nfor emb_dim in [4, 8, 16, 32, 64]:\n    print(f\"\\n=== Training with emb_dim={emb_dim} ===\")\n    model = GlyphModel(\n        len(shapes), len(colors), n_clusters, num_classes, emb_dim=emb_dim\n    ).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    subdict = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    epochs = 5\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            optimizer.zero_grad()\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * labels.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        val_loss, val_metrics, _, _ = evaluate(model, dev_loader, criterion)\n        subdict[\"losses\"][\"train\"].append(train_loss)\n        subdict[\"losses\"][\"val\"].append(val_loss)\n        subdict[\"metrics\"][\"train\"].append(\n            {}\n        )  # placeholders (train metrics not computed)\n        subdict[\"metrics\"][\"val\"].append(val_metrics)\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n            f\"CWA={val_metrics['CWA']:.3f} | SWA={val_metrics['SWA']:.3f} | GCWA={val_metrics['GCWA']:.3f}\"\n        )\n    # final test evaluation\n    test_loss, test_metrics, test_preds, test_tgts = evaluate(\n        model, test_loader, criterion\n    )\n    subdict[\"losses\"][\"test\"] = test_loss\n    subdict[\"metrics\"][\"test\"] = test_metrics\n    subdict[\"predictions\"] = test_preds\n    subdict[\"ground_truth\"] = test_tgts\n    experiment_data[\"embedding_dim_tuning\"][\"SPR_BENCH\"][f\"emb_dim_{emb_dim}\"] = subdict\n    # cleanup\n    del model\n    torch.cuda.empty_cache()\n    print(\n        f\"Test (emb_dim={emb_dim}): loss={test_loss:.4f} | \"\n        f\"CWA={test_metrics['CWA']:.3f} | SWA={test_metrics['SWA']:.3f} | GCWA={test_metrics['GCWA']:.3f}\"\n    )\n\n# ---------------------------------- persist ------------------------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 385986.59\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 230704.71\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 251919.23\nexamples/s]', '\\n', 'Traceback (most recent call last):\\n  File \"runfile.py\",\nline 245, in <module>\\n    logits = model(shapes, colors, clusters, mask)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\\n\nreturn self._call_impl(*args, **kwargs)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/module.py\", line 1747, in _call_impl\\n    return\nforward_call(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"runfile.py\", line 192, in forward\\n    pooled = (e * mask.unsqueeze(-1)).sum(1)\n/ mask.sum(1)\\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~\\nRuntimeError: The size of tensor\na (24) must match the size of tensor b (128) at non-singleton dimension 1\\n',\n'Execution time: 3 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 20000 examples [00:00,\n445482.20 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 193755.55\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 495107.60\nexamples/s]', '\\n', '\\n===== training with lr=3.0e-04 =====', '\\n', 'Traceback\n(most recent call last):\\n  File \"runfile.py\", line 258, in <module>\\n    logits\n= model(s, c, l, mask)\\n             ^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\\n\nreturn self._call_impl(*args, **kwargs)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/module.py\", line 1747, in _call_impl\\n    return\nforward_call(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"runfile.py\", line 186, in forward\\n    pooled = (e * mask.unsqueeze(-1)).sum(1)\n/ mask.sum(1)\\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~\\nRuntimeError: The size of tensor\na (24) must match the size of tensor b (128) at non-singleton dimension 1\\n',\n'Execution time: 3 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 20000 examples [00:00,\n404857.55 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 199669.81\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 609965.24\nexamples/s]', '\\n', '\\n=== Training with batch size 32 ===', '\\n', 'Epoch 1:\ntrain_loss=0.3862 | val_loss=0.2423 | CWA=0.917 | SWA=0.915 | GCWA=0.913', '\\n',\n'Epoch 2: train_loss=0.2202 | val_loss=0.2068 | CWA=0.936 | SWA=0.933 |\nGCWA=0.930', '\\n', 'Epoch 3: train_loss=0.1992 | val_loss=0.1981 | CWA=0.938 |\nSWA=0.935 | GCWA=0.932', '\\n', 'Epoch 4: train_loss=0.1921 | val_loss=0.1911 |\nCWA=0.938 | SWA=0.935 | GCWA=0.933', '\\n', 'Epoch 5: train_loss=0.1879 |\nval_loss=0.1935 | CWA=0.938 | SWA=0.934 | GCWA=0.932', '\\n', 'Test: loss=2.2965\n| CWA=0.627 | SWA=0.683 | GCWA=0.627', '\\n', '\\n=== Training with batch size 64\n===', '\\n', 'Epoch 1: train_loss=0.4818 | val_loss=0.3270 | CWA=0.877 |\nSWA=0.875 | GCWA=0.871', '\\n', 'Epoch 2: train_loss=0.2739 | val_loss=0.2417 |\nCWA=0.921 | SWA=0.919 | GCWA=0.917', '\\n', 'Epoch 3: train_loss=0.2297 |\nval_loss=0.2176 | CWA=0.934 | SWA=0.931 | GCWA=0.929', '\\n', 'Epoch 4:\ntrain_loss=0.2110 | val_loss=0.2081 | CWA=0.936 | SWA=0.933 | GCWA=0.931', '\\n',\n'Epoch 5: train_loss=0.2018 | val_loss=0.2009 | CWA=0.938 | SWA=0.934 |\nGCWA=0.932', '\\n', 'Test: loss=2.0273 | CWA=0.627 | SWA=0.683 | GCWA=0.627',\n'\\n', '\\n=== Training with batch size 128 ===', '\\n', 'Epoch 1:\ntrain_loss=0.5537 | val_loss=0.4132 | CWA=0.833 | SWA=0.832 | GCWA=0.828', '\\n',\n'Epoch 2: train_loss=0.3296 | val_loss=0.2771 | CWA=0.907 | SWA=0.908 |\nGCWA=0.906', '\\n', 'Epoch 3: train_loss=0.2574 | val_loss=0.2428 | CWA=0.918 |\nSWA=0.917 | GCWA=0.915', '\\n', 'Epoch 4: train_loss=0.2295 | val_loss=0.2225 |\nCWA=0.930 | SWA=0.927 | GCWA=0.925', '\\n', 'Epoch 5: train_loss=0.2132 |\nval_loss=0.2099 | CWA=0.936 | SWA=0.932 | GCWA=0.930', '\\n', 'Test: loss=1.5632\n| CWA=0.625 | SWA=0.681 | GCWA=0.625', '\\n', '\\n=== Training with batch size 256\n===', '\\n', 'Epoch 1: train_loss=0.5896 | val_loss=0.4951 | CWA=0.770 |\nSWA=0.771 | GCWA=0.766', '\\n', 'Epoch 2: train_loss=0.4362 | val_loss=0.3749 |\nCWA=0.852 | SWA=0.850 | GCWA=0.846', '\\n', 'Epoch 3: train_loss=0.3334 |\nval_loss=0.2963 | CWA=0.904 | SWA=0.901 | GCWA=0.899', '\\n', 'Epoch 4:\ntrain_loss=0.2755 | val_loss=0.2567 | CWA=0.923 | SWA=0.920 | GCWA=0.919', '\\n',\n'Epoch 5: train_loss=0.2456 | val_loss=0.2362 | CWA=0.926 | SWA=0.922 |\nGCWA=0.921', '\\n', 'Test: loss=1.1828 | CWA=0.621 | SWA=0.676 | GCWA=0.622',\n'\\n', '\\nSaved experiment data to experiment_data.npy', '\\n', 'Execution time:\n14 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 20000 examples [00:00,\n236694.86 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 414932.53\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 251707.57\nexamples/s]', '\\n', '\\n=== Training with emb_dim=4 ===', '\\n', 'Epoch 1:\ntrain_loss=0.5948 | val_loss=0.5292 | CWA=0.733 | SWA=0.732 | GCWA=0.723', '\\n',\n'Epoch 2: train_loss=0.4843 | val_loss=0.4398 | CWA=0.789 | SWA=0.790 |\nGCWA=0.783', '\\n', 'Epoch 3: train_loss=0.4008 | val_loss=0.3601 | CWA=0.851 |\nSWA=0.852 | GCWA=0.847', '\\n', 'Epoch 4: train_loss=0.3278 | val_loss=0.2919 |\nCWA=0.906 | SWA=0.907 | GCWA=0.904', '\\n', 'Epoch 5: train_loss=0.2699 |\nval_loss=0.2456 | CWA=0.925 | SWA=0.923 | GCWA=0.921', '\\n', 'Test (emb_dim=4):\nloss=1.1698 | CWA=0.624 | SWA=0.678 | GCWA=0.624', '\\n', '\\n=== Training with\nemb_dim=8 ===', '\\n', 'Epoch 1: train_loss=0.5720 | val_loss=0.4866 | CWA=0.774\n| SWA=0.780 | GCWA=0.773', '\\n', 'Epoch 2: train_loss=0.4044 | val_loss=0.3329 |\nCWA=0.874 | SWA=0.875 | GCWA=0.873', '\\n', 'Epoch 3: train_loss=0.2999 |\nval_loss=0.2721 | CWA=0.904 | SWA=0.904 | GCWA=0.902', '\\n', 'Epoch 4:\ntrain_loss=0.2617 | val_loss=0.2488 | CWA=0.915 | SWA=0.914 | GCWA=0.912', '\\n',\n'Epoch 5: train_loss=0.2416 | val_loss=0.2329 | CWA=0.922 | SWA=0.920 |\nGCWA=0.918', '\\n', 'Test (emb_dim=8): loss=1.3615 | CWA=0.621 | SWA=0.676 |\nGCWA=0.622', '\\n', '\\n=== Training with emb_dim=16 ===', '\\n', 'Epoch 1:\ntrain_loss=0.4970 | val_loss=0.3597 | CWA=0.867 | SWA=0.868 | GCWA=0.866', '\\n',\n'Epoch 2: train_loss=0.2867 | val_loss=0.2421 | CWA=0.928 | SWA=0.925 |\nGCWA=0.924', '\\n', 'Epoch 3: train_loss=0.2261 | val_loss=0.2134 | CWA=0.936 |\nSWA=0.933 | GCWA=0.930', '\\n', 'Epoch 4: train_loss=0.2070 | val_loss=0.2028 |\nCWA=0.938 | SWA=0.935 | GCWA=0.932', '\\n', 'Epoch 5: train_loss=0.1974 |\nval_loss=0.1970 | CWA=0.939 | SWA=0.935 | GCWA=0.933', '\\n', 'Test (emb_dim=16):\nloss=1.9191 | CWA=0.628 | SWA=0.684 | GCWA=0.627', '\\n', '\\n=== Training with\nemb_dim=32 ===', '\\n', 'Epoch 1: train_loss=0.4846 | val_loss=0.3442 | CWA=0.865\n| SWA=0.863 | GCWA=0.859', '\\n', 'Epoch 2: train_loss=0.2875 | val_loss=0.2520 |\nCWA=0.923 | SWA=0.921 | GCWA=0.919', '\\n', 'Epoch 3: train_loss=0.2361 |\nval_loss=0.2200 | CWA=0.932 | SWA=0.929 | GCWA=0.926', '\\n', 'Epoch 4:\ntrain_loss=0.2148 | val_loss=0.2088 | CWA=0.934 | SWA=0.931 | GCWA=0.929', '\\n',\n'Epoch 5: train_loss=0.2048 | val_loss=0.2040 | CWA=0.935 | SWA=0.932 |\nGCWA=0.929', '\\n', 'Test (emb_dim=32): loss=1.8179 | CWA=0.627 | SWA=0.682 |\nGCWA=0.626', '\\n', '\\n=== Training with emb_dim=64 ===', '\\n', 'Epoch 1:\ntrain_loss=0.4390 | val_loss=0.2985 | CWA=0.904 | SWA=0.904 | GCWA=0.902', '\\n',\n'Epoch 2: train_loss=0.2538 | val_loss=0.2391 | CWA=0.920 | SWA=0.918 |\nGCWA=0.916', '\\n', 'Epoch 3: train_loss=0.2104 | val_loss=0.2080 | CWA=0.937 |\nSWA=0.933 | GCWA=0.931', '\\n', 'Epoch 4: train_loss=0.1957 | val_loss=0.1947 |\nCWA=0.937 | SWA=0.934 | GCWA=0.932', '\\n', 'Epoch 5: train_loss=0.1897 |\nval_loss=0.1891 | CWA=0.938 | SWA=0.935 | GCWA=0.932', '\\n', 'Test (emb_dim=64):\nloss=1.9727 | CWA=0.628 | SWA=0.683 | GCWA=0.627', '\\n', '\\nSaved experiment\ndata to', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_02-26-\n55_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n13/working/experiment_data.npy', '\\n', 'Execution time: 34 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', '\\n===== training run 1 | lr=3.0e-04 =====', '\\n',\n'Epoch 1/3 | train_loss=0.6392 | val_loss=0.5886 | CWA=0.708 | SWA=0.711 |\nGCWA=0.704', '\\n', 'Epoch 2/3 | train_loss=0.5531 | val_loss=0.5169 | CWA=0.756\n| SWA=0.760 | GCWA=0.753', '\\n', 'Epoch 3/3 | train_loss=0.4860 |\nval_loss=0.4511 | CWA=0.800 | SWA=0.805 | GCWA=0.798', '\\n', 'Test | loss=0.6757\n| CWA=0.610 | SWA=0.651 | GCWA=0.611', '\\n', '\\n===== training run 2 |\nlr=1.0e-04 =====', '\\n', 'Epoch 1/3 | train_loss=0.6848 | val_loss=0.6621 |\nCWA=0.677 | SWA=0.670 | GCWA=0.666', '\\n', 'Epoch 2/3 | train_loss=0.6403 |\nval_loss=0.6181 | CWA=0.685 | SWA=0.682 | GCWA=0.675', '\\n', 'Epoch 3/3 |\ntrain_loss=0.5986 | val_loss=0.5808 | CWA=0.696 | SWA=0.695 | GCWA=0.686', '\\n',\n'Test | loss=0.6569 | CWA=0.581 | SWA=0.609 | GCWA=0.582', '\\n', '\\n=====\ntraining run 3 | lr=3.0e-05 =====', '\\n', 'Epoch 1/3 | train_loss=0.6962 |\nval_loss=0.6925 | CWA=0.528 | SWA=0.543 | GCWA=0.545', '\\n', 'Epoch 2/3 |\ntrain_loss=0.6860 | val_loss=0.6831 | CWA=0.600 | SWA=0.610 | GCWA=0.612', '\\n',\n'Epoch 3/3 | train_loss=0.6768 | val_loss=0.6741 | CWA=0.642 | SWA=0.649 |\nGCWA=0.649', '\\n', 'Test | loss=0.6848 | CWA=0.549 | SWA=0.571 | GCWA=0.551',\n'\\n', '\\nBest learning rate: 3.0e-04 with dev GCWA 0.798', '\\n', 'Saved\nexperiment data to', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-\n31_02-26-55_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n10/working', '\\n', 'Execution time: 12 seconds seconds (time limit is 30\nminutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\n----- Training with hidden_dim=32\n-----', '\\n', 'Epoch 1/5  train_loss=0.5676  val_loss=0.4319  CWA=0.820\nSWA=0.821 GCWA=0.816', '\\n', 'Epoch 2/5  train_loss=0.3528  val_loss=0.2885\nCWA=0.906 SWA=0.904 GCWA=0.903', '\\n', 'Epoch 3/5  train_loss=0.2643\nval_loss=0.2421  CWA=0.923 SWA=0.919 GCWA=0.918', '\\n', 'Epoch 4/5\ntrain_loss=0.2319  val_loss=0.2224  CWA=0.928 SWA=0.925 GCWA=0.923', '\\n',\n'Epoch 5/5  train_loss=0.2166  val_loss=0.2120  CWA=0.931 SWA=0.929 GCWA=0.926',\n'\\n', 'TEST  loss=1.5568  CWA=0.626  SWA=0.681  GCWA=0.626', '\\n', '\\n-----\nTraining with hidden_dim=64 -----', '\\n', 'Epoch 1/5  train_loss=0.5411\nval_loss=0.4398  CWA=0.798 SWA=0.802 GCWA=0.795', '\\n', 'Epoch 2/5\ntrain_loss=0.3513  val_loss=0.2848  CWA=0.911 SWA=0.908 GCWA=0.906', '\\n',\n'Epoch 3/5  train_loss=0.2549  val_loss=0.2346  CWA=0.927 SWA=0.924 GCWA=0.922',\n'\\n', 'Epoch 4/5  train_loss=0.2232  val_loss=0.2135  CWA=0.936 SWA=0.933\nGCWA=0.931', '\\n', 'Epoch 5/5  train_loss=0.2072  val_loss=0.2061  CWA=0.938\nSWA=0.934 GCWA=0.932', '\\n', 'TEST  loss=1.6117  CWA=0.628  SWA=0.683\nGCWA=0.627', '\\n', '\\n----- Training with hidden_dim=128 -----', '\\n', 'Epoch\n1/5  train_loss=0.5187  val_loss=0.3747  CWA=0.854 SWA=0.853 GCWA=0.848', '\\n',\n'Epoch 2/5  train_loss=0.3050  val_loss=0.2644  CWA=0.899 SWA=0.898 GCWA=0.894',\n'\\n', 'Epoch 3/5  train_loss=0.2478  val_loss=0.2320  CWA=0.923 SWA=0.920\nGCWA=0.918', '\\n', 'Epoch 4/5  train_loss=0.2221  val_loss=0.2158  CWA=0.929\nSWA=0.927 GCWA=0.924', '\\n', 'Epoch 5/5  train_loss=0.2080  val_loss=0.2067\nCWA=0.936 SWA=0.933 GCWA=0.931', '\\n', 'TEST  loss=1.7643  CWA=0.628  SWA=0.683\nGCWA=0.627', '\\n', '\\n----- Training with hidden_dim=256 -----', '\\n', 'Epoch\n1/5  train_loss=0.4702  val_loss=0.3366  CWA=0.879 SWA=0.875 GCWA=0.873', '\\n',\n'Epoch 2/5  train_loss=0.2684  val_loss=0.2282  CWA=0.935 SWA=0.932 GCWA=0.929',\n'\\n', 'Epoch 3/5  train_loss=0.2120  val_loss=0.2037  CWA=0.937 SWA=0.934\nGCWA=0.931', '\\n', 'Epoch 4/5  train_loss=0.1967  val_loss=0.1940  CWA=0.939\nSWA=0.935 GCWA=0.933', '\\n', 'Epoch 5/5  train_loss=0.1909  val_loss=0.1918\nCWA=0.939 SWA=0.935 GCWA=0.933', '\\n', 'TEST  loss=1.7884  CWA=0.628  SWA=0.683\nGCWA=0.627', '\\n', '\\nAll results saved to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/0-\nrun/process_ForkProcess-11/working/experiment_data.npy', '\\n', 'Execution time:\n10 seconds seconds (time limit is 30 minutes).']", "['Running on', ' ', 'cuda', '\\n', '\\n=== Training with weight_decay=0.0 ===',\n'\\n', 'Epoch 1: train_loss=0.5482 | val_loss=0.4259 | CWA=0.807 | SWA=0.810 |\nGCWA=0.803', '\\n', 'Epoch 2: train_loss=0.3391 | val_loss=0.2778 | CWA=0.909 |\nSWA=0.907 | GCWA=0.905', '\\n', 'Epoch 3: train_loss=0.2498 | val_loss=0.2325 |\nCWA=0.926 | SWA=0.922 | GCWA=0.920', '\\n', 'Epoch 4: train_loss=0.2226 |\nval_loss=0.2152 | CWA=0.934 | SWA=0.930 | GCWA=0.928', '\\n', 'Epoch 5:\ntrain_loss=0.2083 | val_loss=0.2071 | CWA=0.937 | SWA=0.933 | GCWA=0.931', '\\n',\n'Test: loss=1.5795 | CWA=0.627 | SWA=0.682 | GCWA=0.626', '\\n', '\\n=== Training\nwith weight_decay=1e-05 ===', '\\n', 'Epoch 1: train_loss=0.5663 |\nval_loss=0.4691 | CWA=0.781 | SWA=0.785 | GCWA=0.779', '\\n', 'Epoch 2:\ntrain_loss=0.3963 | val_loss=0.3264 | CWA=0.889 | SWA=0.888 | GCWA=0.886', '\\n',\n'Epoch 3: train_loss=0.2796 | val_loss=0.2421 | CWA=0.928 | SWA=0.925 |\nGCWA=0.923', '\\n', 'Epoch 4: train_loss=0.2276 | val_loss=0.2182 | CWA=0.934 |\nSWA=0.931 | GCWA=0.928', '\\n', 'Epoch 5: train_loss=0.2097 | val_loss=0.2074 |\nCWA=0.938 | SWA=0.934 | GCWA=0.932', '\\n', 'Test: loss=1.6595 | CWA=0.628 |\nSWA=0.683 | GCWA=0.627', '\\n', '\\n=== Training with weight_decay=0.0001 ===',\n'\\n', 'Epoch 1: train_loss=0.5848 | val_loss=0.5100 | CWA=0.754 | SWA=0.756 |\nGCWA=0.749', '\\n', 'Epoch 2: train_loss=0.4528 | val_loss=0.3975 | CWA=0.826 |\nSWA=0.829 | GCWA=0.823', '\\n', 'Epoch 3: train_loss=0.3401 | val_loss=0.2871 |\nCWA=0.914 | SWA=0.911 | GCWA=0.909', '\\n', 'Epoch 4: train_loss=0.2565 |\nval_loss=0.2331 | CWA=0.933 | SWA=0.930 | GCWA=0.928', '\\n', 'Epoch 5:\ntrain_loss=0.2216 | val_loss=0.2141 | CWA=0.936 | SWA=0.933 | GCWA=0.930', '\\n',\n'Test: loss=1.3454 | CWA=0.628 | SWA=0.683 | GCWA=0.627', '\\n', '\\n=== Training\nwith weight_decay=0.001 ===', '\\n', 'Epoch 1: train_loss=0.5438 |\nval_loss=0.4488 | CWA=0.808 | SWA=0.806 | GCWA=0.800', '\\n', 'Epoch 2:\ntrain_loss=0.3746 | val_loss=0.3182 | CWA=0.891 | SWA=0.891 | GCWA=0.888', '\\n',\n'Epoch 3: train_loss=0.2765 | val_loss=0.2490 | CWA=0.918 | SWA=0.916 |\nGCWA=0.914', '\\n', 'Epoch 4: train_loss=0.2311 | val_loss=0.2215 | CWA=0.934 |\nSWA=0.931 | GCWA=0.929', '\\n', 'Epoch 5: train_loss=0.2132 | val_loss=0.2103 |\nCWA=0.936 | SWA=0.933 | GCWA=0.931', '\\n', 'Test: loss=1.3469 | CWA=0.628 |\nSWA=0.683 | GCWA=0.627', '\\n', 'Execution time: 10 seconds seconds (time limit\nis 30 minutes).']", "['Device:', ' ', 'cuda', '\\n', '\\n=== training with dropout=0.1 ===', '\\n',\n'Epoch 1: train_loss=0.5486 val_loss=0.4109 CWA=0.830 SWA=0.831 GCWA=0.828',\n'\\n', 'Epoch 2: train_loss=0.3568 val_loss=0.2835 CWA=0.900 SWA=0.897\nGCWA=0.897', '\\n', 'Epoch 3: train_loss=0.2821 val_loss=0.2444 CWA=0.917\nSWA=0.913 GCWA=0.912', '\\n', 'Epoch 4: train_loss=0.2572 val_loss=0.2315\nCWA=0.922 SWA=0.917 GCWA=0.916', '\\n', 'Epoch 5: train_loss=0.2439\nval_loss=0.2265 CWA=0.923 SWA=0.918 GCWA=0.917', '\\n', '\\n=== training with\ndropout=0.2 ===', '\\n', 'Epoch 1: train_loss=0.5869 val_loss=0.5128 CWA=0.755\nSWA=0.757 GCWA=0.752', '\\n', 'Epoch 2: train_loss=0.4937 val_loss=0.4196\nCWA=0.823 SWA=0.829 GCWA=0.827', '\\n', 'Epoch 3: train_loss=0.3967\nval_loss=0.3212 CWA=0.878 SWA=0.878 GCWA=0.877', '\\n', 'Epoch 4:\ntrain_loss=0.3276 val_loss=0.2770 CWA=0.895 SWA=0.892 GCWA=0.892', '\\n', 'Epoch\n5: train_loss=0.2919 val_loss=0.2526 CWA=0.908 SWA=0.906 GCWA=0.904', '\\n',\n'\\n=== training with dropout=0.3 ===', '\\n', 'Epoch 1: train_loss=0.6053\nval_loss=0.5429 CWA=0.720 SWA=0.724 GCWA=0.718', '\\n', 'Epoch 2:\ntrain_loss=0.5339 val_loss=0.4536 CWA=0.793 SWA=0.797 GCWA=0.791', '\\n', 'Epoch\n3: train_loss=0.4588 val_loss=0.3703 CWA=0.852 SWA=0.854 GCWA=0.852', '\\n',\n'Epoch 4: train_loss=0.3775 val_loss=0.3014 CWA=0.883 SWA=0.883 GCWA=0.882',\n'\\n', 'Epoch 5: train_loss=0.3254 val_loss=0.2641 CWA=0.903 SWA=0.899\nGCWA=0.899', '\\n', '\\n=== training with dropout=0.4 ===', '\\n', 'Epoch 1:\ntrain_loss=0.6191 val_loss=0.5524 CWA=0.718 SWA=0.719 GCWA=0.712', '\\n', 'Epoch\n2: train_loss=0.5587 val_loss=0.4879 CWA=0.770 SWA=0.770 GCWA=0.766', '\\n',\n'Epoch 3: train_loss=0.4941 val_loss=0.3961 CWA=0.846 SWA=0.845 GCWA=0.844',\n'\\n', 'Epoch 4: train_loss=0.4110 val_loss=0.3191 CWA=0.878 SWA=0.879\nGCWA=0.878', '\\n', 'Epoch 5: train_loss=0.3439 val_loss=0.2726 CWA=0.900\nSWA=0.898 GCWA=0.897', '\\n', '\\n=== training with dropout=0.5 ===', '\\n', 'Epoch\n1: train_loss=0.6233 val_loss=0.5512 CWA=0.726 SWA=0.727 GCWA=0.721', '\\n',\n'Epoch 2: train_loss=0.5547 val_loss=0.4760 CWA=0.777 SWA=0.780 GCWA=0.776',\n'\\n', 'Epoch 3: train_loss=0.4759 val_loss=0.3765 CWA=0.851 SWA=0.854\nGCWA=0.852', '\\n', 'Epoch 4: train_loss=0.4037 val_loss=0.3129 CWA=0.874\nSWA=0.876 GCWA=0.874', '\\n', 'Epoch 5: train_loss=0.3579 val_loss=0.2792\nCWA=0.890 SWA=0.891 GCWA=0.889', '\\n', '\\nBest dropout=0.10 | Dev GCWA=0.917',\n'\\n', 'Test metrics @ best dropout: CWA=0.623 SWA=0.676 GCWA=0.622', '\\n',\n'Execution time: 23 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\n=== Training with emb_dim=4 ===', '\\n',\n'Epoch 1: train_loss=0.6134 | val_loss=0.5425 | CWA=0.737 | SWA=0.736 |\nGCWA=0.730', '\\n', 'Epoch 2: train_loss=0.4964 | val_loss=0.4615 | CWA=0.787 |\nSWA=0.790 | GCWA=0.783', '\\n', 'Epoch 3: train_loss=0.4289 | val_loss=0.4038 |\nCWA=0.818 | SWA=0.822 | GCWA=0.815', '\\n', 'Epoch 4: train_loss=0.3630 |\nval_loss=0.3279 | CWA=0.883 | SWA=0.883 | GCWA=0.880', '\\n', 'Epoch 5:\ntrain_loss=0.2933 | val_loss=0.2688 | CWA=0.911 | SWA=0.909 | GCWA=0.907', '\\n',\n'Test (emb_dim=4): loss=1.0301 | CWA=0.617 | SWA=0.671 | GCWA=0.618', '\\n',\n'\\n=== Training with emb_dim=8 ===', '\\n', 'Epoch 1: train_loss=0.5707 |\nval_loss=0.4792 | CWA=0.771 | SWA=0.775 | GCWA=0.770', '\\n', 'Epoch 2:\ntrain_loss=0.3969 | val_loss=0.3270 | CWA=0.880 | SWA=0.878 | GCWA=0.876', '\\n',\n'Epoch 3: train_loss=0.2925 | val_loss=0.2646 | CWA=0.909 | SWA=0.907 |\nGCWA=0.906', '\\n', 'Epoch 4: train_loss=0.2520 | val_loss=0.2382 | CWA=0.924 |\nSWA=0.921 | GCWA=0.919', '\\n', 'Epoch 5: train_loss=0.2304 | val_loss=0.2252 |\nCWA=0.927 | SWA=0.924 | GCWA=0.922', '\\n', 'Test (emb_dim=8): loss=1.5770 |\nCWA=0.624 | SWA=0.678 | GCWA=0.624', '\\n', '\\n=== Training with emb_dim=16 ===',\n'\\n', 'Epoch 1: train_loss=0.5232 | val_loss=0.4021 | CWA=0.827 | SWA=0.827 |\nGCWA=0.821', '\\n', 'Epoch 2: train_loss=0.3079 | val_loss=0.2475 | CWA=0.927 |\nSWA=0.924 | GCWA=0.922', '\\n', 'Epoch 3: train_loss=0.2258 | val_loss=0.2139 |\nCWA=0.935 | SWA=0.931 | GCWA=0.929', '\\n', 'Epoch 4: train_loss=0.2051 |\nval_loss=0.2012 | CWA=0.938 | SWA=0.935 | GCWA=0.933', '\\n', 'Epoch 5:\ntrain_loss=0.1958 | val_loss=0.1954 | CWA=0.938 | SWA=0.935 | GCWA=0.933', '\\n',\n'Test (emb_dim=16): loss=1.7493 | CWA=0.628 | SWA=0.683 | GCWA=0.627', '\\n',\n'\\n=== Training with emb_dim=32 ===', '\\n', 'Epoch 1: train_loss=0.4711 |\nval_loss=0.3148 | CWA=0.888 | SWA=0.886 | GCWA=0.883', '\\n', 'Epoch 2:\ntrain_loss=0.2573 | val_loss=0.2217 | CWA=0.934 | SWA=0.931 | GCWA=0.929', '\\n',\n'Epoch 3: train_loss=0.2102 | val_loss=0.2034 | CWA=0.936 | SWA=0.933 |\nGCWA=0.931', '\\n', 'Epoch 4: train_loss=0.1984 | val_loss=0.1946 | CWA=0.938 |\nSWA=0.935 | GCWA=0.933', '\\n', 'Epoch 5: train_loss=0.1930 | val_loss=0.1922 |\nCWA=0.939 | SWA=0.935 | GCWA=0.933', '\\n', 'Test (emb_dim=32): loss=1.9833 |\nCWA=0.628 | SWA=0.684 | GCWA=0.627', '\\n', '\\n=== Training with emb_dim=64 ===',\n'\\n', 'Epoch 1: train_loss=0.4241 | val_loss=0.2702 | CWA=0.922 | SWA=0.919 |\nGCWA=0.918', '\\n', 'Epoch 2: train_loss=0.2303 | val_loss=0.2143 | CWA=0.935 |\nSWA=0.932 | GCWA=0.930', '\\n', 'Epoch 3: train_loss=0.1992 | val_loss=0.1942 |\nCWA=0.939 | SWA=0.935 | GCWA=0.933', '\\n', 'Epoch 4: train_loss=0.1933 |\nval_loss=0.1901 | CWA=0.939 | SWA=0.935 | GCWA=0.933', '\\n', 'Epoch 5:\ntrain_loss=0.1895 | val_loss=0.1952 | CWA=0.938 | SWA=0.935 | GCWA=0.933', '\\n',\n'Test (emb_dim=64): loss=2.0069 | CWA=0.628 | SWA=0.683 | GCWA=0.627', '\\n',\n'\\nSaved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/0-\nrun/process_ForkProcess-12/working/experiment_data.npy', '\\n', 'Execution time:\n41 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\n=== Training with emb_dim=4 ===', '\\n',\n'Epoch 1: train_loss=0.5789 | val_loss=0.4837 | CWA=0.781 | SWA=0.785 |\nGCWA=0.780', '\\n', 'Epoch 2: train_loss=0.4051 | val_loss=0.3255 | CWA=0.883 |\nSWA=0.880 | GCWA=0.877', '\\n', 'Epoch 3: train_loss=0.2881 | val_loss=0.2595 |\nCWA=0.917 | SWA=0.915 | GCWA=0.913', '\\n', 'Epoch 4: train_loss=0.2484 |\nval_loss=0.2377 | CWA=0.924 | SWA=0.921 | GCWA=0.919', '\\n', 'Epoch 5:\ntrain_loss=0.2332 | val_loss=0.2268 | CWA=0.928 | SWA=0.926 | GCWA=0.923', '\\n',\n'Test (emb_dim=4): loss=1.3969 | CWA=0.623 | SWA=0.677 | GCWA=0.623', '\\n',\n'\\n=== Training with emb_dim=8 ===', '\\n', 'Epoch 1: train_loss=0.5681 |\nval_loss=0.4868 | CWA=0.767 | SWA=0.770 | GCWA=0.764', '\\n', 'Epoch 2:\ntrain_loss=0.4217 | val_loss=0.3512 | CWA=0.878 | SWA=0.877 | GCWA=0.875', '\\n',\n'Epoch 3: train_loss=0.2934 | val_loss=0.2548 | CWA=0.926 | SWA=0.923 |\nGCWA=0.922', '\\n', 'Epoch 4: train_loss=0.2361 | val_loss=0.2239 | CWA=0.932 |\nSWA=0.929 | GCWA=0.927', '\\n', 'Epoch 5: train_loss=0.2154 | val_loss=0.2129 |\nCWA=0.938 | SWA=0.935 | GCWA=0.932', '\\n', 'Test (emb_dim=8): loss=1.5396 |\nCWA=0.628 | SWA=0.683 | GCWA=0.627', '\\n', '\\n=== Training with emb_dim=16 ===',\n'\\n', 'Epoch 1: train_loss=0.5082 | val_loss=0.3702 | CWA=0.848 | SWA=0.847 |\nGCWA=0.842', '\\n', 'Epoch 2: train_loss=0.3022 | val_loss=0.2540 | CWA=0.918 |\nSWA=0.915 | GCWA=0.914', '\\n', 'Epoch 3: train_loss=0.2389 | val_loss=0.2241 |\nCWA=0.931 | SWA=0.928 | GCWA=0.926', '\\n', 'Epoch 4: train_loss=0.2167 |\nval_loss=0.2096 | CWA=0.937 | SWA=0.934 | GCWA=0.931', '\\n', 'Epoch 5:\ntrain_loss=0.2050 | val_loss=0.2024 | CWA=0.938 | SWA=0.934 | GCWA=0.932', '\\n',\n'Test (emb_dim=16): loss=1.7208 | CWA=0.628 | SWA=0.683 | GCWA=0.627', '\\n',\n'\\n=== Training with emb_dim=32 ===', '\\n', 'Epoch 1: train_loss=0.4942 |\nval_loss=0.3490 | CWA=0.871 | SWA=0.872 | GCWA=0.870', '\\n', 'Epoch 2:\ntrain_loss=0.2813 | val_loss=0.2357 | CWA=0.928 | SWA=0.926 | GCWA=0.924', '\\n',\n'Epoch 3: train_loss=0.2215 | val_loss=0.2100 | CWA=0.936 | SWA=0.933 |\nGCWA=0.931', '\\n', 'Epoch 4: train_loss=0.2031 | val_loss=0.2057 | CWA=0.939 |\nSWA=0.935 | GCWA=0.933', '\\n', 'Epoch 5: train_loss=0.1967 | val_loss=0.1954 |\nCWA=0.938 | SWA=0.935 | GCWA=0.933', '\\n', 'Test (emb_dim=32): loss=1.7944 |\nCWA=0.628 | SWA=0.683 | GCWA=0.627', '\\n', '\\n=== Training with emb_dim=64 ===',\n'\\n', 'Epoch 1: train_loss=0.4070 | val_loss=0.2652 | CWA=0.923 | SWA=0.920 |\nGCWA=0.919', '\\n', 'Epoch 2: train_loss=0.2328 | val_loss=0.2109 | CWA=0.938 |\nSWA=0.934 | GCWA=0.932', '\\n', 'Epoch 3: train_loss=0.2026 | val_loss=0.1989 |\nCWA=0.938 | SWA=0.935 | GCWA=0.933', '\\n', 'Epoch 4: train_loss=0.1939 |\nval_loss=0.1922 | CWA=0.939 | SWA=0.935 | GCWA=0.933', '\\n', 'Epoch 5:\ntrain_loss=0.1904 | val_loss=0.1911 | CWA=0.939 | SWA=0.935 | GCWA=0.933', '\\n',\n'Test (emb_dim=64): loss=2.3265 | CWA=0.628 | SWA=0.684 | GCWA=0.627', '\\n',\n'\\nSaved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/0-\nrun/process_ForkProcess-13/working/experiment_data.npy', '\\n', 'Execution time:\n18 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\n=== Training with emb_dim=4 ===', '\\n',\n'Epoch 1: train_loss=0.5939 | val_loss=0.5044 | CWA=0.759 | SWA=0.762 |\nGCWA=0.756', '\\n', 'Epoch 2: train_loss=0.4388 | val_loss=0.3713 | CWA=0.852 |\nSWA=0.853 | GCWA=0.848', '\\n', 'Epoch 3: train_loss=0.3300 | val_loss=0.2906 |\nCWA=0.891 | SWA=0.891 | GCWA=0.888', '\\n', 'Epoch 4: train_loss=0.2752 |\nval_loss=0.2572 | CWA=0.909 | SWA=0.909 | GCWA=0.907', '\\n', 'Epoch 5:\ntrain_loss=0.2490 | val_loss=0.2382 | CWA=0.927 | SWA=0.924 | GCWA=0.922', '\\n',\n'Test (emb_dim=4): loss=1.2821 | CWA=0.623 | SWA=0.678 | GCWA=0.623', '\\n',\n'\\n=== Training with emb_dim=8 ===', '\\n', 'Epoch 1: train_loss=0.5805 |\nval_loss=0.4881 | CWA=0.774 | SWA=0.777 | GCWA=0.772', '\\n', 'Epoch 2:\ntrain_loss=0.3909 | val_loss=0.3101 | CWA=0.890 | SWA=0.888 | GCWA=0.885', '\\n',\n'Epoch 3: train_loss=0.2747 | val_loss=0.2509 | CWA=0.922 | SWA=0.920 |\nGCWA=0.917', '\\n', 'Epoch 4: train_loss=0.2371 | val_loss=0.2261 | CWA=0.928 |\nSWA=0.925 | GCWA=0.923', '\\n', 'Epoch 5: train_loss=0.2194 | val_loss=0.2144 |\nCWA=0.933 | SWA=0.930 | GCWA=0.928', '\\n', 'Test (emb_dim=8): loss=1.4375 |\nCWA=0.626 | SWA=0.681 | GCWA=0.626', '\\n', '\\n=== Training with emb_dim=16 ===',\n'\\n', 'Epoch 1: train_loss=0.5070 | val_loss=0.3840 | CWA=0.842 | SWA=0.846 |\nGCWA=0.842', '\\n', 'Epoch 2: train_loss=0.3053 | val_loss=0.2531 | CWA=0.921 |\nSWA=0.918 | GCWA=0.917', '\\n', 'Epoch 3: train_loss=0.2343 | val_loss=0.2198 |\nCWA=0.934 | SWA=0.931 | GCWA=0.929', '\\n', 'Epoch 4: train_loss=0.2127 |\nval_loss=0.2070 | CWA=0.936 | SWA=0.933 | GCWA=0.930', '\\n', 'Epoch 5:\ntrain_loss=0.2014 | val_loss=0.1996 | CWA=0.937 | SWA=0.934 | GCWA=0.931', '\\n',\n'Test (emb_dim=16): loss=1.8016 | CWA=0.628 | SWA=0.683 | GCWA=0.627', '\\n',\n'\\n=== Training with emb_dim=32 ===', '\\n', 'Epoch 1: train_loss=0.4852 |\nval_loss=0.3436 | CWA=0.863 | SWA=0.863 | GCWA=0.859', '\\n', 'Epoch 2:\ntrain_loss=0.2746 | val_loss=0.2311 | CWA=0.934 | SWA=0.930 | GCWA=0.929', '\\n',\n'Epoch 3: train_loss=0.2158 | val_loss=0.2056 | CWA=0.939 | SWA=0.935 |\nGCWA=0.933', '\\n', 'Epoch 4: train_loss=0.1996 | val_loss=0.1976 | CWA=0.939 |\nSWA=0.935 | GCWA=0.933', '\\n', 'Epoch 5: train_loss=0.1935 | val_loss=0.1921 |\nCWA=0.939 | SWA=0.935 | GCWA=0.933', '\\n', 'Test (emb_dim=32): loss=1.9532 |\nCWA=0.628 | SWA=0.684 | GCWA=0.627', '\\n', '\\n=== Training with emb_dim=64 ===',\n'\\n', 'Epoch 1: train_loss=0.4398 | val_loss=0.2949 | CWA=0.907 | SWA=0.904 |\nGCWA=0.902', '\\n', 'Epoch 2: train_loss=0.2373 | val_loss=0.2109 | CWA=0.935 |\nSWA=0.932 | GCWA=0.930', '\\n', 'Epoch 3: train_loss=0.1981 | val_loss=0.1932 |\nCWA=0.939 | SWA=0.935 | GCWA=0.933', '\\n', 'Epoch 4: train_loss=0.1919 |\nval_loss=0.1898 | CWA=0.939 | SWA=0.935 | GCWA=0.933', '\\n', 'Epoch 5:\ntrain_loss=0.1884 | val_loss=0.1887 | CWA=0.939 | SWA=0.935 | GCWA=0.933', '\\n',\n'Test (emb_dim=64): loss=2.1246 | CWA=0.628 | SWA=0.684 | GCWA=0.627', '\\n',\n'\\nSaved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/0-\nrun/process_ForkProcess-10/working/experiment_data.npy', '\\n', 'Execution time:\n16 seconds seconds (time limit is 30 minutes).']", ""], "analysis": ["The execution failed with a RuntimeError during the forward pass of the model.\nThe error occurred because the size of the mask tensor did not match the size of\nthe embedding tensor along dimension 1. This likely happened because the input\nsequences in the batch have variable lengths, and the padding/masking logic is\nnot correctly aligning the dimensions.   To fix this issue, ensure that the mask\ntensor is properly broadcasted to match the dimensions of the embedding tensor.\nSpecifically, verify that the unsqueeze operation on the mask tensor aligns its\ndimensions with the embedding tensor before performing element-wise\nmultiplication. Additionally, double-check the padding logic in the 'collate'\nfunction to ensure consistency in tensor dimensions.", "The execution failed due to a mismatch in tensor dimensions in the forward\nmethod of the GlyphModel class. Specifically, during the computation of the\npooled tensor, the size of tensor 'e' (24) did not match the size of tensor\n'mask.unsqueeze(-1)' (128) along dimension 1. This indicates an issue with how\nthe sequences are being padded or processed in the collate function or the\nmodel's forward method. To fix this, ensure that the padding logic in the\ncollate function aligns with the expected input dimensions of the model.\nAdditionally, debug the forward method to verify the shapes of tensors before\noperations like multiplication or summation.", "The training script executed successfully without any errors or bugs. The\ntraining and validation losses decreased as expected across epochs, and the\nmetrics (CWA, SWA, GCWA) improved during validation. However, there is a\nsignificant performance gap between validation and test metrics, suggesting\npotential overfitting or differences in data distribution. This could be\naddressed in future iterations by implementing techniques like regularization,\ndropout, or data augmentation. The experiment data has been saved successfully\nfor further analysis.", "The script executed successfully without any errors or bugs. It conducted\nhyperparameter tuning for the embedding dimension and evaluated the model on\ntraining, validation, and test sets. The metrics (CWA, SWA, GCWA) were\ncalculated and showed improvements during training for validation sets. However,\nthe test set performance remained significantly lower than validation metrics,\nwhich aligns with the sub-stage focus on addressing the validation-test gap. The\nexperiment data was saved successfully, and the execution time was within the\nexpected limit.", "", "The execution of the training script completed successfully without any errors\nor bugs. The script implemented a hyperparameter optimization process to test\ndifferent hidden dimensions of the model. The results showed improvements in\nvalidation metrics (CWA, SWA, GCWA) during training for all configurations.\nHowever, the test set performance metrics (CWA, SWA, GCWA) remained\nsignificantly lower than the validation metrics, which aligns with the stated\nsub-stage goal of addressing the validation-test gap. The results and experiment\ndata were saved successfully, and the execution time was within the limit. No\nbugs were detected.", "", "", "", "", "", ""], "exc_type": ["RuntimeError", "RuntimeError", null, null, null, null, null, null, null, null, null, null], "exc_info": [{"args": ["The size of tensor a (24) must match the size of tensor b (128) at non-singleton dimension 1"]}, {"args": ["The size of tensor a (24) must match the size of tensor b (128) at non-singleton dimension 1"]}, null, null, null, null, null, null, null, null, null, null], "exc_stack": [[["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 245, "<module>", "logits = model(shapes, colors, clusters, mask)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/nn/modules/module.py", 1736, "_wrapped_call_impl", "return self._call_impl(*args, **kwargs)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/nn/modules/module.py", 1747, "_call_impl", "return forward_call(*args, **kwargs)"], ["runfile.py", 192, "forward", "pooled = (e * mask.unsqueeze(-1)).sum(1) / mask.sum(1)"]], [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 258, "<module>", "logits = model(s, c, l, mask)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/nn/modules/module.py", 1736, "_wrapped_call_impl", "return self._call_impl(*args, **kwargs)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/nn/modules/module.py", 1747, "_call_impl", "return forward_call(*args, **kwargs)"], ["runfile.py", 186, "forward", "pooled = (e * mask.unsqueeze(-1)).sum(1) / mask.sum(1)"]], null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "validation loss", "lower_is_better": true, "description": "The loss on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.197, "best_value": 0.197}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "Color Weighted Accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.939, "best_value": 0.939}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "Shape Weighted Accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.935, "best_value": 0.935}]}, {"metric_name": "validation GCWA", "lower_is_better": false, "description": "Glyph Complexity Weighted Accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.933, "best_value": 0.933}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.9191, "best_value": 1.9191}]}, {"metric_name": "test color weighted accuracy", "lower_is_better": false, "description": "Color Weighted Accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.628, "best_value": 0.628}]}, {"metric_name": "test shape weighted accuracy", "lower_is_better": false, "description": "Shape Weighted Accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.684, "best_value": 0.684}]}, {"metric_name": "test glyph complexity weighted accuracy", "lower_is_better": false, "description": "Glyph Complexity Weighted Accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.627, "best_value": 0.627}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training. Lower values indicate better model performance.", "data": [{"dataset_name": "Training Set", "final_value": 0.486, "best_value": 0.486}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error on the validation set. Lower values indicate better model performance.", "data": [{"dataset_name": "Validation Set", "final_value": 0.4511, "best_value": 0.4511}]}, {"metric_name": "validation color-weighted accuracy (CWA)", "lower_is_better": false, "description": "Measures the color-weighted accuracy on the validation set. Higher values indicate better model performance.", "data": [{"dataset_name": "Validation Set", "final_value": 0.8, "best_value": 0.8}]}, {"metric_name": "validation shape-weighted accuracy (SWA)", "lower_is_better": false, "description": "Measures the shape-weighted accuracy on the validation set. Higher values indicate better model performance.", "data": [{"dataset_name": "Validation Set", "final_value": 0.805, "best_value": 0.805}]}, {"metric_name": "validation glyph-complexity-weighted accuracy (GCWA)", "lower_is_better": false, "description": "Measures the glyph-complexity-weighted accuracy on the validation set. Higher values indicate better model performance.", "data": [{"dataset_name": "Validation Set", "final_value": 0.798, "best_value": 0.798}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Measures the error on the test set. Lower values indicate better model performance.", "data": [{"dataset_name": "Test Set", "final_value": 0.6757, "best_value": 0.6757}]}, {"metric_name": "test color-weighted accuracy (CWA)", "lower_is_better": false, "description": "Measures the color-weighted accuracy on the test set. Higher values indicate better model performance.", "data": [{"dataset_name": "Test Set", "final_value": 0.61, "best_value": 0.61}]}, {"metric_name": "test shape-weighted accuracy (SWA)", "lower_is_better": false, "description": "Measures the shape-weighted accuracy on the test set. Higher values indicate better model performance.", "data": [{"dataset_name": "Test Set", "final_value": 0.651, "best_value": 0.651}]}, {"metric_name": "test glyph-complexity-weighted accuracy (GCWA)", "lower_is_better": false, "description": "Measures the glyph-complexity-weighted accuracy on the test set. Higher values indicate better model performance.", "data": [{"dataset_name": "Test Set", "final_value": 0.611, "best_value": 0.611}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measures the error or difference between predicted and actual values.", "data": [{"dataset_name": "train", "final_value": 0.1909, "best_value": 0.1909}, {"dataset_name": "validation", "final_value": 0.1918, "best_value": 0.1918}, {"dataset_name": "test", "final_value": 1.5568, "best_value": 1.5568}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by the color attribute.", "data": [{"dataset_name": "train", "final_value": 0.939, "best_value": 0.939}, {"dataset_name": "validation", "final_value": 0.939, "best_value": 0.939}, {"dataset_name": "test", "final_value": 0.628, "best_value": 0.628}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by the shape attribute.", "data": [{"dataset_name": "train", "final_value": 0.935, "best_value": 0.935}, {"dataset_name": "validation", "final_value": 0.935, "best_value": 0.935}, {"dataset_name": "test", "final_value": 0.683, "best_value": 0.683}]}, {"metric_name": "glyph-complexity-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by the glyph complexity attribute.", "data": [{"dataset_name": "train", "final_value": 0.933, "best_value": 0.933}, {"dataset_name": "validation", "final_value": 0.933, "best_value": 0.933}, {"dataset_name": "test", "final_value": 0.627, "best_value": 0.627}]}]}, {"metric_names": [{"metric_name": "CWA", "lower_is_better": false, "description": "CWA measures the classification weighted accuracy.", "data": [{"dataset_name": "validation", "final_value": 0.938, "best_value": 0.938}, {"dataset_name": "test", "final_value": 0.628, "best_value": 0.628}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "SWA measures the smoothed weighted accuracy.", "data": [{"dataset_name": "validation", "final_value": 0.934, "best_value": 0.934}, {"dataset_name": "test", "final_value": 0.683, "best_value": 0.683}]}, {"metric_name": "GCWA", "lower_is_better": false, "description": "GCWA measures the generalized classification weighted accuracy.", "data": [{"dataset_name": "validation", "final_value": 0.932, "best_value": 0.932}, {"dataset_name": "test", "final_value": 0.627, "best_value": 0.627}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1922, "best_value": 0.1922}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "Color Weighted Accuracy on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.939, "best_value": 0.939}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "Shape Weighted Accuracy on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.935, "best_value": 0.935}]}, {"metric_name": "validation GCWA", "lower_is_better": false, "description": "Glyph Complexity Weighted Accuracy on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.933, "best_value": 0.933}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Measures the error on the test set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.9833, "best_value": 1.9833}]}, {"metric_name": "test color weighted accuracy", "lower_is_better": false, "description": "Color Weighted Accuracy on the test set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.628, "best_value": 0.628}]}, {"metric_name": "test shape weighted accuracy", "lower_is_better": false, "description": "Shape Weighted Accuracy on the test set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.684, "best_value": 0.684}]}, {"metric_name": "test glyph complexity weighted accuracy", "lower_is_better": false, "description": "Glyph Complexity Weighted Accuracy on the test set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.627, "best_value": 0.627}]}]}, {"metric_names": [{"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on validation dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1911, "best_value": 0.1911}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "Color weighted accuracy on validation dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.939, "best_value": 0.939}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "Shape weighted accuracy on validation dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.935, "best_value": 0.935}]}, {"metric_name": "validation GCWA", "lower_is_better": false, "description": "Glyph complexity weighted accuracy on validation dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.933, "best_value": 0.933}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Loss on test dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 2.3265, "best_value": 2.3265}]}, {"metric_name": "test color weighted accuracy", "lower_is_better": false, "description": "Color weighted accuracy on test dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.628, "best_value": 0.628}]}, {"metric_name": "test shape weighted accuracy", "lower_is_better": false, "description": "Shape weighted accuracy on test dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.684, "best_value": 0.684}]}, {"metric_name": "test glyph complexity weighted accuracy", "lower_is_better": false, "description": "Glyph complexity weighted accuracy on test dataset", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.627, "best_value": 0.627}]}]}, {"metric_names": [{"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1996, "best_value": 0.1996}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "Color Weighted Accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.937, "best_value": 0.937}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "Shape Weighted Accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.934, "best_value": 0.934}]}, {"metric_name": "validation GCWA", "lower_is_better": false, "description": "Glyph Complexity Weighted Accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.931, "best_value": 0.931}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Loss on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.8016, "best_value": 1.8016}]}, {"metric_name": "test color weighted accuracy", "lower_is_better": false, "description": "Color Weighted Accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.628, "best_value": 0.628}]}, {"metric_name": "test shape weighted accuracy", "lower_is_better": false, "description": "Shape Weighted Accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.683, "best_value": 0.683}]}, {"metric_name": "test glyph complexity weighted accuracy", "lower_is_better": false, "description": "Glyph Complexity Weighted Accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.627, "best_value": 0.627}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, true, false, false, false, false, false, false, false, false], "plots": [[], [], ["../../logs/0-run/experiment_results/experiment_cd149e2a93884597a4a6b851d7043e12_proc_1604461/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_cd149e2a93884597a4a6b851d7043e12_proc_1604461/SPR_BENCH_CWA_curves.png", "../../logs/0-run/experiment_results/experiment_cd149e2a93884597a4a6b851d7043e12_proc_1604461/SPR_BENCH_test_metric_bars.png"], ["../../logs/0-run/experiment_results/experiment_16b53856e1414051a86f1b52c8f17ae4_proc_1604462/SPR_BENCH_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_16b53856e1414051a86f1b52c8f17ae4_proc_1604462/SPR_BENCH_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_16b53856e1414051a86f1b52c8f17ae4_proc_1604462/SPR_BENCH_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_f42fd82b489e4547b423b0174669acec_proc_1604459/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f42fd82b489e4547b423b0174669acec_proc_1604459/SPR_BENCH_gcwa_curves.png", "../../logs/0-run/experiment_results/experiment_f42fd82b489e4547b423b0174669acec_proc_1604459/SPR_BENCH_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_f4952ad0bdbb48a4b70514112c1f52b5_proc_1604460/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f4952ad0bdbb48a4b70514112c1f52b5_proc_1604460/SPR_BENCH_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_CWA_curves.png", "../../logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_SWA_curves.png", "../../logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_GCWA_curves.png", "../../logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_1724ddecc0cc439b954a6b666b7a9fab_proc_1604462/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_1724ddecc0cc439b954a6b666b7a9fab_proc_1604462/SPR_BENCH_val_GCWA_curves.png", "../../logs/0-run/experiment_results/experiment_1724ddecc0cc439b954a6b666b7a9fab_proc_1604462/SPR_BENCH_test_metric_bars.png"], ["../../logs/0-run/experiment_results/experiment_b6b0364c3fe14110aa7e8dfa579402b0_proc_1604461/SPR_BENCH_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_b6b0364c3fe14110aa7e8dfa579402b0_proc_1604461/SPR_BENCH_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_b6b0364c3fe14110aa7e8dfa579402b0_proc_1604461/SPR_BENCH_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_8081a9d9145a4ce49de09ebbda7b3d36_proc_1604462/SPR_BENCH_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8081a9d9145a4ce49de09ebbda7b3d36_proc_1604462/SPR_BENCH_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8081a9d9145a4ce49de09ebbda7b3d36_proc_1604462/SPR_BENCH_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_2b39d2fb89c748c594c81245f2e9b40d_proc_1604459/SPR_BENCH_training_loss_curves.png", "../../logs/0-run/experiment_results/experiment_2b39d2fb89c748c594c81245f2e9b40d_proc_1604459/SPR_BENCH_validation_loss_curves.png", "../../logs/0-run/experiment_results/experiment_2b39d2fb89c748c594c81245f2e9b40d_proc_1604459/SPR_BENCH_test_metrics.png"], ["../../logs/0-run/experiment_results/seed_aggregation_eb2dcfbc77564cd9ab4924815e83bd3f/SPR_BENCH_training_loss_mean_sem.png", "../../logs/0-run/experiment_results/seed_aggregation_eb2dcfbc77564cd9ab4924815e83bd3f/SPR_BENCH_validation_loss_mean_sem.png", "../../logs/0-run/experiment_results/seed_aggregation_eb2dcfbc77564cd9ab4924815e83bd3f/SPR_BENCH_test_metrics_mean_sem.png"]], "plot_paths": [[], [], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_cd149e2a93884597a4a6b851d7043e12_proc_1604461/SPR_BENCH_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_cd149e2a93884597a4a6b851d7043e12_proc_1604461/SPR_BENCH_CWA_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_cd149e2a93884597a4a6b851d7043e12_proc_1604461/SPR_BENCH_test_metric_bars.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16b53856e1414051a86f1b52c8f17ae4_proc_1604462/SPR_BENCH_training_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16b53856e1414051a86f1b52c8f17ae4_proc_1604462/SPR_BENCH_validation_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16b53856e1414051a86f1b52c8f17ae4_proc_1604462/SPR_BENCH_test_metrics.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f42fd82b489e4547b423b0174669acec_proc_1604459/SPR_BENCH_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f42fd82b489e4547b423b0174669acec_proc_1604459/SPR_BENCH_gcwa_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f42fd82b489e4547b423b0174669acec_proc_1604459/SPR_BENCH_test_metrics.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f4952ad0bdbb48a4b70514112c1f52b5_proc_1604460/SPR_BENCH_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f4952ad0bdbb48a4b70514112c1f52b5_proc_1604460/SPR_BENCH_test_metrics.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_CWA_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_SWA_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_GCWA_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_test_metrics.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_1724ddecc0cc439b954a6b666b7a9fab_proc_1604462/SPR_BENCH_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_1724ddecc0cc439b954a6b666b7a9fab_proc_1604462/SPR_BENCH_val_GCWA_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_1724ddecc0cc439b954a6b666b7a9fab_proc_1604462/SPR_BENCH_test_metric_bars.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6b0364c3fe14110aa7e8dfa579402b0_proc_1604461/SPR_BENCH_training_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6b0364c3fe14110aa7e8dfa579402b0_proc_1604461/SPR_BENCH_validation_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6b0364c3fe14110aa7e8dfa579402b0_proc_1604461/SPR_BENCH_test_metrics.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_8081a9d9145a4ce49de09ebbda7b3d36_proc_1604462/SPR_BENCH_training_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_8081a9d9145a4ce49de09ebbda7b3d36_proc_1604462/SPR_BENCH_validation_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_8081a9d9145a4ce49de09ebbda7b3d36_proc_1604462/SPR_BENCH_test_metrics.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2b39d2fb89c748c594c81245f2e9b40d_proc_1604459/SPR_BENCH_training_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2b39d2fb89c748c594c81245f2e9b40d_proc_1604459/SPR_BENCH_validation_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2b39d2fb89c748c594c81245f2e9b40d_proc_1604459/SPR_BENCH_test_metrics.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/seed_aggregation_eb2dcfbc77564cd9ab4924815e83bd3f/SPR_BENCH_training_loss_mean_sem.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/seed_aggregation_eb2dcfbc77564cd9ab4924815e83bd3f/SPR_BENCH_validation_loss_mean_sem.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/seed_aggregation_eb2dcfbc77564cd9ab4924815e83bd3f/SPR_BENCH_test_metrics_mean_sem.png"]], "plot_analyses": [[], [], [{"analysis": "The training loss decreases consistently across all batch sizes, indicating that the model is learning effectively. However, there is a noticeable gap between training and validation loss, particularly for larger batch sizes (e.g., 256), suggesting potential overfitting. Smaller batch sizes (e.g., 32 and 64) show better alignment between training and validation loss, implying better generalization.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_cd149e2a93884597a4a6b851d7043e12_proc_1604461/SPR_BENCH_loss_curves.png"}, {"analysis": "Color-Weighted Accuracy (CWA) improves steadily across epochs for all batch sizes, with smaller batch sizes (e.g., 32, 64) achieving slightly higher accuracy compared to larger batch sizes. This indicates that smaller batch sizes may allow the model to capture more nuanced patterns in the data, leading to better validation performance.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_cd149e2a93884597a4a6b851d7043e12_proc_1604461/SPR_BENCH_CWA_curves.png"}, {"analysis": "Test metrics (CWA, SWA, GCWA) are relatively stable across batch sizes, with minor variations. While batch size 64 achieves the highest SWA, the differences are not substantial, suggesting that batch size has a limited impact on test performance. The overall scores remain below the target SOTA performance, indicating room for further optimization.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_cd149e2a93884597a4a6b851d7043e12_proc_1604461/SPR_BENCH_test_metric_bars.png"}], [{"analysis": "The training loss decreases consistently across all embedding dimensions as the number of epochs increases. Larger embedding dimensions (e.g., emb_dim=64) achieve lower training loss, indicating better model capacity and optimization. However, the diminishing returns after emb_dim=16 suggest that increasing embedding dimensions beyond this point may not significantly enhance performance.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16b53856e1414051a86f1b52c8f17ae4_proc_1604462/SPR_BENCH_training_loss_curves.png"}, {"analysis": "The validation loss mirrors the trend observed in training loss, decreasing consistently across epochs. Larger embedding dimensions (e.g., emb_dim=64) result in lower validation loss, suggesting improved generalization. However, the gap between validation loss for emb_dim=16 and emb_dim=64 is minimal, indicating that increasing embedding dimensions beyond 16 may not yield substantial benefits.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16b53856e1414051a86f1b52c8f17ae4_proc_1604462/SPR_BENCH_validation_loss_curves.png"}, {"analysis": "The test metrics (CWA, SWA, GCWA) are relatively stable across embedding dimensions, with no significant improvement observed as embedding dimensions increase. This suggests that while larger embedding dimensions improve training and validation loss, they do not necessarily translate to better performance on the test set. The results indicate potential overfitting or a lack of further generalization benefits from increased embedding size.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_16b53856e1414051a86f1b52c8f17ae4_proc_1604462/SPR_BENCH_test_metrics.png"}], [{"analysis": "This plot shows the training and validation loss over three epochs for three different runs. The training loss consistently decreases for all runs, indicating that the model is learning effectively. However, the validation loss also decreases, which suggests that the model is generalizing well to the validation data and is not overfitting. Among the three runs, 'run1' exhibits the lowest validation loss at the end of epoch 3, indicating that it performs the best on the validation dataset.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f42fd82b489e4547b423b0174669acec_proc_1604459/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot depicts the validation Generalized Color-Weighted Accuracy (GCWA) over epochs for three runs. 'Run1' shows a consistent and significant improvement in GCWA, reaching approximately 0.8 by epoch 3. 'Run2' exhibits a slower and more modest improvement, stabilizing around 0.7. 'Run3' starts with the lowest GCWA but shows steady improvement, reaching around 0.65. 'Run1' demonstrates the highest GCWA, indicating that it is the most effective configuration for generalizing across color-weighted tasks.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f42fd82b489e4547b423b0174669acec_proc_1604459/SPR_BENCH_gcwa_curves.png"}, {"analysis": "This bar chart compares the test set performance across three metrics (CWA, SWA, GCWA) for the three runs. 'Run1' achieves the highest accuracy across all metrics, particularly excelling in SWA. 'Run2' and 'Run3' have comparable performance, with 'Run2' slightly outperforming 'Run3' in CWA and GCWA. The results suggest that 'Run1' is the most robust configuration for both color- and shape-weighted reasoning tasks, while 'Run2' and 'Run3' may require further tuning to close the performance gap.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f42fd82b489e4547b423b0174669acec_proc_1604459/SPR_BENCH_test_metrics.png"}], [{"analysis": "The training loss curves show that as the hidden dimension (h) increases, the model converges faster and achieves lower final training loss values. For example, h=256 consistently outperforms other configurations, indicating that larger hidden dimensions enable the model to capture more complex patterns in the training data. The validation loss curves follow a similar trend, with h=256 achieving the lowest final validation loss. This suggests that increasing the hidden dimension improves the model's ability to generalize to unseen data, likely due to richer latent feature representations.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f4952ad0bdbb48a4b70514112c1f52b5_proc_1604460/SPR_BENCH_loss_curves.png"}, {"analysis": "The test weighted accuracy metrics (CWA, SWA, GCWA) are relatively stable across different hidden dimensions, with only slight variations. All configurations achieve accuracies close to or above the SOTA thresholds (CWA=70.0% and SWA=65.0%), with h=256 showing a marginal advantage. This indicates that while increasing the hidden dimension improves loss metrics, the impact on accuracy metrics is less pronounced. The stability in accuracy across hidden dimensions suggests that the model's performance is robust to changes in this hyperparameter.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f4952ad0bdbb48a4b70514112c1f52b5_proc_1604460/SPR_BENCH_test_metrics.png"}], [{"analysis": "This plot shows the training and validation loss trends for different weight decay (wd) values. The loss consistently decreases with epochs for all wd values, indicating effective learning. The wd=0.0 configuration achieves the lowest loss for both training and validation, suggesting overfitting to the training data. wd=0.001 shows slightly higher validation loss but better generalization.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the Color-Weighted Accuracy (CWA) trends across epochs for various weight decay values. All configurations show a rapid increase in CWA within the first two epochs, stabilizing afterward. wd=0.001 achieves the highest CWA, indicating that this weight decay value may improve learning of color-related features.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_CWA_curves.png"}, {"analysis": "This plot depicts the Shape-Weighted Accuracy (SWA) trends across epochs for different weight decay values. Similar to CWA, all configurations quickly converge, with wd=0.001 achieving the highest SWA. This suggests that wd=0.001 is also beneficial for learning shape-related features.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_SWA_curves.png"}, {"analysis": "This plot shows the Glyph-Complexity-Weighted Accuracy (GCWA) trends across epochs for different weight decay values. The trends are consistent with CWA and SWA, with wd=0.001 achieving the best performance. This indicates that wd=0.001 strikes a good balance in learning glyph complexity features.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_GCWA_curves.png"}, {"analysis": "This bar chart compares the final test metrics (CWA, SWA, GCWA) for different weight decay values. All metrics are relatively similar across configurations, but wd=0.001 slightly outperforms others. This reinforces that wd=0.001 is the optimal choice for generalization across all metrics.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6c7faa8bf6f4fa189ad63aa1a7f99a3_proc_1604461/SPR_BENCH_test_metrics.png"}], [{"analysis": "The plot for training vs. validation loss is empty, indicating that no data has been plotted. This could suggest an issue with the logging or visualization of the loss metrics during training. Without this data, it is impossible to assess the convergence behavior or detect overfitting.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_1724ddecc0cc439b954a6b666b7a9fab_proc_1604462/SPR_BENCH_loss_curves.png"}, {"analysis": "The validation GCWA vs. epoch plot is also empty, showing no data. This prevents any analysis of the model's performance on the validation set over epochs, which is critical for understanding how well the model generalizes.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_1724ddecc0cc439b954a6b666b7a9fab_proc_1604462/SPR_BENCH_val_GCWA_curves.png"}, {"analysis": "The test metrics per dropout plot is blank, indicating that no results for CWA, SWA, or GCWA across different dropout rates have been visualized. This makes it impossible to evaluate the impact of dropout on test performance or to identify an optimal dropout rate.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_1724ddecc0cc439b954a6b666b7a9fab_proc_1604462/SPR_BENCH_test_metric_bars.png"}], [{"analysis": "The training loss decreases steadily across all embedding dimensions as the number of epochs increases, indicating that the model is learning effectively. Higher embedding dimensions (e.g., 64 and 32) converge faster and achieve lower final loss values compared to lower embedding dimensions (e.g., 4 and 8). This suggests that larger embedding dimensions may allow the model to capture more complex patterns, leading to better optimization during training.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6b0364c3fe14110aa7e8dfa579402b0_proc_1604461/SPR_BENCH_training_loss_curves.png"}, {"analysis": "The validation loss follows a similar trend to the training loss, with higher embedding dimensions achieving lower final loss values. This indicates that the model generalizes better with larger embedding dimensions. The gap between training and validation loss is minimal across all dimensions, suggesting that the model is not overfitting.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6b0364c3fe14110aa7e8dfa579402b0_proc_1604461/SPR_BENCH_validation_loss_curves.png"}, {"analysis": "The test metrics (CWA, SWA, GCWA) are relatively stable across different embedding dimensions, with no significant performance improvement as the embedding dimension increases. While higher embedding dimensions lead to better training and validation loss, this does not translate into a substantial improvement in test metrics. This suggests that the choice of embedding dimension has a limited impact on the final performance metrics.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6b0364c3fe14110aa7e8dfa579402b0_proc_1604461/SPR_BENCH_test_metrics.png"}], [{"analysis": "This plot shows the training loss across different embedding dimensions (emb_dim) as the number of epochs increases. All configurations exhibit a consistent decrease in training loss, indicating effective learning. The larger embedding dimensions (e.g., emb_dim=64) achieve lower final training losses, suggesting that higher embedding dimensions capture more information and lead to better optimization. However, the diminishing gap between embedding dimensions as epochs increase suggests that the performance difference becomes less significant with sufficient training.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_8081a9d9145a4ce49de09ebbda7b3d36_proc_1604462/SPR_BENCH_training_loss_curves.png"}, {"analysis": "This plot illustrates the validation loss across different embedding dimensions over the epochs. Similar to the training loss, the validation loss decreases consistently for all configurations, confirming that the model generalizes well to unseen data. Embedding dimensions of 64 and 32 achieve the lowest validation losses, suggesting that larger embeddings improve generalization. The convergence trends also appear stable, with no signs of overfitting within the observed epochs.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_8081a9d9145a4ce49de09ebbda7b3d36_proc_1604462/SPR_BENCH_validation_loss_curves.png"}, {"analysis": "This plot compares the test set performance metrics (CWA, SWA, GCWA) across different embedding dimensions. The scores are relatively consistent across all dimensions, with only slight variations. While larger embedding dimensions (e.g., 64) show marginally better scores, the improvement is not substantial. This suggests that while embedding size affects training and validation losses, its impact on the test metrics is less pronounced. The overall test metric scores remain below the SOTA targets (70% for CWA and 65% for SWA), indicating room for further improvement through other hyperparameter optimizations or model refinements.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_8081a9d9145a4ce49de09ebbda7b3d36_proc_1604462/SPR_BENCH_test_metrics.png"}], [{"analysis": "This plot shows the training loss curves for different embedding dimensions (emb_dim). As the number of epochs increases, the training loss decreases consistently for all embedding dimensions, indicating effective learning. Larger embedding dimensions (e.g., 64) result in faster convergence and lower final training loss, suggesting that increasing the embedding dimension improves model capacity and performance during training.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2b39d2fb89c748c594c81245f2e9b40d_proc_1604459/SPR_BENCH_training_loss_curves.png"}, {"analysis": "This plot depicts the validation loss curves for various embedding dimensions. Similar to the training loss, the validation loss decreases as the number of epochs increases, demonstrating improved generalization. The embedding dimension of 64 achieves the lowest validation loss, indicating better generalization performance. However, the gap between training and validation loss should be monitored for overfitting.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2b39d2fb89c748c594c81245f2e9b40d_proc_1604459/SPR_BENCH_validation_loss_curves.png"}, {"analysis": "This bar chart summarizes the test metrics (CWA, SWA, GCWA) across different embedding dimensions. The scores are relatively stable across dimensions, with slight improvements as the embedding dimension increases. However, the differences are not substantial, suggesting diminishing returns for larger embedding dimensions. All metrics remain below the stated SOTA thresholds, indicating room for further optimization.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2b39d2fb89c748c594c81245f2e9b40d_proc_1604459/SPR_BENCH_test_metrics.png"}], []], "vlm_feedback_summary": ["[]", "[]", "The results highlight a consistent decrease in training loss and improvements in\nvalidation accuracy with smaller batch sizes showing better generalization.\nHowever, the test metrics indicate limited impact of batch size on final\nperformance, and the model has not yet achieved SOTA performance, suggesting\nfurther optimization is needed.", "The plots demonstrate consistent improvement in training and validation loss\nwith increasing embedding dimensions, but the test metrics remain stable,\nindicating limited generalization benefits from larger embeddings.", "The experimental plots provide clear insights into the performance of different\nruns and configurations. 'Run1' consistently outperforms 'Run2' and 'Run3'\nacross all metrics, making it the most effective setup. Validation and test\nmetrics align well, indicating no significant overfitting, and the model shows\nsteady improvements in accuracy over epochs.", "The results indicate that increasing the hidden dimension improves convergence\nand reduces loss, particularly for larger values like h=256. However, the impact\non accuracy metrics (CWA, SWA, GCWA) is minimal, suggesting diminishing returns\nin accuracy improvement with larger hidden dimensions.", "The plots indicate that the weight decay parameter significantly impacts the\nmodel's performance. wd=0.001 consistently achieves the highest accuracy across\nmetrics (CWA, SWA, GCWA) while maintaining a good balance between training and\nvalidation loss, suggesting it is the optimal choice for this experiment.", "All provided plots are empty and lack data. This prevents any meaningful\nanalysis or insights into the experiment's results. It is recommended to ensure\nproper logging and visualization of metrics to enable effective evaluation of\nthe model's performance.", "The results indicate that larger embedding dimensions improve training and\nvalidation loss but do not significantly enhance test metrics. This suggests\nthat while the model learns better representations with larger embeddings, these\ndo not necessarily translate into improved generalization on the test set.", "The plots effectively show the impact of embedding dimensions on training and\nvalidation losses, as well as test metrics. Larger embedding dimensions\ngenerally improve performance, but the gains diminish with sufficient training\nepochs. Test metric scores remain below SOTA, highlighting the need for further\noptimization.", "The plots provide insights into the impact of embedding dimensions on training\nand validation loss as well as test metrics. Larger embedding dimensions improve\nconvergence and generalization, but test metric improvements are marginal,\nsuggesting further optimization is needed to surpass SOTA performance.", "[]"], "exec_time": [3.5836472511291504, 3.3874993324279785, 14.067602396011353, 34.94245624542236, 12.535905122756958, 10.27694821357727, 10.6626296043396, 23.557291746139526, 41.99555587768555, 18.45482301712036, 16.949298858642578, null], "exec_time_feedback": ["", "", "", "Implementation works but runs too quickly (0.58 minutes).We have up to 60\nminutes available for each experiment.Make sure to scale up the experiment by\nincreasing the number of epochs, using a larger model, or working with bigger\ndatasets.Given that the current execution time is {exec_time_minutes:.2f}\nminutes, think about how changing the number of epochs to run, or using a larger\nmodel, or working with bigger datasets to runwill affect the execution time, and\nmake sure to scale up the experiment accordingly.", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [[], [], ["[]"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[]"], ["['SPR_BENCH']"], ["['SPR_BENCH']"], ["\"\""], []], "plot_code": [null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# mandatory working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------- load experiment data ---------------- #\nexp_path_candidates = [\n    os.path.join(os.getcwd(), \"experiment_data.npy\"),\n    os.path.join(working_dir, \"experiment_data.npy\"),\n]\nexperiment_data = None\nfor p in exp_path_candidates:\n    try:\n        experiment_data = np.load(p, allow_pickle=True).item()\n        break\n    except Exception:\n        pass\n\nif experiment_data is None:\n    print(\"Could not locate experiment_data.npy\")\n    exit()\n\n# ---------------- parse metrics ---------------- #\ndataset = \"SPR_BENCH\"\nbs_entries = experiment_data[\"batch_size\"].get(dataset, {})\nbatch_sizes = sorted(bs_entries.keys(), key=int)\n\nloss_curves = {}\ncwa_curves = {}\ntest_metrics = {}\n\nfor bs in batch_sizes:\n    entry = bs_entries[bs]\n    loss_curves[int(bs)] = (entry[\"losses\"][\"train\"], entry[\"losses\"][\"val\"])\n    cwa = [m[\"CWA\"] for m in entry[\"metrics\"][\"val\"]]\n    cwa_curves[int(bs)] = cwa\n    test_metrics[int(bs)] = entry[\"metrics\"][\"test\"]\n\n\n# ---------------- plotting utilities ---------------- #\ndef save_fig(fig, fname):\n    fig.savefig(os.path.join(working_dir, fname), bbox_inches=\"tight\")\n    plt.close(fig)\n\n\n# ---------------- 1. loss curves ---------------- #\ntry:\n    fig = plt.figure()\n    for bs in batch_sizes:\n        t, v = loss_curves[int(bs)]\n        epochs = range(1, len(t) + 1)\n        plt.plot(epochs, t, \"--\", label=f\"{bs}-train\")\n        plt.plot(epochs, v, \"-\", label=f\"{bs}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"SPR_BENCH Training vs Validation Loss\")\n    plt.legend()\n    save_fig(fig, \"SPR_BENCH_loss_curves.png\")\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---------------- 2. CWA curves ---------------- #\ntry:\n    fig = plt.figure()\n    for bs in batch_sizes:\n        cwa = cwa_curves[int(bs)]\n        epochs = range(1, len(cwa) + 1)\n        plt.plot(epochs, cwa, label=f\"{bs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CWA\")\n    plt.title(\"SPR_BENCH Validation Color-Weighted Accuracy (CWA)\")\n    plt.legend(title=\"Batch Size\")\n    save_fig(fig, \"SPR_BENCH_CWA_curves.png\")\nexcept Exception as e:\n    print(f\"Error creating CWA curves: {e}\")\n    plt.close()\n\n# ---------------- 3. test metric bars ---------------- #\ntry:\n    fig, ax = plt.subplots()\n    ind = np.arange(len(batch_sizes))\n    width = 0.25\n    cwa_vals = [test_metrics[int(bs)][\"CWA\"] for bs in batch_sizes]\n    swa_vals = [test_metrics[int(bs)][\"SWA\"] for bs in batch_sizes]\n    gcwa_vals = [test_metrics[int(bs)][\"GCWA\"] for bs in batch_sizes]\n    ax.bar(ind - width, cwa_vals, width, label=\"CWA\")\n    ax.bar(ind, swa_vals, width, label=\"SWA\")\n    ax.bar(ind + width, gcwa_vals, width, label=\"GCWA\")\n    ax.set_xticks(ind)\n    ax.set_xticklabels(batch_sizes)\n    ax.set_xlabel(\"Batch Size\")\n    ax.set_ylabel(\"Score\")\n    ax.set_title(\"SPR_BENCH Test Metrics by Batch Size\")\n    ax.legend()\n    save_fig(fig, \"SPR_BENCH_test_metric_bars.png\")\nexcept Exception as e:\n    print(f\"Error creating test metric bar chart: {e}\")\n    plt.close()\n\n# ---------------- print numerical summary ---------------- #\nprint(\"\\n=== SPR_BENCH Test Metrics ===\")\nfor bs in batch_sizes:\n    tm = test_metrics[int(bs)]\n    print(f'BS {bs}: CWA={tm[\"CWA\"]:.3f}, SWA={tm[\"SWA\"]:.3f}, GCWA={tm[\"GCWA\"]:.3f}')\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data.get(\"embedding_dim_tuning\", {}).get(\"SPR_BENCH\", {})\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = {}\n\nif exp:\n    emb_dims = sorted(int(k.split(\"_\")[-1]) for k in exp.keys())\n    train_losses, val_losses, test_metrics = {}, {}, {}\n\n    for ed in emb_dims:\n        key = f\"emb_dim_{ed}\"\n        d = exp[key]\n        train_losses[ed] = d[\"losses\"][\"train\"]\n        val_losses[ed] = d[\"losses\"][\"val\"]\n        test_metrics[ed] = d[\"metrics\"][\"test\"]\n\n    # ---------- plot 1: training loss ----------\n    try:\n        plt.figure()\n        for ed in emb_dims:\n            plt.plot(\n                range(1, len(train_losses[ed]) + 1),\n                train_losses[ed],\n                label=f\"emb_dim={ed}\",\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Training Loss\")\n        plt.title(\"SPR_BENCH Training Loss vs Epoch\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_training_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating training loss plot: {e}\")\n        plt.close()\n\n    # ---------- plot 2: validation loss ----------\n    try:\n        plt.figure()\n        for ed in emb_dims:\n            plt.plot(\n                range(1, len(val_losses[ed]) + 1), val_losses[ed], label=f\"emb_dim={ed}\"\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Loss\")\n        plt.title(\"SPR_BENCH Validation Loss vs Epoch\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_validation_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating validation loss plot: {e}\")\n        plt.close()\n\n    # ---------- plot 3: test metrics ----------\n    try:\n        labels = [\"CWA\", \"SWA\", \"GCWA\"]\n        x = np.arange(len(emb_dims))\n        width = 0.25\n        plt.figure()\n        for i, m in enumerate(labels):\n            vals = [test_metrics[ed][m] for ed in emb_dims]\n            plt.bar(x + (i - 1) * width, vals, width, label=m)\n        plt.xticks(x, [str(ed) for ed in emb_dims])\n        plt.ylim(0, 1)\n        plt.ylabel(\"Score\")\n        plt.title(\n            \"SPR_BENCH Test Metrics across Embedding Dimensions\\n\"\n            \"Left: CWA, Center: SWA, Right: GCWA\"\n        )\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_test_metrics.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metrics plot: {e}\")\n        plt.close()\n\n    # ---------- print metrics ----------\n    print(\"Test-set metrics by embedding dimension:\")\n    for ed in emb_dims:\n        print(f\"  emb_dim={ed}: {test_metrics[ed]}\")\nelse:\n    print(\"No experiment data found to plot.\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- directories ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ndata_key = \"SPR_BENCH\"\nif data_key not in experiment_data:\n    print(f\"No data found for key {data_key}\")\n    exit()\n\nruns = experiment_data[data_key]\ntrain_losses_runs = runs[\"losses\"][\"train\"]\nval_losses_runs = runs[\"losses\"][\"val\"]\nval_metrics_runs = runs[\"metrics\"][\"val\"]\ntest_metrics_runs = runs[\"metrics\"][\"test\"]\n\n# ---------- 1) train / val loss curves ----------\ntry:\n    plt.figure()\n    for idx, (tr, vl) in enumerate(zip(train_losses_runs, val_losses_runs)):\n        epochs = np.arange(1, len(tr) + 1)\n        plt.plot(epochs, tr, \"-o\", label=f\"run{idx+1} train\")\n        plt.plot(epochs, vl, \"--o\", label=f\"run{idx+1} val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ---------- 2) GCWA validation curves ----------\ntry:\n    plt.figure()\n    for idx, val_hist in enumerate(val_metrics_runs):\n        gcwa = [m[\"GCWA\"] for m in val_hist]\n        epochs = np.arange(1, len(gcwa) + 1)\n        plt.plot(epochs, gcwa, \"-o\", label=f\"run{idx+1}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"GCWA\")\n    plt.title(\"SPR_BENCH: Validation GCWA over Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_gcwa_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating GCWA curve plot: {e}\")\n    plt.close()\n\n# ---------- 3) final test metrics bar chart ----------\ntry:\n    metrics_names = [\"CWA\", \"SWA\", \"GCWA\"]\n    x = np.arange(len(metrics_names))\n    width = 0.25\n    plt.figure()\n    for idx, tm in enumerate(test_metrics_runs):\n        vals = [tm[m] for m in metrics_names]\n        plt.bar(x + width * idx, vals, width=width, label=f\"run{idx+1}\")\n    plt.xticks(x + width, metrics_names)\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"SPR_BENCH: Test Metrics per Run\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_test_metrics.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metrics bar plot: {e}\")\n    plt.close()\n\nprint(\"Plots saved to\", working_dir)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------- load data ---------------- #\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    ed = experiment_data[\"hidden_dim\"][\"SPR_BENCH\"]\n    hidden_dims = sorted(ed[\"losses\"][\"train\"].keys())\n    epochs = len(next(iter(ed[\"losses\"][\"train\"].values())))  # length of any loss list\n\n    # ----------- Plot 1: loss curves ----------- #\n    try:\n        plt.figure(figsize=(10, 4))\n        plt.suptitle(\"SPR_BENCH: Loss Curves by Hidden Dimension\")\n        # Left subplot: training loss\n        ax1 = plt.subplot(1, 2, 1)\n        for hd in hidden_dims:\n            ax1.plot(range(1, epochs + 1), ed[\"losses\"][\"train\"][hd], label=f\"h={hd}\")\n        ax1.set_title(\"Left: Training Loss\")\n        ax1.set_xlabel(\"Epoch\")\n        ax1.set_ylabel(\"Loss\")\n        ax1.legend()\n\n        # Right subplot: validation loss\n        ax2 = plt.subplot(1, 2, 2)\n        for hd in hidden_dims:\n            ax2.plot(range(1, epochs + 1), ed[\"losses\"][\"val\"][hd], label=f\"h={hd}\")\n        ax2.set_title(\"Right: Validation Loss\")\n        ax2.set_xlabel(\"Epoch\")\n        ax2.set_ylabel(\"Loss\")\n        ax2.legend()\n\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ----------- Plot 2: test metrics ----------- #\n    try:\n        metrics_names = [\"CWA\", \"SWA\", \"GCWA\"]\n        bar_width = 0.2\n        x = np.arange(len(hidden_dims))\n\n        plt.figure(figsize=(8, 5))\n        for i, m in enumerate(metrics_names):\n            vals = [ed[\"metrics\"][\"test\"][hd][m] for hd in hidden_dims]\n            plt.bar(x + i * bar_width, vals, width=bar_width, label=m)\n\n        plt.title(\"SPR_BENCH: Test Weighted Accuracies by Hidden Dimension\")\n        plt.xlabel(\"Hidden Dimension\")\n        plt.ylabel(\"Accuracy\")\n        plt.xticks(x + bar_width, [str(hd) for hd in hidden_dims])\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_test_metrics.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(f\"Saved {fname}\")\n    except Exception as e:\n        print(f\"Error creating metrics bar plot: {e}\")\n        plt.close()\n\n    # ----------- Print test metrics table ----------- #\n    print(\"\\nFinal Test Metrics\")\n    print(\"hd\\tCWA\\tSWA\\tGCWA\")\n    for hd in hidden_dims:\n        m = ed[\"metrics\"][\"test\"][hd]\n        print(f'{hd}\\t{m[\"CWA\"]:.3f}\\t{m[\"SWA\"]:.3f}\\t{m[\"GCWA\"]:.3f}')\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ---------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ---------- #\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    wd_data = experiment_data.get(\"weight_decay\", {})\n    wds = sorted(wd_data.keys(), key=float)  # sort numerically as strings\n    epochs = len(next(iter(wd_data.values()))[\"SPR_BENCH\"][\"losses\"][\"train\"])\n\n    # ----- gather tensors -----\n    tr_loss, va_loss, cwa, swa, gcwa, test_m = {}, {}, {}, {}, {}, {}\n    for wd in wds:\n        d = wd_data[wd][\"SPR_BENCH\"]\n        tr_loss[wd] = d[\"losses\"][\"train\"]\n        va_loss[wd] = d[\"losses\"][\"val\"]\n        cwa[wd] = [m[\"CWA\"] for m in d[\"metrics\"][\"val\"]]\n        swa[wd] = [m[\"SWA\"] for m in d[\"metrics\"][\"val\"]]\n        gcwa[wd] = [m[\"GCWA\"] for m in d[\"metrics\"][\"val\"]]\n        test_m[wd] = d[\"metrics\"][\"test\"]\n\n    # Common style helpers\n    epoch_idx = list(range(1, epochs + 1))\n    colours = plt.cm.tab10(np.linspace(0, 1, len(wds)))\n\n    # ---------- 1. Loss curves ----------\n    try:\n        plt.figure()\n        for i, wd in enumerate(wds):\n            plt.plot(\n                epoch_idx,\n                tr_loss[wd],\n                linestyle=\"--\",\n                color=colours[i],\n                label=f\"wd={wd} train\",\n            )\n            plt.plot(\n                epoch_idx,\n                va_loss[wd],\n                linestyle=\"-\",\n                color=colours[i],\n                label=f\"wd={wd} val\",\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH: Train vs Validation Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # ---------- 2. CWA curves ----------\n    try:\n        plt.figure()\n        for i, wd in enumerate(wds):\n            plt.plot(epoch_idx, cwa[wd], color=colours[i], label=f\"wd={wd}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CWA\")\n        plt.title(\"SPR_BENCH: Color-Weighted Accuracy across Epochs\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_CWA_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CWA plot: {e}\")\n        plt.close()\n\n    # ---------- 3. SWA curves ----------\n    try:\n        plt.figure()\n        for i, wd in enumerate(wds):\n            plt.plot(epoch_idx, swa[wd], color=colours[i], label=f\"wd={wd}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SWA\")\n        plt.title(\"SPR_BENCH: Shape-Weighted Accuracy across Epochs\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_SWA_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot: {e}\")\n        plt.close()\n\n    # ---------- 4. GCWA curves ----------\n    try:\n        plt.figure()\n        for i, wd in enumerate(wds):\n            plt.plot(epoch_idx, gcwa[wd], color=colours[i], label=f\"wd={wd}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"GCWA\")\n        plt.title(\"SPR_BENCH: Glyph-Complexity-Weighted Accuracy across Epochs\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_GCWA_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating GCWA plot: {e}\")\n        plt.close()\n\n    # ---------- 5. Test metric bar chart ----------\n    try:\n        labels = [\"CWA\", \"SWA\", \"GCWA\"]\n        x = np.arange(len(labels))\n        width = 0.18\n        plt.figure()\n        for i, wd in enumerate(wds):\n            vals = [test_m[wd][k] for k in labels]\n            plt.bar(x + i * width, vals, width, label=f\"wd={wd}\", color=colours[i])\n        plt.xticks(x + width * (len(wds) - 1) / 2, labels)\n        plt.ylabel(\"Score\")\n        plt.title(\"SPR_BENCH: Test Metrics by Weight Decay\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_test_metrics.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metrics plot: {e}\")\n        plt.close()\n\n    # ---------- print table ----------\n    print(\"\\n=== Test Metrics (SPR_BENCH) ===\")\n    for wd in wds:\n        t = test_m[wd]\n        print(\n            f\"wd={wd:>6}: CWA={t['CWA']:.3f}, SWA={t['SWA']:.3f}, GCWA={t['GCWA']:.3f}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# Helper to fetch arrays safely\ndef get_lists(drop_dict, key):\n    return [drop_dict[d][\"SPR_BENCH\"][key] for d in drop_dict]\n\n\ndropout_dict = experiment_data.get(\"dropout_rate\", {})\ndropouts = sorted(dropout_dict.keys())\nloss_train = [v[\"SPR_BENCH\"][\"losses\"][\"train\"] for v in dropout_dict.values()]\nloss_val = [v[\"SPR_BENCH\"][\"losses\"][\"val\"] for v in dropout_dict.values()]\ngcwa_val = [\n    [e[\"GCWA\"] for e in v[\"SPR_BENCH\"][\"metrics\"][\"val\"]] for v in dropout_dict.values()\n]\ntest_metrics = {\n    d: dropout_dict[d][\"SPR_BENCH\"][\"metrics\"][\"test\"] for d in dropout_dict\n}\n\n# ---------- plotting ----------\ntry:\n    plt.figure()\n    for d, tr, vl in zip(dropouts, loss_train, loss_val):\n        epochs = np.arange(1, len(tr) + 1)\n        plt.plot(epochs, tr, \"--\", label=f\"train loss d={d}\")\n        plt.plot(epochs, vl, \"-\", label=f\"val loss d={d}\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend(fontsize=6)\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname, dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    for d, gc in zip(dropouts, gcwa_val):\n        epochs = np.arange(1, len(gc) + 1)\n        plt.plot(epochs, gc, label=f\"d={d}\")\n    plt.title(\"SPR_BENCH: Validation GCWA vs Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"GCWA\")\n    plt.legend(fontsize=6)\n    fname = os.path.join(working_dir, \"SPR_BENCH_val_GCWA_curves.png\")\n    plt.savefig(fname, dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating GCWA plot: {e}\")\n    plt.close()\n\ntry:\n    metrics = [\"CWA\", \"SWA\", \"GCWA\"]\n    x = np.arange(len(dropouts))\n    width = 0.25\n    plt.figure()\n    for i, m in enumerate(metrics):\n        vals = [test_metrics[d][m] for d in dropouts]\n        plt.bar(x + i * width - width, vals, width, label=m)\n    plt.title(\"SPR_BENCH: Test Metrics per Dropout\")\n    plt.xlabel(\"Dropout Rate\")\n    plt.ylabel(\"Score\")\n    plt.xticks(x, [str(d) for d in dropouts])\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_test_metric_bars.png\")\n    plt.savefig(fname, dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metrics bar plot: {e}\")\n    plt.close()\n\n# ---------- print table ----------\nfor d in dropouts:\n    m = test_metrics[d]\n    print(f\"dropout={d}: CWA={m['CWA']:.3f}, SWA={m['SWA']:.3f}, GCWA={m['GCWA']:.3f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data.get(\"embedding_dim_tuning\", {}).get(\"SPR_BENCH\", {})\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = {}\n\nif exp:\n    emb_dims = sorted(int(k.split(\"_\")[-1]) for k in exp.keys())\n    train_losses, val_losses, test_metrics = {}, {}, {}\n\n    for ed in emb_dims:\n        key = f\"emb_dim_{ed}\"\n        d = exp[key]\n        train_losses[ed] = d[\"losses\"][\"train\"]\n        val_losses[ed] = d[\"losses\"][\"val\"]\n        test_metrics[ed] = d[\"metrics\"][\"test\"]\n\n    # ---------- plot 1: training loss ----------\n    try:\n        plt.figure()\n        for ed in emb_dims:\n            plt.plot(\n                range(1, len(train_losses[ed]) + 1),\n                train_losses[ed],\n                label=f\"emb_dim={ed}\",\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Training Loss\")\n        plt.title(\"SPR_BENCH Training Loss vs Epoch\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_training_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating training loss plot: {e}\")\n        plt.close()\n\n    # ---------- plot 2: validation loss ----------\n    try:\n        plt.figure()\n        for ed in emb_dims:\n            plt.plot(\n                range(1, len(val_losses[ed]) + 1), val_losses[ed], label=f\"emb_dim={ed}\"\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Loss\")\n        plt.title(\"SPR_BENCH Validation Loss vs Epoch\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_validation_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating validation loss plot: {e}\")\n        plt.close()\n\n    # ---------- plot 3: test metrics ----------\n    try:\n        labels = [\"CWA\", \"SWA\", \"GCWA\"]\n        x = np.arange(len(emb_dims))\n        width = 0.25\n        plt.figure()\n        for i, m in enumerate(labels):\n            vals = [test_metrics[ed][m] for ed in emb_dims]\n            plt.bar(x + (i - 1) * width, vals, width, label=m)\n        plt.xticks(x, [str(ed) for ed in emb_dims])\n        plt.ylim(0, 1)\n        plt.ylabel(\"Score\")\n        plt.title(\n            \"SPR_BENCH Test Metrics across Embedding Dimensions\\n\"\n            \"Left: CWA, Center: SWA, Right: GCWA\"\n        )\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_test_metrics.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metrics plot: {e}\")\n        plt.close()\n\n    # ---------- print metrics ----------\n    print(\"Test-set metrics by embedding dimension:\")\n    for ed in emb_dims:\n        print(f\"  emb_dim={ed}: {test_metrics[ed]}\")\nelse:\n    print(\"No experiment data found to plot.\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data.get(\"embedding_dim_tuning\", {}).get(\"SPR_BENCH\", {})\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = {}\n\nif exp:\n    emb_dims = sorted(int(k.split(\"_\")[-1]) for k in exp.keys())\n    train_losses, val_losses, test_metrics = {}, {}, {}\n\n    for ed in emb_dims:\n        key = f\"emb_dim_{ed}\"\n        d = exp[key]\n        train_losses[ed] = d[\"losses\"][\"train\"]\n        val_losses[ed] = d[\"losses\"][\"val\"]\n        test_metrics[ed] = d[\"metrics\"][\"test\"]\n\n    # ---------- plot 1: training loss ----------\n    try:\n        plt.figure()\n        for ed in emb_dims:\n            plt.plot(\n                range(1, len(train_losses[ed]) + 1),\n                train_losses[ed],\n                label=f\"emb_dim={ed}\",\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Training Loss\")\n        plt.title(\"SPR_BENCH Training Loss vs Epoch\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_training_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating training loss plot: {e}\")\n        plt.close()\n\n    # ---------- plot 2: validation loss ----------\n    try:\n        plt.figure()\n        for ed in emb_dims:\n            plt.plot(\n                range(1, len(val_losses[ed]) + 1), val_losses[ed], label=f\"emb_dim={ed}\"\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Loss\")\n        plt.title(\"SPR_BENCH Validation Loss vs Epoch\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_validation_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating validation loss plot: {e}\")\n        plt.close()\n\n    # ---------- plot 3: test metrics ----------\n    try:\n        labels = [\"CWA\", \"SWA\", \"GCWA\"]\n        x = np.arange(len(emb_dims))\n        width = 0.25\n        plt.figure()\n        for i, m in enumerate(labels):\n            vals = [test_metrics[ed][m] for ed in emb_dims]\n            plt.bar(x + (i - 1) * width, vals, width, label=m)\n        plt.xticks(x, [str(ed) for ed in emb_dims])\n        plt.ylim(0, 1)\n        plt.ylabel(\"Score\")\n        plt.title(\n            \"SPR_BENCH Test Metrics across Embedding Dimensions\\n\"\n            \"Left: CWA, Center: SWA, Right: GCWA\"\n        )\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_test_metrics.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metrics plot: {e}\")\n        plt.close()\n\n    # ---------- print metrics ----------\n    print(\"Test-set metrics by embedding dimension:\")\n    for ed in emb_dims:\n        print(f\"  emb_dim={ed}: {test_metrics[ed]}\")\nelse:\n    print(\"No experiment data found to plot.\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data.get(\"embedding_dim_tuning\", {}).get(\"SPR_BENCH\", {})\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = {}\n\nif exp:\n    emb_dims = sorted(int(k.split(\"_\")[-1]) for k in exp.keys())\n    train_losses, val_losses, test_metrics = {}, {}, {}\n\n    for ed in emb_dims:\n        key = f\"emb_dim_{ed}\"\n        d = exp[key]\n        train_losses[ed] = d[\"losses\"][\"train\"]\n        val_losses[ed] = d[\"losses\"][\"val\"]\n        test_metrics[ed] = d[\"metrics\"][\"test\"]\n\n    # ---------- plot 1: training loss ----------\n    try:\n        plt.figure()\n        for ed in emb_dims:\n            plt.plot(\n                range(1, len(train_losses[ed]) + 1),\n                train_losses[ed],\n                label=f\"emb_dim={ed}\",\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Training Loss\")\n        plt.title(\"SPR_BENCH Training Loss vs Epoch\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_training_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating training loss plot: {e}\")\n        plt.close()\n\n    # ---------- plot 2: validation loss ----------\n    try:\n        plt.figure()\n        for ed in emb_dims:\n            plt.plot(\n                range(1, len(val_losses[ed]) + 1), val_losses[ed], label=f\"emb_dim={ed}\"\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Validation Loss\")\n        plt.title(\"SPR_BENCH Validation Loss vs Epoch\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_validation_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating validation loss plot: {e}\")\n        plt.close()\n\n    # ---------- plot 3: test metrics ----------\n    try:\n        labels = [\"CWA\", \"SWA\", \"GCWA\"]\n        x = np.arange(len(emb_dims))\n        width = 0.25\n        plt.figure()\n        for i, m in enumerate(labels):\n            vals = [test_metrics[ed][m] for ed in emb_dims]\n            plt.bar(x + (i - 1) * width, vals, width, label=m)\n        plt.xticks(x, [str(ed) for ed in emb_dims])\n        plt.ylim(0, 1)\n        plt.ylabel(\"Score\")\n        plt.title(\n            \"SPR_BENCH Test Metrics across Embedding Dimensions\\n\"\n            \"Left: CWA, Center: SWA, Right: GCWA\"\n        )\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_test_metrics.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metrics plot: {e}\")\n        plt.close()\n\n    # ---------- print metrics ----------\n    print(\"Test-set metrics by embedding dimension:\")\n    for ed in emb_dims:\n        print(f\"  emb_dim={ed}: {test_metrics[ed]}\")\nelse:\n    print(\"No experiment data found to plot.\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- working directory ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- collect all experiment paths ----------\nexperiment_data_path_list = [\n    \"experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6b0364c3fe14110aa7e8dfa579402b0_proc_1604461/experiment_data.npy\",\n    \"experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_8081a9d9145a4ce49de09ebbda7b3d36_proc_1604462/experiment_data.npy\",\n    \"experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2b39d2fb89c748c594c81245f2e9b40d_proc_1604459/experiment_data.npy\",\n]\n\nall_experiment_data = []\nfor p in experiment_data_path_list:\n    try:\n        full_p = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p)\n        data = np.load(full_p, allow_pickle=True).item()\n        all_experiment_data.append(data)\n    except Exception as e:\n        print(f\"Error loading {p}: {e}\")\n\n# ---------- aggregate data ----------\ntrain_runs, val_runs, metric_runs = {}, {}, {}  # keyed by emb_dim\nmetric_names = set()\nfor data in all_experiment_data:\n    exp = data.get(\"embedding_dim_tuning\", {}).get(\"SPR_BENCH\", {})\n    for k, v in exp.items():\n        emb_dim = int(k.split(\"_\")[-1])\n        # losses\n        train_runs.setdefault(emb_dim, []).append(np.array(v[\"losses\"][\"train\"]))\n        val_runs.setdefault(emb_dim, []).append(np.array(v[\"losses\"][\"val\"]))\n        # metrics\n        metric_runs.setdefault(emb_dim, {})\n        for m_name, m_val in v[\"metrics\"][\"test\"].items():\n            metric_names.add(m_name)\n            metric_runs[emb_dim].setdefault(m_name, []).append(m_val)\n\nemb_dims = sorted(train_runs.keys())\nmetric_names = sorted(metric_names)\n\n\ndef mean_sem(arr_list):\n    \"\"\"Stack (after trimming to shortest length) and return mean and sem.\"\"\"\n    min_len = min(len(a) for a in arr_list)\n    stack = np.stack([a[:min_len] for a in arr_list], axis=0)\n    mean = stack.mean(axis=0)\n    sem = stack.std(axis=0, ddof=1) / np.sqrt(stack.shape[0])\n    return mean, sem\n\n\n# ---------- plot training loss ----------\ntry:\n    plt.figure()\n    for ed in emb_dims:\n        mean, sem = mean_sem(train_runs[ed])\n        epochs = np.arange(1, len(mean) + 1)\n        plt.plot(epochs, mean, label=f\"emb_dim={ed}\")\n        plt.fill_between(epochs, mean - sem, mean + sem, alpha=0.2)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Training Loss\")\n    plt.title(\"SPR_BENCH Training Loss (Mean \u00b1 SEM)\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_training_loss_mean_sem.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated training loss plot: {e}\")\n    plt.close()\n\n# ---------- plot validation loss ----------\ntry:\n    plt.figure()\n    for ed in emb_dims:\n        mean, sem = mean_sem(val_runs[ed])\n        epochs = np.arange(1, len(mean) + 1)\n        plt.plot(epochs, mean, label=f\"emb_dim={ed}\")\n        plt.fill_between(epochs, mean - sem, mean + sem, alpha=0.2)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Validation Loss\")\n    plt.title(\"SPR_BENCH Validation Loss (Mean \u00b1 SEM)\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_validation_loss_mean_sem.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated validation loss plot: {e}\")\n    plt.close()\n\n# ---------- plot test metrics ----------\ntry:\n    x = np.arange(len(emb_dims))\n    width = 0.25\n    plt.figure()\n    for i, m in enumerate(metric_names):\n        means, sems = [], []\n        for ed in emb_dims:\n            vals = metric_runs.get(ed, {}).get(m, [])\n            means.append(np.mean(vals) if vals else np.nan)\n            sems.append(\n                np.std(vals, ddof=1) / np.sqrt(len(vals)) if len(vals) > 1 else 0\n            )\n        plt.bar(\n            x + (i - (len(metric_names) - 1) / 2) * width,\n            means,\n            width,\n            yerr=sems,\n            capsize=3,\n            label=m,\n        )\n    plt.xticks(x, [str(ed) for ed in emb_dims])\n    plt.ylim(0, 1)\n    plt.ylabel(\"Score\")\n    plt.title(\n        \"SPR_BENCH Test Metrics (Mean \u00b1 SEM)\\nLeft: CWA, Center: SWA, Right: GCWA\"\n    )\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_test_metrics_mean_sem.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated test metrics plot: {e}\")\n    plt.close()\n\n# ---------- print aggregated results ----------\nfor ed in emb_dims:\n    print(f\"\\nEmbedding Dimension {ed}:\")\n    for m in metric_names:\n        vals = metric_runs.get(ed, {}).get(m, [])\n        if vals:\n            mean_val = np.mean(vals)\n            sem_val = np.std(vals, ddof=1) / np.sqrt(len(vals)) if len(vals) > 1 else 0\n            print(f\"  {m}: {mean_val:.4f} \u00b1 {sem_val:.4f} (n={len(vals)})\")\n        else:\n            print(f\"  {m}: No data\")\n"], "plot_plan": [null, null, "The script first loads the stored experiment_data.npy, safely handling missing files and creating a writable working directory. It then parses the dictionary to collect per-epoch train/validation losses, validation CWA scores, and final test metrics for each examined batch size of the SPR_BENCH dataset. Three concise visualizations are generated: (1) train vs. validation loss curves, (2) validation CWA curves, and (3) a bar chart summarizing test-set CWA, SWA, and GCWA across batch sizes. Each figure is produced inside its own try-except block to guarantee cleanup even if an error occurs, uses clear titles/subtitles, and is saved with descriptive names that include the dataset and plot type. Figures are limited to a maximum of three to avoid redundancy, and matplotlib figures are closed immediately after saving to free resources. Finally, the script prints a small table of the aggregated test metrics so users can quickly inspect numerical results without opening the plots.", "We first load experiment_data.npy and extract the sub-dictionary corresponding to the embedding-dimension sweep on SPR_BENCH.  For every emb_dim we collect (i) the per-epoch training losses, (ii) the per-epoch validation losses, and (iii) the final test metrics CWA, SWA, GCWA.  Three figures are produced: aggregated training-loss curves, aggregated validation-loss curves, and a grouped bar chart of the three test metrics across all embedding dimensions.  Each figure is wrapped in its own try-except so that failures in one do not affect the others, and every figure is saved inside working_dir with descriptive filenames before being closed.  Titles clearly specify dataset and plotting content, including \u201cLeft / Center / Right\u201d subtitles for the bar chart.  We limit ourselves to these three plots to comply with the \u201c\u22645 figures\u201d rule.  Finally, the code prints the collected test-set metrics so users can see the numerical values alongside the visualizations.  The implementation uses only matplotlib and numpy, relies exclusively on data present in experiment_data.npy, and follows the requested directory/cleanup conventions.", "We will load the saved experiment_data.npy, focus on the single dataset key \u201cSPR_BENCH\u201d, and extract for every learning-rate run: (a) the list of training losses per epoch, (b) the validation losses per epoch, (c) the per-epoch GCWA metric on the dev set, and (d) the final test-set metrics.  \nThree visualizations are produced, each wrapped in an independent try/except block:  \n1. Training vs. validation loss curves (one colour per run) so we can inspect convergence.  \n2. GCWA validation curves for the same runs to see how well glyph-complexity accuracy evolved.  \n3. A grouped bar chart of the final test metrics (CWA, SWA, GCWA) for every run to compare generalisation.  \nAll plots are titled descriptively, saved into working_dir with clear filenames containing the dataset name and plot type, and figures are always closed. We plot every epoch since there are only three, remaining under the 5-figure limit. Code finishes by optionally printing the filenames of the saved plots.", "We will load the saved experiment_data.npy, extract the nested results for the \u201cSPR_BENCH\u201d dataset and iterate over the four hidden-dim settings. First, we will assemble per-epoch training and validation losses, plotting them side-by-side in a single figure with two subplots: left for training, right for validation, each curve labeled by hidden_dim. Second, we will gather the final test-set weighted accuracies (CWA, SWA, GCWA) for every hidden_dim and show them as a grouped bar chart, one group per hidden_dim and three bars per group. Each plot is wrapped in its own try-except block, saved into the working directory with descriptive names, and the figures are always closed. We will also print a concise table of the three test metrics for every hidden_dim to stdout so the user can see numerical values. All plotting uses plain matplotlib without extra styling and only references data present in experiment_data.npy. At most two figures are produced, satisfying the \u22645 figure requirement. The code follows the mandatory import/working_dir header and closes figures in both normal and exception paths. Finally, the script can be run directly and produces the requested visualizations and metric printout.", "We load the saved experiment_data, iterate over the different weight-decay runs, and collect per-epoch losses as well as the three validation metrics and final test metrics. Then, inside five separate try-except blocks, we draw (1) train/validation loss curves, (2) CWA curves, (3) SWA curves, (4) GCWA curves, and (5) a grouped bar chart comparing test metrics across weight-decays. Every figure is titled with the dataset name \u201cSPR_BENCH\u201d and an informative subtitle, saved to working_dir with descriptive filenames, and explicitly closed. Finally, we print a small table of the test metrics so the script produces a quick textual summary in addition to the plots.", "We will load experiment_data.npy, iterate over the different dropout rates, and extract (1) the per-epoch training/validation losses, (2) the per-epoch validation GCWA, and (3) the final test-set metrics for every dropout value.  \nThree figures are produced:  \n\u2022 Fig-1 overlays training and validation loss curves for each dropout to visualise convergence.  \n\u2022 Fig-2 overlays validation GCWA curves for each dropout to study generalisation.  \n\u2022 Fig-3 is a bar-chart that compares the final test CWA, SWA and GCWA for all dropout settings.  \nAll plots are saved in ./working with descriptive names, each inside its own try-except block, and every figure is properly closed.  \nNo synthetic numbers are introduced\u2014everything is read from experiment_data.npy.  \nAt the end, the script prints a small table of the final test metrics so users can also see them in the console.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": ["epochs", "learning_rate", "batch_size", "embedding_dim", null, "hidden_dim (size of the intermediate fully-connected layer)", "weight_decay", "dropout_rate", null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["", "", "", "The script will load experiment_data.npy from the working directory, inspect its\nnested dictionaries and automatically choose the configuration with the highest\ntest GCWA score for each dataset. It then prints, for that best run, the final\nvalidation loss and accuracies together with the final test loss and all three\nweighted-accuracy metrics. All metrics are labelled explicitly (e.g., \u201ctest\ncolor weighted accuracy\u201d) and the dataset name precedes its block of printed\nresults. The code is kept at global scope so it executes as soon as the file is\nrun.", "The script loads the saved experiment data, identifies the run that achieved the\nhighest Glyph-Complexity-Weighted Accuracy (GCWA) on the validation set, and\nthen prints out the key final metrics for that best run. It reports the final\ntraining loss, the final validation loss plus all three validation accuracies,\nand the corresponding test loss and accuracies\u2014each clearly labelled so there is\nno ambiguity about what is being shown. No figures are generated and the code\nexecutes immediately when run.", "Below is a short description followed by the complete script.   The script loads\n`experiment_data.npy` from the `working` directory, parses the nested\ndictionary, and for the single dataset found (`SPR_BENCH`) computes the best\nvalue (maximum for accuracies, minimum for losses) across all hidden-dimension\nruns. It then prints each result with an explicit label such as \u201ctrain color-\nweighted accuracy\u201d or \u201ctest loss\u201d, fulfilling the formatting rules.", "We will load the numpy file from the working directory, iterate through every\nweight-decay sub-experiment, fetch the metrics stored under the single dataset\n\u201cSPR_BENCH\u201d, grab the last (i.e., final) validation-set dictionary and the test-\nset dictionary, and print each metric with an explicit label such as \u201cfinal\nvalidation CWA\u201d or \u201ctest GCWA\u201d. No code is hidden behind an entry-point guard,\nso the script executes immediately.", "", "The script will load experiment_data.npy from the working directory, inspect its\nnested dictionaries and automatically choose the configuration with the highest\ntest GCWA score for each dataset. It then prints, for that best run, the final\nvalidation loss and accuracies together with the final test loss and all three\nweighted-accuracy metrics. All metrics are labelled explicitly (e.g., \u201ctest\ncolor weighted accuracy\u201d) and the dataset name precedes its block of printed\nresults. The code is kept at global scope so it executes as soon as the file is\nrun.", "The script will load experiment_data.npy from the working directory, inspect its\nnested dictionaries and automatically choose the configuration with the highest\ntest GCWA score for each dataset. It then prints, for that best run, the final\nvalidation loss and accuracies together with the final test loss and all three\nweighted-accuracy metrics. All metrics are labelled explicitly (e.g., \u201ctest\ncolor weighted accuracy\u201d) and the dataset name precedes its block of printed\nresults. The code is kept at global scope so it executes as soon as the file is\nrun.", "The script will load experiment_data.npy from the working directory, inspect its\nnested dictionaries and automatically choose the configuration with the highest\ntest GCWA score for each dataset. It then prints, for that best run, the final\nvalidation loss and accuracies together with the final test loss and all three\nweighted-accuracy metrics. All metrics are labelled explicitly (e.g., \u201ctest\ncolor weighted accuracy\u201d) and the dataset name precedes its block of printed\nresults. The code is kept at global scope so it executes as soon as the file is\nrun.", ""], "parse_metrics_code": ["", "", "", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------------\n# 0. locate and load the saved numpy experiment file\n# --------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_file}\")\n\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# --------------------------------------------------------------------------\n# 1. iterate through experiment structure and select best configuration\n# --------------------------------------------------------------------------\nfor exp_group, datasets in experiment_data.items():  # e.g. \"embedding_dim_tuning\"\n    for dataset_name, configs in datasets.items():  # e.g. \"SPR_BENCH\"\n        # ------------------------------------------------------------------\n        # choose the configuration with the best test GCWA score\n        # ------------------------------------------------------------------\n        best_cfg_key = None\n        best_gcwa = -float(\"inf\")\n        for cfg_key, cfg in configs.items():  # e.g. \"emb_dim_32\"\n            gcwa_score = cfg[\"metrics\"][\"test\"].get(\"GCWA\", 0.0)\n            if gcwa_score > best_gcwa:\n                best_gcwa = gcwa_score\n                best_cfg_key = cfg_key\n\n        if best_cfg_key is None:\n            continue  # nothing to report\n\n        best_cfg = configs[best_cfg_key]\n\n        # ------------------------------------------------------------------\n        # 2. collect final / best values\n        # ------------------------------------------------------------------\n        # Validation results: take the last entry (final epoch)\n        val_losses = best_cfg[\"losses\"][\"val\"]\n        val_metrics_list = best_cfg[\"metrics\"][\"val\"]\n        final_val_loss = val_losses[-1] if val_losses else None\n        final_val_metrics = val_metrics_list[-1] if val_metrics_list else {}\n\n        # Test results\n        test_loss = best_cfg[\"losses\"][\"test\"]\n        test_metrics = best_cfg[\"metrics\"][\"test\"]\n\n        # ------------------------------------------------------------------\n        # 3. print results with clear labels\n        # ------------------------------------------------------------------\n        print(dataset_name)  # dataset header\n\n        if final_val_loss is not None:\n            print(f\"validation loss: {final_val_loss:.4f}\")\n        for m_name, m_val in final_val_metrics.items():\n            # ensure consistent three-decimal formatting for accuracies\n            print(f\"validation {m_name}: {m_val:.3f}\")\n\n        print(f\"test loss: {test_loss:.4f}\")\n        print(f\"test color weighted accuracy: {test_metrics['CWA']:.3f}\")\n        print(f\"test shape weighted accuracy: {test_metrics['SWA']:.3f}\")\n        print(f\"test glyph complexity weighted accuracy: {test_metrics['GCWA']:.3f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\ned = experiment_data[\"SPR_BENCH\"]\n\n\n# ---------- pick the best run (highest final-epoch validation GCWA) ----------\ndef final_val_gcwa(run_idx: int) -> float:\n    # last epoch metrics for this run\n    return ed[\"metrics\"][\"val\"][run_idx][-1][\"GCWA\"]\n\n\nbest_run_idx = max(range(len(ed[\"metrics\"][\"val\"])), key=final_val_gcwa)\n\n# ---------- pull data for that run ----------\ntrain_loss_final = ed[\"losses\"][\"train\"][best_run_idx][-1]\nval_loss_final = ed[\"losses\"][\"val\"][best_run_idx][-1]\ntest_loss = ed[\"losses\"][\"test\"][best_run_idx]\n\nval_metrics_final = ed[\"metrics\"][\"val\"][best_run_idx][-1]  # dict with CWA, SWA, GCWA\ntest_metrics = ed[\"metrics\"][\"test\"][best_run_idx]  # dict with CWA, SWA, GCWA\n\n# ---------- print results ----------\nprint(\"Training Set:\")\nprint(f\"final training loss: {train_loss_final:.4f}\")\n\nprint(\"\\nValidation Set:\")\nprint(f\"final validation loss: {val_loss_final:.4f}\")\nprint(f\"final validation color-weighted accuracy (CWA): {val_metrics_final['CWA']:.3f}\")\nprint(f\"final validation shape-weighted accuracy (SWA): {val_metrics_final['SWA']:.3f}\")\nprint(\n    f\"final validation glyph-complexity-weighted accuracy (GCWA): {val_metrics_final['GCWA']:.3f}\"\n)\n\nprint(\"\\nTest Set:\")\nprint(f\"test loss: {test_loss:.4f}\")\nprint(f\"test color-weighted accuracy (CWA): {test_metrics['CWA']:.3f}\")\nprint(f\"test shape-weighted accuracy (SWA): {test_metrics['SWA']:.3f}\")\nprint(f\"test glyph-complexity-weighted accuracy (GCWA): {test_metrics['GCWA']:.3f}\")\n", "import os\nimport numpy as np\n\n# ------------ load ---------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# ------------ helpers ------------- #\ndef best(values, higher_is_better=True):\n    \"\"\"Return the best (max or min) from an iterable of numeric values.\"\"\"\n    return max(values) if higher_is_better else min(values)\n\n\ndef gather_best_metrics(dataset_dict):\n    \"\"\"\n    dataset_dict is experiment_data[\"hidden_dim\"][DATASET_NAME]\n    Returns a dict with best values across all hidden_dim choices.\n    \"\"\"\n    best_metrics = {\n        \"train CWA\": -1,\n        \"train SWA\": -1,\n        \"train GCWA\": -1,\n        \"validation CWA\": -1,\n        \"validation SWA\": -1,\n        \"validation GCWA\": -1,\n        \"test CWA\": -1,\n        \"test SWA\": -1,\n        \"test GCWA\": -1,\n        \"train loss\": float(\"inf\"),\n        \"validation loss\": float(\"inf\"),\n        \"test loss\": float(\"inf\"),\n    }\n\n    # hidden-dim runs\n    for hd in dataset_dict[\"metrics\"][\"train\"]:\n        # ---------- losses ---------- #\n        tr_losses = dataset_dict[\"losses\"][\"train\"][hd]  # list per epoch\n        val_losses = dataset_dict[\"losses\"][\"val\"][hd]  # list per epoch\n        test_loss = dataset_dict[\"losses\"][\"test\"][hd]  # scalar\n\n        best_metrics[\"train loss\"] = best(\n            [best_metrics[\"train loss\"], best(tr_losses, higher_is_better=False)],\n            higher_is_better=False,\n        )\n        best_metrics[\"validation loss\"] = best(\n            [best_metrics[\"validation loss\"], best(val_losses, higher_is_better=False)],\n            higher_is_better=False,\n        )\n        best_metrics[\"test loss\"] = best(\n            [best_metrics[\"test loss\"], test_loss], higher_is_better=False\n        )\n\n        # ---------- accuracies ---------- #\n        tr_m_list = dataset_dict[\"metrics\"][\"train\"][hd]  # list of dicts per epoch\n        val_m_list = dataset_dict[\"metrics\"][\"val\"][hd]  # list of dicts per epoch\n        test_m = dataset_dict[\"metrics\"][\"test\"][hd]  # dict\n\n        # Flatten lists into per-metric lists\n        for m_dict in tr_m_list:\n            best_metrics[\"train CWA\"] = max(best_metrics[\"train CWA\"], m_dict[\"CWA\"])\n            best_metrics[\"train SWA\"] = max(best_metrics[\"train SWA\"], m_dict[\"SWA\"])\n            best_metrics[\"train GCWA\"] = max(best_metrics[\"train GCWA\"], m_dict[\"GCWA\"])\n\n        for m_dict in val_m_list:\n            best_metrics[\"validation CWA\"] = max(\n                best_metrics[\"validation CWA\"], m_dict[\"CWA\"]\n            )\n            best_metrics[\"validation SWA\"] = max(\n                best_metrics[\"validation SWA\"], m_dict[\"SWA\"]\n            )\n            best_metrics[\"validation GCWA\"] = max(\n                best_metrics[\"validation GCWA\"], m_dict[\"GCWA\"]\n            )\n\n        best_metrics[\"test CWA\"] = max(best_metrics[\"test CWA\"], test_m[\"CWA\"])\n        best_metrics[\"test SWA\"] = max(best_metrics[\"test SWA\"], test_m[\"SWA\"])\n        best_metrics[\"test GCWA\"] = max(best_metrics[\"test GCWA\"], test_m[\"GCWA\"])\n\n    return best_metrics\n\n\n# ------------ main logic ---------- #\nfor data_name, data_dict in experiment_data[\"hidden_dim\"].items():\n    # Print dataset name\n    print(f\"{data_name}\")\n    metrics = gather_best_metrics(data_dict)\n\n    # Explicit printing of each metric\n    print(f\"train loss: {metrics['train loss']:.4f}\")\n    print(f\"validation loss: {metrics['validation loss']:.4f}\")\n    print(f\"test loss: {metrics['test loss']:.4f}\")\n\n    print(f\"train color-weighted accuracy: {metrics['train CWA']:.3f}\")\n    print(f\"validation color-weighted accuracy: {metrics['validation CWA']:.3f}\")\n    print(f\"test color-weighted accuracy: {metrics['test CWA']:.3f}\")\n\n    print(f\"train shape-weighted accuracy: {metrics['train SWA']:.3f}\")\n    print(f\"validation shape-weighted accuracy: {metrics['validation SWA']:.3f}\")\n    print(f\"test shape-weighted accuracy: {metrics['test SWA']:.3f}\")\n\n    print(f\"train glyph-complexity-weighted accuracy: {metrics['train GCWA']:.3f}\")\n    print(\n        f\"validation glyph-complexity-weighted accuracy: {metrics['validation GCWA']:.3f}\"\n    )\n    print(f\"test glyph-complexity-weighted accuracy: {metrics['test GCWA']:.3f}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# 1. Load experiment data\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# -------------------------------------------------\n# 2. Extract and print metrics\n# -------------------------------------------------\nfor wd_str, wd_block in experiment_data.get(\"weight_decay\", {}).items():\n    dataset_name = \"SPR_BENCH\"\n    if dataset_name not in wd_block:\n        continue\n\n    print(f\"{dataset_name} (weight_decay={wd_str})\")\n\n    ds_entry = wd_block[dataset_name]\n\n    # --- final validation metrics ---\n    val_history = ds_entry.get(\"metrics\", {}).get(\"val\", [])\n    if val_history:\n        final_val_metrics = val_history[-1]\n        for metric_key, metric_value in final_val_metrics.items():\n            print(f\"final validation {metric_key}: {metric_value:.3f}\")\n\n    # --- test metrics ---\n    test_metrics = ds_entry.get(\"metrics\", {}).get(\"test\", {})\n    for metric_key, metric_value in test_metrics.items():\n        print(f\"test {metric_key}: {metric_value:.3f}\")\n\n    print()  # blank line between weight-decay settings\n", "", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------------\n# 0. locate and load the saved numpy experiment file\n# --------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_file}\")\n\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# --------------------------------------------------------------------------\n# 1. iterate through experiment structure and select best configuration\n# --------------------------------------------------------------------------\nfor exp_group, datasets in experiment_data.items():  # e.g. \"embedding_dim_tuning\"\n    for dataset_name, configs in datasets.items():  # e.g. \"SPR_BENCH\"\n        # ------------------------------------------------------------------\n        # choose the configuration with the best test GCWA score\n        # ------------------------------------------------------------------\n        best_cfg_key = None\n        best_gcwa = -float(\"inf\")\n        for cfg_key, cfg in configs.items():  # e.g. \"emb_dim_32\"\n            gcwa_score = cfg[\"metrics\"][\"test\"].get(\"GCWA\", 0.0)\n            if gcwa_score > best_gcwa:\n                best_gcwa = gcwa_score\n                best_cfg_key = cfg_key\n\n        if best_cfg_key is None:\n            continue  # nothing to report\n\n        best_cfg = configs[best_cfg_key]\n\n        # ------------------------------------------------------------------\n        # 2. collect final / best values\n        # ------------------------------------------------------------------\n        # Validation results: take the last entry (final epoch)\n        val_losses = best_cfg[\"losses\"][\"val\"]\n        val_metrics_list = best_cfg[\"metrics\"][\"val\"]\n        final_val_loss = val_losses[-1] if val_losses else None\n        final_val_metrics = val_metrics_list[-1] if val_metrics_list else {}\n\n        # Test results\n        test_loss = best_cfg[\"losses\"][\"test\"]\n        test_metrics = best_cfg[\"metrics\"][\"test\"]\n\n        # ------------------------------------------------------------------\n        # 3. print results with clear labels\n        # ------------------------------------------------------------------\n        print(dataset_name)  # dataset header\n\n        if final_val_loss is not None:\n            print(f\"validation loss: {final_val_loss:.4f}\")\n        for m_name, m_val in final_val_metrics.items():\n            # ensure consistent three-decimal formatting for accuracies\n            print(f\"validation {m_name}: {m_val:.3f}\")\n\n        print(f\"test loss: {test_loss:.4f}\")\n        print(f\"test color weighted accuracy: {test_metrics['CWA']:.3f}\")\n        print(f\"test shape weighted accuracy: {test_metrics['SWA']:.3f}\")\n        print(f\"test glyph complexity weighted accuracy: {test_metrics['GCWA']:.3f}\")\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------------\n# 0. locate and load the saved numpy experiment file\n# --------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_file}\")\n\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# --------------------------------------------------------------------------\n# 1. iterate through experiment structure and select best configuration\n# --------------------------------------------------------------------------\nfor exp_group, datasets in experiment_data.items():  # e.g. \"embedding_dim_tuning\"\n    for dataset_name, configs in datasets.items():  # e.g. \"SPR_BENCH\"\n        # ------------------------------------------------------------------\n        # choose the configuration with the best test GCWA score\n        # ------------------------------------------------------------------\n        best_cfg_key = None\n        best_gcwa = -float(\"inf\")\n        for cfg_key, cfg in configs.items():  # e.g. \"emb_dim_32\"\n            gcwa_score = cfg[\"metrics\"][\"test\"].get(\"GCWA\", 0.0)\n            if gcwa_score > best_gcwa:\n                best_gcwa = gcwa_score\n                best_cfg_key = cfg_key\n\n        if best_cfg_key is None:\n            continue  # nothing to report\n\n        best_cfg = configs[best_cfg_key]\n\n        # ------------------------------------------------------------------\n        # 2. collect final / best values\n        # ------------------------------------------------------------------\n        # Validation results: take the last entry (final epoch)\n        val_losses = best_cfg[\"losses\"][\"val\"]\n        val_metrics_list = best_cfg[\"metrics\"][\"val\"]\n        final_val_loss = val_losses[-1] if val_losses else None\n        final_val_metrics = val_metrics_list[-1] if val_metrics_list else {}\n\n        # Test results\n        test_loss = best_cfg[\"losses\"][\"test\"]\n        test_metrics = best_cfg[\"metrics\"][\"test\"]\n\n        # ------------------------------------------------------------------\n        # 3. print results with clear labels\n        # ------------------------------------------------------------------\n        print(dataset_name)  # dataset header\n\n        if final_val_loss is not None:\n            print(f\"validation loss: {final_val_loss:.4f}\")\n        for m_name, m_val in final_val_metrics.items():\n            # ensure consistent three-decimal formatting for accuracies\n            print(f\"validation {m_name}: {m_val:.3f}\")\n\n        print(f\"test loss: {test_loss:.4f}\")\n        print(f\"test color weighted accuracy: {test_metrics['CWA']:.3f}\")\n        print(f\"test shape weighted accuracy: {test_metrics['SWA']:.3f}\")\n        print(f\"test glyph complexity weighted accuracy: {test_metrics['GCWA']:.3f}\")\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------------\n# 0. locate and load the saved numpy experiment file\n# --------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_file}\")\n\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# --------------------------------------------------------------------------\n# 1. iterate through experiment structure and select best configuration\n# --------------------------------------------------------------------------\nfor exp_group, datasets in experiment_data.items():  # e.g. \"embedding_dim_tuning\"\n    for dataset_name, configs in datasets.items():  # e.g. \"SPR_BENCH\"\n        # ------------------------------------------------------------------\n        # choose the configuration with the best test GCWA score\n        # ------------------------------------------------------------------\n        best_cfg_key = None\n        best_gcwa = -float(\"inf\")\n        for cfg_key, cfg in configs.items():  # e.g. \"emb_dim_32\"\n            gcwa_score = cfg[\"metrics\"][\"test\"].get(\"GCWA\", 0.0)\n            if gcwa_score > best_gcwa:\n                best_gcwa = gcwa_score\n                best_cfg_key = cfg_key\n\n        if best_cfg_key is None:\n            continue  # nothing to report\n\n        best_cfg = configs[best_cfg_key]\n\n        # ------------------------------------------------------------------\n        # 2. collect final / best values\n        # ------------------------------------------------------------------\n        # Validation results: take the last entry (final epoch)\n        val_losses = best_cfg[\"losses\"][\"val\"]\n        val_metrics_list = best_cfg[\"metrics\"][\"val\"]\n        final_val_loss = val_losses[-1] if val_losses else None\n        final_val_metrics = val_metrics_list[-1] if val_metrics_list else {}\n\n        # Test results\n        test_loss = best_cfg[\"losses\"][\"test\"]\n        test_metrics = best_cfg[\"metrics\"][\"test\"]\n\n        # ------------------------------------------------------------------\n        # 3. print results with clear labels\n        # ------------------------------------------------------------------\n        print(dataset_name)  # dataset header\n\n        if final_val_loss is not None:\n            print(f\"validation loss: {final_val_loss:.4f}\")\n        for m_name, m_val in final_val_metrics.items():\n            # ensure consistent three-decimal formatting for accuracies\n            print(f\"validation {m_name}: {m_val:.3f}\")\n\n        print(f\"test loss: {test_loss:.4f}\")\n        print(f\"test color weighted accuracy: {test_metrics['CWA']:.3f}\")\n        print(f\"test shape weighted accuracy: {test_metrics['SWA']:.3f}\")\n        print(f\"test glyph complexity weighted accuracy: {test_metrics['GCWA']:.3f}\")\n", ""], "parse_term_out": ["", "", "", "['SPR_BENCH', '\\n', 'validation loss: 0.1970', '\\n', 'validation CWA: 0.939',\n'\\n', 'validation SWA: 0.935', '\\n', 'validation GCWA: 0.933', '\\n', 'test loss:\n1.9191', '\\n', 'test color weighted accuracy: 0.628', '\\n', 'test shape weighted\naccuracy: 0.684', '\\n', 'test glyph complexity weighted accuracy: 0.627', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Training Set:', '\\n', 'final training loss: 0.4860', '\\n', '\\nValidation\nSet:', '\\n', 'final validation loss: 0.4511', '\\n', 'final validation color-\nweighted accuracy (CWA): 0.800', '\\n', 'final validation shape-weighted accuracy\n(SWA): 0.805', '\\n', 'final validation glyph-complexity-weighted accuracy\n(GCWA): 0.798', '\\n', '\\nTest Set:', '\\n', 'test loss: 0.6757', '\\n', 'test\ncolor-weighted accuracy (CWA): 0.610', '\\n', 'test shape-weighted accuracy\n(SWA): 0.651', '\\n', 'test glyph-complexity-weighted accuracy (GCWA): 0.611',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'train loss: 0.1909', '\\n', 'validation loss: 0.1918', '\\n',\n'test loss: 1.5568', '\\n', 'train color-weighted accuracy: 0.939', '\\n',\n'validation color-weighted accuracy: 0.939', '\\n', 'test color-weighted\naccuracy: 0.628', '\\n', 'train shape-weighted accuracy: 0.935', '\\n',\n'validation shape-weighted accuracy: 0.935', '\\n', 'test shape-weighted\naccuracy: 0.683', '\\n', 'train glyph-complexity-weighted accuracy: 0.933', '\\n',\n'validation glyph-complexity-weighted accuracy: 0.933', '\\n', 'test glyph-\ncomplexity-weighted accuracy: 0.627', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['SPR_BENCH (weight_decay=0.0)', '\\n', 'final validation CWA: 0.937', '\\n',\n'final validation SWA: 0.933', '\\n', 'final validation GCWA: 0.931', '\\n', 'test\nCWA: 0.627', '\\n', 'test SWA: 0.682', '\\n', 'test GCWA: 0.626', '\\n', '\\n',\n'SPR_BENCH (weight_decay=1e-05)', '\\n', 'final validation CWA: 0.938', '\\n',\n'final validation SWA: 0.934', '\\n', 'final validation GCWA: 0.932', '\\n', 'test\nCWA: 0.628', '\\n', 'test SWA: 0.683', '\\n', 'test GCWA: 0.627', '\\n', '\\n',\n'SPR_BENCH (weight_decay=0.0001)', '\\n', 'final validation CWA: 0.936', '\\n',\n'final validation SWA: 0.933', '\\n', 'final validation GCWA: 0.930', '\\n', 'test\nCWA: 0.628', '\\n', 'test SWA: 0.683', '\\n', 'test GCWA: 0.627', '\\n', '\\n',\n'SPR_BENCH (weight_decay=0.001)', '\\n', 'final validation CWA: 0.936', '\\n',\n'final validation SWA: 0.933', '\\n', 'final validation GCWA: 0.931', '\\n', 'test\nCWA: 0.628', '\\n', 'test SWA: 0.683', '\\n', 'test GCWA: 0.627', '\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "", "['SPR_BENCH', '\\n', 'validation loss: 0.1922', '\\n', 'validation CWA: 0.939',\n'\\n', 'validation SWA: 0.935', '\\n', 'validation GCWA: 0.933', '\\n', 'test loss:\n1.9833', '\\n', 'test color weighted accuracy: 0.628', '\\n', 'test shape weighted\naccuracy: 0.684', '\\n', 'test glyph complexity weighted accuracy: 0.627', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'validation loss: 0.1911', '\\n', 'validation CWA: 0.939',\n'\\n', 'validation SWA: 0.935', '\\n', 'validation GCWA: 0.933', '\\n', 'test loss:\n2.3265', '\\n', 'test color weighted accuracy: 0.628', '\\n', 'test shape weighted\naccuracy: 0.684', '\\n', 'test glyph complexity weighted accuracy: 0.627', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'validation loss: 0.1996', '\\n', 'validation CWA: 0.937',\n'\\n', 'validation SWA: 0.934', '\\n', 'validation GCWA: 0.931', '\\n', 'test loss:\n1.8016', '\\n', 'test color weighted accuracy: 0.628', '\\n', 'test shape weighted\naccuracy: 0.683', '\\n', 'test glyph complexity weighted accuracy: 0.627', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]}