<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 3], [0, 1], [0, 4], [0, 2]], "layout": [[0.5, 0.0], [0.0, 1.0], [0.3333333333333333, 1.0], [0.6666666666666666, 1.0], [1.0, 1.0]], "plan": ["A lightweight baseline will first parse each symbol into its two discrete latent\nfactors \u2013 shape (first character) and color (second character).  We cluster the\nfull set of unique glyphs in the training data by running K-means on the 2-d\n(shape-id, color-id) representation, giving every glyph a third latent feature:\ncluster-id.  For every sequence we create three padded integer tensors (shape-\nids, color-ids, cluster-ids) that are fed into three learnable embedding tables\nwhose outputs are concatenated.  A masked mean-pool over the time dimension\nproduces one fixed-size vector per sequence, which is passed through a small MLP\nfor classification.  We train for a few epochs with cross-entropy, evaluating\nafter each epoch on the dev split and reporting Color-Weighted Accuracy, Shape-\nWeighted Accuracy and our new Glyph-Complexity-Weighted Accuracy (GCWA).  All\nmetrics, losses and predictions are stored in the required experiment_data\nstructure and saved to the working directory; plots are optional but numeric\ntraces are persisted.  The code is self-contained \u2013 if the official SPR_BENCH\nfolder is missing it falls back to a tiny synthetic dataset so that the script\nalways runs end-to-end.  GPU usage is handled automatically and all tensors /\nmodels are moved to the detected device.", "Hyperparam tuning name: num_epochs. The updated solution runs a small hyper-\nparameter search over the maximum number of training epochs (5, 10, 20 and 30)\nwhile employing early-stopping on the validation loss (patience = 3).   For\nevery setting the model is freshly initialised, trained, evaluated on dev/test\nand all plottable data are aggregated in a single experiment_data dictionary\nthat is finally persisted as experiment_data.npy.", "Hyperparam tuning name: learning_rate. We sweep four learning-rate values (5e-4,\n1e-3, 2e-3, 5e-3).   For every rate we re-initialize the model, train for a\nsmall number of epochs, evaluate on dev and test sets, and record the results in\nexperiment_data under the key 'learning_rate'\u2192'SPR_BENCH'.   Finally we persist\nall collected losses, metrics, predictions, and ground-truth labels into\nexperiment_data.npy for later plotting/analysis.", "Hyperparam tuning name: batch_size. Below is a concise outline followed by the\nfull self-contained script.  Outline   We create a synthetic (or official) SPR-\nBENCH dataset, then loop over a list of candidate batch sizes [32,64,128,256].\nFor every batch size we build fresh DataLoaders, a new model, and train for a\nfew epochs, recording train/validation losses and weighted-accuracy metrics.\nAll results are stored in the mandatory experiment_data dict under the top-level\nkey \"batch_size\" and finally saved to working/experiment_data.npy.", "Hyperparam tuning name: embedding_dim. The solution sweeps over embedding\ndimensions {4, 8, 16, 32}.   For each size it builds a fresh GlyphModel, trains\nfor a few epochs, evaluates on dev and test splits, and stores losses, weighted-\naccuracy metrics and test predictions in a hierarchically organised\nexperiment_data dict:\nexperiment_data['embedding_dim']['SPR_BENCH'][f'dim_{emb_dim}'] \u2192 {metrics,\nlosses, predictions, ground_truth}.   All collected information is finally saved\nto working/experiment_data.npy."], "code": ["import os, pathlib, random, time, json\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# -------- device ---------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------- metrics utilities (given + GCWA) ---------- #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\n# -------- data loading (official or synthetic) ---------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path) -> DatasetDict:\n    if root.exists():\n\n        def _load(split_csv):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / split_csv),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        d = DatasetDict()\n        for sp in [\"train\", \"dev\", \"test\"]:\n            d[sp] = _load(f\"{sp}.csv\")\n        return d\n    return None\n\n\ndef build_synthetic() -> DatasetDict:\n    shapes = list(\"ABCD\")\n    colors = list(\"1234\")\n\n    def gen_split(n):\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            label = random.randint(0, 3)\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": label})\n        return rows\n\n    d = DatasetDict()\n    d[\"train\"] = load_dataset(\n        \"json\",\n        data_files={\"train\": [json.dumps(r) for r in gen_split(500)]},\n        split=\"train\",\n    )\n    d[\"dev\"] = load_dataset(\n        \"json\",\n        data_files={\"train\": [json.dumps(r) for r in gen_split(100)]},\n        split=\"train\",\n    )\n    d[\"test\"] = load_dataset(\n        \"json\",\n        data_files={\"train\": [json.dumps(r) for r in gen_split(100)]},\n        split=\"train\",\n    )\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# -------- vocab & clustering ---------- #\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 = pad\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\n\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in token_set], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(token_vecs)\ntok2cluster = {tok: int(c) + 1 for tok, c in zip(token_set, kmeans.labels_)}  # 0 pad\n\n\n# -------- Dataset class ---------- #\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        shape_ids = [shape2id[t[0]] for t in seq]\n        color_ids = [color2id[t[1]] for t in seq]\n        cluster_ids = [tok2cluster[t] for t in seq]\n        return {\n            \"shape\": shape_ids,\n            \"color\": color_ids,\n            \"cluster\": cluster_ids,\n            \"label\": self.labels[idx],\n            \"seq_str\": (\n                spr[\"train\"].features[\"sequence\"]._type if False else self.seqs[idx]\n            ),\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        arr = [b[key] + [0] * (maxlen - len(b[key])) for b in batch]\n        return torch.tensor(arr, dtype=torch.long)\n\n    shapes = pad(\"shape\")\n    colors = pad(\"color\")\n    clusters = pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# -------- model ---------- #\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\nmodel = GlyphModel(len(shapes), len(colors), n_clusters, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# -------- experiment data dict ---------- #\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n\n# -------- training loop ---------- #\ndef evaluate(loader):\n    model.eval()\n    all_preds, all_tgts, all_seqs = [], [], []\n    total_loss = 0.0\n    with torch.no_grad():\n        for batch in loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            total_loss += loss.item() * labels.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_tgts.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seqs\"])\n    avg_loss = total_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    swa = shape_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    gcwa = glyph_complexity_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    return avg_loss, {\"CWA\": cwa, \"SWA\": swa, \"GCWA\": gcwa}, all_preds, all_tgts\n\n\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running_loss = 0.0\n    for batch in train_loader:\n        shapes = batch[\"shape\"].to(device)\n        colors = batch[\"color\"].to(device)\n        clusters = batch[\"cluster\"].to(device)\n        mask = batch[\"mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        optimizer.zero_grad()\n        logits = model(shapes, colors, clusters, mask)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * labels.size(0)\n    train_loss = running_loss / len(train_loader.dataset)\n    val_loss, val_metrics, preds, tgts = evaluate(dev_loader)\n\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(val_metrics)\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n        f\"CWA={val_metrics['CWA']:.3f} | SWA={val_metrics['SWA']:.3f} | GCWA={val_metrics['GCWA']:.3f}\"\n    )\n\n# -------- final test evaluation ---------- #\ntest_loss, test_metrics, test_preds, test_tgts = evaluate(test_loader)\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = test_preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = test_tgts\nexperiment_data[\"SPR_BENCH\"][\"metrics\"][\"test\"] = test_metrics\nprint(\n    f'Test: loss={test_loss:.4f} | CWA={test_metrics[\"CWA\"]:.3f} | '\n    f'SWA={test_metrics[\"SWA\"]:.3f} | GCWA={test_metrics[\"GCWA\"]:.3f}'\n)\n\n# -------- persist --------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# num_epochs hyper-parameter tuning \u2013 single-file runnable script\nimport os, pathlib, random, json, copy, time\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# ------------------------------------------------------------------------- #\n# misc helpers & paths\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------------------- #\n# metric utilities\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\n# ------------------------------------------------------------------------- #\n# data loading (uses official SPR_BENCH if present, otherwise synthetic)\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path) -> DatasetDict | None:\n    if root.exists():\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in (\"train\", \"dev\", \"test\")})\n    return None\n\n\ndef build_synthetic() -> DatasetDict:\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen_split(n):\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    d = DatasetDict()\n    for sp, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        json_strs = [json.dumps(r) for r in gen_split(n)]\n        d[sp] = load_dataset(\"json\", data_files={\"train\": json_strs}, split=\"train\")\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# ------------------------------------------------------------------------- #\n# vocabularies & token clustering\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 = pad\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\n\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in token_set], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(token_vecs)\ntok2cluster = {tok: int(c) + 1 for tok, c in zip(token_set, kmeans.labels_)}  # 0 pad\n\n\n# ------------------------------------------------------------------------- #\n# torch dataset\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split: str):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        return {\n            \"shape\": [shape2id[t[0]] for t in seq],\n            \"color\": [color2id[t[1]] for t in seq],\n            \"cluster\": [tok2cluster[t] for t in seq],\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\n# common loaders\nbatch_size = 128\ntrain_loader_full = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader_full = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader_full = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ------------------------------------------------------------------------- #\n# model\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\n# ------------------------------------------------------------------------- #\n# evaluation helper\ndef evaluate(model, loader, criterion):\n    model.eval()\n    tot_loss, preds, tgts, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            tot_loss += loss.item() * labels.size(0)\n            pred = logits.argmax(1).cpu().tolist()\n            preds.extend(pred)\n            tgts.extend(labels.cpu().tolist())\n            seqs.extend(batch[\"seqs\"])\n    avg_loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, tgts, preds)\n    swa = shape_weighted_accuracy(seqs, tgts, preds)\n    gcwa = glyph_complexity_weighted_accuracy(seqs, tgts, preds)\n    return avg_loss, {\"CWA\": cwa, \"SWA\": swa, \"GCWA\": gcwa}, preds, tgts\n\n\n# ------------------------------------------------------------------------- #\n# experiment data container\nexperiment_data = {\"num_epochs\": {}}\n\n# hyper-parameter candidates\nepoch_candidates = [5, 10, 20, 30]\npatience = 3  # early-stopping patience\n\nfor max_epochs in epoch_candidates:\n    print(f\"\\n=== Training with max_epochs = {max_epochs} ===\")\n    run_key = f\"epochs_{max_epochs}\"\n    experiment_data[\"num_epochs\"][run_key] = {\n        \"metrics\": {\"train\": [], \"val\": [], \"test\": None},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"best_epoch\": None,\n    }\n\n    # fresh model / optimiser / criterion\n    model = GlyphModel(len(shapes), len(colors), n_clusters, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    best_val_loss, best_state, epochs_no_improve = float(\"inf\"), None, 0\n\n    # training loop with early stopping\n    for epoch in range(1, max_epochs + 1):\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader_full:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            optimizer.zero_grad()\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * labels.size(0)\n        train_loss = running_loss / len(train_loader_full.dataset)\n        val_loss, val_metrics, _, _ = evaluate(model, dev_loader_full, criterion)\n\n        # record\n        experiment_data[\"num_epochs\"][run_key][\"losses\"][\"train\"].append(train_loss)\n        experiment_data[\"num_epochs\"][run_key][\"losses\"][\"val\"].append(val_loss)\n        experiment_data[\"num_epochs\"][run_key][\"metrics\"][\"train\"].append({})\n        experiment_data[\"num_epochs\"][run_key][\"metrics\"][\"val\"].append(val_metrics)\n\n        print(\n            f\"Epoch {epoch:02d}: train_loss={train_loss:.4f} | \"\n            f\"val_loss={val_loss:.4f} | CWA={val_metrics['CWA']:.3f} \"\n            f\"SWA={val_metrics['SWA']:.3f} GCWA={val_metrics['GCWA']:.3f}\"\n        )\n\n        # early-stopping check\n        if val_loss < best_val_loss - 1e-4:\n            best_val_loss = val_loss\n            best_state = copy.deepcopy(model.state_dict())\n            experiment_data[\"num_epochs\"][run_key][\"best_epoch\"] = epoch\n            epochs_no_improve = 0\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= patience:\n                print(f\"Early stopping triggered at epoch {epoch}\")\n                break\n\n    # reload best weights & evaluate on test\n    model.load_state_dict(best_state)\n    test_loss, test_metrics, test_preds, test_tgts = evaluate(\n        model, test_loader_full, criterion\n    )\n    experiment_data[\"num_epochs\"][run_key][\"losses\"][\"test\"] = test_loss\n    experiment_data[\"num_epochs\"][run_key][\"metrics\"][\"test\"] = test_metrics\n    experiment_data[\"num_epochs\"][run_key][\"predictions\"] = test_preds\n    experiment_data[\"num_epochs\"][run_key][\"ground_truth\"] = test_tgts\n\n    print(\n        f\"Test: loss={test_loss:.4f} | \"\n        f\"CWA={test_metrics['CWA']:.3f} SWA={test_metrics['SWA']:.3f} \"\n        f\"GCWA={test_metrics['GCWA']:.3f}\"\n    )\n\n# ------------------------------------------------------------------------- #\n# persist experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, time, json, math, copy, warnings\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# ---------- reproducibility ---------- #\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\n# ---------- paths ---------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ---------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics ---------- #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\n# ---------- data loading ---------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path) -> DatasetDict | None:\n    if root.exists():\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synthetic() -> DatasetDict:\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen_split(n):\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    def to_dataset(rows):\n        return load_dataset(\n            \"json\", data_files={\"train\": [json.dumps(r) for r in rows]}, split=\"train\"\n        )\n\n    return DatasetDict(\n        {\n            \"train\": to_dataset(gen_split(600)),\n            \"dev\": to_dataset(gen_split(150)),\n            \"test\": to_dataset(gen_split(150)),\n        }\n    )\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# ---------- vocabulary / clustering ---------- #\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 pad\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in token_set], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=SEED).fit(token_vecs)\ntok2cluster = {tok: int(c) + 1 for tok, c in zip(token_set, kmeans.labels_)}  # 0 pad\n\n\n# ---------- dataset & dataloader ---------- #\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq_tokens = self.seqs[idx].split()\n        shape_ids = [shape2id[t[0]] for t in seq_tokens]\n        color_ids = [color2id[t[1]] for t in seq_tokens]\n        cluster_ids = [tok2cluster[t] for t in seq_tokens]\n        return {\n            \"shape\": shape_ids,\n            \"color\": color_ids,\n            \"cluster\": cluster_ids,\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# ---------- model ---------- #\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\n# ---------- helper: evaluation ---------- #\ncriterion = nn.CrossEntropyLoss()\n\n\n@torch.no_grad()\ndef evaluate(model, loader):\n    model.eval()\n    total_loss, preds, tgts, seqs = 0.0, [], [], []\n    for batch in loader:\n        shapes, colors, clusters, mask = (\n            batch[k].to(device) for k in [\"shape\", \"color\", \"cluster\", \"mask\"]\n        )\n        labels = batch[\"labels\"].to(device)\n        logits = model(shapes, colors, clusters, mask)\n        loss = criterion(logits, labels)\n        total_loss += loss.item() * labels.size(0)\n        p = logits.argmax(1).cpu().tolist()\n        preds.extend(p)\n        tgts.extend(labels.cpu().tolist())\n        seqs.extend(batch[\"seqs\"])\n    avg_loss = total_loss / len(loader.dataset)\n    return (\n        avg_loss,\n        {\n            \"CWA\": color_weighted_accuracy(seqs, tgts, preds),\n            \"SWA\": shape_weighted_accuracy(seqs, tgts, preds),\n            \"GCWA\": glyph_complexity_weighted_accuracy(seqs, tgts, preds),\n        },\n        preds,\n        tgts,\n    )\n\n\n# ---------- hyperparameter sweep ---------- #\nlearning_rates = [5e-4, 1e-3, 2e-3, 5e-3]\nepochs = 5\n\nexperiment_data = {\n    \"learning_rate\": {\n        \"SPR_BENCH\": {\n            \"lrs\": learning_rates,\n            \"losses\": {\"train\": [], \"val\": []},\n            \"metrics\": {\"val\": [], \"test\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nfor lr in learning_rates:\n    print(f\"\\n=== Training with learning rate {lr} ===\")\n    model = GlyphModel(len(shapes), len(colors), n_clusters, num_classes).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            shapes, colors, clusters, mask = (\n                batch[k].to(device) for k in [\"shape\", \"color\", \"cluster\", \"mask\"]\n            )\n            labels = batch[\"labels\"].to(device)\n            optimizer.zero_grad()\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * labels.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        val_loss, val_metrics, _, _ = evaluate(model, dev_loader)\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} \"\n            f\"| CWA={val_metrics['CWA']:.3f} | SWA={val_metrics['SWA']:.3f} | GCWA={val_metrics['GCWA']:.3f}\"\n        )\n\n    # record results for this lr (final epoch stats)\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"metrics\"][\"val\"].append(val_metrics)\n\n    # final test evaluation\n    test_loss, test_metrics, test_preds, test_tgts = evaluate(model, test_loader)\n    print(\n        f\"Test: loss={test_loss:.4f} | CWA={test_metrics['CWA']:.3f} | \"\n        f\"SWA={test_metrics['SWA']:.3f} | GCWA={test_metrics['GCWA']:.3f}\"\n    )\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"metrics\"][\"test\"].append(\n        test_metrics\n    )\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"predictions\"].append(test_preds)\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"ground_truth\"].append(test_tgts)\n\n# ---------- persist ---------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, random, json, pathlib, time\nimport numpy as np\nimport torch, math\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import Dataset as HFDataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# ---------- paths & device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- metric helpers ----------\ndef count_color_variety(seq):  # e.g. A1 B2 C3 -> 3\n    return len({tok[1] for tok in seq.strip().split() if len(tok) > 1})\n\n\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.strip().split() if tok})\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wt for wt, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wt for wt, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    return sum(wt for wt, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\n# ---------- dataset (try official else synthetic) ----------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path):\n    if root.exists():\n        from datasets import load_dataset\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        return DatasetDict({sp: _load(f\"{sp}.csv\") for sp in [\"train\", \"dev\", \"test\"]})\n    return None\n\n\ndef build_synthetic():\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen(n):  # produce list[dict]\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        return rows\n\n    d = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        d[split] = HFDataset.from_list(gen(n))\n    return d\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# ---------- vocab & token clustering ----------\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 reserved for PAD\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in sorted(set(all_tokens))], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(token_vecs)\ntok2cluster = {\n    tok: int(c) + 1 for tok, c in zip(sorted(set(all_tokens)), kmeans.labels_)\n}  # 0 pad\n\n\n# ---------- torch Dataset ----------\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        return {\n            \"shape\": [shape2id[t[0]] for t in seq],\n            \"color\": [color2id[t[1]] for t in seq],\n            \"cluster\": [tok2cluster[t] for t in seq],\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\n# ---------- model ----------\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / (mask.sum(1) + 1e-9)\n        return self.ff(pooled)\n\n\n# ---------- training / evaluation helpers ----------\ndef evaluate(model, loader, criterion):\n    model.eval()\n    total_loss, all_preds, all_tgts, all_seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            shapes, colors, clusters, mask = [\n                batch[k].to(device) for k in [\"shape\", \"color\", \"cluster\", \"mask\"]\n            ]\n            labels = batch[\"labels\"].to(device)\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            total_loss += loss.item() * labels.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_tgts.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seqs\"])\n    avg_loss = total_loss / len(loader.dataset)\n    return (\n        avg_loss,\n        {\n            \"CWA\": color_weighted_accuracy(all_seqs, all_tgts, all_preds),\n            \"SWA\": shape_weighted_accuracy(all_seqs, all_tgts, all_preds),\n            \"GCWA\": glyph_complexity_weighted_accuracy(all_seqs, all_tgts, all_preds),\n        },\n        all_preds,\n        all_tgts,\n    )\n\n\n# ---------- hyper-parameter tuning ----------\nbatch_sizes = [32, 64, 128, 256]\nepochs = 5\nexperiment_data = {\"batch_size\": {\"SPR_BENCH\": {}}}\n\nfor bs in batch_sizes:\n    print(f\"\\n=== Training with batch_size={bs} ===\")\n    # loaders\n    train_loader = DataLoader(\n        SPRTorchDataset(\"train\"), batch_size=bs, shuffle=True, collate_fn=collate\n    )\n    dev_loader = DataLoader(\n        SPRTorchDataset(\"dev\"), batch_size=bs, shuffle=False, collate_fn=collate\n    )\n    test_loader = DataLoader(\n        SPRTorchDataset(\"test\"), batch_size=bs, shuffle=False, collate_fn=collate\n    )\n    # model, opt\n    model = GlyphModel(len(shapes), len(colors), n_clusters, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    # storage\n    run_data = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for ep in range(1, epochs + 1):\n        model.train()\n        running = 0.0\n        for batch in train_loader:\n            shapes, colors, clusters, mask = [\n                batch[k].to(device) for k in [\"shape\", \"color\", \"cluster\", \"mask\"]\n            ]\n            labels = batch[\"labels\"].to(device)\n            optimizer.zero_grad()\n            loss = criterion(model(shapes, colors, clusters, mask), labels)\n            loss.backward()\n            optimizer.step()\n            running += loss.item() * labels.size(0)\n        tr_loss = running / len(train_loader.dataset)\n        val_loss, val_metrics, _, _ = evaluate(model, dev_loader, criterion)\n        run_data[\"losses\"][\"train\"].append(tr_loss)\n        run_data[\"losses\"][\"val\"].append(val_loss)\n        run_data[\"metrics\"][\"val\"].append(val_metrics)\n        print(\n            f\"Epoch {ep} | train_loss {tr_loss:.4f} | val_loss {val_loss:.4f} | \"\n            f\"CWA {val_metrics['CWA']:.3f} | SWA {val_metrics['SWA']:.3f} | GCWA {val_metrics['GCWA']:.3f}\"\n        )\n    # final test\n    test_loss, test_metrics, test_preds, test_tgts = evaluate(\n        model, test_loader, criterion\n    )\n    run_data[\"predictions\"] = test_preds\n    run_data[\"ground_truth\"] = test_tgts\n    run_data[\"metrics\"][\"test\"] = test_metrics\n    print(\n        f\"Test | loss {test_loss:.4f} | CWA {test_metrics['CWA']:.3f} | \"\n        f\"SWA {test_metrics['SWA']:.3f} | GCWA {test_metrics['GCWA']:.3f}\"\n    )\n    experiment_data[\"batch_size\"][\"SPR_BENCH\"][bs] = run_data\n    del model\n    torch.cuda.empty_cache()\n\n# ---------- persist ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved results to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, json, time\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.cluster import KMeans\n\n# -------------------- paths / dirs -------------------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------- device -------------------- #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# -------------------- metrics -------------------- #\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef glyph_complexity_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) * count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\n# -------------------- data loading -------------------- #\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n\n\ndef try_load_spr(root: pathlib.Path) -> DatasetDict:\n    if root.exists():\n\n        def _load(csv_name):\n            return load_dataset(\n                \"csv\",\n                data_files=str(root / csv_name),\n                split=\"train\",\n                cache_dir=\".cache_dsets\",\n            )\n\n        d = DatasetDict()\n        for sp in [\"train\", \"dev\", \"test\"]:\n            d[sp] = _load(f\"{sp}.csv\")\n        return d\n    return None\n\n\ndef build_synthetic() -> DatasetDict:\n    shapes, colors = list(\"ABCD\"), list(\"1234\")\n\n    def gen_split(n):\n        rows = []\n        for i in range(n):\n            length = random.randint(3, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(length)\n            )\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": random.randint(0, 3)})\n        # save to tmp json lines file (datasets can't load from list of dict easily without disk)\n        tmp_path = os.path.join(working_dir, f\"tmp_{time.time_ns()}.jsonl\")\n        with open(tmp_path, \"w\") as f:\n            for r in rows:\n                f.write(json.dumps(r) + \"\\n\")\n        ds = load_dataset(\"json\", data_files=tmp_path, split=\"train\")\n        os.remove(tmp_path)\n        return ds\n\n    return DatasetDict(\n        {\"train\": gen_split(600), \"dev\": gen_split(120), \"test\": gen_split(120)}\n    )\n\n\nspr = try_load_spr(DATA_PATH) or build_synthetic()\nnum_classes = len(set(spr[\"train\"][\"label\"]))\n\n# -------------------- vocab & clustering -------------------- #\nall_tokens = [tok for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 pad\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}  # 0 pad\n\ntoken_set = sorted(set(all_tokens))\ntoken_vecs = np.array(\n    [[shape2id[t[0]], color2id[t[1]]] for t in token_set], dtype=float\n)\nn_clusters = min(max(4, len(token_vecs) // 3), 32)\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(token_vecs)\ntok2cluster = {tok: int(c) + 1 for tok, c in zip(token_set, kmeans.labels_)}  # 0 pad\n\n\n# -------------------- dataset / dataloader -------------------- #\nclass SPRTorchDataset(Dataset):\n    def __init__(self, split):\n        self.seqs = spr[split][\"sequence\"]\n        self.labels = spr[split][\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx].split()\n        shape_ids = [shape2id[t[0]] for t in seq]\n        color_ids = [color2id[t[1]] for t in seq]\n        cluster_ids = [tok2cluster[t] for t in seq]\n        return {\n            \"shape\": shape_ids,\n            \"color\": color_ids,\n            \"cluster\": cluster_ids,\n            \"label\": self.labels[idx],\n            \"seq_str\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(key):\n        return torch.tensor(\n            [b[key] + [0] * (maxlen - len(b[key])) for b in batch], dtype=torch.long\n        )\n\n    shapes, colors, clusters = pad(\"shape\"), pad(\"color\"), pad(\"cluster\")\n    mask = (shapes != 0).float()\n    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    seqs = [b[\"seq_str\"] for b in batch]\n    return {\n        \"shape\": shapes,\n        \"color\": colors,\n        \"cluster\": clusters,\n        \"mask\": mask,\n        \"labels\": labels,\n        \"seqs\": seqs,\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(\"train\"), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(\"dev\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\ntest_loader = DataLoader(\n    SPRTorchDataset(\"test\"), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\n\n\n# -------------------- model -------------------- #\nclass GlyphModel(nn.Module):\n    def __init__(self, n_shape, n_color, n_cluster, num_classes, emb_dim=8):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape + 1, emb_dim, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color + 1, emb_dim, padding_idx=0)\n        self.cluster_emb = nn.Embedding(n_cluster + 1, emb_dim, padding_idx=0)\n        self.ff = nn.Sequential(\n            nn.Linear(emb_dim * 3, 64), nn.ReLU(), nn.Linear(64, num_classes)\n        )\n\n    def forward(self, shapes, colors, clusters, mask):\n        e = torch.cat(\n            [\n                self.shape_emb(shapes),\n                self.color_emb(colors),\n                self.cluster_emb(clusters),\n            ],\n            dim=-1,\n        )\n        mask = mask.unsqueeze(-1)\n        pooled = (e * mask).sum(1) / mask.sum(1)\n        return self.ff(pooled)\n\n\n# -------------------- evaluation helper -------------------- #\ndef evaluate(model, loader, criterion):\n    model.eval()\n    total_loss, all_preds, all_tgts, all_seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            total_loss += loss.item() * labels.size(0)\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_tgts.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seqs\"])\n    avg_loss = total_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    swa = shape_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    gcwa = glyph_complexity_weighted_accuracy(all_seqs, all_tgts, all_preds)\n    return avg_loss, {\"CWA\": cwa, \"SWA\": swa, \"GCWA\": gcwa}, all_preds, all_tgts\n\n\n# -------------------- hyperparameter sweep -------------------- #\nembedding_grid = [4, 8, 16, 32]\nepochs = 5\n\nexperiment_data = {\"embedding_dim\": {\"SPR_BENCH\": {}}}\n\nfor emb_dim in embedding_grid:\n    print(f\"\\n===== Training with embedding_dim={emb_dim} =====\")\n    model = GlyphModel(\n        len(shapes), len(colors), n_clusters, num_classes, emb_dim=emb_dim\n    ).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    exp_entry = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    # training loop\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            shapes = batch[\"shape\"].to(device)\n            colors = batch[\"color\"].to(device)\n            clusters = batch[\"cluster\"].to(device)\n            mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            optimizer.zero_grad()\n            logits = model(shapes, colors, clusters, mask)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * labels.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        val_loss, val_metrics, _, _ = evaluate(model, dev_loader, criterion)\n        exp_entry[\"losses\"][\"train\"].append(train_loss)\n        exp_entry[\"losses\"][\"val\"].append(val_loss)\n        exp_entry[\"metrics\"][\"val\"].append(val_metrics)\n        print(\n            f\"Epoch {epoch}/{epochs} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f} \"\n            f\"| CWA={val_metrics['CWA']:.3f} | SWA={val_metrics['SWA']:.3f} | GCWA={val_metrics['GCWA']:.3f}\"\n        )\n    # final test evaluation\n    test_loss, test_metrics, test_preds, test_tgts = evaluate(\n        model, test_loader, criterion\n    )\n    exp_entry[\"metrics\"][\"test\"] = test_metrics\n    exp_entry[\"losses\"][\"test\"] = test_loss\n    exp_entry[\"predictions\"] = test_preds\n    exp_entry[\"ground_truth\"] = test_tgts\n    print(\n        f\"Test | loss={test_loss:.4f} | CWA={test_metrics['CWA']:.3f} | \"\n        f\"SWA={test_metrics['SWA']:.3f} | GCWA={test_metrics['GCWA']:.3f}\"\n    )\n    experiment_data[\"embedding_dim\"][\"SPR_BENCH\"][f\"dim_{emb_dim}\"] = exp_entry\n\n# -------------------- persist -------------------- #\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n"], "term_out": ["['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 362689.45\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 176743.67\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 306404.07\nexamples/s]', '\\n', 'Epoch 1: train_loss=0.5482 | val_loss=0.4259 | CWA=0.807 |\nSWA=0.810 | GCWA=0.803', '\\n', 'Epoch 2: train_loss=0.3391 | val_loss=0.2778 |\nCWA=0.909 | SWA=0.907 | GCWA=0.905', '\\n', 'Epoch 3: train_loss=0.2498 |\nval_loss=0.2325 | CWA=0.926 | SWA=0.922 | GCWA=0.920', '\\n', 'Epoch 4:\ntrain_loss=0.2226 | val_loss=0.2152 | CWA=0.934 | SWA=0.930 | GCWA=0.928', '\\n',\n'Epoch 5: train_loss=0.2083 | val_loss=0.2071 | CWA=0.937 | SWA=0.933 |\nGCWA=0.931', '\\n', 'Test: loss=1.5795 | CWA=0.627 | SWA=0.682 | GCWA=0.626',\n'\\n', 'Execution time: 5 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 201271.36\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 170462.74\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 425032.33\nexamples/s]', '\\n', '\\n=== Training with max_epochs = 5 ===', '\\n', 'Epoch 01:\ntrain_loss=0.5573 | val_loss=0.4449 | CWA=0.804 SWA=0.809 GCWA=0.801', '\\n',\n'Epoch 02: train_loss=0.3584 | val_loss=0.2883 | CWA=0.900 SWA=0.899\nGCWA=0.896', '\\n', 'Epoch 03: train_loss=0.2621 | val_loss=0.2385 | CWA=0.925\nSWA=0.922 GCWA=0.920', '\\n', 'Epoch 04: train_loss=0.2305 | val_loss=0.2227 |\nCWA=0.934 SWA=0.931 GCWA=0.928', '\\n', 'Epoch 05: train_loss=0.2159 |\nval_loss=0.2128 | CWA=0.933 SWA=0.930 GCWA=0.928', '\\n', 'Test: loss=1.5782 |\nCWA=0.627 SWA=0.682 GCWA=0.627', '\\n', '\\n=== Training with max_epochs = 10\n===', '\\n', 'Epoch 01: train_loss=0.5610 | val_loss=0.4710 | CWA=0.786 SWA=0.788\nGCWA=0.783', '\\n', 'Epoch 02: train_loss=0.3878 | val_loss=0.3101 | CWA=0.896\nSWA=0.893 GCWA=0.891', '\\n', 'Epoch 03: train_loss=0.2695 | val_loss=0.2400 |\nCWA=0.927 SWA=0.924 GCWA=0.922', '\\n', 'Epoch 04: train_loss=0.2255 |\nval_loss=0.2151 | CWA=0.936 SWA=0.933 GCWA=0.931', '\\n', 'Epoch 05:\ntrain_loss=0.2072 | val_loss=0.2040 | CWA=0.938 SWA=0.935 GCWA=0.933', '\\n',\n'Epoch 06: train_loss=0.1979 | val_loss=0.1966 | CWA=0.938 SWA=0.935\nGCWA=0.933', '\\n', 'Epoch 07: train_loss=0.1928 | val_loss=0.1927 | CWA=0.938\nSWA=0.935 GCWA=0.933', '\\n', 'Epoch 08: train_loss=0.1894 | val_loss=0.1907 |\nCWA=0.939 SWA=0.935 GCWA=0.933', '\\n', 'Epoch 09: train_loss=0.1873 |\nval_loss=0.1883 | CWA=0.939 SWA=0.935 GCWA=0.933', '\\n', 'Epoch 10:\ntrain_loss=0.1861 | val_loss=0.1881 | CWA=0.939 SWA=0.935 GCWA=0.933', '\\n',\n'Test: loss=1.9237 | CWA=0.628 SWA=0.684 GCWA=0.627', '\\n', '\\n=== Training with\nmax_epochs = 20 ===', '\\n', 'Epoch 01: train_loss=0.5794 | val_loss=0.4793 |\nCWA=0.786 SWA=0.787 GCWA=0.781', '\\n', 'Epoch 02: train_loss=0.3923 |\nval_loss=0.3168 | CWA=0.904 SWA=0.902 GCWA=0.901', '\\n', 'Epoch 03:\ntrain_loss=0.2768 | val_loss=0.2479 | CWA=0.925 SWA=0.923 GCWA=0.921', '\\n',\n'Epoch 04: train_loss=0.2355 | val_loss=0.2252 | CWA=0.932 SWA=0.929\nGCWA=0.927', '\\n', 'Epoch 05: train_loss=0.2177 | val_loss=0.2133 | CWA=0.935\nSWA=0.932 GCWA=0.930', '\\n', 'Epoch 06: train_loss=0.2077 | val_loss=0.2059 |\nCWA=0.936 SWA=0.933 GCWA=0.931', '\\n', 'Epoch 07: train_loss=0.2014 |\nval_loss=0.2031 | CWA=0.936 SWA=0.933 GCWA=0.931', '\\n', 'Epoch 08:\ntrain_loss=0.1967 | val_loss=0.1979 | CWA=0.937 SWA=0.934 GCWA=0.931', '\\n',\n'Epoch 09: train_loss=0.1940 | val_loss=0.1939 | CWA=0.938 SWA=0.935\nGCWA=0.933', '\\n', 'Epoch 10: train_loss=0.1913 | val_loss=0.1929 | CWA=0.938\nSWA=0.935 GCWA=0.933', '\\n', 'Epoch 11: train_loss=0.1898 | val_loss=0.1926 |\nCWA=0.938 SWA=0.935 GCWA=0.933', '\\n', 'Epoch 12: train_loss=0.1887 |\nval_loss=0.1923 | CWA=0.938 SWA=0.935 GCWA=0.933', '\\n', 'Epoch 13:\ntrain_loss=0.1878 | val_loss=0.1905 | CWA=0.939 SWA=0.935 GCWA=0.933', '\\n',\n'Epoch 14: train_loss=0.1869 | val_loss=0.1890 | CWA=0.939 SWA=0.935\nGCWA=0.933', '\\n', 'Epoch 15: train_loss=0.1865 | val_loss=0.1878 | CWA=0.939\nSWA=0.935 GCWA=0.933', '\\n', 'Epoch 16: train_loss=0.1858 | val_loss=0.1873 |\nCWA=0.939 SWA=0.935 GCWA=0.933', '\\n', 'Epoch 17: train_loss=0.1852 |\nval_loss=0.1868 | CWA=0.939 SWA=0.935 GCWA=0.933', '\\n', 'Epoch 18:\ntrain_loss=0.1853 | val_loss=0.1870 | CWA=0.939 SWA=0.935 GCWA=0.933', '\\n',\n'Epoch 19: train_loss=0.1842 | val_loss=0.1875 | CWA=0.939 SWA=0.935\nGCWA=0.933', '\\n', 'Epoch 20: train_loss=0.1846 | val_loss=0.1883 | CWA=0.939\nSWA=0.935 GCWA=0.933', '\\n', 'Early stopping triggered at epoch 20', '\\n',\n'Test: loss=2.4454 | CWA=0.628 SWA=0.684 GCWA=0.627', '\\n', '\\n=== Training with\nmax_epochs = 30 ===', '\\n', 'Epoch 01: train_loss=0.5391 | val_loss=0.4573 |\nCWA=0.783 SWA=0.789 GCWA=0.781', '\\n', 'Epoch 02: train_loss=0.3713 |\nval_loss=0.2971 | CWA=0.886 SWA=0.885 GCWA=0.882', '\\n', 'Epoch 03:\ntrain_loss=0.2695 | val_loss=0.2455 | CWA=0.917 SWA=0.915 GCWA=0.913', '\\n',\n'Epoch 04: train_loss=0.2335 | val_loss=0.2240 | CWA=0.926 SWA=0.923\nGCWA=0.921', '\\n', 'Epoch 05: train_loss=0.2163 | val_loss=0.2118 | CWA=0.931\nSWA=0.928 GCWA=0.925', '\\n', 'Epoch 06: train_loss=0.2062 | val_loss=0.2051 |\nCWA=0.932 SWA=0.929 GCWA=0.926', '\\n', 'Epoch 07: train_loss=0.2006 |\nval_loss=0.2024 | CWA=0.934 SWA=0.931 GCWA=0.929', '\\n', 'Epoch 08:\ntrain_loss=0.1969 | val_loss=0.1980 | CWA=0.935 SWA=0.932 GCWA=0.930', '\\n',\n'Epoch 09: train_loss=0.1940 | val_loss=0.1967 | CWA=0.936 SWA=0.933\nGCWA=0.930', '\\n', 'Epoch 10: train_loss=0.1918 | val_loss=0.1964 | CWA=0.937\nSWA=0.934 GCWA=0.931', '\\n', 'Epoch 11: train_loss=0.1910 | val_loss=0.1940 |\nCWA=0.936 SWA=0.933 GCWA=0.930', '\\n', 'Epoch 12: train_loss=0.1899 |\nval_loss=0.1904 | CWA=0.937 SWA=0.934 GCWA=0.932', '\\n', 'Epoch 13:\ntrain_loss=0.1881 | val_loss=0.1904 | CWA=0.938 SWA=0.934 GCWA=0.932', '\\n',\n'Epoch 14: train_loss=0.1875 | val_loss=0.1899 | CWA=0.938 SWA=0.935\nGCWA=0.932', '\\n', 'Epoch 15: train_loss=0.1867 | val_loss=0.1890 | CWA=0.938\nSWA=0.934 GCWA=0.932', '\\n', 'Epoch 16: train_loss=0.1865 | val_loss=0.1889 |\nCWA=0.938 SWA=0.935 GCWA=0.933', '\\n', 'Epoch 17: train_loss=0.1860 |\nval_loss=0.1876 | CWA=0.938 SWA=0.935 GCWA=0.932', '\\n', 'Epoch 18:\ntrain_loss=0.1851 | val_loss=0.1869 | CWA=0.938 SWA=0.934 GCWA=0.932', '\\n',\n'Epoch 19: train_loss=0.1837 | val_loss=0.1852 | CWA=0.938 SWA=0.935\nGCWA=0.933', '\\n', 'Epoch 20: train_loss=0.1833 | val_loss=0.1853 | CWA=0.938\nSWA=0.935 GCWA=0.933', '\\n', 'Epoch 21: train_loss=0.1823 | val_loss=0.1846 |\nCWA=0.938 SWA=0.935 GCWA=0.933', '\\n', 'Epoch 22: train_loss=0.1817 |\nval_loss=0.1825 | CWA=0.938 SWA=0.935 GCWA=0.933', '\\n', 'Epoch 23:\ntrain_loss=0.1808 | val_loss=0.1840 | CWA=0.939 SWA=0.935 GCWA=0.933', '\\n',\n'Epoch 24: train_loss=0.1808 | val_loss=0.1827 | CWA=0.939 SWA=0.935\nGCWA=0.933', '\\n', 'Epoch 25: train_loss=0.1799 | val_loss=0.1819 | CWA=0.938\nSWA=0.935 GCWA=0.933', '\\n', 'Epoch 26: train_loss=0.1796 | val_loss=0.1807 |\nCWA=0.938 SWA=0.935 GCWA=0.933', '\\n', 'Epoch 27: train_loss=0.1791 |\nval_loss=0.1806 | CWA=0.939 SWA=0.935 GCWA=0.933', '\\n', 'Epoch 28:\ntrain_loss=0.1795 | val_loss=0.1811 | CWA=0.938 SWA=0.935 GCWA=0.933', '\\n',\n'Epoch 29: train_loss=0.1791 | val_loss=0.1799 | CWA=0.939 SWA=0.935\nGCWA=0.933', '\\n', 'Epoch 30: train_loss=0.1788 | val_loss=0.1800 | CWA=0.939\nSWA=0.935 GCWA=0.933', '\\n', 'Test: loss=3.2064 | CWA=0.628 SWA=0.684\nGCWA=0.627', '\\n', '\\nSaved experiment data to', ' ', '/home/zxl240011/AI-Scient\nist-v2/experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/0-\nrun/process_ForkProcess-6/working/experiment_data.npy', '\\n', 'Execution time: a\nminute seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 231751.27\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 495323.93\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 598972.37\nexamples/s]', '\\n', '\\n=== Training with learning rate 0.0005 ===', '\\n', 'Epoch\n1: train_loss=0.5987 | val_loss=0.5170 | CWA=0.747 | SWA=0.749 | GCWA=0.743',\n'\\n', 'Epoch 2: train_loss=0.4489 | val_loss=0.3830 | CWA=0.850 | SWA=0.850 |\nGCWA=0.846', '\\n', 'Epoch 3: train_loss=0.3445 | val_loss=0.3065 | CWA=0.893 |\nSWA=0.891 | GCWA=0.888', '\\n', 'Epoch 4: train_loss=0.2907 | val_loss=0.2702 |\nCWA=0.914 | SWA=0.911 | GCWA=0.909', '\\n', 'Epoch 5: train_loss=0.2636 |\nval_loss=0.2510 | CWA=0.917 | SWA=0.914 | GCWA=0.912', '\\n', 'Test: loss=1.1341\n| CWA=0.620 | SWA=0.674 | GCWA=0.621', '\\n', '\\n=== Training with learning rate\n0.001 ===', '\\n', 'Epoch 1: train_loss=0.5278 | val_loss=0.4228 | CWA=0.810 |\nSWA=0.812 | GCWA=0.806', '\\n', 'Epoch 2: train_loss=0.3575 | val_loss=0.2976 |\nCWA=0.894 | SWA=0.893 | GCWA=0.891', '\\n', 'Epoch 3: train_loss=0.2764 |\nval_loss=0.2555 | CWA=0.917 | SWA=0.914 | GCWA=0.912', '\\n', 'Epoch 4:\ntrain_loss=0.2456 | val_loss=0.2359 | CWA=0.923 | SWA=0.920 | GCWA=0.917', '\\n',\n'Epoch 5: train_loss=0.2301 | val_loss=0.2240 | CWA=0.929 | SWA=0.925 |\nGCWA=0.923', '\\n', 'Test: loss=1.4928 | CWA=0.628 | SWA=0.682 | GCWA=0.628',\n'\\n', '\\n=== Training with learning rate 0.002 ===', '\\n', 'Epoch 1:\ntrain_loss=0.5257 | val_loss=0.4060 | CWA=0.818 | SWA=0.819 | GCWA=0.812', '\\n',\n'Epoch 2: train_loss=0.3228 | val_loss=0.2526 | CWA=0.918 | SWA=0.916 |\nGCWA=0.914', '\\n', 'Epoch 3: train_loss=0.2351 | val_loss=0.2266 | CWA=0.930 |\nSWA=0.927 | GCWA=0.924', '\\n', 'Epoch 4: train_loss=0.2155 | val_loss=0.2093 |\nCWA=0.929 | SWA=0.926 | GCWA=0.923', '\\n', 'Epoch 5: train_loss=0.2080 |\nval_loss=0.2077 | CWA=0.931 | SWA=0.928 | GCWA=0.925', '\\n', 'Test: loss=1.9258\n| CWA=0.629 | SWA=0.683 | GCWA=0.628', '\\n', '\\n=== Training with learning rate\n0.005 ===', '\\n', 'Epoch 1: train_loss=0.3828 | val_loss=0.2320 | CWA=0.924 |\nSWA=0.921 | GCWA=0.919', '\\n', 'Epoch 2: train_loss=0.2113 | val_loss=0.2034 |\nCWA=0.930 | SWA=0.927 | GCWA=0.924', '\\n', 'Epoch 3: train_loss=0.2032 |\nval_loss=0.2015 | CWA=0.931 | SWA=0.928 | GCWA=0.925', '\\n', 'Epoch 4:\ntrain_loss=0.1990 | val_loss=0.1961 | CWA=0.932 | SWA=0.929 | GCWA=0.926', '\\n',\n'Epoch 5: train_loss=0.1941 | val_loss=0.1944 | CWA=0.931 | SWA=0.927 |\nGCWA=0.925', '\\n', 'Test: loss=2.6090 | CWA=0.629 | SWA=0.683 | GCWA=0.628',\n'\\n', 'Saved experiment_data.npy', '\\n', 'Execution time: 14 seconds seconds\n(time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 20000 examples [00:00,\n274099.00 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 274514.30\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 247345.04\nexamples/s]', '\\n', '\\n=== Training with batch_size=32 ===', '\\n', 'Epoch 1 |\ntrain_loss 0.3862 | val_loss 0.2423 | CWA 0.917 | SWA 0.915 | GCWA 0.913', '\\n',\n'Epoch 2 | train_loss 0.2202 | val_loss 0.2068 | CWA 0.936 | SWA 0.933 | GCWA\n0.930', '\\n', 'Epoch 3 | train_loss 0.1992 | val_loss 0.1981 | CWA 0.938 | SWA\n0.935 | GCWA 0.932', '\\n', 'Epoch 4 | train_loss 0.1921 | val_loss 0.1911 | CWA\n0.938 | SWA 0.935 | GCWA 0.933', '\\n', 'Epoch 5 | train_loss 0.1879 | val_loss\n0.1935 | CWA 0.938 | SWA 0.934 | GCWA 0.932', '\\n', 'Test | loss 2.2965 | CWA\n0.627 | SWA 0.683 | GCWA 0.627', '\\n', '\\n=== Training with batch_size=64 ===',\n'\\n', 'Epoch 1 | train_loss 0.4818 | val_loss 0.3270 | CWA 0.877 | SWA 0.875 |\nGCWA 0.871', '\\n', 'Epoch 2 | train_loss 0.2739 | val_loss 0.2417 | CWA 0.921 |\nSWA 0.919 | GCWA 0.917', '\\n', 'Epoch 3 | train_loss 0.2297 | val_loss 0.2176 |\nCWA 0.934 | SWA 0.931 | GCWA 0.929', '\\n', 'Epoch 4 | train_loss 0.2110 |\nval_loss 0.2081 | CWA 0.936 | SWA 0.933 | GCWA 0.931', '\\n', 'Epoch 5 |\ntrain_loss 0.2018 | val_loss 0.2009 | CWA 0.938 | SWA 0.934 | GCWA 0.932', '\\n',\n'Test | loss 2.0273 | CWA 0.627 | SWA 0.683 | GCWA 0.627', '\\n', '\\n=== Training\nwith batch_size=128 ===', '\\n', 'Epoch 1 | train_loss 0.5537 | val_loss 0.4132 |\nCWA 0.833 | SWA 0.832 | GCWA 0.828', '\\n', 'Epoch 2 | train_loss 0.3296 |\nval_loss 0.2771 | CWA 0.907 | SWA 0.908 | GCWA 0.906', '\\n', 'Epoch 3 |\ntrain_loss 0.2574 | val_loss 0.2428 | CWA 0.918 | SWA 0.917 | GCWA 0.915', '\\n',\n'Epoch 4 | train_loss 0.2295 | val_loss 0.2225 | CWA 0.930 | SWA 0.927 | GCWA\n0.925', '\\n', 'Epoch 5 | train_loss 0.2132 | val_loss 0.2099 | CWA 0.936 | SWA\n0.932 | GCWA 0.930', '\\n', 'Test | loss 1.5632 | CWA 0.625 | SWA 0.681 | GCWA\n0.625', '\\n', '\\n=== Training with batch_size=256 ===', '\\n', 'Epoch 1 |\ntrain_loss 0.5896 | val_loss 0.4951 | CWA 0.770 | SWA 0.771 | GCWA 0.766', '\\n',\n'Epoch 2 | train_loss 0.4362 | val_loss 0.3749 | CWA 0.852 | SWA 0.850 | GCWA\n0.846', '\\n', 'Epoch 3 | train_loss 0.3334 | val_loss 0.2963 | CWA 0.904 | SWA\n0.901 | GCWA 0.899', '\\n', 'Epoch 4 | train_loss 0.2755 | val_loss 0.2567 | CWA\n0.923 | SWA 0.920 | GCWA 0.919', '\\n', 'Epoch 5 | train_loss 0.2456 | val_loss\n0.2362 | CWA 0.926 | SWA 0.922 | GCWA 0.921', '\\n', 'Test | loss 1.1828 | CWA\n0.621 | SWA 0.676 | GCWA 0.622', '\\n', 'Saved results to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_02-26-\n55_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n8/working/experiment_data.npy', '\\n', 'Execution time: 24 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 20000 examples [00:00,\n290531.67 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 360310.63\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 207322.70\nexamples/s]', '\\n', '\\n===== Training with embedding_dim=4 =====', '\\n', 'Epoch\n1/5 | train_loss=0.5948 | val_loss=0.5292 | CWA=0.733 | SWA=0.732 | GCWA=0.723',\n'\\n', 'Epoch 2/5 | train_loss=0.4843 | val_loss=0.4398 | CWA=0.789 | SWA=0.790 |\nGCWA=0.783', '\\n', 'Epoch 3/5 | train_loss=0.4008 | val_loss=0.3601 | CWA=0.851\n| SWA=0.852 | GCWA=0.847', '\\n', 'Epoch 4/5 | train_loss=0.3278 |\nval_loss=0.2919 | CWA=0.906 | SWA=0.907 | GCWA=0.904', '\\n', 'Epoch 5/5 |\ntrain_loss=0.2699 | val_loss=0.2456 | CWA=0.925 | SWA=0.923 | GCWA=0.921', '\\n',\n'Test | loss=1.1698 | CWA=0.624 | SWA=0.678 | GCWA=0.624', '\\n', '\\n=====\nTraining with embedding_dim=8 =====', '\\n', 'Epoch 1/5 | train_loss=0.5720 |\nval_loss=0.4866 | CWA=0.774 | SWA=0.780 | GCWA=0.773', '\\n', 'Epoch 2/5 |\ntrain_loss=0.4044 | val_loss=0.3329 | CWA=0.874 | SWA=0.875 | GCWA=0.873', '\\n',\n'Epoch 3/5 | train_loss=0.2999 | val_loss=0.2721 | CWA=0.904 | SWA=0.904 |\nGCWA=0.902', '\\n', 'Epoch 4/5 | train_loss=0.2617 | val_loss=0.2488 | CWA=0.915\n| SWA=0.914 | GCWA=0.912', '\\n', 'Epoch 5/5 | train_loss=0.2416 |\nval_loss=0.2329 | CWA=0.922 | SWA=0.920 | GCWA=0.918', '\\n', 'Test | loss=1.3615\n| CWA=0.621 | SWA=0.676 | GCWA=0.622', '\\n', '\\n===== Training with\nembedding_dim=16 =====', '\\n', 'Epoch 1/5 | train_loss=0.4970 | val_loss=0.3597\n| CWA=0.867 | SWA=0.868 | GCWA=0.866', '\\n', 'Epoch 2/5 | train_loss=0.2867 |\nval_loss=0.2421 | CWA=0.928 | SWA=0.925 | GCWA=0.924', '\\n', 'Epoch 3/5 |\ntrain_loss=0.2261 | val_loss=0.2134 | CWA=0.936 | SWA=0.933 | GCWA=0.930', '\\n',\n'Epoch 4/5 | train_loss=0.2070 | val_loss=0.2028 | CWA=0.938 | SWA=0.935 |\nGCWA=0.932', '\\n', 'Epoch 5/5 | train_loss=0.1974 | val_loss=0.1970 | CWA=0.939\n| SWA=0.935 | GCWA=0.933', '\\n', 'Test | loss=1.9191 | CWA=0.628 | SWA=0.684 |\nGCWA=0.627', '\\n', '\\n===== Training with embedding_dim=32 =====', '\\n', 'Epoch\n1/5 | train_loss=0.4846 | val_loss=0.3442 | CWA=0.865 | SWA=0.863 | GCWA=0.859',\n'\\n', 'Epoch 2/5 | train_loss=0.2875 | val_loss=0.2520 | CWA=0.923 | SWA=0.921 |\nGCWA=0.919', '\\n', 'Epoch 3/5 | train_loss=0.2361 | val_loss=0.2200 | CWA=0.932\n| SWA=0.929 | GCWA=0.926', '\\n', 'Epoch 4/5 | train_loss=0.2148 |\nval_loss=0.2088 | CWA=0.934 | SWA=0.931 | GCWA=0.929', '\\n', 'Epoch 5/5 |\ntrain_loss=0.2048 | val_loss=0.2040 | CWA=0.935 | SWA=0.932 | GCWA=0.929', '\\n',\n'Test | loss=1.8179 | CWA=0.627 | SWA=0.682 | GCWA=0.626', '\\n', 'Saved\nexperiment data to', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-\n31_02-26-55_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n9/working/experiment_data.npy', '\\n', 'Execution time: 14 seconds seconds (time\nlimit is 30 minutes).']"], "analysis": ["", "", "", "", ""], "exc_type": [null, null, null, null, null], "exc_info": [null, null, null, null, null], "exc_stack": [null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.2083, "best_value": 0.2083}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.2071, "best_value": 0.2071}]}, {"metric_name": "validation Color Weighted Accuracy", "lower_is_better": false, "description": "The weighted accuracy for color classification on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.937, "best_value": 0.937}]}, {"metric_name": "validation Shape Weighted Accuracy", "lower_is_better": false, "description": "The weighted accuracy for shape classification on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.933, "best_value": 0.933}]}, {"metric_name": "validation Glyph Complexity Weighted Accuracy", "lower_is_better": false, "description": "The weighted accuracy for glyph complexity classification on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.931, "best_value": 0.931}]}, {"metric_name": "Test Color Weighted Accuracy", "lower_is_better": false, "description": "The weighted accuracy for color classification on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.627, "best_value": 0.627}]}, {"metric_name": "Test Shape Weighted Accuracy", "lower_is_better": false, "description": "The weighted accuracy for shape classification on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.682, "best_value": 0.682}]}, {"metric_name": "Test Glyph Complexity Weighted Accuracy", "lower_is_better": false, "description": "The weighted accuracy for glyph complexity classification on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.626, "best_value": 0.626}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss during training at the best epoch.", "data": [{"dataset_name": "epochs_5", "final_value": 0.2159, "best_value": 0.2159}, {"dataset_name": "epochs_10", "final_value": 0.1861, "best_value": 0.1861}, {"dataset_name": "epochs_20", "final_value": 0.1852, "best_value": 0.1852}, {"dataset_name": "epochs_30", "final_value": 0.1791, "best_value": 0.1791}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss during validation at the best epoch.", "data": [{"dataset_name": "epochs_5", "final_value": 0.2128, "best_value": 0.2128}, {"dataset_name": "epochs_10", "final_value": 0.1881, "best_value": 0.1881}, {"dataset_name": "epochs_20", "final_value": 0.1868, "best_value": 0.1868}, {"dataset_name": "epochs_30", "final_value": 0.1799, "best_value": 0.1799}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss on the test set using the final model.", "data": [{"dataset_name": "epochs_5", "final_value": 1.5782, "best_value": 1.5782}, {"dataset_name": "epochs_10", "final_value": 1.9237, "best_value": 1.9237}, {"dataset_name": "epochs_20", "final_value": 2.4454, "best_value": 2.4454}, {"dataset_name": "epochs_30", "final_value": 3.2064, "best_value": 3.2064}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "The CWA metric on the test set using the final model.", "data": [{"dataset_name": "epochs_5", "final_value": 0.627, "best_value": 0.627}, {"dataset_name": "epochs_10", "final_value": 0.628, "best_value": 0.628}, {"dataset_name": "epochs_20", "final_value": 0.628, "best_value": 0.628}, {"dataset_name": "epochs_30", "final_value": 0.628, "best_value": 0.628}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "The SWA metric on the test set using the final model.", "data": [{"dataset_name": "epochs_5", "final_value": 0.682, "best_value": 0.682}, {"dataset_name": "epochs_10", "final_value": 0.684, "best_value": 0.684}, {"dataset_name": "epochs_20", "final_value": 0.684, "best_value": 0.684}, {"dataset_name": "epochs_30", "final_value": 0.684, "best_value": 0.684}]}, {"metric_name": "test GCWA", "lower_is_better": false, "description": "The GCWA metric on the test set using the final model.", "data": [{"dataset_name": "epochs_5", "final_value": 0.627, "best_value": 0.627}, {"dataset_name": "epochs_10", "final_value": 0.627, "best_value": 0.627}, {"dataset_name": "epochs_20", "final_value": 0.627, "best_value": 0.627}, {"dataset_name": "epochs_30", "final_value": 0.627, "best_value": 0.627}]}]}, {"metric_names": [{"metric_name": "loss", "lower_is_better": true, "description": "Measure of error in the model's predictions.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1944, "best_value": 0.1944}]}, {"metric_name": "CWA", "lower_is_better": false, "description": "Custom Weighted Accuracy.", "data": [{"dataset_name": "SPR_BENCH_validation", "final_value": 0.931, "best_value": 0.931}, {"dataset_name": "SPR_BENCH_test", "final_value": 0.629, "best_value": 0.629}]}, {"metric_name": "SWA", "lower_is_better": false, "description": "Simple Weighted Accuracy.", "data": [{"dataset_name": "SPR_BENCH_validation", "final_value": 0.928, "best_value": 0.928}, {"dataset_name": "SPR_BENCH_test", "final_value": 0.683, "best_value": 0.683}]}, {"metric_name": "GCWA", "lower_is_better": false, "description": "Generalized Custom Weighted Accuracy.", "data": [{"dataset_name": "SPR_BENCH_validation", "final_value": 0.925, "best_value": 0.925}, {"dataset_name": "SPR_BENCH_test", "final_value": 0.628, "best_value": 0.628}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is learning.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1879, "best_value": 0.1879}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation set, used to evaluate model performance during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.2362, "best_value": 0.1911}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "The Correct Weighted Accuracy on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.926, "best_value": 0.938}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "The Smoothed Weighted Accuracy on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.922, "best_value": 0.935}]}, {"metric_name": "validation GCWA", "lower_is_better": false, "description": "The Generalized Correct Weighted Accuracy on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.921, "best_value": 0.933}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "The Correct Weighted Accuracy on the test set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.621, "best_value": 0.627}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "The Smoothed Weighted Accuracy on the test set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.676, "best_value": 0.683}]}, {"metric_name": "test GCWA", "lower_is_better": false, "description": "The Generalized Correct Weighted Accuracy on the test set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.622, "best_value": 0.627}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss computed on the training dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_4", "final_value": 0.2699, "best_value": 0.2699}, {"dataset_name": "SPR_BENCH_dim_8", "final_value": 0.2416, "best_value": 0.2416}, {"dataset_name": "SPR_BENCH_dim_16", "final_value": 0.1974, "best_value": 0.1974}, {"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.2048, "best_value": 0.2048}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss computed on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_4", "final_value": 0.2456, "best_value": 0.2456}, {"dataset_name": "SPR_BENCH_dim_8", "final_value": 0.2329, "best_value": 0.2329}, {"dataset_name": "SPR_BENCH_dim_16", "final_value": 0.197, "best_value": 0.197}, {"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.204, "best_value": 0.204}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss computed on the test dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_4", "final_value": 1.1698, "best_value": 1.1698}, {"dataset_name": "SPR_BENCH_dim_8", "final_value": 1.3615, "best_value": 1.3615}, {"dataset_name": "SPR_BENCH_dim_16", "final_value": 1.9191, "best_value": 1.9191}, {"dataset_name": "SPR_BENCH_dim_32", "final_value": 1.8179, "best_value": 1.8179}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy computed on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_4", "final_value": 0.925, "best_value": 0.925}, {"dataset_name": "SPR_BENCH_dim_8", "final_value": 0.922, "best_value": 0.922}, {"dataset_name": "SPR_BENCH_dim_16", "final_value": 0.939, "best_value": 0.939}, {"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.935, "best_value": 0.935}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy computed on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_4", "final_value": 0.923, "best_value": 0.923}, {"dataset_name": "SPR_BENCH_dim_8", "final_value": 0.92, "best_value": 0.92}, {"dataset_name": "SPR_BENCH_dim_16", "final_value": 0.935, "best_value": 0.935}, {"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.932, "best_value": 0.932}]}, {"metric_name": "validation glyph-complexity-weighted accuracy", "lower_is_better": false, "description": "The glyph-complexity-weighted accuracy computed on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_4", "final_value": 0.921, "best_value": 0.921}, {"dataset_name": "SPR_BENCH_dim_8", "final_value": 0.918, "best_value": 0.918}, {"dataset_name": "SPR_BENCH_dim_16", "final_value": 0.933, "best_value": 0.933}, {"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.929, "best_value": 0.929}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy computed on the test dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_4", "final_value": 0.624, "best_value": 0.624}, {"dataset_name": "SPR_BENCH_dim_8", "final_value": 0.621, "best_value": 0.621}, {"dataset_name": "SPR_BENCH_dim_16", "final_value": 0.628, "best_value": 0.628}, {"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.627, "best_value": 0.627}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy computed on the test dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_4", "final_value": 0.678, "best_value": 0.678}, {"dataset_name": "SPR_BENCH_dim_8", "final_value": 0.676, "best_value": 0.676}, {"dataset_name": "SPR_BENCH_dim_16", "final_value": 0.684, "best_value": 0.684}, {"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.682, "best_value": 0.682}]}, {"metric_name": "test glyph-complexity-weighted accuracy", "lower_is_better": false, "description": "The glyph-complexity-weighted accuracy computed on the test dataset.", "data": [{"dataset_name": "SPR_BENCH_dim_4", "final_value": 0.624, "best_value": 0.624}, {"dataset_name": "SPR_BENCH_dim_8", "final_value": 0.622, "best_value": 0.622}, {"dataset_name": "SPR_BENCH_dim_16", "final_value": 0.627, "best_value": 0.627}, {"dataset_name": "SPR_BENCH_dim_32", "final_value": 0.626, "best_value": 0.626}]}]}], "is_best_node": [false, false, true, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_5667722118364ba89f2792db6eab414d_proc_1599548/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_5667722118364ba89f2792db6eab414d_proc_1599548/SPR_BENCH_val_metrics_curve.png", "../../logs/0-run/experiment_results/experiment_5667722118364ba89f2792db6eab414d_proc_1599548/SPR_BENCH_test_metrics_bar.png"], ["../../logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_5.png", "../../logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_10.png", "../../logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_20.png", "../../logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_30.png", "../../logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_test_metric_comparison.png"], ["../../logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_loss_vs_lr.png", "../../logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_val_metrics_vs_lr.png", "../../logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_test_metrics_vs_lr.png", "../../logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_confusion_matrix_lr_2e-03.png"], ["../../logs/0-run/experiment_results/experiment_0724ee2ef5a844639908253e87371e41_proc_1602623/SPR_BENCH_training_loss.png", "../../logs/0-run/experiment_results/experiment_0724ee2ef5a844639908253e87371e41_proc_1602623/SPR_BENCH_validation_loss.png", "../../logs/0-run/experiment_results/experiment_0724ee2ef5a844639908253e87371e41_proc_1602623/SPR_BENCH_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_0a357670eec34aea8056974fc38a7442_proc_1602625/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_0a357670eec34aea8056974fc38a7442_proc_1602625/SPR_BENCH_val_GCWA.png", "../../logs/0-run/experiment_results/experiment_0a357670eec34aea8056974fc38a7442_proc_1602625/SPR_BENCH_test_metrics_bar.png"]], "plot_paths": [["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5667722118364ba89f2792db6eab414d_proc_1599548/SPR_BENCH_loss_curve.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5667722118364ba89f2792db6eab414d_proc_1599548/SPR_BENCH_val_metrics_curve.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5667722118364ba89f2792db6eab414d_proc_1599548/SPR_BENCH_test_metrics_bar.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_5.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_10.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_20.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_30.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_test_metric_comparison.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_loss_vs_lr.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_val_metrics_vs_lr.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_test_metrics_vs_lr.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_confusion_matrix_lr_2e-03.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0724ee2ef5a844639908253e87371e41_proc_1602623/SPR_BENCH_training_loss.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0724ee2ef5a844639908253e87371e41_proc_1602623/SPR_BENCH_validation_loss.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0724ee2ef5a844639908253e87371e41_proc_1602623/SPR_BENCH_test_metrics.png"], ["experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0a357670eec34aea8056974fc38a7442_proc_1602625/SPR_BENCH_loss_curves.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0a357670eec34aea8056974fc38a7442_proc_1602625/SPR_BENCH_val_GCWA.png", "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0a357670eec34aea8056974fc38a7442_proc_1602625/SPR_BENCH_test_metrics_bar.png"]], "plot_analyses": [[{"analysis": "The loss curves indicate consistent and stable training. Both training and validation losses decrease steadily over the epochs, with no signs of overfitting or underfitting. The gap between the training and validation loss is minimal, suggesting good generalization.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5667722118364ba89f2792db6eab414d_proc_1599548/SPR_BENCH_loss_curve.png"}, {"analysis": "The validation metrics for CWA, SWA, and GCWA show a clear upward trend, indicating that the model improves in handling the tasks as training progresses. The curves plateau near the final epochs, suggesting convergence. CWA consistently outperforms SWA and GCWA, aligning with the hypothesis that clustering symbolic glyphs may enhance accuracy.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5667722118364ba89f2792db6eab414d_proc_1599548/SPR_BENCH_val_metrics_curve.png"}, {"analysis": "The bar chart of final test metrics shows that the model achieves its best performance on CWA, followed by SWA and GCWA. While the results are promising, the scores are below the stated SOTA targets of 70.0% for CWA and 65.0% for SWA, indicating room for further optimization and experimentation.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5667722118364ba89f2792db6eab414d_proc_1599548/SPR_BENCH_test_metrics_bar.png"}], [{"analysis": "The loss curves for 5 epochs demonstrate a consistent decrease in both training and validation loss, indicating that the model is learning effectively. The gap between training and validation loss is small, suggesting that the model is not overfitting at this stage.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_5.png"}, {"analysis": "The loss curves for 10 epochs show further reduction in both training and validation loss. The curves converge closely, which is a positive indicator of generalization. However, the rate of loss reduction diminishes after around 7 epochs, suggesting a potential plateau.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_10.png"}, {"analysis": "The loss curves for 20 epochs reveal that the model achieves minimal loss values for both training and validation sets. The curves are nearly identical, showing strong generalization. However, the minimal improvement after 10 epochs suggests diminishing returns with additional training.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_20.png"}, {"analysis": "The loss curves for 30 epochs indicate that the model has fully converged, as the loss values remain stable after around 20 epochs. The close alignment of training and validation loss suggests no overfitting, but training beyond 20 epochs provides no significant performance gains.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_loss_curve_epochs_30.png"}, {"analysis": "The weighted accuracy plot for CWA, SWA, and GCWA across different epochs indicates steady improvement in performance metrics as the number of epochs increases. However, the gains diminish after 20 epochs, aligning with the observed loss curves. The model achieves near-optimal performance at around 20 epochs, with all metrics nearing their peak values.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_52b92479ef38404ba76c56cd0df500e0_proc_1602617/synthetic_spr_test_metric_comparison.png"}], [{"analysis": "This plot shows the train and validation loss for different learning rates. As the learning rate increases, both train and validation losses decrease, indicating improved learning. The losses converge closely, which suggests that the model is not overfitting and that the chosen learning rates are effective for training.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_loss_vs_lr.png"}, {"analysis": "This plot compares validation metrics (CWA, SWA, GCWA) across different learning rates. The scores improve significantly as the learning rate increases from 5e-4 to 2e-3, but they plateau or slightly decline at 5e-3. This suggests that 2e-3 is likely the optimal learning rate for validation performance.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_val_metrics_vs_lr.png"}, {"analysis": "This plot compares test metrics (CWA, SWA, GCWA) across different learning rates. Similar to the validation metrics, performance improves as the learning rate increases, with a plateau at 2e-3 and 5e-3. SWA performs the best among the metrics, indicating that the model captures shape-related patterns effectively.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_test_metrics_vs_lr.png"}, {"analysis": "This confusion matrix evaluates the model's performance at the learning rate of 2e-3. The true positive and true negative counts are relatively high, but there are still notable false positives and false negatives. This indicates that while the model performs well overall, there is room for improvement in minimizing misclassifications.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_2cfe53b7ab6e46a0bddc848be2d3f305_proc_1602622/SPR_BENCH_confusion_matrix_lr_2e-03.png"}], [{"analysis": "The plot shows the training loss decreasing steadily across all batch sizes (32, 64, 128, 256) as the number of epochs increases. Smaller batch sizes (e.g., BS=32) achieve lower training loss compared to larger batch sizes (e.g., BS=256), indicating that smaller batch sizes may lead to better optimization during training. The diminishing rate of loss reduction after around 3 epochs suggests a plateauing effect, where further training may yield diminishing returns.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0724ee2ef5a844639908253e87371e41_proc_1602623/SPR_BENCH_training_loss.png"}, {"analysis": "The validation loss follows a similar trend to the training loss, with smaller batch sizes achieving lower validation loss. This suggests better generalization for smaller batch sizes. The consistent reduction in validation loss across epochs indicates that the model is learning effectively without overfitting. However, the gap between larger and smaller batch sizes in terms of validation loss highlights the importance of batch size selection for model performance.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0724ee2ef5a844639908253e87371e41_proc_1602623/SPR_BENCH_validation_loss.png"}, {"analysis": "The test metrics (CWA, SWA, and GCWA) are relatively consistent across all batch sizes, with slight variations. SWA tends to have the highest scores, followed by GCWA and CWA. This indicates that the model performs well across various metrics regardless of the batch size used during training. The results suggest that the choice of batch size has minimal impact on the final test performance, although smaller batch sizes may still be preferable for slightly better optimization during training and validation.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0724ee2ef5a844639908253e87371e41_proc_1602623/SPR_BENCH_test_metrics.png"}], [{"analysis": "The loss curves indicate that increasing the embedding dimension improves the convergence rate and reduces the final loss for both training and validation datasets. Specifically, higher dimensions (dim_16 and dim_32) result in significantly lower cross-entropy loss compared to lower dimensions (dim_4 and dim_8). This suggests that the model benefits from higher-dimensional latent feature representations, likely due to increased capacity to capture intricate relationships in the data. However, the diminishing gap between training and validation losses at higher dimensions also indicates minimal overfitting.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0a357670eec34aea8056974fc38a7442_proc_1602625/SPR_BENCH_loss_curves.png"}, {"analysis": "The GCWA (Generalized Color-Weighted Accuracy) validation metric improves steadily across epochs for all embedding dimensions. Models with higher dimensions (dim_16 and dim_32) achieve superior GCWA earlier and maintain a consistent lead over lower dimensions (dim_4 and dim_8). This underscores the effectiveness of higher embedding dimensions in capturing color-based patterns, leading to better generalization performance.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0a357670eec34aea8056974fc38a7442_proc_1602625/SPR_BENCH_val_GCWA.png"}, {"analysis": "The test metrics plot shows that all three metrics (CWA, SWA, GCWA) are positively influenced by increasing embedding dimensions. However, the improvement plateaus as the dimension increases from dim_16 to dim_32, suggesting diminishing returns beyond a certain point. All metrics achieve values close to or above the state-of-the-art benchmark, indicating the success of the clustering approach in improving both color- and shape-weighted accuracies. The consistency across metrics also highlights the robustness of the model's performance across different evaluation criteria.", "plot_path": "experiments/2025-08-31_02-26-55_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0a357670eec34aea8056974fc38a7442_proc_1602625/SPR_BENCH_test_metrics_bar.png"}]], "vlm_feedback_summary": ["The experimental results demonstrate steady training and validation loss\nreduction, with validation metrics improving consistently over epochs. Although\nthe final test scores are below the SOTA targets, the trends suggest that the\napproach has potential with further refinement.", "The loss curves and weighted accuracy plots indicate that the model effectively\nlearns and generalizes well, with diminishing returns in performance after 20\nepochs. The metrics suggest that training beyond 20 epochs may not be necessary\nfor optimal performance.", "The plots indicate that increasing the learning rate improves both training and\nvalidation performance up to a certain point (2e-3), beyond which the gains\nplateau. Validation and test metrics align, with SWA showing the highest\nperformance. The confusion matrix highlights good overall performance with some\nscope for reducing misclassifications.", "The plots provide insights into the effect of batch size on training,\nvalidation, and test performance. Smaller batch sizes generally lead to better\noptimization and generalization during training and validation. However, the\ntest performance remains consistent across batch sizes, indicating robustness of\nthe model to batch size variations.", "The experimental results demonstrate that increasing embedding dimensions\nenhances model performance, particularly in terms of convergence speed,\ngeneralization, and alignment with state-of-the-art benchmarks. However, the\ngains diminish beyond a certain dimensionality, suggesting an optimal range for\nembedding dimensions."], "exec_time": [5.952783584594727, 96.17214226722717, 14.26250433921814, 24.644038438796997, 14.844539642333984], "exec_time_feedback": ["", "", "", "", ""], "datasets_successfully_tested": [["[]"], ["[\"Synthetic SPR Dataset\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"]], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------ load data ------------------ #\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ndata_key = \"SPR_BENCH\"\ned = experiment_data.get(data_key, {})\n\nloss_train = ed.get(\"losses\", {}).get(\"train\", [])\nloss_val = ed.get(\"losses\", {}).get(\"val\", [])\nval_metrics = ed.get(\"metrics\", {}).get(\"val\", [])\ntest_metrics = ed.get(\"metrics\", {}).get(\"test\", {})\n\nepochs = list(range(1, len(loss_train) + 1))\n\n# ------------------ Plot 1: loss curves ------------------ #\ntry:\n    plt.figure()\n    plt.plot(epochs, loss_train, label=\"Train Loss\")\n    plt.plot(epochs, loss_val, label=\"Val Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(f\"{data_key} Loss Curves\\nLeft: Training, Right: Validation\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{data_key}_loss_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# ------------------ Plot 2: validation metric curves ------------------ #\ntry:\n    if val_metrics:\n        cwa = [m[\"CWA\"] for m in val_metrics]\n        swa = [m[\"SWA\"] for m in val_metrics]\n        gcwa = [m[\"GCWA\"] for m in val_metrics]\n        plt.figure()\n        plt.plot(epochs, cwa, label=\"CWA\")\n        plt.plot(epochs, swa, label=\"SWA\")\n        plt.plot(epochs, gcwa, label=\"GCWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(f\"{data_key} Validation Metrics over Epochs\\nCWA, SWA, GCWA\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{data_key}_val_metrics_curve.png\")\n        plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating validation metric curve: {e}\")\n    plt.close()\n\n# ------------------ Plot 3: test metric bar chart ------------------ #\ntry:\n    if test_metrics:\n        labels = [\"CWA\", \"SWA\", \"GCWA\"]\n        values = [test_metrics.get(k, 0) for k in labels]\n        plt.figure()\n        plt.bar(labels, values, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n        plt.ylim(0, 1)\n        plt.ylabel(\"Score\")\n        plt.title(f\"{data_key} Test Metrics\\nBar Chart of Final Scores\")\n        fname = os.path.join(working_dir, f\"{data_key}_test_metrics_bar.png\")\n        plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metric bar chart: {e}\")\n    plt.close()\n\n# ------------------ print final metrics ------------------ #\nif test_metrics:\n    print(\"Test metrics:\")\n    for k, v in test_metrics.items():\n        print(f\"{k}: {v:.3f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------ #\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    runs = experiment_data.get(\"num_epochs\", {})\n    # 1\u20134: loss curves for each run\n    for run_idx, (run_key, run_data) in enumerate(runs.items()):\n        try:\n            train_losses = run_data[\"losses\"][\"train\"]\n            val_losses = run_data[\"losses\"][\"val\"]\n            epochs = list(range(1, len(train_losses) + 1))\n\n            plt.figure()\n            plt.plot(epochs, train_losses, label=\"Train Loss\")\n            plt.plot(epochs, val_losses, label=\"Validation Loss\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"Synthetic SPR Dataset \u2013 Loss Curves\\nRun {run_key}\")\n            plt.legend()\n            fname = f\"synthetic_spr_loss_curve_{run_key}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss curve for {run_key}: {e}\")\n            plt.close()\n\n    # 5: bar chart comparing final test metrics across runs (max 5 bars * 3 groups)\n    try:\n        metrics_names = [\"CWA\", \"SWA\", \"GCWA\"]\n        x = np.arange(len(runs))  # bar positions\n        width = 0.25\n        plt.figure()\n        for i, m in enumerate(metrics_names):\n            vals = [runs[r][\"metrics\"][\"test\"][m] for r in runs]\n            plt.bar(x + i * width, vals, width, label=m)\n        plt.xticks(x + width, list(runs.keys()), rotation=45)\n        plt.ylim(0, 1.05)\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.title(\n            \"Synthetic SPR Dataset \u2013 Test Weighted Accuracies\\nLeft: CWA, Middle: SWA, Right: GCWA\"\n        )\n        plt.legend()\n        fname = \"synthetic_spr_test_metric_comparison.png\"\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric comparison plot: {e}\")\n        plt.close()\n\n    # print evaluation metrics\n    print(\"\\nFinal Test Metrics per Run:\")\n    for run_key, run_data in runs.items():\n        tm = run_data[\"metrics\"][\"test\"]\n        print(\n            f\"{run_key}: CWA={tm['CWA']:.3f}  SWA={tm['SWA']:.3f}  GCWA={tm['GCWA']:.3f}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------- load data ---------------- #\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    data = experiment_data[\"learning_rate\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exit()\n\nlrs = np.array(data[\"lrs\"])\ntr_losses = np.array(data[\"losses\"][\"train\"])\nval_losses = np.array(data[\"losses\"][\"val\"])\nval_mets = data[\"metrics\"][\"val\"]  # list of dicts\ntest_mets = data[\"metrics\"][\"test\"]  # list of dicts\n\n# turn metric dict lists into arrays\nval_cwa = np.array([m[\"CWA\"] for m in val_mets])\nval_swa = np.array([m[\"SWA\"] for m in val_mets])\nval_gcwa = np.array([m[\"GCWA\"] for m in val_mets])\ntst_cwa = np.array([m[\"CWA\"] for m in test_mets])\ntst_swa = np.array([m[\"SWA\"] for m in test_mets])\ntst_gcwa = np.array([m[\"GCWA\"] for m in test_mets])\n\nbest_idx = int(np.argmax(val_gcwa))\nbest_lr = lrs[best_idx]\nprint(\"\\n==== Summary of results on SPR_BENCH ====\")\nfor i, lr in enumerate(lrs):\n    print(\n        f\"LR={lr:.0e} | VAL CWA={val_cwa[i]:.3f} SWA={val_swa[i]:.3f} GCWA={val_gcwa[i]:.3f} \"\n        f\"| TEST CWA={tst_cwa[i]:.3f} SWA={tst_swa[i]:.3f} GCWA={tst_gcwa[i]:.3f}\"\n    )\nprint(f\"\\nChosen best LR (highest VAL GCWA): {best_lr:.0e}\\n\")\n\n# -------------- plotting ------------------ #\n# 1) train vs val loss\ntry:\n    plt.figure()\n    w = 0.35\n    idx = np.arange(len(lrs))\n    plt.bar(idx - w / 2, tr_losses, width=w, label=\"Train Loss\")\n    plt.bar(idx + w / 2, val_losses, width=w, label=\"Val Loss\")\n    plt.xticks(idx, [f\"{lr:.0e}\" for lr in lrs])\n    plt.xlabel(\"Learning Rate\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"SPR_BENCH: Final Train vs. Val Loss\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_vs_lr.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# 2) validation metrics\ntry:\n    plt.figure()\n    plt.plot(lrs, val_cwa, \"o-\", label=\"CWA\")\n    plt.plot(lrs, val_swa, \"s-\", label=\"SWA\")\n    plt.plot(lrs, val_gcwa, \"d-\", label=\"GCWA\")\n    plt.xscale(\"log\")\n    plt.xlabel(\"Learning Rate\")\n    plt.ylabel(\"Score\")\n    plt.title(\"SPR_BENCH: Validation Metrics vs. Learning Rate\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_metrics_vs_lr.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating validation metric plot: {e}\")\n    plt.close()\n\n# 3) test metrics\ntry:\n    plt.figure()\n    plt.plot(lrs, tst_cwa, \"o-\", label=\"CWA\")\n    plt.plot(lrs, tst_swa, \"s-\", label=\"SWA\")\n    plt.plot(lrs, tst_gcwa, \"d-\", label=\"GCWA\")\n    plt.xscale(\"log\")\n    plt.xlabel(\"Learning Rate\")\n    plt.ylabel(\"Score\")\n    plt.title(\"SPR_BENCH: Test Metrics vs. Learning Rate\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_test_metrics_vs_lr.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metric plot: {e}\")\n    plt.close()\n\n# 4) confusion matrix for best LR\ntry:\n    preds = np.array(data[\"predictions\"][best_idx])\n    tgts = np.array(data[\"ground_truth\"][best_idx])\n    classes = np.unique(tgts)\n    n_cls = len(classes)\n    cm = np.zeros((n_cls, n_cls), dtype=int)\n    for t, p in zip(tgts, preds):\n        cm[t, p] += 1\n\n    plt.figure()\n    im = plt.imshow(cm, cmap=\"Blues\")\n    plt.colorbar(im)\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(f\"SPR_BENCH: Confusion Matrix (LR={best_lr:.0e})\")\n    plt.xticks(classes)\n    plt.yticks(classes)\n    for i in range(n_cls):\n        for j in range(n_cls):\n            plt.text(\n                j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\", fontsize=8\n            )\n    plt.tight_layout()\n    plt.savefig(\n        os.path.join(working_dir, f\"SPR_BENCH_confusion_matrix_lr_{best_lr:.0e}.png\")\n    )\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- load data --------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exit(0)\n\ndata_branch = experiment_data.get(\"batch_size\", {}).get(\"SPR_BENCH\", {})\nif not data_branch:\n    print(\"No SPR_BENCH data found in experiment_data.npy\")\n    exit(0)\n\nbatch_sizes = sorted(data_branch.keys())\nepochs = max(len(data_branch[bs][\"losses\"][\"train\"]) for bs in batch_sizes)\n\n# -------- gather arrays --------\ntrain_losses = {bs: data_branch[bs][\"losses\"][\"train\"] for bs in batch_sizes}\nval_losses = {bs: data_branch[bs][\"losses\"][\"val\"] for bs in batch_sizes}\ntest_metrics = {bs: data_branch[bs][\"metrics\"][\"test\"] for bs in batch_sizes}\n\n# -------- print test metrics --------\nprint(\"Final test metrics (CWA | SWA | GCWA):\")\nfor bs in batch_sizes:\n    m = test_metrics[bs]\n    print(f'  BS={bs:>3}: {m[\"CWA\"]:.3f} | {m[\"SWA\"]:.3f} | {m[\"GCWA\"]:.3f}')\n\n\n# -------- plotting helpers --------\ndef save_fig(fig, name):\n    path = os.path.join(working_dir, name)\n    fig.savefig(path, dpi=150, bbox_inches=\"tight\")\n    plt.close(fig)\n    print(f\"Saved {path}\")\n\n\n# -------- Figure 1: training loss --------\ntry:\n    fig1 = plt.figure()\n    for bs in batch_sizes:\n        plt.plot(\n            range(1, len(train_losses[bs]) + 1), train_losses[bs], label=f\"BS={bs}\"\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Training Loss\")\n    plt.title(\"SPR_BENCH \u2013 Training Loss vs Epoch\")\n    plt.legend()\n    save_fig(fig1, \"SPR_BENCH_training_loss.png\")\nexcept Exception as e:\n    print(f\"Error creating training-loss plot: {e}\")\n    plt.close()\n\n# -------- Figure 2: validation loss --------\ntry:\n    fig2 = plt.figure()\n    for bs in batch_sizes:\n        plt.plot(range(1, len(val_losses[bs]) + 1), val_losses[bs], label=f\"BS={bs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Validation Loss\")\n    plt.title(\"SPR_BENCH \u2013 Validation Loss vs Epoch\")\n    plt.legend()\n    save_fig(fig2, \"SPR_BENCH_validation_loss.png\")\nexcept Exception as e:\n    print(f\"Error creating validation-loss plot: {e}\")\n    plt.close()\n\n# -------- Figure 3: test metrics bar chart --------\ntry:\n    metrics_names = [\"CWA\", \"SWA\", \"GCWA\"]\n    x = np.arange(len(batch_sizes))\n    width = 0.25\n    fig3, ax = plt.subplots()\n    for i, mname in enumerate(metrics_names):\n        vals = [test_metrics[bs][mname] for bs in batch_sizes]\n        ax.bar(x + i * width - width, vals, width, label=mname)\n    ax.set_xticks(x)\n    ax.set_xticklabels([str(bs) for bs in batch_sizes])\n    ax.set_xlabel(\"Batch Size\")\n    ax.set_ylabel(\"Score\")\n    ax.set_title(\"SPR_BENCH \u2013 Test Metrics by Batch Size\")\n    ax.legend()\n    save_fig(fig3, \"SPR_BENCH_test_metrics.png\")\nexcept Exception as e:\n    print(f\"Error creating test-metrics plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# helper to safely fetch\ndef safe_get(d, *keys, default=None):\n    for k in keys:\n        d = d.get(k, {})\n    return d if d else default\n\n\ndataset = \"SPR_BENCH\"\nembed_dict = safe_get(experiment_data, \"embedding_dim\", dataset, default={})\ndims = (\n    sorted(embed_dict.keys(), key=lambda s: int(s.split(\"_\")[-1])) if embed_dict else []\n)\n\n# ---- Figure 1: train/val loss curves ---- #\ntry:\n    plt.figure()\n    for dim in dims:\n        tr_losses = embed_dict[dim][\"losses\"][\"train\"]\n        val_losses = embed_dict[dim][\"losses\"][\"val\"]\n        epochs = range(1, len(tr_losses) + 1)\n        plt.plot(epochs, tr_losses, label=f\"{dim}-train\")\n        plt.plot(epochs, val_losses, linestyle=\"--\", label=f\"{dim}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(f\"Loss Curves - {dataset}\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{dataset}_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ---- Figure 2: per-epoch validation GCWA ---- #\ntry:\n    plt.figure()\n    for dim in dims:\n        val_metrics = embed_dict[dim][\"metrics\"][\"val\"]\n        gcwa = [m[\"GCWA\"] for m in val_metrics]\n        epochs = range(1, len(gcwa) + 1)\n        plt.plot(epochs, gcwa, label=dim)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"GCWA\")\n    plt.title(f\"Validation GCWA over Epochs - {dataset}\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{dataset}_val_GCWA.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating GCWA plot: {e}\")\n    plt.close()\n\n# ---- Figure 3: final test metrics vs embedding dim ---- #\ntry:\n    metrics_names = [\"CWA\", \"SWA\", \"GCWA\"]\n    x = np.arange(len(dims))\n    width = 0.25\n    plt.figure()\n    for i, m in enumerate(metrics_names):\n        vals = [embed_dict[dim][\"metrics\"][\"test\"][m] for dim in dims]\n        plt.bar(x + i * width, vals, width=width, label=m)\n    plt.xticks(x + width, [dim for dim in dims])\n    plt.ylabel(\"Score\")\n    plt.title(f\"Test Metrics vs Embedding Dim - {dataset}\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{dataset}_test_metrics_bar.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metrics bar plot: {e}\")\n    plt.close()\n"], "plot_plan": ["We load the persisted experiment_data.npy, safely access its contents, and create three core visualizations: (1) a line plot comparing training and validation losses over epochs, (2) a multi-line plot of validation CWA, SWA and GCWA to track metric trends, and (3) a bar chart summarising the final test CWA/SWA/GCWA.  Each plot is wrapped in its own try-except block, is given an informative title/sub-title indicating the dataset and plot type, and is saved into working_dir with descriptive filenames.  We respect the 5-figure cap by making only these three plots, and all matplotlib figures are explicitly closed.  After plotting we also print the final test metrics to stdout so the user can quickly see quantitative results alongside the visuals.  The code follows the mandated import order and directory handling, uses only data found in experiment_data.npy, and therefore remains robust whether run inside or outside the original training script\u2019s environment.  Finally, figures are named clearly (e.g. \u201cSPR_BENCH_loss_curve.png\u201d) to aid later inspection.", "We will load the saved experiment_data.npy file, detect the four hyper-parameter runs (epochs_5/10/20/30) and extract training losses, validation losses and the final test metrics. For visualization we create at most five figures: one line plot per run showing train vs. validation loss across epochs (four figures) and a fifth bar-chart comparing the three weighted accuracies (CWA, SWA, GCWA) on the test set across the runs. Each plot lives inside an independent try-except block; figures are saved to working_dir with descriptive names that include the dataset (\u201csynthetic_spr\u201d) and plot type. We ensure working_dir exists, always close figures, and give every plot a clear title mentioning the dataset, the run and (when relevant) the comparison being shown. After the plots we iterate again over the runs and print their stored test metrics so users can inspect numbers alongside the images. No made-up data is introduced; everything comes directly from experiment_data. The code is concise and self-contained, beginning with the required imports.", "The script first loads the persisted experiment_data.npy file, retrieves the section corresponding to the learning-rate sweep on the SPR_BENCH dataset, and extracts learning-rates, final train/validation losses, validation metrics, test metrics, predictions, and ground-truth labels. It then computes the best learning-rate according to the highest validation GCWA score and prints a small report summarising all validation and test metrics as well as the chosen best LR. Four figures are produced (each wrapped in its own try-except block): (1) a grouped bar plot comparing final train vs. validation loss per learning-rate, (2) a multi-line plot of the three validation metrics (CWA, SWA, GCWA) across learning-rates, (3) an analogous plot for test metrics, and (4) a confusion-matrix heat-map for the best learning-rate. All figures follow the naming, titling and saving conventions, are stored under working_dir, and every figure is closed after saving to prevent memory leaks.", "We will first load experiment_data.npy, focusing on the \u201cbatch_size \u2192 SPR_BENCH\u201d branch. For every batch-size run we collect the per-epoch training and validation losses plus the final test metrics (CWA, SWA, GCWA). We then:  \n1. Print a concise table of the three test metrics for each batch size.  \n2. Build at most three figures: (a) training loss curves vs. epoch for all batch sizes, (b) validation loss curves vs. epoch, and (c) a grouped bar-chart of the three test metrics across batch sizes.  \nEach figure is constructed inside its own try-except block, given a clear title (e.g. \u201cSPR_BENCH \u2013 Training Loss vs Epoch\u201d) and saved to working_dir with descriptive names. We ensure plt.close() in both success and failure cases and never fabricate data\u2014everything comes straight from experiment_data.npy. Finally, the script prints the path of every saved figure so users can quickly locate them.", "We will load the saved experiment_data.npy, extract the per-epoch training/validation losses and validation metrics for all tested embedding dimensions, and also collect the final test CWA/SWA/GCWA scores.  \nFigure 1 overlays the training and validation loss curves for every embedding_dim so we can compare convergence.  \nFigure 2 shows the per-epoch validation GCWA for each embedding_dim, giving insight into how weighted accuracy evolves.  \nFigure 3 is a bar chart of the final test CWA, SWA and GCWA versus embedding_dim to reveal which dimensionality generalises best.  \nEach figure lives in a separate try-except block, is titled clearly (dataset, metric, curves/bar), saved to working_dir with descriptive names, and then the figure is closed.  \nOnly data present in experiment_data.npy are used; if loading fails or keys are missing we catch the exception and continue.  \nWe limit ourselves to these three plots (\u22645) to satisfy the interval guideline and keep the output concise.  \nThe script starts with the required imports, sets working_dir, and prints a short confirmation after each save."], "ablation_name": [null, null, null, null, null], "hyperparam_name": [null, "num_epochs", "learning_rate", "batch_size", "embedding_dim"], "is_seed_node": [false, false, false, false, false], "is_seed_agg_node": [false, false, false, false, false], "parse_metrics_plan": ["To analyze the saved metrics we (1) locate the working directory, (2) load the\nNumPy file into a Python dictionary, (3) iterate over every dataset present, and\n(4) print the final value for each stored metric with explicit, human-readable\nnames such as \u201ctraining loss,\u201d \u201cvalidation Color Weighted Accuracy,\u201d etc. Only\nscalar values are printed; no figures are generated.", "The script will load the saved experiment_data.npy file from the \u201cworking\u201d\ndirectory, iterate over every hyper-parameter run (e.g., epochs_5, epochs_10, \u2026)\nand, for each run, identify the epoch that achieved the lowest validation loss\n(\u201cbest_epoch\u201d). It then collects the training loss and validation loss from that\nepoch together with the final test loss and the three weighted-accuracy metrics\n(CWA, SWA, GCWA). For every run, it prints the run name (treated here as the\ndataset identifier) followed by clearly labelled metric/value pairs, adhering to\nthe naming guidelines. No plots are produced and the code executes immediately\nwhen the file is run.", "The code will locate the working directory, load experiment_data.npy, and\nextract the section corresponding to the SPR_BENCH dataset.   For every metric\nstored (training loss, validation loss, and the three weighted accuracies on\nboth validation and test sets), it will compute the \u201cbest\u201d value across all\nlearning-rate runs (minimum for losses, maximum for accuracies).   Finally, it\nprints the dataset name followed by clearly labeled metric/value pairs.", "The script loads the serialized results dictionary, navigates its nested\nstructure to reach each batch-size run under the single dataset (SPR_BENCH), and\nthen extracts the requested summary statistics. Specifically, it reports the\nfinal training loss, the best (minimum) validation loss, the best validation\nCWA/SWA/GCWA achieved over all epochs, and the final test CWA/SWA/GCWA. Each\nvalue is printed with an explicit, self-describing label so the output is\nunambiguous.", "We will load experiment_data.npy from the \u201cworking\u201d directory, traverse its\nnested dictionaries, and for every dataset (e.g., SPR_BENCH) iterate over the\ndifferent embedding-dimension configurations.   For each configuration we print:\nthe final training loss, final validation loss, best validation accuracies (max\nacross epochs) for CWA, SWA and GCWA, and the single test-set loss and\naccuracies stored after training.   Each metric is printed with an explicit,\ndescriptive name and always preceded by the dataset (and configuration) label.\nThe script contains only top-level code so it runs immediately when executed."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# -------- locate and load the saved experiment data -------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------- helper to print the final / best metric values -------- #\ndef print_dataset_metrics(name: str, data: dict):\n    print(name)  # dataset name first\n\n    # ---- losses ---- #\n    train_losses = data.get(\"losses\", {}).get(\"train\", [])\n    val_losses = data.get(\"losses\", {}).get(\"val\", [])\n    if train_losses:\n        print(f\"Final training loss: {train_losses[-1]:.4f}\")\n    if val_losses:\n        print(f\"Final validation loss: {val_losses[-1]:.4f}\")\n\n    # ---- validation metrics ---- #\n    val_metrics_list = data.get(\"metrics\", {}).get(\"val\", [])\n    if val_metrics_list:\n        val_metrics = val_metrics_list[-1]  # take final epoch\u2019s metrics\n        if \"CWA\" in val_metrics:\n            print(f\"Final validation Color Weighted Accuracy: {val_metrics['CWA']:.3f}\")\n        if \"SWA\" in val_metrics:\n            print(f\"Final validation Shape Weighted Accuracy: {val_metrics['SWA']:.3f}\")\n        if \"GCWA\" in val_metrics:\n            print(\n                f\"Final validation Glyph Complexity Weighted Accuracy: {val_metrics['GCWA']:.3f}\"\n            )\n\n    # ---- test metrics ---- #\n    test_metrics = data.get(\"metrics\", {}).get(\"test\", {})\n    if test_metrics:\n        if \"CWA\" in test_metrics:\n            print(f\"Test Color Weighted Accuracy: {test_metrics['CWA']:.3f}\")\n        if \"SWA\" in test_metrics:\n            print(f\"Test Shape Weighted Accuracy: {test_metrics['SWA']:.3f}\")\n        if \"GCWA\" in test_metrics:\n            print(\n                f\"Test Glyph Complexity Weighted Accuracy: {test_metrics['GCWA']:.3f}\"\n            )\n    print()  # blank line for readability\n\n\n# -------- iterate over all datasets and display results -------- #\nfor dataset_name, dataset_info in experiment_data.items():\n    print_dataset_metrics(dataset_name, dataset_info)\n", "import os\nimport numpy as np\n\n# -------------------------------------------------------------------------\n# Helper: resolve working directory and load the saved numpy dict\nworking_dir = os.path.join(os.getcwd(), \"working\")\nnpy_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(npy_path, allow_pickle=True).item()\n\n# -------------------------------------------------------------------------\n# Iterate over each hyper-parameter configuration and report best metrics\nfor run_name, run_dict in experiment_data[\"num_epochs\"].items():\n    best_epoch = run_dict[\"best_epoch\"]  # 1-based indexing\n    best_idx = best_epoch - 1  # convert to 0-based\n\n    # Retrieve losses\n    train_loss_best = run_dict[\"losses\"][\"train\"][best_idx]\n    val_loss_best = run_dict[\"losses\"][\"val\"][best_idx]\n    test_loss_final = run_dict[\"losses\"][\"test\"]\n\n    # Retrieve test metrics\n    test_metrics = run_dict[\"metrics\"][\"test\"]  # dict with CWA, SWA, GCWA\n\n    # ---------------------------------------------------------------------\n    # Printing\n    print(f\"\\nDataset: {run_name}\")\n    print(f\"Best epoch: {best_epoch}\")\n    print(f\"Training loss (best epoch): {train_loss_best:.4f}\")\n    print(f\"Validation loss (best epoch): {val_loss_best:.4f}\")\n    print(f\"Test loss (final model): {test_loss_final:.4f}\")\n    print(f\"Test CWA: {test_metrics['CWA']:.3f}\")\n    print(f\"Test SWA: {test_metrics['SWA']:.3f}\")\n    print(f\"Test GCWA: {test_metrics['GCWA']:.3f}\")\n", "import os\nimport numpy as np\n\n# ---------- load data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper to select best ----------\ndef best(values, higher_is_better=False):\n    return max(values) if higher_is_better else min(values)\n\n\n# ---------- extract & report ----------\nlr_block = experiment_data[\"learning_rate\"]\nfor dataset_name, data in lr_block.items():\n    print(dataset_name)  # dataset header\n\n    # losses\n    train_losses = data[\"losses\"][\"train\"]\n    val_losses = data[\"losses\"][\"val\"]\n    print(f\"  train loss: {best(train_losses, higher_is_better=False):.4f}\")\n    print(f\"  validation loss: {best(val_losses, higher_is_better=False):.4f}\")\n\n    # validation metrics\n    val_metrics_list = data[\"metrics\"][\"val\"]\n    val_cwa = best([m[\"CWA\"] for m in val_metrics_list], True)\n    val_swa = best([m[\"SWA\"] for m in val_metrics_list], True)\n    val_gcwa = best([m[\"GCWA\"] for m in val_metrics_list], True)\n    print(f\"  validation CWA: {val_cwa:.3f}\")\n    print(f\"  validation SWA: {val_swa:.3f}\")\n    print(f\"  validation GCWA: {val_gcwa:.3f}\")\n\n    # test metrics\n    test_metrics_list = data[\"metrics\"][\"test\"]\n    test_cwa = best([m[\"CWA\"] for m in test_metrics_list], True)\n    test_swa = best([m[\"SWA\"] for m in test_metrics_list], True)\n    test_gcwa = best([m[\"GCWA\"] for m in test_metrics_list], True)\n    print(f\"  test CWA: {test_cwa:.3f}\")\n    print(f\"  test SWA: {test_swa:.3f}\")\n    print(f\"  test GCWA: {test_gcwa:.3f}\")\n", "import os\nimport numpy as np\n\n# --------- locate and load the result file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# --------- iterate over datasets and batch-size runs ----------\nfor dataset_name, runs in experiment_data.get(\"batch_size\", {}).items():\n    print(f\"\\nDataset: {dataset_name}\")\n    for bs in sorted(runs):  # print each batch-size configuration\n        run_data = runs[bs]\n        train_losses = run_data[\"losses\"][\"train\"]\n        val_losses = run_data[\"losses\"][\"val\"]\n        val_metrics = run_data[\"metrics\"][\"val\"]\n        test_metrics = run_data[\"metrics\"][\"test\"]\n\n        # ---- compute summary statistics ----\n        final_train_loss = train_losses[-1] if train_losses else float(\"nan\")\n        best_val_loss = min(val_losses) if val_losses else float(\"nan\")\n        best_val_cwa = (\n            max(m[\"CWA\"] for m in val_metrics) if val_metrics else float(\"nan\")\n        )\n        best_val_swa = (\n            max(m[\"SWA\"] for m in val_metrics) if val_metrics else float(\"nan\")\n        )\n        best_val_gcwa = (\n            max(m[\"GCWA\"] for m in val_metrics) if val_metrics else float(\"nan\")\n        )\n        test_cwa = test_metrics.get(\"CWA\", float(\"nan\"))\n        test_swa = test_metrics.get(\"SWA\", float(\"nan\"))\n        test_gcwa = test_metrics.get(\"GCWA\", float(\"nan\"))\n\n        # ---- formatted printing ----\n        print(f\"  Batch size {bs}:\")\n        print(f\"    final training loss:   {final_train_loss:.4f}\")\n        print(f\"    best validation loss:  {best_val_loss:.4f}\")\n        print(f\"    best validation CWA:   {best_val_cwa:.3f}\")\n        print(f\"    best validation SWA:   {best_val_swa:.3f}\")\n        print(f\"    best validation GCWA:  {best_val_gcwa:.3f}\")\n        print(f\"    test CWA:              {test_cwa:.3f}\")\n        print(f\"    test SWA:              {test_swa:.3f}\")\n        print(f\"    test GCWA:             {test_gcwa:.3f}\")\n", "import os\nimport numpy as np\n\n# -------- load data -------- #\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------- helper to print metrics -------- #\ndef print_config_metrics(config_name: str, entry: dict, indent: str = \"  \"):\n    # Losses\n    train_losses = entry[\"losses\"].get(\"train\", [])\n    val_losses = entry[\"losses\"].get(\"val\", [])\n    test_loss = entry[\"losses\"][\"test\"]\n\n    if train_losses:\n        print(f\"{indent}training loss: {train_losses[-1]:.4f}\")\n    if val_losses:\n        print(f\"{indent}validation loss: {val_losses[-1]:.4f}\")\n    print(f\"{indent}test loss: {test_loss:.4f}\")\n\n    # Validation metrics \u2013 take best (max) value across epochs\n    val_metrics_list = entry[\"metrics\"].get(\"val\", [])\n    if val_metrics_list:\n        best_val = {\n            m: max(x[m] for x in val_metrics_list) for m in [\"CWA\", \"SWA\", \"GCWA\"]\n        }\n        print(f\"{indent}best validation color-weighted accuracy: {best_val['CWA']:.3f}\")\n        print(f\"{indent}best validation shape-weighted accuracy: {best_val['SWA']:.3f}\")\n        print(\n            f\"{indent}best validation glyph-complexity-weighted accuracy: {best_val['GCWA']:.3f}\"\n        )\n\n    # Test metrics \u2013 single dictionary\n    test_metrics = entry[\"metrics\"][\"test\"]\n    print(f\"{indent}test color-weighted accuracy: {test_metrics['CWA']:.3f}\")\n    print(f\"{indent}test shape-weighted accuracy: {test_metrics['SWA']:.3f}\")\n    print(\n        f\"{indent}test glyph-complexity-weighted accuracy: {test_metrics['GCWA']:.3f}\"\n    )\n\n\n# -------- iterate and display -------- #\nfor dataset_name, configs in experiment_data.get(\"embedding_dim\", {}).items():\n    print(dataset_name)  # dataset header\n    for config_name, entry in configs.items():\n        print(f\" configuration: {config_name}\")\n        print_config_metrics(config_name, entry, indent=\"  \")\n    print()  # blank line between datasets\n"], "parse_term_out": ["['SPR_BENCH', '\\n', 'Final training loss: 0.2083', '\\n', 'Final validation loss:\n0.2071', '\\n', 'Final validation Color Weighted Accuracy: 0.937', '\\n', 'Final\nvalidation Shape Weighted Accuracy: 0.933', '\\n', 'Final validation Glyph\nComplexity Weighted Accuracy: 0.931', '\\n', 'Test Color Weighted Accuracy:\n0.627', '\\n', 'Test Shape Weighted Accuracy: 0.682', '\\n', 'Test Glyph\nComplexity Weighted Accuracy: 0.626', '\\n', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['\\nDataset: epochs_5', '\\n', 'Best epoch: 5', '\\n', 'Training loss (best\nepoch): 0.2159', '\\n', 'Validation loss (best epoch): 0.2128', '\\n', 'Test loss\n(final model): 1.5782', '\\n', 'Test CWA: 0.627', '\\n', 'Test SWA: 0.682', '\\n',\n'Test GCWA: 0.627', '\\n', '\\nDataset: epochs_10', '\\n', 'Best epoch: 10', '\\n',\n'Training loss (best epoch): 0.1861', '\\n', 'Validation loss (best epoch):\n0.1881', '\\n', 'Test loss (final model): 1.9237', '\\n', 'Test CWA: 0.628', '\\n',\n'Test SWA: 0.684', '\\n', 'Test GCWA: 0.627', '\\n', '\\nDataset: epochs_20', '\\n',\n'Best epoch: 17', '\\n', 'Training loss (best epoch): 0.1852', '\\n', 'Validation\nloss (best epoch): 0.1868', '\\n', 'Test loss (final model): 2.4454', '\\n', 'Test\nCWA: 0.628', '\\n', 'Test SWA: 0.684', '\\n', 'Test GCWA: 0.627', '\\n',\n'\\nDataset: epochs_30', '\\n', 'Best epoch: 29', '\\n', 'Training loss (best\nepoch): 0.1791', '\\n', 'Validation loss (best epoch): 0.1799', '\\n', 'Test loss\n(final model): 3.2064', '\\n', 'Test CWA: 0.628', '\\n', 'Test SWA: 0.684', '\\n',\n'Test GCWA: 0.627', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['SPR_BENCH', '\\n', '  train loss: 0.1941', '\\n', '  validation loss: 0.1944',\n'\\n', '  validation CWA: 0.931', '\\n', '  validation SWA: 0.928', '\\n', '\nvalidation GCWA: 0.925', '\\n', '  test CWA: 0.629', '\\n', '  test SWA: 0.683',\n'\\n', '  test GCWA: 0.628', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Batch size 32:', '\\n', '    final training\nloss:   0.1879', '\\n', '    best validation loss:  0.1911', '\\n', '    best\nvalidation CWA:   0.938', '\\n', '    best validation SWA:   0.935', '\\n', '\nbest validation GCWA:  0.933', '\\n', '    test CWA:              0.627', '\\n', '\ntest SWA:              0.683', '\\n', '    test GCWA:             0.627', '\\n', '\nBatch size 64:', '\\n', '    final training loss:   0.2018', '\\n', '    best\nvalidation loss:  0.2009', '\\n', '    best validation CWA:   0.938', '\\n', '\nbest validation SWA:   0.934', '\\n', '    best validation GCWA:  0.932', '\\n', '\ntest CWA:              0.627', '\\n', '    test SWA:              0.683', '\\n', '\ntest GCWA:             0.627', '\\n', '  Batch size 128:', '\\n', '    final\ntraining loss:   0.2132', '\\n', '    best validation loss:  0.2099', '\\n', '\nbest validation CWA:   0.936', '\\n', '    best validation SWA:   0.932', '\\n', '\nbest validation GCWA:  0.930', '\\n', '    test CWA:              0.625', '\\n', '\ntest SWA:              0.681', '\\n', '    test GCWA:             0.625', '\\n', '\nBatch size 256:', '\\n', '    final training loss:   0.2456', '\\n', '    best\nvalidation loss:  0.2362', '\\n', '    best validation CWA:   0.926', '\\n', '\nbest validation SWA:   0.922', '\\n', '    best validation GCWA:  0.921', '\\n', '\ntest CWA:              0.621', '\\n', '    test SWA:              0.676', '\\n', '\ntest GCWA:             0.622', '\\n', 'Execution time: a moment seconds (time\nlimit is 30 minutes).']", "['SPR_BENCH', '\\n', ' configuration: dim_4', '\\n', '  training loss: 0.2699',\n'\\n', '  validation loss: 0.2456', '\\n', '  test loss: 1.1698', '\\n', '  best\nvalidation color-weighted accuracy: 0.925', '\\n', '  best validation shape-\nweighted accuracy: 0.923', '\\n', '  best validation glyph-complexity-weighted\naccuracy: 0.921', '\\n', '  test color-weighted accuracy: 0.624', '\\n', '  test\nshape-weighted accuracy: 0.678', '\\n', '  test glyph-complexity-weighted\naccuracy: 0.624', '\\n', ' configuration: dim_8', '\\n', '  training loss:\n0.2416', '\\n', '  validation loss: 0.2329', '\\n', '  test loss: 1.3615', '\\n', '\nbest validation color-weighted accuracy: 0.922', '\\n', '  best validation shape-\nweighted accuracy: 0.920', '\\n', '  best validation glyph-complexity-weighted\naccuracy: 0.918', '\\n', '  test color-weighted accuracy: 0.621', '\\n', '  test\nshape-weighted accuracy: 0.676', '\\n', '  test glyph-complexity-weighted\naccuracy: 0.622', '\\n', ' configuration: dim_16', '\\n', '  training loss:\n0.1974', '\\n', '  validation loss: 0.1970', '\\n', '  test loss: 1.9191', '\\n', '\nbest validation color-weighted accuracy: 0.939', '\\n', '  best validation shape-\nweighted accuracy: 0.935', '\\n', '  best validation glyph-complexity-weighted\naccuracy: 0.933', '\\n', '  test color-weighted accuracy: 0.628', '\\n', '  test\nshape-weighted accuracy: 0.684', '\\n', '  test glyph-complexity-weighted\naccuracy: 0.627', '\\n', ' configuration: dim_32', '\\n', '  training loss:\n0.2048', '\\n', '  validation loss: 0.2040', '\\n', '  test loss: 1.8179', '\\n', '\nbest validation color-weighted accuracy: 0.935', '\\n', '  best validation shape-\nweighted accuracy: 0.932', '\\n', '  best validation glyph-complexity-weighted\naccuracy: 0.929', '\\n', '  test color-weighted accuracy: 0.627', '\\n', '  test\nshape-weighted accuracy: 0.682', '\\n', '  test glyph-complexity-weighted\naccuracy: 0.626', '\\n', '\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']"], "parse_exc_type": [null, null, null, null, null], "parse_exc_info": [null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
