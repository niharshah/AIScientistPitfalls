
% This paper discusses clustering algorithms, including K-means and DBSCAN, and evaluates them using silhouette scores, Davies-Bouldin scores, and Calinski-Harabasz scores. It is relevant for establishing the foundational methodology for clustering and evaluation in the symbolic glyph clustering process described in the SPR_BENCH experiments. This citation will appear in the methodology section when discussing clustering algorithms and their evaluation metrics.
@conference{tadikamalla2024efficientds,
 author = {Sai Sanjana Tadikamalla and Y.Venkata Chandu and Gummadi Devendra Kumar and Kadiyala Sarath and Syed Shareefunnisa},
 booktitle = {International Workshop on Artificial Intelligence and Cognition},
 journal = {2024 IEEE 3rd World Conference on Applied Intelligence and Computing (AIC)},
 pages = {340-345},
 title = {Efficient Data Summarization Using Contemporary Clustering Techniques},
 year = {2024}
}

% Paper #0 provides a foundational exploration of neural networks' ability to perform abstract reasoning and introduces a dataset for measuring reasoning capabilities, which is highly relevant to SPR_BENCH and symbolic reasoning tasks. It will be cited in the related work section to highlight the challenges and benchmarks in abstract reasoning. Paper #1 discusses the integration of neural networks and symbolic reasoning in Neurosymbolic AI, offering theoretical insights and practical frameworks that align with the methodology of symbolic glyph clustering. It will be cited in the related work section to provide context for combining neural and symbolic approaches in reasoning tasks.
@article{santoro2018measuringar,
 author = {Adam Santoro and Felix Hill and D. Barrett and Ari S. Morcos and T. Lillicrap},
 booktitle = {International Conference on Machine Learning},
 journal = {ArXiv},
 title = {Measuring abstract reasoning in neural networks},
 volume = {abs/1807.04225},
 year = {2018}
}

@article{pulicharla2025neurosymbolicab,
 author = {Mohan Raja Pulicharla},
 booktitle = {World Journal of Advanced Research and Reviews},
 journal = {World Journal of Advanced Research and Reviews},
 title = {Neurosymbolic AI: Bridging neural networks and symbolic reasoning},
 year = {2025}
}

% Paper 0 discusses Gaussian prototypical networks, which extend prototypical networks by incorporating confidence regions and clustering in the embedding space. This is relevant for the clustering methodology applied in symbolic glyph reasoning. Paper 4 introduces infinite mixture prototypes, which adaptively represent complex data distributions through clustering. Both papers will be cited in the methodology section to strengthen the argument for using clustering-based approaches in few-shot learning for symbolic reasoning tasks.
@article{fort2017gaussianpn,
 author = {Stanislav Fort},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Gaussian Prototypical Networks for Few-Shot Learning on Omniglot},
 volume = {abs/1708.02735},
 year = {2017}
}

@article{allen2019infinitemp,
 author = {Kelsey R. Allen and Evan Shelhamer and Hanul Shin and J. Tenenbaum},
 booktitle = {International Conference on Machine Learning},
 pages = {232-241},
 title = {Infinite Mixture Prototypes for Few-Shot Learning},
 year = {2019}
}

% The paper 'Primender Sequence: A Novel Mathematical Construct for Testing Symbolic Inference and AI Reasoning' introduces a benchmark for evaluating symbolic reasoning capabilities of models. It employs metrics such as rule inference accuracy and symbolic explanation quality, making it highly relevant for discussing evaluation methodologies like CWA and SWA used in SPR_BENCH experiments. This citation will be included in the evaluation methodology section to provide context for specialized metrics in symbolic reasoning tasks.
@article{faiz2025primendersa,
 author = {Mohd Anwar Jamal Faiz},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Primender Sequence: A Novel Mathematical Construct for Testing Symbolic Inference and AI Reasoning},
 volume = {abs/2506.10585},
 year = {2025}
}

% The paper 'Logical Neural Networks' introduces a framework that integrates neural learning and symbolic reasoning while ensuring interpretability through disentangled representations. It is relevant for supporting the methodology of disentangling latent representations for shape and color in symbolic glyph clustering. This citation will be included in the methodology section to provide a theoretical basis for disentangled representation learning in symbolic reasoning tasks.
@article{riegel2020logicalnn,
 author = {Ryan Riegel and Alexander G. Gray and F. Luus and Naweed Khan and Ndivhuwo Makondo and I. Akhalwaya and Haifeng Qian and Ronald Fagin and F. Barahona and Udit Sharma and S. Ikbal and Hima P. Karanam and S. Neelam and Ankita Likhyani and S. Srivastava},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Logical Neural Networks},
 volume = {abs/2006.13155},
 year = {2020}
}

% The paper 'H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark' introduces a robust evaluation of human performance on the ARC benchmark, which is a widely used dataset for symbolic reasoning tasks. This work is relevant for discussing benchmarks like SPR_BENCH and their role in evaluating reasoning capabilities. It will be cited in the related work section to provide context for symbolic reasoning datasets and the challenges they present for AI systems.
@article{legris2024harcar,
 author = {Solim LeGris and Wai Keen Vong and B. Lake and T. Gureckis},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark},
 volume = {abs/2409.01374},
 year = {2024}
}

% The paper 'Efficient Image Retrieval in Fashion: Leveraging Clustering and Principal Component Analysis for Search Space Reduction' discusses the application of PCA for dimensionality reduction in clustering tasks to improve computational efficiency while maintaining clustering quality. This is highly relevant to the methodology of symbolic glyph clustering, where PCA is proposed as a mitigation strategy to address the scalability challenges of clustering large datasets. The citation will be included in the methodology section to support the use of PCA for reducing computational costs in clustering latent features for SPR_BENCH.
@article{guzel2024efficientir,
 author = {Başak Esin Köktürk Güzel},
 booktitle = {Erzincan Üniversitesi Fen Bilimleri Enstitüsü Dergisi},
 journal = {Erzincan Üniversitesi Fen Bilimleri Enstitüsü Dergisi},
 title = {Efficient Image Retrieval in Fashion: Leveraging Clustering and Principal Component Analysis for Search Space Reduction},
 year = {2024}
}

% The foundational paper introducing BERT, 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,' provides an explanation of BERT's pre-training and fine-tuning methodologies. It is relevant for supporting the use of BERT in extracting latent features for symbolic glyph clustering in the methodology section.
@article{devlin2019bertpo,
 author = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
 booktitle = {North American Chapter of the Association for Computational Linguistics},
 pages = {4171-4186},
 title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
 year = {2019}
}

% The paper 'Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent' provides theoretical insights and empirical evidence for how transformers acquire reasoning abilities in symbolic tasks. It is highly relevant to support the methodology involving attention-style mean pooling in symbolic glyph clustering and reasoning tasks for SPR_BENCH. This citation will be included in the methodology section to substantiate the use of transformers in symbolic reasoning applications.
@inproceedings{yang2025multiheadtp,
 author = {Tong Yang and Yu Huang and Yingbin Liang and Yuejie Chi},
 title = {Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent},
 year = {2025}
}
