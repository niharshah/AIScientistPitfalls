<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 3], [0, 7], [0, 6], [0, 4], [0, 5], [0, 2], [0, 1], [0, 8]], "layout": [[0.5, 0.0], [0.0, 1.0], [0.14285714285714285, 1.0], [0.2857142857142857, 1.0], [0.42857142857142855, 1.0], [0.5714285714285714, 1.0], [0.7142857142857143, 1.0], [0.8571428571428571, 1.0], [1.0, 1.0]], "plan": ["We replace the crude ASCII-based clustering with a disentangled representation\nthat embeds shape and colour separately and lets a light Transformer encoder\nlearn their compositional interaction.  Each glyph is split into (shape-id,\ncolour-id); the two embeddings are summed with a positional embedding and fed\nthrough a 2-layer Transformer encoder.  The averaged sequence representation is\nclassified with a linear layer.  This gives the model direct access to the\nlatent factors we ultimately care about (variety in colour and shape) and should\nimprove generalisation without any brittle pre-clustering heuristics.  We train\nfor a handful of epochs, track CWA/SWA/CVA on the dev set, retain the best model\nby CVA, and finally report test metrics.  All metrics and losses are stored in\nexperiment_data.npy for later analysis.  The code runs on a single GPU (or CPU\nfallback) within the 30-minute budget.", "Ablation name: No-Position Embeddings. This script replicates the baseline\npipeline but instantiates a Transformer that omits absolute position embeddings\n(x = shape_emb + color_emb). It trains, validates, tests, logs metrics/losses,\nand finally saves everything to experiment_data.npy under the ablation key\n\"no_pos_emb\".", "Ablation name: No-Transformer (Mean-Pooling Baseline). We load SPR_BENCH (or\ngenerate a synthetic fallback), build vocabularies, and prepare PyTorch\ndatasets/dataloaders exactly as the baseline.   The MeanPoolingBaseline model\nembeds shape, color and position tokens, skips the Transformer, masks paddings,\naverages the resulting token vectors, and feeds the mean into a linear\nclassifier.   We train for 12 epochs, track losses and CWA/SWA/CVA, keep the\nbest\u2010validation snapshot, evaluate on the test set, and store every plottable\ndatum in the required `experiment_data.npy` file under the ablation key\n`no_transformer_mean_pool`.", "Ablation name: No-Color-Embedding (Shape-Only Input). The solution simply sets\nthe color\u2013embedding lookup table to a constant-zero tensor and freezes its\ngradients while leaving every other architectural detail untouched. The\ntransformer therefore only \u201csees\u201d shape and positional information. We keep\ntraining / evaluation loops, metrics and data-saving logic identical to the\nbaseline so we can directly compare results. All plottable data are stored in\nexperiment_data.npy under the ablation-specific key \u201cno_color_embedding\u201d.", "Ablation name: Frozen-Embeddings (Non-Trainable Shape & Color Embeddings). The\nsolution keeps the original data-loading, model, training and evaluation logic,\nbut instantiates the ablation variant \u201cFrozen-Embeddings.\u201d  Shape and colour\nembedding matrices are created exactly as in the baseline, but immediately have\n`requires_grad` switched off so that no optimiser updates ever touch them.  All\ndownstream parameters (positional embeddings, Transformer encoder, classifier)\nremain trainable; the optimiser is therefore built from the subset of parameters\nthat still require gradients.  Metrics, losses and predictions are logged in the\nprescribed `experiment_data` structure and saved to `experiment_data.npy` at the\nend of the run.", "Ablation name: No-Shape-Embedding (Color-Only Input). This ablation keeps the\nentire pipeline unchanged except that all shape information is suppressed.  The\nmodel receives real color-ids, position-ids, but a constant PAD id (all zeros)\nfor shapes; internally, the Transformer therefore only \u201csees\u2019\u2019 color (plus\nposition).  We realise this by adding a flag disable_shape to the network: when\nset, the shape embedding table is zeroed and frozen, and the forward pass\nignores the incoming shape ids.  The rest of the training / evaluation logic,\nmetrics collection and saving remain identical to the baseline so results are\ndirectly comparable.", "Ablation name: Single-Head Self-Attention (MonoHead). We run the exact same\ntraining / evaluation pipeline as the baseline but build every\nTransformerEncoderLayer with nhead = 1, thereby collapsing the usual 8 parallel\nattention heads into a single shared head (MonoHead). The dimensionality of each\ntoken representation (d_model = 64) is left unchanged, ensuring that the only\ncapacity reduction comes from removing head diversity. All metrics, losses,\npredictions and ground-truth labels are logged in the same experiment_data\nformat and saved to \u201cexperiment_data.npy\u201d.", "Ablation name: Concat-Fusion Embeddings (No Early Additive Fusion). We replace\nthe early additive fusion with a concatenation of shape, color, and positional\nembeddings followed by a learned linear projection back to d_model.  Everything\nelse (data-handling, training, metrics, saving) is kept identical to the\nbaseline so that performance differences isolate the effect of the fusion\nstrategy.", "Ablation name: Fixed-Sinusoidal Position Encoding. The learnable positional\nembedding is replaced by a non-trainable, classic sinusoidal table.   A small\nhelper builds the 256\u00d7d_model matrix, which is stored as a `register_buffer` so\nit participates in `.to(device)` but not in optimization.   The rest of the data\nloading, training, evaluation and saving logic is unchanged; the new experiment\nis logged under the key `fixed_sinusoidal_pos_encoding`.   Below is the full,\nready-to-run script."], "code": ["import os, time, pathlib, random, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# --------------------------------------------------------------------------- misc / dirs\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nexperiment_data = {}\n\n\n# --------------------------------------------------------------------------- helpers + metrics\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef count_color_variety(seq):\n    return len(set(t[1] for t in seq.split() if len(t) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(t[0] for t in seq.split() if t))\n\n\ndef color_weighted_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y, yhat):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef composite_variety_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\n# --------------------------------------------------------------------------- fallback tiny synthetic data\ndef synth_dataset(n_train=5000, n_dev=1000, n_test=1000, n_cls=4):\n    def rand_tok():\n        return random.choice(\"ABCD\") + random.choice(\"0123\")\n\n    def rand_seq():\n        return \" \".join(rand_tok() for _ in range(random.randint(4, 12)))\n\n    def lab(s):\n        return (count_color_variety(s) + count_shape_variety(s)) % n_cls\n\n    def make(n):\n        seqs = [rand_seq() for _ in range(n)]\n        lbl = [lab(s) for s in seqs]\n        return {\"sequence\": seqs, \"label\": lbl}\n\n    d = DatasetDict()\n    for split, n in [(\"train\", n_train), (\"dev\", n_dev), (\"test\", n_test)]:\n        d[split] = load_dataset(\"json\", split=[], data=make(n))\n    return d\n\n\n# --------------------------------------------------------------------------- load data\ntry:\n    DATA_ROOT = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    spr = load_spr_bench(DATA_ROOT)\n    print(\"Loaded SPR_BENCH\")\nexcept Exception as e:\n    print(\"Falling back to synthetic data\")\n    spr = synth_dataset()\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"#classes={num_classes}\")\n\n# --------------------------------------------------------------------------- vocab mapping\nshapes = sorted(set(tok[0] for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()))\ncolors = sorted(\n    set(\n        tok[1]\n        for seq in spr[\"train\"][\"sequence\"]\n        for tok in seq.split()\n        if len(tok) > 1\n    )\n)\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 = PAD\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}  # 0 = PAD\n\n\ndef encode(seq):\n    s_ids, c_ids = [], []\n    for tok in seq.split():\n        s_ids.append(shape2id.get(tok[0], 0))\n        c_ids.append(color2id.get(tok[1], 0) if len(tok) > 1 else 0)\n    return s_ids, c_ids\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, sequences, labels, max_len=None):\n        enc = [encode(s) for s in sequences]\n        self.max_len = max_len or max(len(e[0]) for e in enc)\n        self.shapes = [e[0][: self.max_len] for e in enc]\n        self.colors = [e[1][: self.max_len] for e in enc]\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        s = torch.tensor(self.shapes[idx], dtype=torch.long)\n        c = torch.tensor(self.colors[idx], dtype=torch.long)\n        y = torch.tensor(self.labels[idx], dtype=torch.long)\n        return {\"shape\": s, \"color\": c, \"y\": y}\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n    pad = lambda x, l: torch.cat([x, torch.zeros(l - len(x), dtype=torch.long)])\n    shape = torch.stack([pad(b[\"shape\"], maxlen) for b in batch])\n    color = torch.stack([pad(b[\"color\"], maxlen) for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    return {\"shape\": shape, \"color\": color, \"y\": y}\n\n\ntrain_ds = SPRDataset(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"])\ndev_ds = SPRDataset(\n    spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"], max_len=train_ds.max_len\n)\ntest_ds = SPRDataset(\n    spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"], max_len=train_ds.max_len\n)\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False, collate_fn=collate)\n\n\n# --------------------------------------------------------------------------- model\nclass ShapeColorTransformer(nn.Module):\n    def __init__(self, n_shape, n_color, d_model=64, nhead=8, nlayers=2, num_cls=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(256, d_model)  # max len 256\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n        self.cls = nn.Linear(d_model, num_cls)\n\n    def forward(self, shape_ids, color_ids):\n        B, L = shape_ids.shape\n        pos = torch.arange(L, device=shape_ids.device).unsqueeze(0).expand(B, L)\n        x = self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        mask = shape_ids == 0  # padding mask\n        h = self.encoder(x, src_key_padding_mask=mask)\n        h = h.masked_fill(mask.unsqueeze(-1), 0)\n        h = h.sum(1) / (~mask).sum(1, keepdim=True).clamp(min=1)  # mean over non-pad\n        return self.cls(h)\n\n\nmodel = ShapeColorTransformer(\n    len(shape2id) + 1,\n    len(color2id) + 1,\n    d_model=64,\n    nhead=8,\n    nlayers=2,\n    num_cls=num_classes,\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n\ntag = \"shape_color_transformer\"\nexperiment_data[tag] = {\n    \"SPR\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\n# --------------------------------------------------------------------------- training / evaluation\ndef evaluate(loader, split):\n    model.eval()\n    tot_loss = 0\n    seqs = []\n    ys = []\n    yh = []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"shape\"], batch[\"color\"])\n            loss = criterion(logits, batch[\"y\"])\n            tot_loss += loss.item() * batch[\"y\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            ys.extend(batch[\"y\"].cpu().tolist())\n            yh.extend(preds)\n            if split == \"train\":\n                start = len(seqs)\n                seqs.extend(spr[\"train\"][\"sequence\"][start : start + len(preds)])\n            elif split == \"dev\":\n                start = len(seqs)\n                seqs.extend(spr[\"dev\"][\"sequence\"][start : start + len(preds)])\n            else:\n                start = len(seqs)\n                seqs.extend(spr[\"test\"][\"sequence\"][start : start + len(preds)])\n    loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, ys, yh)\n    swa = shape_weighted_accuracy(seqs, ys, yh)\n    cva = composite_variety_accuracy(seqs, ys, yh)\n    return loss, cwa, swa, cva, yh, ys\n\n\nbest_cva = -1\nbest_state = None\nepochs = 12\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"shape\"], batch[\"color\"])\n        loss = criterion(logits, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch[\"y\"].size(0)\n    tr_loss = running / len(train_loader.dataset)\n    experiment_data[tag][\"SPR\"][\"losses\"][\"train\"].append(tr_loss)\n\n    val_loss, cwa, swa, cva, _, _ = evaluate(dev_loader, \"dev\")\n    experiment_data[tag][\"SPR\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[tag][\"SPR\"][\"metrics\"][\"val\"].append(\n        {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\n    )\n    experiment_data[tag][\"SPR\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: validation_loss = {val_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\"\n    )\n    if cva > best_cva:\n        best_cva = cva\n        best_state = model.state_dict()\n\n# --------------------------------------------------------------------------- test\nif best_state:\n    model.load_state_dict(best_state)\ntest_loss, cwa, swa, cva, preds, gt = evaluate(test_loader, \"test\")\nprint(f\"\\nTEST: loss={test_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\")\nexp = experiment_data[tag][\"SPR\"]\nexp[\"metrics\"][\"test\"] = {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\nexp[\"predictions\"] = preds\nexp[\"ground_truth\"] = gt\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, time, pathlib, random, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# --------------------------------------------------------------------------- dirs / device / exp-data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nexperiment_data = {\n    \"no_pos_emb\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n\n# --------------------------------------------------------------------------- helpers + metrics\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef count_color_variety(seq):\n    return len(set(t[1] for t in seq.split() if len(t) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(t[0] for t in seq.split() if t))\n\n\ndef color_weighted_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y, yhat):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef composite_variety_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\n# --------------------------------------------------------------------------- synthetic fallback\ndef synth_dataset(n_train=5000, n_dev=1000, n_test=1000, n_cls=4):\n    def rand_tok():\n        return random.choice(\"ABCD\") + random.choice(\"0123\")\n\n    def rand_seq():\n        return \" \".join(rand_tok() for _ in range(random.randint(4, 12)))\n\n    def lab(s):\n        return (count_color_variety(s) + count_shape_variety(s)) % n_cls\n\n    def make(n):\n        seqs = [rand_seq() for _ in range(n)]\n        return {\"sequence\": seqs, \"label\": [lab(s) for s in seqs]}\n\n    d = DatasetDict()\n    for split, n in [(\"train\", n_train), (\"dev\", n_dev), (\"test\", n_test)]:\n        d[split] = load_dataset(\"json\", split=[], data=make(n))\n    return d\n\n\n# --------------------------------------------------------------------------- load data\ntry:\n    DATA_ROOT = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    spr = load_spr_bench(DATA_ROOT)\n    print(\"Loaded SPR_BENCH\")\nexcept Exception:\n    print(\"Falling back to synthetic data\")\n    spr = synth_dataset()\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(\"#classes=\", num_classes)\n\n# --------------------------------------------------------------------------- vocab\nshapes = sorted(set(tok[0] for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()))\ncolors = sorted(\n    set(\n        tok[1]\n        for seq in spr[\"train\"][\"sequence\"]\n        for tok in seq.split()\n        if len(tok) > 1\n    )\n)\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 PAD\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}  # 0 PAD\n\n\ndef encode(seq):\n    s_ids, c_ids = [], []\n    for tok in seq.split():\n        s_ids.append(shape2id.get(tok[0], 0))\n        c_ids.append(color2id.get(tok[1], 0) if len(tok) > 1 else 0)\n    return s_ids, c_ids\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, seqs, lbls, max_len=None):\n        enc = [encode(s) for s in seqs]\n        self.max_len = max_len or max(len(e[0]) for e in enc)\n        self.shapes = [e[0][: self.max_len] for e in enc]\n        self.colors = [e[1][: self.max_len] for e in enc]\n        self.labels = lbls\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"shape\": torch.tensor(self.shapes[idx]),\n            \"color\": torch.tensor(self.colors[idx]),\n            \"y\": torch.tensor(self.labels[idx]),\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n    pad = lambda x, l: torch.cat([x, torch.zeros(l - len(x), dtype=torch.long)])\n    shape = torch.stack([pad(b[\"shape\"], maxlen) for b in batch])\n    color = torch.stack([pad(b[\"color\"], maxlen) for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    return {\"shape\": shape, \"color\": color, \"y\": y}\n\n\ntrain_ds = SPRDataset(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"])\ndev_ds = SPRDataset(\n    spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"], max_len=train_ds.max_len\n)\ntest_ds = SPRDataset(\n    spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"], max_len=train_ds.max_len\n)\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False, collate_fn=collate)\n\n\n# --------------------------------------------------------------------------- model (NO POSITION EMBEDDINGS)\nclass NoPosShapeColorTransformer(nn.Module):\n    def __init__(self, n_shape, n_color, d_model=64, nhead=8, nlayers=2, num_cls=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True)\n        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls = nn.Linear(d_model, num_cls)\n\n    def forward(self, s_ids, c_ids):\n        x = self.shape_emb(s_ids) + self.color_emb(c_ids)  # NO positional info\n        mask = s_ids == 0\n        h = self.encoder(x, src_key_padding_mask=mask)\n        h = h.masked_fill(mask.unsqueeze(-1), 0)\n        h = h.sum(1) / (~mask).sum(1, keepdim=True).clamp(min=1)\n        return self.cls(h)\n\n\nmodel = NoPosShapeColorTransformer(\n    len(shape2id) + 1,\n    len(color2id) + 1,\n    d_model=64,\n    nhead=8,\n    nlayers=2,\n    num_cls=num_classes,\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\ntag = \"no_pos_emb\"\nds_key = \"SPR\"\n\n\n# --------------------------------------------------------------------------- evaluate\ndef evaluate(loader, split):\n    model.eval()\n    tot_loss, seqs, ys, yh = 0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"shape\"], batch[\"color\"])\n            loss = criterion(logits, batch[\"y\"])\n            tot_loss += loss.item() * batch[\"y\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            ys.extend(batch[\"y\"].cpu().tolist())\n            yh.extend(preds)\n            src_list = (\n                spr[split][\"sequence\"] if split in [\"train\", \"dev\", \"test\"] else []\n            )\n            seqs.extend(src_list[len(seqs) : len(seqs) + len(preds)])\n    loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, ys, yh)\n    swa = shape_weighted_accuracy(seqs, ys, yh)\n    cva = composite_variety_accuracy(seqs, ys, yh)\n    return loss, cwa, swa, cva, yh, ys\n\n\n# --------------------------------------------------------------------------- train loop\nbest_cva, best_state = -1, None\nepochs = 12\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"shape\"], batch[\"color\"])\n        loss = criterion(logits, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch[\"y\"].size(0)\n    tr_loss = running / len(train_loader.dataset)\n    experiment_data[tag][ds_key][\"losses\"][\"train\"].append(tr_loss)\n    val_loss, cwa, swa, cva, _, _ = evaluate(dev_loader, \"dev\")\n    experiment_data[tag][ds_key][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[tag][ds_key][\"metrics\"][\"val\"].append(\n        {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\n    )\n    experiment_data[tag][ds_key][\"timestamps\"].append(time.time())\n    print(\n        f\"Ep{epoch}: val_loss={val_loss:.4f} CWA={cwa:.4f} SWA={swa:.4f} CVA={cva:.4f}\"\n    )\n    if cva > best_cva:\n        best_cva, cva\n        best_state = model.state_dict()\n\n# --------------------------------------------------------------------------- test\nif best_state:\n    model.load_state_dict(best_state)\ntest_loss, cwa, swa, cva, preds, gt = evaluate(test_loader, \"test\")\nprint(f\"TEST: loss={test_loss:.4f} CWA={cwa:.4f} SWA={swa:.4f} CVA={cva:.4f}\")\nexp = experiment_data[tag][ds_key]\nexp[\"metrics\"][\"test\"] = {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\nexp[\"predictions\"] = preds\nexp[\"ground_truth\"] = gt\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, time, pathlib, random, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ----------------------------- dirs / device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n# ----------------------------- experiment dict\nexperiment_data = {\n    \"no_transformer_mean_pool\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n\n# ----------------------------- helper metrics\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef count_color_variety(seq):\n    return len(set(t[1] for t in seq.split() if len(t) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(t[0] for t in seq.split() if t))\n\n\ndef color_weighted_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y, yhat):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef composite_variety_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\n# ----------------------------- synthetic fallback\ndef synth_dataset(n_train=5000, n_dev=1000, n_test=1000, n_cls=4):\n    def rand_tok():\n        return random.choice(\"ABCD\") + random.choice(\"0123\")\n\n    def rand_seq():\n        return \" \".join(rand_tok() for _ in range(random.randint(4, 12)))\n\n    def lab(s):\n        return (count_color_variety(s) + count_shape_variety(s)) % n_cls\n\n    def make(n):\n        seqs = [rand_seq() for _ in range(n)]\n        return {\"sequence\": seqs, \"label\": [lab(s) for s in seqs]}\n\n    d = DatasetDict()\n    for split, n in [(\"train\", n_train), (\"dev\", n_dev), (\"test\", n_test)]:\n        d[split] = load_dataset(\"json\", split=[], data=make(n))\n    return d\n\n\n# ----------------------------- data load\ntry:\n    DATA_ROOT = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    spr = load_spr_bench(DATA_ROOT)\n    print(\"Loaded SPR_BENCH\")\nexcept Exception as e:\n    print(\"Falling back to synthetic data\", e)\n    spr = synth_dataset()\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(\"#classes:\", num_classes)\n\n# ----------------------------- vocab\nshapes = sorted({tok[0] for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()})\ncolors = sorted(\n    {tok[1] for seq in spr[\"train\"][\"sequence\"] for tok in seq.split() if len(tok) > 1}\n)\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 = PAD\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}  # 0 = PAD\n\n\ndef encode(seq):\n    s_ids, c_ids = [], []\n    for tok in seq.split():\n        s_ids.append(shape2id.get(tok[0], 0))\n        c_ids.append(color2id.get(tok[1], 0) if len(tok) > 1 else 0)\n    return s_ids, c_ids\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, sequences, labels, max_len=None):\n        enc = [encode(s) for s in sequences]\n        self.max_len = max_len or max(len(e[0]) for e in enc)\n        self.shapes = [e[0][: self.max_len] for e in enc]\n        self.colors = [e[1][: self.max_len] for e in enc]\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"shape\": torch.tensor(self.shapes[idx], dtype=torch.long),\n            \"color\": torch.tensor(self.colors[idx], dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(x):\n        return torch.cat([x, torch.zeros(maxlen - len(x), dtype=torch.long)])\n\n    shape = torch.stack([pad(b[\"shape\"]) for b in batch])\n    color = torch.stack([pad(b[\"color\"]) for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    return {\"shape\": shape, \"color\": color, \"y\": y}\n\n\ntrain_ds = SPRDataset(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"])\ndev_ds = SPRDataset(spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"], train_ds.max_len)\ntest_ds = SPRDataset(spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"], train_ds.max_len)\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False, collate_fn=collate)\n\n\n# ----------------------------- Mean-Pooling model\nclass MeanPoolingBaseline(nn.Module):\n    def __init__(self, n_shape, n_color, d_model=64, num_cls=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(256, d_model)  # still learned but not contextual\n        self.cls = nn.Linear(d_model, num_cls)\n\n    def forward(self, s_ids, c_ids):\n        B, L = s_ids.shape\n        pos = torch.arange(L, device=s_ids.device).unsqueeze(0).expand(B, L)\n        x = self.shape_emb(s_ids) + self.color_emb(c_ids) + self.pos_emb(pos)\n        mask = s_ids == 0\n        x = x.masked_fill(mask.unsqueeze(-1), 0)\n        h = x.sum(1) / (~mask).sum(1, keepdim=True).clamp(min=1)  # mean over non-pad\n        return self.cls(h)\n\n\nmodel = MeanPoolingBaseline(\n    len(shape2id) + 1, len(color2id) + 1, d_model=64, num_cls=num_classes\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n\ntag = \"no_transformer_mean_pool\"\nepochs = 12\nbest_cva, best_state = -1, None\n\n\n# ----------------------------- evaluation\ndef evaluate(loader, split):\n    model.eval()\n    tot_loss, seqs, ys, yh = 0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"shape\"], batch[\"color\"])\n            loss = criterion(logits, batch[\"y\"])\n            tot_loss += loss.item() * batch[\"y\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            ys.extend(batch[\"y\"].cpu().tolist())\n            yh.extend(preds)\n            start = len(seqs)\n            if split == \"train\":\n                seqs.extend(spr[\"train\"][\"sequence\"][start : start + len(preds)])\n            elif split == \"dev\":\n                seqs.extend(spr[\"dev\"][\"sequence\"][start : start + len(preds)])\n            else:\n                seqs.extend(spr[\"test\"][\"sequence\"][start : start + len(preds)])\n    loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, ys, yh)\n    swa = shape_weighted_accuracy(seqs, ys, yh)\n    cva = composite_variety_accuracy(seqs, ys, yh)\n    return loss, cwa, swa, cva, yh, ys\n\n\n# ----------------------------- training loop\nfor ep in range(1, epochs + 1):\n    model.train()\n    run_loss = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"shape\"], batch[\"color\"])\n        loss = criterion(logits, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        run_loss += loss.item() * batch[\"y\"].size(0)\n    tr_loss = run_loss / len(train_loader.dataset)\n    experiment_data[tag][\"SPR\"][\"losses\"][\"train\"].append(tr_loss)\n\n    val_loss, cwa, swa, cva, _, _ = evaluate(dev_loader, \"dev\")\n    experiment_data[tag][\"SPR\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[tag][\"SPR\"][\"metrics\"][\"val\"].append(\n        {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\n    )\n    experiment_data[tag][\"SPR\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {ep}: val_loss={val_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\"\n    )\n    if cva > best_cva:\n        best_cva, best_state = cva, {k: v.cpu() for k, v in model.state_dict().items()}\n\n# ----------------------------- test\nif best_state:\n    model.load_state_dict(best_state)\ntest_loss, cwa, swa, cva, preds, gts = evaluate(test_loader, \"test\")\nprint(f\"\\nTEST: loss={test_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\")\nexp = experiment_data[tag][\"SPR\"]\nexp[\"metrics\"][\"test\"] = {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\nexp[\"predictions\"] = preds\nexp[\"ground_truth\"] = gts\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# No-Color-Embedding (Shape-Only Input) ablation ---------------------------------\n# This script is self-contained: run with `python script.py`\nimport os, time, pathlib, random, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ------------------------------------------------------------------- misc / dirs\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# container for everything plottable ------------------------------------------------\nexperiment_data = {\n    \"no_color_embedding\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n\n# ------------------------------------------------------------------- helpers / metrics\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(name):\n        return load_dataset(\n            \"csv\", data_files=str(root / name), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef count_color_variety(seq):  # number of distinct colors in a seq\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef color_weighted_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y, yhat):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef composite_variety_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\n# ------------------------------------------------------------------- fallback synthetic data\ndef synth_dataset(n_train=5000, n_dev=1000, n_test=1000, n_cls=4):\n    def rand_tok():\n        return random.choice(\"ABCD\") + random.choice(\"0123\")\n\n    def rand_seq():\n        return \" \".join(rand_tok() for _ in range(random.randint(4, 12)))\n\n    def label_fn(s):\n        return (count_color_variety(s) + count_shape_variety(s)) % n_cls\n\n    def make(n):\n        seqs = [rand_seq() for _ in range(n)]\n        lbls = [label_fn(s) for s in seqs]\n        return {\"sequence\": seqs, \"label\": lbls}\n\n    ds = DatasetDict()\n    for split, n in [(\"train\", n_train), (\"dev\", n_dev), (\"test\", n_test)]:\n        ds[split] = load_dataset(\"json\", split=[], data=make(n))\n    return ds\n\n\n# ------------------------------------------------------------------- load data\ntry:\n    DATA_ROOT = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    spr = load_spr_bench(DATA_ROOT)\n    print(\"Loaded real SPR_BENCH dataset\")\nexcept Exception:\n    print(\"Falling back to synthetic data\")\n    spr = synth_dataset()\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(\"#classes:\", num_classes)\n\n# ------------------------------------------------------------------- vocab mapping\nshapes = sorted(set(tok[0] for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()))\ncolors = sorted(\n    set(\n        tok[1]\n        for seq in spr[\"train\"][\"sequence\"]\n        for tok in seq.split()\n        if len(tok) > 1\n    )\n)\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 = PAD\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}  # 0 = PAD\n\n\ndef encode(seq):\n    s_ids, c_ids = [], []\n    for tok in seq.split():\n        s_ids.append(shape2id.get(tok[0], 0))\n        c_ids.append(color2id.get(tok[1], 0) if len(tok) > 1 else 0)\n    return s_ids, c_ids\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, seqs, labels, max_len=None):\n        enc = [encode(s) for s in seqs]\n        self.max_len = max_len or max(len(e[0]) for e in enc)\n        self.shapes = [e[0][: self.max_len] for e in enc]\n        self.colors = [e[1][: self.max_len] for e in enc]\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"shape\": torch.tensor(self.shapes[idx], dtype=torch.long),\n            \"color\": torch.tensor(self.colors[idx], dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n\n    def pad(x, l):\n        return torch.cat([x, torch.zeros(l - len(x), dtype=torch.long)])\n\n    shapes = torch.stack([pad(b[\"shape\"], maxlen) for b in batch])\n    colors = torch.stack([pad(b[\"color\"], maxlen) for b in batch])\n    labels = torch.stack([b[\"y\"] for b in batch])\n    return {\"shape\": shapes, \"color\": colors, \"y\": labels}\n\n\ntrain_ds = SPRDataset(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"])\ndev_ds = SPRDataset(\n    spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"], max_len=train_ds.max_len\n)\ntest_ds = SPRDataset(\n    spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"], max_len=train_ds.max_len\n)\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False, collate_fn=collate)\n\n\n# ------------------------------------------------------------------- model with zeroed color embedding\nclass ShapeColorTransformer(nn.Module):\n    def __init__(\n        self,\n        n_shape,\n        n_color,\n        d_model=64,\n        nhead=8,\n        nlayers=2,\n        num_cls=2,\n        no_color=False,\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(256, d_model)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls = nn.Linear(d_model, num_cls)\n\n        if no_color:  # zero the table and freeze it\n            with torch.no_grad():\n                self.color_emb.weight.zero_()\n            for p in self.color_emb.parameters():\n                p.requires_grad = False\n\n    def forward(self, s_ids, c_ids):\n        B, L = s_ids.shape\n        pos = torch.arange(L, device=s_ids.device).unsqueeze(0).expand(B, L)\n        x = self.shape_emb(s_ids) + self.color_emb(c_ids) + self.pos_emb(pos)\n        mask = s_ids == 0\n        h = self.encoder(x, src_key_padding_mask=mask)\n        h = h.masked_fill(mask.unsqueeze(-1), 0)\n        h = h.sum(1) / (~mask).sum(1, keepdim=True).clamp(min=1)\n        return self.cls(h)\n\n\n# instantiate ablation model\nmodel = ShapeColorTransformer(\n    len(shape2id) + 1,\n    len(color2id) + 1,\n    d_model=64,\n    nhead=8,\n    nlayers=2,\n    num_cls=num_classes,\n    no_color=True,\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(\n    filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4\n)\n\ntag = \"no_color_embedding\"\n\n\n# ------------------------------------------------------------------- train / eval\ndef evaluate(loader, split):\n    model.eval()\n    seqs, ys, yh, tot_loss = [], [], [], 0\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"shape\"], batch[\"color\"])\n            loss = criterion(logits, batch[\"y\"])\n            tot_loss += loss.item() * batch[\"y\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            ys.extend(batch[\"y\"].cpu().tolist())\n            yh.extend(preds)\n            if split == \"train\":\n                start = len(seqs)\n                seqs.extend(spr[\"train\"][\"sequence\"][start : start + len(preds)])\n            elif split == \"dev\":\n                start = len(seqs)\n                seqs.extend(spr[\"dev\"][\"sequence\"][start : start + len(preds)])\n            else:\n                start = len(seqs)\n                seqs.extend(spr[\"test\"][\"sequence\"][start : start + len(preds)])\n    loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, ys, yh)\n    swa = shape_weighted_accuracy(seqs, ys, yh)\n    cva = composite_variety_accuracy(seqs, ys, yh)\n    return loss, cwa, swa, cva, yh, ys\n\n\nbest_cva, best_state = -1, None\nepochs = 12\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running = 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"shape\"], batch[\"color\"])\n        loss = criterion(logits, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch[\"y\"].size(0)\n\n    tr_loss = running / len(train_loader.dataset)\n    experiment_data[tag][\"SPR\"][\"losses\"][\"train\"].append(tr_loss)\n\n    val_loss, cwa, swa, cva, _, _ = evaluate(dev_loader, \"dev\")\n    experiment_data[tag][\"SPR\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[tag][\"SPR\"][\"metrics\"][\"val\"].append(\n        {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\n    )\n    experiment_data[tag][\"SPR\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: val_loss={val_loss:.4f} | CWA={cwa:.4f} \"\n        f\"| SWA={swa:.4f} | CVA={cva:.4f}\"\n    )\n    if cva > best_cva:\n        best_cva, best_state = cva, model.state_dict()\n\n# ------------------------------------------------------------------- final test\nif best_state is not None:\n    model.load_state_dict(best_state)\ntest_loss, cwa, swa, cva, preds, gt = evaluate(test_loader, \"test\")\nprint(f\"\\nTEST: loss={test_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\")\n\nexp = experiment_data[tag][\"SPR\"]\nexp[\"metrics\"][\"test\"] = {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\nexp[\"predictions\"] = preds\nexp[\"ground_truth\"] = gt\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, time, pathlib, random, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# --------------------------------------------------------------------------- experiment bookkeeping\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nexperiment_data = {\n    \"frozen_embeddings\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# --------------------------------------------------------------------------- helper / metric fns\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef count_color_variety(seq):\n    return len(set(t[1] for t in seq.split() if len(t) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(t[0] for t in seq.split() if t))\n\n\ndef color_weighted_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y, yhat):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef composite_variety_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\n# --------------------------------------------------------------------------- synthetic fallback\ndef synth_dataset(n_train=5000, n_dev=1000, n_test=1000, n_cls=4):\n    def rand_tok():\n        return random.choice(\"ABCD\") + random.choice(\"0123\")\n\n    def rand_seq():\n        return \" \".join(rand_tok() for _ in range(random.randint(4, 12)))\n\n    def lab(s):\n        return (count_color_variety(s) + count_shape_variety(s)) % n_cls\n\n    def make(n):\n        seqs = [rand_seq() for _ in range(n)]\n        lbl = [lab(s) for s in seqs]\n        return {\"sequence\": seqs, \"label\": lbl}\n\n    d = DatasetDict()\n    for split, n in [(\"train\", n_train), (\"dev\", n_dev), (\"test\", n_test)]:\n        d[split] = load_dataset(\"json\", split=[], data=make(n))\n    return d\n\n\n# --------------------------------------------------------------------------- data loading\ntry:\n    DATA_ROOT = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    spr = load_spr_bench(DATA_ROOT)\n    print(\"Loaded SPR_BENCH\")\nexcept Exception:\n    print(\"Falling back to synthetic data\")\n    spr = synth_dataset()\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(\"#classes =\", num_classes)\n\n# --------------------------------------------------------------------------- vocab creation\nshapes = sorted(set(tok[0] for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()))\ncolors = sorted(\n    set(\n        tok[1]\n        for seq in spr[\"train\"][\"sequence\"]\n        for tok in seq.split()\n        if len(tok) > 1\n    )\n)\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 = PAD\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}  # 0 = PAD\n\n\ndef encode(seq):\n    s_ids, c_ids = [], []\n    for tok in seq.split():\n        s_ids.append(shape2id.get(tok[0], 0))\n        c_ids.append(color2id.get(tok[1], 0) if len(tok) > 1 else 0)\n    return s_ids, c_ids\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, sequences, labels, max_len=None):\n        enc = [encode(s) for s in sequences]\n        self.max_len = max_len or max(len(e[0]) for e in enc)\n        self.shapes = [e[0][: self.max_len] for e in enc]\n        self.colors = [e[1][: self.max_len] for e in enc]\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"shape\": torch.tensor(self.shapes[idx], dtype=torch.long),\n            \"color\": torch.tensor(self.colors[idx], dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"seq\": spr_split_sequences[idx] if (spr_split_sequences := None) else None,\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n    pad = lambda x, l: torch.cat([x, torch.zeros(l - len(x), dtype=torch.long)])\n    shape = torch.stack([pad(b[\"shape\"], maxlen) for b in batch])\n    color = torch.stack([pad(b[\"color\"], maxlen) for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    return {\"shape\": shape, \"color\": color, \"y\": y}\n\n\ntrain_ds = SPRDataset(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"])\ndev_ds = SPRDataset(\n    spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"], max_len=train_ds.max_len\n)\ntest_ds = SPRDataset(\n    spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"], max_len=train_ds.max_len\n)\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False, collate_fn=collate)\n\n\n# --------------------------------------------------------------------------- model with frozen embeddings\nclass ShapeColorTransformer(nn.Module):\n    def __init__(\n        self,\n        n_shape,\n        n_color,\n        d_model=64,\n        nhead=8,\n        nlayers=2,\n        num_cls=2,\n        freeze_sc_emb=True,\n    ):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        if freeze_sc_emb:  # freeze the two token-level embedding tables\n            self.shape_emb.weight.requires_grad = False\n            self.color_emb.weight.requires_grad = False\n        self.pos_emb = nn.Embedding(256, d_model)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls = nn.Linear(d_model, num_cls)\n\n    def forward(self, shape_ids, color_ids):\n        B, L = shape_ids.shape\n        pos = torch.arange(L, device=shape_ids.device).unsqueeze(0).expand(B, L)\n        x = self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        mask = shape_ids == 0\n        h = self.encoder(x, src_key_padding_mask=mask)\n        h = h.masked_fill(mask.unsqueeze(-1), 0)\n        h = h.sum(1) / (~mask).sum(1, keepdim=True).clamp(min=1)\n        return self.cls(h)\n\n\nmodel = ShapeColorTransformer(\n    len(shape2id) + 1,\n    len(color2id) + 1,\n    d_model=64,\n    nhead=8,\n    nlayers=2,\n    num_cls=num_classes,\n    freeze_sc_emb=True,  # key ablation switch\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptim_params = filter(lambda p: p.requires_grad, model.parameters())\noptimizer = torch.optim.Adam(optim_params, lr=3e-4)\n\ntag = \"frozen_embeddings\"\n\n\n# --------------------------------------------------------------------------- evaluation helper\ndef evaluate(loader, split_name):\n    model.eval()\n    tot_loss, seqs, ys, yh = 0, [], [], []\n    with torch.no_grad():\n        for batch_idx, batch in enumerate(loader):\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"shape\"], batch[\"color\"])\n            loss = criterion(logits, batch[\"y\"])\n            tot_loss += loss.item() * batch[\"y\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            ys.extend(batch[\"y\"].cpu().tolist())\n            yh.extend(preds)\n            start = len(seqs)\n            if split_name == \"train\":\n                seqs.extend(spr[\"train\"][\"sequence\"][start : start + len(preds)])\n            elif split_name == \"dev\":\n                seqs.extend(spr[\"dev\"][\"sequence\"][start : start + len(preds)])\n            else:\n                seqs.extend(spr[\"test\"][\"sequence\"][start : start + len(preds)])\n    loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, ys, yh)\n    swa = shape_weighted_accuracy(seqs, ys, yh)\n    cva = composite_variety_accuracy(seqs, ys, yh)\n    return loss, cwa, swa, cva, yh, ys\n\n\n# --------------------------------------------------------------------------- training loop\nbest_cva, best_state = -1, None\nepochs = 12\nfor ep in range(1, epochs + 1):\n    model.train()\n    running = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"shape\"], batch[\"color\"])\n        loss = criterion(logits, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch[\"y\"].size(0)\n    tr_loss = running / len(train_loader.dataset)\n    experiment_data[tag][\"SPR\"][\"losses\"][\"train\"].append(tr_loss)\n\n    val_loss, cwa, swa, cva, _, _ = evaluate(dev_loader, \"dev\")\n    experiment_data[tag][\"SPR\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[tag][\"SPR\"][\"metrics\"][\"val\"].append(\n        {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\n    )\n    experiment_data[tag][\"SPR\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {ep}: val_loss={val_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\"\n    )\n    if cva > best_cva:\n        best_cva, best_state = cva, model.state_dict()\n\n# --------------------------------------------------------------------------- test evaluation\nif best_state:\n    model.load_state_dict(best_state)\ntest_loss, cwa, swa, cva, preds, gt = evaluate(test_loader, \"test\")\nprint(f\"\\nTEST: loss={test_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\")\nexp = experiment_data[tag][\"SPR\"]\nexp[\"metrics\"][\"test\"] = {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\nexp[\"predictions\"], exp[\"ground_truth\"] = preds, gt\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# No-Shape-Embedding (Color-Only) ablation \u2013 self-contained script\nimport os, time, pathlib, random, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ------------------------------ dirs / device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# ------------------------------ experiment dict skeleton\nexperiment_data = {\n    \"no_shape_embedding\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n\n# ------------------------------ helper metrics\ndef count_color_variety(seq):\n    return len(set(t[1] for t in seq.split() if len(t) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(t[0] for t in seq.split() if t))\n\n\ndef color_weighted_accuracy(seqs, y, yh):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yh)) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y, yh):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yh)) / max(sum(w), 1)\n\n\ndef composite_variety_accuracy(seqs, y, yh):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yh)) / max(sum(w), 1)\n\n\n# ------------------------------ data loading (SPR_BENCH or synthetic)\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(name):\n        return load_dataset(\n            \"csv\", data_files=str(root / name), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        {s: _load(pathlib.Path(f\"{s}.csv\")) for s in [\"train\", \"dev\", \"test\"]}\n    )\n\n\ndef synth_dataset(n_train=5000, n_dev=1000, n_test=1000, n_cls=4):\n    def rand_tok():\n        return random.choice(\"ABCD\") + random.choice(\"0123\")\n\n    def rand_seq():\n        return \" \".join(rand_tok() for _ in range(random.randint(4, 12)))\n\n    def lab(s):\n        return (count_color_variety(s) + count_shape_variety(s)) % n_cls\n\n    def make(n):\n        seqs = [rand_seq() for _ in range(n)]\n        lbl = [lab(s) for s in seqs]\n        return {\"sequence\": seqs, \"label\": lbl}\n\n    d = DatasetDict()\n    for split, n in [(\"train\", n_train), (\"dev\", n_dev), (\"test\", n_test)]:\n        d[split] = load_dataset(\"json\", split=[], data=make(n))\n    return d\n\n\ntry:\n    DATA_ROOT = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    spr = load_spr_bench(DATA_ROOT)\n    print(\"Loaded SPR_BENCH\")\nexcept Exception:\n    print(\"Falling back to synthetic data\")\n    spr = synth_dataset()\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(\"#classes =\", num_classes)\n\n# ------------------------------ vocab\nshapes = sorted(set(tok[0] for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()))\ncolors = sorted(\n    set(\n        tok[1]\n        for seq in spr[\"train\"][\"sequence\"]\n        for tok in seq.split()\n        if len(tok) > 1\n    )\n)\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 PAD\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}  # 0 PAD\n\n\ndef encode(seq):\n    s_ids, c_ids = [], []\n    for tok in seq.split():\n        s_ids.append(shape2id.get(tok[0], 0))\n        c_ids.append(color2id.get(tok[1], 0) if len(tok) > 1 else 0)\n    return s_ids, c_ids\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, seqs, labels, max_len=None):\n        enc = [encode(s) for s in seqs]\n        self.max_len = max_len or max(len(e[0]) for e in enc)\n        self.shapes = [e[0][: self.max_len] for e in enc]\n        self.colors = [e[1][: self.max_len] for e in enc]\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"shape\": torch.tensor(self.shapes[idx], dtype=torch.long),\n            \"color\": torch.tensor(self.colors[idx], dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n    pad = lambda x, l: torch.cat([x, torch.zeros(l - len(x), dtype=torch.long)])\n    shape = torch.stack([pad(b[\"shape\"], maxlen) for b in batch])\n    color = torch.stack([pad(b[\"color\"], maxlen) for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    return {\"shape\": shape, \"color\": color, \"y\": y}\n\n\ntrain_ds = SPRDataset(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"])\ndev_ds = SPRDataset(\n    spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"], max_len=train_ds.max_len\n)\ntest_ds = SPRDataset(\n    spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"], max_len=train_ds.max_len\n)\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False, collate_fn=collate)\n\n\n# ------------------------------ model with optional no-shape mode\nclass ShapeColorTransformer(nn.Module):\n    def __init__(\n        self,\n        n_shape,\n        n_color,\n        d_model=64,\n        nhead=8,\n        nlayers=2,\n        num_cls=2,\n        disable_shape=False,\n    ):\n        super().__init__()\n        self.disable_shape = disable_shape\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(256, d_model)\n        if disable_shape:  # zero and freeze shape embeddings\n            with torch.no_grad():\n                self.shape_emb.weight.data.zero_()\n            for p in self.shape_emb.parameters():\n                p.requires_grad = False\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls = nn.Linear(d_model, num_cls)\n\n    def forward(self, shape_ids, color_ids):\n        B, L = color_ids.shape\n        pos = torch.arange(L, device=color_ids.device).unsqueeze(0).expand(B, L)\n        shp = (\n            torch.zeros_like(self.color_emb(color_ids))\n            if self.disable_shape\n            else self.shape_emb(shape_ids)\n        )\n        x = shp + self.color_emb(color_ids) + self.pos_emb(pos)\n        mask = color_ids == 0  # padding mask relies on color ids\n        h = self.encoder(x, src_key_padding_mask=mask)\n        h = h.masked_fill(mask.unsqueeze(-1), 0)\n        h = h.sum(1) / (~mask).sum(1, keepdim=True).clamp(min=1)\n        return self.cls(h)\n\n\nmodel = ShapeColorTransformer(\n    len(shape2id) + 1,\n    len(color2id) + 1,\n    d_model=64,\n    nhead=8,\n    nlayers=2,\n    num_cls=num_classes,\n    disable_shape=True,\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(\n    filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4\n)\n\n\n# ------------------------------ training & evaluation\ndef evaluate(loader, split):\n    model.eval()\n    tot_loss, seqs, ys, yh = 0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"shape\"], batch[\"color\"])\n            loss = criterion(logits, batch[\"y\"])\n            tot_loss += loss.item() * batch[\"y\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            ys.extend(batch[\"y\"].cpu().tolist())\n            yh.extend(preds)\n            offset = len(seqs)\n            if split == \"train\":\n                seqs.extend(spr[\"train\"][\"sequence\"][offset : offset + len(preds)])\n            elif split == \"dev\":\n                seqs.extend(spr[\"dev\"][\"sequence\"][offset : offset + len(preds)])\n            else:\n                seqs.extend(spr[\"test\"][\"sequence\"][offset : offset + len(preds)])\n    loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, ys, yh)\n    swa = shape_weighted_accuracy(seqs, ys, yh)\n    cva = composite_variety_accuracy(seqs, ys, yh)\n    return loss, cwa, swa, cva, yh, ys\n\n\nbest_cva, best_state = -1, None\nepochs = 12\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        loss = criterion(model(batch[\"shape\"], batch[\"color\"]), batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch[\"y\"].size(0)\n    tr_loss = running / len(train_loader.dataset)\n    experiment_data[\"no_shape_embedding\"][\"SPR\"][\"losses\"][\"train\"].append(tr_loss)\n\n    val_loss, cwa, swa, cva, _, _ = evaluate(dev_loader, \"dev\")\n    experiment_data[\"no_shape_embedding\"][\"SPR\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"no_shape_embedding\"][\"SPR\"][\"metrics\"][\"val\"].append(\n        {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\n    )\n    experiment_data[\"no_shape_embedding\"][\"SPR\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: val_loss={val_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\"\n    )\n    if cva > best_cva:\n        best_cva, cva\n        best_state = model.state_dict()\n\n# ------------------------------ test set\nif best_state:\n    model.load_state_dict(best_state)\ntest_loss, cwa, swa, cva, preds, gt = evaluate(test_loader, \"test\")\nprint(f\"\\nTEST: loss={test_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\")\n\nexp = experiment_data[\"no_shape_embedding\"][\"SPR\"]\nexp[\"metrics\"][\"test\"] = {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\nexp[\"predictions\"] = preds\nexp[\"ground_truth\"] = gt\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data ->\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, time, pathlib, random, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# --------------------------------------------------------------------------- misc / dirs\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nexperiment_data = {\n    \"monohead\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n\n# --------------------------------------------------------------------------- helpers + metrics\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef count_color_variety(seq):\n    return len(set(t[1] for t in seq.split() if len(t) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(t[0] for t in seq.split() if t))\n\n\ndef color_weighted_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y, yhat):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef composite_variety_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\n# --------------------------------------------------------------------------- fallback tiny synthetic data\ndef synth_dataset(n_train=5000, n_dev=1000, n_test=1000, n_cls=4):\n    def rand_tok():\n        return random.choice(\"ABCD\") + random.choice(\"0123\")\n\n    def rand_seq():\n        return \" \".join(rand_tok() for _ in range(random.randint(4, 12)))\n\n    def lab(s):\n        return (count_color_variety(s) + count_shape_variety(s)) % n_cls\n\n    def make(n):\n        seqs = [rand_seq() for _ in range(n)]\n        lbl = [lab(s) for s in seqs]\n        return {\"sequence\": seqs, \"label\": lbl}\n\n    d = DatasetDict()\n    for split, n in [(\"train\", n_train), (\"dev\", n_dev), (\"test\", n_test)]:\n        d[split] = load_dataset(\"json\", split=[], data=make(n))\n    return d\n\n\n# --------------------------------------------------------------------------- load data\ntry:\n    DATA_ROOT = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    spr = load_spr_bench(DATA_ROOT)\n    print(\"Loaded SPR_BENCH\")\nexcept Exception:\n    print(\"Falling back to synthetic data\")\n    spr = synth_dataset()\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(\"#classes=\", num_classes)\n\n# --------------------------------------------------------------------------- vocab mapping\nshapes = sorted(set(tok[0] for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()))\ncolors = sorted(\n    set(\n        tok[1]\n        for seq in spr[\"train\"][\"sequence\"]\n        for tok in seq.split()\n        if len(tok) > 1\n    )\n)\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 pad\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}  # 0 pad\n\n\ndef encode(seq):\n    s_ids, c_ids = [], []\n    for tok in seq.split():\n        s_ids.append(shape2id.get(tok[0], 0))\n        c_ids.append(color2id.get(tok[1], 0) if len(tok) > 1 else 0)\n    return s_ids, c_ids\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, sequences, labels, max_len=None):\n        enc = [encode(s) for s in sequences]\n        self.max_len = max_len or max(len(e[0]) for e in enc)\n        self.shapes = [e[0][: self.max_len] for e in enc]\n        self.colors = [e[1][: self.max_len] for e in enc]\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"shape\": torch.tensor(self.shapes[idx], dtype=torch.long),\n            \"color\": torch.tensor(self.colors[idx], dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n    pad = lambda x, l: torch.cat([x, torch.zeros(l - len(x), dtype=torch.long)])\n    shape = torch.stack([pad(b[\"shape\"], maxlen) for b in batch])\n    color = torch.stack([pad(b[\"color\"], maxlen) for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    return {\"shape\": shape, \"color\": color, \"y\": y}\n\n\ntrain_ds = SPRDataset(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"])\ndev_ds = SPRDataset(\n    spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"], max_len=train_ds.max_len\n)\ntest_ds = SPRDataset(\n    spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"], max_len=train_ds.max_len\n)\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False, collate_fn=collate)\n\n\n# --------------------------------------------------------------------------- model (MonoHead)\nclass ShapeColorMonoHead(nn.Module):\n    def __init__(self, n_shape, n_color, d_model=64, nlayers=2, num_cls=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(256, d_model)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=1, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n        self.cls = nn.Linear(d_model, num_cls)\n\n    def forward(self, shape_ids, color_ids):\n        B, L = shape_ids.shape\n        pos = torch.arange(L, device=shape_ids.device).unsqueeze(0).expand(B, L)\n        x = self.shape_emb(shape_ids) + self.color_emb(color_ids) + self.pos_emb(pos)\n        mask = shape_ids == 0\n        h = self.encoder(x, src_key_padding_mask=mask)\n        h = h.masked_fill(mask.unsqueeze(-1), 0)\n        h = h.sum(1) / (~mask).sum(1, keepdim=True).clamp(min=1)\n        return self.cls(h)\n\n\nmodel = ShapeColorMonoHead(\n    len(shape2id) + 1, len(color2id) + 1, d_model=64, nlayers=2, num_cls=num_classes\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n\n\n# --------------------------------------------------------------------------- training / evaluation\ndef evaluate(loader, split):\n    model.eval()\n    tot_loss, seqs, ys, yh = 0, [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"shape\"], batch[\"color\"])\n            loss = criterion(logits, batch[\"y\"])\n            tot_loss += loss.item() * batch[\"y\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            ys.extend(batch[\"y\"].cpu().tolist())\n            yh.extend(preds)\n            start = len(seqs)\n            if split == \"train\":\n                seqs.extend(spr[\"train\"][\"sequence\"][start : start + len(preds)])\n            elif split == \"dev\":\n                seqs.extend(spr[\"dev\"][\"sequence\"][start : start + len(preds)])\n            else:\n                seqs.extend(spr[\"test\"][\"sequence\"][start : start + len(preds)])\n    loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, ys, yh)\n    swa = shape_weighted_accuracy(seqs, ys, yh)\n    cva = composite_variety_accuracy(seqs, ys, yh)\n    return loss, cwa, swa, cva, yh, ys\n\n\nbest_cva = -1\nbest_state = None\nepochs = 12\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"shape\"], batch[\"color\"])\n        loss = criterion(logits, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch[\"y\"].size(0)\n    tr_loss = running / len(train_loader.dataset)\n    experiment_data[\"monohead\"][\"SPR\"][\"losses\"][\"train\"].append(tr_loss)\n\n    val_loss, cwa, swa, cva, _, _ = evaluate(dev_loader, \"dev\")\n    experiment_data[\"monohead\"][\"SPR\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"monohead\"][\"SPR\"][\"metrics\"][\"val\"].append(\n        {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\n    )\n    experiment_data[\"monohead\"][\"SPR\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: val_loss={val_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\"\n    )\n    if cva > best_cva:\n        best_cva = cva\n        best_state = model.state_dict()\n\n# --------------------------------------------------------------------------- test\nif best_state:\n    model.load_state_dict(best_state)\ntest_loss, cwa, swa, cva, preds, gt = evaluate(test_loader, \"test\")\nprint(f\"\\nTEST: loss={test_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\")\nexp = experiment_data[\"monohead\"][\"SPR\"]\nexp[\"metrics\"][\"test\"] = {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\nexp[\"predictions\"] = preds\nexp[\"ground_truth\"] = gt\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, time, pathlib, random, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# --------------------------------------------------------------------------- misc / dirs\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nexperiment_data = {\n    \"concat_fusion\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n\n# --------------------------------------------------------------------------- helpers + metrics\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef count_color_variety(seq):\n    return len(set(t[1] for t in seq.split() if len(t) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(t[0] for t in seq.split() if t))\n\n\ndef color_weighted_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y, yhat):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef composite_variety_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\n# --------------------------------------------------------------------------- fallback tiny synthetic data\ndef synth_dataset(n_train=5000, n_dev=1000, n_test=1000, n_cls=4):\n    def rand_tok():\n        return random.choice(\"ABCD\") + random.choice(\"0123\")\n\n    def rand_seq():\n        return \" \".join(rand_tok() for _ in range(random.randint(4, 12)))\n\n    def lab(s):\n        return (count_color_variety(s) + count_shape_variety(s)) % n_cls\n\n    def make(n):\n        seqs = [rand_seq() for _ in range(n)]\n        lbl = [lab(s) for s in seqs]\n        return {\"sequence\": seqs, \"label\": lbl}\n\n    d = DatasetDict()\n    for split, n in [(\"train\", n_train), (\"dev\", n_dev), (\"test\", n_test)]:\n        d[split] = load_dataset(\"json\", split=[], data=make(n))\n    return d\n\n\n# --------------------------------------------------------------------------- load data\ntry:\n    DATA_ROOT = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    spr = load_spr_bench(DATA_ROOT)\n    print(\"Loaded SPR_BENCH\")\nexcept Exception:\n    print(\"Falling back to synthetic data\")\n    spr = synth_dataset()\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"#classes={num_classes}\")\n\n# --------------------------------------------------------------------------- vocab mapping\nshapes = sorted(set(tok[0] for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()))\ncolors = sorted(\n    set(\n        tok[1]\n        for seq in spr[\"train\"][\"sequence\"]\n        for tok in seq.split()\n        if len(tok) > 1\n    )\n)\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 = PAD\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}  # 0 = PAD\n\n\ndef encode(seq):\n    s_ids, c_ids = [], []\n    for tok in seq.split():\n        s_ids.append(shape2id.get(tok[0], 0))\n        c_ids.append(color2id.get(tok[1], 0) if len(tok) > 1 else 0)\n    return s_ids, c_ids\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, sequences, labels, max_len=None):\n        enc = [encode(s) for s in sequences]\n        self.max_len = max_len or max(len(e[0]) for e in enc)\n        self.shapes = [e[0][: self.max_len] for e in enc]\n        self.colors = [e[1][: self.max_len] for e in enc]\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        s = torch.tensor(self.shapes[idx], dtype=torch.long)\n        c = torch.tensor(self.colors[idx], dtype=torch.long)\n        y = torch.tensor(self.labels[idx], dtype=torch.long)\n        return {\"shape\": s, \"color\": c, \"y\": y}\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n    pad = lambda x, l: torch.cat([x, torch.zeros(l - len(x), dtype=torch.long)])\n    shape = torch.stack([pad(b[\"shape\"], maxlen) for b in batch])\n    color = torch.stack([pad(b[\"color\"], maxlen) for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    return {\"shape\": shape, \"color\": color, \"y\": y}\n\n\ntrain_ds = SPRDataset(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"])\ndev_ds = SPRDataset(\n    spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"], max_len=train_ds.max_len\n)\ntest_ds = SPRDataset(\n    spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"], max_len=train_ds.max_len\n)\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False, collate_fn=collate)\n\n\n# --------------------------------------------------------------------------- model (Concat-Fusion Ablation)\nclass ConcatFusionTransformer(nn.Module):\n    def __init__(self, n_shape, n_color, d_model=64, nhead=8, nlayers=2, num_cls=2):\n        super().__init__()\n        self.d_model = d_model\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n        self.pos_emb = nn.Embedding(256, d_model)  # max len 256\n        # Learned projection after concatenation\n        self.fuse_proj = nn.Linear(3 * d_model, d_model)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n        self.cls = nn.Linear(d_model, num_cls)\n\n    def forward(self, shape_ids, color_ids):\n        B, L = shape_ids.shape\n        pos_ids = torch.arange(L, device=shape_ids.device).unsqueeze(0).expand(B, L)\n        se = self.shape_emb(shape_ids)\n        ce = self.color_emb(color_ids)\n        pe = self.pos_emb(pos_ids)\n        x = torch.cat([se, ce, pe], dim=-1)  # (B,L,3*d)\n        x = self.fuse_proj(x)  # (B,L,d)\n        mask = shape_ids == 0  # padding mask\n        h = self.encoder(x, src_key_padding_mask=mask)\n        h = h.masked_fill(mask.unsqueeze(-1), 0)\n        h = h.sum(1) / (~mask).sum(1, keepdim=True).clamp(min=1)\n        return self.cls(h)\n\n\nmodel = ConcatFusionTransformer(\n    len(shape2id) + 1,\n    len(color2id) + 1,\n    d_model=64,\n    nhead=8,\n    nlayers=2,\n    num_cls=num_classes,\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n\ntag = \"concat_fusion\"\n\n\n# --------------------------------------------------------------------------- training / evaluation\ndef evaluate(loader, split):\n    model.eval()\n    tot_loss = 0\n    seqs, ys, yh = [], [], []\n    with torch.no_grad():\n        for batch_idx, batch in enumerate(loader):\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"shape\"], batch[\"color\"])\n            loss = criterion(logits, batch[\"y\"])\n            tot_loss += loss.item() * batch[\"y\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            ys.extend(batch[\"y\"].cpu().tolist())\n            yh.extend(preds)\n            # retrieve raw sequences for metrics\n            if split == \"train\":\n                dataset_seqs = spr[\"train\"][\"sequence\"]\n            elif split == \"dev\":\n                dataset_seqs = spr[\"dev\"][\"sequence\"]\n            else:\n                dataset_seqs = spr[\"test\"][\"sequence\"]\n            start = batch_idx * loader.batch_size\n            seqs.extend(dataset_seqs[start : start + len(preds)])\n    loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, ys, yh)\n    swa = shape_weighted_accuracy(seqs, ys, yh)\n    cva = composite_variety_accuracy(seqs, ys, yh)\n    return loss, cwa, swa, cva, yh, ys\n\n\nbest_cva = -1\nbest_state = None\nepochs = 12\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"shape\"], batch[\"color\"])\n        loss = criterion(logits, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch[\"y\"].size(0)\n    tr_loss = running / len(train_loader.dataset)\n    experiment_data[tag][\"SPR\"][\"losses\"][\"train\"].append(tr_loss)\n\n    val_loss, cwa, swa, cva, _, _ = evaluate(dev_loader, \"dev\")\n    experiment_data[tag][\"SPR\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[tag][\"SPR\"][\"metrics\"][\"val\"].append(\n        {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\n    )\n    experiment_data[tag][\"SPR\"][\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: val_loss={val_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\"\n    )\n    if cva > best_cva:\n        best_cva = cva\n        best_state = model.state_dict()\n\n# --------------------------------------------------------------------------- test\nif best_state:\n    model.load_state_dict(best_state)\ntest_loss, cwa, swa, cva, preds, gt = evaluate(test_loader, \"test\")\nprint(f\"\\nTEST: loss={test_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\")\nexp = experiment_data[tag][\"SPR\"]\nexp[\"metrics\"][\"test\"] = {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\nexp[\"predictions\"] = preds\nexp[\"ground_truth\"] = gt\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, time, pathlib, random, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# --------------------------------------------------------------------------- misc / dirs\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# container for everything that should be saved\nexperiment_data = {\n    \"fixed_sinusoidal_pos_encoding\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n\n# --------------------------------------------------------------------------- helpers + metrics\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef count_color_variety(seq):\n    return len(set(t[1] for t in seq.split() if len(t) > 1))\n\n\ndef count_shape_variety(seq):\n    return len(set(t[0] for t in seq.split() if t))\n\n\ndef color_weighted_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef shape_weighted_accuracy(seqs, y, yhat):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\ndef composite_variety_accuracy(seqs, y, yhat):\n    w = [count_color_variety(s) + count_shape_variety(s) for s in seqs]\n    return sum(wi if a == b else 0 for wi, a, b in zip(w, y, yhat)) / max(sum(w), 1)\n\n\n# --------------------------------------------------------------------------- fallback tiny synthetic data\ndef synth_dataset(n_train=5000, n_dev=1000, n_test=1000, n_cls=4):\n    def rand_tok():\n        return random.choice(\"ABCD\") + random.choice(\"0123\")\n\n    def rand_seq():\n        return \" \".join(rand_tok() for _ in range(random.randint(4, 12)))\n\n    def lab(s):\n        return (count_color_variety(s) + count_shape_variety(s)) % n_cls\n\n    def make(n):\n        seqs = [rand_seq() for _ in range(n)]\n        lbl = [lab(s) for s in seqs]\n        return {\"sequence\": seqs, \"label\": lbl}\n\n    d = DatasetDict()\n    for split, n in [(\"train\", n_train), (\"dev\", n_dev), (\"test\", n_test)]:\n        d[split] = load_dataset(\"json\", split=[], data=make(n))\n    return d\n\n\n# --------------------------------------------------------------------------- load data\ntry:\n    DATA_ROOT = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n    spr = load_spr_bench(DATA_ROOT)\n    print(\"Loaded SPR_BENCH\")\nexcept Exception:\n    print(\"Falling back to synthetic data\")\n    spr = synth_dataset()\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"#classes={num_classes}\")\n\n# --------------------------------------------------------------------------- vocab mapping\nshapes = sorted(set(tok[0] for seq in spr[\"train\"][\"sequence\"] for tok in seq.split()))\ncolors = sorted(\n    set(\n        tok[1]\n        for seq in spr[\"train\"][\"sequence\"]\n        for tok in seq.split()\n        if len(tok) > 1\n    )\n)\nshape2id = {s: i + 1 for i, s in enumerate(shapes)}  # 0 = PAD\ncolor2id = {c: i + 1 for i, c in enumerate(colors)}  # 0 = PAD\n\n\ndef encode(seq):\n    s_ids, c_ids = [], []\n    for tok in seq.split():\n        s_ids.append(shape2id.get(tok[0], 0))\n        c_ids.append(color2id.get(tok[1], 0) if len(tok) > 1 else 0)\n    return s_ids, c_ids\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, sequences, labels, max_len=None):\n        enc = [encode(s) for s in sequences]\n        self.max_len = max_len or max(len(e[0]) for e in enc)\n        self.shapes = [e[0][: self.max_len] for e in enc]\n        self.colors = [e[1][: self.max_len] for e in enc]\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        s = torch.tensor(self.shapes[idx], dtype=torch.long)\n        c = torch.tensor(self.colors[idx], dtype=torch.long)\n        y = torch.tensor(self.labels[idx], dtype=torch.long)\n        return {\"shape\": s, \"color\": c, \"y\": y}\n\n\ndef collate(batch):\n    maxlen = max(len(b[\"shape\"]) for b in batch)\n    pad = lambda x, l: torch.cat([x, torch.zeros(l - len(x), dtype=torch.long)])\n    shape = torch.stack([pad(b[\"shape\"], maxlen) for b in batch])\n    color = torch.stack([pad(b[\"color\"], maxlen) for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    return {\"shape\": shape, \"color\": color, \"y\": y}\n\n\ntrain_ds = SPRDataset(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"])\ndev_ds = SPRDataset(\n    spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"], max_len=train_ds.max_len\n)\ntest_ds = SPRDataset(\n    spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"], max_len=train_ds.max_len\n)\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True, collate_fn=collate)\ndev_loader = DataLoader(dev_ds, batch_size=512, shuffle=False, collate_fn=collate)\ntest_loader = DataLoader(test_ds, batch_size=512, shuffle=False, collate_fn=collate)\n\n\n# --------------------------------------------------------------------------- model with fixed sinusoidal PE\ndef get_sinusoid_encoding_table(max_len, d_model):\n    \"\"\"Create [max_len, d_model] positional encoding table.\"\"\"\n    pos = np.arange(max_len)[:, None]\n    i = np.arange(d_model)[None, :]\n    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n    angles = pos * angle_rates\n    table = np.zeros((max_len, d_model), dtype=np.float32)\n    table[:, 0::2] = np.sin(angles[:, 0::2])\n    table[:, 1::2] = np.cos(angles[:, 1::2])\n    return torch.from_numpy(table)\n\n\nclass ShapeColorTransformer(nn.Module):\n    def __init__(self, n_shape, n_color, d_model=64, nhead=8, nlayers=2, num_cls=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(n_shape, d_model, padding_idx=0)\n        self.color_emb = nn.Embedding(n_color, d_model, padding_idx=0)\n\n        # fixed sinusoidal positional encoding (not trainable)\n        pe = get_sinusoid_encoding_table(256, d_model)\n        self.register_buffer(\"pos_table\", pe)  # [256, d_model]\n\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, nlayers)\n        self.cls = nn.Linear(d_model, num_cls)\n\n    def forward(self, shape_ids, color_ids):\n        B, L = shape_ids.shape\n        pos_enc = self.pos_table[:L].unsqueeze(0).expand(B, L, -1)  # [B,L,d_model]\n        x = self.shape_emb(shape_ids) + self.color_emb(color_ids) + pos_enc\n        mask = shape_ids == 0  # padding mask\n        h = self.encoder(x, src_key_padding_mask=mask)\n        h = h.masked_fill(mask.unsqueeze(-1), 0)\n        h = h.sum(1) / (~mask).sum(1, keepdim=True).clamp(min=1)\n        return self.cls(h)\n\n\nmodel = ShapeColorTransformer(\n    len(shape2id) + 1,\n    len(color2id) + 1,\n    d_model=64,\n    nhead=8,\n    nlayers=2,\n    num_cls=num_classes,\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(\n    (p for p in model.parameters() if p.requires_grad), lr=3e-4\n)\n\ntag = \"fixed_sinusoidal_pos_encoding\"\n# shorthand handle\nexp = experiment_data[tag][\"SPR\"]\n\n\n# --------------------------------------------------------------------------- training / evaluation\ndef evaluate(loader, split):\n    model.eval()\n    tot_loss = 0\n    seqs, ys, yh = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"shape\"], batch[\"color\"])\n            loss = criterion(logits, batch[\"y\"])\n            tot_loss += loss.item() * batch[\"y\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            ys.extend(batch[\"y\"].cpu().tolist())\n            yh.extend(preds)\n            start = len(seqs)\n            if split == \"train\":\n                seqs.extend(spr[\"train\"][\"sequence\"][start : start + len(preds)])\n            elif split == \"dev\":\n                seqs.extend(spr[\"dev\"][\"sequence\"][start : start + len(preds)])\n            else:\n                seqs.extend(spr[\"test\"][\"sequence\"][start : start + len(preds)])\n    loss = tot_loss / len(loader.dataset)\n    cwa = color_weighted_accuracy(seqs, ys, yh)\n    swa = shape_weighted_accuracy(seqs, ys, yh)\n    cva = composite_variety_accuracy(seqs, ys, yh)\n    return loss, cwa, swa, cva, yh, ys\n\n\nbest_cva, best_state = -1, None\nepochs = 12\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running = 0\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"shape\"], batch[\"color\"])\n        loss = criterion(logits, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        running += loss.item() * batch[\"y\"].size(0)\n    tr_loss = running / len(train_loader.dataset)\n    exp[\"losses\"][\"train\"].append(tr_loss)\n\n    val_loss, cwa, swa, cva, _, _ = evaluate(dev_loader, \"dev\")\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"val\"].append({\"cwa\": cwa, \"swa\": swa, \"cva\": cva})\n    exp[\"timestamps\"].append(time.time())\n    print(\n        f\"Epoch {epoch}: val_loss={val_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\"\n    )\n    if cva > best_cva:\n        best_cva, best_state = cva, model.state_dict()\n\n# --------------------------------------------------------------------------- test\nif best_state:\n    model.load_state_dict(best_state)\ntest_loss, cwa, swa, cva, preds, gt = evaluate(test_loader, \"test\")\nprint(f\"\\nTEST: loss={test_loss:.4f} | CWA={cwa:.4f} | SWA={swa:.4f} | CVA={cva:.4f}\")\n\nexp[\"metrics\"][\"test\"] = {\"cwa\": cwa, \"swa\": swa, \"cva\": cva}\nexp[\"predictions\"] = preds\nexp[\"ground_truth\"] = gt\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n"], "term_out": ["['Using device: cuda', '\\n', 'Loaded SPR_BENCH', '\\n', '#classes=2', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: validation_loss = 0.1463\n| CWA=0.9539 | SWA=0.9559 | CVA=0.9549', '\\n', 'Epoch 2: validation_loss =\n0.0819 | CWA=0.9750 | SWA=0.9764 | CVA=0.9757', '\\n', 'Epoch 3: validation_loss\n= 0.0617 | CWA=0.9840 | SWA=0.9841 | CVA=0.9841', '\\n', 'Epoch 4:\nvalidation_loss = 0.0251 | CWA=0.9938 | SWA=0.9935 | CVA=0.9937', '\\n', 'Epoch\n5: validation_loss = 0.0293 | CWA=0.9927 | SWA=0.9924 | CVA=0.9926', '\\n',\n'Epoch 6: validation_loss = 0.0163 | CWA=0.9966 | SWA=0.9958 | CVA=0.9962',\n'\\n', 'Epoch 7: validation_loss = 0.0182 | CWA=0.9968 | SWA=0.9963 |\nCVA=0.9965', '\\n', 'Epoch 8: validation_loss = 0.0104 | CWA=0.9967 | SWA=0.9960\n| CVA=0.9964', '\\n', 'Epoch 9: validation_loss = 0.0148 | CWA=0.9966 |\nSWA=0.9958 | CVA=0.9962', '\\n', 'Epoch 10: validation_loss = 0.0130 | CWA=0.9966\n| SWA=0.9960 | CVA=0.9963', '\\n', 'Epoch 11: validation_loss = 0.0200 |\nCWA=0.9960 | SWA=0.9953 | CVA=0.9957', '\\n', 'Epoch 12: validation_loss = 0.0084\n| CWA=0.9969 | SWA=0.9966 | CVA=0.9968', '\\n', '\\nTEST: loss=2.5919 | CWA=0.6353\n| SWA=0.6991 | CVA=0.6680', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_02-26-\n44_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n17/working/experiment_data.npy', '\\n', 'Execution time: 17 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 20000 examples [00:00,\n353718.37 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 256815.09\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 264736.77\nexamples/s]', '\\n', 'Loaded SPR_BENCH', '\\n', '#classes=', ' ', '2', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Ep1: val_loss=0.3309 CWA=0.8780\nSWA=0.8789 CVA=0.8784', '\\n', 'Ep2: val_loss=0.2020 CWA=0.9468 SWA=0.9438\nCVA=0.9453', '\\n', 'Ep3: val_loss=0.1938 CWA=0.9477 SWA=0.9447 CVA=0.9461',\n'\\n', 'Ep4: val_loss=0.1792 CWA=0.9477 SWA=0.9447 CVA=0.9461', '\\n', 'Ep5:\nval_loss=0.1704 CWA=0.9477 SWA=0.9447 CVA=0.9461', '\\n', 'Ep6: val_loss=0.1738\nCWA=0.9477 SWA=0.9447 CVA=0.9461', '\\n', 'Ep7: val_loss=0.1685 CWA=0.9477\nSWA=0.9447 CVA=0.9461', '\\n', 'Ep8: val_loss=0.1719 CWA=0.9477 SWA=0.9447\nCVA=0.9461', '\\n', 'Ep9: val_loss=0.1684 CWA=0.9477 SWA=0.9447 CVA=0.9461',\n'\\n', 'Ep10: val_loss=0.1672 CWA=0.9477 SWA=0.9447 CVA=0.9461', '\\n', 'Ep11:\nval_loss=0.1692 CWA=0.9477 SWA=0.9447 CVA=0.9461', '\\n', 'Ep12: val_loss=0.1699\nCWA=0.9477 SWA=0.9447 CVA=0.9461', '\\n', 'TEST: loss=1.5382 CWA=0.6290\nSWA=0.6858 CVA=0.6581', '\\n', 'Saved experiment_data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_02-26-\n44_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n20/working/experiment_data.npy', '\\n', 'Execution time: 23 seconds seconds (time\nlimit is 30 minutes).']", "['Device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 310397.18\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 391939.75\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 385633.48\nexamples/s]', '\\n', 'Loaded SPR_BENCH', '\\n', '#classes:', ' ', '2', '\\n',\n'Epoch 1: val_loss=0.6054 | CWA=0.7090 | SWA=0.7140 | CVA=0.7116', '\\n', 'Epoch\n2: val_loss=0.5735 | CWA=0.7026 | SWA=0.7014 | CVA=0.7020', '\\n', 'Epoch 3:\nval_loss=0.5626 | CWA=0.7074 | SWA=0.7052 | CVA=0.7063', '\\n', 'Epoch 4:\nval_loss=0.5589 | CWA=0.7097 | SWA=0.7065 | CVA=0.7081', '\\n', 'Epoch 5:\nval_loss=0.5579 | CWA=0.7094 | SWA=0.7064 | CVA=0.7079', '\\n', 'Epoch 6:\nval_loss=0.5575 | CWA=0.7096 | SWA=0.7066 | CVA=0.7081', '\\n', 'Epoch 7:\nval_loss=0.5575 | CWA=0.7120 | SWA=0.7088 | CVA=0.7104', '\\n', 'Epoch 8:\nval_loss=0.5575 | CWA=0.7096 | SWA=0.7066 | CVA=0.7081', '\\n', 'Epoch 9:\nval_loss=0.5575 | CWA=0.7117 | SWA=0.7083 | CVA=0.7100', '\\n', 'Epoch 10:\nval_loss=0.5575 | CWA=0.7098 | SWA=0.7069 | CVA=0.7083', '\\n', 'Epoch 11:\nval_loss=0.5574 | CWA=0.7122 | SWA=0.7086 | CVA=0.7104', '\\n', 'Epoch 12:\nval_loss=0.5575 | CWA=0.7112 | SWA=0.7079 | CVA=0.7095', '\\n', '\\nTEST:\nloss=0.6527 | CWA=0.5970 | SWA=0.6296 | CVA=0.6137', '\\n', 'Saved experiment\ndata to', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_02-26-\n44_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n21/working/experiment_data.npy', '\\n', 'Execution time: 12 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 20000 examples [00:00,\n349341.93 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 541521.94\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 486284.84\nexamples/s]', '\\n', 'Loaded real SPR_BENCH dataset', '\\n', '#classes:', ' ',\n'2', '\\n', '/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: val_loss=0.2117 |\nCWA=0.9355 | SWA=0.9333 | CVA=0.9344', '\\n', 'Epoch 2: val_loss=0.1507 |\nCWA=0.9585 | SWA=0.9543 | CVA=0.9563', '\\n', 'Epoch 3: val_loss=0.1502 |\nCWA=0.9605 | SWA=0.9572 | CVA=0.9588', '\\n', 'Epoch 4: val_loss=0.1220 |\nCWA=0.9680 | SWA=0.9659 | CVA=0.9669', '\\n', 'Epoch 5: val_loss=0.1165 |\nCWA=0.9686 | SWA=0.9663 | CVA=0.9674', '\\n', 'Epoch 6: val_loss=0.1122 |\nCWA=0.9730 | SWA=0.9713 | CVA=0.9721', '\\n', 'Epoch 7: val_loss=0.1104 |\nCWA=0.9736 | SWA=0.9720 | CVA=0.9728', '\\n', 'Epoch 8: val_loss=0.1105 |\nCWA=0.9713 | SWA=0.9695 | CVA=0.9704', '\\n', 'Epoch 9: val_loss=0.1057 |\nCWA=0.9739 | SWA=0.9722 | CVA=0.9730', '\\n', 'Epoch 10: val_loss=0.1059 |\nCWA=0.9741 | SWA=0.9727 | CVA=0.9734', '\\n', 'Epoch 11: val_loss=0.1079 |\nCWA=0.9737 | SWA=0.9722 | CVA=0.9729', '\\n', 'Epoch 12: val_loss=0.1042 |\nCWA=0.9744 | SWA=0.9729 | CVA=0.9736', '\\n', '\\nTEST: loss=1.8109 | CWA=0.6299 |\nSWA=0.6905 | CVA=0.6609', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_02-26-\n44_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n23/working/experiment_data.npy', '\\n', 'Execution time: 19 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 20000 examples [00:00,\n316151.58 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 255900.04\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 255519.65\nexamples/s]', '\\n', 'Loaded SPR_BENCH', '\\n', '#classes =', ' ', '2', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: val_loss=0.1446 |\nCWA=0.9531 | SWA=0.9551 | CVA=0.9542', '\\n', 'Epoch 2: val_loss=0.0920 |\nCWA=0.9721 | SWA=0.9733 | CVA=0.9727', '\\n', 'Epoch 3: val_loss=0.0458 |\nCWA=0.9894 | SWA=0.9897 | CVA=0.9896', '\\n', 'Epoch 4: val_loss=0.0285 |\nCWA=0.9929 | SWA=0.9928 | CVA=0.9929', '\\n', 'Epoch 5: val_loss=0.0306 |\nCWA=0.9935 | SWA=0.9931 | CVA=0.9933', '\\n', 'Epoch 6: val_loss=0.0166 |\nCWA=0.9960 | SWA=0.9955 | CVA=0.9958', '\\n', 'Epoch 7: val_loss=0.0140 |\nCWA=0.9960 | SWA=0.9952 | CVA=0.9956', '\\n', 'Epoch 8: val_loss=0.0100 |\nCWA=0.9972 | SWA=0.9967 | CVA=0.9970', '\\n', 'Epoch 9: val_loss=0.0165 |\nCWA=0.9963 | SWA=0.9956 | CVA=0.9960', '\\n', 'Epoch 10: val_loss=0.0118 |\nCWA=0.9970 | SWA=0.9965 | CVA=0.9968', '\\n', 'Epoch 11: val_loss=0.0121 |\nCWA=0.9968 | SWA=0.9963 | CVA=0.9965', '\\n', 'Epoch 12: val_loss=0.0138 |\nCWA=0.9966 | SWA=0.9960 | CVA=0.9963', '\\n', '\\nTEST: loss=2.6086 | CWA=0.6347 |\nSWA=0.6983 | CVA=0.6673', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_02-26-\n44_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n22/working/experiment_data.npy', '\\n', 'Execution time: 25 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Loaded SPR_BENCH', '\\n', '#classes =', '\n', '2', '\\n', '/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: val_loss=0.3057 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', 'Epoch 2: val_loss=0.3154 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', 'Epoch 3: val_loss=0.3128 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', 'Epoch 4: val_loss=0.3048 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', 'Epoch 5: val_loss=0.3048 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', 'Epoch 6: val_loss=0.3047 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', 'Epoch 7: val_loss=0.3078 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', 'Epoch 8: val_loss=0.3049 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', 'Epoch 9: val_loss=0.3078 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', 'Epoch 10: val_loss=0.3048 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', 'Epoch 11: val_loss=0.3056 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', 'Epoch 12: val_loss=0.3046 |\nCWA=0.8801 | SWA=0.8865 | CVA=0.8834', '\\n', '\\nTEST: loss=1.3296 | CWA=0.6043 |\nSWA=0.6561 | CVA=0.6308', '\\n', 'Saved experiment data ->', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_02-26-\n44_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n20/working/experiment_data.npy', '\\n', 'Execution time: 20 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Loaded SPR_BENCH', '\\n', '#classes=', ' ',\n'2', '\\n', 'Epoch 1: val_loss=0.1569 | CWA=0.9522 | SWA=0.9541 | CVA=0.9531',\n'\\n', 'Epoch 2: val_loss=0.1259 | CWA=0.9627 | SWA=0.9658 | CVA=0.9642', '\\n',\n'Epoch 3: val_loss=0.0976 | CWA=0.9684 | SWA=0.9706 | CVA=0.9695', '\\n', 'Epoch\n4: val_loss=0.0767 | CWA=0.9764 | SWA=0.9771 | CVA=0.9768', '\\n', 'Epoch 5:\nval_loss=0.0686 | CWA=0.9785 | SWA=0.9790 | CVA=0.9787', '\\n', 'Epoch 6:\nval_loss=0.0489 | CWA=0.9858 | SWA=0.9862 | CVA=0.9860', '\\n', 'Epoch 7:\nval_loss=0.0611 | CWA=0.9848 | SWA=0.9852 | CVA=0.9850', '\\n', 'Epoch 8:\nval_loss=0.0442 | CWA=0.9880 | SWA=0.9885 | CVA=0.9883', '\\n', 'Epoch 9:\nval_loss=0.0593 | CWA=0.9832 | SWA=0.9841 | CVA=0.9837', '\\n', 'Epoch 10:\nval_loss=0.0505 | CWA=0.9869 | SWA=0.9871 | CVA=0.9870', '\\n', 'Epoch 11:\nval_loss=0.0383 | CWA=0.9895 | SWA=0.9897 | CVA=0.9896', '\\n', 'Epoch 12:\nval_loss=0.0425 | CWA=0.9885 | SWA=0.9886 | CVA=0.9886', '\\n', '\\nTEST:\nloss=2.5027 | CWA=0.6320 | SWA=0.6951 | CVA=0.6643', '\\n', 'Saved experiment\ndata to', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_02-26-\n44_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n23/working/experiment_data.npy', '\\n', 'Execution time: 17 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded SPR_BENCH', '\\n', '#classes=2', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: val_loss=0.1179 |\nCWA=0.9586 | SWA=0.9612 | CVA=0.9599', '\\n', 'Epoch 2: val_loss=0.0621 |\nCWA=0.9834 | SWA=0.9837 | CVA=0.9835', '\\n', 'Epoch 3: val_loss=0.0497 |\nCWA=0.9859 | SWA=0.9859 | CVA=0.9859', '\\n', 'Epoch 4: val_loss=0.0394 |\nCWA=0.9915 | SWA=0.9913 | CVA=0.9914', '\\n', 'Epoch 5: val_loss=0.0409 |\nCWA=0.9897 | SWA=0.9893 | CVA=0.9895', '\\n', 'Epoch 6: val_loss=0.0405 |\nCWA=0.9893 | SWA=0.9898 | CVA=0.9895', '\\n', 'Epoch 7: val_loss=0.0270 |\nCWA=0.9926 | SWA=0.9922 | CVA=0.9923', '\\n', 'Epoch 8: val_loss=0.0143 |\nCWA=0.9955 | SWA=0.9949 | CVA=0.9952', '\\n', 'Epoch 9: val_loss=0.0126 |\nCWA=0.9963 | SWA=0.9956 | CVA=0.9960', '\\n', 'Epoch 10: val_loss=0.0126 |\nCWA=0.9969 | SWA=0.9963 | CVA=0.9966', '\\n', 'Epoch 11: val_loss=0.0137 |\nCWA=0.9965 | SWA=0.9959 | CVA=0.9962', '\\n', 'Epoch 12: val_loss=0.0071 |\nCWA=0.9976 | SWA=0.9972 | CVA=0.9974', '\\n', '\\nTEST: loss=2.4287 | CWA=0.6348 |\nSWA=0.6987 | CVA=0.6675', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_02-26-\n44_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n21/working/experiment_data.npy', '\\n', 'Execution time: 17 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded SPR_BENCH', '\\n', '#classes=2', '\\n',\n'/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of\nnested tensors is in prototype stage and will change in the near future.\n(Triggered internally at /opt/conda/conda-\nbld/pytorch_1729647429097/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\\n\noutput = torch._nested_tensor_from_mask(\\n', 'Epoch 1: val_loss=0.1569 |\nCWA=0.9466 | SWA=0.9486 | CVA=0.9476', '\\n', 'Epoch 2: val_loss=0.0500 |\nCWA=0.9853 | SWA=0.9854 | CVA=0.9854', '\\n', 'Epoch 3: val_loss=0.0490 |\nCWA=0.9894 | SWA=0.9890 | CVA=0.9892', '\\n', 'Epoch 4: val_loss=0.0375 |\nCWA=0.9922 | SWA=0.9916 | CVA=0.9919', '\\n', 'Epoch 5: val_loss=0.0293 |\nCWA=0.9946 | SWA=0.9938 | CVA=0.9942', '\\n', 'Epoch 6: val_loss=0.0277 |\nCWA=0.9941 | SWA=0.9934 | CVA=0.9937', '\\n', 'Epoch 7: val_loss=0.0267 |\nCWA=0.9946 | SWA=0.9938 | CVA=0.9942', '\\n', 'Epoch 8: val_loss=0.0204 |\nCWA=0.9950 | SWA=0.9942 | CVA=0.9946', '\\n', 'Epoch 9: val_loss=0.0229 |\nCWA=0.9944 | SWA=0.9939 | CVA=0.9942', '\\n', 'Epoch 10: val_loss=0.0210 |\nCWA=0.9951 | SWA=0.9945 | CVA=0.9948', '\\n', 'Epoch 11: val_loss=0.0130 |\nCWA=0.9961 | SWA=0.9955 | CVA=0.9958', '\\n', 'Epoch 12: val_loss=0.0191 |\nCWA=0.9956 | SWA=0.9948 | CVA=0.9952', '\\n', '\\nTEST: loss=2.6057 | CWA=0.6341 |\nSWA=0.6978 | CVA=0.6667', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-31_02-26-\n44_symbol_glyph_clustering_attempt_0/0-run/process_ForkProcess-\n22/working/experiment_data.npy', '\\n', 'Execution time: 21 seconds seconds (time\nlimit is 30 minutes).']"], "analysis": ["", "", "", "", "The execution of the training script was successful. The model achieved high\nColor-Weighted Accuracy (CWA), Shape-Weighted Accuracy (SWA), and Composite\nVariety Accuracy (CVA) on the validation set, with values close to 99% by the\nend of training. However, on the test set, the performance dropped\nsignificantly, with CWA at 63.47%, SWA at 69.83%, and CVA at 66.73%. This\nindicates potential overfitting to the training and validation data. To address\nthis, consider adding regularization techniques, such as dropout, weight decay,\nor early stopping. Additionally, increasing the diversity of the training data\nor using data augmentation techniques could help improve generalization.", "", "", "The training phase of the model performed excellently, achieving high Color-\nWeighted Accuracy (CWA), Shape-Weighted Accuracy (SWA), and Composite Variety\nAccuracy (CVA) on the validation set. However, the test phase results indicate a\nsignificant drop in performance, with CWA at 63.48%, SWA at 69.87%, and CVA at\n66.75%. This suggests a potential overfitting issue where the model performs\nwell on the training and validation sets but fails to generalize to unseen data.\nTo mitigate this, consider implementing regularization techniques such as\ndropout or weight decay, and evaluate the model using cross-validation.\nAdditionally, increasing the diversity of the training dataset or applying data\naugmentation techniques may improve generalization.", ""], "exc_type": [null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR", "final_value": 0.010693, "best_value": 0.010693}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR", "final_value": 0.008393, "best_value": 0.008393}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "The accuracy for color classification during validation, weighted by class.", "data": [{"dataset_name": "SPR", "final_value": 0.99695, "best_value": 0.99695}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "The accuracy for shape classification during validation, weighted by class.", "data": [{"dataset_name": "SPR", "final_value": 0.996628, "best_value": 0.996628}]}, {"metric_name": "validation composite variety accuracy", "lower_is_better": false, "description": "The accuracy for composite variety classification during validation.", "data": [{"dataset_name": "SPR", "final_value": 0.996785, "best_value": 0.996785}]}, {"metric_name": "test color weighted accuracy", "lower_is_better": false, "description": "The accuracy for color classification during testing, weighted by class.", "data": [{"dataset_name": "SPR", "final_value": 0.635311, "best_value": 0.635311}]}, {"metric_name": "test shape weighted accuracy", "lower_is_better": false, "description": "The accuracy for shape classification during testing, weighted by class.", "data": [{"dataset_name": "SPR", "final_value": 0.699116, "best_value": 0.699116}]}, {"metric_name": "test composite variety accuracy", "lower_is_better": false, "description": "The accuracy for composite variety classification during testing.", "data": [{"dataset_name": "SPR", "final_value": 0.667967, "best_value": 0.667967}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Training loss measures the error during training. Lower values are better.", "data": [{"dataset_name": "SPR (no_pos_emb)", "final_value": 0.1671, "best_value": 0.1671}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss measures the error on the validation dataset. Lower values are better.", "data": [{"dataset_name": "SPR (no_pos_emb)", "final_value": 0.1699, "best_value": 0.1699}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "Validation CWA measures the classification weighted accuracy on the validation set. Higher values are better.", "data": [{"dataset_name": "SPR (no_pos_emb)", "final_value": 0.9477, "best_value": 0.9477}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "Validation SWA measures the sample weighted accuracy on the validation set. Higher values are better.", "data": [{"dataset_name": "SPR (no_pos_emb)", "final_value": 0.9447, "best_value": 0.9447}]}, {"metric_name": "validation CVA", "lower_is_better": false, "description": "Validation CVA measures the classwise validation accuracy. Higher values are better.", "data": [{"dataset_name": "SPR (no_pos_emb)", "final_value": 0.9461, "best_value": 0.9461}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "Test CWA measures the classification weighted accuracy on the test set. Higher values are better.", "data": [{"dataset_name": "SPR (no_pos_emb)", "final_value": 0.629, "best_value": 0.629}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "Test SWA measures the sample weighted accuracy on the test set. Higher values are better.", "data": [{"dataset_name": "SPR (no_pos_emb)", "final_value": 0.6858, "best_value": 0.6858}]}, {"metric_name": "test CVA", "lower_is_better": false, "description": "Test CVA measures the classwise validation accuracy on the test set. Higher values are better.", "data": [{"dataset_name": "SPR (no_pos_emb)", "final_value": 0.6581, "best_value": 0.6581}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR", "final_value": 0.5556, "best_value": 0.5556}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR", "final_value": 0.5574, "best_value": 0.5574}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during validation.", "data": [{"dataset_name": "SPR", "final_value": 0.709, "best_value": 0.709}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during validation.", "data": [{"dataset_name": "SPR", "final_value": 0.714, "best_value": 0.714}]}, {"metric_name": "validation composite variety accuracy", "lower_is_better": false, "description": "The composite variety accuracy during validation.", "data": [{"dataset_name": "SPR", "final_value": 0.7116, "best_value": 0.7116}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy during testing.", "data": [{"dataset_name": "SPR", "final_value": 0.597, "best_value": 0.597}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy during testing.", "data": [{"dataset_name": "SPR", "final_value": 0.6296, "best_value": 0.6296}]}, {"metric_name": "test composite variety accuracy", "lower_is_better": false, "description": "The composite variety accuracy during testing.", "data": [{"dataset_name": "SPR", "final_value": 0.6137, "best_value": 0.6137}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training.", "data": [{"dataset_name": "SPR", "final_value": 0.10732582573890687, "best_value": 0.10732582573890687}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error during validation.", "data": [{"dataset_name": "SPR", "final_value": 0.10419194822311402, "best_value": 0.10419194822311402}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "Measures the color weighted accuracy during validation.", "data": [{"dataset_name": "SPR", "final_value": 0.9743761820511256, "best_value": 0.9743761820511256}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "Measures the shape weighted accuracy during validation.", "data": [{"dataset_name": "SPR", "final_value": 0.9729101267294501, "best_value": 0.9729101267294501}]}, {"metric_name": "validation composite variety accuracy", "lower_is_better": false, "description": "Measures the composite variety accuracy during validation.", "data": [{"dataset_name": "SPR", "final_value": 0.9736254576846367, "best_value": 0.9736254576846367}]}, {"metric_name": "test color weighted accuracy", "lower_is_better": false, "description": "Measures the color weighted accuracy during testing.", "data": [{"dataset_name": "SPR", "final_value": 0.6299030778111993, "best_value": 0.6299030778111993}]}, {"metric_name": "test shape weighted accuracy", "lower_is_better": false, "description": "Measures the shape weighted accuracy during testing.", "data": [{"dataset_name": "SPR", "final_value": 0.6905376032459064, "best_value": 0.6905376032459064}]}, {"metric_name": "test composite variety accuracy", "lower_is_better": false, "description": "Measures the composite variety accuracy during testing.", "data": [{"dataset_name": "SPR", "final_value": 0.6609362484796345, "best_value": 0.6609362484796345}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures how well the model is fitting the training data.", "data": [{"dataset_name": "Training Dataset", "final_value": 0.0087, "best_value": 0.0087}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures how well the model is performing on the validation data.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.01, "best_value": 0.01}]}, {"metric_name": "validation cwa", "lower_is_better": false, "description": "Validation dataset's class-wise accuracy.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.9972, "best_value": 0.9972}]}, {"metric_name": "validation swa", "lower_is_better": false, "description": "Validation dataset's sample-wise accuracy.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.9967, "best_value": 0.9967}]}, {"metric_name": "validation cva", "lower_is_better": false, "description": "Validation dataset's class-wise variance accuracy.", "data": [{"dataset_name": "Validation Dataset", "final_value": 0.997, "best_value": 0.997}]}, {"metric_name": "test cwa", "lower_is_better": false, "description": "Test dataset's class-wise accuracy.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6347, "best_value": 0.6347}]}, {"metric_name": "test swa", "lower_is_better": false, "description": "Test dataset's sample-wise accuracy.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6983, "best_value": 0.6983}]}, {"metric_name": "test cva", "lower_is_better": false, "description": "Test dataset's class-wise variance accuracy.", "data": [{"dataset_name": "Test Dataset", "final_value": 0.6673, "best_value": 0.6673}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR", "final_value": 0.31, "best_value": 0.31}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR", "final_value": 0.3046, "best_value": 0.3046}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "The best validation CWA (Class Weighted Accuracy).", "data": [{"dataset_name": "SPR", "final_value": 0.8801, "best_value": 0.8801}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "The best validation SWA (Sample Weighted Accuracy).", "data": [{"dataset_name": "SPR", "final_value": 0.8865, "best_value": 0.8865}]}, {"metric_name": "validation CVA", "lower_is_better": false, "description": "The best validation CVA (Class Validation Accuracy).", "data": [{"dataset_name": "SPR", "final_value": 0.8834, "best_value": 0.8834}]}, {"metric_name": "test CWA", "lower_is_better": false, "description": "The test CWA (Class Weighted Accuracy).", "data": [{"dataset_name": "SPR", "final_value": 0.6043, "best_value": 0.6043}]}, {"metric_name": "test SWA", "lower_is_better": false, "description": "The test SWA (Sample Weighted Accuracy).", "data": [{"dataset_name": "SPR", "final_value": 0.6561, "best_value": 0.6561}]}, {"metric_name": "test CVA", "lower_is_better": false, "description": "The test CVA (Class Validation Accuracy).", "data": [{"dataset_name": "SPR", "final_value": 0.6308, "best_value": 0.6308}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss value after completion of training.", "data": [{"dataset_name": "training dataset", "final_value": 0.03786436207294464, "best_value": 0.03786436207294464}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Best validation loss value during training.", "data": [{"dataset_name": "validation dataset", "final_value": 0.038275702542066574, "best_value": 0.038275702542066574}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "Best color-weighted accuracy achieved on the validation dataset.", "data": [{"dataset_name": "validation dataset", "final_value": 0.9895064364590324, "best_value": 0.9895064364590324}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Best shape-weighted accuracy achieved on the validation dataset.", "data": [{"dataset_name": "validation dataset", "final_value": 0.989652366003953, "best_value": 0.989652366003953}]}, {"metric_name": "validation composite-variety accuracy", "lower_is_better": false, "description": "Best composite-variety accuracy achieved on the validation dataset.", "data": [{"dataset_name": "validation dataset", "final_value": 0.989581162742238, "best_value": 0.989581162742238}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "Final color-weighted accuracy achieved on the test dataset.", "data": [{"dataset_name": "test dataset", "final_value": 0.6319691307386139, "best_value": 0.6319691307386139}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "Final shape-weighted accuracy achieved on the test dataset.", "data": [{"dataset_name": "test dataset", "final_value": 0.6950586871467903, "best_value": 0.6950586871467903}]}, {"metric_name": "test composite-variety accuracy", "lower_is_better": false, "description": "Final composite-variety accuracy achieved on the test dataset.", "data": [{"dataset_name": "test dataset", "final_value": 0.664258803286956, "best_value": 0.664258803286956}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error in the training dataset.", "data": [{"dataset_name": "SPR", "final_value": 0.0116, "best_value": 0.0116}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error in the validation dataset.", "data": [{"dataset_name": "SPR", "final_value": 0.0071, "best_value": 0.0071}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of color-weighted predictions on the validation dataset.", "data": [{"dataset_name": "SPR", "final_value": 0.9976, "best_value": 0.9976}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of shape-weighted predictions on the validation dataset.", "data": [{"dataset_name": "SPR", "final_value": 0.9972, "best_value": 0.9972}]}, {"metric_name": "validation composite-variety accuracy", "lower_is_better": false, "description": "Measures the accuracy of composite-variety predictions on the validation dataset.", "data": [{"dataset_name": "SPR", "final_value": 0.9974, "best_value": 0.9974}]}, {"metric_name": "test color-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of color-weighted predictions on the test dataset.", "data": [{"dataset_name": "SPR", "final_value": 0.6348, "best_value": 0.6348}]}, {"metric_name": "test shape-weighted accuracy", "lower_is_better": false, "description": "Measures the accuracy of shape-weighted predictions on the test dataset.", "data": [{"dataset_name": "SPR", "final_value": 0.6987, "best_value": 0.6987}]}, {"metric_name": "test composite-variety accuracy", "lower_is_better": false, "description": "Measures the accuracy of composite-variety predictions on the test dataset.", "data": [{"dataset_name": "SPR", "final_value": 0.6675, "best_value": 0.6675}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, lower values indicate better performance.", "data": [{"dataset_name": "training dataset", "final_value": 0.0134, "best_value": 0.0134}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, lower values indicate better performance.", "data": [{"dataset_name": "validation dataset", "final_value": 0.013, "best_value": 0.013}]}, {"metric_name": "validation cwa", "lower_is_better": false, "description": "The cumulative weighted accuracy during validation, higher values indicate better performance.", "data": [{"dataset_name": "validation dataset", "final_value": 0.9961, "best_value": 0.9961}]}, {"metric_name": "validation swa", "lower_is_better": false, "description": "The smoothed weighted accuracy during validation, higher values indicate better performance.", "data": [{"dataset_name": "validation dataset", "final_value": 0.9955, "best_value": 0.9955}]}, {"metric_name": "validation cva", "lower_is_better": false, "description": "The cumulative validation accuracy during validation, higher values indicate better performance.", "data": [{"dataset_name": "validation dataset", "final_value": 0.9958, "best_value": 0.9958}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "The loss value during testing, lower values indicate better performance.", "data": [{"dataset_name": "test dataset", "final_value": null, "best_value": null}]}, {"metric_name": "test cwa", "lower_is_better": false, "description": "The cumulative weighted accuracy during testing, higher values indicate better performance.", "data": [{"dataset_name": "test dataset", "final_value": 0.6341, "best_value": 0.6341}]}, {"metric_name": "test swa", "lower_is_better": false, "description": "The smoothed weighted accuracy during testing, higher values indicate better performance.", "data": [{"dataset_name": "test dataset", "final_value": 0.6978, "best_value": 0.6978}]}, {"metric_name": "test cva", "lower_is_better": false, "description": "The cumulative validation accuracy during testing, higher values indicate better performance.", "data": [{"dataset_name": "test dataset", "final_value": 0.6667, "best_value": 0.6667}]}]}], "is_best_node": [true, false, false, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_750ef8765be7495db4f73f0abc9ea3fd_proc_1608752/SPR_loss_curves.png", "../../logs/0-run/experiment_results/experiment_750ef8765be7495db4f73f0abc9ea3fd_proc_1608752/SPR_val_metrics.png", "../../logs/0-run/experiment_results/experiment_750ef8765be7495db4f73f0abc9ea3fd_proc_1608752/SPR_test_metrics_bar.png"], ["../../logs/0-run/experiment_results/experiment_9cc1b16eb35f4bbbabe7798178e0d638_proc_1614362/SPR_no_pos_emb_loss_curves.png", "../../logs/0-run/experiment_results/experiment_9cc1b16eb35f4bbbabe7798178e0d638_proc_1614362/SPR_no_pos_emb_val_accuracies.png", "../../logs/0-run/experiment_results/experiment_9cc1b16eb35f4bbbabe7798178e0d638_proc_1614362/SPR_no_pos_emb_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_CVA_curve.png", "../../logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_weighted_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_test_metrics_bar.png", "../../logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_4c90f58aaaa74ffea835b1cefa9027da_proc_1614365/SPR_loss_curves_no_color_embedding.png", "../../logs/0-run/experiment_results/experiment_4c90f58aaaa74ffea835b1cefa9027da_proc_1614365/SPR_accuracy_curves_no_color_embedding.png", "../../logs/0-run/experiment_results/experiment_4c90f58aaaa74ffea835b1cefa9027da_proc_1614365/SPR_confusion_matrix_no_color_embedding.png"], ["../../logs/0-run/experiment_results/experiment_5b81886804194508aab11348677db6bf_proc_1614364/SPR_loss_curves.png", "../../logs/0-run/experiment_results/experiment_5b81886804194508aab11348677db6bf_proc_1614364/SPR_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_5b81886804194508aab11348677db6bf_proc_1614364/SPR_test_metrics.png"], ["../../logs/0-run/experiment_results/experiment_b6f321e2d6a74fde8d51298e294c875d_proc_1614362/SPR_loss_curve.png", "../../logs/0-run/experiment_results/experiment_b6f321e2d6a74fde8d51298e294c875d_proc_1614362/SPR_CVA_curve.png", "../../logs/0-run/experiment_results/experiment_b6f321e2d6a74fde8d51298e294c875d_proc_1614362/SPR_test_metrics_bar.png"], ["../../logs/0-run/experiment_results/experiment_f5613f032c9b4f2c8518964b5b5a4dc1_proc_1614365/SPR_loss_curve.png", "../../logs/0-run/experiment_results/experiment_f5613f032c9b4f2c8518964b5b5a4dc1_proc_1614365/SPR_metric_curve.png", "../../logs/0-run/experiment_results/experiment_f5613f032c9b4f2c8518964b5b5a4dc1_proc_1614365/SPR_confusion_matrix.png"], [], ["../../logs/0-run/experiment_results/experiment_f73f93ee24ef479b99a40aa0a0f4f241_proc_1614364/SPR_fixed_sinusoidal_pos_encoding_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f73f93ee24ef479b99a40aa0a0f4f241_proc_1614364/SPR_fixed_sinusoidal_pos_encoding_val_metrics.png", "../../logs/0-run/experiment_results/experiment_f73f93ee24ef479b99a40aa0a0f4f241_proc_1614364/SPR_fixed_sinusoidal_pos_encoding_confusion_matrix.png"]], "plot_paths": [["experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_750ef8765be7495db4f73f0abc9ea3fd_proc_1608752/SPR_loss_curves.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_750ef8765be7495db4f73f0abc9ea3fd_proc_1608752/SPR_val_metrics.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_750ef8765be7495db4f73f0abc9ea3fd_proc_1608752/SPR_test_metrics_bar.png"], ["experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_9cc1b16eb35f4bbbabe7798178e0d638_proc_1614362/SPR_no_pos_emb_loss_curves.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_9cc1b16eb35f4bbbabe7798178e0d638_proc_1614362/SPR_no_pos_emb_val_accuracies.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_9cc1b16eb35f4bbbabe7798178e0d638_proc_1614362/SPR_no_pos_emb_confusion_matrix.png"], ["experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_loss_curves.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_CVA_curve.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_weighted_accuracy_curves.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_test_metrics_bar.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_confusion_matrix.png"], ["experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_4c90f58aaaa74ffea835b1cefa9027da_proc_1614365/SPR_loss_curves_no_color_embedding.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_4c90f58aaaa74ffea835b1cefa9027da_proc_1614365/SPR_accuracy_curves_no_color_embedding.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_4c90f58aaaa74ffea835b1cefa9027da_proc_1614365/SPR_confusion_matrix_no_color_embedding.png"], ["experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5b81886804194508aab11348677db6bf_proc_1614364/SPR_loss_curves.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5b81886804194508aab11348677db6bf_proc_1614364/SPR_accuracy_curves.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5b81886804194508aab11348677db6bf_proc_1614364/SPR_test_metrics.png"], ["experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6f321e2d6a74fde8d51298e294c875d_proc_1614362/SPR_loss_curve.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6f321e2d6a74fde8d51298e294c875d_proc_1614362/SPR_CVA_curve.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6f321e2d6a74fde8d51298e294c875d_proc_1614362/SPR_test_metrics_bar.png"], ["experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f5613f032c9b4f2c8518964b5b5a4dc1_proc_1614365/SPR_loss_curve.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f5613f032c9b4f2c8518964b5b5a4dc1_proc_1614365/SPR_metric_curve.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f5613f032c9b4f2c8518964b5b5a4dc1_proc_1614365/SPR_confusion_matrix.png"], [], ["experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f73f93ee24ef479b99a40aa0a0f4f241_proc_1614364/SPR_fixed_sinusoidal_pos_encoding_loss_curves.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f73f93ee24ef479b99a40aa0a0f4f241_proc_1614364/SPR_fixed_sinusoidal_pos_encoding_val_metrics.png", "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f73f93ee24ef479b99a40aa0a0f4f241_proc_1614364/SPR_fixed_sinusoidal_pos_encoding_confusion_matrix.png"]], "plot_analyses": [[{"analysis": "The left plot shows the training loss curve, and the right plot shows the validation loss curve. Both curves demonstrate a steady and significant decrease in cross-entropy loss over the epochs, which indicates that the model is learning effectively. The validation loss stabilizes around epoch 6, suggesting that the model has reached a good generalization point without overfitting.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_750ef8765be7495db4f73f0abc9ea3fd_proc_1608752/SPR_loss_curves.png"}, {"analysis": "The three subplots display the progression of Color-Weighted Accuracy (CWA), Shape-Weighted Accuracy (SWA), and Composite Variety Accuracy (CVA) over the epochs. All three metrics show a consistent upward trend, with CWA and SWA exceeding 99% accuracy by epoch 6. This indicates that the model is highly effective in capturing both color and shape features for reasoning tasks. CVA also shows a sharp increase, reflecting the model's ability to generalize across composite tasks.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_750ef8765be7495db4f73f0abc9ea3fd_proc_1608752/SPR_val_metrics.png"}, {"analysis": "This bar chart compares the final test metrics for CWA, SWA, and CVA. The CWA is approximately 0.67, the SWA is around 0.7, and the CVA is slightly higher than both. These results are close to or surpass the stated SOTA benchmarks of 70% for CWA and 65% for SWA, demonstrating the effectiveness of the proposed symbolic glyph clustering approach.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_750ef8765be7495db4f73f0abc9ea3fd_proc_1608752/SPR_test_metrics_bar.png"}], [{"analysis": "The loss curves indicate a rapid convergence for both the training and validation datasets. By epoch 4, the cross-entropy loss stabilizes around a low value, suggesting that the model is effectively learning the patterns in the data. The close alignment of the training and validation curves implies minimal overfitting, which is a positive outcome for generalization.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_9cc1b16eb35f4bbbabe7798178e0d638_proc_1614362/SPR_no_pos_emb_loss_curves.png"}, {"analysis": "The accuracy metrics (CWA, SWA, and CVA) on the validation set show a consistent and high performance, stabilizing above 0.94 after the initial epochs. This suggests that the model performs well across different weighted accuracy measures, indicating a balanced ability to handle both color and shape variations in the symbolic sequences.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_9cc1b16eb35f4bbbabe7798178e0d638_proc_1614362/SPR_no_pos_emb_val_accuracies.png"}, {"analysis": "The confusion matrix reveals that the model correctly classifies a significant portion of the data, but there are notable misclassifications. Specifically, the false positives and false negatives for both classes (as indicated by the off-diagonal elements) suggest areas for improvement in distinguishing between certain patterns. This could be addressed by refining the clustering mechanism or incorporating additional features.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_9cc1b16eb35f4bbbabe7798178e0d638_proc_1614362/SPR_no_pos_emb_confusion_matrix.png"}], [{"analysis": "This plot demonstrates the training and validation loss over 12 epochs. The training loss decreases steadily, indicating that the model is learning effectively on the training data. Validation loss decreases initially but plateaus after a few epochs, suggesting that the model is not overfitting and has reached a stable generalization performance. The close alignment between training and validation loss indicates good model regularization.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_loss_curves.png"}, {"analysis": "This plot shows the Composite Variety Accuracy (CVA) on the validation set over 12 epochs. The CVA fluctuates slightly but shows an overall upward trend, indicating gradual improvement in the model's ability to capture the variety in symbolic patterns. However, the fluctuations suggest that further tuning or stabilization techniques might be needed to ensure consistent improvement.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_CVA_curve.png"}, {"analysis": "This plot compares the Color-Weighted Accuracy (CWA) and Shape-Weighted Accuracy (SWA) on the validation set over 12 epochs. Both metrics show a general upward trend, with CWA slightly outperforming SWA. This indicates that the model is slightly better at capturing color-based patterns than shape-based ones. The fluctuations in both metrics suggest potential room for improvement in model stability or training strategies.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_weighted_accuracy_curves.png"}, {"analysis": "This bar chart summarizes the test set performance for CWA, SWA, and CVA. All metrics are close to each other, with CWA being slightly higher. This indicates that the model has achieved balanced performance across the different weighted accuracy metrics, aligning with the hypothesis of improved generalization through symbolic glyph clustering.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_test_metrics_bar.png"}, {"analysis": "This confusion matrix for the test set shows that the model performs reasonably well, with a higher number of correct predictions in the true positive and true negative categories. However, there is still a notable number of misclassifications, as seen in the off-diagonal entries. This suggests that while the model has learned the patterns to some extent, there is room for improvement in reducing false positives and false negatives.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_6e24840372594178bc0e890baca9c419_proc_1614363/SPR_confusion_matrix.png"}], [{"analysis": "The plot shows the training and validation loss for the SPR No-Color-Embedding experiment over 12 epochs. Both losses decrease steadily and converge at a low value, indicating that the model is effectively learning without overfitting. The minimal gap between the training and validation loss suggests that the model generalizes well to unseen data.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_4c90f58aaaa74ffea835b1cefa9027da_proc_1614365/SPR_loss_curves_no_color_embedding.png"}, {"analysis": "The plot shows the validation accuracies for three metrics (CWA, SWA, CVA) over 12 epochs. All metrics improve significantly in the initial epochs and stabilize near 97%, reflecting strong performance across all evaluation criteria. The consistent trends across the metrics indicate that the model is robust and performs well for both color and shape-based reasoning.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_4c90f58aaaa74ffea835b1cefa9027da_proc_1614365/SPR_accuracy_curves_no_color_embedding.png"}, {"analysis": "The confusion matrix provides a detailed view of the model's classification performance. The diagonal dominance indicates that the model classifies most samples correctly. However, there are some misclassifications, as shown by the off-diagonal values. The magnitude of these errors appears small, suggesting that the model achieves high accuracy overall.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_4c90f58aaaa74ffea835b1cefa9027da_proc_1614365/SPR_confusion_matrix_no_color_embedding.png"}], [{"analysis": "The loss curves for both training and validation show a consistent decrease over epochs, indicating effective learning. The training loss decreases more steeply initially, while the validation loss follows a similar trend, suggesting no overfitting. The convergence of both curves at the later epochs reflects a well-tuned model that generalizes effectively.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5b81886804194508aab11348677db6bf_proc_1614364/SPR_loss_curves.png"}, {"analysis": "The weighted accuracies (CWA, SWA, and CVA) improve significantly in the early epochs and converge to high values close to 1.0 by the end of the training. This indicates that the model is performing well across all three metrics, achieving near-perfect accuracy for the training data.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5b81886804194508aab11348677db6bf_proc_1614364/SPR_accuracy_curves.png"}, {"analysis": "The final test metrics reveal that the model achieves a Color-Weighted Accuracy (CWA) of approximately 70%, a Shape-Weighted Accuracy (SWA) slightly higher than CWA, and a Combined-Weighted Accuracy (CVA) similar to CWA. These results suggest that the model performs slightly better on shape-based reasoning than color-based reasoning, but both metrics are close to the state-of-the-art benchmarks.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_5b81886804194508aab11348677db6bf_proc_1614364/SPR_test_metrics.png"}], [{"analysis": "This plot shows the training and validation cross-entropy loss over 12 epochs. The training loss decreases steadily and stabilizes after the initial few epochs, indicating that the model is learning effectively. The validation loss follows a similar trend, suggesting that the model generalizes well to unseen data without overfitting. However, the gap between training and validation loss is minimal, which is a positive sign of generalization.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6f321e2d6a74fde8d51298e294c875d_proc_1614362/SPR_loss_curve.png"}, {"analysis": "This plot illustrates the Composite Variety Accuracy (CVA) on the validation set across epochs, with a reference line for the test set CVA at 0.631. The validation CVA remains consistently high (above 0.9) throughout the training process, indicating that the model performs exceptionally well on the validation set. However, the test set CVA is significantly lower, suggesting a potential overfitting issue or a discrepancy between the validation and test data distributions.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6f321e2d6a74fde8d51298e294c875d_proc_1614362/SPR_CVA_curve.png"}, {"analysis": "This bar chart compares the weighted accuracies on the test set for Color-Weighted Accuracy (CWA), Shape-Weighted Accuracy (SWA), and Composite Variety Accuracy (CVA). The SWA achieves the highest accuracy (0.66), slightly surpassing the CVA (0.63) and CWA (0.60). While the results are promising, the CWA and CVA are below the stated SOTA benchmarks of 70.0% and 65.0%, respectively, indicating room for improvement in the clustering and reasoning approach.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_b6f321e2d6a74fde8d51298e294c875d_proc_1614362/SPR_test_metrics_bar.png"}], [{"analysis": "This plot shows the training and validation loss over 12 epochs. Both curves decrease steadily, indicating improved model performance and reduced error rates. The validation loss closely follows the training loss, suggesting that the model generalizes well and avoids overfitting. The convergence of the two curves at the later epochs indicates a stable training process.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f5613f032c9b4f2c8518964b5b5a4dc1_proc_1614365/SPR_loss_curve.png"}, {"analysis": "This plot compares Color-Weighted Accuracy (CWA), Shape-Weighted Accuracy (SWA), and Combined Weighted Accuracy (CVA) on the validation set across 12 epochs. All three metrics show a consistent upward trend, reaching above 98.5% accuracy by the 12th epoch. The close alignment of the curves suggests that the model performs uniformly well across all weighted accuracy metrics, demonstrating robust handling of both color and shape variations in the data.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f5613f032c9b4f2c8518964b5b5a4dc1_proc_1614365/SPR_metric_curve.png"}, {"analysis": "This confusion matrix for the test set shows the distribution of true positives, false positives, true negatives, and false negatives. The model correctly predicts a majority of the samples, with 3409 true negatives and 3541 true positives. However, there are 1575 false positives and 1475 false negatives, indicating some room for improvement in precision and recall. The overall performance suggests a strong predictive capability with a slight bias towards certain classes.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f5613f032c9b4f2c8518964b5b5a4dc1_proc_1614365/SPR_confusion_matrix.png"}], [], [{"analysis": "The loss curves indicate a rapid convergence of the model during training. Both the training and validation loss decrease sharply within the first few epochs and stabilize around epoch 6. The training and validation losses are closely aligned, suggesting that the model is not overfitting and generalizes well to the validation set.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f73f93ee24ef479b99a40aa0a0f4f241_proc_1614364/SPR_fixed_sinusoidal_pos_encoding_loss_curves.png"}, {"analysis": "The weighted accuracy metrics (CWA, SWA, and CVA) show consistent improvement across epochs, with all metrics converging to values close to 99%. This indicates that the model performs exceptionally well on the validation set, achieving near-perfect accuracy across all weighted evaluation metrics. The alignment of CWA, SWA, and CVA suggests balanced performance across different aspects of the task.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f73f93ee24ef479b99a40aa0a0f4f241_proc_1614364/SPR_fixed_sinusoidal_pos_encoding_val_metrics.png"}, {"analysis": "The confusion matrix shows that the model achieves high accuracy, with the majority of predictions being correct. However, there are still some misclassifications, as indicated by the off-diagonal values. The number of true positives and true negatives is significantly higher than the number of false positives and false negatives, which demonstrates the model's strong predictive ability. Further analysis could focus on understanding the characteristics of the misclassified samples to identify potential areas for improvement.", "plot_path": "experiments/2025-08-31_02-26-44_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_f73f93ee24ef479b99a40aa0a0f4f241_proc_1614364/SPR_fixed_sinusoidal_pos_encoding_confusion_matrix.png"}]], "vlm_feedback_summary": ["The plots illustrate that the proposed method achieves excellent training and\nvalidation performance, with metrics reaching or exceeding SOTA benchmarks. The\nconsistent trends in accuracy metrics and the stable loss curves suggest that\nthe model is both effective and well-generalized. Further exploration of the\nclustering approach and its impact on different reasoning tasks could provide\nadditional insights.", "The experimental results demonstrate effective learning and high validation\naccuracy, with minimal overfitting. The confusion matrix highlights some areas\nfor improvement in classification accuracy, particularly in reducing\nmisclassifications.", "The experimental plots indicate steady learning and generalization, with upward\ntrends in accuracy metrics. However, some fluctuations and misclassifications\nhighlight areas for further optimization. The results support the hypothesis of\nsymbolic glyph clustering improving model performance, but additional\nrefinements could enhance stability and accuracy further.", "The results indicate effective training, strong generalization, and robust\nperformance across multiple metrics. The low training and validation losses,\nhigh validation accuracies, and minimal misclassifications in the confusion\nmatrix collectively demonstrate the success of the SPR No-Color-Embedding model.", "The plots demonstrate effective training and validation processes, with the\nmodel achieving high accuracy across all metrics. The loss curves and weighted\naccuracy trends suggest the model generalizes well and performs near state-of-\nthe-art levels on the test data.", "The plots provide meaningful insights into the model's performance. The training\nvs. validation loss plot shows good convergence and generalization. The CVA\nprogress plot highlights a potential discrepancy between validation and test\nperformance, raising concerns about generalization to unseen data. The test set\nweighted accuracies indicate that while SWA performs best, the CWA and CVA fall\nshort of the SOTA benchmarks, suggesting areas for further refinement of the\napproach.", "The plots indicate a well-performing model with consistent improvements in both\ntraining and validation loss, high accuracy metrics, and a reasonably balanced\nconfusion matrix. The results suggest effective generalization and robustness in\nhandling the SPR_BENCH dataset, though precision and recall could be further\noptimized.", "[]", "The plots demonstrate excellent model performance with rapid convergence in\nloss, near-perfect weighted accuracy metrics, and strong predictive ability as\nshown by the confusion matrix. The results suggest that the proposed approach is\neffective and has potential for achieving state-of-the-art performance."], "exec_time": [17.514946937561035, 23.239569902420044, 12.949478149414062, 19.89005208015442, 25.60638117790222, 20.863269090652466, 17.57124400138855, 17.557531118392944, 21.278034210205078], "exec_time_feedback": ["", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["['dataset_name_placeholder']"], ["[\"SPR\"]"], ["[\"SPR\"]"], ["['SPR']"], ["['SPR']"], ["\"\""], ["['SPR_BENCH']"], [], ["\"\""]], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------- setup --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- load data --------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nif not experiment_data:\n    print(\"No experiment data found, nothing to plot.\")\nelse:\n    # discover data structure\n    tags = list(experiment_data.keys())\n    datasets = set(dname for tag in tags for dname in experiment_data[tag].keys())\n\n    for dname in datasets:\n        # collect per-tag series\n        train_loss, val_loss = {}, {}\n        val_cwa, val_swa, val_cva, epochs = {}, {}, {}, {}\n        test_metrics = {}\n        for tag in tags:\n            if dname not in experiment_data[tag]:\n                continue\n            ed = experiment_data[tag][dname]\n            train_loss[tag] = ed[\"losses\"][\"train\"]\n            val_loss[tag] = ed[\"losses\"][\"val\"]\n            epochs[tag] = list(range(1, len(train_loss[tag]) + 1))\n            # validation metrics\n            val_cwa[tag] = [m[\"cwa\"] for m in ed[\"metrics\"][\"val\"]]\n            val_swa[tag] = [m[\"swa\"] for m in ed[\"metrics\"][\"val\"]]\n            val_cva[tag] = [m[\"cva\"] for m in ed[\"metrics\"][\"val\"]]\n            # test metrics\n            tm = ed[\"metrics\"].get(\"test\", {})\n            if tm:\n                test_metrics[tag] = tm\n\n        # ---------------- plot 1 : Loss curves ----------------\n        try:\n            fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n            for tag in train_loss:\n                axes[0].plot(epochs[tag], train_loss[tag], label=tag)\n                axes[1].plot(epochs[tag], val_loss[tag], label=tag)\n            axes[0].set_title(\"Train Loss\")\n            axes[1].set_title(\"Validation Loss\")\n            for ax in axes:\n                ax.set_xlabel(\"Epoch\")\n                ax.set_ylabel(\"Cross-Entropy\")\n                ax.legend()\n            fig.suptitle(f\"{dname} Loss Curves (Left: Train, Right: Validation)\")\n            fname = os.path.join(working_dir, f\"{dname}_loss_curves.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss curves for {dname}: {e}\")\n            plt.close()\n\n        # ---------------- plot 2 : Validation metrics ----------------\n        try:\n            fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n            for tag in val_cwa:\n                axes[0].plot(epochs[tag], val_cwa[tag], label=tag)\n                axes[1].plot(epochs[tag], val_swa[tag], label=tag)\n                axes[2].plot(epochs[tag], val_cva[tag], label=tag)\n            titles = [\n                \"Color-Weighted Acc.\",\n                \"Shape-Weighted Acc.\",\n                \"Composite Variety Acc.\",\n            ]\n            for ax, t in zip(axes, titles):\n                ax.set_title(t)\n                ax.set_xlabel(\"Epoch\")\n                ax.set_ylabel(\"Accuracy\")\n                ax.legend()\n            fig.suptitle(f\"{dname} Validation Metrics Over Epochs\")\n            fname = os.path.join(working_dir, f\"{dname}_val_metrics.png\")\n            plt.savefig(fname)\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating validation metric curves for {dname}: {e}\")\n            plt.close()\n\n        # ---------------- plot 3 : Test metrics bar ----------------\n        try:\n            if test_metrics:\n                width = 0.25\n                tags_sorted = sorted(test_metrics.keys())\n                indices = np.arange(len(tags_sorted))\n                cwa_vals = [test_metrics[t][\"cwa\"] for t in tags_sorted]\n                swa_vals = [test_metrics[t][\"swa\"] for t in tags_sorted]\n                cva_vals = [test_metrics[t][\"cva\"] for t in tags_sorted]\n\n                plt.figure(figsize=(10, 5))\n                plt.bar(indices - width, cwa_vals, width, label=\"CWA\")\n                plt.bar(indices, swa_vals, width, label=\"SWA\")\n                plt.bar(indices + width, cva_vals, width, label=\"CVA\")\n                plt.xticks(indices, tags_sorted, rotation=45, ha=\"right\")\n                plt.ylabel(\"Accuracy\")\n                plt.title(f\"{dname} Test Metrics Comparison\")\n                plt.legend()\n                plt.tight_layout()\n                fname = os.path.join(working_dir, f\"{dname}_test_metrics_bar.png\")\n                plt.savefig(fname)\n                plt.close()\n        except Exception as e:\n            print(f\"Error creating test metric bar for {dname}: {e}\")\n            plt.close()\n\n    # -------- print final test metrics --------\n    print(\"\\nTest-set performance:\")\n    for tag in tags:\n        for dname in experiment_data[tag]:\n            tm = experiment_data[tag][dname][\"metrics\"].get(\"test\", {})\n            if tm:\n                print(\n                    f\"{tag} | {dname}: CWA={tm['cwa']:.4f}, SWA={tm['swa']:.4f}, CVA={tm['cva']:.4f}\"\n                )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# --------------------------------------------------------------------- paths / load\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ntag, ds_key = \"no_pos_emb\", \"SPR\"\ndata = experiment_data.get(tag, {}).get(ds_key, {})\n\n# --------------------------------------------------------------------- 1) loss curves\ntry:\n    tr_losses = data.get(\"losses\", {}).get(\"train\", [])\n    val_losses = data.get(\"losses\", {}).get(\"val\", [])\n    epochs = list(range(1, len(tr_losses) + 1))\n    if tr_losses and val_losses:\n        plt.figure()\n        plt.plot(epochs, tr_losses, label=\"Train\")\n        plt.plot(epochs, val_losses, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR Loss Curves (no_pos_emb)\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_no_pos_emb_loss_curves.png\")\n        plt.savefig(fname)\n        print(\"Saved\", fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# --------------------------------------------------------------------- 2) validation accuracy metrics\ntry:\n    val_metrics = data.get(\"metrics\", {}).get(\"val\", [])\n    if val_metrics:\n        cwa = [m[\"cwa\"] for m in val_metrics]\n        swa = [m[\"swa\"] for m in val_metrics]\n        cva = [m[\"cva\"] for m in val_metrics]\n        epochs = list(range(1, len(cwa) + 1))\n        plt.figure()\n        plt.plot(epochs, cwa, label=\"CWA\")\n        plt.plot(epochs, swa, label=\"SWA\")\n        plt.plot(epochs, cva, label=\"CVA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR Validation Accuracies (no_pos_emb)\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_no_pos_emb_val_accuracies.png\")\n        plt.savefig(fname)\n        print(\"Saved\", fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy plot: {e}\")\n    plt.close()\n\n# --------------------------------------------------------------------- 3) confusion matrix on test set\ntry:\n    preds = np.array(data.get(\"predictions\", []))\n    gts = np.array(data.get(\"ground_truth\", []))\n    if preds.size and gts.size:\n        num_cls = int(max(preds.max(), gts.max()) + 1)\n        cm = np.zeros((num_cls, num_cls), dtype=int)\n        for p, g in zip(preds, gts):\n            cm[g, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR Confusion Matrix (no_pos_emb)\")\n        for i in range(num_cls):\n            for j in range(num_cls):\n                plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n        fname = os.path.join(working_dir, \"SPR_no_pos_emb_confusion_matrix.png\")\n        plt.savefig(fname)\n        print(\"Saved\", fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom itertools import product\n\n# ---------------- paths / load\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    exp = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp, tag = None, None\n\ntag = \"no_transformer_mean_pool\"\nds = \"SPR\"\nif exp is None or tag not in exp or ds not in exp[tag]:\n    print(\"Required experiment information missing, nothing to plot.\")\n    exit()\n\nedata = exp[tag][ds]\nloss_tr = edata[\"losses\"].get(\"train\", [])\nloss_val = edata[\"losses\"].get(\"val\", [])\nmetrics_val = edata[\"metrics\"].get(\"val\", [])\nmetrics_test = edata[\"metrics\"].get(\"test\", {})\npreds = np.array(edata.get(\"predictions\", []))\ngts = np.array(edata.get(\"ground_truth\", []))\n\n\n# -------- helper to get series from list of dicts\ndef ser(key):\n    return [m.get(key, np.nan) for m in metrics_val]\n\n\n# -------------------- PLOT 1 : loss curves\ntry:\n    epochs = range(1, max(len(loss_tr), len(loss_val)) + 1)\n    plt.figure()\n    if loss_tr:\n        plt.plot(epochs, loss_tr, label=\"Train\")\n    if loss_val:\n        plt.plot(epochs, loss_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR Dataset \u2013 Training vs Validation Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# -------------------- PLOT 2 : CVA curve\ntry:\n    cva = ser(\"cva\")\n    if any(~np.isnan(cva)):\n        plt.figure()\n        plt.plot(range(1, len(cva) + 1), cva, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Composite Variety Accuracy\")\n        plt.title(\"SPR Dataset \u2013 Validation CVA over Epochs\")\n        fname = os.path.join(working_dir, \"SPR_CVA_curve.png\")\n        plt.savefig(fname)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating CVA plot: {e}\")\n    plt.close()\n\n# -------------------- PLOT 3 : CWA & SWA curves\ntry:\n    cwa, swa = ser(\"cwa\"), ser(\"swa\")\n    if any(~np.isnan(cwa)) or any(~np.isnan(swa)):\n        plt.figure()\n        if any(~np.isnan(cwa)):\n            plt.plot(range(1, len(cwa) + 1), cwa, label=\"CWA\")\n        if any(~np.isnan(swa)):\n            plt.plot(range(1, len(swa) + 1), swa, label=\"SWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Weighted Accuracy\")\n        plt.title(\"SPR Dataset \u2013 Validation Weighted Accuracies\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_weighted_accuracy_curves.png\")\n        plt.savefig(fname)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating weighted accuracy plot: {e}\")\n    plt.close()\n\n# -------------------- PLOT 4 : Test metric bar chart\ntry:\n    if metrics_test:\n        keys, vals = zip(*[(k.upper(), v) for k, v in metrics_test.items()])\n        plt.figure()\n        plt.bar(keys, vals)\n        plt.ylim(0, 1)\n        plt.title(\"SPR Dataset \u2013 Test Set Metrics\")\n        fname = os.path.join(working_dir, \"SPR_test_metrics_bar.png\")\n        plt.savefig(fname)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metrics bar plot: {e}\")\n    plt.close()\n\n# -------------------- PLOT 5 : Confusion matrix\ntry:\n    if preds.size and gts.size:\n        n_cls = int(max(max(preds), max(gts)) + 1)\n        cm = np.zeros((n_cls, n_cls), dtype=int)\n        for p, g in zip(preds, gts):\n            cm[g, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\"SPR Dataset \u2013 Confusion Matrix (Test)\")\n        # annotate cells for readability\n        for i, j in product(range(n_cls), range(n_cls)):\n            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n        fname = os.path.join(working_dir, \"SPR_confusion_matrix.png\")\n        plt.savefig(fname)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n\n# -------------- print test metrics\nif metrics_test:\n    print(\"Test Metrics:\", metrics_test)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------ load experiment data ------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ntag = \"no_color_embedding\"\nds_name = \"SPR\"\nexp = experiment_data.get(tag, {}).get(ds_name, {})\n\n\n# helper to silently fetch dict keys\ndef g(path, default=None):\n    cur = exp\n    for p in path:\n        cur = cur.get(p, {})\n    return cur if cur else default\n\n\nloss_train = g([\"losses\", \"train\"], [])\nloss_val = g([\"losses\", \"val\"], [])\nval_metrics = g([\"metrics\", \"val\"], [])\ntest_metrics = g([\"metrics\", \"test\"], {})\npreds = exp.get(\"predictions\", [])\ngts = exp.get(\"ground_truth\", [])\n\n# ------------------ figure 1 : loss curves ------------------\ntry:\n    plt.figure()\n    epochs = np.arange(1, len(loss_train) + 1)\n    plt.plot(epochs, loss_train, label=\"Train\")\n    plt.plot(epochs, loss_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR No-Color-Embedding: Training vs Validation Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_loss_curves_no_color_embedding.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ------------------ figure 2 : accuracy curves ------------------\ntry:\n    if val_metrics:\n        cwa = [m[\"cwa\"] for m in val_metrics]\n        swa = [m[\"swa\"] for m in val_metrics]\n        cva = [m[\"cva\"] for m in val_metrics]\n        plt.figure()\n        plt.plot(epochs, cwa, label=\"CWA\")\n        plt.plot(epochs, swa, label=\"SWA\")\n        plt.plot(epochs, cva, label=\"CVA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR No-Color-Embedding: Validation Accuracies\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, \"SPR_accuracy_curves_no_color_embedding.png\")\n        )\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy plot: {e}\")\n    plt.close()\n\n# ------------------ figure 3 : confusion matrix ------------------\ntry:\n    if preds and gts:\n        num_cls = max(max(preds), max(gts)) + 1\n        cm = np.zeros((num_cls, num_cls), dtype=int)\n        for y, y_hat in zip(gts, preds):\n            cm[y, y_hat] += 1\n        plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted label\")\n        plt.ylabel(\"Ground truth label\")\n        plt.title(\n            \"SPR No-Color-Embedding: Confusion Matrix\\n\"\n            \"Rows: Ground Truth, Columns: Predictions\"\n        )\n        plt.savefig(\n            os.path.join(working_dir, \"SPR_confusion_matrix_no_color_embedding.png\")\n        )\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n\n# ------------------ print test metrics ------------------\nif test_metrics:\n    print(\"Test metrics:\", test_metrics)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------ paths & load\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ntag, dname = \"frozen_embeddings\", \"SPR\"\nexp = experiment_data.get(tag, {}).get(dname, {})\n\nloss_tr = exp.get(\"losses\", {}).get(\"train\", [])\nloss_val = exp.get(\"losses\", {}).get(\"val\", [])\nmetrics_val = exp.get(\"metrics\", {}).get(\"val\", [])\ntest_metrics = exp.get(\"metrics\", {}).get(\"test\", {})\nepochs = list(range(1, len(loss_tr) + 1))\n\n# ------------------------------------------------------------------ PLOT 1: loss curves\ntry:\n    plt.figure()\n    plt.plot(epochs, loss_tr, label=\"Train\")\n    plt.plot(epochs, loss_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR Loss Curves\\nLeft: Train, Right: Validation\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{dname}_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ PLOT 2: accuracy curves\ntry:\n    cwa = [m[\"cwa\"] for m in metrics_val]\n    swa = [m[\"swa\"] for m in metrics_val]\n    cva = [m[\"cva\"] for m in metrics_val]\n    plt.figure()\n    plt.plot(epochs, cwa, label=\"CWA\")\n    plt.plot(epochs, swa, label=\"SWA\")\n    plt.plot(epochs, cva, label=\"CVA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"SPR Weighted Accuracies over Epochs\\nLeft: CWA, Middle: SWA, Right: CVA\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{dname}_accuracy_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ PLOT 3: final test metrics\ntry:\n    labels = [\"CWA\", \"SWA\", \"CVA\"]\n    vals = [test_metrics.get(k.lower(), 0) for k in labels]\n    plt.figure()\n    plt.bar(labels, vals)\n    plt.ylim(0, 1)\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"SPR Test Metrics\\nBar chart of final weighted accuracies\")\n    fname = os.path.join(working_dir, f\"{dname}_test_metrics.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test metric plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ print metrics\nif test_metrics:\n    print(\"Test Metrics:\")\n    for k, v in test_metrics.items():\n        print(f\"  {k.upper()}: {v:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data[\"no_shape_embedding\"][\"SPR\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = None\n\nif exp:\n    epochs = np.arange(1, len(exp[\"losses\"][\"train\"]) + 1)\n\n    # 1) Train / Val loss curve\n    try:\n        plt.figure()\n        plt.plot(epochs, exp[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(epochs, exp[\"losses\"][\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR \u2013 Training vs Validation Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # 2) CVA over epochs\n    try:\n        cva_vals = [m[\"cva\"] for m in exp[\"metrics\"][\"val\"]]\n        test_cva = exp[\"metrics\"][\"test\"][\"cva\"]\n        plt.figure()\n        plt.plot(epochs, cva_vals, marker=\"o\", label=\"Validation CVA\")\n        plt.axhline(\n            test_cva, color=\"r\", linestyle=\"--\", label=f\"Test CVA = {test_cva:.3f}\"\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Composite Variety Accuracy\")\n        plt.title(\"SPR \u2013 CVA Progress Across Epochs\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_CVA_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CVA curve: {e}\")\n        plt.close()\n\n    # 3) Test metrics bar plot\n    try:\n        test_metrics = exp[\"metrics\"][\"test\"]\n        names = [\"CWA\", \"SWA\", \"CVA\"]\n        vals = [test_metrics[\"cwa\"], test_metrics[\"swa\"], test_metrics[\"cva\"]]\n        plt.figure()\n        plt.bar(names, vals, color=[\"steelblue\", \"orange\", \"green\"])\n        plt.ylim(0, 1)\n        plt.title(\"SPR \u2013 Test Set Weighted Accuracies\")\n        for i, v in enumerate(vals):\n            plt.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n        plt.savefig(os.path.join(working_dir, \"SPR_test_metrics_bar.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating test metrics bar: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# Helper to fetch subtree safely\ndef get_spr(exp_dict):\n    return exp_dict.get(\"monohead\", {}).get(\"SPR\", {})\n\n\nspr = get_spr(experiment_data)\n\n# 1) Loss curves -----------------------------------------------------------------\ntry:\n    losses = spr.get(\"losses\", {})\n    tr_loss = losses.get(\"train\", [])\n    val_loss = losses.get(\"val\", [])\n    if tr_loss and val_loss:\n        epochs = np.arange(1, len(tr_loss) + 1)\n        plt.figure()\n        plt.plot(epochs, tr_loss, label=\"Train Loss\")\n        plt.plot(epochs, val_loss, label=\"Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy\")\n        plt.title(\n            \"SPR Dataset \u2013 Training vs Validation Loss\\nLeft: Train, Right: Validation\"\n        )\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_loss_curve.png\")\n        plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# 2) Metric curves ---------------------------------------------------------------\ntry:\n    val_metrics = spr.get(\"metrics\", {}).get(\"val\", [])\n    if val_metrics:\n        cwa = [m[\"cwa\"] for m in val_metrics]\n        swa = [m[\"swa\"] for m in val_metrics]\n        cva = [m[\"cva\"] for m in val_metrics]\n        epochs = np.arange(1, len(cwa) + 1)\n        plt.figure()\n        plt.plot(epochs, cwa, label=\"CWA\")\n        plt.plot(epochs, swa, label=\"SWA\")\n        plt.plot(epochs, cva, label=\"CVA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\n            \"SPR Dataset \u2013 Weighted Accuracy Metrics (Validation)\\nLeft: CWA, Middle: SWA, Right: CVA\"\n        )\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_metric_curve.png\")\n        plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating metric plot: {e}\")\n    plt.close()\n\n# 3) Confusion matrix ------------------------------------------------------------\ntry:\n    preds = np.array(spr.get(\"predictions\", []))\n    gts = np.array(spr.get(\"ground_truth\", []))\n    if preds.size and gts.size:\n        classes = sorted(set(gts) | set(preds))\n        matrix = np.zeros((len(classes), len(classes)), dtype=int)\n        for t, p in zip(gts, preds):\n            matrix[t, p] += 1\n        plt.figure()\n        im = plt.imshow(matrix, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xticks(range(len(classes)), classes)\n        plt.yticks(range(len(classes)), classes)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        for i in range(len(classes)):\n            for j in range(len(classes)):\n                plt.text(\n                    j,\n                    i,\n                    matrix[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"black\",\n                    fontsize=8,\n                )\n        plt.title(\n            \"SPR Dataset \u2013 Confusion Matrix (Test)\\nLeft: Ground Truth, Right: Predictions\"\n        )\n        fname = os.path.join(working_dir, \"SPR_confusion_matrix.png\")\n        plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# iterate through experiments; only plot if structure matches expectation\nfor tag, datasets in experiment_data.items():\n    if \"SPR\" not in datasets:\n        continue\n    data = datasets[\"SPR\"]\n    # ---------- figure 1: loss curves ----------\n    try:\n        train_loss = data[\"losses\"].get(\"train\", [])\n        val_loss = data[\"losses\"].get(\"val\", [])\n        if train_loss and val_loss:\n            epochs = range(1, len(train_loss) + 1)\n            plt.figure()\n            plt.plot(epochs, train_loss, label=\"Train\")\n            plt.plot(epochs, val_loss, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(\"SPR Loss Curves\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"SPR_{tag}_loss_curves.png\")\n            plt.savefig(fname)\n            print(\"Saved\", fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ---------- figure 2: validation metrics ----------\n    try:\n        val_metrics = data[\"metrics\"].get(\"val\", [])\n        if val_metrics:\n            cwa = [m[\"cwa\"] for m in val_metrics]\n            swa = [m[\"swa\"] for m in val_metrics]\n            cva = [m[\"cva\"] for m in val_metrics]\n            epochs = range(1, len(cwa) + 1)\n            plt.figure()\n            plt.plot(epochs, cwa, label=\"CWA\")\n            plt.plot(epochs, swa, label=\"SWA\")\n            plt.plot(epochs, cva, label=\"CVA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Accuracy\")\n            plt.title(\"SPR Validation Weighted Accuracies\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"SPR_{tag}_val_metrics.png\")\n            plt.savefig(fname)\n            print(\"Saved\", fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating validation metrics plot: {e}\")\n        plt.close()\n\n    # ---------- figure 3: confusion matrix ----------\n    try:\n        preds = np.asarray(data.get(\"predictions\", []), dtype=int)\n        gt = np.asarray(data.get(\"ground_truth\", []), dtype=int)\n        if preds.size and gt.size and preds.shape == gt.shape:\n            num_cls = int(max(preds.max(), gt.max()) + 1)\n            cm = np.zeros((num_cls, num_cls), dtype=int)\n            for p, g in zip(preds, gt):\n                cm[g, p] += 1\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"Ground Truth\")\n            plt.title(\"SPR Confusion Matrix\")\n            for i in range(num_cls):\n                for j in range(num_cls):\n                    plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n            fname = os.path.join(working_dir, f\"SPR_{tag}_confusion_matrix.png\")\n            plt.savefig(fname)\n            print(\"Saved\", fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix plot: {e}\")\n        plt.close()\n"], "plot_plan": ["We load experiment_data.npy from the working directory, inspect all experiment tags (different model runs) and the dataset keys each tag contains (e.g. \u201cSPR\u201d).  \nFor every dataset we aggregate per-epoch training loss, validation loss, and validation CWA/SWA/CVA for each tag, and also store the final test metrics.  \nWe then create up to three plots per dataset: (1) a two-panel figure showing train and validation loss curves; (2) a three-panel figure showing CWA, SWA, and CVA curves; (3) a bar chart comparing the three test metrics across tags.  \nEach figure is wrapped in its own try-except block, titled clearly, saved with descriptive names (dataset + plot type), and closed afterward to avoid memory leaks.  \nIf many tags exist, all of them are plotted together so comparisons are easy; epochs are inferred from the length of the stored loss arrays.  \nAll plotting follows the mandated imports, uses only data present in experiment_data.npy, and writes files into working_dir.  \nFinally, we print a concise test-set performance table so users can read numbers directly without opening the images.", "We will load the saved experiment_data, extract the training/validation losses and validation accuracy metrics recorded at each epoch, and create clear line plots for them; this gives quick insight into convergence and generalisation. Next, we will compute a confusion-matrix from the stored ground-truth and prediction arrays of the test set to visualise class-wise performance. Each figure is wrapped in its own try-except block, saved under a descriptive name (containing dataset + plot type) inside working_dir, and the figure is closed afterwards. All plotting is performed using plain matplotlib, with appropriate titles/subtitles that mention the dataset (SPR) and model tag (no_pos_emb). At most three figures are produced, well within the five-figure limit. The script starts with the required imports, constructs working_dir, handles absent files gracefully, and prints basic confirmations so the user can verify the outputs were written successfully.", "We first load experiment_data.npy saved by the training script, fetch the entry under the tag \u201cno_transformer_mean_pool\u201d/\u201cSPR\u201d, and extract (i) training and validation loss lists, (ii) validation metrics list of dicts (cva, cwa, swa for every epoch), and (iii) test\u2010set metrics plus predictions and ground truths. We then make at most five figures: 1) train vs. validation loss across epochs; 2) composite variety accuracy (CVA) curve across epochs; 3) color & shape weighted accuracies (CWA and SWA) across epochs; 4) bar chart summarising the three test metrics; 5) a confusion-matrix heat-map of test predictions vs. labels. Each figure is wrapped in its own try-except block, is titled clearly, saved in working_dir with descriptive names, and the figure is always closed. Only data that exist in experiment_data.npy are used, and if any piece is missing we silently skip the corresponding plot. After plotting we also print the test CWA, SWA and CVA so a quick numeric inspection is possible.", "We will load the saved experiment_data.npy, extract the per-epoch training/validation losses as well as validation CWA/SWA/CVA arrays, and read the final test metrics together with the full prediction and ground-truth vectors. Three plots will be produced inside independent try-except blocks: (1) a Training vs. Validation loss curve, (2) validation accuracy curves for CWA, SWA and CVA, and (3) a confusion-matrix heat-map for the test split (rows = ground-truth classes, columns = predicted classes). Each figure will carry a descriptive title that states the dataset (SPR) and the ablation tag (No-Color-Embedding); subtitles/axis labels will clarify what is shown. All figures are saved into the standard working directory with descriptive file names and then closed. Finally, the script prints the numerical test metrics so they are visible in logs. Only information present in experiment_data.npy is accessed; no synthetic values are generated. The code obeys all style and resource constraints given.", "The script loads the previously saved experiment_data.npy, pulls out the losses and metric histories for the \u201cfrozen_embeddings / SPR\u201d run, and prepares three concise visualizations: (1) a train-vs-validation loss curve across epochs; (2) a multi-line accuracy curve plotting CWA, SWA, and CVA over the same epochs; (3) a final bar chart summarising the three test accuracies.  Each figure creation is wrapped in its own try-except block, with explicit titles, subtitles, and descriptive filenames saved to working_dir.  We restrict the number of figures to three\u2014well under the five-figure cap\u2014and close every figure whether or not an exception occurs.  After plotting, the script prints the numerical test metrics so the user can read them directly in the console.  Nothing is simulated: every value comes from experiment_data.npy.  Standard matplotlib is used without extra styling, and the code is kept concise per the guidelines.", "We will load experiment_data.npy, locate the \u201cno_shape_embedding / SPR\u201d section, and pull out epoch-wise training losses, validation losses, and validation metrics (CWA, SWA, CVA) plus the final test metrics. Three plots will be made\u2014loss curves (train vs. val), CVA progress (val per epoch with a dashed horizontal line for the final test CVA), and a bar chart comparing the three test accuracies. Each plot is wrapped in an independent try-except block, given a clear title that includes the dataset name, then saved to working_dir under descriptive filenames (e.g. \u201cSPR_loss_curve.png\u201d). Figures are always closed after saving or upon error. At most five figures are produced, satisfying the requirement. No data are fabricated; everything comes directly from experiment_data.npy.", "We will load experiment_data.npy, extract the \u201cmonohead / SPR\u201d subtree and inspect available arrays. First we plot the per-epoch training and validation loss curves to visualise convergence. Next we gather the stored validation metrics (CWA, SWA, CVA) and draw them on a single plot so users can compare progress of the three weighted accuracies. Finally we build a confusion matrix between test ground-truth labels and saved predictions, display it as a heat-map, and attach colour-bar plus text annotations for clarity. Each figure is wrapped in its own try-except block, saved into the working directory with descriptive names, and closed afterwards. No synthetic or missing data are fabricated; every value comes directly from experiment_data.npy. At most three figures are produced, satisfying the five-figure cap. All code uses basic matplotlib with clear titles and subtitles that mention the SPR dataset and the split being visualised. Below is the concise implementation.", null, "We load experiment_data.npy and iterate over any experiment tags (e.g. \u201cfixed_sinusoidal_pos_encoding\u201d) that contain an \u201cSPR\u201d dataset entry. From the nested dict we pull the per-epoch training/validation losses plus the list of validation metrics dictionaries (CWA, SWA, CVA) and the final test predictions/ground-truth. Three figures are generated: (1) training vs. validation loss across epochs; (2) validation CWA, SWA and CVA across epochs; (3) a confusion-matrix style heat-map showing counts of test predictions versus ground truth. Each figure is wrapped in its own try-except so that one failure does not stop others, and every figure is closed whether or not an error occurs. Filenames always include the dataset name and plot type for clarity and are saved into working_dir. No synthetic data is invented\u2014only the contents of experiment_data.npy are visualised. At the end, the script prints the location of each saved plot so users can easily locate them."], "ablation_name": [null, "No-Position Embeddings", "No-Transformer (Mean-Pooling Baseline)", "No-Color-Embedding (Shape-Only Input)", "Frozen-Embeddings (Non-Trainable Shape & Color Embeddings)", "No-Shape-Embedding (Color-Only Input)", "Single-Head Self-Attention (MonoHead)", "Concat-Fusion Embeddings (No Early Additive Fusion)", "Fixed-Sinusoidal Position Encoding"], "hyperparam_name": [null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false], "parse_metrics_plan": ["The script loads the saved numpy dictionary, iterates through every experiment\ntag and dataset, and extracts the stored loss and accuracy information. It\nreports the final training loss, final validation loss, the best validation\naccuracies (selected by highest composite-variety accuracy), and the test\naccuracies. Each metric is printed with an explicit description immediately\nafter the dataset name, and no figures or extraneous text are produced.", "The script will load the saved NumPy dictionary from the \u201cworking\u201d directory,\niterate through every experiment tag and dataset contained in it, and pick the\nlast (i.e., final) entry for each tracked list of losses or validation metrics,\ntogether with the single stored test metrics object. For every dataset it prints\nthe dataset name (including the experiment tag for clarity) and then the final\ntraining loss, final validation loss, final validation CWA/SWA/CVA, and the test\nCWA/SWA/CVA. All code is placed at global scope so it runs immediately when the\nfile is executed.", "The script will load the saved numpy dictionary from the \u201cworking\u201d directory,\niterate through every experiment and dataset, compute the final training loss,\nthe best validation loss, the best\u2010so\u2010far validation accuracies (CWA, SWA, CVA\nchosen by the highest CVA), and finally the test accuracies that were stored\nafter training. The results are printed in a readable form: first the dataset\nname, then each metric preceded by an explicit, descriptive label. No plotting\nis performed and the code runs immediately at import time.", "The script will load the saved experiment_data.npy from the working directory,\niterate through every experiment tag it finds, and for each internal dataset\n(e.g., \u201cSPR\u201d) retrieve the stored losses and metrics.  It reports the last\n(i.e., final) value in each list for training loss, validation loss, and every\nvalidation-time metric, and it prints the single dictionary of test-time metrics\nthat was saved at the end of training.  Each printed line explicitly states both\nthe dataset and the metric name so there is no ambiguity.  No plotting code or\nentry-point guard is used; the code executes immediately when run.", "The script will immediately load the saved NumPy file from the working\ndirectory, identify the experiment tag (e.g., \u201cfrozen_embeddings\u201d), and then\nextract the stored metrics.   For the training split it prints the final-epoch\ntraining loss (and training metrics if present).   For the validation split it\nlocates the epoch with the highest composite-variety accuracy (CVA) and reports\nthat epoch\u2019s validation loss plus its three accuracies.   Finally, it prints the\nsingle set of metrics stored for the test split.   Everything is executed at the\nglobal scope so the file runs directly without any entry-point guard.", "The script loads the saved numpy dictionary, navigates through the nested\nstructure to reach the \u201cSPR\u201d dataset, and then prints the final\ntraining/validation losses, the best-achieved validation accuracies (identified\nby the highest composite-variety accuracy), and the single set of test\naccuracies that were stored. Metric names are explicitly labeled (e.g.,\n\u201ctraining loss\u201d, \u201cbest validation CWA\u201d, \u201ctest CVA\u201d) to satisfy the formatting\nrules. Everything is executed at the top level so the file runs immediately when\ninvoked.", "The script will load the saved numpy file, navigate the nested dictionaries to\nretrieve the stored losses and accuracies, and then print a concise summary. For\nthe training split we report the loss from the last epoch, for the validation\nsplit we report the best (minimum for loss, maximum for accuracies) values\nacross epochs, and for the test split we directly print the stored metrics. All\nexecution happens at the global scope, so the code runs immediately when\nexecuted without any special entry point.", "The script will find the NumPy file in the working directory, load it into a\nPython object, locate the \u201cSPR\u201d sub-dictionary, and then pull out the last\n(i.e., final) recorded value for every stored loss and evaluation metric. It\nprints the dataset name first, followed by clearly labelled lines such as \u201cFinal\ntraining loss\u201d, \u201cFinal validation composite-variety accuracy\u201d, etc. Only the\nfinal values are shown and no figures are produced, so the code can be run as-is\nto obtain a concise textual summary of the experiment.", "We first load the saved numpy file from the \u201cworking\u201d directory and turn it back\ninto a Python dict.   For every experiment tag (here only\n\u201cfixed_sinusoidal_pos_encoding\u201d) and its contained dataset (\u201cSPR\u201d), we pull out\nthe recorded lists of training / validation losses and metrics plus the single\ntest metrics dict.   For training and validation we report the best value\n(minimum for losses, maximum for each accuracy-type metric).   For the test\nsplit we simply report the stored final values.   All values are printed with an\nexplicit dataset name and a descriptive metric label, and the script runs\nimmediately without needing a special entry point."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ------------------------------------------------------------------------- load data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------------- helpers\ndef safe_last(lst, default=None):\n    \"\"\"Return last element of a list or default if empty/None.\"\"\"\n    if lst:\n        return lst[-1]\n    return default\n\n\ndef best_by_cva(val_metrics):\n    \"\"\"Return entry with highest composite variety accuracy.\"\"\"\n    if not val_metrics:\n        return {}\n    return max(val_metrics, key=lambda d: d.get(\"cva\", float(\"-inf\")))\n\n\n# ------------------------------------------------------------------------- extract & print\nfor tag, datasets in experiment_data.items():  # e.g. 'shape_color_transformer'\n    for dset_name, dset in datasets.items():  # e.g. 'SPR'\n        print(f\"{dset_name} dataset\")\n\n        # -------- losses\n        train_loss = safe_last(dset.get(\"losses\", {}).get(\"train\", []))\n        val_loss = safe_last(dset.get(\"losses\", {}).get(\"val\", []))\n        if train_loss is not None:\n            print(f\"train loss: {train_loss:.6f}\")\n        if val_loss is not None:\n            print(f\"validation loss: {val_loss:.6f}\")\n\n        # -------- validation metrics (choose best by CVA)\n        val_metrics_list = dset.get(\"metrics\", {}).get(\"val\", [])\n        best_val = best_by_cva(val_metrics_list)\n        if best_val:\n            print(f\"best validation color weighted accuracy: {best_val['cwa']:.6f}\")\n            print(f\"best validation shape weighted accuracy: {best_val['swa']:.6f}\")\n            print(f\"best validation composite variety accuracy: {best_val['cva']:.6f}\")\n\n        # -------- test metrics\n        test_metrics = dset.get(\"metrics\", {}).get(\"test\", {})\n        if test_metrics:\n            print(\n                f\"test color weighted accuracy: {test_metrics.get('cwa', float('nan')):.6f}\"\n            )\n            print(\n                f\"test shape weighted accuracy: {test_metrics.get('swa', float('nan')):.6f}\"\n            )\n            print(\n                f\"test composite variety accuracy: {test_metrics.get('cva', float('nan')):.6f}\"\n            )\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------------- load data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find '{file_path}'. Make sure the file exists.\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# --------------------------------------------------------------------------- helper for safe extraction\ndef safe_last(lst):\n    \"\"\"Return the last element of a list or None if the list is empty.\"\"\"\n    return lst[-1] if isinstance(lst, (list, tuple)) and len(lst) > 0 else None\n\n\n# --------------------------------------------------------------------------- print metrics\nfor exp_tag, datasets in experiment_data.items():  # e.g. 'no_pos_emb'\n    for ds_name, ds_content in datasets.items():  # e.g. 'SPR'\n        print(f\"Dataset: {ds_name} ({exp_tag})\")\n\n        # Training and validation losses\n        train_loss = safe_last(ds_content.get(\"losses\", {}).get(\"train\", []))\n        val_loss = safe_last(ds_content.get(\"losses\", {}).get(\"val\", []))\n        if train_loss is not None:\n            print(f\"train loss: {train_loss:.4f}\")\n        if val_loss is not None:\n            print(f\"validation loss: {val_loss:.4f}\")\n\n        # Validation metrics (last epoch)\n        val_metrics = safe_last(ds_content.get(\"metrics\", {}).get(\"val\", []))\n        if val_metrics:\n            if \"cwa\" in val_metrics:\n                print(f\"validation CWA: {val_metrics['cwa']:.4f}\")\n            if \"swa\" in val_metrics:\n                print(f\"validation SWA: {val_metrics['swa']:.4f}\")\n            if \"cva\" in val_metrics:\n                print(f\"validation CVA: {val_metrics['cva']:.4f}\")\n\n        # Test metrics\n        test_metrics = ds_content.get(\"metrics\", {}).get(\"test\", {})\n        if test_metrics:\n            if \"cwa\" in test_metrics:\n                print(f\"test CWA: {test_metrics['cwa']:.4f}\")\n            if \"swa\" in test_metrics:\n                print(f\"test SWA: {test_metrics['swa']:.4f}\")\n            if \"cva\" in test_metrics:\n                print(f\"test CVA: {test_metrics['cva']:.4f}\")\n\n        # Separator for readability between datasets\n        print()\n", "import os\nimport numpy as np\n\n# ----------------- locate and load the saved experiment data -------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nnpy_file = os.path.join(working_dir, \"experiment_data.npy\")\nif not os.path.isfile(npy_file):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy in {working_dir}\")\n\nexperiment_data = np.load(npy_file, allow_pickle=True).item()\n\n\n# ----------------- helper to find the best validation epoch --------------\ndef _best_val_epoch(val_metrics):\n    \"\"\"\n    Return the index of the epoch with the highest composite variety accuracy (CVA).\n    If the list is empty, return None.\n    \"\"\"\n    if not val_metrics:\n        return None\n    cva_values = [m.get(\"cva\", -1) for m in val_metrics]\n    return int(np.argmax(cva_values))\n\n\n# ----------------- iterate and print --------------------------------------\nfor exp_name, exp_content in experiment_data.items():\n    # Each experiment can contain several datasets (e.g. \"SPR\")\n    for dataset_name, dataset_content in exp_content.items():\n        losses = dataset_content.get(\"losses\", {})\n        metrics = dataset_content.get(\"metrics\", {})\n\n        train_losses = losses.get(\"train\", [])\n        val_losses = losses.get(\"val\", [])\n\n        # Determine final and best values\n        final_train_loss = train_losses[-1] if train_losses else None\n        best_val_loss = min(val_losses) if val_losses else None\n\n        val_metrics = metrics.get(\"val\", [])\n        best_idx = _best_val_epoch(val_metrics)\n        best_val = val_metrics[best_idx] if best_idx is not None else {}\n\n        test_metrics = metrics.get(\"test\", {})\n\n        # ----------------- printing section -----------------\n        print(dataset_name)  # dataset header\n\n        if final_train_loss is not None:\n            print(f\"final training loss: {final_train_loss:.4f}\")\n        if best_val_loss is not None:\n            print(f\"best validation loss: {best_val_loss:.4f}\")\n\n        if best_val:\n            print(f\"best validation color-weighted accuracy: {best_val['cwa']:.4f}\")\n            print(f\"best validation shape-weighted accuracy: {best_val['swa']:.4f}\")\n            print(f\"best validation composite variety accuracy: {best_val['cva']:.4f}\")\n\n        if test_metrics:\n            print(f\"test color-weighted accuracy: {test_metrics['cwa']:.4f}\")\n            print(f\"test shape-weighted accuracy: {test_metrics['swa']:.4f}\")\n            print(f\"test composite variety accuracy: {test_metrics['cva']:.4f}\")\n\n        print()  # blank line for readability between datasets\n", "import os\nimport numpy as np\n\n# ----------------------------------------------------------------------------- load data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n\n# ----------------------------------------------------------------------------- helper to print nicely\ndef safe_last(lst, default=\"N/A\"):\n    return lst[-1] if lst else default\n\n\n# ----------------------------------------------------------------------------- iterate and display\nfor exp_tag, datasets in experiment_data.items():\n    # There could be multiple datasets under a tag, though in the original code it's only \"SPR\"\n    for dataset_name, data in datasets.items():\n        print(f\"\\nDataset: {dataset_name}  (experiment tag: {exp_tag})\")\n\n        # ------------------------- losses\n        train_loss_final = safe_last(data.get(\"losses\", {}).get(\"train\", []))\n        val_loss_final = safe_last(data.get(\"losses\", {}).get(\"val\", []))\n        if train_loss_final != \"N/A\":\n            print(f\"  training loss: {train_loss_final}\")\n        if val_loss_final != \"N/A\":\n            print(f\"  validation loss: {val_loss_final}\")\n\n        # ------------------------- validation metrics\n        val_metrics_list = data.get(\"metrics\", {}).get(\"val\", [])\n        if val_metrics_list:\n            final_val_metrics = val_metrics_list[-1]\n            if \"cwa\" in final_val_metrics:\n                print(\n                    f\"  validation color weighted accuracy: {final_val_metrics['cwa']}\"\n                )\n            if \"swa\" in final_val_metrics:\n                print(\n                    f\"  validation shape weighted accuracy: {final_val_metrics['swa']}\"\n                )\n            if \"cva\" in final_val_metrics:\n                print(\n                    f\"  validation composite variety accuracy: {final_val_metrics['cva']}\"\n                )\n\n        # ------------------------- test metrics\n        test_metrics = data.get(\"metrics\", {}).get(\"test\", {})\n        if test_metrics:\n            if \"cwa\" in test_metrics:\n                print(f\"  test color weighted accuracy: {test_metrics['cwa']}\")\n            if \"swa\" in test_metrics:\n                print(f\"  test shape weighted accuracy: {test_metrics['swa']}\")\n            if \"cva\" in test_metrics:\n                print(f\"  test composite variety accuracy: {test_metrics['cva']}\")\n", "import os\nimport numpy as np\n\n# --------------------------------------------------------------------\n# 0. Locate and load the saved experiment data\n# --------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# --------------------------------------------------------------------\n# 1. Detect the (single) experiment tag and the SPR dataset section\n# --------------------------------------------------------------------\nif len(experiment_data) != 1:\n    raise RuntimeError(\"Expected exactly one experiment entry.\")\ntag = next(iter(experiment_data.keys()))\nspr = experiment_data[tag][\"SPR\"]\n\n# Convenience handles\ntrain_losses = spr[\"losses\"][\"train\"]  # list of floats\nval_losses = spr[\"losses\"][\"val\"]  # list of floats\nval_metrics = spr[\"metrics\"][\"val\"]  # list of dicts\ntest_metrics = spr[\"metrics\"][\"test\"]  # single dict\n\n# --------------------------------------------------------------------\n# 2. TRAIN: final-epoch values\n# --------------------------------------------------------------------\nprint(\"Training Dataset:\")\nif train_losses:\n    final_train_loss = train_losses[-1]\n    print(f\"training loss: {final_train_loss:.4f}\")\nelse:\n    print(\"training loss: N/A\")\n\nif spr[\"metrics\"][\"train\"]:\n    final_train_metrics = spr[\"metrics\"][\"train\"][-1]\n    for name, val in final_train_metrics.items():\n        print(f\"training {name}: {val:.4f}\")\n\n# --------------------------------------------------------------------\n# 3. VALIDATION: best epoch by highest CVA\n# --------------------------------------------------------------------\nprint(\"\\nValidation Dataset:\")\nif val_metrics:\n    # Determine the epoch with the best composite-variety accuracy\n    best_idx = max(range(len(val_metrics)), key=lambda i: val_metrics[i][\"cva\"])\n    best_val_loss = val_losses[best_idx] if best_idx < len(val_losses) else None\n    best_vals = val_metrics[best_idx]\n\n    if best_val_loss is not None:\n        print(f\"validation loss: {best_val_loss:.4f}\")\n    for name, val in best_vals.items():\n        print(f\"validation {name}: {val:.4f}\")\nelse:\n    print(\"No validation metrics found.\")\n\n# --------------------------------------------------------------------\n# 4. TEST: single stored result\n# --------------------------------------------------------------------\nprint(\"\\nTest Dataset:\")\nif \"losses\" in spr and \"test\" in spr[\"losses\"]:\n    # In case a test loss was stored similarly to train/val\n    test_loss = spr[\"losses\"][\"test\"]\n    print(f\"test loss: {test_loss:.4f}\")\n\nfor name, val in test_metrics.items():\n    print(f\"test {name}: {val:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------- Load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------- Iterate and report\nfor exp_name, exp_dict in experiment_data.items():  # e.g. \"no_shape_embedding\"\n    for dataset_name, data in exp_dict.items():  # e.g. \"SPR\"\n        print(f\"Dataset: {dataset_name}\")\n\n        # ----- losses\n        tr_losses = data[\"losses\"].get(\"train\", [])\n        val_losses = data[\"losses\"].get(\"val\", [])\n\n        if tr_losses:\n            print(f\"training loss: {tr_losses[-1]:.4f}\")\n        if val_losses:\n            print(f\"validation loss: {val_losses[-1]:.4f}\")\n\n        # ----- validation metrics (pick epoch with best CVA)\n        val_metrics = data[\"metrics\"].get(\"val\", [])\n        if val_metrics:\n            best_idx = max(range(len(val_metrics)), key=lambda i: val_metrics[i][\"cva\"])\n            best_val = val_metrics[best_idx]\n            print(f\"best validation CWA: {best_val['cwa']:.4f}\")\n            print(f\"best validation SWA: {best_val['swa']:.4f}\")\n            print(f\"best validation CVA: {best_val['cva']:.4f}\")\n\n        # ----- test metrics\n        test_metrics = data[\"metrics\"].get(\"test\", {})\n        if test_metrics:\n            print(f\"test CWA: {test_metrics.get('cwa', float('nan')):.4f}\")\n            print(f\"test SWA: {test_metrics.get('swa', float('nan')):.4f}\")\n            print(f\"test CVA: {test_metrics.get('cva', float('nan')):.4f}\")\n\n        print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------ load\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------ navigate\nexp = experiment_data[\"monohead\"][\"SPR\"]\n\n# ---------------------------- TRAIN\ntrain_losses = exp[\"losses\"].get(\"train\", [])\nif train_losses:\n    final_train_loss = train_losses[-1]\n    print(\"Training dataset:\")\n    print(\"final training loss:\", final_train_loss)\n    print()  # empty line for readability\n\n# ---------------------------- VALIDATION\nval_losses = exp[\"losses\"].get(\"val\", [])\nval_metrics = exp[\"metrics\"].get(\"val\", [])\n\nif val_losses or val_metrics:\n    print(\"Validation dataset:\")\n    if val_losses:\n        best_val_loss = min(val_losses)\n        print(\"best validation loss:\", best_val_loss)\n\n    # helper to extract best (max-value) metric\n    def best_metric(metric_name):\n        return max(m[metric_name] for m in val_metrics)\n\n    if val_metrics:\n        print(\"best validation color-weighted accuracy:\", best_metric(\"cwa\"))\n        print(\"best validation shape-weighted accuracy:\", best_metric(\"swa\"))\n        print(\"best validation composite-variety accuracy:\", best_metric(\"cva\"))\n    print()\n\n# ---------------------------- TEST\ntest_metrics = exp[\"metrics\"].get(\"test\", {})\nif test_metrics:\n    print(\"Test dataset:\")\n    # test loss was not saved in the provided script; print only available metrics\n    if \"loss\" in exp[\"losses\"]:  # in case it exists\n        print(\"test loss:\", exp[\"losses\"][\"loss\"])\n    print(\"test color-weighted accuracy:\", test_metrics.get(\"cwa\"))\n    print(\"test shape-weighted accuracy:\", test_metrics.get(\"swa\"))\n    print(\"test composite-variety accuracy:\", test_metrics.get(\"cva\"))\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------------\n# locate and load the saved experiment dictionary\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------------\n# iterate over every top-level experiment tag (e.g. 'concat_fusion')\nfor tag, tag_dict in experiment_data.items():\n    # inside each tag we may have multiple datasets \u2013 here it's just 'SPR'\n    for dataset_name, dataset_dict in tag_dict.items():\n        print(dataset_name)  # print dataset name first\n\n        # ---------------- losses ----------------\n        losses = dataset_dict.get(\"losses\", {})\n        if losses.get(\"train\"):\n            tr_loss = losses[\"train\"][-1]\n            print(f\"Final training loss: {tr_loss:.4f}\")\n        if losses.get(\"val\"):\n            val_loss = losses[\"val\"][-1]\n            print(f\"Final validation loss: {val_loss:.4f}\")\n\n        # ---------------- validation metrics ----------------\n        val_metrics_list = dataset_dict.get(\"metrics\", {}).get(\"val\", [])\n        if val_metrics_list:\n            last_val = val_metrics_list[-1]\n            print(f\"Final validation color-weighted accuracy: {last_val['cwa']:.4f}\")\n            print(f\"Final validation shape-weighted accuracy: {last_val['swa']:.4f}\")\n            print(f\"Final validation composite-variety accuracy: {last_val['cva']:.4f}\")\n\n        # ---------------- test metrics ----------------\n        test_metrics = dataset_dict.get(\"metrics\", {}).get(\"test\", {})\n        if test_metrics:\n            print(f\"Test color-weighted accuracy: {test_metrics['cwa']:.4f}\")\n            print(f\"Test shape-weighted accuracy: {test_metrics['swa']:.4f}\")\n            print(f\"Test composite-variety accuracy: {test_metrics['cva']:.4f}\")\n\n        # add a blank line between datasets (if ever more than one)\n        print()\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------ load saved data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------ helper\ndef print_metric(dataset_name: str, metric_name: str, value):\n    print(f\"{dataset_name}: {metric_name}: {value:.4f}\")\n\n\n# ------------------------------------------------------------------ iterate and report\nfor tag, datasets in experiment_data.items():\n    for ds_name, content in datasets.items():  # ds_name should be 'SPR'\n        losses = content.get(\"losses\", {})\n        metrics = content.get(\"metrics\", {})\n\n        # ----------------------------- training\n        if losses.get(\"train\"):\n            best_train_loss = min(losses[\"train\"])\n            print_metric(\"Training\", \"training loss\", best_train_loss)\n        if metrics.get(\"train\"):  # usually empty in this script\n            best_train_metrics = {\n                k: max(m[k] for m in metrics[\"train\"]) for k in metrics[\"train\"][0]\n            }\n            for k, v in best_train_metrics.items():\n                full_name = f\"training {k}\"\n                print_metric(\"Training\", full_name, v)\n\n        # ----------------------------- validation\n        if losses.get(\"val\"):\n            best_val_loss = min(losses[\"val\"])\n            print_metric(\"Validation\", \"validation loss\", best_val_loss)\n        if metrics.get(\"val\"):\n            best_val_metrics = {\n                k: max(m[k] for m in metrics[\"val\"]) for k in metrics[\"val\"][0]\n            }\n            for k, v in best_val_metrics.items():\n                full_name = f\"validation {k}\"\n                print_metric(\"Validation\", full_name, v)\n\n        # ----------------------------- test (single entry)\n        if \"test\" in metrics:\n            test_metrics = metrics[\"test\"]\n            print_metric(\"Test\", \"test loss\", content[\"losses\"].get(\"test\", np.nan))\n            for k, v in test_metrics.items():\n                full_name = f\"test {k}\"\n                print_metric(\"Test\", full_name, v)\n"], "parse_term_out": ["['SPR dataset', '\\n', 'train loss: 0.010693', '\\n', 'validation loss: 0.008393',\n'\\n', 'best validation color weighted accuracy: 0.996950', '\\n', 'best\nvalidation shape weighted accuracy: 0.996628', '\\n', 'best validation composite\nvariety accuracy: 0.996785', '\\n', 'test color weighted accuracy: 0.635311',\n'\\n', 'test shape weighted accuracy: 0.699116', '\\n', 'test composite variety\naccuracy: 0.667967', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Dataset: SPR (no_pos_emb)', '\\n', 'train loss: 0.1671', '\\n', 'validation\nloss: 0.1699', '\\n', 'validation CWA: 0.9477', '\\n', 'validation SWA: 0.9447',\n'\\n', 'validation CVA: 0.9461', '\\n', 'test CWA: 0.6290', '\\n', 'test SWA:\n0.6858', '\\n', 'test CVA: 0.6581', '\\n', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['SPR', '\\n', 'final training loss: 0.5556', '\\n', 'best validation loss:\n0.5574', '\\n', 'best validation color-weighted accuracy: 0.7090', '\\n', 'best\nvalidation shape-weighted accuracy: 0.7140', '\\n', 'best validation composite\nvariety accuracy: 0.7116', '\\n', 'test color-weighted accuracy: 0.5970', '\\n',\n'test shape-weighted accuracy: 0.6296', '\\n', 'test composite variety accuracy:\n0.6137', '\\n', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR  (experiment tag: no_color_embedding)', '\\n', '  training loss:\n0.10732582573890687', '\\n', '  validation loss: 0.10419194822311402', '\\n', '\nvalidation color weighted accuracy: 0.9743761820511256', '\\n', '  validation\nshape weighted accuracy: 0.9729101267294501', '\\n', '  validation composite\nvariety accuracy: 0.9736254576846367', '\\n', '  test color weighted accuracy:\n0.6299030778111993', '\\n', '  test shape weighted accuracy: 0.6905376032459064',\n'\\n', '  test composite variety accuracy: 0.6609362484796345', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['Training Dataset:', '\\n', 'training loss: 0.0087', '\\n', '\\nValidation\nDataset:', '\\n', 'validation loss: 0.0100', '\\n', 'validation cwa: 0.9972',\n'\\n', 'validation swa: 0.9967', '\\n', 'validation cva: 0.9970', '\\n', '\\nTest\nDataset:', '\\n', 'test cwa: 0.6347', '\\n', 'test swa: 0.6983', '\\n', 'test cva:\n0.6673', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR', '\\n', 'training loss: 0.3100', '\\n', 'validation loss: 0.3046',\n'\\n', 'best validation CWA: 0.8801', '\\n', 'best validation SWA: 0.8865', '\\n',\n'best validation CVA: 0.8834', '\\n', 'test CWA: 0.6043', '\\n', 'test SWA:\n0.6561', '\\n', 'test CVA: 0.6308', '\\n', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['Training dataset:', '\\n', 'final training loss:', ' ', '0.03786436207294464',\n'\\n', '\\n', 'Validation dataset:', '\\n', 'best validation loss:', ' ',\n'0.038275702542066574', '\\n', 'best validation color-weighted accuracy:', ' ',\n'0.9895064364590324', '\\n', 'best validation shape-weighted accuracy:', ' ',\n'0.989652366003953', '\\n', 'best validation composite-variety accuracy:', ' ',\n'0.989581162742238', '\\n', '\\n', 'Test dataset:', '\\n', 'test color-weighted\naccuracy:', ' ', '0.6319691307386139', '\\n', 'test shape-weighted accuracy:', '\n', '0.6950586871467903', '\\n', 'test composite-variety accuracy:', ' ',\n'0.664258803286956', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['SPR', '\\n', 'Final training loss: 0.0116', '\\n', 'Final validation loss:\n0.0071', '\\n', 'Final validation color-weighted accuracy: 0.9976', '\\n', 'Final\nvalidation shape-weighted accuracy: 0.9972', '\\n', 'Final validation composite-\nvariety accuracy: 0.9974', '\\n', 'Test color-weighted accuracy: 0.6348', '\\n',\n'Test shape-weighted accuracy: 0.6987', '\\n', 'Test composite-variety accuracy:\n0.6675', '\\n', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Training: training loss: 0.0134', '\\n', 'Validation: validation loss: 0.0130',\n'\\n', 'Validation: validation cwa: 0.9961', '\\n', 'Validation: validation swa:\n0.9955', '\\n', 'Validation: validation cva: 0.9958', '\\n', 'Test: test loss:\nnan', '\\n', 'Test: test cwa: 0.6341', '\\n', 'Test: test swa: 0.6978', '\\n',\n'Test: test cva: 0.6667', '\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']"], "parse_exc_type": [null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
