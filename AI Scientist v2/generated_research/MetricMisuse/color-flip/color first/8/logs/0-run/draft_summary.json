{
  "Experiment_description": "The experiment involves mapping glyphs into 2D points using shape and color indices and clustering them with K-Means to extract features. These features are used to train a one-hidden-layer MLP for sequence classification. Evaluation metrics like CWA, SWA, and CSHM are tracked.",
  "Significance": "These experiments are crucial as they establish a baseline for glyph-based sequence classification using dimensionality reduction and clustering. The insights gained can guide future improvements and expansions by understanding how well basic feature extraction and classification work in this setup.",
  "Description": "Glyphs are mapped into two-dimensional points based on shape and color indices and clustered using K-Means. These clusters are transformed into histograms, augmented with shape and color counts, and used to train a simple MLP with cross-entropy loss. Evaluation metrics are computed each epoch to analyze performance.",
  "List_of_included_plots": [
    {
      "path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_9b78000dea1d40889e99e48a9889b112_proc_1723175/spr_bench_loss_curves.png",
      "description": "The plot shows the training and validation cross-entropy loss over epochs.",
      "analysis": "The consistent decline in both training and validation loss suggests effective learning without overfitting, indicating the model's ability to generalize from training data."
    },
    {
      "path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_9b78000dea1d40889e99e48a9889b112_proc_1723175/spr_bench_weighted_accuracies.png",
      "description": "This plot presents the validation weighted accuracies for CWA, SWA, and CSHM.",
      "analysis": "The improvements in weighted accuracies around epoch 8 highlight a significant enhancement in model performance, reflecting better pattern recognition capabilities."
    },
    {
      "path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_9b78000dea1d40889e99e48a9889b112_proc_1723175/spr_bench_confusion_matrix.png",
      "description": "The confusion matrix for the test set reveals the distribution of predicted versus true labels.",
      "analysis": "The high accuracy in the confusion matrix indicates effective class differentiation, with most predictions aligning with true labels, affirming the model's classification capabilities."
    }
  ],
  "Key_numerical_results": [
    {
      "result": 1.3635,
      "description": "Final training loss",
      "analysis": "The relatively low final training loss indicates that the model has effectively learned the training data."
    },
    {
      "result": 1.3603,
      "description": "Final validation loss",
      "analysis": "The close proximity of validation loss to training loss suggests that the model generalizes well, with no significant overfitting."
    },
    {
      "result": 0.335,
      "description": "Final validation colour-weighted accuracy",
      "analysis": "The colour-weighted accuracy measures the model's performance in classifying based on color features, with a moderate final score indicating room for improvement."
    },
    {
      "result": 0.339,
      "description": "Final validation shape-weighted accuracy",
      "analysis": "The shape-weighted accuracy reflects the model's ability to classify based on shape features, showing similar performance to colour-weighted accuracy."
    },
    {
      "result": 0.337,
      "description": "Final validation harmonic mean accuracy",
      "analysis": "This metric provides a balance between color and shape weighted accuracies, indicating overall moderate classification performance."
    },
    {
      "result": 0.29,
      "description": "Final test classification accuracy",
      "analysis": "The test classification accuracy suggests that while the model captures some patterns, there is significant scope for improvement in real-world application."
    }
  ]
}