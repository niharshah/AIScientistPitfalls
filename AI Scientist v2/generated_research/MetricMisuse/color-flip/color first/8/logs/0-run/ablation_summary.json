[
  {
    "overall_plan": "The overall plan involves developing a sequence modeling framework to capture sequential regularities by mapping glyphs to a 2-dimensional latent vector and clustering them using K-means. These clusters are treated as tokens in a sequence model comprising trainable embeddings input into a bi-GRU, whose final hidden state is concatenated with handcrafted global features, shape-variety and colour-variety, to enhance model interpretability. A small MLP head produces the final labels. The training uses early stopping based on the harmonic mean of CWA and SWA, with additional OCGA monitoring. The model is designed to run on GPU and fallback to synthetic data if necessary, saving all metrics and predictions for analysis. The current plan introduces an ablation study by removing shape-colour variety features to assess their necessity, ensuring the model's reliance on GRU representations. This comprehensive plan not only targets effective sequence modeling but also evaluates the importance of model components through ablation studies.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "The loss value for the training dataset.",
            "data": [
              {
                "dataset_name": "training set",
                "final_value": 0.3404,
                "best_value": 0.3404
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "The loss value for the validation dataset.",
            "data": [
              {
                "dataset_name": "validation set",
                "final_value": 0.483,
                "best_value": 0.483
              }
            ]
          },
          {
            "metric_name": "validation CWA",
            "lower_is_better": false,
            "description": "The CWA metric for the validation dataset.",
            "data": [
              {
                "dataset_name": "validation set",
                "final_value": 0.778,
                "best_value": 0.778
              }
            ]
          },
          {
            "metric_name": "validation SWA",
            "lower_is_better": false,
            "description": "The SWA metric for the validation dataset.",
            "data": [
              {
                "dataset_name": "validation set",
                "final_value": 0.776,
                "best_value": 0.776
              }
            ]
          },
          {
            "metric_name": "validation harmonic mean",
            "lower_is_better": false,
            "description": "The harmonic mean metric for the validation dataset.",
            "data": [
              {
                "dataset_name": "validation set",
                "final_value": 0.777,
                "best_value": 0.777
              }
            ]
          },
          {
            "metric_name": "validation OCGA",
            "lower_is_better": false,
            "description": "The OCGA metric for the validation dataset.",
            "data": [
              {
                "dataset_name": "validation set",
                "final_value": 0.0,
                "best_value": 0.0
              }
            ]
          },
          {
            "metric_name": "test accuracy",
            "lower_is_better": false,
            "description": "The accuracy value for the test dataset.",
            "data": [
              {
                "dataset_name": "test set",
                "final_value": 0.799,
                "best_value": 0.799
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os, random, pathlib, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import LabelEncoder\n\n# ---------- dirs / device -----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using\", device)\n\n\n# ---------- metrics -----------------------------------------------------------\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split()})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split()})\n\n\ndef CWA(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef SWA(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\nhmean = lambda a, b, eps=1e-8: 2 * a * b / (a + b + eps)\n\n\n# ---------- load real or synthetic SPR ---------------------------------------\ndef load_real(root):\n    from datasets import load_dataset\n\n    def _ld(f):\n        return list(load_dataset(\"csv\", data_files=str(root / f), split=\"train\"))\n\n    return {\"train\": _ld(\"train.csv\"), \"dev\": _ld(\"dev.csv\"), \"test\": _ld(\"test.csv\")}\n\n\ndef synth(n):\n    shapes, colors = \"ABCD\", \"1234\"\n    mk = lambda: \" \".join(\n        random.choice(shapes) + random.choice(colors) for _ in range(8)\n    )\n    lab = lambda s: max([t[0] for t in s.split()], key=[t[0] for t in s.split()].count)\n    return [{\"id\": i, \"sequence\": (s := mk()), \"label\": lab(s)} for i in range(n)]\n\n\nDATA_DIR = pathlib.Path(\"SPR_BENCH\")\ntry:\n    data = load_real(DATA_DIR)\nexcept Exception:\n    print(\"Real SPR_BENCH not found \u2192 synthetic\")\n    data = {\"train\": synth(4000), \"dev\": synth(1000), \"test\": synth(1000)}\n\n# ---------- glyph \u2192 cluster ids ---------------------------------------------\nall_toks = [\n    tok for row in itertools.chain(*data.values()) for tok in row[\"sequence\"].split()\n]\nshapes, colors = sorted({t[0] for t in all_toks}), sorted({t[1] for t in all_toks})\ns2i, c2i = {s: i for i, s in enumerate(shapes)}, {c: i for i, c in enumerate(colors)}\ntokvec = lambda t: np.array([s2i[t[0]], c2i[t[1]]], np.float32)\nvecs = np.stack([tokvec(t) for t in all_toks])\ncands = [6, 8, 10, 12, 14]\nsample = np.random.choice(len(vecs), min(3000, len(vecs)), replace=False)\nscores = [\n    silhouette_score(\n        vecs[sample], KMeans(k, n_init=8, random_state=0).fit(vecs[sample]).labels_\n    )\n    for k in cands\n]\nk_best = cands[int(np.argmax(scores))]\nprint(\"Chosen k:\", k_best)\nkmeans = KMeans(n_clusters=k_best, n_init=20, random_state=1).fit(vecs)\n\ntrain_clusters = set(\n    kmeans.predict(\n        np.stack([tokvec(t) for r in data[\"train\"] for t in r[\"sequence\"].split()])\n    )\n)\n\nPAD = 0\n\n\ndef seq2clust(seq):\n    return (kmeans.predict(np.stack([tokvec(t) for t in seq.split()])) + 1).astype(\n        np.int64\n    )\n\n\n# ---------- Dataset / DataLoader --------------------------------------------\nclass SPRDataset(Dataset):\n    def __init__(self, rows):\n        self.seqs = [r[\"sequence\"] for r in rows]\n        self.x = [seq2clust(s) for s in self.seqs]\n        self.shp = [count_shape_variety(s) for s in self.seqs]\n        self.col = [count_color_variety(s) for s in self.seqs]\n        self.y = le.transform([r[\"label\"] for r in rows]).astype(np.int64)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\n            \"ids\": torch.tensor(self.x[idx]),\n            \"shc\": torch.tensor([self.shp[idx], self.col[idx]], dtype=torch.float32),\n            \"y\": torch.tensor(self.y[idx]),\n            \"seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    lens = [len(b[\"ids\"]) for b in batch]\n    maxlen = max(lens)\n    ids = torch.full((len(batch), maxlen), PAD, dtype=torch.long)\n    for i, b in enumerate(batch):\n        ids[i, : lens[i]] = b[\"ids\"]\n    # --- No-SHC ablation: zero-out handcrafted features ---------------------\n    shc = torch.zeros(len(batch), 2, dtype=torch.float32)\n    y = torch.stack([b[\"y\"] for b in batch])\n    seq = [b[\"seq\"] for b in batch]\n    return {\"ids\": ids, \"lens\": torch.tensor(lens), \"shc\": shc, \"y\": y, \"seq\": seq}\n\n\nle = LabelEncoder()\nle.fit([r[\"label\"] for r in data[\"train\"]])\ntrain_dl = DataLoader(\n    SPRDataset(data[\"train\"]), batch_size=256, shuffle=True, collate_fn=collate\n)\ndev_dl = DataLoader(SPRDataset(data[\"dev\"]), batch_size=512, collate_fn=collate)\ntest_dl = DataLoader(SPRDataset(data[\"test\"]), batch_size=512, collate_fn=collate)\n\n\n# ---------- Model ------------------------------------------------------------\nclass GRUReasoner(nn.Module):\n    def __init__(self, vocab, embed=32, hid=64, num_cls=4):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed, padding_idx=PAD)\n        self.gru = nn.GRU(embed, hid, bidirectional=True, batch_first=True)\n        # still expect a 2-dim vector, but will receive zeros\n        self.head = nn.Sequential(\n            nn.Linear(hid * 2 + 2, 64), nn.ReLU(), nn.Linear(64, num_cls)\n        )\n\n    def forward(self, ids, lens, shc):\n        e = self.emb(ids)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[0], h[1]], 1)\n        z = torch.cat([h, shc.to(h)], 1)\n        return self.head(z)\n\n\nmodel = GRUReasoner(k_best + 1, num_cls=len(le.classes_)).to(device)\nopt = torch.optim.Adam(model.parameters(), lr=2e-3)\ncrit = nn.CrossEntropyLoss()\n\n\n# ---------- OCGA -------------------------------------------------------------\ndef OCGA(seqs, y_t, y_p):\n    tot = acc = 0\n    for s, t, p in zip(seqs, y_t, y_p):\n        cl = set(kmeans.predict(np.stack([tokvec(tok) for tok in s.split()])))\n        if not cl.issubset(train_clusters):\n            tot += 1\n            acc += int(t == p)\n    return acc / max(1, tot)\n\n\n# ---------- logging dict -----------------------------------------------------\nexperiment_data = {\n    \"No-SHC\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\nlog = experiment_data[\"No-SHC\"][\"SPR\"]\n\n# ---------- training ---------------------------------------------------------\nbest_hm, best_state, best_epoch, wait = -1, None, 0, 0\nfor epoch in range(1, 61):\n    model.train()\n    tr_loss = 0\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        opt.zero_grad()\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        loss = crit(out, batch[\"y\"])\n        loss.backward()\n        opt.step()\n        tr_loss += loss.item() * batch[\"y\"].size(0)\n    tr_loss /= len(train_dl.dataset)\n    log[\"losses\"][\"train\"].append((epoch, tr_loss))\n\n    model.eval()\n    val_loss = 0\n    preds = gts = seqs = []\n    preds = []\n    gts = []\n    seqs = []\n    with torch.no_grad():\n        for batch in dev_dl:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n            val_loss += crit(out, batch[\"y\"]).item() * batch[\"y\"].size(0)\n            preds.extend(out.argmax(1).cpu().numpy())\n            gts.extend(batch[\"y\"].cpu().numpy())\n            seqs.extend(batch[\"seq\"])\n    val_loss /= len(dev_dl.dataset)\n    cwa, swa = CWA(seqs, gts, preds), SWA(seqs, gts, preds)\n    hm = hmean(cwa, swa)\n    ocga = OCGA(seqs, gts, preds)\n    log[\"losses\"][\"val\"].append((epoch, val_loss))\n    log[\"metrics\"][\"val\"].append((epoch, cwa, swa, hm, ocga))\n    print(\n        f\"Ep{epoch:02d} val_loss={val_loss:.4f} CWA={cwa:.3f} SWA={swa:.3f} HM={hm:.3f} OCGA={ocga:.3f}\"\n    )\n    if hm > best_hm + 1e-4:\n        best_hm, best_state, best_epoch, wait = (\n            hm,\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n            0,\n        )\n    else:\n        wait += 1\n    if wait >= 10:\n        print(\"Early stop\")\n        break\n\n# ---------- test -------------------------------------------------------------\nmodel.load_state_dict(best_state)\nmodel.to(device)\nmodel.eval()\npreds = gts = seqs = []\npreds = []\ngts = []\nseqs = []\nwith torch.no_grad():\n    for batch in test_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        preds.extend(out.argmax(1).cpu().numpy())\n        gts.extend(batch[\"y\"].cpu().numpy())\n        seqs.extend(batch[\"seq\"])\nlog[\"predictions\"] = preds\nlog[\"ground_truth\"] = gts\nprint(\n    \"TEST CWA={:.3f} SWA={:.3f} OCGA={:.3f}\".format(\n        CWA(seqs, gts, preds), SWA(seqs, gts, preds), OCGA(seqs, gts, preds)\n    )\n)\n\n# ---------- save -------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved to\", os.path.join(working_dir, \"experiment_data.npy\"))\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------ load data ------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nspr = experiment_data.get(\"No-SHC\", {}).get(\"SPR\", {})\nlosses = spr.get(\"losses\", {})\nmetrics = spr.get(\"metrics\", {})\n\n# ------------------ loss curves -----------------\ntry:\n    tr = np.array(losses.get(\"train\", []))\n    va = np.array(losses.get(\"val\", []))\n    if tr.size and va.size:\n        plt.figure()\n        plt.plot(tr[:, 0], tr[:, 1], label=\"Train\")\n        plt.plot(va[:, 0], va[:, 1], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR Dataset - Loss Curves (No-SHC)\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_No-SHC_loss_curves.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# -------------- metric curves -------------------\ntry:\n    mv = np.array(metrics.get(\"val\", []))\n    if mv.size:\n        epochs, cwa, swa, hm, ocga = mv.T\n        plt.figure()\n        plt.plot(epochs, cwa, label=\"CWA\")\n        plt.plot(epochs, swa, label=\"SWA\")\n        plt.plot(epochs, hm, label=\"HMean\")\n        plt.plot(epochs, ocga, label=\"OCGA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(\"SPR Dataset - Validation Metrics (No-SHC)\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_No-SHC_metric_curves.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating metric curve plot: {e}\")\n    plt.close()\n",
    "plot_plan": "We first load the saved experiment_data.npy from the working directory and extract the logging dictionary for the \u201cNo-SHC / SPR\u201d run. From this we obtain two ordered lists: losses[\"train\"] / losses[\"val\"] (each a list of (epoch, loss)) and metrics[\"val\"] (list of (epoch, CWA, SWA, HM, OCGA)). We convert these to NumPy arrays so they can be plotted easily. Two standard visualizations are created: (1) a line plot showing training and validation loss versus epoch, and (2) a multi-line plot of the four evaluation metrics versus epoch. Each figure is produced inside its own try-except block; any error is reported, the figure is closed, and execution continues. Figures are stored under descriptive names that include the dataset and plot type inside the working directory. Every plot carries a clear title specifying the dataset and, when applicable, a subtitle clarifying the lines that are being compared. Only data present in experiment_data.npy are plotted, and at most these two figures are generated, satisfying the \u201c\u22645 plots\u201d rule. The code below implements the above steps concisely and prints nothing beyond potential error messages.",
    "plot_analyses": [
      {
        "analysis": "The loss curves for both the training and validation sets show a steady decrease over the epochs, indicating effective learning. However, the validation loss starts to increase slightly after around epoch 12, suggesting potential overfitting. This implies that earlier stopping might improve generalization. The overall downward trend in both curves demonstrates that the model is learning effectively from the data.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_ee41de1d31854e20a7184174fcd5cfce_proc_1749405/SPR_No-SHC_loss_curves.png"
      },
      {
        "analysis": "The validation metrics (CWA, SWA, and HMean) stabilize at around 0.78, which is above the stated SOTA benchmarks of 0.70 for CWA and 0.65 for SWA. This indicates that the model is performing well on the validation set. However, the OCGA metric remains at zero, suggesting an issue either with the calculation or relevance of this metric in the current experimental setup. Further investigation into the OCGA metric is recommended to determine its role and correctness in the evaluation.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_ee41de1d31854e20a7184174fcd5cfce_proc_1749405/SPR_No-SHC_metric_curves.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_ee41de1d31854e20a7184174fcd5cfce_proc_1749405/SPR_No-SHC_loss_curves.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_ee41de1d31854e20a7184174fcd5cfce_proc_1749405/SPR_No-SHC_metric_curves.png"
    ],
    "vlm_feedback_summary": "The plots indicate effective model training with validation metrics surpassing SOTA benchmarks. However, potential overfitting and an issue with the OCGA metric require further investigation.",
    "exp_results_dir": "experiment_results/experiment_ee41de1d31854e20a7184174fcd5cfce_proc_1749405",
    "ablation_name": "Remove Shape-Color Variety Features (No-SHC)",
    "exp_results_npy_files": [
      "experiment_results/experiment_ee41de1d31854e20a7184174fcd5cfce_proc_1749405/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "The overall plan is centered around capturing sequential regularities in data by transforming glyphs into a latent space and clustering them to simplify input for a sequence model. Initially, each glyph was mapped to a 2-dimensional latent vector, clustered using K-means to generate tokens, and processed by a bi-directional GRU augmented with global features that were fed into an MLP head for classification. This approach was designed to enhance the model's ability to detect nuanced patterns beyond simple histogram methods while optimizing metrics such as CWA, SWA, and OCGA. The current plan extends this by conducting an ablation study that uses raw glyph IDs directly, foregoing clustering to isolate and analyze its impact on model performance while keeping other variables constant. This comprehensive strategy aims to validate the initial hypothesis that clustering improves model effectiveness and to refine the processing pipeline based on empirical evidence.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "The loss during training phase.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.001,
                "best_value": 0.001
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "The loss during validation phase.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.0399,
                "best_value": 0.0399
              }
            ]
          },
          {
            "metric_name": "validation CWA",
            "lower_is_better": false,
            "description": "The Correct Word Accuracy during validation phase.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.987,
                "best_value": 0.987
              }
            ]
          },
          {
            "metric_name": "validation SWA",
            "lower_is_better": false,
            "description": "The Sentence Word Accuracy during validation phase.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.987,
                "best_value": 0.987
              }
            ]
          },
          {
            "metric_name": "validation harmonic mean",
            "lower_is_better": false,
            "description": "The harmonic mean of validation metrics.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.987,
                "best_value": 0.987
              }
            ]
          },
          {
            "metric_name": "validation OCGA",
            "lower_is_better": false,
            "description": "The Overall Correct Grammar Accuracy during validation phase.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.0,
                "best_value": 0.0
              }
            ]
          },
          {
            "metric_name": "test accuracy",
            "lower_is_better": false,
            "description": "The accuracy on the test dataset.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.986,
                "best_value": 0.986
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "# No-KMeans-RawGlyphIDs ablation ------------------------------------------------\nimport os, random, pathlib, itertools, numpy as np, torch, warnings\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import LabelEncoder\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# ---------- mandatory dirs / device ---------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics -------------------------------------------------\ndef count_color_variety(seq):  # colors = second char\n    return len({t[1] for t in seq.split()})\n\n\ndef count_shape_variety(seq):  # shapes = first char\n    return len({t[0] for t in seq.split()})\n\n\ndef CWA(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef SWA(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef hmean(a, b, eps=1e-8):\n    return 2 * a * b / (a + b + eps)\n\n\n# ---------- load real or synthetic SPR ------------------------------\ndef load_real(root):\n    from datasets import load_dataset\n\n    def _ld(f):  # returns list of dict rows\n        return list(load_dataset(\"csv\", data_files=str(root / f), split=\"train\"))\n\n    return {\"train\": _ld(\"train.csv\"), \"dev\": _ld(\"dev.csv\"), \"test\": _ld(\"test.csv\")}\n\n\ndef synth(n):\n    shapes, colors = \"ABCD\", \"1234\"\n\n    def mk():\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(8))\n\n    def lab(s):\n        return max([t[0] for t in s.split()], key=[t[0] for t in s.split()].count)\n\n    return [{\"id\": i, \"sequence\": (s := mk()), \"label\": lab(s)} for i in range(n)]\n\n\nDATA_DIR = pathlib.Path(\"SPR_BENCH\")\ntry:\n    data = load_real(DATA_DIR)\nexcept Exception:\n    print(\"Real SPR_BENCH not found, using synthetic\")\n    data = {\"train\": synth(4000), \"dev\": synth(1000), \"test\": synth(1000)}\n\n# ---------- build raw glyph-id vocabulary ---------------------------\nall_tokens = [\n    tok for row in itertools.chain(*data.values()) for tok in row[\"sequence\"].split()\n]\nshapes = sorted({t[0] for t in all_tokens})\ncolors = sorted({t[1] for t in all_tokens})\ntok2id = {s + c: i + 1 for i, (s, c) in enumerate(itertools.product(shapes, colors))}\nPAD = 0\nprint(f\"Vocabulary size (glyphs): {len(tok2id)}\")\n\n\ndef seq2ids(seq):\n    return np.array([tok2id[t] for t in seq.split()], np.int64)\n\n\n# Training-set token set for OCGA-token metric\ntrain_token_set = set(t for row in data[\"train\"] for t in row[\"sequence\"].split())\n\n\n# ---------- Dataset & DataLoader ------------------------------------\nclass SPRDataset(Dataset):\n    def __init__(self, rows):\n        self.seqs = [r[\"sequence\"] for r in rows]\n        self.x = [seq2ids(s) for s in self.seqs]\n        self.shp = [count_shape_variety(s) for s in self.seqs]\n        self.col = [count_color_variety(s) for s in self.seqs]\n        self.y = le.transform([r[\"label\"] for r in rows]).astype(np.int64)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\n            \"ids\": torch.tensor(self.x[idx]),\n            \"shc\": torch.tensor([self.shp[idx], self.col[idx]], dtype=torch.float32),\n            \"y\": torch.tensor(self.y[idx]),\n            \"seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    lens = [len(b[\"ids\"]) for b in batch]\n    maxlen = max(lens)\n    ids = torch.full((len(batch), maxlen), PAD, dtype=torch.long)\n    for i, b in enumerate(batch):\n        ids[i, : lens[i]] = b[\"ids\"]\n    shc = torch.stack([b[\"shc\"] for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    seq = [b[\"seq\"] for b in batch]\n    return {\"ids\": ids, \"lens\": torch.tensor(lens), \"shc\": shc, \"y\": y, \"seq\": seq}\n\n\nle = LabelEncoder()\nle.fit([r[\"label\"] for r in data[\"train\"]])\n\ntrain_dl = DataLoader(\n    SPRDataset(data[\"train\"]), batch_size=256, shuffle=True, collate_fn=collate\n)\ndev_dl = DataLoader(SPRDataset(data[\"dev\"]), batch_size=512, collate_fn=collate)\ntest_dl = DataLoader(SPRDataset(data[\"test\"]), batch_size=512, collate_fn=collate)\n\n\n# ---------- Model ---------------------------------------------------\nclass GRUReasoner(nn.Module):\n    def __init__(self, vocab, embed=32, hid=64, num_cls=4):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed, padding_idx=PAD)\n        self.gru = nn.GRU(embed, hid, batch_first=True, bidirectional=True)\n        self.head = nn.Sequential(\n            nn.Linear(hid * 2 + 2, 64), nn.ReLU(), nn.Linear(64, num_cls)\n        )\n\n    def forward(self, ids, lens, shc):\n        e = self.emb(ids)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[0], h[1]], dim=1)\n        z = torch.cat([h, shc], dim=1)\n        return self.head(z)\n\n\nmodel = GRUReasoner(len(tok2id) + 1, num_cls=len(le.classes_)).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\n# ---------- OCGA-token (tokens unseen in train) ---------------------\ndef OCGA(seqs, y_t, y_p):\n    tot = acc = 0\n    for s, t, p in zip(seqs, y_t, y_p):\n        toks = set(s.split())\n        if not toks.issubset(train_token_set):\n            tot += 1\n            acc += int(t == p)\n    return acc / max(1, tot)\n\n\n# ---------- experiment data dict ------------------------------------\nexperiment_data = {\n    \"NoKMeansRawGlyphIDs\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------- training ------------------------------------------------\nbest_hm, best_state, wait = -1, None, 0\nfor epoch in range(1, 61):\n    # train\n    model.train()\n    tr_loss = 0\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        loss = criterion(out, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        tr_loss += loss.item() * batch[\"y\"].size(0)\n    tr_loss /= len(train_dl.dataset)\n    experiment_data[\"NoKMeansRawGlyphIDs\"][\"SPR\"][\"losses\"][\"train\"].append(\n        (epoch, tr_loss)\n    )\n\n    # validation\n    model.eval()\n    val_loss, preds, gts, seqs = 0, [], [], []\n    with torch.no_grad():\n        for batch in dev_dl:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n            val_loss += criterion(out, batch[\"y\"]).item() * batch[\"y\"].size(0)\n            p = out.argmax(1).cpu().numpy()\n            preds.extend(p)\n            gts.extend(batch[\"y\"].cpu().numpy())\n            seqs.extend(batch[\"seq\"])\n    val_loss /= len(dev_dl.dataset)\n    cwa, swa = CWA(seqs, gts, preds), SWA(seqs, gts, preds)\n    hm, ocga = hmean(cwa, swa), OCGA(seqs, gts, preds)\n    experiment_data[\"NoKMeansRawGlyphIDs\"][\"SPR\"][\"losses\"][\"val\"].append(\n        (epoch, val_loss)\n    )\n    experiment_data[\"NoKMeansRawGlyphIDs\"][\"SPR\"][\"metrics\"][\"val\"].append(\n        (epoch, cwa, swa, hm, ocga)\n    )\n    print(\n        f\"Epoch {epoch:02d}: val_loss={val_loss:.4f} CWA={cwa:.3f} SWA={swa:.3f} HM={hm:.3f} OCGA={ocga:.3f}\"\n    )\n\n    if hm > best_hm + 1e-4:\n        best_hm, best_state, wait = (\n            hm,\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            0,\n        )\n    else:\n        wait += 1\n    if wait >= 10:\n        print(\"Early stopping.\")\n        break\n\n# ---------- test ----------------------------------------------------\nmodel.load_state_dict(best_state)\nmodel.to(device)\nmodel.eval()\npreds, gts, seqs = [], [], []\nwith torch.no_grad():\n    for batch in test_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        preds.extend(out.argmax(1).cpu().numpy())\n        gts.extend(batch[\"y\"].cpu().numpy())\n        seqs.extend(batch[\"seq\"])\n\nexperiment_data[\"NoKMeansRawGlyphIDs\"][\"SPR\"][\"predictions\"] = preds\nexperiment_data[\"NoKMeansRawGlyphIDs\"][\"SPR\"][\"ground_truth\"] = gts\nprint(\n    \"TEST CWA={:.3f} SWA={:.3f} OCGA={:.3f}\".format(\n        CWA(seqs, gts, preds), SWA(seqs, gts, preds), OCGA(seqs, gts, preds)\n    )\n)\n\n# ---------- save ----------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------------------------\ntry:\n    data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = data[\"NoKMeansRawGlyphIDs\"][\"SPR\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = None\n\nif exp:\n    # --------- reshape helpers -------------------------------------\n    def to_xy(lst):\n        arr = np.array(lst)\n        return arr[:, 0], arr[:, 1:].astype(float) if arr.ndim > 1 else arr[:, 1]\n\n    # --------- 1. Loss curves --------------------------------------\n    try:\n        epochs_tr, losses_tr = to_xy(exp[\"losses\"][\"train\"])\n        epochs_val, losses_val = to_xy(exp[\"losses\"][\"val\"])\n        plt.figure()\n        plt.plot(epochs_tr, losses_tr, label=\"Train\")\n        plt.plot(epochs_val, losses_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR: Training vs Validation Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # --------- 2. Validation metrics curves ------------------------\n    try:\n        epochs_m, metrics = to_xy(exp[\"metrics\"][\"val\"])\n        cwa, swa, hm, ocga = metrics.T\n        plt.figure()\n        plt.plot(epochs_m, cwa, label=\"CWA\")\n        plt.plot(epochs_m, swa, label=\"SWA\")\n        plt.plot(epochs_m, hm, label=\"HM\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(\"SPR: Validation Metrics (CWA/SWA/HM)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_val_metrics.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metrics plot: {e}\")\n        plt.close()\n\n    # --------- 3. OCGA curve ---------------------------------------\n    try:\n        plt.figure()\n        plt.plot(epochs_m, ocga, label=\"OCGA\", color=\"purple\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"OCGA\")\n        plt.title(\"SPR: Validation OCGA over Epochs\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_val_OCGA.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating OCGA plot: {e}\")\n        plt.close()\n\n    # --------- 4. Confusion matrix ---------------------------------\n    try:\n        preds = np.array(exp[\"predictions\"])\n        gts = np.array(exp[\"ground_truth\"])\n        num_cls = max(preds.max(), gts.max()) + 1\n        cm = np.zeros((num_cls, num_cls), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n        cm_norm = cm / cm.sum(axis=1, keepdims=True).clip(min=1)\n        plt.figure()\n        im = plt.imshow(cm_norm, cmap=\"Blues\")\n        plt.colorbar(im, fraction=0.046)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(f\"SPR: Confusion Matrix (Accuracy={np.mean(preds==gts):.3f})\")\n        for i in range(num_cls):\n            for j in range(num_cls):\n                plt.text(\n                    j,\n                    i,\n                    cm[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"white\" if cm_norm[i, j] > 0.5 else \"black\",\n                    fontsize=8,\n                )\n        plt.savefig(os.path.join(working_dir, \"SPR_confusion_matrix.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n",
    "plot_plan": "We first load `experiment_data.npy`, ensuring we work inside the provided `working` directory. We extract the single run `NoKMeansRawGlyphIDs \u2192 SPR` and separate the stored lists into NumPy arrays for easier plotting. Four figures will be produced: (1) training vs validation loss curves over epochs, (2) validation CWA/SWA/HM curves, (3) validation OCGA curve, and (4) a test-set confusion matrix together with overall accuracy in the title. Each figure is wrapped in an independent `try-except` block; any error is printed and the figure is closed to avoid resource leaks. We use clear titles that include the dataset name and a brief subtitle; filenames likewise include `SPR` and the plot type. We compute the confusion matrix with `numpy` (no heavy dependencies) and normalise it for readability. Only existing data are used, and a maximum of four plots are saved\u2014well within the five-figure limit.",
    "plot_analyses": [
      {
        "analysis": "The plot shows the training and validation loss over 30 epochs. Both losses decrease sharply initially and stabilize around epoch 10, indicating successful learning and convergence of the model. The validation loss closely follows the training loss, suggesting minimal overfitting and good generalization.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_21021ca8d7f44b5d83bcab53dc0355b6_proc_1749406/SPR_loss_curves.png"
      },
      {
        "analysis": "This plot shows the performance of the model on three validation metrics: Color-Weighted Accuracy (CWA), Shape-Weighted Accuracy (SWA), and their Harmonic Mean (HM). The scores improve rapidly in the first few epochs and stabilize near perfect scores (close to 1.0) after epoch 10, indicating that the model achieves excellent performance on the SPR_BENCH dataset.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_21021ca8d7f44b5d83bcab53dc0355b6_proc_1749406/SPR_val_metrics.png"
      },
      {
        "analysis": "This plot depicts the validation OCGA metric, which remains constant at 0 throughout all epochs. This suggests that the metric is either not being updated correctly during training or is not relevant to the current evaluation setup. Further investigation is needed to determine why this metric is static.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_21021ca8d7f44b5d83bcab53dc0355b6_proc_1749406/SPR_val_OCGA.png"
      },
      {
        "analysis": "The confusion matrix illustrates the model's predictions versus the true labels. The high diagonal values and low off-diagonal values indicate that the model achieves high accuracy (98.6%). The minor misclassifications are spread across a few categories, demonstrating that the model performs well across all classes.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_21021ca8d7f44b5d83bcab53dc0355b6_proc_1749406/SPR_confusion_matrix.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_21021ca8d7f44b5d83bcab53dc0355b6_proc_1749406/SPR_loss_curves.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_21021ca8d7f44b5d83bcab53dc0355b6_proc_1749406/SPR_val_metrics.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_21021ca8d7f44b5d83bcab53dc0355b6_proc_1749406/SPR_val_OCGA.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_21021ca8d7f44b5d83bcab53dc0355b6_proc_1749406/SPR_confusion_matrix.png"
    ],
    "vlm_feedback_summary": "The experimental results indicate strong model performance, with rapid convergence and high accuracy on validation metrics. The static OCGA metric requires further investigation to determine its relevance or implementation issues. The confusion matrix confirms the model's robustness across multiple categories.",
    "exp_results_dir": "experiment_results/experiment_21021ca8d7f44b5d83bcab53dc0355b6_proc_1749406",
    "ablation_name": "No-KMeans-RawGlyphIDs",
    "exp_results_npy_files": [
      "experiment_results/experiment_21021ca8d7f44b5d83bcab53dc0355b6_proc_1749406/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "The overall plan is to explore the capture of sequential regularities in glyph data by mapping each glyph to a 2-dimensional latent vector, clustering using K-means, and treating the resulting cluster ID as a token in a sequence model. The initial approach involves a bidirectional GRU concatenated with two global features for classification, with performance monitored by specific metrics. The current plan focuses on an ablation study by replacing the bidirectional GRU with a unidirectional GRU of the same hidden size per direction to evaluate the impact of bidirectionality on performance. This combined approach aims to determine the optimal model architecture for capturing sequential dependencies in glyph data.",
    "analysis": "The execution of the training script was successful. The model trained and evaluated without any errors, and the results were saved as expected. The chosen k for clustering was 14, and the training process reached early stopping after 19 epochs due to no improvement in the harmonic mean (HM). The final test results achieved a Color-Weighted Accuracy (CWA) of 0.858 and Shape-Weighted Accuracy (SWA) of 0.856, which are above the SOTA benchmarks of 70.0% for CWA and 65.0% for SWA. However, the Out-of-Cluster Generalization Accuracy (OCGA) remained 0.000, indicating no generalization to unseen clusters. Future iterations should focus on improving OCGA.",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "Measures the error during training; lower values indicate better performance.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.2002,
                "best_value": 0.2002
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Measures the error during validation; lower values indicate better performance.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.3117,
                "best_value": 0.3117
              }
            ]
          },
          {
            "metric_name": "validation CWA",
            "lower_is_better": false,
            "description": "Validation metric for Correctly Weighted Accuracy; higher values are better.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.8697,
                "best_value": 0.8697
              }
            ]
          },
          {
            "metric_name": "validation SWA",
            "lower_is_better": false,
            "description": "Validation metric for Simple Weighted Accuracy; higher values are better.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.8665,
                "best_value": 0.8665
              }
            ]
          },
          {
            "metric_name": "validation harmonic mean",
            "lower_is_better": false,
            "description": "Validation metric for the harmonic mean of accuracies; higher values are better.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.8681,
                "best_value": 0.8681
              }
            ]
          },
          {
            "metric_name": "validation OCGA",
            "lower_is_better": false,
            "description": "Validation metric for Overall Correct Group Accuracy; higher values are better.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.0,
                "best_value": 0.0
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os, random, pathlib, itertools, numpy as np, torch, warnings\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import LabelEncoder\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# ---------- dirs / device -------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics --------------------------------------------------\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split()})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split()})\n\n\ndef CWA(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef SWA(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef hmean(a, b, eps=1e-8):\n    return 2 * a * b / (a + b + eps)\n\n\n# ---------- load SPR -------------------------------------------------\ndef load_real(root):\n    from datasets import load_dataset\n\n    def _ld(f):\n        return list(load_dataset(\"csv\", data_files=str(root / f), split=\"train\"))\n\n    return {\"train\": _ld(\"train.csv\"), \"dev\": _ld(\"dev.csv\"), \"test\": _ld(\"test.csv\")}\n\n\ndef synth(n):\n    shapes, colors = \"ABCD\", \"1234\"\n\n    def mk():\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(8))\n\n    def lab(s):\n        return max([t[0] for t in s.split()], key=[t[0] for t in s.split()].count)\n\n    return [{\"id\": i, \"sequence\": (s := mk()), \"label\": lab(s)} for i in range(n)]\n\n\nDATA_DIR = pathlib.Path(\"SPR_BENCH\")\ntry:\n    data = load_real(DATA_DIR)\nexcept Exception:\n    print(\"Real SPR_BENCH not found, using synthetic\")\n    data = {\"train\": synth(4000), \"dev\": synth(1000), \"test\": synth(1000)}\n\n# ---------- clustering ----------------------------------------------\nall_toks = [\n    tok for row in itertools.chain(*data.values()) for tok in row[\"sequence\"].split()\n]\nshapes, colors = sorted({t[0] for t in all_toks}), sorted({t[1] for t in all_toks})\ns2i, c2i = {s: i for i, s in enumerate(shapes)}, {c: i for i, c in enumerate(colors)}\n\n\ndef tokvec(t):\n    return np.array([s2i[t[0]], c2i[t[1]]], np.float32)\n\n\nvecs = np.stack([tokvec(t) for t in all_toks])\ncands = [6, 8, 10, 12, 14]\nsample = np.random.choice(len(vecs), min(3000, len(vecs)), replace=False)\nscores = [\n    silhouette_score(\n        vecs[sample], KMeans(k, n_init=8, random_state=0).fit(vecs[sample]).labels_\n    )\n    for k in cands\n]\nk_best = cands[int(np.argmax(scores))]\nprint(\"Chosen k=\", k_best)\nkmeans = KMeans(n_clusters=k_best, n_init=20, random_state=1).fit(vecs)\ntrain_clusters = set(\n    kmeans.predict(\n        np.stack([tokvec(t) for r in data[\"train\"] for t in r[\"sequence\"].split()])\n    )\n)\n\n# ---------- seq\u2192cluster id list -------------------------------------\nPAD = 0\n\n\ndef seq2clust(seq):\n    return (kmeans.predict(np.stack([tokvec(t) for t in seq.split()])) + 1).astype(\n        np.int64\n    )\n\n\n# ---------- Dataset --------------------------------------------------\nclass SPRDataset(Dataset):\n    def __init__(self, rows):\n        self.seqs = [r[\"sequence\"] for r in rows]\n        self.x = [seq2clust(s) for s in self.seqs]\n        self.shp = [count_shape_variety(s) for s in self.seqs]\n        self.col = [count_color_variety(s) for s in self.seqs]\n        self.y = le.transform([r[\"label\"] for r in rows]).astype(np.int64)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\n            \"ids\": torch.tensor(self.x[idx]),\n            \"shc\": torch.tensor([self.shp[idx], self.col[idx]], dtype=torch.float32),\n            \"y\": torch.tensor(self.y[idx]),\n            \"seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    lens = [len(b[\"ids\"]) for b in batch]\n    maxlen = max(lens)\n    ids = torch.full((len(batch), maxlen), PAD, dtype=torch.long)\n    for i, b in enumerate(batch):\n        ids[i, : lens[i]] = b[\"ids\"]\n    shc = torch.stack([b[\"shc\"] for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    seq = [b[\"seq\"] for b in batch]\n    return {\"ids\": ids, \"lens\": torch.tensor(lens), \"shc\": shc, \"y\": y, \"seq\": seq}\n\n\nle = LabelEncoder()\nle.fit([r[\"label\"] for r in data[\"train\"]])\ntrain_dl = DataLoader(\n    SPRDataset(data[\"train\"]), batch_size=256, shuffle=True, collate_fn=collate\n)\ndev_dl = DataLoader(SPRDataset(data[\"dev\"]), batch_size=512, collate_fn=collate)\ntest_dl = DataLoader(SPRDataset(data[\"test\"]), batch_size=512, collate_fn=collate)\n\n\n# ---------- UniGRU Model --------------------------------------------\nclass UniGRUReasoner(nn.Module):\n    def __init__(self, vocab, embed=32, hid=64, num_cls=4):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed, padding_idx=PAD)\n        self.gru = nn.GRU(embed, hid, bidirectional=False, batch_first=True)\n        self.head = nn.Sequential(\n            nn.Linear(hid + 2, 64), nn.ReLU(), nn.Linear(64, num_cls)\n        )\n\n    def forward(self, ids, lens, shc):\n        e = self.emb(ids)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)  # h: [1,B,hid]\n        h = h.squeeze(0)  # [B,hid]\n        z = torch.cat([h, shc], 1)\n        return self.head(z)\n\n\nmodel = UniGRUReasoner(k_best + 1, num_cls=len(le.classes_)).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\n# ---------- OCGA -----------------------------------------------------\ndef OCGA(seqs, y_t, y_p):\n    tot = acc = 0\n    for s, t, p in zip(seqs, y_t, y_p):\n        cl = set(kmeans.predict(np.stack([tokvec(tok) for tok in s.split()])))\n        if not cl.issubset(train_clusters):\n            tot += 1\n            acc += int(t == p)\n    return acc / max(1, tot)\n\n\n# ---------- experiment dict -----------------------------------------\nexperiment_data = {\n    \"UniGRU_no_bidi\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------- training -------------------------------------------------\nbest_hm, best_state, best_epoch, wait = -1, None, 0, 0\nfor epoch in range(1, 61):\n    model.train()\n    tr_loss = 0\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        loss = criterion(out, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        tr_loss += loss.item() * batch[\"y\"].size(0)\n    tr_loss /= len(train_dl.dataset)\n    experiment_data[\"UniGRU_no_bidi\"][\"SPR\"][\"losses\"][\"train\"].append((epoch, tr_loss))\n\n    model.eval()\n    val_loss = 0\n    preds = []\n    gts = []\n    seqs = []\n    with torch.no_grad():\n        for batch in dev_dl:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n            val_loss += criterion(out, batch[\"y\"]).item() * batch[\"y\"].size(0)\n            p = out.argmax(1).cpu().numpy()\n            preds.extend(p)\n            g = batch[\"y\"].cpu().numpy()\n            gts.extend(g)\n            seqs.extend(batch[\"seq\"])\n    val_loss /= len(dev_dl.dataset)\n    cwa, swa = CWA(seqs, gts, preds), SWA(seqs, gts, preds)\n    hm = hmean(cwa, swa)\n    ocga = OCGA(seqs, gts, preds)\n    experiment_data[\"UniGRU_no_bidi\"][\"SPR\"][\"losses\"][\"val\"].append((epoch, val_loss))\n    experiment_data[\"UniGRU_no_bidi\"][\"SPR\"][\"metrics\"][\"val\"].append(\n        (epoch, cwa, swa, hm, ocga)\n    )\n    print(\n        f\"Epoch {epoch:02d}: val_loss={val_loss:.4f} CWA={cwa:.3f} SWA={swa:.3f} HM={hm:.3f} OCGA={ocga:.3f}\"\n    )\n\n    if hm > best_hm + 1e-4:\n        best_hm, best_state, best_epoch, wait = (\n            hm,\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n            0,\n        )\n    else:\n        wait += 1\n    if wait >= 10:\n        print(\"Early stopping.\")\n        break\n\n# ---------- test -----------------------------------------------------\nmodel.load_state_dict(best_state)\nmodel.to(device)\nmodel.eval()\npreds, gts, seqs = [], [], []\nwith torch.no_grad():\n    for batch in test_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        preds.extend(out.argmax(1).cpu().numpy())\n        gts.extend(batch[\"y\"].cpu().numpy())\n        seqs.extend(batch[\"seq\"])\nexperiment_data[\"UniGRU_no_bidi\"][\"SPR\"][\"predictions\"] = preds\nexperiment_data[\"UniGRU_no_bidi\"][\"SPR\"][\"ground_truth\"] = gts\nprint(\n    \"TEST CWA={:.3f} SWA={:.3f} OCGA={:.3f}\".format(\n        CWA(seqs, gts, preds), SWA(seqs, gts, preds), OCGA(seqs, gts, preds)\n    )\n)\n\n# ---------- save -----------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- setup ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load -----------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# Helper to safely fetch nested keys\ndef get(d, *keys, default=None):\n    for k in keys:\n        if isinstance(d, dict) and k in d:\n            d = d[k]\n        else:\n            return default\n    return d\n\n\nrun_key = \"UniGRU_no_bidi\"\nloss_tr = get(experiment_data, run_key, \"SPR\", \"losses\", \"train\", default=[])\nloss_val = get(experiment_data, run_key, \"SPR\", \"losses\", \"val\", default=[])\nmet_val = get(experiment_data, run_key, \"SPR\", \"metrics\", \"val\", default=[])\npreds = get(experiment_data, run_key, \"SPR\", \"predictions\", default=[])\ngts = get(experiment_data, run_key, \"SPR\", \"ground_truth\", default=[])\n\n# ---------- 1. loss curves ------------------------------------------\ntry:\n    if loss_tr and loss_val:\n        ep_tr, v_tr = zip(*loss_tr)\n        ep_val, v_val = zip(*loss_val)\n        plt.figure()\n        plt.plot(ep_tr, v_tr, label=\"Train\")\n        plt.plot(ep_val, v_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR Dataset \u2013 Training / Validation Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_loss_curve_UniGRU_no_bidi.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# ---------- 2. validation metrics curves ----------------------------\ntry:\n    if met_val:\n        ep, cwa, swa, hm, ocga = zip(*met_val)\n        plt.figure()\n        plt.plot(ep, cwa, label=\"CWA\")\n        plt.plot(ep, swa, label=\"SWA\")\n        plt.plot(ep, hm, label=\"Harmonic Mean\")\n        plt.plot(ep, ocga, label=\"OCGA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(\"SPR Dataset \u2013 Validation Metrics over Epochs\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_metric_curves_UniGRU_no_bidi.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating metric curves: {e}\")\n    plt.close()\n\n# ---------- 3. confusion matrix -------------------------------------\ntry:\n    if preds and gts:\n        preds = np.asarray(preds)\n        gts = np.asarray(gts)\n        n_cls = max(preds.max(), gts.max()) + 1\n        cm = np.zeros((n_cls, n_cls), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR Dataset \u2013 Confusion Matrix (Test Set)\")\n        fname = os.path.join(working_dir, \"SPR_confusion_matrix_UniGRU_no_bidi.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ---------- 4. prediction vs ground truth class counts --------------\ntry:\n    if preds and gts:\n        uniq = np.arange(max(max(preds), max(gts)) + 1)\n        pred_cnt = [(preds == u).sum() for u in uniq]\n        gt_cnt = [(gts == u).sum() for u in uniq]\n        x = np.arange(len(uniq))\n        width = 0.35\n        plt.figure()\n        plt.bar(x - width / 2, gt_cnt, width, label=\"Ground Truth\")\n        plt.bar(x + width / 2, pred_cnt, width, label=\"Predicted\")\n        plt.xlabel(\"Class ID\")\n        plt.ylabel(\"Count\")\n        plt.title(\"SPR Dataset \u2013 Class Distribution (Test Set)\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_class_distribution_UniGRU_no_bidi.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating class distribution plot: {e}\")\n    plt.close()\n",
    "plot_plan": "We load the stored experiment_data, extract epoch-wise losses and metrics, and generate up to four simple visualizations: (1) training vs. validation loss curves; (2) validation metrics (CWA, SWA, harmonic mean, OCGA) over epochs; (3) a confusion matrix for the best model\u2019s test predictions; and (4) a bar chart comparing class distributions of predictions and ground-truth.  Each figure is created in its own try-except block, saved to working_dir with descriptive filenames, and the figure is always closed.  We plot at most the recorded epochs (\u226460) and rely solely on the values present in experiment_data.npy.  The code begins with the required imports, creates working_dir if necessary, and prints a short confirmation for each saved plot.  Matplotlib\u2019s basic API is used without extra styling, and clear titles/subtitles are provided to indicate dataset and content.  Confusion matrix and class count computations are done with NumPy to stay self-contained.  All plots comply with the instruction to avoid fabricating data and to close figures after saving.  Finally, the script can be run once to create the PNG files; no further interaction is required.",
    "plot_analyses": [
      {
        "analysis": "This plot shows the training and validation loss over epochs. Both losses decrease significantly in the initial epochs, indicating that the model is learning effectively. The validation loss stabilizes after a few epochs, with a slight increase towards the end, suggesting potential overfitting. Regularization techniques like dropout or early stopping might mitigate this issue.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_616e3332414b4ad189c06832d9137a47_proc_1749408/SPR_loss_curve_UniGRU_no_bidi.png"
      },
      {
        "analysis": "This plot illustrates the performance of the model based on validation metrics (CWA, SWA, and Harmonic Mean) over epochs. The metrics improve rapidly in the initial epochs and plateau around 0.85, indicating strong performance. However, the OCGA metric remains constant at zero, which could imply that it is either not computed correctly or irrelevant to this experiment. Further investigation is needed to address this anomaly.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_616e3332414b4ad189c06832d9137a47_proc_1749408/SPR_metric_curves_UniGRU_no_bidi.png"
      },
      {
        "analysis": "This confusion matrix provides insights into the model's predictions on the test set. The diagonal dominance indicates that the model performs well in classifying most categories correctly. However, there are some off-diagonal elements, which reflect misclassifications. Analyzing these errors may help identify challenging cases and improve the model.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_616e3332414b4ad189c06832d9137a47_proc_1749408/SPR_confusion_matrix_UniGRU_no_bidi.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_616e3332414b4ad189c06832d9137a47_proc_1749408/SPR_loss_curve_UniGRU_no_bidi.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_616e3332414b4ad189c06832d9137a47_proc_1749408/SPR_metric_curves_UniGRU_no_bidi.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_616e3332414b4ad189c06832d9137a47_proc_1749408/SPR_confusion_matrix_UniGRU_no_bidi.png"
    ],
    "vlm_feedback_summary": "The plots provide valuable insights into the model's training process, validation performance, and test set predictions. The training and validation losses show effective learning with slight overfitting, the validation metrics highlight strong performance with an anomaly in OCGA, and the confusion matrix reveals areas for improvement in classification accuracy.",
    "exp_results_dir": "experiment_results/experiment_616e3332414b4ad189c06832d9137a47_proc_1749408",
    "ablation_name": "UniGRU (No-Bidirectional Encoder)",
    "exp_results_npy_files": [
      "experiment_results/experiment_616e3332414b4ad189c06832d9137a47_proc_1749408/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "The overall plan initially involved developing a sequence modeling framework to capture sequential regularities in data, a task where simple histograms fall short. This was achieved by mapping glyphs to latent vectors, clustering them, treating cluster ids as tokens, and feeding them into a bi-GRU model augmented by global features to produce labels. The system employed early stopping based on critical performance metrics and was versatile in terms of data and computational resources. Building on this, the current plan introduces an ablation study named 'Frozen-Random-Embedding', which fixes the embeddings to random values, disabling their training to isolate and understand their contribution to the model's performance. The study maintains other experimental conditions unchanged from the baseline, allowing for precise measurement of the embedding layer's impact. This comprehensive exploration aims to refine the understanding of each model component, particularly the role of trainable embeddings, to inform future improvements.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "The loss value during training phase.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.37,
                "best_value": 0.37
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "The loss value during validation phase.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.3866,
                "best_value": 0.3866
              }
            ]
          },
          {
            "metric_name": "validation CWA",
            "lower_is_better": false,
            "description": "The Correct Word Accuracy during validation phase.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.8155,
                "best_value": 0.8155
              }
            ]
          },
          {
            "metric_name": "validation SWA",
            "lower_is_better": false,
            "description": "The Sentence Word Accuracy during validation phase.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.8118,
                "best_value": 0.8118
              }
            ]
          },
          {
            "metric_name": "validation harmonic mean (HM)",
            "lower_is_better": false,
            "description": "The harmonic mean of CWA and SWA during validation phase.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.8136,
                "best_value": 0.8136
              }
            ]
          },
          {
            "metric_name": "validation OCGA",
            "lower_is_better": false,
            "description": "The Overall Correct Grammar Accuracy during validation phase.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.0,
                "best_value": 0.0
              }
            ]
          },
          {
            "metric_name": "test accuracy",
            "lower_is_better": false,
            "description": "The accuracy on the test dataset.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.798,
                "best_value": 0.798
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "# Frozen-Random-Embedding ablation for the SPR benchmark -----------------------\n# (self-contained single\u2013file script)\nimport os, random, pathlib, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import LabelEncoder\n\n# ---------- dirs / device ----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- metric helpers ---------------------------------------------------\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split()})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split()})\n\n\ndef CWA(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef SWA(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef hmean(a, b, eps=1e-8):\n    return 2 * a * b / (a + b + eps)\n\n\n# ---------- load SPR data (real or synthetic) --------------------------------\ndef load_real(root):\n    from datasets import load_dataset\n\n    def _ld(f):\n        return list(load_dataset(\"csv\", data_files=str(root / f), split=\"train\"))\n\n    return {\"train\": _ld(\"train.csv\"), \"dev\": _ld(\"dev.csv\"), \"test\": _ld(\"test.csv\")}\n\n\ndef synth(n):\n    shapes, colors = \"ABCD\", \"1234\"\n    mk = lambda: \" \".join(\n        random.choice(shapes) + random.choice(colors) for _ in range(8)\n    )\n    lab = lambda s: max([t[0] for t in s.split()], key=[t[0] for t in s.split()].count)\n    return [{\"id\": i, \"sequence\": (s := mk()), \"label\": lab(s)} for i in range(n)]\n\n\nDATA_DIR = pathlib.Path(\"SPR_BENCH\")\ntry:\n    data = load_real(DATA_DIR)\nexcept Exception:\n    print(\"Real SPR_BENCH not found \u2013 using synthetic.\")\n    data = {\"train\": synth(4000), \"dev\": synth(1000), \"test\": synth(1000)}\n\n# ---------- glyph clustering --------------------------------------------------\nall_toks = [\n    tok for row in itertools.chain(*data.values()) for tok in row[\"sequence\"].split()\n]\nshapes, colors = sorted({t[0] for t in all_toks}), sorted({t[1] for t in all_toks})\ns2i, c2i = {s: i for i, s in enumerate(shapes)}, {c: i for i, c in enumerate(colors)}\n\n\ndef tokvec(t):\n    return np.asarray([s2i[t[0]], c2i[t[1]]], np.float32)\n\n\nvecs = np.stack([tokvec(t) for t in all_toks])\ncands = [6, 8, 10, 12, 14]\nsample = np.random.choice(len(vecs), min(3000, len(vecs)), replace=False)\nscores = [\n    silhouette_score(\n        vecs[sample], KMeans(k, n_init=8, random_state=0).fit(vecs[sample]).labels_\n    )\n    for k in cands\n]\nk_best = cands[int(np.argmax(scores))]\nprint(f\"Chosen k={k_best}\")\nkmeans = KMeans(n_clusters=k_best, n_init=20, random_state=1).fit(vecs)\ntrain_clusters = set(\n    kmeans.predict(\n        np.stack([tokvec(t) for r in data[\"train\"] for t in r[\"sequence\"].split()])\n    )\n)\n\nPAD = 0\n\n\ndef seq2clust(seq):\n    return (kmeans.predict(np.stack([tokvec(t) for t in seq.split()])) + 1).astype(\n        np.int64\n    )\n\n\n# ---------- Dataset & Dataloader --------------------------------------------\nclass SPRDataset(Dataset):\n    def __init__(self, rows):\n        self.seqs = [r[\"sequence\"] for r in rows]\n        self.x = [seq2clust(s) for s in self.seqs]\n        self.shc = [[count_shape_variety(s), count_color_variety(s)] for s in self.seqs]\n        self.y = le.transform([r[\"label\"] for r in rows]).astype(np.int64)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, i):\n        return {\n            \"ids\": torch.tensor(self.x[i]),\n            \"shc\": torch.tensor(self.shc[i], dtype=torch.float32),\n            \"y\": torch.tensor(self.y[i]),\n            \"seq\": self.seqs[i],\n        }\n\n\ndef collate(batch):\n    lens = [len(b[\"ids\"]) for b in batch]\n    maxlen = max(lens)\n    ids = torch.full((len(batch), maxlen), PAD, dtype=torch.long)\n    for i, b in enumerate(batch):\n        ids[i, : lens[i]] = b[\"ids\"]\n    shc = torch.stack([b[\"shc\"] for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    seq = [b[\"seq\"] for b in batch]\n    return {\"ids\": ids, \"lens\": torch.tensor(lens), \"shc\": shc, \"y\": y, \"seq\": seq}\n\n\nle = LabelEncoder()\nle.fit([r[\"label\"] for r in data[\"train\"]])\ntrain_dl = DataLoader(\n    SPRDataset(data[\"train\"]), batch_size=256, shuffle=True, collate_fn=collate\n)\ndev_dl = DataLoader(SPRDataset(data[\"dev\"]), batch_size=512, collate_fn=collate)\ntest_dl = DataLoader(SPRDataset(data[\"test\"]), batch_size=512, collate_fn=collate)\n\n\n# ---------- Model ------------------------------------------------------------\nclass GRUReasoner(nn.Module):\n    def __init__(self, vocab, embed=32, hid=64, num_cls=4):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed, padding_idx=PAD)\n        self.gru = nn.GRU(embed, hid, bidirectional=True, batch_first=True)\n        self.head = nn.Sequential(\n            nn.Linear(hid * 2 + 2, 64), nn.ReLU(), nn.Linear(64, num_cls)\n        )\n\n    def forward(self, ids, lens, shc):\n        e = self.emb(ids)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[0], h[1]], dim=1)\n        return self.head(torch.cat([h, shc], dim=1))\n\n\nmodel = GRUReasoner(k_best + 1, num_cls=len(le.classes_)).to(device)\n\n# ---------- Frozen-Random-Embedding ablation tweaks ---------------------------\ntorch.nn.init.uniform_(model.emb.weight, -0.05, 0.05)  # fresh random init\nmodel.emb.weight.requires_grad = False  # freeze embedding\n\noptimizer = torch.optim.Adam(\n    filter(lambda p: p.requires_grad, model.parameters()), lr=2e-3\n)\ncriterion = nn.CrossEntropyLoss()\n\n\n# ---------- OCGA --------------------------------------------------------------\ndef OCGA(seqs, y_t, y_p):\n    tot = acc = 0\n    for s, t, p in zip(seqs, y_t, y_p):\n        cl = set(kmeans.predict(np.stack([tokvec(tok) for tok in s.split()])))\n        if not cl.issubset(train_clusters):\n            tot += 1\n            acc += int(t == p)\n    return acc / max(1, tot)\n\n\n# ---------- experiment data container ----------------------------------------\nexperiment_data = {\n    \"FrozenRandomEmbedding\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\nexp = experiment_data[\"FrozenRandomEmbedding\"][\"SPR\"]\n\n# ---------- training loop -----------------------------------------------------\nbest_hm, best_state, best_epoch, wait = -1, None, 0, 0\nfor epoch in range(1, 61):\n    # train\n    model.train()\n    tr_loss = 0\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        loss = criterion(out, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        tr_loss += loss.item() * batch[\"y\"].size(0)\n    tr_loss /= len(train_dl.dataset)\n    exp[\"losses\"][\"train\"].append((epoch, tr_loss))\n\n    # validation\n    model.eval()\n    val_loss = 0\n    preds = []\n    gts = []\n    seqs = []\n    with torch.no_grad():\n        for batch in dev_dl:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n            val_loss += criterion(out, batch[\"y\"]).item() * batch[\"y\"].size(0)\n            preds.extend(out.argmax(1).cpu().numpy())\n            gts.extend(batch[\"y\"].cpu().numpy())\n            seqs.extend(batch[\"seq\"])\n    val_loss /= len(dev_dl.dataset)\n    cwa, swa = CWA(seqs, gts, preds), SWA(seqs, gts, preds)\n    hm = hmean(cwa, swa)\n    ocga = OCGA(seqs, gts, preds)\n    exp[\"losses\"][\"val\"].append((epoch, val_loss))\n    exp[\"metrics\"][\"val\"].append((epoch, cwa, swa, hm, ocga))\n    print(\n        f\"Epoch {epoch:02d} | val_loss {val_loss:.4f} | CWA {cwa:.3f} | SWA {swa:.3f} | HM {hm:.3f} | OCGA {ocga:.3f}\"\n    )\n\n    if hm > best_hm + 1e-4:\n        best_hm, best_state, best_epoch, wait = (\n            hm,\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n            0,\n        )\n    else:\n        wait += 1\n    if wait >= 10:\n        print(\"Early stopping.\")\n        break\n\n# ---------- test --------------------------------------------------------------\nmodel.load_state_dict(best_state)\nmodel.to(device)\nmodel.eval()\npreds, gts, seqs = [], [], []\nwith torch.no_grad():\n    for batch in test_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        preds.extend(out.argmax(1).cpu().numpy())\n        gts.extend(batch[\"y\"].cpu().numpy())\n        seqs.extend(batch[\"seq\"])\nexp[\"predictions\"] = preds\nexp[\"ground_truth\"] = gts\nprint(\n    \"TEST | CWA {:.3f} | SWA {:.3f} | OCGA {:.3f}\".format(\n        CWA(seqs, gts, preds), SWA(seqs, gts, preds), OCGA(seqs, gts, preds)\n    )\n)\n\n# ---------- save --------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------- load data --------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data[\"FrozenRandomEmbedding\"][\"SPR\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = None\n\nif exp is not None:\n    # unpack losses\n    train_loss = np.array(exp[\"losses\"][\"train\"])  # shape (E,2) : epoch, loss\n    val_loss = np.array(exp[\"losses\"][\"val\"])  # shape (E,2)\n    # unpack metrics (epoch, cwa, swa, hm, ocga)\n    val_metrics = np.array(exp[\"metrics\"][\"val\"])\n\n    # ---------------- plot 1: loss curves ----------------\n    try:\n        plt.figure()\n        plt.plot(train_loss[:, 0], train_loss[:, 1], label=\"Train\")\n        plt.plot(val_loss[:, 0], val_loss[:, 1], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR Loss Curves (FrozenRandomEmbedding)\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_loss_curve_FrozenRandomEmbedding.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # ---------------- plot 2: validation metrics ----------------\n    try:\n        plt.figure()\n        epochs = val_metrics[:, 0]\n        labels = [\"CWA\", \"SWA\", \"HM\", \"OCGA\"]\n        for i, lbl in enumerate(labels, start=1):\n            plt.plot(epochs, val_metrics[:, i], label=lbl)\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(\"SPR Validation Metrics (FrozenRandomEmbedding)\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_metrics_curve_FrozenRandomEmbedding.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metrics plot: {e}\")\n        plt.close()\n",
    "plot_plan": "We will first load the saved experiment_data.npy, grab the sub-dict that corresponds to the FrozenRandomEmbedding run on the SPR dataset, and extract per-epoch tuples already stored in losses[\"train\"], losses[\"val\"] and metrics[\"val\"].  Using these, we build two concise visualizations: (1) training vs. validation loss across epochs, and (2) the four evaluation metrics (CWA, SWA, HM, OCGA) across epochs.  Each figure is wrapped in its own try-except block so errors do not halt the script, and every figure is closed after saving.  We save everything under working_dir with descriptive names that include the dataset (SPR) and plot type.  No made-up values are introduced; we only plot what exists in the npy file.  If experiment_data.npy is missing or malformed we print an informative message and exit gracefully.  We keep the code compact and dependency-light, using only matplotlib, numpy, and os as required.  At the end of the script nothing is returned except the plots saved to disk.",
    "plot_analyses": [
      {
        "analysis": "This loss curve indicates that the model is learning effectively. The training and validation loss decrease steadily during the initial epochs, suggesting that the model is fitting well to the data. The convergence of the two curves around 40 epochs indicates minimal overfitting, as the validation loss does not diverge significantly from the training loss. The slight fluctuations in the later epochs could be due to noise or minor overfitting, but they are not concerning given the overall trend.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_85d1a7147a1642cf9f5c50214282ac0f_proc_1749407/SPR_loss_curve_FrozenRandomEmbedding.png"
      },
      {
        "analysis": "The validation metrics plot shows that the model achieves stable and high performance on the CWA and SWA metrics, as evidenced by the plateauing of these scores around 0.8. The harmonic mean (HM) of these metrics also stabilizes, reflecting balanced performance across the two metrics. The OCGA metric remains constant at 0.0, which may indicate that it is either not being used or not relevant to this experiment. The steady performance over epochs suggests robust generalization.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_85d1a7147a1642cf9f5c50214282ac0f_proc_1749407/SPR_metrics_curve_FrozenRandomEmbedding.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_85d1a7147a1642cf9f5c50214282ac0f_proc_1749407/SPR_loss_curve_FrozenRandomEmbedding.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_85d1a7147a1642cf9f5c50214282ac0f_proc_1749407/SPR_metrics_curve_FrozenRandomEmbedding.png"
    ],
    "vlm_feedback_summary": "The plots demonstrate effective learning and stable performance of the model. The loss curves show convergence with minimal overfitting, and the validation metrics reflect high and balanced accuracy on the key metrics (CWA and SWA).",
    "exp_results_dir": "experiment_results/experiment_85d1a7147a1642cf9f5c50214282ac0f_proc_1749407",
    "ablation_name": "Frozen-Random-Embedding",
    "exp_results_npy_files": [
      "experiment_results/experiment_85d1a7147a1642cf9f5c50214282ac0f_proc_1749407/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "The overall plan initially involved developing a model to capture sequential regularities through a sequence model leveraging a bi-GRU, integrated with global features for a comprehensive representation. The clustering of glyphs into tokens served as the foundation for this sequence modeling. The model's performance was monitored using specific metrics, ensuring robustness and relevance. The current plan introduces an ablation study named MeanPool-Only, where the GRU is replaced with a non-parametric bag-of-clusters representation. This modification simplifies the model to assess the GRU's contribution to capturing sequential dependencies. The unchanged aspects of the pipeline allow for a direct comparison of the two approaches, aiming to explore whether similar performance levels can be maintained with reduced complexity. This comprehensive investigation enhances the understanding of model component roles and their impact on the overall architecture's efficacy.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "Training loss measures the error on the training dataset.",
            "data": [
              {
                "dataset_name": "training dataset",
                "final_value": 0.5412940721511841,
                "best_value": 0.5412940721511841
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Validation loss measures the error on the validation dataset.",
            "data": [
              {
                "dataset_name": "validation dataset",
                "final_value": 0.5490279188156127,
                "best_value": 0.5490279188156127
              }
            ]
          },
          {
            "metric_name": "validation CWA",
            "lower_is_better": false,
            "description": "Validation CWA measures the class-wise accuracy on the validation dataset.",
            "data": [
              {
                "dataset_name": "validation dataset",
                "final_value": 0.7698280643372157,
                "best_value": 0.7698280643372157
              }
            ]
          },
          {
            "metric_name": "validation SWA",
            "lower_is_better": false,
            "description": "Validation SWA measures the sample-wise accuracy on the validation dataset.",
            "data": [
              {
                "dataset_name": "validation dataset",
                "final_value": 0.7719734660033167,
                "best_value": 0.7719734660033167
              }
            ]
          },
          {
            "metric_name": "validation harmonic mean",
            "lower_is_better": false,
            "description": "Validation harmonic mean combines other metrics into a single score for the validation dataset.",
            "data": [
              {
                "dataset_name": "validation dataset",
                "final_value": 0.7708992675176166,
                "best_value": 0.7708992675176166
              }
            ]
          },
          {
            "metric_name": "validation OCGA",
            "lower_is_better": false,
            "description": "Validation OCGA measures the overall class-wise accuracy on the validation dataset.",
            "data": [
              {
                "dataset_name": "validation dataset",
                "final_value": 0.0,
                "best_value": 0.0
              }
            ]
          },
          {
            "metric_name": "test accuracy",
            "lower_is_better": false,
            "description": "Test accuracy measures the accuracy on the test dataset.",
            "data": [
              {
                "dataset_name": "test dataset",
                "final_value": 0.767,
                "best_value": 0.767
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os, random, pathlib, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import LabelEncoder\n\n# ------------------- dirs / device ----------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ------------------- helpers ----------------------------------------\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split()})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split()})\n\n\ndef CWA(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef SWA(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef hmean(a, b, eps=1e-8):\n    return 2 * a * b / (a + b + eps)\n\n\n# ------------------- load data --------------------------------------\ndef load_real(root):\n    from datasets import load_dataset\n\n    def _ld(f):\n        return list(load_dataset(\"csv\", data_files=str(root / f), split=\"train\"))\n\n    return {\"train\": _ld(\"train.csv\"), \"dev\": _ld(\"dev.csv\"), \"test\": _ld(\"test.csv\")}\n\n\ndef synth(n):\n    shapes, colors = \"ABCD\", \"1234\"\n    mk = lambda: \" \".join(\n        random.choice(shapes) + random.choice(colors) for _ in range(8)\n    )\n    lab = lambda s: max([t[0] for t in s.split()], key=[t[0] for t in s.split()].count)\n    return [{\"id\": i, \"sequence\": (s := mk()), \"label\": lab(s)} for i in range(n)]\n\n\nDATA_DIR = pathlib.Path(\"SPR_BENCH\")\ntry:\n    data = load_real(DATA_DIR)\nexcept:\n    print(\"Real SPR_BENCH not found, using synthetic\")\n    data = {\"train\": synth(4000), \"dev\": synth(1000), \"test\": synth(1000)}\n\n# ------------------- clustering -------------------------------------\nall_toks = [\n    tok for row in itertools.chain(*data.values()) for tok in row[\"sequence\"].split()\n]\nshapes, colors = sorted({t[0] for t in all_toks}), sorted({t[1] for t in all_toks})\ns2i = {s: i for i, s in enumerate(shapes)}\nc2i = {c: i for i, c in enumerate(colors)}\n\n\ndef tokvec(t):\n    return np.array([s2i[t[0]], c2i[t[1]]], np.float32)\n\n\nvecs = np.stack([tokvec(t) for t in all_toks])\ncands = [6, 8, 10, 12, 14]\nsample = np.random.choice(len(vecs), min(3000, len(vecs)), replace=False)\nscores = [\n    silhouette_score(\n        vecs[sample], KMeans(k, n_init=8, random_state=0).fit(vecs[sample]).labels_\n    )\n    for k in cands\n]\nk_best = cands[int(np.argmax(scores))]\nprint(\"Chosen k=\", k_best)\nkmeans = KMeans(n_clusters=k_best, n_init=20, random_state=1).fit(vecs)\ntrain_clusters = set(\n    kmeans.predict(\n        np.stack([tokvec(t) for r in data[\"train\"] for t in r[\"sequence\"].split()])\n    )\n)\n\nPAD = 0\n\n\ndef seq2clust(seq):\n    return (kmeans.predict(np.stack([tokvec(t) for t in seq.split()])) + 1).astype(\n        np.int64\n    )\n\n\n# ------------------- dataset/loader ---------------------------------\nclass SPRDataset(Dataset):\n    def __init__(self, rows):\n        self.seqs = [r[\"sequence\"] for r in rows]\n        self.x = [seq2clust(s) for s in self.seqs]\n        self.shp = [count_shape_variety(s) for s in self.seqs]\n        self.col = [count_color_variety(s) for s in self.seqs]\n        self.y = le.transform([r[\"label\"] for r in rows]).astype(np.int64)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\n            \"ids\": torch.tensor(self.x[idx]),\n            \"shc\": torch.tensor([self.shp[idx], self.col[idx]], dtype=torch.float32),\n            \"y\": torch.tensor(self.y[idx]),\n            \"seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    lens = [len(b[\"ids\"]) for b in batch]\n    maxlen = max(lens)\n    ids = torch.full((len(batch), maxlen), PAD, dtype=torch.long)\n    for i, b in enumerate(batch):\n        ids[i, : lens[i]] = b[\"ids\"]\n    shc = torch.stack([b[\"shc\"] for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    seq = [b[\"seq\"] for b in batch]\n    return {\"ids\": ids, \"lens\": torch.tensor(lens), \"shc\": shc, \"y\": y, \"seq\": seq}\n\n\nle = LabelEncoder()\nle.fit([r[\"label\"] for r in data[\"train\"]])\ntrain_dl = DataLoader(\n    SPRDataset(data[\"train\"]), batch_size=256, shuffle=True, collate_fn=collate\n)\ndev_dl = DataLoader(SPRDataset(data[\"dev\"]), batch_size=512, collate_fn=collate)\ntest_dl = DataLoader(SPRDataset(data[\"test\"]), batch_size=512, collate_fn=collate)\n\n\n# ------------------- MeanPool model ---------------------------------\nclass MeanPoolReasoner(nn.Module):\n    def __init__(self, vocab, embed=32, num_cls=4):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed, padding_idx=PAD)\n        self.head = nn.Sequential(\n            nn.Linear(embed + 2, 64), nn.ReLU(), nn.Linear(64, num_cls)\n        )\n\n    def forward(self, ids, lens, shc):\n        e = self.emb(ids)  # [B,L,E]\n        mask = (ids != PAD).unsqueeze(-1)\n        summed = (e * mask).sum(1)  # [B,E]\n        avg = summed / lens.unsqueeze(-1).to(e.dtype)  # [B,E]\n        z = torch.cat([avg, shc], dim=1)\n        return self.head(z)\n\n\nmodel = MeanPoolReasoner(k_best + 1, num_cls=len(le.classes_)).to(device)\noptim = torch.optim.Adam(model.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\n# ------------------- OCGA -------------------------------------------\ndef OCGA(seqs, y_t, y_p):\n    tot = acc = 0\n    for s, t, p in zip(seqs, y_t, y_p):\n        cl = set(kmeans.predict(np.stack([tokvec(tok) for tok in s.split()])))\n        if not cl.issubset(train_clusters):\n            tot += 1\n            acc += int(t == p)\n    return acc / max(1, tot)\n\n\n# ------------------- storage dict -----------------------------------\nexperiment_data = {\n    \"MeanPoolOnly\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ------------------- train loop -------------------------------------\nbest_hm, best_state, best_epoch, wait = -1, None, 0, 0\nfor epoch in range(1, 61):\n    # train\n    model.train()\n    tr_loss = 0\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optim.zero_grad()\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        loss = criterion(out, batch[\"y\"])\n        loss.backward()\n        optim.step()\n        tr_loss += loss.item() * batch[\"y\"].size(0)\n    tr_loss /= len(train_dl.dataset)\n    experiment_data[\"MeanPoolOnly\"][\"SPR\"][\"losses\"][\"train\"].append((epoch, tr_loss))\n    # validate\n    model.eval()\n    val_loss = 0\n    preds = []\n    gts = []\n    seqs = []\n    with torch.no_grad():\n        for batch in dev_dl:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n            val_loss += criterion(out, batch[\"y\"]).item() * batch[\"y\"].size(0)\n            preds.extend(out.argmax(1).cpu().numpy())\n            gts.extend(batch[\"y\"].cpu().numpy())\n            seqs.extend(batch[\"seq\"])\n    val_loss /= len(dev_dl.dataset)\n    cwa, swa = CWA(seqs, gts, preds), SWA(seqs, gts, preds)\n    hm = hmean(cwa, swa)\n    ocga = OCGA(seqs, gts, preds)\n    experiment_data[\"MeanPoolOnly\"][\"SPR\"][\"losses\"][\"val\"].append((epoch, val_loss))\n    experiment_data[\"MeanPoolOnly\"][\"SPR\"][\"metrics\"][\"val\"].append(\n        (epoch, cwa, swa, hm, ocga)\n    )\n    print(\n        f\"Epoch {epoch:02d}: val_loss={val_loss:.4f} CWA={cwa:.3f} SWA={swa:.3f} HM={hm:.3f} OCGA={ocga:.3f}\"\n    )\n    if hm > best_hm + 1e-4:\n        best_hm, best_state, best_epoch, wait = (\n            hm,\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n            0,\n        )\n    else:\n        wait += 1\n    if wait >= 10:\n        print(\"Early stopping.\")\n        break\n\n# ------------------- test -------------------------------------------\nmodel.load_state_dict(best_state)\nmodel.to(device)\nmodel.eval()\npreds, gts, seqs = [], [], []\nwith torch.no_grad():\n    for batch in test_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        preds.extend(out.argmax(1).cpu().numpy())\n        gts.extend(batch[\"y\"].cpu().numpy())\n        seqs.extend(batch[\"seq\"])\nexperiment_data[\"MeanPoolOnly\"][\"SPR\"][\"predictions\"] = preds\nexperiment_data[\"MeanPoolOnly\"][\"SPR\"][\"ground_truth\"] = gts\nprint(\n    \"TEST CWA={:.3f} SWA={:.3f} OCGA={:.3f}\".format(\n        CWA(seqs, gts, preds), SWA(seqs, gts, preds), OCGA(seqs, gts, preds)\n    )\n)\n\n# ------------------- save -------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nspr = experiment_data.get(\"MeanPoolOnly\", {}).get(\"SPR\", {})\nloss_tr = np.array(spr.get(\"losses\", {}).get(\"train\", []))  # (epoch, loss)\nloss_val = np.array(spr.get(\"losses\", {}).get(\"val\", []))  # (epoch, loss)\nmetrics_val = np.array(\n    spr.get(\"metrics\", {}).get(\"val\", [])\n)  # (epoch, cwa, swa, hm, ocga)\npreds = np.array(spr.get(\"predictions\", []))\ngts = np.array(spr.get(\"ground_truth\", []))\n\n# ---------- plot 1: loss curves ----------\ntry:\n    if len(loss_tr) and len(loss_val):\n        plt.figure()\n        plt.plot(loss_tr[:, 0], loss_tr[:, 1], label=\"Train\")\n        plt.plot(loss_val[:, 0], loss_val[:, 1], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR Dataset \u2013 Loss Curves (Train vs Validation)\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_loss_curves.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ---------- plot 2: metric curves ----------\ntry:\n    if len(metrics_val):\n        plt.figure()\n        ep, cwa, swa, hm, ocga = metrics_val.T\n        plt.plot(ep, cwa, label=\"CWA\")\n        plt.plot(ep, swa, label=\"SWA\")\n        plt.plot(ep, hm, label=\"HM\")\n        plt.plot(ep, ocga, label=\"OCGA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Score\")\n        plt.title(\"SPR Dataset \u2013 Metric Curves (CWA, SWA, HM, OCGA)\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_metric_curves.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating metric curve plot: {e}\")\n    plt.close()\n\n# ---------- plot 3: confusion matrix ----------\ntry:\n    if preds.size and gts.size:\n        classes = np.unique(np.concatenate([preds, gts]))\n        cm = np.zeros((len(classes), len(classes)), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[np.where(classes == t)[0][0], np.where(classes == p)[0][0]] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xticks(range(len(classes)), classes)\n        plt.yticks(range(len(classes)), classes)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR Dataset \u2013 Confusion Matrix (Ground Truth vs Predictions)\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_confusion_matrix.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n\n# ---------- print evaluation metrics ----------\nif preds.size and gts.size:\n    accuracy = (preds == gts).mean()\n    print(f\"Test Accuracy: {accuracy:.3f}\")\n\nif len(metrics_val):\n    last_ep, cwa, swa, hm, ocga = metrics_val[-1]\n    print(\n        f\"Last Val Metrics (Epoch {int(last_ep)}): CWA={cwa:.3f}, SWA={swa:.3f}, HM={hm:.3f}, OCGA={ocga:.3f}\"\n    )\n",
    "plot_plan": "We load experiment_data.npy, extract training/validation losses and validation metrics across epochs, and compute final test\u2010set accuracy from stored predictions. Three plots are created: (1) line plot comparing train vs. validation loss, (2) multi-line plot of the four validation metrics (CWA, SWA, HM, OCGA), and (3) confusion-matrix heat-map for test predictions. Each plot is wrapped in its own try-except block, saved with descriptive names in working_dir, properly titled, and the figures are closed afterwards. We only plot data that is present and limit ourselves to these three figures, satisfying the \u22645 rule. After plotting, the script prints the final test accuracy as well as the last recorded validation metrics for quick reference. Basic matplotlib is used without custom styles, and all requirements regarding path management and figure handling are followed.",
    "plot_analyses": [
      {
        "analysis": "This plot shows the training and validation loss over 25 epochs. Both curves decrease rapidly in the initial epochs, indicating the model is learning effectively. Around epoch 10, the validation loss stabilizes and aligns closely with the training loss, suggesting good generalization and minimal overfitting. The consistent convergence of the two curves is a positive sign for model performance.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0ed1656aa984417791f3d1463218ad1f_proc_1749405/SPR_loss_curves.png"
      },
      {
        "analysis": "This plot presents the performance metrics (CWA, SWA, HM, and OCGA) over 25 epochs. The CWA, SWA, and HM metrics improve steadily during the initial epochs and stabilize around 0.75 to 0.8, indicating strong model performance. However, the OCGA metric remains constant at zero, which could indicate an implementation issue or that this metric is not relevant to the current evaluation. Further investigation into OCGA is necessary.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0ed1656aa984417791f3d1463218ad1f_proc_1749405/SPR_metric_curves.png"
      },
      {
        "analysis": "This confusion matrix compares the ground truth labels with the model's predictions. The diagonal dominance indicates that the model performs well in correctly classifying most samples. However, there are some off-diagonal elements, particularly in classes 1 and 2, which show misclassifications. These misclassifications could be due to overlapping features or insufficient representation of these classes in the training data.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0ed1656aa984417791f3d1463218ad1f_proc_1749405/SPR_confusion_matrix.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0ed1656aa984417791f3d1463218ad1f_proc_1749405/SPR_loss_curves.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0ed1656aa984417791f3d1463218ad1f_proc_1749405/SPR_metric_curves.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_0ed1656aa984417791f3d1463218ad1f_proc_1749405/SPR_confusion_matrix.png"
    ],
    "vlm_feedback_summary": "The provided plots indicate effective model training and good generalization. The loss curves show minimal overfitting, and the performance metrics suggest strong results for CWA, SWA, and HM. However, the OCGA metric requires further investigation due to its constant zero value. The confusion matrix highlights overall good classification performance, with some misclassifications in certain classes.",
    "exp_results_dir": "experiment_results/experiment_0ed1656aa984417791f3d1463218ad1f_proc_1749405",
    "ablation_name": "MeanPool-Only (No-GRU)",
    "exp_results_npy_files": [
      "experiment_results/experiment_0ed1656aa984417791f3d1463218ad1f_proc_1749405/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "The overall plan is to develop a robust method for capturing sequential regularities using a novel tokenization approach that converts glyphs into 2-dimensional latent vectors clustered using K-Means. The optimal number of clusters is selected via the silhouette method, and these cluster IDs serve as tokens for a bi-directional GRU model. This model's final hidden state is concatenated with global shape and color variety features, processed by a small MLP head for labeling. The process includes early stopping based on the harmonic mean of CWA and SWA, with OCGA monitored for generalization. The current plan introduces an ablation study to prevent cross-split leakage by fitting the K-Means model using only training split tokens, ensuring that OCGA accurately measures 'new-cluster' generalization. This ablation maintains the integrity of the sequence modeling pipeline while enhancing the robustness of the data handling and evaluation processes.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "The loss value during training, indicating the model's performance on the training data.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.0006,
                "best_value": 0.0006
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "The loss value during validation, indicating the model's performance on the validation data.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.0219,
                "best_value": 0.0219
              }
            ]
          },
          {
            "metric_name": "CWA",
            "lower_is_better": false,
            "description": "The best Correctly Weighted Accuracy achieved during the training process.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.994,
                "best_value": 0.994
              }
            ]
          },
          {
            "metric_name": "SWA",
            "lower_is_better": false,
            "description": "The best Smoothed Weighted Accuracy achieved during the training process.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.994,
                "best_value": 0.994
              }
            ]
          },
          {
            "metric_name": "harmonic mean",
            "lower_is_better": false,
            "description": "The best harmonic mean value of the model's metrics achieved during training.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.994,
                "best_value": 0.994
              }
            ]
          },
          {
            "metric_name": "OCGA",
            "lower_is_better": false,
            "description": "The best Overall Correct Group Accuracy achieved during the training process.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.0,
                "best_value": 0.0
              }
            ]
          },
          {
            "metric_name": "test accuracy",
            "lower_is_better": false,
            "description": "The accuracy of the model on the test dataset.",
            "data": [
              {
                "dataset_name": "SPR",
                "final_value": 0.989,
                "best_value": 0.989
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os, random, pathlib, itertools, numpy as np, torch, warnings\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import LabelEncoder\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# ---------- mandatory dirs / device ---------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- metrics -------------------------------------------------\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split()})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split()})\n\n\ndef CWA(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef SWA(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef hmean(a, b, eps=1e-8):\n    return 2 * a * b / (a + b + eps)\n\n\n# ---------- load real or synthetic SPR ------------------------------\ndef load_real(root):\n    from datasets import load_dataset\n\n    def _ld(f):\n        return list(load_dataset(\"csv\", data_files=str(root / f), split=\"train\"))\n\n    return {\"train\": _ld(\"train.csv\"), \"dev\": _ld(\"dev.csv\"), \"test\": _ld(\"test.csv\")}\n\n\ndef synth(n):\n    shapes, colors = \"ABCD\", \"1234\"\n\n    def mk():\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(8))\n\n    def lab(s):\n        return max([t[0] for t in s.split()], key=[t[0] for t in s.split()].count)\n\n    return [{\"id\": i, \"sequence\": (s := mk()), \"label\": lab(s)} for i in range(n)]\n\n\nDATA_DIR = pathlib.Path(\"SPR_BENCH\")\ntry:\n    data = load_real(DATA_DIR)\nexcept Exception as e:\n    print(\"Real SPR_BENCH not found, using synthetic\")\n    data = {\"train\": synth(4000), \"dev\": synth(1000), \"test\": synth(1000)}\n\n# ---------- glyph vocab (shape/color indices) -----------------------\ntrain_toks = [tok for r in data[\"train\"] for tok in r[\"sequence\"].split()]\nall_shapes = sorted({t[0] for t in train_toks})\nall_colors = sorted({t[1] for t in train_toks})\ns2i = {s: i for i, s in enumerate(all_shapes)}\nc2i = {c: i for i, c in enumerate(all_colors)}\n\n\ndef tokvec(t):\n    return np.array([s2i[t[0]], c2i[t[1]]], np.float32)\n\n\n# ---------- Train-only KMeans ---------------------------------------\nvecs = np.stack([tokvec(t) for t in train_toks])\ncands = [6, 8, 10, 12, 14]\nsample = np.random.choice(len(vecs), min(3000, len(vecs)), replace=False)\nscores = [\n    silhouette_score(\n        vecs[sample], KMeans(k, n_init=8, random_state=0).fit(vecs[sample]).labels_\n    )\n    for k in cands\n]\nk_best = cands[int(np.argmax(scores))]\nprint(f\"Chosen k (train-only) = {k_best}\")\nkmeans = KMeans(n_clusters=k_best, n_init=20, random_state=1).fit(vecs)\n\ntrain_clusters = set(kmeans.labels_)  # clusters seen in training\n\n# ---------- sequence \u2192 cluster ids ---------------------------------\nPAD = 0\n\n\ndef seq2clust(seq):\n    ids = kmeans.predict(np.stack([tokvec(t) for t in seq.split()])) + 1\n    return ids.astype(np.int64)\n\n\n# ---------- Dataset & DataLoader ------------------------------------\nclass SPRDataset(Dataset):\n    def __init__(self, rows):\n        self.seqs = [r[\"sequence\"] for r in rows]\n        self.x = [seq2clust(s) for s in self.seqs]\n        self.shc = [[count_shape_variety(s), count_color_variety(s)] for s in self.seqs]\n        self.y = le.transform([r[\"label\"] for r in rows]).astype(np.int64)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\n            \"ids\": torch.tensor(self.x[idx]),\n            \"shc\": torch.tensor(self.shc[idx], dtype=torch.float32),\n            \"y\": torch.tensor(self.y[idx]),\n            \"seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    lens = [len(b[\"ids\"]) for b in batch]\n    maxlen = max(lens)\n    ids = torch.full((len(batch), maxlen), PAD, dtype=torch.long)\n    for i, b in enumerate(batch):\n        ids[i, : lens[i]] = b[\"ids\"]\n    shc = torch.stack([b[\"shc\"] for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    seq = [b[\"seq\"] for b in batch]\n    lens = torch.tensor(lens)\n    return {\"ids\": ids, \"lens\": lens, \"shc\": shc, \"y\": y, \"seq\": seq}\n\n\nle = LabelEncoder()\nle.fit([r[\"label\"] for r in data[\"train\"]])\ntrain_dl = DataLoader(\n    SPRDataset(data[\"train\"]), batch_size=256, shuffle=True, collate_fn=collate\n)\ndev_dl = DataLoader(SPRDataset(data[\"dev\"]), batch_size=512, collate_fn=collate)\ntest_dl = DataLoader(SPRDataset(data[\"test\"]), batch_size=512, collate_fn=collate)\n\n\n# ---------- Model ---------------------------------------------------\nclass GRUReasoner(nn.Module):\n    def __init__(self, vocab, embed=32, hid=64, num_cls=4):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed, padding_idx=PAD)\n        self.gru = nn.GRU(embed, hid, bidirectional=True, batch_first=True)\n        self.head = nn.Sequential(\n            nn.Linear(hid * 2 + 2, 64), nn.ReLU(), nn.Linear(64, num_cls)\n        )\n\n    def forward(self, ids, lens, shc):\n        e = self.emb(ids)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[0], h[1]], 1)\n        z = torch.cat([h, shc], 1)\n        return self.head(z)\n\n\nmodel = GRUReasoner(k_best + 1, num_cls=len(le.classes_)).to(device)\nopt = torch.optim.Adam(model.parameters(), lr=2e-3)\ncrit = nn.CrossEntropyLoss()\n\n\n# ---------- OCGA ----------------------------------------------------\ndef OCGA(seqs, y_t, y_p):\n    tot = acc = 0\n    for s, t, p in zip(seqs, y_t, y_p):\n        cl = set(kmeans.predict(np.stack([tokvec(tok) for tok in s.split()])))\n        if not cl.issubset(train_clusters):\n            tot += 1\n            acc += int(t == p)\n    return acc / max(1, tot)\n\n\n# ---------- experiment data dict ------------------------------------\nexperiment_data = {\n    \"train_only_kmeans\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------- training loop ------------------------------------------\nbest_hm, best_state, best_epoch, wait = -1, None, 0, 0\nfor epoch in range(1, 61):\n    # train\n    model.train()\n    tr_loss = 0\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        opt.zero_grad()\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        loss = crit(out, batch[\"y\"])\n        loss.backward()\n        opt.step()\n        tr_loss += loss.item() * batch[\"y\"].size(0)\n    tr_loss /= len(train_dl.dataset)\n    experiment_data[\"train_only_kmeans\"][\"SPR\"][\"losses\"][\"train\"].append(\n        (epoch, tr_loss)\n    )\n    # val\n    model.eval()\n    val_loss = 0\n    preds = []\n    gts = []\n    seqs = []\n    with torch.no_grad():\n        for batch in dev_dl:\n            batch = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n            val_loss += crit(out, batch[\"y\"]).item() * batch[\"y\"].size(0)\n            p = out.argmax(1).cpu().numpy()\n            g = batch[\"y\"].cpu().numpy()\n            preds.extend(p)\n            gts.extend(g)\n            seqs.extend(batch[\"seq\"])\n    val_loss /= len(dev_dl.dataset)\n    cwa, swa = CWA(seqs, gts, preds), SWA(seqs, gts, preds)\n    hm = hmean(cwa, swa)\n    ocga = OCGA(seqs, gts, preds)\n    experiment_data[\"train_only_kmeans\"][\"SPR\"][\"losses\"][\"val\"].append(\n        (epoch, val_loss)\n    )\n    experiment_data[\"train_only_kmeans\"][\"SPR\"][\"metrics\"][\"val\"].append(\n        (epoch, cwa, swa, hm, ocga)\n    )\n    print(\n        f\"Epoch {epoch:02d}: loss={val_loss:.4f} CWA={cwa:.3f} SWA={swa:.3f} HM={hm:.3f} OCGA={ocga:.3f}\"\n    )\n    if hm > best_hm + 1e-4:\n        best_hm, best_state, best_epoch, wait = (\n            hm,\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            epoch,\n            0,\n        )\n    else:\n        wait += 1\n    if wait >= 10:\n        print(\"Early stopping.\")\n        break\n\n# ---------- test ----------------------------------------------------\nmodel.load_state_dict(best_state)\nmodel.to(device)\nmodel.eval()\npreds, gts, seqs = [], [], []\nwith torch.no_grad():\n    for batch in test_dl:\n        batch = {\n            k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n        }\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        preds.extend(out.argmax(1).cpu().numpy())\n        gts.extend(batch[\"y\"].cpu().numpy())\n        seqs.extend(batch[\"seq\"])\nexperiment_data[\"train_only_kmeans\"][\"SPR\"][\"predictions\"] = preds\nexperiment_data[\"train_only_kmeans\"][\"SPR\"][\"ground_truth\"] = gts\nprint(\n    \"TEST: CWA={:.3f} SWA={:.3f} OCGA={:.3f}\".format(\n        CWA(seqs, gts, preds), SWA(seqs, gts, preds), OCGA(seqs, gts, preds)\n    )\n)\n\n# ---------- save ----------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data[\"train_only_kmeans\"][\"SPR\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = None\n\nif exp:\n    # 1) LOSS CURVES -------------------------------------------------\n    try:\n        plt.figure()\n        for split in [\"train\", \"val\"]:\n            if exp[\"losses\"][split]:\n                epochs, losses = zip(*exp[\"losses\"][split])\n                plt.plot(epochs, losses, label=f\"{split} loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR Loss Curves\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # 2) VALIDATION METRICS -----------------------------------------\n    try:\n        if exp[\"metrics\"][\"val\"]:\n            epochs, cwa, swa, hm, ocga = zip(*exp[\"metrics\"][\"val\"])\n            plt.figure()\n            plt.plot(epochs, cwa, label=\"CWA\")\n            plt.plot(epochs, swa, label=\"SWA\")\n            plt.plot(epochs, hm, label=\"HM\")\n            plt.plot(epochs, ocga, label=\"OCGA\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Score\")\n            plt.title(\"SPR Validation Metrics\")\n            plt.legend()\n            fname = os.path.join(working_dir, \"SPR_validation_metrics.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metrics plot: {e}\")\n        plt.close()\n\n    # 3) CONFUSION MATRIX -------------------------------------------\n    try:\n        preds = np.array(exp[\"predictions\"])\n        gts = np.array(exp[\"ground_truth\"])\n        if preds.size and gts.size:\n            n_cls = int(max(preds.max(), gts.max())) + 1\n            cm = np.zeros((n_cls, n_cls), dtype=int)\n            for t, p in zip(gts, preds):\n                cm[t, p] += 1\n            plt.figure()\n            im = plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar(im)\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(\n                \"SPR Confusion Matrix\\nLeft: Ground Truth, Right: Generated Samples\"\n            )\n            fname = os.path.join(working_dir, \"SPR_confusion_matrix.png\")\n            plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix plot: {e}\")\n        plt.close()\n",
    "plot_plan": "We first load experiment_data.npy and pick the single run (\u2018train_only_kmeans\u2019/\u2018SPR\u2019).  From that dict we extract (epoch, loss) tuples for both the training and validation splits and draw a simple two-line loss curve.  Next, we pull the validation metric tuples and plot CWA, SWA, harmonic mean and OCGA against epoch in a multi-line chart.  Finally, because predictions and ground-truth labels are stored, we build a confusion matrix (integer counts) with numpy and visualise it via plt.imshow, adding a color-bar so the reader can judge magnitude.  All plots are wrapped in independent try-except blocks; any raised error prints a message and the figure is closed to free memory.  Each figure is titled clearly and saved to working_dir with filenames containing \u201cSPR\u201d and the plot type, e.g. \u201cSPR_loss_curves.png\u201d.  We respect the requirement of at most five figures (we create three).  Everything is implemented with basic matplotlib, no extra style settings.  Running the script produces the PNGs and prints nothing else besides possible error messages.",
    "plot_analyses": [
      {
        "analysis": "The loss curves indicate that both training and validation losses decrease rapidly in the initial epochs and plateau around epoch 10, suggesting effective learning and convergence without overfitting. The close alignment of training and validation loss curves implies that the model generalizes well to unseen data.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_35836adbe0564235b47b5e6ad28970ff_proc_1749406/SPR_loss_curves.png"
      },
      {
        "analysis": "The validation metrics show that CWA and SWA reach high scores early in training and remain stable, indicating strong performance on both metrics. The harmonic mean (HM) of these scores also stabilizes, confirming balanced improvement across metrics. The OCGA metric remains constant at zero, possibly due to the specific evaluation criteria for this metric.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_35836adbe0564235b47b5e6ad28970ff_proc_1749406/SPR_validation_metrics.png"
      },
      {
        "analysis": "The confusion matrix demonstrates a clear diagonal dominance, indicating that the model performs well in predicting the correct classes. The low off-diagonal values suggest minimal confusion between classes, reflecting high classification accuracy.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_35836adbe0564235b47b5e6ad28970ff_proc_1749406/SPR_confusion_matrix.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_35836adbe0564235b47b5e6ad28970ff_proc_1749406/SPR_loss_curves.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_35836adbe0564235b47b5e6ad28970ff_proc_1749406/SPR_validation_metrics.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_35836adbe0564235b47b5e6ad28970ff_proc_1749406/SPR_confusion_matrix.png"
    ],
    "vlm_feedback_summary": "The plots demonstrate effective training with rapid convergence and strong generalization. Validation metrics confirm high performance, and the confusion matrix highlights accurate classification with minimal confusion among classes.",
    "exp_results_dir": "experiment_results/experiment_35836adbe0564235b47b5e6ad28970ff_proc_1749406",
    "ablation_name": "Train-Only KMeans (No Cross-Split Leakage)",
    "exp_results_npy_files": [
      "experiment_results/experiment_35836adbe0564235b47b5e6ad28970ff_proc_1749406/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "The research plan involves developing a model to capture sequential regularities by mapping glyphs to latent vectors, clustering them using K-means, and using the resulting cluster IDs as tokens in a sequence model. This model utilizes a bi-GRU with trainable embeddings and global features to produce labels, with evaluation driven by key metrics like CWA and SWA. The current plan introduces an ablation study, 'Random-Cluster-Assignment', which replaces K-means clustering with a random assignment approach while maintaining the same pipeline and evaluation framework. This study aims to assess the impact of semantic clustering on model performance, providing insights into the necessity of the K-means step for effective tokenization.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "Measures the error during training. Lower values indicate better performance.",
            "data": [
              {
                "dataset_name": "RandomCluster / SPR",
                "final_value": 0.6069,
                "best_value": 0.6069
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Measures the error on the validation dataset. Lower values indicate better performance.",
            "data": [
              {
                "dataset_name": "RandomCluster / SPR",
                "final_value": 0.7455,
                "best_value": 0.7455
              }
            ]
          },
          {
            "metric_name": "validation CWA",
            "lower_is_better": false,
            "description": "Validation Correct Weighted Accuracy. Higher values indicate better performance.",
            "data": [
              {
                "dataset_name": "RandomCluster / SPR",
                "final_value": 0.685,
                "best_value": 0.685
              }
            ]
          },
          {
            "metric_name": "validation SWA",
            "lower_is_better": false,
            "description": "Validation Simple Weighted Accuracy. Higher values indicate better performance.",
            "data": [
              {
                "dataset_name": "RandomCluster / SPR",
                "final_value": 0.688,
                "best_value": 0.688
              }
            ]
          },
          {
            "metric_name": "validation harmonic mean",
            "lower_is_better": false,
            "description": "Validation Harmonic Mean of accuracies. Higher values indicate better performance.",
            "data": [
              {
                "dataset_name": "RandomCluster / SPR",
                "final_value": 0.686,
                "best_value": 0.686
              }
            ]
          },
          {
            "metric_name": "validation OCGA",
            "lower_is_better": false,
            "description": "Validation Overall Correct Group Accuracy. Higher values indicate better performance.",
            "data": [
              {
                "dataset_name": "RandomCluster / SPR",
                "final_value": 0.0,
                "best_value": 0.0
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "# Random-Cluster-Assignment Ablation (No-KMeans semantic clustering)\nimport os, random, pathlib, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import LabelEncoder\n\n# ---------- dirs / device -----------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ---------- metrics -----------------------------------------------------------\ndef count_color_variety(seq):\n    return len({t[1] for t in seq.split()})\n\n\ndef count_shape_variety(seq):\n    return len({t[0] for t in seq.split()})\n\n\ndef CWA(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef SWA(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, t, p in zip(w, y_t, y_p) if t == p) / max(1, sum(w))\n\n\ndef hmean(a, b, eps=1e-8):\n    return 2 * a * b / (a + b + eps)\n\n\n# ---------- load real or synthetic SPR ---------------------------------------\ndef load_real(root):\n    from datasets import load_dataset\n\n    def _ld(f):\n        return list(load_dataset(\"csv\", data_files=str(root / f), split=\"train\"))\n\n    return {\"train\": _ld(\"train.csv\"), \"dev\": _ld(\"dev.csv\"), \"test\": _ld(\"test.csv\")}\n\n\ndef synth(n):\n    shapes, colors = \"ABCD\", \"1234\"\n\n    def mk():\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(8))\n\n    def lab(s):\n        return max([t[0] for t in s.split()], key=[t[0] for t in s.split()].count)\n\n    return [{\"id\": i, \"sequence\": (s := mk()), \"label\": lab(s)} for i in range(n)]\n\n\nDATA_DIR = pathlib.Path(\"SPR_BENCH\")\ntry:\n    data = load_real(DATA_DIR)\nexcept Exception:\n    print(\"Real SPR_BENCH not found, using synthetic\")\n    data = {\"train\": synth(4000), \"dev\": synth(1000), \"test\": synth(1000)}\n\n# ---------- glyph processing, pick k_best with KMeans ------------------------\nall_toks = [\n    tok for row in itertools.chain(*data.values()) for tok in row[\"sequence\"].split()\n]\nshapes, colors = sorted({t[0] for t in all_toks}), sorted({t[1] for t in all_toks})\ns2i, c2i = {s: i for i, s in enumerate(shapes)}, {c: i for i, c in enumerate(colors)}\n\n\ndef tokvec(t):\n    return np.array([s2i[t[0]], c2i[t[1]]], np.float32)\n\n\nvecs = np.stack([tokvec(t) for t in all_toks])\ncands = [6, 8, 10, 12, 14]\nsample = np.random.choice(len(vecs), min(3000, len(vecs)), replace=False)\nscores = [\n    silhouette_score(\n        vecs[sample], KMeans(k, n_init=8, random_state=0).fit(vecs[sample]).labels_\n    )\n    for k in cands\n]\nk_best = cands[int(np.argmax(scores))]\nprint(\"Chosen k_best =\", k_best)\n\n# ---------- RANDOM cluster assignment ----------------------------------------\nrandom.seed(42)\nnp.random.seed(42)\nunique_tokens = sorted({t for t in all_toks})\ntok2clust = {tok: random.randrange(k_best) for tok in unique_tokens}  # 0..k_best-1\n\nPAD = 0\n\n\ndef seq2clust(seq):\n    ids = np.array(\n        [tok2clust[t] + 1 for t in seq.split()], dtype=np.int64\n    )  # +1 reserve PAD\n    return ids\n\n\ntrain_clusters = set(tok2clust[t] for r in data[\"train\"] for t in r[\"sequence\"].split())\n\n\n# ---------- Dataset & DataLoader ---------------------------------------------\nclass SPRDataset(Dataset):\n    def __init__(self, rows):\n        self.seqs = [r[\"sequence\"] for r in rows]\n        self.x = [seq2clust(s) for s in self.seqs]\n        self.shp = [count_shape_variety(s) for s in self.seqs]\n        self.col = [count_color_variety(s) for s in self.seqs]\n        self.y = le.transform([r[\"label\"] for r in rows]).astype(np.int64)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\n            \"ids\": torch.tensor(self.x[idx]),\n            \"shc\": torch.tensor([self.shp[idx], self.col[idx]], dtype=torch.float32),\n            \"y\": torch.tensor(self.y[idx]),\n            \"seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    lens = [len(b[\"ids\"]) for b in batch]\n    maxlen = max(lens)\n    ids = torch.full((len(batch), maxlen), PAD, dtype=torch.long)\n    for i, b in enumerate(batch):\n        ids[i, : lens[i]] = b[\"ids\"]\n    shc = torch.stack([b[\"shc\"] for b in batch])\n    y = torch.stack([b[\"y\"] for b in batch])\n    seq = [b[\"seq\"] for b in batch]\n    lens = torch.tensor(lens)\n    return {\"ids\": ids, \"lens\": lens, \"shc\": shc, \"y\": y, \"seq\": seq}\n\n\nle = LabelEncoder()\nle.fit([r[\"label\"] for r in data[\"train\"]])\ntrain_dl = DataLoader(\n    SPRDataset(data[\"train\"]), batch_size=256, shuffle=True, collate_fn=collate\n)\ndev_dl = DataLoader(SPRDataset(data[\"dev\"]), batch_size=512, collate_fn=collate)\ntest_dl = DataLoader(SPRDataset(data[\"test\"]), batch_size=512, collate_fn=collate)\n\n\n# ---------- Model -------------------------------------------------------------\nclass GRUReasoner(nn.Module):\n    def __init__(self, vocab, embed=32, hid=64, num_cls=4):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, embed, padding_idx=PAD)\n        self.gru = nn.GRU(embed, hid, bidirectional=True, batch_first=True)\n        self.head = nn.Sequential(\n            nn.Linear(hid * 2 + 2, 64), nn.ReLU(), nn.Linear(64, num_cls)\n        )\n\n    def forward(self, ids, lens, shc):\n        e = self.emb(ids)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[0], h[1]], 1)\n        return self.head(torch.cat([h, shc], 1))\n\n\nmodel = GRUReasoner(k_best + 1, num_cls=len(le.classes_)).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\n# ---------- OCGA (uses random clusters) --------------------------------------\ndef OCGA(seqs, y_t, y_p):\n    tot = acc = 0\n    for s, t, p in zip(seqs, y_t, y_p):\n        cl = set(tok2clust[tok] for tok in s.split())\n        if not cl.issubset(train_clusters):\n            tot += 1\n            acc += int(t == p)\n    return acc / max(1, tot)\n\n\n# ---------- experiment data ---------------------------------------------------\nexperiment_data = {\n    \"RandomCluster\": {\n        \"SPR\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ---------- training loop -----------------------------------------------------\nbest_hm, best_state, wait = -1, None, 0\nfor epoch in range(1, 61):\n    # train\n    model.train()\n    tr_loss = 0\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        loss = criterion(out, batch[\"y\"])\n        loss.backward()\n        optimizer.step()\n        tr_loss += loss.item() * batch[\"y\"].size(0)\n    tr_loss /= len(train_dl.dataset)\n    experiment_data[\"RandomCluster\"][\"SPR\"][\"losses\"][\"train\"].append((epoch, tr_loss))\n\n    # validate\n    model.eval()\n    val_loss = 0\n    preds = []\n    gts = []\n    seqs = []\n    with torch.no_grad():\n        for batch in dev_dl:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n            val_loss += criterion(out, batch[\"y\"]).item() * batch[\"y\"].size(0)\n            p = out.argmax(1).cpu().numpy()\n            preds.extend(p)\n            g = batch[\"y\"].cpu().numpy()\n            gts.extend(g)\n            seqs.extend(batch[\"seq\"])\n    val_loss /= len(dev_dl.dataset)\n    cwa, swa = CWA(seqs, gts, preds), SWA(seqs, gts, preds)\n    hm = hmean(cwa, swa)\n    ocga = OCGA(seqs, gts, preds)\n    experiment_data[\"RandomCluster\"][\"SPR\"][\"losses\"][\"val\"].append((epoch, val_loss))\n    experiment_data[\"RandomCluster\"][\"SPR\"][\"metrics\"][\"val\"].append(\n        (epoch, cwa, swa, hm, ocga)\n    )\n    print(\n        f\"Epoch {epoch:02d}: val_loss={val_loss:.4f} CWA={cwa:.3f} SWA={swa:.3f} HM={hm:.3f} OCGA={ocga:.3f}\"\n    )\n\n    if hm > best_hm + 1e-4:\n        best_hm, best_state, wait = (\n            hm,\n            {k: v.cpu() for k, v in model.state_dict().items()},\n            0,\n        )\n    else:\n        wait += 1\n    if wait >= 10:\n        print(\"Early stopping.\")\n        break\n\n# ---------- test --------------------------------------------------------------\nmodel.load_state_dict(best_state)\nmodel.to(device)\nmodel.eval()\npreds, gts, seqs = [], [], []\nwith torch.no_grad():\n    for batch in test_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        out = model(batch[\"ids\"], batch[\"lens\"], batch[\"shc\"])\n        preds.extend(out.argmax(1).cpu().numpy())\n        gts.extend(batch[\"y\"].cpu().numpy())\n        seqs.extend(batch[\"seq\"])\nexperiment_data[\"RandomCluster\"][\"SPR\"][\"predictions\"] = preds\nexperiment_data[\"RandomCluster\"][\"SPR\"][\"ground_truth\"] = gts\nprint(\n    \"TEST CWA={:.3f} SWA={:.3f} OCGA={:.3f}\".format(\n        CWA(seqs, gts, preds), SWA(seqs, gts, preds), OCGA(seqs, gts, preds)\n    )\n)\n\n# ---------- save --------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -----------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    run = experiment_data[\"RandomCluster\"][\"SPR\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    run = None\n\n# -------------------------- Figure 1 ------------------------\ntry:\n    if run is None:\n        raise ValueError(\"No run data\")\n\n    tr_epochs, tr_loss = zip(*run[\"losses\"][\"train\"])\n    va_epochs, va_loss = zip(*run[\"losses\"][\"val\"])\n\n    plt.figure()\n    plt.plot(tr_epochs, tr_loss, label=\"Train\")\n    plt.plot(va_epochs, va_loss, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR RandomCluster \u2013 Training vs Validation Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"RandomCluster_SPR_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# -------------------------- Figure 2 ------------------------\ntry:\n    if run is None:\n        raise ValueError(\"No run data\")\n\n    met = np.array(run[\"metrics\"][\"val\"])  # cols: epoch, CWA, SWA, HM, OCGA\n    epochs, cwa, swa, hm, ocga = met.T\n\n    plt.figure()\n    plt.plot(epochs, cwa, label=\"CWA\")\n    plt.plot(epochs, swa, label=\"SWA\")\n    plt.plot(epochs, hm, label=\"Harmonic Mean\")\n    plt.plot(epochs, ocga, label=\"OCGA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Score\")\n    plt.title(\"SPR RandomCluster \u2013 Validation Metrics over Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"RandomCluster_SPR_metric_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating metric curves: {e}\")\n    plt.close()\n\n# -------------------------- Figure 3 ------------------------\ntry:\n    if run is None:\n        raise ValueError(\"No run data\")\n\n    preds = np.array(run[\"predictions\"])\n    gts = np.array(run[\"ground_truth\"])\n    classes = np.unique(np.concatenate([gts, preds]))\n    cm = np.zeros((classes.size, classes.size), dtype=int)\n    for t, p in zip(gts, preds):\n        cm[np.where(classes == t)[0][0], np.where(classes == p)[0][0]] += 1\n\n    plt.figure()\n    im = plt.imshow(cm, cmap=\"Blues\")\n    plt.colorbar(im, fraction=0.046, pad=0.04)\n    plt.xticks(range(len(classes)), classes)\n    plt.yticks(range(len(classes)), classes)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Ground Truth\")\n    plt.title(\"SPR RandomCluster \u2013 Test Confusion Matrix\")\n    fname = os.path.join(working_dir, \"RandomCluster_SPR_confusion_matrix.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n",
    "plot_plan": "We first load experiment_data.npy, extract the RandomCluster/SPR sub-dictionary and turn the stored (epoch, value) tuples into numpy arrays.  Figure 1 shows the learning curves: training and validation loss versus epoch.  Figure 2 tracks all four validation metrics (CWA, SWA, HM, OCGA) across epochs, allowing quick inspection of which metric drove early stopping.  Figure 3 visualises the final test-set confusion matrix built directly from the stored prediction and ground-truth arrays, giving a quick sense of per-class performance.  Each plot is wrapped in a try-except block so that one failure does not crash the script, every figure is titled, saved to working_dir with descriptive names, and then closed.  A maximum of three figures keeps us well below the 5-plot limit.  Only data found inside experiment_data.npy are used\u2014no synthetic values are introduced.  The script prints a short confirmation message after each successful save so users know where to look.",
    "plot_analyses": [
      {
        "analysis": "This plot shows the training and validation loss over epochs for the SPR RandomCluster model. The training loss decreases steadily, indicating that the model is learning from the data. However, the validation loss initially decreases but starts to increase slightly after around 10 epochs, suggesting potential overfitting. This implies that the model performs well on the training data but may not generalize as effectively to unseen data. Regularization techniques or early stopping could help mitigate this issue.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_799d1033f5874a45a66ca59eecfac90e_proc_1749408/RandomCluster_SPR_loss_curves.png"
      },
      {
        "analysis": "This plot presents the validation metrics (CWA, SWA, Harmonic Mean, and OCGA) over epochs. Both CWA and SWA stabilize around 0.7, which is close to the state-of-the-art benchmark. The harmonic mean of CWA and SWA also remains consistent, indicating balanced performance across the two metrics. However, OCGA remains at zero throughout, suggesting that this metric might not be relevant or correctly implemented in this context. Further investigation into the OCGA metric's calculation or relevance is necessary.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_799d1033f5874a45a66ca59eecfac90e_proc_1749408/RandomCluster_SPR_metric_curves.png"
      },
      {
        "analysis": "This confusion matrix illustrates the test set predictions of the SPR RandomCluster model. The diagonal dominance indicates that the model correctly predicts the majority of the labels. However, there is noticeable misclassification across some classes, particularly between classes 2 and 3, which may indicate overlapping features or insufficient differentiation in the clustering process. Enhancing the quality of the clustering algorithm or incorporating additional features could improve classification accuracy.",
        "plot_path": "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_799d1033f5874a45a66ca59eecfac90e_proc_1749408/RandomCluster_SPR_confusion_matrix.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_799d1033f5874a45a66ca59eecfac90e_proc_1749408/RandomCluster_SPR_loss_curves.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_799d1033f5874a45a66ca59eecfac90e_proc_1749408/RandomCluster_SPR_metric_curves.png",
      "experiments/2025-08-31_14-12-02_symbol_glyph_clustering_attempt_0/logs/0-run/experiment_results/experiment_799d1033f5874a45a66ca59eecfac90e_proc_1749408/RandomCluster_SPR_confusion_matrix.png"
    ],
    "vlm_feedback_summary": "The results highlight the model's potential for achieving competitive accuracy in SPR tasks, with metrics nearing state-of-the-art levels. However, signs of overfitting and issues with specific metrics (e.g., OCGA) warrant further investigation. Improvements in clustering quality and regularization techniques could enhance performance and generalization.",
    "exp_results_dir": "experiment_results/experiment_799d1033f5874a45a66ca59eecfac90e_proc_1749408",
    "ablation_name": "Random-Cluster-Assignment (No-KMeans Semantic Clustering)",
    "exp_results_npy_files": [
      "experiment_results/experiment_799d1033f5874a45a66ca59eecfac90e_proc_1749408/experiment_data.npy"
    ]
  }
]