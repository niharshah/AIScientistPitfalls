<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 4], [1, 5], [3, 6], [4, 8], [4, 10], [4, 11], [4, 9]], "layout": [[0.2727272727272727, 0.0], [0.45454545454545453, 0.0], [0.6363636363636364, 0.0], [0.8181818181818182, 0.0], [0.2727272727272727, 0.5], [0.45454545454545453, 0.5], [0.8181818181818182, 0.5], [1.0, 0.0], [0.0, 1.0], [0.18181818181818182, 1.0], [0.36363636363636365, 1.0], [0.5454545454545454, 1.0]], "plan": ["We start with a straightforward supervised baseline that encodes each symbolic\ntoken (e.g. \u201cAb\u201d) as a discrete vocabulary item, pads variable\u2013length sequences,\nand learns an embedding + Bi-LSTM classifier.  A small embedding (64 d) feeds a\nbidirectional LSTM (128 h) whose mean-pooled hidden states are passed to a\nlinear layer predicting the rule class.  Training uses cross-entropy on the\nlabelled set, with Adam and early stopping through a fixed epoch budget (5).  At\nevery epoch we evaluate on the dev split, logging loss, Shape-Weighted Accuracy,\nColor-Weighted Accuracy and their Harmonic mean (HWA); these metrics and losses\nare stored in a dict and finally saved to \u201cworking/experiment_data.npy\u201d.  All\ntensors and the model are moved to GPU when available, and DataLoader batches\nare moved inside the loop.  This establishes a clean, reproducible baseline upon\nwhich we can later add the context-aware contrastive pre-training phase.  The\ncode is fully self-contained, loads SPR_BENCH from the local path, and finishes\nin well under 30 minutes.", "We first turn each symbolic token into an index, build a small Bi-GRU encoder\nand pre-train it for a few epochs with a SimCLR-style contrastive objective,\nwhere two randomly masked views of every sequence form the positive pair.\nAfterwards we attach a linear classifier and fine-tune the whole network with\ncross-entropy on the labelled split. At every epoch we evaluate on the dev set,\ncompute Shape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA) and their\nharmonic mean (HWA), print them and store them (together with losses) in the\nexperiment_data dictionary. The script follows all device-handling rules, uses a\npadding-aware DataLoader, saves metrics as numpy arrays in ./working, and should\nfinish in well under 30 minutes while giving a solid, extensible baseline.", "We begin with a minimal supervised baseline: we load the SPR_BENCH data, build a\nsimple whitespace-token vocabulary, and pad sequences to a fixed length.  An\nEmbedding layer followed by a bidirectional GRU encodes each sequence; mean-\npooled hidden states feed a linear classifier.  We train with cross-entropy on\nthe train split, monitor loss and Harmonic-Weighted-Accuracy (HWA) on the dev\nsplit each epoch, and report final metrics on both dev and test.  All tensors\nand the model are moved to GPU when available, and metrics plus losses are\nstored in a dictionary that is saved to ./working/experiment_data.npy.  This\nprovides a clean, reproducible baseline before introducing any contrastive pre-\ntraining or sophisticated augmentations.", "We first load SPR_BENCH with the helper from SPR.py, build a simple token-level\nvocabulary, and encode each sequence as a list of ids (padding within each\nbatch).  A small Bi-GRU encoder (embedding->BiGRU->mean-pool) provides fixed-\nlength sequence embeddings.  We pre-train this encoder for a few epochs with a\nSimCLR-style NT-Xent contrastive loss: each training example is augmented twice\nvia random token deletion and random swaps, producing positive pairs while other\nsamples in the batch act as negatives.  After pre-training we attach a linear\nclassifier, fine-tune the whole model with cross-entropy on the labelled\ntraining split, and evaluate on dev/test.  At every epoch we compute Shape-\nWeighted Accuracy (SWA), Color-Weighted Accuracy (CWA) and their harmonic mean\nHWA; metrics, losses, predictions and ground-truth are stored in a dict, saved\nto ./working/experiment_data.npy, and printed.  The code is single-file, GPU-\naware, saves figures/arrays under ./working, and runs in <30 min with modest\nhyper-parameters.", "The failure arose because the DataLoader worker processes tried to read the CSV\nfiles through a relative path that no longer existed after `fork()`.  Turning\nthe root path into an absolute, verified location before spawning any workers\n(or by simply using `num_workers = 0`) eliminates the \u201cfile not found\u201d error.\nThe revised script below (1) automatically searches for a valid SPR_BENCH\ndirectory, coercing it to an absolute path with `.resolve()`, (2) sets\n`num_workers = 0` to avoid additional fork-related issues, and (3) keeps the\nrest of the pipeline unchanged while following the mandatory GPU, metric-\ntracking, and data-saving requirements.", "The failure came from hard-coding a single location for the SPR_BENCH folder.\nI add a tiny helper (`locate_spr_bench`) that searches several likely places\n(env-var, local folder, parent folder, sample absolute path) and only raises if\nnone of them exists.   All subsequent code uses this discovered path, so the\nscript works no matter where the benchmark is copied.   While touching the\nscript I also moved every tensor/model to the detected `device` as recommended\nand filled the missing training-metric logging.", "The error arose because the script depends on a separate SPR.py file that is not\non Python\u2019s module search path in many execution environments.  By embedding the\nrequired utilities (dataset loader and metric functions) directly in the script\nwe remove that dependency, guaranteeing the module is always found.  The revised\nscript inlines those functions, keeps every tensor/model on the correct device,\nlogs/records all requested metrics each epoch, and finally saves everything in\nthe working directory.  No logic is otherwise altered, so the experiment now\nruns end-to-end without import errors.", "We first load the SPR_BENCH splits with the helper in SPR.py, build a simple\ntokenizer over the symbolic tokens, and encode each sequence to a fixed-length\ninteger tensor.  For pre-training we define a tiny encoder (token embedding +\none Transformer block + mean-pool) and run a SimCLR-style contrastive loss on\ntwo stochastic augmentations of every sequence (token dropout + token swap).\nAfter a few epochs we copy the encoder weights, attach a linear classification\nhead, and fine-tune with cross-entropy on the labelled data.  At every epoch we\nevaluate on the dev split, reporting validation loss, Shape-Weighted Accuracy\n(SWA), Color-Weighted Accuracy (CWA) and their Harmonic Weighted Accuracy (HWA).\nThe same metrics are computed on the test split at the end.  All losses and\nmetrics are stored in the required experiment_data dict and persisted with\nnp.save, and a quick TSNE plot of the learned embeddings is saved to ./working\nfor qualitative inspection.  The entire script runs on GPU when available and\nrespects all device movement rules.  This provides a minimal yet functional\ncontext-aware contrastive baseline that we will refine in later stages.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, time, json, math, random\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- SPR dataset utilities (copied from prompt) ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------- Dataset path ----------\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # adjust if different\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- Vocabulary & Label mappings ----------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr[\"train\"])\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\nprint(f\"Vocab size={len(vocab)}, num_labels={num_labels}\")\n\n\n# ---------- PyTorch Dataset ----------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, vocab, label2id):\n        self.data = hf_dataset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode_seq(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        ids = self.encode_seq(ex[\"sequence\"])\n        label = self.label2id[ex[\"label\"]]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }  # keep raw for metrics\n\n\ndef collate_fn(batch):\n    max_len = max(len(x[\"input_ids\"]) for x in batch)\n    pad_id = 0\n    input_ids = torch.zeros(len(batch), max_len, dtype=torch.long)\n    labels = torch.zeros(len(batch), dtype=torch.long)\n    sequences = []\n    for i, b in enumerate(batch):\n        seq_len = len(b[\"input_ids\"])\n        input_ids[i, :seq_len] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        sequences.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": sequences}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_fn,\n    num_workers=2,\n    pin_memory=True,\n)\ndev_loader = DataLoader(\n    dev_ds,\n    batch_size=256,\n    shuffle=False,\n    collate_fn=collate_fn,\n    num_workers=2,\n    pin_memory=True,\n)\n\n\n# ---------- Model ----------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(\n            emb_dim, hidden_dim, num_layers=1, bidirectional=True, batch_first=True\n        )\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)  # [B,L,E]\n        outputs, _ = self.lstm(emb)  # [B,L,2H]\n        mask = (x != 0).unsqueeze(-1)\n        summed = (outputs * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        mean = summed / lengths  # [B,2H]\n        logits = self.fc(mean)\n        return logits\n\n\nmodel = BiLSTMClassifier(len(vocab), 64, 128, num_labels).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------- experiment data container ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ---------- Training loop ----------\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    # ---- train ----\n    model.train()\n    running_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"])\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = running_loss / len(train_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n\n    # ---- eval ----\n    model.eval()\n    val_loss, all_pred, all_true, all_seq = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            tensor_batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(tensor_batch[\"input_ids\"])\n            loss = criterion(logits, tensor_batch[\"labels\"])\n            val_loss += loss.item() * tensor_batch[\"labels\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            truths = tensor_batch[\"labels\"].cpu().tolist()\n            all_pred.extend(preds)\n            all_true.extend(truths)\n            all_seq.extend(batch[\"sequences\"])\n    val_loss /= len(dev_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n\n    # metrics\n    swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n    cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\n    )\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append({\"loss\": train_loss})\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = all_pred\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_true\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n        f\"SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n    )\n\n# ---------- Save experiment data ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, random, pathlib, math, time, json\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import disable_caching\n\ndisable_caching()\n\n# ------------------------------------------------------------------------------------------------------------------#\n# obligatory working dir + device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------------------------------------------------------------------------------------------------------#\n# ---------------  DATA LOADING UTILS (from given SPR.py)  ---------------------------------------------------------#\nfrom datasets import load_dataset, DatasetDict\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(token[0] for token in sequence.strip().split() if token))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(token[1] for token in sequence.strip().split() if len(token) > 1))\n\n\ndef shape_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_shape_variety(seq) for seq in sequences]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\ndef color_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_color_variety(seq) for seq in sequences]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa + 1e-8)\n\n\n# ------------------------------------------------------------------------------------------------------------------#\n# ----------------------------  DATASET + TOKENISER -----------------------------------------------------------------#\nPAD_TOKEN = \"<PAD>\"\nUNK_TOKEN = \"<UNK>\"\n\n\nclass Vocab:\n    def __init__(self):\n        self.token2idx = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n        self.idx2token = [PAD_TOKEN, UNK_TOKEN]\n\n    def add(self, tok):\n        if tok not in self.token2idx:\n            self.token2idx[tok] = len(self.idx2token)\n            self.idx2token.append(tok)\n\n    def encode(self, seq):\n        return [self.token2idx.get(t, 1) for t in seq]\n\n    def __len__(self):\n        return len(self.idx2token)\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, dset_split, vocab=None, build_vocab=False):\n        self.seqs = dset_split[\"sequence\"]\n        self.labels = [int(x) for x in dset_split[\"label\"]]\n        self.vocab = vocab\n        if build_vocab:\n            for s in self.seqs:\n                for tok in s.strip().split():\n                    self.vocab.add(tok)\n        self.encoded = [self.vocab.encode(s.strip().split()) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.encoded[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"seq_text\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(item[\"input_ids\"]) for item in batch)\n    input_ids = []\n    for item in batch:\n        pad_length = maxlen - len(item[\"input_ids\"])\n        input_ids.append(\n            torch.cat([item[\"input_ids\"], torch.zeros(pad_length, dtype=torch.long)])\n        )\n    input_ids = torch.stack(input_ids)  # (B, L)\n    labels = torch.stack([item[\"label\"] for item in batch])\n    seq_text = [item[\"seq_text\"] for item in batch]\n    return {\"input_ids\": input_ids, \"label\": labels, \"seq_text\": seq_text}\n\n\n# ------------------------------------------------------------------------------------------------------------------#\n# ---------------------------  DATA AUGmentation for contrastive ----------------------------------------------------#\ndef random_mask(tokens, p=0.3):\n    return [\n        t for t in tokens if random.random() > p\n    ] or tokens  # keep at least one token\n\n\ndef make_views(tokens):\n    v1 = random_mask(tokens, p=0.3)\n    v2 = random_mask(tokens, p=0.3)\n    return v1, v2\n\n\n# ------------------------------------------------------------------------------------------------------------------#\n# -----------------------------------  MODEL  -----------------------------------------------------------------------#\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, embed_dim=64, hidden=128):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.gru = nn.GRU(embed_dim, hidden, bidirectional=True, batch_first=True)\n        self.hidden = hidden\n\n    def forward(self, x, lengths=None):\n        emb = self.embedding(x)  # (B,L,E)\n        if lengths is not None:\n            packed = nn.utils.rnn.pack_padded_sequence(\n                emb, lengths, batch_first=True, enforce_sorted=False\n            )\n            out, _ = self.gru(packed)\n            out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n        else:\n            out, _ = self.gru(emb)\n        rep = out.mean(dim=1)  # simple mean pooling (B, 2H)\n        return rep  # (B, 2H)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(encoder.hidden * 2, num_classes)\n\n    def forward(self, input_ids):\n        rep = self.encoder(input_ids)\n        return self.head(rep)\n\n\n# ------------------------------------------------------------------------------------------------------------------#\n# -----------------------------  CONTRASTIVE UTIL -------------------------------------------------------------------#\ndef simclr_loss(rep1, rep2, temperature=0.5):\n    \"\"\"rep1, rep2 : (N,D)\"\"\"\n    rep1 = nn.functional.normalize(rep1, dim=1)\n    rep2 = nn.functional.normalize(rep2, dim=1)\n    N = rep1.size(0)\n    logits = torch.matmul(rep1, rep2.T) / temperature  # (N,N)\n    labels = torch.arange(N, device=rep1.device)\n    loss_a = nn.functional.cross_entropy(logits, labels)\n    loss_b = nn.functional.cross_entropy(logits.T, labels)\n    return (loss_a + loss_b) / 2\n\n\n# ------------------------------------------------------------------------------------------------------------------#\n# --------------------------------  LOAD DATA -----------------------------------------------------------------------#\nDATA_PATH = pathlib.Path(os.environ.get(\"SPR_PATH\", \"./SPR_BENCH\"))\nassert DATA_PATH.exists(), f\"Data path not found: {DATA_PATH}\"\nspr = load_spr_bench(DATA_PATH)\nprint(\"Loaded SPR splits:\", {k: len(v) for k, v in spr.items()})\n\nvocab = Vocab()\ntrain_ds = SPRDataset(spr[\"train\"], vocab=vocab, build_vocab=True)\ndev_ds = SPRDataset(spr[\"dev\"], vocab=vocab)\ntest_ds = SPRDataset(spr[\"test\"], vocab=vocab)\n\nbatch_size_contrast = 256\nbatch_size_sup = 256\n\ntrain_loader_contrast = DataLoader(\n    train_ds, batch_size=batch_size_contrast, shuffle=True, collate_fn=collate_fn\n)\ntrain_loader_sup = DataLoader(\n    train_ds, batch_size=batch_size_sup, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    dev_ds, batch_size=batch_size_sup, shuffle=False, collate_fn=collate_fn\n)\n\nnum_classes = len(set(train_ds.labels))\nprint(\"Vocab size:\", len(vocab), \"Num classes:\", num_classes)\n\n# ------------------------------------------------------------------------------------------------------------------#\n# --------------------------------  PRETRAIN CONTRASTIVE ------------------------------------------------------------#\nencoder = Encoder(len(vocab)).to(device)\ncontrast_opt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n\ncontrast_epochs = 3\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"contrastive\": [], \"supervised\": {\"train\": [], \"val\": []}},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\nfor epoch in range(1, contrast_epochs + 1):\n    encoder.train()\n    epoch_loss = 0.0\n    for batch in train_loader_contrast:\n        seqs = [s.strip().split() for s in batch[\"seq_text\"]]\n        view1_tok = []\n        view2_tok = []\n        for tokens in seqs:\n            v1, v2 = make_views(tokens)\n            view1_tok.append(torch.tensor(vocab.encode(v1), dtype=torch.long))\n            view2_tok.append(torch.tensor(vocab.encode(v2), dtype=torch.long))\n        # pad\n        maxlen = max(max(len(x) for x in view1_tok), max(len(x) for x in view2_tok))\n\n        def pad(list_tok):\n            return torch.stack(\n                [\n                    torch.cat([t, torch.zeros(maxlen - len(t), dtype=torch.long)])\n                    for t in list_tok\n                ]\n            )\n\n        v1_ids = pad(view1_tok).to(device)\n        v2_ids = pad(view2_tok).to(device)\n\n        rep1 = encoder(v1_ids)\n        rep2 = encoder(v2_ids)\n        loss = simclr_loss(rep1, rep2)\n        contrast_opt.zero_grad()\n        loss.backward()\n        contrast_opt.step()\n        epoch_loss += loss.item() * len(seqs)\n    epoch_loss /= len(train_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"contrastive\"].append(epoch_loss)\n    print(f\"[Contrastive] Epoch {epoch}: loss = {epoch_loss:.4f}\")\n\n# ------------------------------------------------------------------------------------------------------------------#\n# -----------------------------  SUPERVISED FINETUNE ----------------------------------------------------------------#\nmodel = Classifier(encoder, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nsup_epochs = 5\nfor epoch in range(1, sup_epochs + 1):\n    # ---- train ----#\n    model.train()\n    train_loss = 0.0\n    for batch in train_loader_sup:\n        inputs = batch[\"input_ids\"].to(device)\n        labels = batch[\"label\"].to(device)\n        logits = model(inputs)\n        loss = criterion(logits, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * inputs.size(0)\n    train_loss /= len(train_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"supervised\"][\"train\"].append(train_loss)\n\n    # ---- validation ----#\n    model.eval()\n    val_loss = 0.0\n    all_pred, all_gt, all_seq = [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            inputs = batch[\"input_ids\"].to(device)\n            labels = batch[\"label\"].to(device)\n            logits = model(inputs)\n            loss = criterion(logits, labels)\n            val_loss += loss.item() * inputs.size(0)\n            preds = logits.argmax(dim=1).cpu().tolist()\n            all_pred.extend(preds)\n            all_gt.extend(labels.cpu().tolist())\n            all_seq.extend(batch[\"seq_text\"])\n    val_loss /= len(dev_ds)\n    swa = shape_weighted_accuracy(all_seq, all_gt, all_pred)\n    cwa = color_weighted_accuracy(all_seq, all_gt, all_pred)\n    hwa = harmonic_weighted_accuracy(swa, cwa)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"supervised\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\n    )\n    print(\n        f\"Epoch {epoch}: validation_loss = {val_loss:.4f} | SWA={swa:.3f} CWA={cwa:.3f} HWA={hwa:.3f}\"\n    )\n\n# store final predictions & ground truth for dev\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = all_pred\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_gt\n\n# ------------------------------------------------------------------------------------------------------------------#\n# -----------------------------  SAVE METRICS -----------------------------------------------------------------------#\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy to\", working_dir)\n", "import os, pathlib, time, math, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy\n\n# ------------------------------------------------------------------\n# working dir & device\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ------------------------------------------------------------------\n# data ----------------------------------------------------------------\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\ndsets = load_spr_bench(DATA_PATH)\n\n# build vocabulary ----------------------------------------------------\nspecial_tokens = [\"<PAD>\", \"<UNK>\"]\nvocab = set()\nfor seq in dsets[\"train\"][\"sequence\"]:\n    vocab.update(seq.strip().split())\nidx2tok = special_tokens + sorted(vocab)\ntok2idx = {tok: i for i, tok in enumerate(idx2tok)}\n\n\ndef encode(seq, max_len):\n    toks = seq.strip().split()\n    ids = [tok2idx.get(t, tok2idx[\"<UNK>\"]) for t in toks][:max_len]\n    if len(ids) < max_len:\n        ids += [tok2idx[\"<PAD>\"]] * (max_len - len(ids))\n    return ids\n\n\nseq_lens = [len(s.split()) for s in dsets[\"train\"][\"sequence\"]]\nMAX_LEN = int(np.percentile(seq_lens, 95))  # cover most sequences\n\n\ndef map_split(split_name):\n    sequences = dsets[split_name][\"sequence\"]\n    labels = dsets[split_name][\"label\"]\n    if isinstance(labels[0], str):\n        uniq = sorted(list(set(labels)))\n        lbl2id = {s: i for i, s in enumerate(uniq)}\n        labels = [lbl2id[l] for l in labels]\n    return [encode(s, MAX_LEN) for s in sequences], labels, sequences\n\n\ntrain_X, train_y, train_raw = map_split(\"train\")\ndev_X, dev_y, dev_raw = map_split(\"dev\")\ntest_X, test_y, test_raw = map_split(\"test\")\nNUM_LABELS = len(set(train_y))\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.long)\n        self.y = torch.tensor(y, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return {\"input_ids\": self.X[idx], \"labels\": self.y[idx]}\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRDataset(train_X, train_y), batch_size=batch_size, shuffle=True\n)\ndev_loader = DataLoader(SPRDataset(dev_X, dev_y), batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(\n    SPRDataset(test_X, test_y), batch_size=batch_size, shuffle=False\n)\n\n\n# ------------------------------------------------------------------\n# model ----------------------------------------------------------------\nclass SequenceClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_labels, pad_idx):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.classifier = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, input_ids):\n        x = self.embedding(input_ids)\n        out, _ = self.gru(x)\n        mask = (input_ids != tok2idx[\"<PAD>\"]).float().unsqueeze(-1)\n        pooled = (out * mask).sum(1) / mask.sum(1).clamp(min=1e-6)  # mean pooling\n        return self.classifier(pooled)\n\n\nmodel = SequenceClassifier(len(idx2tok), 64, 128, NUM_LABELS, tok2idx[\"<PAD>\"]).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n\n\n# ------------------------------------------------------------------\n# training utils -----------------------------------------------------\ndef evaluate(loader, raw_sequences):\n    model.eval()\n    losses, preds, gts = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            losses.append(loss.item())\n            preds.extend(torch.argmax(logits, 1).cpu().tolist())\n            gts.extend(batch[\"labels\"].cpu().tolist())\n    swa = shape_weighted_accuracy(raw_sequences, gts, preds)\n    cwa = color_weighted_accuracy(raw_sequences, gts, preds)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    return np.mean(losses), swa, cwa, hwa, preds, gts\n\n\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# ------------------------------------------------------------------\n# train loop ---------------------------------------------------------\nEPOCHS = 5\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    epoch_losses = []\n    for batch in train_loader:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"])\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        epoch_losses.append(loss.item())\n    train_loss = np.mean(epoch_losses)\n\n    val_loss, swa, cwa, hwa, _, _ = evaluate(dev_loader, dev_raw)\n\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\n    )\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  HWA={hwa:.4f}\"\n    )\n\n# ------------------------------------------------------------------\n# final evaluation ---------------------------------------------------\nval_loss, swa, cwa, hwa, val_preds, val_gts = evaluate(dev_loader, dev_raw)\ntest_loss, swa_t, cwa_t, hwa_t, test_preds, test_gts = evaluate(test_loader, test_raw)\nprint(f\"Final DEV -- loss:{val_loss:.4f}  SWA:{swa:.4f}  CWA:{cwa:.4f}  HWA:{hwa:.4f}\")\nprint(\n    f\"Final TEST -- loss:{test_loss:.4f} SWA:{swa_t:.4f} CWA:{cwa_t:.4f} HWA:{hwa_t:.4f}\"\n)\n\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = {\"dev\": val_preds, \"test\": test_preds}\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = {\"dev\": val_gts, \"test\": test_gts}\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, random, math, time, itertools, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom datasets import DatasetDict\nfrom SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Setup \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": [], \"test\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": {\"val\": [], \"test\": []},\n        \"ground_truth\": {\"val\": [], \"test\": []},\n        \"timestamps\": [],\n    }\n}\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Data loading \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nDATA_PATH = pathlib.Path(os.environ.get(\"SPR_PATH\", \"SPR_BENCH\"))\nspr = load_spr_bench(DATA_PATH)  # DatasetDict with 'train', 'dev', 'test'\n\n\n# build vocabulary over training split\ndef tokens(seq):\n    return seq.strip().split()\n\n\nvocab = {\"<pad>\": 0, \"<unk>\": 1}\nfor s in spr[\"train\"][\"sequence\"]:\n    for tok in tokens(s):\n        if tok not in vocab:\n            vocab[tok] = len(vocab)\npad_id, unk_id = 0, 1\nprint(f\"Vocab size: {len(vocab)}\")\n\n\n# encode function\ndef encode(seq):\n    return [vocab.get(tok, unk_id) for tok in tokens(seq)]\n\n\n# label mapping\nlabels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {lbl: i for i, lbl in enumerate(labels)}\nnum_labels = len(labels)\n\n\n# dataset wrappers\nclass SPRContrastive(torch.utils.data.Dataset):\n    def __init__(self, seqs):\n        self.seqs = [encode(s) for s in seqs]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def augment(self, ids):\n        ids = ids.copy()\n        # random deletion\n        ids = [t for t in ids if random.random() > 0.15 or len(ids) <= 1]\n        # random swap once\n        if len(ids) > 1 and random.random() < 0.5:\n            i, j = random.sample(range(len(ids)), 2)\n            ids[i], ids[j] = ids[j], ids[i]\n        return ids if ids else [ids[0]]  # ensure non-empty\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        return self.augment(seq), self.augment(seq)\n\n\nclass SPRSupervised(torch.utils.data.Dataset):\n    def __init__(self, seqs, labels_):\n        self.data = [(encode(s), label2id[l]) for s, l in zip(seqs, labels_)]\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n\ndef collate_pair(batch):\n    # batch: list of (view1, view2), each list of token ids\n    v1, v2 = zip(*batch)\n\n    def pad(seqs):\n        L = max(len(s) for s in seqs)\n        arr = torch.full((len(seqs), L), pad_id, dtype=torch.long)\n        for i, s in enumerate(seqs):\n            arr[i, : len(s)] = torch.tensor(s)\n        return arr\n\n    return {\"x1\": pad(v1), \"x2\": pad(v2)}\n\n\ndef collate_sup(batch):\n    seqs, labs = zip(*batch)\n    L = max(len(s) for s in seqs)\n    arr = torch.full((len(seqs), L), pad_id, dtype=torch.long)\n    for i, s in enumerate(seqs):\n        arr[i, : len(s)] = torch.tensor(s)\n    return {\"x\": arr, \"y\": torch.tensor(labs)}\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Model \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nclass Encoder(nn.Module):\n    def __init__(self, vocab_sz, emb=64, hid=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_sz, emb, padding_idx=pad_id)\n        self.rnn = nn.GRU(emb, hid, batch_first=True, bidirectional=True)\n\n    def forward(self, x):\n        m = (x != pad_id).unsqueeze(-1)\n        h, _ = self.rnn(self.emb(x))\n        h = h * m  # mask pads\n        rep = h.sum(1) / m.sum(1).clamp_min(1)  # mean pooling\n        return rep  # [B, 2*hid]\n\n\nclass ProjectionHead(nn.Module):\n    def __init__(self, in_dim, proj=128):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, proj), nn.ReLU(inplace=True), nn.Linear(proj, proj)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, in_dim, num_labels):\n        super().__init__()\n        self.fc = nn.Linear(in_dim, num_labels)\n\n    def forward(self, x):\n        return self.fc(x)\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Contrastive pretrain \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nbatch_size = 128\npre_epochs = 3\ntemperature = 0.5\n\nenc = Encoder(len(vocab)).to(device)\nproj = ProjectionHead(256).to(device)\n\noptimizer = torch.optim.Adam(\n    itertools.chain(enc.parameters(), proj.parameters()), lr=1e-3\n)\ntrain_loader = DataLoader(\n    SPRContrastive(spr[\"train\"][\"sequence\"]),\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=collate_pair,\n)\n\n\ndef nt_xent(z1, z2, T=0.5):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2], 0)  # 2N, D\n    sim = torch.mm(z, z.t()) / T  # 2N,2N\n    mask = ~torch.eye(2 * N, dtype=torch.bool, device=z.device)\n    sim = sim.masked_select(mask).view(2 * N, -1)\n    pos = torch.exp((z1 * z2).sum(-1) / T)\n    denom = torch.exp(sim).sum(-1)[:N] + torch.exp(sim).sum(-1)[N:]\n    loss = -torch.log(pos / denom).mean()\n    return loss\n\n\nfor epoch in range(1, pre_epochs + 1):\n    enc.train()\n    proj.train()\n    tloss = 0\n    batches = 0\n    for batch in train_loader:\n        x1, x2 = batch[\"x1\"].to(device), batch[\"x2\"].to(device)\n        z1 = proj(enc(x1))\n        z2 = proj(enc(x2))\n        loss = nt_xent(z1, z2, temperature)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        tloss += loss.item()\n        batches += 1\n    print(f\"[Pretrain] Epoch {epoch}: loss={tloss/batches:.4f}\")\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Supervised fine-tune \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nft_epochs = 5\nclf = Classifier(256, num_labels).to(device)\noptimizer = torch.optim.Adam(\n    itertools.chain(enc.parameters(), clf.parameters()), lr=1e-3\n)\ncriterion = nn.CrossEntropyLoss()\n\ntrain_sup = DataLoader(\n    SPRSupervised(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"]),\n    batch_size=256,\n    shuffle=True,\n    collate_fn=collate_sup,\n)\nval_sup = DataLoader(\n    SPRSupervised(spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"]),\n    batch_size=256,\n    shuffle=False,\n    collate_fn=collate_sup,\n)\ntest_sup = DataLoader(\n    SPRSupervised(spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"]),\n    batch_size=256,\n    shuffle=False,\n    collate_fn=collate_sup,\n)\n\n\ndef evaluate(loader, split):\n    enc.eval()\n    clf.eval()\n    y_true, y_pred, seqs = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            x = batch[\"x\"].to(device)\n            logits = clf(enc(x))\n            pred = logits.argmax(-1).cpu().tolist()\n            y_pred.extend(pred)\n            y_true.extend(batch[\"y\"].tolist())\n            seqs.extend(\n                [\"\"] * len(pred)\n            )  # Placeholder, sequences not needed for metrics relying on seq; we reuse original seqs later\n    return y_true, y_pred\n\n\n# For SWA/CWA we need sequences; create parallel list mapping\ndef sequences_from_loader(loader_data):\n    for b in loader_data:\n        yield from b\n\n\nval_seqs = spr[\"dev\"][\"sequence\"]\ntest_seqs = spr[\"test\"][\"sequence\"]\n\nfor epoch in range(1, ft_epochs + 1):\n    enc.train()\n    clf.train()\n    running = 0\n    batches = 0\n    for batch in train_sup:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        logits = clf(enc(batch[\"x\"]))\n        loss = criterion(logits, batch[\"y\"])\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        running += loss.item()\n        batches += 1\n    train_loss = running / batches\n    # validation\n    y_true, y_pred = [], []\n    enc.eval()\n    clf.eval()\n    with torch.no_grad():\n        for batch in val_sup:\n            x = batch[\"x\"].to(device)\n            logits = clf(enc(x))\n            y_pred.extend(logits.argmax(-1).cpu().tolist())\n            y_true.extend(batch[\"y\"].tolist())\n    swa = shape_weighted_accuracy(val_seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(val_seqs, y_true, y_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"epoch\": epoch, \"loss\": train_loss}\n    )\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"epoch\": epoch, \"SWA\": swa, \"CWA\": cwa, \"HWA\": hwa}\n    )\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(1 - hwa)  # dummy\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f}  SWA={swa:.4f}  CWA={cwa:.4f}  HWA={hwa:.4f}\"\n    )\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Final Test Eval \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ny_true, y_pred = [], []\nwith torch.no_grad():\n    for batch in test_sup:\n        x = batch[\"x\"].to(device)\n        logits = clf(enc(x))\n        y_pred.extend(logits.argmax(-1).cpu().tolist())\n        y_true.extend(batch[\"y\"].tolist())\nswa = shape_weighted_accuracy(test_seqs, y_true, y_pred)\ncwa = color_weighted_accuracy(test_seqs, y_true, y_pred)\nhwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0\nprint(f\"[TEST]  SWA={swa:.4f}  CWA={cwa:.4f}  HWA={hwa:.4f}\")\n\nexperiment_data[\"SPR_BENCH\"][\"metrics\"][\"test\"].append(\n    {\"SWA\": swa, \"CWA\": cwa, \"HWA\": hwa}\n)\nexperiment_data[\"SPR_BENCH\"][\"predictions\"][\n    \"val\"\n] = y_pred  # reuse variable for brevity\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"][\"val\"] = y_true\nexperiment_data[\"SPR_BENCH\"][\"timestamps\"].append(time.time())\n\n# save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, random, time, json, math\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ---------- mandatory working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- experiment container ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n\n# ---------- locate SPR_BENCH ----------\ndef find_spr_bench_path() -> pathlib.Path:\n    \"\"\"Return absolute Path to SPR_BENCH containing the expected csv files.\"\"\"\n    candidates = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),  # user-specified\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",  # fallback (from error log)\n    ]\n    for c in candidates:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p}\")\n            return p\n    raise FileNotFoundError(\n        \"SPR_BENCH directory with train.csv/dev.csv/test.csv not found. \"\n        \"Set env var SPR_BENCH_PATH or place directory next to this script.\"\n    )\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ---------- dataset utilities ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",  # read full csv\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    dset = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        dset[split] = _load(f\"{split}.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------- load dataset ----------\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- build vocab / labels ----------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\npad_id = vocab[\"<pad>\"]\nprint(f\"Vocab size = {len(vocab)}, num_labels = {num_labels}\")\n\n\n# ---------- Torch dataset ----------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, vocab, label2id):\n        self.data = hf_dataset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode_seq(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        ids = self.encode_seq(ex[\"sequence\"])\n        label = self.label2id[ex[\"label\"]]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    sequences = []\n    for i, b in enumerate(batch):\n        seq_len = len(b[\"input_ids\"])\n        input_ids[i, :seq_len] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        sequences.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": sequences}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\ntrain_loader = DataLoader(\n    train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n)  # <= BUGFIX\ndev_loader = DataLoader(\n    dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n)\n\n\n# ---------- model ----------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)  # [B, L, E]\n        outputs, _ = self.lstm(emb)  # [B, L, 2H]\n        mask = (x != pad_id).unsqueeze(-1)  # [B, L, 1]\n        summed = (outputs * mask).sum(1)  # [B, 2H]\n        lengths = mask.sum(1).clamp(min=1)  # [B,1]\n        mean = summed / lengths\n        return self.fc(mean)  # [B, C]\n\n\nmodel = BiLSTMClassifier(len(vocab), 64, 128, num_labels, pad_idx=pad_id).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------- training ----------\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    # ---- train ----\n    model.train()\n    running_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"])\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = running_loss / len(train_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"epoch\": epoch, \"loss\": train_loss}\n    )\n\n    # ---- eval ----\n    model.eval()\n    val_loss, all_pred, all_true, all_seq = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            tensor_batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(tensor_batch[\"input_ids\"])\n            loss = criterion(logits, tensor_batch[\"labels\"])\n            val_loss += loss.item() * tensor_batch[\"labels\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            truths = tensor_batch[\"labels\"].cpu().tolist()\n            all_pred.extend(preds)\n            all_true.extend(truths)\n            all_seq.extend(batch[\"sequences\"])\n    val_loss /= len(dev_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n\n    swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n    cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n    )\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = all_pred\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_true\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} \"\n        f\"| SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n    )\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#  Context-aware contrastive baseline for SPR \u2011- robust to missing data path\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nimport os, random, pathlib, time, json\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict, disable_caching\n\n# -----------------------------------------------------------------------------\n#  House-keeping\n# -----------------------------------------------------------------------------\ndisable_caching()\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -----------------------------------------------------------------------------\n#  Locate SPR_BENCH dataset folder\n# -----------------------------------------------------------------------------\ndef locate_spr_bench() -> pathlib.Path:\n    \"\"\"Return a valid pathlib.Path to SPR_BENCH or raise FileNotFoundError.\"\"\"\n    candidates = [\n        os.environ.get(\"SPR_PATH\", None),  # user-supplied env var\n        \"./SPR_BENCH\",  # current dir\n        \"../SPR_BENCH\",  # parent dir\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",  # example absolute path\n    ]\n    for c in candidates:\n        if c and os.path.exists(c):\n            print(f\"Found SPR_BENCH at: {c}\")\n            return pathlib.Path(c)\n    raise FileNotFoundError(\n        \"SPR_BENCH dataset not found. Set SPR_PATH env-var or place the folder \"\n        \"next to this script.\"\n    )\n\n\n# -----------------------------------------------------------------------------\n#  Data-loading helpers (taken from given SPR.py)\n# -----------------------------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"),\n        dev=_load(\"dev.csv\"),\n        test=_load(\"test.csv\"),\n    )\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len({tok[0] for tok in sequence.strip().split() if tok})\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len({tok[1] for tok in sequence.strip().split() if len(tok) > 1})\n\n\ndef shape_weighted_accuracy(seq, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seq]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1e-9)\n\n\ndef color_weighted_accuracy(seq, y_true, y_pred):\n    w = [count_color_variety(s) for s in seq]\n    correct = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1e-9)\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa + 1e-9)\n\n\n# -----------------------------------------------------------------------------\n#  Simple tokenizer / vocab\n# -----------------------------------------------------------------------------\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\nclass Vocab:\n    def __init__(self):\n        self.tok2idx = {PAD: 0, UNK: 1}\n        self.idx2tok = [PAD, UNK]\n\n    def add(self, tok):\n        if tok not in self.tok2idx:\n            self.tok2idx[tok] = len(self.idx2tok)\n            self.idx2tok.append(tok)\n\n    def encode(self, toks):  # list[str] -> list[int]\n        return [self.tok2idx.get(t, 1) for t in toks]\n\n    def __len__(self):\n        return len(self.idx2tok)\n\n\nclass SPRDataset(Dataset):\n    def __init__(self, hf_split, vocab: Vocab, build_vocab=False):\n        self.text = hf_split[\"sequence\"]\n        self.labels = [int(x) for x in hf_split[\"label\"]]\n        self.vocab = vocab\n        if build_vocab:\n            for s in self.text:\n                for tok in s.strip().split():\n                    self.vocab.add(tok)\n        self.encoded = [self.vocab.encode(s.strip().split()) for s in self.text]\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.encoded[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"seq\": self.text[idx],\n        }\n\n\ndef collate(batch):\n    maxlen = max(len(x[\"input_ids\"]) for x in batch)\n    ids = [\n        torch.cat(\n            [\n                b[\"input_ids\"],\n                torch.zeros(maxlen - len(b[\"input_ids\"]), dtype=torch.long),\n            ]\n        )\n        for b in batch\n    ]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    seqs = [b[\"seq\"] for b in batch]\n    return {\"input_ids\": torch.stack(ids), \"label\": labels, \"seq\": seqs}\n\n\n# -----------------------------------------------------------------------------\n#  Data augmentations for contrastive learning\n# -----------------------------------------------------------------------------\ndef random_mask(tokens, p=0.3):\n    return [t for t in tokens if random.random() > p] or tokens\n\n\ndef make_views(tokens):\n    return random_mask(tokens), random_mask(tokens)\n\n\n# -----------------------------------------------------------------------------\n#  Model (biGRU encoder + linear head)\n# -----------------------------------------------------------------------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, emb=64, h=128):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, emb, padding_idx=0)\n        self.gru = nn.GRU(emb, h, bidirectional=True, batch_first=True)\n        self.h = h\n\n    def forward(self, ids):\n        emb = self.embedding(ids)\n        out, _ = self.gru(emb)\n        return out.mean(1)  # (B, 2h)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, enc, num_cls):\n        super().__init__()\n        self.encoder = enc\n        self.head = nn.Linear(enc.h * 2, num_cls)\n\n    def forward(self, ids):\n        rep = self.encoder(ids)\n        return self.head(rep)\n\n\n# -----------------------------------------------------------------------------\n#  Contrastive loss (SimCLR)\n# -----------------------------------------------------------------------------\ndef simclr_loss(r1, r2, temp=0.5):\n    r1, r2 = nn.functional.normalize(r1, dim=1), nn.functional.normalize(r2, dim=1)\n    logits = (r1 @ r2.T) / temp\n    labels = torch.arange(r1.size(0), device=r1.device)\n    return (\n        nn.functional.cross_entropy(logits, labels)\n        + nn.functional.cross_entropy(logits.T, labels)\n    ) / 2\n\n\n# -----------------------------------------------------------------------------\n#  Load data\n# -----------------------------------------------------------------------------\nDATA_PATH = locate_spr_bench()\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\nvocab = Vocab()\ntrain_ds = SPRDataset(spr[\"train\"], vocab, build_vocab=True)\ndev_ds = SPRDataset(spr[\"dev\"], vocab)\ntest_ds = SPRDataset(spr[\"test\"], vocab)\n\ntrain_loader_contrast = DataLoader(\n    train_ds, batch_size=256, shuffle=True, collate_fn=collate\n)\ntrain_loader_sup = DataLoader(\n    train_ds, batch_size=256, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(dev_ds, batch_size=256, shuffle=False, collate_fn=collate)\n\nnum_classes = len(set(train_ds.labels))\nprint(\"Vocab:\", len(vocab), \"| Classes:\", num_classes)\n\n# -----------------------------------------------------------------------------\n#  Experiment bookkeeping\n# -----------------------------------------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"contrastive\": [], \"supervised\": {\"train\": [], \"val\": []}},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# -----------------------------------------------------------------------------\n#  Contrastive pre-training\n# -----------------------------------------------------------------------------\nencoder = Encoder(len(vocab)).to(device)\noptim_c = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n\nfor epoch in range(1, 4):\n    encoder.train()\n    epoch_loss = 0\n    for batch in train_loader_contrast:\n        # build two augmented views\n        seqs = [s.split() for s in batch[\"seq\"]]\n        v1, v2 = [], []\n        for toks in seqs:\n            a, b = make_views(toks)\n            v1.append(torch.tensor(vocab.encode(a), dtype=torch.long))\n            v2.append(torch.tensor(vocab.encode(b), dtype=torch.long))\n        maxlen = max(max(len(t) for t in v1), max(len(t) for t in v2))\n        pad = lambda L: torch.stack(\n            [torch.cat([t, torch.zeros(maxlen - len(t), dtype=torch.long)]) for t in L]\n        )\n        ids1, ids2 = pad(v1).to(device), pad(v2).to(device)\n        r1, r2 = encoder(ids1), encoder(ids2)\n        loss = simclr_loss(r1, r2)\n        optim_c.zero_grad()\n        loss.backward()\n        optim_c.step()\n        epoch_loss += loss.item() * ids1.size(0)\n    epoch_loss /= len(train_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"contrastive\"].append(epoch_loss)\n    print(f\"[Contrast] epoch {epoch} loss {epoch_loss:.4f}\")\n\n# -----------------------------------------------------------------------------\n#  Supervised fine-tuning\n# -----------------------------------------------------------------------------\nmodel = Classifier(encoder, num_classes).to(device)\noptim_s = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\nfor epoch in range(1, 6):\n    # ---- train ----\n    model.train()\n    running_loss, preds, gts, seqs = 0, [], [], []\n    for batch in train_loader_sup:\n        batch_t = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        logits = model(batch_t[\"input_ids\"])\n        loss = criterion(logits, batch_t[\"label\"])\n        optim_s.zero_grad()\n        loss.backward()\n        optim_s.step()\n        running_loss += loss.item() * batch_t[\"input_ids\"].size(0)\n        preds.extend(logits.argmax(1).cpu().tolist())\n        gts.extend(batch_t[\"label\"].cpu().tolist())\n        seqs.extend(batch[\"seq\"])\n    running_loss /= len(train_ds)\n    swa = shape_weighted_accuracy(seqs, gts, preds)\n    cwa = color_weighted_accuracy(seqs, gts, preds)\n    hwa = harmonic_weighted_accuracy(swa, cwa)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"supervised\"][\"train\"].append(running_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\n    )\n\n    # ---- validation ----\n    model.eval()\n    val_loss, vp, vg, vs = 0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch_t = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch_t[\"input_ids\"])\n            loss = criterion(logits, batch_t[\"label\"])\n            val_loss += loss.item() * batch_t[\"input_ids\"].size(0)\n            vp.extend(logits.argmax(1).cpu().tolist())\n            vg.extend(batch_t[\"label\"].cpu().tolist())\n            vs.extend(batch[\"seq\"])\n    val_loss /= len(dev_ds)\n    swa = shape_weighted_accuracy(vs, vg, vp)\n    cwa = color_weighted_accuracy(vs, vg, vp)\n    hwa = harmonic_weighted_accuracy(swa, cwa)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"supervised\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\n    )\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = vp\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = vg\n    print(\n        f\"Epoch {epoch}: val_loss={val_loss:.4f} SWA={swa:.3f} CWA={cwa:.3f} HWA={hwa:.3f}\"\n    )\n\n# -----------------------------------------------------------------------------\n#  Save experiment data\n# -----------------------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy to\", working_dir)\n", "import os, pathlib, random, itertools, time, math, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 House-keeping \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 In-lined SPR utils \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfrom datasets import load_dataset, DatasetDict  # lightweight HF loader\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split if split != \"dev\" else \"dev\"] = _load(f\"{split}.csv\")\n    return d\n\n\n# counting helpers\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / max(sum(w), 1)\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Experiment store \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": [], \"test\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": {\"val\": [], \"test\": []},\n        \"ground_truth\": {\"val\": [], \"test\": []},\n        \"timestamps\": [],\n    }\n}\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Data Loading \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nDATA_PATH = pathlib.Path(os.environ.get(\"SPR_PATH\", \"SPR_BENCH\"))\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\ndef tok_split(seq):\n    return seq.strip().split()\n\n\nvocab = {\"<pad>\": 0, \"<unk>\": 1}\nfor s in spr[\"train\"][\"sequence\"]:\n    for t in tok_split(s):\n        if t not in vocab:\n            vocab[t] = len(vocab)\npad_id, unk_id = 0, 1\nprint(f\"Vocab size = {len(vocab)}\")\n\n\ndef encode(seq):\n    return [vocab.get(t, unk_id) for t in tok_split(seq)]\n\n\nlabels = sorted(set(spr[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(labels)}\nnum_labels = len(labels)\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Dataset wrappers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nclass SPRContrastive(torch.utils.data.Dataset):\n    def __init__(self, sequences):\n        self.seqs = [encode(s) for s in sequences]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def _augment(self, ids):\n        ids = ids.copy()\n        ids = [t for t in ids if random.random() > 0.15 or len(ids) <= 1]\n        if len(ids) > 1 and random.random() < 0.5:\n            i, j = random.sample(range(len(ids)), 2)\n            ids[i], ids[j] = ids[j], ids[i]\n        return ids if ids else [ids[0]]\n\n    def __getitem__(self, idx):\n        base = self.seqs[idx]\n        return self._augment(base), self._augment(base)\n\n\nclass SPRSupervised(torch.utils.data.Dataset):\n    def __init__(self, seqs, labs):\n        self.data = [(encode(s), label2id[l]) for s, l in zip(seqs, labs)]\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n\ndef pad_batch(seqs):\n    L = max(len(s) for s in seqs)\n    out = torch.full((len(seqs), L), pad_id, dtype=torch.long)\n    for i, s in enumerate(seqs):\n        out[i, : len(s)] = torch.tensor(s)\n    return out\n\n\ndef collate_pair(batch):\n    v1, v2 = zip(*batch)\n    return {\"x1\": pad_batch(v1), \"x2\": pad_batch(v2)}\n\n\ndef collate_sup(batch):\n    seqs, labs = zip(*batch)\n    return {\"x\": pad_batch(seqs), \"y\": torch.tensor(labs)}\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Models \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nclass Encoder(nn.Module):\n    def __init__(self, vocab_sz, emb=64, hid=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_sz, emb, padding_idx=pad_id)\n        self.rnn = nn.GRU(emb, hid, batch_first=True, bidirectional=True)\n\n    def forward(self, x):\n        mask = (x != pad_id).unsqueeze(-1)\n        h, _ = self.rnn(self.emb(x))\n        h = h * mask\n        return h.sum(1) / mask.sum(1).clamp_min(1)\n\n\nclass ProjectionHead(nn.Module):\n    def __init__(self, in_dim, proj=128):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, proj), nn.ReLU(inplace=True), nn.Linear(proj, proj)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, in_dim, num_lab):\n        super().__init__()\n        self.fc = nn.Linear(in_dim, num_lab)\n\n    def forward(self, x):\n        return self.fc(x)\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Contrastive Pre-training \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nbatch_size = 128\npre_epochs = 3\ntemperature = 0.5\n\nenc = Encoder(len(vocab)).to(device)\nproj = ProjectionHead(256).to(device)\n\ncontrast_loader = DataLoader(\n    SPRContrastive(spr[\"train\"][\"sequence\"]),\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=collate_pair,\n)\n\nopt_pre = torch.optim.Adam(\n    itertools.chain(enc.parameters(), proj.parameters()), lr=1e-3\n)\n\n\ndef nt_xent(z1, z2, T):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    sim = torch.mm(z, z.t()) / T\n    mask = torch.eye(2 * N, device=sim.device).bool()\n    sim = sim.masked_fill(mask, -9e15)\n    pos = torch.exp((z1 * z2).sum(-1) / T)\n    denom = torch.exp(sim).sum(-1)\n    loss = -torch.log(pos / (denom[:N] + denom[N:])).mean()\n    return loss\n\n\nfor ep in range(1, pre_epochs + 1):\n    enc.train()\n    proj.train()\n    run_loss = 0\n    batches = 0\n    for b in contrast_loader:\n        b = {k: v.to(device) for k, v in b.items()}\n        z1 = proj(enc(b[\"x1\"]))\n        z2 = proj(enc(b[\"x2\"]))\n        loss = nt_xent(z1, z2, temperature)\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        run_loss += loss.item()\n        batches += 1\n    print(f\"[Pretrain] epoch {ep}: contrastive_loss={run_loss/batches:.4f}\")\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Supervised Fine-tuning \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nclf = Classifier(256, num_labels).to(device)\nopt_ft = torch.optim.Adam(itertools.chain(enc.parameters(), clf.parameters()), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\ntrain_sup = DataLoader(\n    SPRSupervised(spr[\"train\"][\"sequence\"], spr[\"train\"][\"label\"]),\n    batch_size=256,\n    shuffle=True,\n    collate_fn=collate_sup,\n)\nval_sup = DataLoader(\n    SPRSupervised(spr[\"dev\"][\"sequence\"], spr[\"dev\"][\"label\"]),\n    batch_size=256,\n    shuffle=False,\n    collate_fn=collate_sup,\n)\ntest_sup = DataLoader(\n    SPRSupervised(spr[\"test\"][\"sequence\"], spr[\"test\"][\"label\"]),\n    batch_size=256,\n    shuffle=False,\n    collate_fn=collate_sup,\n)\n\nft_epochs = 5\nval_seqs = spr[\"dev\"][\"sequence\"]\ntest_seqs = spr[\"test\"][\"sequence\"]\n\nfor ep in range(1, ft_epochs + 1):\n    # ---------- train ----------\n    enc.train()\n    clf.train()\n    tr_loss, batches = 0, 0\n    for batch in train_sup:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        logits = clf(enc(batch[\"x\"]))\n        loss = criterion(logits, batch[\"y\"])\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        tr_loss += loss.item()\n        batches += 1\n    tr_loss /= batches\n    # ---------- validate ----------\n    enc.eval()\n    clf.eval()\n    val_loss, y_true, y_pred = 0, [], []\n    with torch.no_grad():\n        for batch in val_sup:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = clf(enc(batch[\"x\"]))\n            loss = criterion(logits, batch[\"y\"])\n            val_loss += loss.item()\n            y_pred.extend(logits.argmax(-1).cpu().tolist())\n            y_true.extend(batch[\"y\"].cpu().tolist())\n    val_loss /= len(val_sup)\n    swa = shape_weighted_accuracy(val_seqs, y_true, y_pred)\n    cwa = color_weighted_accuracy(val_seqs, y_true, y_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0\n    # ---------- logging ----------\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"epoch\": ep, \"loss\": tr_loss}\n    )\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"epoch\": ep, \"SWA\": swa, \"CWA\": cwa, \"HWA\": hwa}\n    )\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    print(\n        f\"Epoch {ep}: train_loss={tr_loss:.4f}  val_loss={val_loss:.4f}  SWA={swa:.4f}  CWA={cwa:.4f}  HWA={hwa:.4f}\"\n    )\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Final Test Eval \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nenc.eval()\nclf.eval()\ny_true, y_pred = [], []\nwith torch.no_grad():\n    for batch in test_sup:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        logits = clf(enc(batch[\"x\"]))\n        y_pred.extend(logits.argmax(-1).cpu().tolist())\n        y_true.extend(batch[\"y\"].cpu().tolist())\nswa = shape_weighted_accuracy(test_seqs, y_true, y_pred)\ncwa = color_weighted_accuracy(test_seqs, y_true, y_pred)\nhwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0\nprint(f\"[TEST]  SWA={swa:.4f}  CWA={cwa:.4f}  HWA={hwa:.4f}\")\n\nexperiment_data[\"SPR_BENCH\"][\"metrics\"][\"test\"].append(\n    {\"SWA\": swa, \"CWA\": cwa, \"HWA\": hwa}\n)\nexperiment_data[\"SPR_BENCH\"][\"predictions\"][\"test\"] = y_pred\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"][\"test\"] = y_true\nexperiment_data[\"SPR_BENCH\"][\"timestamps\"].append(time.time())\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Save experiment data \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os, pathlib, random, math, time\nfrom typing import List, Dict\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# -------------------------------------------------\n# working dir & device setup\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n# -------------------------------------------------\n# load dataset helper\nfrom SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy\n\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # change if necessary\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n# -------------------------------------------------\n# tokenisation utilities\nPAD = \"<pad>\"\nUNK = \"<unk>\"\n\n\ndef build_vocab(ds):\n    vocab = {PAD: 0, UNK: 1}\n    for split in [\"train\", \"dev\", \"test\"]:\n        for seq in ds[split][\"sequence\"]:\n            for tok in seq.strip().split():\n                if tok not in vocab:\n                    vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr)\nvsize = len(vocab)\nprint(\"Vocab size:\", vsize)\n\n\ndef encode(seq: str, max_len: int, vocab: Dict[str, int]) -> List[int]:\n    toks = seq.strip().split()\n    ids = [vocab.get(t, 1) for t in toks][:max_len]\n    ids += [0] * (max_len - len(ids))\n    return ids\n\n\nMAX_LEN = max(len(s.split()) for s in spr[\"train\"][\"sequence\"])\nMAX_LEN = min(MAX_LEN, 40)  # cap for speed\n\n\n# -------------------------------------------------\n# data augmentations\ndef augment(tokens: List[int]) -> List[int]:\n    t = tokens.copy()\n    t = [tok for tok in t if tok != 0]  # drop pads\n    # token dropout\n    t = [tok for tok in t if random.random() > 0.1]\n    # token swap\n    for _ in range(max(1, int(0.1 * len(t)))):\n        if len(t) > 1:\n            i, j = random.sample(range(len(t)), 2)\n            t[i], t[j] = t[j], t[i]\n    if not t:\n        t = [tokens[0]]  # avoid empty\n    t = t[:MAX_LEN]\n    t += [0] * (MAX_LEN - len(t))\n    return t\n\n\n# -------------------------------------------------\n# datasets\nclass ContrastiveSPR(Dataset):\n    def __init__(self, sequences):\n        self.sequences = sequences\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, idx):\n        seq = self.sequences[idx]\n        ids = encode(seq, MAX_LEN, vocab)\n        view1 = augment(ids)\n        view2 = augment(ids)\n        return torch.LongTensor(view1), torch.LongTensor(view2)\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(self, sequences, labels):\n        self.seqs = sequences\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        ids = encode(self.seqs[idx], MAX_LEN, vocab)\n        return torch.LongTensor(ids), torch.LongTensor([self.labels[idx]])\n\n\n# label mapping\nlabels = sorted(list(set(spr[\"train\"][\"label\"])))\nlab2id = {l: i for i, l in enumerate(labels)}\n\n\ndef encode_labels(lst):\n    return [lab2id[x] for x in lst]\n\n\n# -------------------------------------------------\n# model\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        self.pos = nn.Parameter(torch.randn(MAX_LEN, d_model))\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward=256, dropout=0.1, batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=1)\n\n    def forward(self, x):\n        x = self.emb(x) + self.pos[: x.size(1)]\n        h = self.transformer(x)\n        h = h.masked_fill((x.abs().sum(-1, keepdim=True) == 0), 0)\n        return h.mean(1)  # mean pool\n\n\nclass SupModel(nn.Module):\n    def __init__(self, enc, num_classes):\n        super().__init__()\n        self.encoder = enc\n        self.head = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        z = self.encoder(x)\n        return self.head(z)\n\n\n# -------------------------------------------------\n# contrastive loss\ndef nt_xent(z1, z2, tau=0.1):\n    z1 = F.normalize(z1, dim=1)\n    z2 = F.normalize(z2, dim=1)\n    B = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    sim = torch.mm(z, z.t()) / tau\n    labels = torch.arange(B, device=z1.device)\n    labels = torch.cat([labels, labels], 0)\n    mask = torch.eye(2 * B, device=z1.device).bool()\n    sim = sim.masked_fill(mask, -9e15)\n    loss = F.cross_entropy(sim, labels)\n    return loss\n\n\n# -------------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# -------------------------------------------------\n# pretraining\nBATCH = 256\ncontrast_ds = ContrastiveSPR(spr[\"train\"][\"sequence\"])\ncontrast_loader = DataLoader(\n    contrast_ds, batch_size=BATCH, shuffle=True, drop_last=True\n)\nencoder = Encoder(vsize).to(device)\nopt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n\nEPOCHS_PT = 3\nprint(\"=== Contrastive pre-training ===\")\nfor epoch in range(1, EPOCHS_PT + 1):\n    encoder.train()\n    tot_loss = 0\n    for v1, v2 in contrast_loader:\n        v1, v2 = v1.to(device), v2.to(device)\n        z1 = encoder(v1)\n        z2 = encoder(v2)\n        loss = nt_xent(z1, z2)\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        tot_loss += loss.item()\n    print(f\"Pretrain Epoch {epoch}: loss={tot_loss/len(contrast_loader):.4f}\")\n\n# -------------------------------------------------\n# fine-tuning\ntrain_ds = SupervisedSPR(spr[\"train\"][\"sequence\"], encode_labels(spr[\"train\"][\"label\"]))\ndev_ds = SupervisedSPR(spr[\"dev\"][\"sequence\"], encode_labels(spr[\"dev\"][\"label\"]))\ntest_ds = SupervisedSPR(spr[\"test\"][\"sequence\"], encode_labels(spr[\"test\"][\"label\"]))\n\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\nval_loader = DataLoader(dev_ds, batch_size=256)\ntest_loader = DataLoader(test_ds, batch_size=256)\n\nmodel = SupModel(encoder, len(labels)).to(device)\nclf_opt = torch.optim.Adam(model.parameters(), lr=2e-3)\nce = nn.CrossEntropyLoss()\n\nEPOCHS_FT = 5\nprint(\"=== Supervised fine-tuning ===\")\nfor epoch in range(1, EPOCHS_FT + 1):\n    # train\n    model.train()\n    tr_loss = 0\n    for x, y in train_loader:\n        x, y = x.to(device), y.squeeze(1).to(device)\n        logits = model(x)\n        loss = ce(logits, y)\n        clf_opt.zero_grad()\n        loss.backward()\n        clf_opt.step()\n        tr_loss += loss.item()\n    tr_loss /= len(train_loader)\n    # val\n    model.eval()\n    val_loss = 0\n    all_preds = []\n    all_gt = []\n    all_seq = []\n    with torch.no_grad():\n        for x, y in val_loader:\n            x, y = x.to(device), y.squeeze(1).to(device)\n            logits = model(x)\n            loss = ce(logits, y)\n            val_loss += loss.item()\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_gt.extend(y.cpu().tolist())\n            all_seq.extend(\n                [\n                    seq\n                    for seq in spr[\"dev\"][\"sequence\"][\n                        len(all_seq) : len(all_seq) + len(preds)\n                    ]\n                ]\n            )\n    val_loss /= len(val_loader)\n    # metrics\n    swa = shape_weighted_accuracy(all_seq, all_gt, all_preds)\n    cwa = color_weighted_accuracy(all_seq, all_gt, all_preds)\n    hwa = 2 * swa * cwa / (swa + cwa + 1e-8)\n    # log\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(tr_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\n    )\n    print(\n        f\"Epoch {epoch}: validation_loss = {val_loss:.4f} | SWA={swa:.3f} CWA={cwa:.3f} HWA={hwa:.3f}\"\n    )\n\n# -------------------------------------------------\n# final test evaluation\nmodel.eval()\nall_preds = []\nall_gt = []\nall_seq = []\nwith torch.no_grad():\n    for x, y in test_loader:\n        x, y = x.to(device), y.squeeze(1).to(device)\n        logits = model(x)\n        preds = logits.argmax(1).cpu().tolist()\n        all_preds.extend(preds)\n        all_gt.extend(y.cpu().tolist())\n        start = len(all_seq)\n        all_seq.extend(\n            [seq for seq in spr[\"test\"][\"sequence\"][start : start + len(preds)]]\n        )\nswa = shape_weighted_accuracy(all_seq, all_gt, all_preds)\ncwa = color_weighted_accuracy(all_seq, all_gt, all_preds)\nhwa = 2 * swa * cwa / (swa + cwa + 1e-8)\nprint(f\"Test: SWA={swa:.3f} CWA={cwa:.3f} HWA={hwa:.3f}\")\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = all_preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_gt\nexperiment_data[\"SPR_BENCH\"][\"metrics\"][\"test\"] = {\"swa\": swa, \"cwa\": cwa, \"hwa\": hwa}\n\n# -------------------------------------------------\n# save metrics\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, json, math\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ---------- mandatory working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- experiment container ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n\n# ---------- locate SPR_BENCH ----------\ndef find_spr_bench_path() -> pathlib.Path:\n    \"\"\"Return absolute Path to SPR_BENCH containing the expected csv files.\"\"\"\n    candidates = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),  # user-specified\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",  # fallback (from error log)\n    ]\n    for c in candidates:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p}\")\n            return p\n    raise FileNotFoundError(\n        \"SPR_BENCH directory with train.csv/dev.csv/test.csv not found. \"\n        \"Set env var SPR_BENCH_PATH or place directory next to this script.\"\n    )\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ---------- dataset utilities ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",  # read full csv\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    dset = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        dset[split] = _load(f\"{split}.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------- load dataset ----------\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- build vocab / labels ----------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\npad_id = vocab[\"<pad>\"]\nprint(f\"Vocab size = {len(vocab)}, num_labels = {num_labels}\")\n\n\n# ---------- Torch dataset ----------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, vocab, label2id):\n        self.data = hf_dataset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode_seq(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        ids = self.encode_seq(ex[\"sequence\"])\n        label = self.label2id[ex[\"label\"]]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    sequences = []\n    for i, b in enumerate(batch):\n        seq_len = len(b[\"input_ids\"])\n        input_ids[i, :seq_len] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        sequences.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": sequences}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\ntrain_loader = DataLoader(\n    train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n)  # <= BUGFIX\ndev_loader = DataLoader(\n    dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n)\n\n\n# ---------- model ----------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)  # [B, L, E]\n        outputs, _ = self.lstm(emb)  # [B, L, 2H]\n        mask = (x != pad_id).unsqueeze(-1)  # [B, L, 1]\n        summed = (outputs * mask).sum(1)  # [B, 2H]\n        lengths = mask.sum(1).clamp(min=1)  # [B,1]\n        mean = summed / lengths\n        return self.fc(mean)  # [B, C]\n\n\nmodel = BiLSTMClassifier(len(vocab), 64, 128, num_labels, pad_idx=pad_id).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------- training ----------\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    # ---- train ----\n    model.train()\n    running_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"])\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = running_loss / len(train_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"epoch\": epoch, \"loss\": train_loss}\n    )\n\n    # ---- eval ----\n    model.eval()\n    val_loss, all_pred, all_true, all_seq = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            tensor_batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(tensor_batch[\"input_ids\"])\n            loss = criterion(logits, tensor_batch[\"labels\"])\n            val_loss += loss.item() * tensor_batch[\"labels\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            truths = tensor_batch[\"labels\"].cpu().tolist()\n            all_pred.extend(preds)\n            all_true.extend(truths)\n            all_seq.extend(batch[\"sequences\"])\n    val_loss /= len(dev_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n\n    swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n    cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n    )\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = all_pred\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_true\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} \"\n        f\"| SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n    )\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, json, math\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ---------- mandatory working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- experiment container ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n\n# ---------- locate SPR_BENCH ----------\ndef find_spr_bench_path() -> pathlib.Path:\n    \"\"\"Return absolute Path to SPR_BENCH containing the expected csv files.\"\"\"\n    candidates = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),  # user-specified\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",  # fallback (from error log)\n    ]\n    for c in candidates:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p}\")\n            return p\n    raise FileNotFoundError(\n        \"SPR_BENCH directory with train.csv/dev.csv/test.csv not found. \"\n        \"Set env var SPR_BENCH_PATH or place directory next to this script.\"\n    )\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ---------- dataset utilities ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",  # read full csv\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    dset = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        dset[split] = _load(f\"{split}.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------- load dataset ----------\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- build vocab / labels ----------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\npad_id = vocab[\"<pad>\"]\nprint(f\"Vocab size = {len(vocab)}, num_labels = {num_labels}\")\n\n\n# ---------- Torch dataset ----------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, vocab, label2id):\n        self.data = hf_dataset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode_seq(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        ids = self.encode_seq(ex[\"sequence\"])\n        label = self.label2id[ex[\"label\"]]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    sequences = []\n    for i, b in enumerate(batch):\n        seq_len = len(b[\"input_ids\"])\n        input_ids[i, :seq_len] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        sequences.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": sequences}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\ntrain_loader = DataLoader(\n    train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n)  # <= BUGFIX\ndev_loader = DataLoader(\n    dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n)\n\n\n# ---------- model ----------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)  # [B, L, E]\n        outputs, _ = self.lstm(emb)  # [B, L, 2H]\n        mask = (x != pad_id).unsqueeze(-1)  # [B, L, 1]\n        summed = (outputs * mask).sum(1)  # [B, 2H]\n        lengths = mask.sum(1).clamp(min=1)  # [B,1]\n        mean = summed / lengths\n        return self.fc(mean)  # [B, C]\n\n\nmodel = BiLSTMClassifier(len(vocab), 64, 128, num_labels, pad_idx=pad_id).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------- training ----------\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    # ---- train ----\n    model.train()\n    running_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"])\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = running_loss / len(train_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"epoch\": epoch, \"loss\": train_loss}\n    )\n\n    # ---- eval ----\n    model.eval()\n    val_loss, all_pred, all_true, all_seq = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            tensor_batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(tensor_batch[\"input_ids\"])\n            loss = criterion(logits, tensor_batch[\"labels\"])\n            val_loss += loss.item() * tensor_batch[\"labels\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            truths = tensor_batch[\"labels\"].cpu().tolist()\n            all_pred.extend(preds)\n            all_true.extend(truths)\n            all_seq.extend(batch[\"sequences\"])\n    val_loss /= len(dev_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n\n    swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n    cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n    )\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = all_pred\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_true\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} \"\n        f\"| SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n    )\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, json, math\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ---------- mandatory working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- experiment container ----------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n\n# ---------- locate SPR_BENCH ----------\ndef find_spr_bench_path() -> pathlib.Path:\n    \"\"\"Return absolute Path to SPR_BENCH containing the expected csv files.\"\"\"\n    candidates = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),  # user-specified\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",  # fallback (from error log)\n    ]\n    for c in candidates:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p}\")\n            return p\n    raise FileNotFoundError(\n        \"SPR_BENCH directory with train.csv/dev.csv/test.csv not found. \"\n        \"Set env var SPR_BENCH_PATH or place directory next to this script.\"\n    )\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ---------- dataset utilities ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",  # read full csv\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    dset = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        dset[split] = _load(f\"{split}.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------- load dataset ----------\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- build vocab / labels ----------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\npad_id = vocab[\"<pad>\"]\nprint(f\"Vocab size = {len(vocab)}, num_labels = {num_labels}\")\n\n\n# ---------- Torch dataset ----------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, vocab, label2id):\n        self.data = hf_dataset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode_seq(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        ids = self.encode_seq(ex[\"sequence\"])\n        label = self.label2id[ex[\"label\"]]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    sequences = []\n    for i, b in enumerate(batch):\n        seq_len = len(b[\"input_ids\"])\n        input_ids[i, :seq_len] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        sequences.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": sequences}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\ntrain_loader = DataLoader(\n    train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n)  # <= BUGFIX\ndev_loader = DataLoader(\n    dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n)\n\n\n# ---------- model ----------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)  # [B, L, E]\n        outputs, _ = self.lstm(emb)  # [B, L, 2H]\n        mask = (x != pad_id).unsqueeze(-1)  # [B, L, 1]\n        summed = (outputs * mask).sum(1)  # [B, 2H]\n        lengths = mask.sum(1).clamp(min=1)  # [B,1]\n        mean = summed / lengths\n        return self.fc(mean)  # [B, C]\n\n\nmodel = BiLSTMClassifier(len(vocab), 64, 128, num_labels, pad_idx=pad_id).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# ---------- training ----------\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    # ---- train ----\n    model.train()\n    running_loss = 0.0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"])\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = running_loss / len(train_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        {\"epoch\": epoch, \"loss\": train_loss}\n    )\n\n    # ---- eval ----\n    model.eval()\n    val_loss, all_pred, all_true, all_seq = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            tensor_batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(tensor_batch[\"input_ids\"])\n            loss = criterion(logits, tensor_batch[\"labels\"])\n            val_loss += loss.item() * tensor_batch[\"labels\"].size(0)\n            preds = logits.argmax(-1).cpu().tolist()\n            truths = tensor_batch[\"labels\"].cpu().tolist()\n            all_pred.extend(preds)\n            all_true.extend(truths)\n            all_seq.extend(batch[\"sequences\"])\n    val_loss /= len(dev_ds)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n\n    swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n    cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n    hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n    )\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = all_pred\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_true\n\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} \"\n        f\"| SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n    )\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 55, in <module>\\n    spr = load_spr_bench(DATA_PATH)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 27, in load_spr_bench\\n\ndset[\"train\"] = _load(\"train.csv\")\\n                    ^^^^^^^^^^^^^^^^^^\\n\nFile \"runfile.py\", line 19, in _load\\n    return load_dataset(\\n\n^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 2062, in load_dataset\\n    builder_instance =\nload_dataset_builder(\\n                       ^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1782, in load_dataset_builder\\n\ndataset_module = dataset_module_factory(\\n\n^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1497, in dataset_module_factory\\n\n).get_module()\\n      ^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 913, in get_module\\n    data_files =\nDataFilesDict.from_patterns(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\nFile \"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 690, in from_patterns\\n    else\nDataFilesList.from_patterns(\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 583, in from_patterns\\n\nresolve_pattern(\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 384, in resolve_pattern\\n    raise\nFileNotFoundError(error_msg)\\nFileNotFoundError: Unable to find\n\\'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n1/SPR_BENCH/train.csv\\'\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 186, in <module>\\n    assert DATA_PATH.exists(), f\"Data path\nnot found: {DATA_PATH}\"\\n           ^^^^^^^^^^^^^^^^^^\\nAssertionError: Data\npath not found: SPR_BENCH\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']", "['Traceback (most recent call last):\\n  File \"runfile.py\", line 4, in <module>\\n\nfrom SPR import load_spr_bench, shape_weighted_accuracy,\ncolor_weighted_accuracy\\nModuleNotFoundError: No module named \\'SPR\\'\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Traceback (most recent call last):\\n  File \"runfile.py\", line 5, in <module>\\n\nfrom SPR import load_spr_bench, shape_weighted_accuracy,\ncolor_weighted_accuracy\\nModuleNotFoundError: No module named \\'SPR\\'\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 521485.02\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 672336.50\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 740532.85\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize = 18, num_labels = 2', '\\n', 'Epoch 1: train_loss=0.2429 | val_loss=0.1411\n| SWA=0.9505 CWA=0.9489 HWA=0.9497', '\\n', 'Epoch 2: train_loss=0.1038 |\nval_loss=0.0847 | SWA=0.9766 CWA=0.9770 HWA=0.9768', '\\n', 'Epoch 3:\ntrain_loss=0.0702 | val_loss=0.0592 | SWA=0.9874 CWA=0.9877 HWA=0.9876', '\\n',\n'Epoch 4: train_loss=0.0442 | val_loss=0.0369 | SWA=0.9932 CWA=0.9935\nHWA=0.9934', '\\n', 'Epoch 5: train_loss=0.0308 | val_loss=0.0289 | SWA=0.9930\nCWA=0.9936 HWA=0.9933', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n1/working/experiment_data.npy', '\\n', 'Execution time: 11 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 451923.72\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 575808.46\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 520443.23\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n',\n'Vocab:', ' ', '18', ' ', '| Classes:', ' ', '2', '\\n', '[Contrast] epoch 1 loss\n4.4118', '\\n', '[Contrast] epoch 2 loss 4.3681', '\\n', '[Contrast] epoch 3 loss\n4.3689', '\\n', 'Epoch 1: val_loss=0.1760 SWA=0.946 CWA=0.943 HWA=0.944', '\\n',\n'Epoch 2: val_loss=0.1399 SWA=0.955 CWA=0.953 HWA=0.954', '\\n', 'Epoch 3:\nval_loss=0.1126 SWA=0.965 CWA=0.965 HWA=0.965', '\\n', 'Epoch 4: val_loss=0.0824\nSWA=0.977 CWA=0.978 HWA=0.977', '\\n', 'Epoch 5: val_loss=0.0659 SWA=0.982\nCWA=0.983 HWA=0.983', '\\n', 'Saved experiment_data.npy to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n3/working', '\\n', 'Execution time: 8 seconds seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 65, in <module>\\n    spr = load_spr_bench(DATA_PATH)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 27, in load_spr_bench\\n\nd[split if split != \"dev\" else \"dev\"] = _load(f\"{split}.csv\")\\n\n^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 18, in _load\\n    return\nload_dataset(\\n           ^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 2062, in load_dataset\\n    builder_instance =\nload_dataset_builder(\\n                       ^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1782, in load_dataset_builder\\n\ndataset_module = dataset_module_factory(\\n\n^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1497, in dataset_module_factory\\n\n).get_module()\\n      ^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 913, in get_module\\n    data_files =\nDataFilesDict.from_patterns(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\nFile \"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 690, in from_patterns\\n    else\nDataFilesList.from_patterns(\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 583, in from_patterns\\n\nresolve_pattern(\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 384, in resolve_pattern\\n    raise\nFileNotFoundError(error_msg)\\nFileNotFoundError: Unable to find\n\\'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n4/SPR_BENCH/train.csv\\'\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 18, in <module>\\n    from SPR import load_spr_bench,\nshape_weighted_accuracy, color_weighted_accuracy\\nModuleNotFoundError: No module\nnamed \\'SPR\\'\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 481522.76\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 514575.39\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 700077.45\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize = 18, num_labels = 2', '\\n', 'Epoch 1: train_loss=0.2449 | val_loss=0.1526\n| SWA=0.9526 CWA=0.9503 HWA=0.9514', '\\n', 'Epoch 2: train_loss=0.1135 |\nval_loss=0.0881 | SWA=0.9698 CWA=0.9696 HWA=0.9697', '\\n', 'Epoch 3:\ntrain_loss=0.0627 | val_loss=0.0499 | SWA=0.9885 CWA=0.9893 HWA=0.9889', '\\n',\n'Epoch 4: train_loss=0.0410 | val_loss=0.0360 | SWA=0.9912 CWA=0.9919\nHWA=0.9916', '\\n', 'Epoch 5: train_loss=0.0302 | val_loss=0.0370 | SWA=0.9890\nCWA=0.9897 HWA=0.9893', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n2/working/experiment_data.npy', '\\n', 'Execution time: 11 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 544704.19\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 665487.89\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 792649.34\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize = 18, num_labels = 2', '\\n', 'Epoch 1: train_loss=0.2369 | val_loss=0.1277\n| SWA=0.9607 CWA=0.9588 HWA=0.9598', '\\n', 'Epoch 2: train_loss=0.0929 |\nval_loss=0.0679 | SWA=0.9831 CWA=0.9838 HWA=0.9834', '\\n', 'Epoch 3:\ntrain_loss=0.0535 | val_loss=0.0460 | SWA=0.9857 CWA=0.9869 HWA=0.9863', '\\n',\n'Epoch 4: train_loss=0.0367 | val_loss=0.0341 | SWA=0.9898 CWA=0.9907\nHWA=0.9902', '\\n', 'Epoch 5: train_loss=0.0264 | val_loss=0.0250 | SWA=0.9928\nCWA=0.9938 HWA=0.9933', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n4/working/experiment_data.npy', '\\n', 'Execution time: 11 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Vocab size = 18, num_labels = 2', '\\n', 'Epoch 1: train_loss=0.2438 |\nval_loss=0.1515 | SWA=0.9586 CWA=0.9563 HWA=0.9574', '\\n', 'Epoch 2:\ntrain_loss=0.1204 | val_loss=0.0892 | SWA=0.9708 CWA=0.9707 HWA=0.9707', '\\n',\n'Epoch 3: train_loss=0.0695 | val_loss=0.0520 | SWA=0.9874 CWA=0.9878\nHWA=0.9876', '\\n', 'Epoch 4: train_loss=0.0414 | val_loss=0.0372 | SWA=0.9898\nCWA=0.9905 HWA=0.9901', '\\n', 'Epoch 5: train_loss=0.0288 | val_loss=0.0327 |\nSWA=0.9924 CWA=0.9933 HWA=0.9929', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n1/working/experiment_data.npy', '\\n', 'Execution time: 11 seconds seconds (time\nlimit is 30 minutes).']", ""], "analysis": ["The execution failed due to a FileNotFoundError. The script attempted to load\nthe SPR_BENCH dataset from a specified path ('/home/zxl240011/AI-\nScientist-v2/SPR_BENCH/train.csv'), but the file was not found at that location.\nTo fix this issue, ensure that the SPR_BENCH dataset is correctly located at the\nspecified path or update the DATA_PATH variable in the script to point to the\ncorrect location of the dataset.", "The execution failed due to a missing dataset directory. The error message\nindicates that the specified data path 'SPR_BENCH' does not exist. To fix this\nissue, ensure that the dataset is properly downloaded and the 'SPR_BENCH'\ndirectory is placed in the correct location. Alternatively, specify the correct\npath to the dataset using the 'SPR_PATH' environment variable.", "The script failed to execute due to a ModuleNotFoundError: No module named\n'SPR'. This indicates that the SPR module, which contains utility functions like\nload_spr_bench, shape_weighted_accuracy, and color_weighted_accuracy, is not\navailable or not correctly imported. To fix this, ensure that the SPR.py file is\nin the same directory as the script being executed or in the PYTHONPATH. If it's\nin a different directory, update the PYTHONPATH or use an absolute import path\nto locate the module.", "The execution failed with a 'ModuleNotFoundError' for the module 'SPR'. This\nindicates that the 'SPR' module, which contains the necessary functions for the\nscript, is not available in the current environment.   To fix this issue, ensure\nthat the 'SPR.py' file is in the same directory as the script being executed or\nproperly installed as a module. Alternatively, verify the PYTHONPATH environment\nvariable to include the directory containing 'SPR.py'.", "", "", "The execution failed because the script could not find the dataset files\n(train.csv, dev.csv, test.csv) in the specified directory path\n'/home/zxl240011/AI-Scientist-v2/experiments/.../SPR_BENCH/'. This likely\noccurred because the dataset path was not correctly set or the files were\nmissing from the expected location.   To fix this issue: 1. Verify that the\ndataset files (train.csv, dev.csv, test.csv) are present in the specified\ndirectory. 2. Ensure that the environment variable 'SPR_PATH' or the hardcoded\npath provided in 'DATA_PATH' points to the correct directory containing the\ndataset. 3. If the dataset is not yet downloaded, download it and place it in\nthe correct directory structure as expected by the script.", "The script failed to execute due to a `ModuleNotFoundError`. The error indicates\nthat the module `SPR` could not be found. This could be because the `SPR.py`\nfile is not in the same directory as the script being executed, or the Python\npath does not include the directory containing the `SPR.py` file.   **Proposed\nFix:** 1. Ensure that the `SPR.py` file is in the same directory as the script\nbeing executed, or provide the correct relative or absolute path to the `SPR.py`\nfile. 2. If the file is in a different directory, add that directory to the\nPython path. For example, you can use:    ```python    import sys\nsys.path.append('/path/to/directory/containing/SPR.py')    ``` 3. Verify the\nfile name and ensure it is correctly spelled as `SPR.py`.", "", "", "", ""], "exc_type": ["FileNotFoundError", "AssertionError", "ModuleNotFoundError", "ModuleNotFoundError", null, null, "FileNotFoundError", "ModuleNotFoundError", null, null, null, null], "exc_info": [{"args": ["Unable to find '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-1/SPR_BENCH/train.csv'"]}, {"args": ["Data path not found: SPR_BENCH"]}, {"args": ["No module named 'SPR'"], "name": "SPR", "msg": "No module named 'SPR'"}, {"args": ["No module named 'SPR'"], "name": "SPR", "msg": "No module named 'SPR'"}, null, null, {"args": ["Unable to find '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-4/SPR_BENCH/train.csv'"]}, {"args": ["No module named 'SPR'"], "name": "SPR", "msg": "No module named 'SPR'"}, null, null, null, null], "exc_stack": [[["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 55, "<module>", "spr = load_spr_bench(DATA_PATH)"], ["runfile.py", 27, "load_spr_bench", "dset[\"train\"] = _load(\"train.csv\")"], ["runfile.py", 19, "_load", "return load_dataset("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 2062, "load_dataset", "builder_instance = load_dataset_builder("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1782, "load_dataset_builder", "dataset_module = dataset_module_factory("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1497, "dataset_module_factory", ").get_module()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 913, "get_module", "data_files = DataFilesDict.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 690, "from_patterns", "else DataFilesList.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 583, "from_patterns", "resolve_pattern("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 384, "resolve_pattern", "raise FileNotFoundError(error_msg)"]], [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 186, "<module>", "assert DATA_PATH.exists(), f\"Data path not found: {DATA_PATH}\""]], [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 4, "<module>", "from SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy"]], [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 5, "<module>", "from SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy"]], null, null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 65, "<module>", "spr = load_spr_bench(DATA_PATH)"], ["runfile.py", 27, "load_spr_bench", "d[split if split != \"dev\" else \"dev\"] = _load(f\"{split}.csv\")"], ["runfile.py", 18, "_load", "return load_dataset("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 2062, "load_dataset", "builder_instance = load_dataset_builder("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1782, "load_dataset_builder", "dataset_module = dataset_module_factory("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1497, "dataset_module_factory", ").get_module()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 913, "get_module", "data_files = DataFilesDict.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 690, "from_patterns", "else DataFilesList.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 583, "from_patterns", "resolve_pattern("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 384, "resolve_pattern", "raise FileNotFoundError(error_msg)"]], [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 18, "<module>", "from SPR import load_spr_bench, shape_weighted_accuracy, color_weighted_accuracy"]], null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.030832, "best_value": 0.030832}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.993366, "best_value": 0.993366}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "The shape weighted accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.993198, "best_value": 0.993198}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "The color weighted accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.993533, "best_value": 0.993533}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.036855, "best_value": 0.036855}]}]}, {"metric_names": [{"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by the shape of the objects in the dataset.", "data": [{"dataset_name": "train", "final_value": 0.9802, "best_value": 0.9802}, {"dataset_name": "validation", "final_value": 0.982, "best_value": 0.982}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by the color of the objects in the dataset.", "data": [{"dataset_name": "train", "final_value": 0.9802, "best_value": 0.9802}, {"dataset_name": "validation", "final_value": 0.9832, "best_value": 0.9832}]}, {"metric_name": "harmonic-weighted accuracy", "lower_is_better": false, "description": "Harmonic mean of shape-weighted and color-weighted accuracy.", "data": [{"dataset_name": "train", "final_value": 0.9802, "best_value": 0.9802}, {"dataset_name": "validation", "final_value": 0.9826, "best_value": 0.9826}]}, {"metric_name": "contrastive loss", "lower_is_better": true, "description": "Loss function used for contrastive learning.", "data": [{"dataset_name": "overall", "final_value": 4.3689, "best_value": 4.3689}]}, {"metric_name": "supervised loss", "lower_is_better": true, "description": "Loss function for supervised learning.", "data": [{"dataset_name": "train", "final_value": 0.0725, "best_value": 0.0725}, {"dataset_name": "validation", "final_value": 0.0659, "best_value": 0.0659}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is learning.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.030211, "best_value": 0.030211}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic mean of weighted accuracy on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.991584, "best_value": 0.991584}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "The weighted accuracy for shape classification on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.991222, "best_value": 0.991222}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "The weighted accuracy for color classification on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.991947, "best_value": 0.991947}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation set, indicating model performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.035984, "best_value": 0.035984}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The final loss value during training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.026362, "best_value": 0.026362}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "Harmonic weighted accuracy on the validation dataset at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.993284, "best_value": 0.993284}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "Shape weighted accuracy on the validation dataset at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.992792, "best_value": 0.992792}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "Color weighted accuracy on the validation dataset at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.993777, "best_value": 0.993777}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.025005, "best_value": 0.025005}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.028795, "best_value": 0.028795}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.992866, "best_value": 0.992866}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "The shape weighted accuracy on the validation set at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.992443, "best_value": 0.992443}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "The color weighted accuracy on the validation set at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.993289, "best_value": 0.993289}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation set at the best epoch.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.032675, "best_value": 0.032675}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, true, false, false, false, false, false, false, false], "plots": [[], [], [], [], ["../../logs/0-run/experiment_results/experiment_011dc39e6870428fb1f22d89b185653c_proc_2983630/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_011dc39e6870428fb1f22d89b185653c_proc_2983630/SPR_BENCH_weighted_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_011dc39e6870428fb1f22d89b185653c_proc_2983630/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_supervised_loss.png", "../../logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_contrastive_loss.png", "../../logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_HWA.png", "../../logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_SWA.png", "../../logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_CWA.png"], [], [], ["../../logs/0-run/experiment_results/experiment_2a72eb39cf984b288880ffac60f1d335_proc_2983631/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_2a72eb39cf984b288880ffac60f1d335_proc_2983631/SPR_BENCH_weighted_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_2a72eb39cf984b288880ffac60f1d335_proc_2983631/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_21043688b5e94657b15cc4254182eb65_proc_2983633/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_21043688b5e94657b15cc4254182eb65_proc_2983633/SPR_BENCH_weighted_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_21043688b5e94657b15cc4254182eb65_proc_2983633/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_59c2d3fd98414f9ea7e92b256549bc3a_proc_2983630/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_59c2d3fd98414f9ea7e92b256549bc3a_proc_2983630/SPR_BENCH_weighted_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_59c2d3fd98414f9ea7e92b256549bc3a_proc_2983630/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/seed_aggregation_71b2c3417b2344ed8fb6d2b2dab4562a/SPR_BENCH_aggregated_loss_curves.png", "../../logs/0-run/experiment_results/seed_aggregation_71b2c3417b2344ed8fb6d2b2dab4562a/SPR_BENCH_aggregated_weighted_accuracy_curves.png", "../../logs/0-run/experiment_results/seed_aggregation_71b2c3417b2344ed8fb6d2b2dab4562a/SPR_BENCH_aggregated_confusion_matrix.png"]], "plot_paths": [[], [], [], [], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_011dc39e6870428fb1f22d89b185653c_proc_2983630/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_011dc39e6870428fb1f22d89b185653c_proc_2983630/SPR_BENCH_weighted_accuracy_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_011dc39e6870428fb1f22d89b185653c_proc_2983630/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_supervised_loss.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_contrastive_loss.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_HWA.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_SWA.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_CWA.png"], [], [], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_2a72eb39cf984b288880ffac60f1d335_proc_2983631/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_2a72eb39cf984b288880ffac60f1d335_proc_2983631/SPR_BENCH_weighted_accuracy_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_2a72eb39cf984b288880ffac60f1d335_proc_2983631/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_21043688b5e94657b15cc4254182eb65_proc_2983633/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_21043688b5e94657b15cc4254182eb65_proc_2983633/SPR_BENCH_weighted_accuracy_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_21043688b5e94657b15cc4254182eb65_proc_2983633/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_59c2d3fd98414f9ea7e92b256549bc3a_proc_2983630/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_59c2d3fd98414f9ea7e92b256549bc3a_proc_2983630/SPR_BENCH_weighted_accuracy_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_59c2d3fd98414f9ea7e92b256549bc3a_proc_2983630/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_71b2c3417b2344ed8fb6d2b2dab4562a/SPR_BENCH_aggregated_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_71b2c3417b2344ed8fb6d2b2dab4562a/SPR_BENCH_aggregated_weighted_accuracy_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_71b2c3417b2344ed8fb6d2b2dab4562a/SPR_BENCH_aggregated_confusion_matrix.png"]], "plot_analyses": [[], [], [], [], [{"analysis": "The loss curves indicate that both training and validation losses decrease steadily over the epochs, eventually converging to very low values. This suggests that the model is learning effectively and there is minimal overfitting, as the validation loss closely follows the training loss throughout the training process. The rapid decrease in loss during the initial epochs highlights efficient learning dynamics.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_011dc39e6870428fb1f22d89b185653c_proc_2983630/SPR_BENCH_loss_curves.png"}, {"analysis": "The weighted accuracy plot shows a consistent improvement in SWA, CWA, and HWA metrics across epochs, ultimately reaching near-perfect accuracy. This indicates that the model is highly effective at capturing the logical rules and symbolic patterns in the dataset. The alignment and overlapping of SWA, CWA, and HWA curves suggest balanced performance across different weighted accuracy measures.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_011dc39e6870428fb1f22d89b185653c_proc_2983630/SPR_BENCH_weighted_accuracy_curves.png"}, {"analysis": "The confusion matrix reveals a clear separation between the true and predicted classes, with strong diagonal dominance. This indicates that the model is highly accurate in its predictions, with very few misclassifications. The visualization confirms the robustness of the model in handling the SPR task effectively.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_011dc39e6870428fb1f22d89b185653c_proc_2983630/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The plot shows the supervised loss for both training and validation datasets over five epochs. The training loss consistently decreases, indicating that the model is learning effectively. Similarly, the validation loss also decreases, suggesting that the model generalizes well to unseen data. The convergence of both losses towards lower values implies that the training process is stable and effective without overfitting.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_supervised_loss.png"}, {"analysis": "The plot illustrates the NT-Xent loss during the contrastive pre-training phase over three epochs. There is a sharp decrease in loss from the first to the second epoch, indicating rapid improvement in the quality of embeddings during the initial stage of training. However, the loss stabilizes after the second epoch, suggesting that the pre-training has reached a plateau and further improvements may require additional adjustments or more epochs.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_contrastive_loss.png"}, {"analysis": "The plot presents the harmonic weighted accuracy (HWA) for both training and validation datasets over five epochs. Initially, the validation accuracy surpasses the training accuracy, which is a common occurrence in the early stages of training due to regularization effects. Both accuracies steadily increase and converge towards a high value near 0.98, indicating strong performance and generalization. The close alignment of the two curves suggests that the model is not overfitting.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_HWA.png"}, {"analysis": "The plot depicts the shape-weighted accuracy (SWA) for training and validation datasets over five epochs. Both accuracies improve consistently, with validation accuracy initially higher than training accuracy. The curves converge towards a value close to 0.98, highlighting the model's ability to effectively learn and generalize shape-related patterns in the dataset. The steady improvement and convergence of the two curves indicate a well-optimized training process.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_SWA.png"}, {"analysis": "The plot shows the color-weighted accuracy (CWA) for training and validation datasets over five epochs. Similar to the SWA plot, both accuracies increase steadily, with validation accuracy initially higher but eventually converging with the training accuracy near 0.98. This demonstrates the model's capability to learn and generalize color-related patterns effectively. The consistent improvement and alignment of the curves indicate a robust training process.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_517c0ec6b6134964b55aa878ad940d78_proc_2983632/SPR_BENCH_CWA.png"}], [], [], [{"analysis": "The loss curves illustrate that both training and validation loss decrease consistently over the epochs, indicating effective learning and generalization. The convergence of the two curves toward the end suggests that the model is not overfitting and has achieved a good balance between training and validation performance.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_2a72eb39cf984b288880ffac60f1d335_proc_2983631/SPR_BENCH_loss_curves.png"}, {"analysis": "The weighted accuracy metrics (SWA, CWA, and HWA) show a steady increase over the epochs, reaching nearly perfect scores by epoch 4. This demonstrates that the model is effectively capturing the patterns in the SPR_BENCH dataset and achieving high accuracy across different weighting schemes. The slight dip at epoch 5 might indicate minor overfitting or noise in the evaluation.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_2a72eb39cf984b288880ffac60f1d335_proc_2983631/SPR_BENCH_weighted_accuracy_curves.png"}, {"analysis": "The confusion matrix reveals a strong diagonal dominance, indicating that the model is making accurate predictions for the majority of cases. The high intensity along the main diagonal suggests that the model has a strong ability to classify sequences correctly, with minimal misclassification in off-diagonal elements.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_2a72eb39cf984b288880ffac60f1d335_proc_2983631/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The loss curves indicate that both the training and validation losses decrease steadily over the epochs, converging to very low values by the fifth epoch. This suggests that the model is learning effectively without significant overfitting, as the validation loss closely follows the training loss throughout.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_21043688b5e94657b15cc4254182eb65_proc_2983633/SPR_BENCH_loss_curves.png"}, {"analysis": "The weighted accuracy metrics (SWA, CWA, and HWA) show consistent improvement across epochs, reaching near-perfect accuracy by the fifth epoch. This indicates that the model performs exceptionally well across all weighted metrics, validating the effectiveness of the proposed context-aware contrastive learning framework.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_21043688b5e94657b15cc4254182eb65_proc_2983633/SPR_BENCH_weighted_accuracy_curves.png"}, {"analysis": "The confusion matrix shows a clear separation between true positive and true negative predictions, with minimal misclassification. This further supports the high performance of the model and its ability to distinguish between classes accurately.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_21043688b5e94657b15cc4254182eb65_proc_2983633/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The loss curves indicate a consistent and smooth decrease in both training and validation loss over the epochs, suggesting that the model is learning effectively without overfitting. The validation loss closely follows the training loss, further supporting the absence of overfitting and indicating good generalization capability.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_59c2d3fd98414f9ea7e92b256549bc3a_proc_2983630/SPR_BENCH_loss_curves.png"}, {"analysis": "The weighted accuracy metrics (SWA, CWA, and HWA) show a steady increase over the epochs, with all metrics converging to high values near 0.995 by the final epoch. This suggests that the model performs well across all weighted accuracy measures, indicating that the proposed context-aware contrastive learning framework is effective for the SPR task.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_59c2d3fd98414f9ea7e92b256549bc3a_proc_2983630/SPR_BENCH_weighted_accuracy_curves.png"}, {"analysis": "The confusion matrix shows a clear diagonal dominance, indicating that the model is making accurate predictions with minimal misclassifications. The intensity of the diagonal cells reflects the high number of correct predictions, further corroborating the high accuracy metrics observed in the previous plot.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_59c2d3fd98414f9ea7e92b256549bc3a_proc_2983630/SPR_BENCH_confusion_matrix.png"}], []], "vlm_feedback_summary": ["[]", "[]", "[]", "[]", "The experimental results demonstrate strong performance, with effectively\ndecreasing loss curves, near-perfect weighted accuracy metrics, and a highly\naccurate confusion matrix. The model appears to be well-tuned for the SPR task,\nachieving balanced and robust results across all evaluation metrics.", "The plots collectively demonstrate a well-optimized training process with\nconsistent improvements in performance metrics and effective generalization. The\nsupervised loss plot confirms stable training without overfitting, while the\ncontrastive pre-training loss plot indicates rapid initial improvement followed\nby stabilization. The accuracy plots (HWA, SWA, CWA) highlight the model's\nstrong performance in learning and generalizing symbolic patterns in the\ndataset.", "[]", "[]", "The experimental results show strong model performance, with consistent loss\nreduction, high weighted accuracy metrics, and minimal misclassification errors.\nThese findings suggest the proposed contrastive learning framework is effective\nfor the SPR task.", "The experimental plots demonstrate strong model performance, with loss curves\nshowing effective learning and weighted accuracy metrics approaching perfection.\nThe confusion matrix corroborates these findings, indicating minimal\nmisclassification.", "The results demonstrate strong performance, with smooth loss reduction and high\naccuracy metrics across all measures. The confusion matrix confirms the model's\neffectiveness in making accurate predictions.", "[]"], "exec_time": [0.6125020980834961, 0.40908265113830566, 0.0022962093353271484, 0.22524642944335938, 11.679917812347412, 8.55061650276184, 0.42075276374816895, 0.0033028125762939453, 11.380681276321411, 11.592158079147339, 11.553755044937134, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [[], [], [], [], ["['SPR_BENCH']"], ["[\"experiment_data\"]"], [], [], ["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], []], "plot_code": [null, null, null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nspr = experiment_data.get(\"SPR_BENCH\", {})\n\n\n# ---------- helper ----------\ndef save_and_close(fig, fname):\n    fig.savefig(os.path.join(working_dir, fname), bbox_inches=\"tight\")\n    plt.close(fig)\n    print(f\"Saved {fname}\")\n\n\n# ---------- 1. loss curves ----------\ntry:\n    tr_loss = spr.get(\"losses\", {}).get(\"train\", [])\n    va_loss = spr.get(\"losses\", {}).get(\"val\", [])\n    if tr_loss and va_loss:\n        epochs = np.arange(1, len(tr_loss) + 1)\n        fig = plt.figure()\n        plt.plot(epochs, tr_loss, label=\"Train Loss\")\n        plt.plot(epochs, va_loss, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\")\n        plt.legend()\n        save_and_close(fig, \"SPR_BENCH_loss_curves.png\")\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---------- 2. metric curves ----------\ntry:\n    val_metrics = spr.get(\"metrics\", {}).get(\"val\", [])\n    if val_metrics:\n        swa = [m[\"swa\"] for m in val_metrics]\n        cwa = [m[\"cwa\"] for m in val_metrics]\n        hwa = [m[\"hwa\"] for m in val_metrics]\n        epochs = np.arange(1, len(swa) + 1)\n        fig = plt.figure()\n        plt.plot(epochs, swa, label=\"SWA\")\n        plt.plot(epochs, cwa, label=\"CWA\")\n        plt.plot(epochs, hwa, label=\"HWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH Weighted Accuracies\")\n        plt.legend()\n        save_and_close(fig, \"SPR_BENCH_weighted_accuracy_curves.png\")\nexcept Exception as e:\n    print(f\"Error creating metric curves: {e}\")\n    plt.close()\n\n# ---------- 3. confusion matrix ----------\ntry:\n    preds = np.array(spr.get(\"predictions\", []), dtype=int)\n    trues = np.array(spr.get(\"ground_truth\", []), dtype=int)\n    if preds.size and trues.size:\n        num_labels = int(max(preds.max(), trues.max())) + 1\n        cm = np.zeros((num_labels, num_labels), dtype=int)\n        for t, p in zip(trues, preds):\n            cm[t, p] += 1\n        fig = plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\n            \"SPR_BENCH Confusion Matrix\\nLeft: Ground Truth, Right: Generated Predictions\"\n        )\n        save_and_close(fig, \"SPR_BENCH_confusion_matrix.png\")\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# Re-establish working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nfor dset, data in experiment_data.items():\n    # Helper to fetch list safely\n    def safe_get(path, default=None):\n        cur = data\n        for k in path:\n            cur = cur.get(k, None) if isinstance(cur, dict) else None\n            if cur is None:\n                return default\n        return cur\n\n    # 1) Supervised loss curves ------------------------------------------------\n    try:\n        tr_loss = safe_get([\"losses\", \"supervised\", \"train\"])\n        val_loss = safe_get([\"losses\", \"supervised\", \"val\"])\n        if tr_loss and val_loss:\n            plt.figure()\n            epochs = np.arange(1, len(tr_loss) + 1)\n            plt.plot(epochs, tr_loss, label=\"Train\")\n            plt.plot(epochs, val_loss, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(f\"{dset} Supervised Loss\\nTrain vs Validation\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset}_supervised_loss.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating supervised loss plot for {dset}: {e}\")\n        plt.close()\n\n    # 2) Contrastive loss ------------------------------------------------------\n    try:\n        contrast = safe_get([\"losses\", \"contrastive\"])\n        if contrast:\n            plt.figure()\n            plt.plot(np.arange(1, len(contrast) + 1), contrast, marker=\"o\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"NT-Xent Loss\")\n            plt.title(f\"{dset} Contrastive Pre-training Loss\")\n            fname = os.path.join(working_dir, f\"{dset}_contrastive_loss.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating contrastive loss plot for {dset}: {e}\")\n        plt.close()\n\n    # Metric extractor ---------------------------------------------------------\n    metrics_train = safe_get([\"metrics\", \"train\"], [])\n    metrics_val = safe_get([\"metrics\", \"val\"], [])\n\n    def metric_series(key, source):\n        return [m.get(key, np.nan) for m in source] if source else []\n\n    # 3) HWA curves ------------------------------------------------------------\n    try:\n        tr_hwa, val_hwa = metric_series(\"hwa\", metrics_train), metric_series(\n            \"hwa\", metrics_val\n        )\n        if tr_hwa and val_hwa:\n            plt.figure()\n            epochs = np.arange(1, len(tr_hwa) + 1)\n            plt.plot(epochs, tr_hwa, label=\"Train\")\n            plt.plot(epochs, val_hwa, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Harmonic Weighted Acc\")\n            plt.title(f\"{dset} HWA\\nTrain vs Validation\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset}_HWA.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating HWA plot for {dset}: {e}\")\n        plt.close()\n\n    # 4) SWA curves ------------------------------------------------------------\n    try:\n        tr_swa, val_swa = metric_series(\"swa\", metrics_train), metric_series(\n            \"swa\", metrics_val\n        )\n        if tr_swa and val_swa:\n            plt.figure()\n            epochs = np.arange(1, len(tr_swa) + 1)\n            plt.plot(epochs, tr_swa, label=\"Train\")\n            plt.plot(epochs, val_swa, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Shape Weighted Acc\")\n            plt.title(f\"{dset} SWA\\nTrain vs Validation\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset}_SWA.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating SWA plot for {dset}: {e}\")\n        plt.close()\n\n    # 5) CWA curves ------------------------------------------------------------\n    try:\n        tr_cwa, val_cwa = metric_series(\"cwa\", metrics_train), metric_series(\n            \"cwa\", metrics_val\n        )\n        if tr_cwa and val_cwa:\n            plt.figure()\n            epochs = np.arange(1, len(tr_cwa) + 1)\n            plt.plot(epochs, tr_cwa, label=\"Train\")\n            plt.plot(epochs, val_cwa, label=\"Validation\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Color Weighted Acc\")\n            plt.title(f\"{dset} CWA\\nTrain vs Validation\")\n            plt.legend()\n            fname = os.path.join(working_dir, f\"{dset}_CWA.png\")\n            plt.savefig(fname)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating CWA plot for {dset}: {e}\")\n        plt.close()\n\n    # Print final validation metrics ------------------------------------------\n    try:\n        if metrics_val:\n            last = metrics_val[-1]\n            print(\n                f\"{dset} final validation metrics: SWA={last.get('swa'):.3f}, \"\n                f\"CWA={last.get('cwa'):.3f}, HWA={last.get('hwa'):.3f}\"\n            )\n    except Exception as e:\n        print(f\"Error printing final metrics for {dset}: {e}\")\n", null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nspr = experiment_data.get(\"SPR_BENCH\", {})\n\n\n# ---------- helper ----------\ndef save_and_close(fig, fname):\n    fig.savefig(os.path.join(working_dir, fname), bbox_inches=\"tight\")\n    plt.close(fig)\n    print(f\"Saved {fname}\")\n\n\n# ---------- 1. loss curves ----------\ntry:\n    tr_loss = spr.get(\"losses\", {}).get(\"train\", [])\n    va_loss = spr.get(\"losses\", {}).get(\"val\", [])\n    if tr_loss and va_loss:\n        epochs = np.arange(1, len(tr_loss) + 1)\n        fig = plt.figure()\n        plt.plot(epochs, tr_loss, label=\"Train Loss\")\n        plt.plot(epochs, va_loss, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\")\n        plt.legend()\n        save_and_close(fig, \"SPR_BENCH_loss_curves.png\")\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---------- 2. metric curves ----------\ntry:\n    val_metrics = spr.get(\"metrics\", {}).get(\"val\", [])\n    if val_metrics:\n        swa = [m[\"swa\"] for m in val_metrics]\n        cwa = [m[\"cwa\"] for m in val_metrics]\n        hwa = [m[\"hwa\"] for m in val_metrics]\n        epochs = np.arange(1, len(swa) + 1)\n        fig = plt.figure()\n        plt.plot(epochs, swa, label=\"SWA\")\n        plt.plot(epochs, cwa, label=\"CWA\")\n        plt.plot(epochs, hwa, label=\"HWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH Weighted Accuracies\")\n        plt.legend()\n        save_and_close(fig, \"SPR_BENCH_weighted_accuracy_curves.png\")\nexcept Exception as e:\n    print(f\"Error creating metric curves: {e}\")\n    plt.close()\n\n# ---------- 3. confusion matrix ----------\ntry:\n    preds = np.array(spr.get(\"predictions\", []), dtype=int)\n    trues = np.array(spr.get(\"ground_truth\", []), dtype=int)\n    if preds.size and trues.size:\n        num_labels = int(max(preds.max(), trues.max())) + 1\n        cm = np.zeros((num_labels, num_labels), dtype=int)\n        for t, p in zip(trues, preds):\n            cm[t, p] += 1\n        fig = plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\n            \"SPR_BENCH Confusion Matrix\\nLeft: Ground Truth, Right: Generated Predictions\"\n        )\n        save_and_close(fig, \"SPR_BENCH_confusion_matrix.png\")\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nspr = experiment_data.get(\"SPR_BENCH\", {})\n\n\n# ---------- helper ----------\ndef save_and_close(fig, fname):\n    fig.savefig(os.path.join(working_dir, fname), bbox_inches=\"tight\")\n    plt.close(fig)\n    print(f\"Saved {fname}\")\n\n\n# ---------- 1. loss curves ----------\ntry:\n    tr_loss = spr.get(\"losses\", {}).get(\"train\", [])\n    va_loss = spr.get(\"losses\", {}).get(\"val\", [])\n    if tr_loss and va_loss:\n        epochs = np.arange(1, len(tr_loss) + 1)\n        fig = plt.figure()\n        plt.plot(epochs, tr_loss, label=\"Train Loss\")\n        plt.plot(epochs, va_loss, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\")\n        plt.legend()\n        save_and_close(fig, \"SPR_BENCH_loss_curves.png\")\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---------- 2. metric curves ----------\ntry:\n    val_metrics = spr.get(\"metrics\", {}).get(\"val\", [])\n    if val_metrics:\n        swa = [m[\"swa\"] for m in val_metrics]\n        cwa = [m[\"cwa\"] for m in val_metrics]\n        hwa = [m[\"hwa\"] for m in val_metrics]\n        epochs = np.arange(1, len(swa) + 1)\n        fig = plt.figure()\n        plt.plot(epochs, swa, label=\"SWA\")\n        plt.plot(epochs, cwa, label=\"CWA\")\n        plt.plot(epochs, hwa, label=\"HWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH Weighted Accuracies\")\n        plt.legend()\n        save_and_close(fig, \"SPR_BENCH_weighted_accuracy_curves.png\")\nexcept Exception as e:\n    print(f\"Error creating metric curves: {e}\")\n    plt.close()\n\n# ---------- 3. confusion matrix ----------\ntry:\n    preds = np.array(spr.get(\"predictions\", []), dtype=int)\n    trues = np.array(spr.get(\"ground_truth\", []), dtype=int)\n    if preds.size and trues.size:\n        num_labels = int(max(preds.max(), trues.max())) + 1\n        cm = np.zeros((num_labels, num_labels), dtype=int)\n        for t, p in zip(trues, preds):\n            cm[t, p] += 1\n        fig = plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\n            \"SPR_BENCH Confusion Matrix\\nLeft: Ground Truth, Right: Generated Predictions\"\n        )\n        save_and_close(fig, \"SPR_BENCH_confusion_matrix.png\")\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nspr = experiment_data.get(\"SPR_BENCH\", {})\n\n\n# ---------- helper ----------\ndef save_and_close(fig, fname):\n    fig.savefig(os.path.join(working_dir, fname), bbox_inches=\"tight\")\n    plt.close(fig)\n    print(f\"Saved {fname}\")\n\n\n# ---------- 1. loss curves ----------\ntry:\n    tr_loss = spr.get(\"losses\", {}).get(\"train\", [])\n    va_loss = spr.get(\"losses\", {}).get(\"val\", [])\n    if tr_loss and va_loss:\n        epochs = np.arange(1, len(tr_loss) + 1)\n        fig = plt.figure()\n        plt.plot(epochs, tr_loss, label=\"Train Loss\")\n        plt.plot(epochs, va_loss, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\")\n        plt.legend()\n        save_and_close(fig, \"SPR_BENCH_loss_curves.png\")\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---------- 2. metric curves ----------\ntry:\n    val_metrics = spr.get(\"metrics\", {}).get(\"val\", [])\n    if val_metrics:\n        swa = [m[\"swa\"] for m in val_metrics]\n        cwa = [m[\"cwa\"] for m in val_metrics]\n        hwa = [m[\"hwa\"] for m in val_metrics]\n        epochs = np.arange(1, len(swa) + 1)\n        fig = plt.figure()\n        plt.plot(epochs, swa, label=\"SWA\")\n        plt.plot(epochs, cwa, label=\"CWA\")\n        plt.plot(epochs, hwa, label=\"HWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH Weighted Accuracies\")\n        plt.legend()\n        save_and_close(fig, \"SPR_BENCH_weighted_accuracy_curves.png\")\nexcept Exception as e:\n    print(f\"Error creating metric curves: {e}\")\n    plt.close()\n\n# ---------- 3. confusion matrix ----------\ntry:\n    preds = np.array(spr.get(\"predictions\", []), dtype=int)\n    trues = np.array(spr.get(\"ground_truth\", []), dtype=int)\n    if preds.size and trues.size:\n        num_labels = int(max(preds.max(), trues.max())) + 1\n        cm = np.zeros((num_labels, num_labels), dtype=int)\n        for t, p in zip(trues, preds):\n            cm[t, p] += 1\n        fig = plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\n            \"SPR_BENCH Confusion Matrix\\nLeft: Ground Truth, Right: Generated Predictions\"\n        )\n        save_and_close(fig, \"SPR_BENCH_confusion_matrix.png\")\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- experiment paths ----------\nexperiment_data_path_list = [\n    \"experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_2a72eb39cf984b288880ffac60f1d335_proc_2983631/experiment_data.npy\",\n    \"experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_21043688b5e94657b15cc4254182eb65_proc_2983633/experiment_data.npy\",\n    \"experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_59c2d3fd98414f9ea7e92b256549bc3a_proc_2983630/experiment_data.npy\",\n]\n\n\n# ---------- helpers ----------\ndef save_and_close(fig, fname):\n    fig.savefig(os.path.join(working_dir, fname), bbox_inches=\"tight\")\n    plt.close(fig)\n    print(f\"Saved {fname}\")\n\n\ndef stack_and_trim(list_of_lists):\n    \"\"\"Stack runs by trimming to the shortest length.\"\"\"\n    if not list_of_lists:\n        return np.empty((0, 0))\n    min_len = min(len(l) for l in list_of_lists)\n    if min_len == 0:\n        return np.empty((0, 0))\n    arr = np.stack([np.array(l[:min_len], dtype=float) for l in list_of_lists])\n    return arr  # shape (n_runs, min_len)\n\n\n# ---------- load all runs ----------\nall_runs = []\nfor p in experiment_data_path_list:\n    try:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p)\n        exp_data = np.load(full_path, allow_pickle=True).item()\n        spr = exp_data.get(\"SPR_BENCH\", {})\n        if spr:\n            all_runs.append(spr)\n    except Exception as e:\n        print(f\"Error loading {p}: {e}\")\n\nn_runs = len(all_runs)\nif n_runs == 0:\n    print(\"No SPR_BENCH data found in any run.\")\nelse:\n    print(f\"Loaded {n_runs} SPR_BENCH runs.\")\n\n# ========== 1. aggregated loss curves ==========\ntry:\n    train_losses = [run.get(\"losses\", {}).get(\"train\", []) for run in all_runs]\n    val_losses = [run.get(\"losses\", {}).get(\"val\", []) for run in all_runs]\n    tr_mat = stack_and_trim(train_losses)\n    va_mat = stack_and_trim(val_losses)\n\n    if tr_mat.size and va_mat.size:\n        epochs = np.arange(1, tr_mat.shape[1] + 1)\n        tr_mean, tr_se = tr_mat.mean(0), tr_mat.std(0, ddof=1) / np.sqrt(n_runs)\n        va_mean, va_se = va_mat.mean(0), va_mat.std(0, ddof=1) / np.sqrt(n_runs)\n\n        fig = plt.figure()\n        plt.plot(epochs, tr_mean, label=\"Train Loss (mean)\")\n        plt.fill_between(\n            epochs, tr_mean - tr_se, tr_mean + tr_se, alpha=0.3, label=\"Train SE\"\n        )\n        plt.plot(epochs, va_mean, label=\"Val Loss (mean)\")\n        plt.fill_between(\n            epochs, va_mean - va_se, va_mean + va_se, alpha=0.3, label=\"Val SE\"\n        )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\n            \"SPR_BENCH Aggregated Loss Curves\\n(mean \u00b1 standard error, N={})\".format(\n                n_runs\n            )\n        )\n        plt.legend()\n        save_and_close(fig, \"SPR_BENCH_aggregated_loss_curves.png\")\n\n        # print final numbers\n        print(\"Final epoch Train Loss: {:.4f} \u00b1 {:.4f}\".format(tr_mean[-1], tr_se[-1]))\n        print(\"Final epoch Val   Loss: {:.4f} \u00b1 {:.4f}\".format(va_mean[-1], va_se[-1]))\nexcept Exception as e:\n    print(f\"Error creating aggregated loss curves: {e}\")\n    plt.close()\n\n# ========== 2. aggregated weighted accuracy curves ==========\ntry:\n    swa_runs = [\n        [m[\"swa\"] for m in run.get(\"metrics\", {}).get(\"val\", [])] for run in all_runs\n    ]\n    cwa_runs = [\n        [m[\"cwa\"] for m in run.get(\"metrics\", {}).get(\"val\", [])] for run in all_runs\n    ]\n    hwa_runs = [\n        [m[\"hwa\"] for m in run.get(\"metrics\", {}).get(\"val\", [])] for run in all_runs\n    ]\n\n    swa_mat = stack_and_trim(swa_runs)\n    cwa_mat = stack_and_trim(cwa_runs)\n    hwa_mat = stack_and_trim(hwa_runs)\n\n    if swa_mat.size and cwa_mat.size and hwa_mat.size:\n        epochs = np.arange(1, swa_mat.shape[1] + 1)\n\n        fig = plt.figure()\n        for mat, name, color in zip(\n            [swa_mat, cwa_mat, hwa_mat],\n            [\"SWA\", \"CWA\", \"HWA\"],\n            [\"tab:blue\", \"tab:orange\", \"tab:green\"],\n        ):\n            mean = mat.mean(0)\n            se = mat.std(0, ddof=1) / np.sqrt(n_runs)\n            plt.plot(epochs, mean, label=f\"{name} (mean)\", color=color)\n            plt.fill_between(\n                epochs, mean - se, mean + se, alpha=0.3, color=color, label=f\"{name} SE\"\n            )\n\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\n            \"SPR_BENCH Aggregated Weighted Accuracies\\n(mean \u00b1 standard error, N={})\".format(\n                n_runs\n            )\n        )\n        plt.legend()\n        save_and_close(fig, \"SPR_BENCH_aggregated_weighted_accuracy_curves.png\")\n\n        # print final numbers\n        for mat, name in zip([swa_mat, cwa_mat, hwa_mat], [\"SWA\", \"CWA\", \"HWA\"]):\n            mean, se = mat.mean(0)[-1], (mat.std(0, ddof=1) / np.sqrt(n_runs))[-1]\n            print(f\"Final epoch {name}: {mean:.4f} \u00b1 {se:.4f}\")\nexcept Exception as e:\n    print(f\"Error creating aggregated weighted accuracy curves: {e}\")\n    plt.close()\n\n# ========== 3. aggregated confusion matrix ==========\ntry:\n    preds_all, trues_all = [], []\n    for run in all_runs:\n        preds_all.append(np.array(run.get(\"predictions\", []), dtype=int))\n        trues_all.append(np.array(run.get(\"ground_truth\", []), dtype=int))\n\n    if preds_all and all(p.size for p in preds_all):\n        preds = np.concatenate(preds_all)\n        trues = np.concatenate(trues_all)\n        num_labels = int(max(preds.max(), trues.max())) + 1\n        cm = np.zeros((num_labels, num_labels), dtype=int)\n        for t, p in zip(trues, preds):\n            cm[t, p] += 1\n\n        fig = plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\n            \"SPR_BENCH Aggregated Confusion Matrix\\nLeft: Ground Truth, Right: Generated Predictions\"\n        )\n        save_and_close(fig, \"SPR_BENCH_aggregated_confusion_matrix.png\")\nexcept Exception as e:\n    print(f\"Error creating aggregated confusion matrix: {e}\")\n    plt.close()\n"], "plot_plan": [null, null, null, null, "We will first load experiment_data.npy and safely extract the SPR_BENCH sub-dictionary.  \nFor losses we read the parallel lists experiment_data['SPR_BENCH']['losses']['train'] and ['val'], build an epoch index and draw a single line plot comparing training vs validation loss.  \nFor metrics the validation list contains dictionaries per epoch; we iterate to collect the SWA, CWA and HWA values and plot them together on one figure with a shared epoch axis.  \nIf predictions and ground-truth are available we compute a simple confusion matrix via numpy\u2019s bincount and display it with imshow; the number of labels is inferred from the max id seen, and we limit creation to at most one confusion-matrix figure.  \nEach figure is wrapped in its own try-except block, is given a clear title/sub-title, saved to working_dir with descriptive names, and the figure is closed in both success and error cases.  \nNo synthetic data are generated\u2014everything comes from experiment_data.npy.  \nWe keep the total number of plots \u22643, well within the 5-figure limit, and ensure working_dir exists before saving.  \nThe code uses only matplotlib and numpy, obeys the import/startup requirements, and prints a short confirmation message after each successful save.", "The script loads experiment_data.npy, safely extracts results for each dataset (here only \u201cSPR_BENCH\u201d), and generates up to five standard figures: (1) supervised training/validation loss curves, (2) contrastive pre-training loss, and (3-5) training/validation curves for HWA, SWA, and CWA. Each plot is wrapped in its own try-except block to guarantee robustness, saved with descriptive names in the working directory, and closed afterwards to free resources. Titles clearly state the dataset and plot type, while subtitles mention the data splits. At the end, the code prints the last recorded validation metrics so users can quickly inspect final performance. Figures are only produced if the corresponding arrays exist, preventing errors when data is missing. No synthetic data are created; everything comes directly from experiment_data.npy. The entire plotting routine relies solely on basic matplotlib functions and adheres to the directory structure established by the experiment code.", null, null, null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": [null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["", "", "", "", "The script will load experiment_data.npy from the working directory, iterate\nover each dataset stored inside, and report the final training loss together\nwith the best\u2010performing validation statistics (chosen by the highest harmonic-\nweighted accuracy, HWA). Each metric is printed with an explicit, descriptive\nlabel, and no plots or extraneous text are produced.", "The script will load the saved experiment_data.npy from the working directory,\nunpack its nested dictionary, and for every dataset present (e.g., \u201cSPR_BENCH\u201d)\nprint the final value recorded for each metric and loss. It explicitly names\neach metric (e.g., \u201ctrain shape-weighted accuracy\u201d) to comply with the\nguidelines and prints only the last entry in every recorded list, assuming this\nrepresents the final epoch. No plotting or main-guard is used, so the code runs\nimmediately when executed.", "", "", "The script will load experiment_data.npy from the working directory, iterate\nover each dataset stored inside, and report the final training loss together\nwith the best\u2010performing validation statistics (chosen by the highest harmonic-\nweighted accuracy, HWA). Each metric is printed with an explicit, descriptive\nlabel, and no plots or extraneous text are produced.", "The script will load experiment_data.npy from the working directory, iterate\nover each dataset stored inside, and report the final training loss together\nwith the best\u2010performing validation statistics (chosen by the highest harmonic-\nweighted accuracy, HWA). Each metric is printed with an explicit, descriptive\nlabel, and no plots or extraneous text are produced.", "The script will load experiment_data.npy from the working directory, iterate\nover each dataset stored inside, and report the final training loss together\nwith the best\u2010performing validation statistics (chosen by the highest harmonic-\nweighted accuracy, HWA). Each metric is printed with an explicit, descriptive\nlabel, and no plots or extraneous text are produced.", ""], "parse_metrics_code": ["", "", "", "", "import os\nimport numpy as np\n\n# ---------- locate experiment file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"experiment_data.npy not found at {exp_file}\")\n\n# ---------- load ----------\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# ---------- analysis & printing ----------\nfor dataset_name, content in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # ---- training metrics ----\n    train_history = content.get(\"metrics\", {}).get(\"train\", [])\n    if train_history:\n        final_train_loss = train_history[-1].get(\"loss\", None)\n        if final_train_loss is not None:\n            print(f\"final training loss: {final_train_loss:.6f}\")\n\n    # ---- validation metrics ----\n    val_history = content.get(\"metrics\", {}).get(\"val\", [])\n    if val_history:\n        # pick entry with highest HWA\n        best_val = max(val_history, key=lambda x: x.get(\"hwa\", -float(\"inf\")))\n        print(f\"best validation harmonic weighted accuracy: {best_val['hwa']:.6f}\")\n        print(\n            f\"validation shape weighted accuracy at best epoch: {best_val['swa']:.6f}\"\n        )\n        print(\n            f\"validation color weighted accuracy at best epoch: {best_val['cwa']:.6f}\"\n        )\n        print(f\"validation loss at best epoch: {best_val['loss']:.6f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load the experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"experiment_data.npy not found at: {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# Iterate over datasets and print final metrics / losses\n# ------------------------------------------------------------------\nfor dataset_name, content in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # ---------- Metrics ----------\n    train_metrics = content.get(\"metrics\", {}).get(\"train\", [])\n    val_metrics = content.get(\"metrics\", {}).get(\"val\", [])\n\n    if train_metrics:\n        last_train = train_metrics[-1]\n        print(f\"train shape-weighted accuracy: {last_train.get('swa', 'NA'):.4f}\")\n        print(f\"train color-weighted  accuracy: {last_train.get('cwa', 'NA'):.4f}\")\n        print(f\"train harmonic-weighted accuracy: {last_train.get('hwa', 'NA'):.4f}\")\n\n    if val_metrics:\n        last_val = val_metrics[-1]\n        print(f\"validation shape-weighted accuracy: {last_val.get('swa', 'NA'):.4f}\")\n        print(f\"validation color-weighted  accuracy: {last_val.get('cwa', 'NA'):.4f}\")\n        print(f\"validation harmonic-weighted accuracy: {last_val.get('hwa', 'NA'):.4f}\")\n\n    # ---------- Losses ----------\n    contrastive_losses = content.get(\"losses\", {}).get(\"contrastive\", [])\n    sup_train_losses = content.get(\"losses\", {}).get(\"supervised\", {}).get(\"train\", [])\n    sup_val_losses = content.get(\"losses\", {}).get(\"supervised\", {}).get(\"val\", [])\n\n    if contrastive_losses:\n        print(f\"contrastive loss: {contrastive_losses[-1]:.4f}\")\n\n    if sup_train_losses:\n        print(f\"train supervised loss: {sup_train_losses[-1]:.4f}\")\n\n    if sup_val_losses:\n        print(f\"validation supervised loss: {sup_val_losses[-1]:.4f}\")\n", "", "", "import os\nimport numpy as np\n\n# ---------- locate experiment file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"experiment_data.npy not found at {exp_file}\")\n\n# ---------- load ----------\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# ---------- analysis & printing ----------\nfor dataset_name, content in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # ---- training metrics ----\n    train_history = content.get(\"metrics\", {}).get(\"train\", [])\n    if train_history:\n        final_train_loss = train_history[-1].get(\"loss\", None)\n        if final_train_loss is not None:\n            print(f\"final training loss: {final_train_loss:.6f}\")\n\n    # ---- validation metrics ----\n    val_history = content.get(\"metrics\", {}).get(\"val\", [])\n    if val_history:\n        # pick entry with highest HWA\n        best_val = max(val_history, key=lambda x: x.get(\"hwa\", -float(\"inf\")))\n        print(f\"best validation harmonic weighted accuracy: {best_val['hwa']:.6f}\")\n        print(\n            f\"validation shape weighted accuracy at best epoch: {best_val['swa']:.6f}\"\n        )\n        print(\n            f\"validation color weighted accuracy at best epoch: {best_val['cwa']:.6f}\"\n        )\n        print(f\"validation loss at best epoch: {best_val['loss']:.6f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate experiment file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"experiment_data.npy not found at {exp_file}\")\n\n# ---------- load ----------\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# ---------- analysis & printing ----------\nfor dataset_name, content in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # ---- training metrics ----\n    train_history = content.get(\"metrics\", {}).get(\"train\", [])\n    if train_history:\n        final_train_loss = train_history[-1].get(\"loss\", None)\n        if final_train_loss is not None:\n            print(f\"final training loss: {final_train_loss:.6f}\")\n\n    # ---- validation metrics ----\n    val_history = content.get(\"metrics\", {}).get(\"val\", [])\n    if val_history:\n        # pick entry with highest HWA\n        best_val = max(val_history, key=lambda x: x.get(\"hwa\", -float(\"inf\")))\n        print(f\"best validation harmonic weighted accuracy: {best_val['hwa']:.6f}\")\n        print(\n            f\"validation shape weighted accuracy at best epoch: {best_val['swa']:.6f}\"\n        )\n        print(\n            f\"validation color weighted accuracy at best epoch: {best_val['cwa']:.6f}\"\n        )\n        print(f\"validation loss at best epoch: {best_val['loss']:.6f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate experiment file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nif not os.path.isfile(exp_file):\n    raise FileNotFoundError(f\"experiment_data.npy not found at {exp_file}\")\n\n# ---------- load ----------\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# ---------- analysis & printing ----------\nfor dataset_name, content in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # ---- training metrics ----\n    train_history = content.get(\"metrics\", {}).get(\"train\", [])\n    if train_history:\n        final_train_loss = train_history[-1].get(\"loss\", None)\n        if final_train_loss is not None:\n            print(f\"final training loss: {final_train_loss:.6f}\")\n\n    # ---- validation metrics ----\n    val_history = content.get(\"metrics\", {}).get(\"val\", [])\n    if val_history:\n        # pick entry with highest HWA\n        best_val = max(val_history, key=lambda x: x.get(\"hwa\", -float(\"inf\")))\n        print(f\"best validation harmonic weighted accuracy: {best_val['hwa']:.6f}\")\n        print(\n            f\"validation shape weighted accuracy at best epoch: {best_val['swa']:.6f}\"\n        )\n        print(\n            f\"validation color weighted accuracy at best epoch: {best_val['cwa']:.6f}\"\n        )\n        print(f\"validation loss at best epoch: {best_val['loss']:.6f}\")\n", ""], "parse_term_out": ["", "", "", "", "['SPR_BENCH', '\\n', 'final training loss: 0.030832', '\\n', 'best validation\nharmonic weighted accuracy: 0.993366', '\\n', 'validation shape weighted accuracy\nat best epoch: 0.993198', '\\n', 'validation color weighted accuracy at best\nepoch: 0.993533', '\\n', 'validation loss at best epoch: 0.036855', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'train shape-weighted accuracy: 0.9802', '\\n', 'train color-\nweighted  accuracy: 0.9802', '\\n', 'train harmonic-weighted accuracy: 0.9802',\n'\\n', 'validation shape-weighted accuracy: 0.9820', '\\n', 'validation color-\nweighted  accuracy: 0.9832', '\\n', 'validation harmonic-weighted accuracy:\n0.9826', '\\n', 'contrastive loss: 4.3689', '\\n', 'train supervised loss:\n0.0725', '\\n', 'validation supervised loss: 0.0659', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "", "", "['SPR_BENCH', '\\n', 'final training loss: 0.030211', '\\n', 'best validation\nharmonic weighted accuracy: 0.991584', '\\n', 'validation shape weighted accuracy\nat best epoch: 0.991222', '\\n', 'validation color weighted accuracy at best\nepoch: 0.991947', '\\n', 'validation loss at best epoch: 0.035984', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'final training loss: 0.026362', '\\n', 'best validation\nharmonic weighted accuracy: 0.993284', '\\n', 'validation shape weighted accuracy\nat best epoch: 0.992792', '\\n', 'validation color weighted accuracy at best\nepoch: 0.993777', '\\n', 'validation loss at best epoch: 0.025005', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'final training loss: 0.028795', '\\n', 'best validation\nharmonic weighted accuracy: 0.992866', '\\n', 'validation shape weighted accuracy\nat best epoch: 0.992443', '\\n', 'validation color weighted accuracy at best\nepoch: 0.993289', '\\n', 'validation loss at best epoch: 0.032675', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
