<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 8], [0, 11], [0, 10], [0, 9]], "layout": [[0.17647058823529413, 0.0], [0.29411764705882354, 0.0], [0.4117647058823529, 0.0], [0.5294117647058824, 0.0], [0.6470588235294118, 0.0], [0.7647058823529411, 0.0], [0.8823529411764706, 0.0], [1.0, 0.0], [0.0, 1.0], [0.11764705882352941, 1.0], [0.23529411764705882, 1.0], [0.35294117647058826, 1.0]], "plan": ["Hyperparam tuning name: num_epochs. We explore the hyper-parameter \u201cnum_epochs\u201d\nby training fresh BiLSTM models for 5, 10, 20 and 30 epochs with an early-\nstopping patience of 3 epochs on harmonic weighted accuracy (HWA).   For every\nsetting we log per-epoch train/validation losses and the three weighted\naccuracies, store final predictions/ground-truth and keep the best epoch\u2019s\nmetrics.   All results are gathered in the experiment_data dictionary under the\nkey 'num_epochs_tuning' and saved to working/experiment_data.npy so they can be\nplotted later.", "Hyperparam tuning name: learning_rate. We loop over a small set of learning-\nrates (5e-4, 1e-3, 2e-3, 3e-3), re-initialising the BiLSTM and Adam optimiser\neach time.   For every rate we train for five epochs, evaluate on the dev split,\ncollect losses and shape/color/harmonic weighted accuracies, and store\neverything in a hierarchical experiment_data dictionary keyed by the learning-\nrate.   After the sweep finishes the whole structure is saved to\nworking/experiment_data.npy so it can be plotted later.", "Hyperparam tuning name: batch_size. We sweep four batch sizes (32 / 64 / 128 /\n256) while keeping every other setting fixed.   For each batch size we rebuild\nthe dataloader, re-initialise the BiLSTM, train for five epochs, evaluate on the\ndev set, and log train/validation losses together with SWA, CWA and HWA.   The\nresults for every run are stored in a hierarchical experiment_data dictionary\nunder the top-level key \"batch_size\", then saved to working/experiment_data.npy\nso that downstream notebooks can analyse the influence of mini-batch size on\nconvergence and generalisation.", "Hyperparam tuning name: dropout_rate. The solution loops over several dropout\nprobabilities (0.0 / 0.1 / 0.3 / 0.5), instantiates a fresh Bi-LSTM model with a\ndropout layer between the mean-pooled sequence representation and the final\nlinear layer, trains each model for five epochs, evaluates on the dev set, and\nstores all losses/metrics/predictions in a structured experiment_data dictionary\nbefore saving it to experiment_data.npy.", "Hyperparam tuning name: embedding_dim. The solution iterates over several\nembedding sizes (32, 64, 128 and 256), trains a fresh Bi-LSTM model for each\nsize, evaluates it after every epoch, and stores all losses/metrics/predictions\nin a hierarchical experiment_data dictionary under the key \"embedding_dim\".\nAfter the sweep finishes, the whole dictionary is saved to\nworking/experiment_data.npy for later plotting or analysis.", "Hyperparam tuning name: hidden_dim. We keep the original Bi-LSTM classifier and\ntraining loop but wrap them in a simple grid-search over the LSTM hidden state\ndimensionality (64, 128, 256, 512).   For each hidden_dim we re-instantiate the\nmodel, optimizer and metric containers, train for five epochs, evaluate on the\ndev set, and store all losses/metrics/predictions inside a nested\nexperiment_data dictionary under the key \"hidden_dim\".   After the sweep\nfinishes the whole experiment_data object is saved as experiment_data.npy in the\nmandated format.", "Hyperparam tuning name: weight_decay. We grid-search six candidate L2\nregularization strengths (weight_decay \u2208 {0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2}).\nFor every value we re-initialise the BiLSTM, train for five epochs, evaluate on\nthe dev split and log per-epoch losses and weighted accuracies.   Results are\nstored under experiment_data['weight_decay']['SPR_BENCH']['runs'][str(wd)] and\nfinally saved to working/experiment_data.npy.", "Hyperparam tuning name: num_lstm_layers. We keep the original pipeline intact\nbut wrap the whole training / evaluation routine in a loop that instantiates a\nfresh BiLSTMClassifier with 1, 2 or 3 stacked bidirectional layers (num_layers).\nFor every setting we store per-epoch train/validation losses and the shape-,\ncolor- and harmonic-weighted accuracies, together with final predictions and\nground-truth, inside a nested experiment_data dictionary keyed by the layer\ncount.   Nothing else in the training regime is modified, ensuring a focused\nablation on model depth; once all runs finish the whole structure is saved to\nworking/experiment_data.npy for later plotting or analysis.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, random, time, json, math\nimport numpy as np, torch\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ----------------- reproducibility -----------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# ----------------- working dir ---------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- experiment container ------------\nexperiment_data = {\n    \"num_epochs_tuning\": {\n        \"SPR_BENCH\": {}  # will be filled with one entry per epoch-setting\n    }\n}\n\n# ----------------- device --------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ----------------- locate SPR_BENCH ----------------\ndef find_spr_bench_path() -> pathlib.Path:\n    cand = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for c in cand:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(\"Found SPR_BENCH at:\", p)\n            return p\n    raise FileNotFoundError(\"SPR_BENCH with train/dev/test csv not found.\")\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ----------------- dataset utils -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    num = sum(w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred))\n    return num / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    num = sum(w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred))\n    return num / sum(w) if sum(w) > 0 else 0.0\n\n\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ----------------- vocab / labels ------------------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\npad_id = vocab[\"<pad>\"]\nnum_labels = len(label2id)\nprint(f\"Vocab={len(vocab)}, num_labels={num_labels}\")\n\n\n# ----------------- torch dataset -------------------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dset, vocab, label2id):\n        self.data = hf_dset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        return {\n            \"input_ids\": torch.tensor(self.encode(ex[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(self.label2id[ex[\"label\"]], dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    seqs = []\n    for i, b in enumerate(batch):\n        l = len(b[\"input_ids\"])\n        input_ids[i, :l] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        seqs.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": seqs}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\n\n# ----------------- model ---------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        out, _ = self.lstm(emb)\n        mask = (x != pad_id).unsqueeze(-1)\n        summed = (out * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        mean = summed / lengths\n        return self.fc(mean)\n\n\n# ----------------- training util -------------------\ndef run_training(max_epochs: int, patience: int = 3):\n    model = BiLSTMClassifier(len(vocab), 64, 128, num_labels, pad_idx=pad_id).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n    train_loader = DataLoader(\n        train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n    )\n    dev_loader = DataLoader(\n        dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n    )\n    logs = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    best_hwa = -1\n    best_state = None\n    epochs_no_improve = 0\n    for epoch in range(1, max_epochs + 1):\n        # ---- train ----\n        model.train()\n        run_loss = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            run_loss += loss.item() * batch[\"labels\"].size(0)\n        train_loss = run_loss / len(train_ds)\n        logs[\"losses\"][\"train\"].append(train_loss)\n        logs[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"loss\": train_loss})\n        # ---- eval ----\n        model.eval()\n        val_loss = 0.0\n        all_pred = []\n        all_true = []\n        all_seq = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                t_batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(t_batch[\"input_ids\"])\n                loss = criterion(logits, t_batch[\"labels\"])\n                val_loss += loss.item() * t_batch[\"labels\"].size(0)\n                preds = logits.argmax(-1).cpu().tolist()\n                truths = t_batch[\"labels\"].cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(truths)\n                all_seq.extend(batch[\"sequences\"])\n        val_loss /= len(dev_ds)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        logs[\"losses\"][\"val\"].append(val_loss)\n        logs[\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n        )\n        print(\n            f\"[{max_epochs}e] Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} HWA={hwa:.4f}\"\n        )\n        # early stopping on HWA\n        if hwa > best_hwa + 1e-5:\n            best_hwa = hwa\n            best_state = model.state_dict()\n            epochs_no_improve = 0\n            logs[\"predictions\"] = all_pred\n            logs[\"ground_truth\"] = all_true\n        else:\n            epochs_no_improve += 1\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n    if best_state is not None:  # load best for reproducibility\n        model.load_state_dict(best_state)\n    return logs\n\n\n# ----------------- hyperparameter tuning -----------\nepoch_grid = [5, 10, 20, 30]\nfor epochs in epoch_grid:\n    print(f\"\\n=== Training for max {epochs} epochs ===\")\n    logs = run_training(epochs, patience=3)\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][str(epochs)] = logs\n\n# ----------------- save ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# hyperparam-tuning: learning-rate sweep for SPR-BENCH\nimport os, pathlib, random, time, json, math\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# -------- working dir --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- device --------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# -------- experiment container --------\nexperiment_data = {\"learning_rate\": {}}  # top-level key follows guideline\n\n\n# -------- locate SPR_BENCH --------\ndef find_spr_bench_path() -> pathlib.Path:\n    candidates = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for c in candidates:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p}\")\n            return p\n    raise FileNotFoundError(\n        \"SPR_BENCH directory with train.csv/dev.csv/test.csv not found. \"\n        \"Set env var SPR_BENCH_PATH or place directory next to this script.\"\n    )\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# -------- dataset utilities --------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    dset = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        dset[split] = _load(f\"{split}.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\n# -------- load dataset --------\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# -------- build vocab / labels --------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\npad_id = vocab[\"<pad>\"]\nprint(f\"Vocab size = {len(vocab)}, num_labels = {num_labels}\")\n\n\n# -------- Torch dataset --------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, vocab, label2id):\n        self.data = hf_dataset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode_seq(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        ids = self.encode_seq(ex[\"sequence\"])\n        label = self.label2id[ex[\"label\"]]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    sequences = []\n    for i, b in enumerate(batch):\n        seq_len = len(b[\"input_ids\"])\n        input_ids[i, :seq_len] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        sequences.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": sequences}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\ntrain_loader = DataLoader(\n    train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n)\ndev_loader = DataLoader(\n    dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n)\n\n\n# -------- model --------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        outputs, _ = self.lstm(emb)\n        mask = (x != pad_id).unsqueeze(-1)\n        summed = (outputs * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        mean = summed / lengths\n        return self.fc(mean)\n\n\n# -------- training loop (sweep over learning-rates) --------\nlr_list = [5e-4, 1e-3, 2e-3, 3e-3]\nepochs = 5\ncriterion = nn.CrossEntropyLoss()\n\nfor lr in lr_list:\n    tag = f\"lr_{lr:.4g}\"\n    print(f\"\\n===== Training with learning-rate {lr} =====\")\n    experiment_data[\"learning_rate\"][tag] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    model = BiLSTMClassifier(len(vocab), 64, 128, num_labels, pad_idx=pad_id).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    for epoch in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * batch[\"labels\"].size(0)\n        train_loss = running_loss / len(train_ds)\n        experiment_data[\"learning_rate\"][tag][\"losses\"][\"train\"].append(train_loss)\n        experiment_data[\"learning_rate\"][tag][\"metrics\"][\"train\"].append(\n            {\"epoch\": epoch, \"loss\": train_loss}\n        )\n\n        # ---- eval ----\n        model.eval()\n        val_loss, all_pred, all_true, all_seq = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                tb = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(tb[\"input_ids\"])\n                loss = criterion(logits, tb[\"labels\"])\n                val_loss += loss.item() * tb[\"labels\"].size(0)\n                preds = logits.argmax(-1).cpu().tolist()\n                truths = tb[\"labels\"].cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(truths)\n                all_seq.extend(batch[\"sequences\"])\n        val_loss /= len(dev_ds)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n        experiment_data[\"learning_rate\"][tag][\"losses\"][\"val\"].append(val_loss)\n        experiment_data[\"learning_rate\"][tag][\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n        )\n        experiment_data[\"learning_rate\"][tag][\"predictions\"] = all_pred\n        experiment_data[\"learning_rate\"][tag][\"ground_truth\"] = all_true\n\n        print(\n            f\"Epoch {epoch}: lr={lr} train_loss={train_loss:.4f} \"\n            f\"| val_loss={val_loss:.4f} | SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n\n# -------- save --------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, time, json, math, warnings\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ---------- mandatory working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- experiment container ----------\nexperiment_data = {\n    \"batch_size\": {  # hyperparameter tuning type\n        # every batch size will create its own entry under \"SPR_BENCH\"\n    }\n}\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- locate SPR_BENCH ----------\ndef find_spr_bench_path() -> pathlib.Path:\n    candidates = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for c in candidates:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p}\")\n            return p\n    raise FileNotFoundError(\n        \"SPR_BENCH directory with train.csv/dev.csv/test.csv not found. \"\n        \"Set env var SPR_BENCH_PATH or place directory next to this script.\"\n    )\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ---------- dataset utilities ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    dset = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        dset[split] = _load(f\"{split}.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------- load dataset ----------\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- build vocab / labels ----------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\npad_id = vocab[\"<pad>\"]\nprint(f\"Vocab size = {len(vocab)}, num_labels = {num_labels}\")\n\n\n# ---------- Torch dataset ----------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, vocab, label2id):\n        self.data = hf_dataset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode_seq(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        ids = self.encode_seq(ex[\"sequence\"])\n        label = self.label2id[ex[\"label\"]]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    sequences = []\n    for i, b in enumerate(batch):\n        seq_len = len(b[\"input_ids\"])\n        input_ids[i, :seq_len] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        sequences.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": sequences}\n\n\n# ---------- Model ----------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        outputs, _ = self.lstm(emb)\n        mask = (x != pad_id).unsqueeze(-1)\n        summed = (outputs * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        mean = summed / lengths\n        return self.fc(mean)\n\n\n# ---------- training routine ----------\ndef run_experiment(train_bs, epochs=5, lr=1e-3):\n    print(f\"\\n--- Training with batch_size={train_bs} ---\")\n    # datasets\n    train_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\n    dev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=train_bs,\n        shuffle=True,\n        collate_fn=collate_fn,\n        num_workers=0,\n    )\n    dev_loader = DataLoader(\n        dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n    )\n\n    model = BiLSTMClassifier(len(vocab), 64, 128, num_labels, pad_idx=pad_id).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    run_log = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * batch[\"labels\"].size(0)\n        train_loss = running_loss / len(train_ds)\n        run_log[\"losses\"][\"train\"].append(train_loss)\n        run_log[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"loss\": train_loss})\n\n        # ---- eval ----\n        model.eval()\n        val_loss, all_pred, all_true, all_seq = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                tensor_batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(tensor_batch[\"input_ids\"])\n                loss = criterion(logits, tensor_batch[\"labels\"])\n                val_loss += loss.item() * tensor_batch[\"labels\"].size(0)\n                preds = logits.argmax(-1).cpu().tolist()\n                truths = tensor_batch[\"labels\"].cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(truths)\n                all_seq.extend(batch[\"sequences\"])\n        val_loss /= len(dev_ds)\n        run_log[\"losses\"][\"val\"].append(val_loss)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        run_log[\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n        )\n        run_log[\"predictions\"] = all_pred\n        run_log[\"ground_truth\"] = all_true\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} \"\n            f\"| SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n    return run_log\n\n\n# ---------- hyperparameter sweep ----------\nbatch_sizes = [32, 64, 128, 256]\nfor bs in batch_sizes:\n    run_log = run_experiment(bs)\n    # Init nested structure\n    experiment_data[\"batch_size\"].setdefault(\"SPR_BENCH\", {})\n    experiment_data[\"batch_size\"][\"SPR_BENCH\"][f\"bs{bs}\"] = run_log\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# -------------------- hyper-param tuning :  DROPOUT --------------------\nimport os, pathlib, random, time, json, math\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ---------- reproducibility ----------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n# ---------- save container ----------\nexperiment_data = {}\n\n\n# ---------- locate SPR_BENCH ----------\ndef find_spr_bench_path() -> pathlib.Path:\n    for p in [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]:\n        if not p:\n            continue\n        p = pathlib.Path(p).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            return p\n    raise FileNotFoundError(\"SPR_BENCH train/dev/test csv not found\")\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ---------- dataset ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- utils ----------\ndef count_shape_variety(sequence):  # how many unique first char tokens\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence):  # how many unique second char tokens\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# ---------- vocab / labels ----------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\npad_id = vocab[\"<pad>\"]\nnum_labels = len(label2id)\nprint(\"Vocab:\", len(vocab), \"Labels:\", num_labels)\n\n\n# ---------- torch dataset ----------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, vocab, label2id):\n        self.data, self.vocab, self.label2id = hf_dataset, vocab, label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode(self, seq):\n        return [self.vocab.get(t, self.vocab[\"<unk>\"]) for t in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        return {\n            \"input_ids\": torch.tensor(self.encode(ex[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(self.label2id[ex[\"label\"]], dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels, sequences = [], []\n    for i, b in enumerate(batch):\n        seq_len = len(b[\"input_ids\"])\n        input_ids[i, :seq_len] = b[\"input_ids\"]\n        labels.append(b[\"label\"])\n        sequences.append(b[\"sequence\"])\n    return {\n        \"input_ids\": input_ids,\n        \"labels\": torch.stack(labels),\n        \"sequences\": sequences,\n    }\n\n\ntrain_ds, dev_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id), SPRTorchDataset(\n    spr[\"dev\"], vocab, label2id\n)\ntrain_loader = DataLoader(\n    train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n)\ndev_loader = DataLoader(\n    dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n)\n\n\n# ---------- model ----------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(\n        self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0, dropout=0.1\n    ):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        out, _ = self.lstm(emb)\n        mask = (x != pad_id).unsqueeze(-1)\n        mean = (out * mask).sum(1) / mask.sum(1).clamp(min=1)\n        mean = self.dropout(mean)\n        return self.fc(mean)\n\n\n# ---------- training routine ----------\ndef run_experiment(drop_rate):\n    tag = f\"dropout_{drop_rate}\"\n    experiment_data[tag] = {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n    model = BiLSTMClassifier(\n        len(vocab), 64, 128, num_labels, pad_idx=pad_id, dropout=drop_rate\n    ).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    epochs = 5\n    for epoch in range(1, epochs + 1):\n        # train\n        model.train()\n        running = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            loss = criterion(model(batch[\"input_ids\"]), batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            running += loss.item() * batch[\"labels\"].size(0)\n        train_loss = running / len(train_ds)\n        experiment_data[tag][\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n        experiment_data[tag][\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n            {\"epoch\": epoch, \"loss\": train_loss}\n        )\n        # eval\n        model.eval()\n        vloss = 0.0\n        preds = []\n        truths = []\n        seqs = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                tensor_batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(tensor_batch[\"input_ids\"])\n                vloss += criterion(\n                    logits, tensor_batch[\"labels\"]\n                ).item() * tensor_batch[\"labels\"].size(0)\n                preds.extend(logits.argmax(-1).cpu().tolist())\n                truths.extend(tensor_batch[\"labels\"].cpu().tolist())\n                seqs.extend(batch[\"sequences\"])\n        vloss /= len(dev_ds)\n        swa = shape_weighted_accuracy(seqs, truths, preds)\n        cwa = color_weighted_accuracy(seqs, truths, preds)\n        hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        experiment_data[tag][\"SPR_BENCH\"][\"losses\"][\"val\"].append(vloss)\n        experiment_data[tag][\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": vloss}\n        )\n        experiment_data[tag][\"SPR_BENCH\"][\"predictions\"] = preds\n        experiment_data[tag][\"SPR_BENCH\"][\"ground_truth\"] = truths\n        print(\n            f\"[{tag}] Epoch {epoch}: train {train_loss:.3f} | val {vloss:.3f} | HWA {hwa:.3f}\"\n        )\n    return\n\n\n# ---------- run for multiple dropout settings ----------\nfor drop in [0.0, 0.1, 0.3, 0.5]:\n    run_experiment(drop)\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, json, math, time\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ------------------- dirs / device -------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# ------------------- experiment container -------------------\nexperiment_data = {\"embedding_dim\": {}}  # will hold results keyed by emb size\n\n\n# ------------------- locate data -------------------\ndef find_spr_bench_path() -> pathlib.Path:\n    cands = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for c in cands:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(\"Found SPR_BENCH at:\", p)\n            return p\n    raise FileNotFoundError(\"SPR_BENCH not found. Set SPR_BENCH_PATH or place folder.\")\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ------------------- helpers -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):  # always use split='train' to load whole file\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef count_shape_variety(seq: str) -> int:\n    return len(set(tok[0] for tok in seq.strip().split() if tok))\n\n\ndef count_color_variety(seq: str) -> int:\n    return len(set(tok[1] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ------------------- datasets -------------------\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in enumerate(label2id)}\nnum_labels = len(label2id)\npad_id = vocab[\"<pad>\"]\nprint(\"Vocab size:\", len(vocab), \"| num_labels:\", num_labels)\n\n\n# ------------------- torch dataset -------------------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf, vocab, label2id):\n        self.data = hf\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        ids = self.encode(ex[\"sequence\"])\n        label = self.label2id[ex[\"label\"]]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    seqs = []\n    for i, b in enumerate(batch):\n        l = len(b[\"input_ids\"])\n        input_ids[i, :l] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        seqs.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": seqs}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\ntrain_loader = DataLoader(\n    train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n)\ndev_loader = DataLoader(\n    dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n)\n\n\n# ------------------- model -------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        outputs, _ = self.lstm(emb)\n        mask = (x != pad_id).unsqueeze(-1)\n        summed = (outputs * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        mean = summed / lengths\n        return self.fc(mean)\n\n\n# ------------------- training routine -------------------\ndef train_one_setting(emb_dim, epochs=3, hidden_dim=128):\n    print(f\"\\n=== Training with embedding_dim={emb_dim} ===\")\n    model = BiLSTMClassifier(\n        len(vocab), emb_dim, hidden_dim, num_labels, pad_idx=pad_id\n    ).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    exp_entry = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for epoch in range(1, epochs + 1):\n        # ----- train -----\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * batch[\"labels\"].size(0)\n        train_loss = running_loss / len(train_ds)\n        exp_entry[\"losses\"][\"train\"].append(train_loss)\n        exp_entry[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"loss\": train_loss})\n\n        # ----- eval -----\n        model.eval()\n        val_loss = 0.0\n        all_pred = []\n        all_true = []\n        all_seq = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                tens = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(tens[\"input_ids\"])\n                loss = criterion(logits, tens[\"labels\"])\n                val_loss += loss.item() * tens[\"labels\"].size(0)\n                preds = logits.argmax(-1).cpu().tolist()\n                truths = tens[\"labels\"].cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(truths)\n                all_seq.extend(batch[\"sequences\"])\n        val_loss /= len(dev_ds)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        exp_entry[\"losses\"][\"val\"].append(val_loss)\n        exp_entry[\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n        )\n        exp_entry[\"predictions\"] = all_pred\n        exp_entry[\"ground_truth\"] = all_true\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} \"\n            f\"| SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n    return exp_entry\n\n\n# ------------------- hyperparameter sweep -------------------\nfor emb_dim in [32, 64, 128, 256]:\n    experiment_data[\"embedding_dim\"][emb_dim] = train_one_setting(emb_dim)\n\n# ------------------- save -------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, time, json, math, sys\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ---------- reproducibility ----------\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# ---------- working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- experiment container ----------\nexperiment_data = {\"hidden_dim\": {}}  # hyper-parameter tuning container\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- locate SPR_BENCH ----------\ndef find_spr_bench_path() -> pathlib.Path:\n    candidates = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for c in candidates:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p}\")\n            return p\n    raise FileNotFoundError(\n        \"SPR_BENCH directory with train.csv/dev.csv/test.csv not found. \"\n        \"Set env var SPR_BENCH_PATH or place directory next to this script.\"\n    )\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ---------- dataset utilities ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    dset = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        dset[split] = _load(f\"{split}.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------- load dataset ----------\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- vocab / labels ----------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\npad_id = vocab[\"<pad>\"]\nnum_labels = len(label2id)\nprint(f\"Vocab size = {len(vocab)}, num_labels = {num_labels}\")\n\n\n# ---------- Torch datasets ----------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, vocab, label2id):\n        self.data = hf_dataset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode_seq(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        ids = self.encode_seq(ex[\"sequence\"])\n        label = self.label2id[ex[\"label\"]]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    sequences = []\n    for i, b in enumerate(batch):\n        seq_len = len(b[\"input_ids\"])\n        input_ids[i, :seq_len] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        sequences.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": sequences}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\ntrain_loader = DataLoader(\n    train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n)\ndev_loader = DataLoader(\n    dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n)\n\n\n# ---------- model ----------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        outputs, _ = self.lstm(emb)\n        mask = (x != pad_id).unsqueeze(-1)\n        summed = (outputs * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        mean = summed / lengths\n        return self.fc(mean)\n\n\n# ---------- hyperparameter sweep ----------\nhidden_dims = [64, 128, 256, 512]\nepochs = 5\n\nfor hdim in hidden_dims:\n    print(f\"\\n======== Training with hidden_dim={hdim} ========\")\n    # container for this run\n    experiment_data[\"hidden_dim\"][hdim] = {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n    # build fresh model/optim\n    model = BiLSTMClassifier(len(vocab), 64, hdim, num_labels, pad_idx=pad_id).to(\n        device\n    )\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    for epoch in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * batch[\"labels\"].size(0)\n        train_loss = running_loss / len(train_ds)\n        experiment_data[\"hidden_dim\"][hdim][\"SPR_BENCH\"][\"losses\"][\"train\"].append(\n            train_loss\n        )\n        experiment_data[\"hidden_dim\"][hdim][\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n            {\"epoch\": epoch, \"loss\": train_loss}\n        )\n        # ---- eval ----\n        model.eval()\n        val_loss, all_pred, all_true, all_seq = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                tensor_batch = {\n                    k: (v.to(device) if torch.is_tensor(v) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(tensor_batch[\"input_ids\"])\n                loss = criterion(logits, tensor_batch[\"labels\"])\n                val_loss += loss.item() * tensor_batch[\"labels\"].size(0)\n                preds = logits.argmax(-1).cpu().tolist()\n                truths = tensor_batch[\"labels\"].cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(truths)\n                all_seq.extend(batch[\"sequences\"])\n        val_loss /= len(dev_ds)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        # record\n        dstore = experiment_data[\"hidden_dim\"][hdim][\"SPR_BENCH\"]\n        dstore[\"losses\"][\"val\"].append(val_loss)\n        dstore[\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n        )\n        if epoch == epochs:  # save preds only from last epoch\n            dstore[\"predictions\"] = all_pred\n            dstore[\"ground_truth\"] = all_true\n        print(\n            f\"hdim={hdim} | Epoch {epoch}: train_loss={train_loss:.4f} \"\n            f\"| val_loss={val_loss:.4f} | SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, time, json, math, gc\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ---------- reproducibility ----------\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\n\n# ---------- mandatory working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- experiment container ----------\nexperiment_data = {\n    \"weight_decay\": {\n        \"SPR_BENCH\": {\"runs\": {}}  # each weight_decay value gets its own dict\n    }\n}\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- locate SPR_BENCH ----------\ndef find_spr_bench_path() -> pathlib.Path:\n    candidates = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for c in candidates:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p}\")\n            return p\n    raise FileNotFoundError(\n        \"SPR_BENCH directory with train.csv/dev.csv/test.csv not found.\"\n    )\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ---------- dataset utilities ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    dset = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        dset[split] = _load(f\"{split}.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\n# ---------- load dataset ----------\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- build vocab / labels ----------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\nnum_labels, pad_id = len(label2id), vocab[\"<pad>\"]\nprint(f\"Vocab size = {len(vocab)}, num_labels = {num_labels}\")\n\n\n# ---------- Torch dataset ----------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, vocab, label2id):\n        self.data, self.vocab, self.label2id = hf_dataset, vocab, label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode_seq(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        return {\n            \"input_ids\": torch.tensor(\n                self.encode_seq(ex[\"sequence\"]), dtype=torch.long\n            ),\n            \"label\": torch.tensor(self.label2id[ex[\"label\"]], dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels, sequences = torch.empty(len(batch), dtype=torch.long), []\n    for i, b in enumerate(batch):\n        input_ids[i, : len(b[\"input_ids\"])] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        sequences.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": sequences}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\ntrain_loader = DataLoader(\n    train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n)\ndev_loader = DataLoader(\n    dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n)\n\n\n# ---------- model definition ----------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        outputs, _ = self.lstm(emb)\n        mask = (x != pad_id).unsqueeze(-1)\n        mean = (outputs * mask).sum(1) / mask.sum(1).clamp(min=1)\n        return self.fc(mean)\n\n\n# ---------- hyperparameter tuning ----------\nweight_decays = [0.0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\nepochs = 5\n\nfor wd in weight_decays:\n    print(f\"\\n===== Training with weight_decay={wd} =====\")\n    run_key = str(wd)\n    experiment_data[\"weight_decay\"][\"SPR_BENCH\"][\"runs\"][run_key] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    model = BiLSTMClassifier(len(vocab), 64, 128, num_labels, pad_idx=pad_id).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=wd)\n\n    for epoch in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * batch[\"labels\"].size(0)\n        train_loss = running_loss / len(train_ds)\n\n        # ---- eval ----\n        model.eval()\n        val_loss, all_pred, all_true, all_seq = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                t_batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(t_batch[\"input_ids\"])\n                loss = criterion(logits, t_batch[\"labels\"])\n                val_loss += loss.item() * t_batch[\"labels\"].size(0)\n                preds = logits.argmax(-1).cpu().tolist()\n                truths = t_batch[\"labels\"].cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(truths)\n                all_seq.extend(batch[\"sequences\"])\n        val_loss /= len(dev_ds)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n        # ---- log ----\n        run_dict = experiment_data[\"weight_decay\"][\"SPR_BENCH\"][\"runs\"][run_key]\n        run_dict[\"losses\"][\"train\"].append(train_loss)\n        run_dict[\"losses\"][\"val\"].append(val_loss)\n        run_dict[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"loss\": train_loss})\n        run_dict[\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n        )\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n\n    # store preds of last epoch\n    run_dict[\"predictions\"] = all_pred\n    run_dict[\"ground_truth\"] = all_true\n\n    # free memory\n    del model, optimizer, criterion\n    torch.cuda.empty_cache()\n    gc.collect()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, random, time, json, math\nimport torch, numpy as np\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ---------- mandatory working dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------- experiment container ----------\nexperiment_data = {\n    \"num_lstm_layers\": {}  # each key = layer count, value = metrics/losses/...\n}\n\n\n# ---------- locate SPR_BENCH ----------\ndef find_spr_bench_path() -> pathlib.Path:\n    candidates = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for c in candidates:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(f\"Found SPR_BENCH at: {p}\")\n            return p\n    raise FileNotFoundError(\"SPR_BENCH with train.csv/dev.csv/test.csv not found.\")\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ---------- dataset utilities ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    return DatasetDict({s: _load(f\"{s}.csv\") for s in [\"train\", \"dev\", \"test\"]})\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# ---------- load dataset ----------\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ---------- build vocab / labels ----------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\nnum_labels = len(label2id)\npad_id = vocab[\"<pad>\"]\nprint(f\"Vocab size = {len(vocab)}, num_labels = {num_labels}\")\n\n\n# ---------- Torch dataset ----------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, vocab, label2id):\n        self.data = hf_dataset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode_seq(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        ids = self.encode_seq(ex[\"sequence\"])\n        label = self.label2id[ex[\"label\"]]\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    sequences = []\n    for i, b in enumerate(batch):\n        l = len(b[\"input_ids\"])\n        input_ids[i, :l] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        sequences.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": sequences}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\ntrain_loader = DataLoader(\n    train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n)\ndev_loader = DataLoader(\n    dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n)\n\n\n# ---------- model ----------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(\n        self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0, num_layers=1\n    ):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(\n            emb_dim,\n            hidden_dim,\n            num_layers=num_layers,\n            bidirectional=True,\n            batch_first=True,\n        )\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        outputs, _ = self.lstm(emb)  # [B,L,2H]\n        mask = (x != pad_id).unsqueeze(-1)\n        summed = (outputs * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        mean = summed / lengths\n        return self.fc(mean)\n\n\n# ---------- hyperparameter tuning ----------\nlayer_options = [1, 2, 3]\nepochs = 5\nfor layers in layer_options:\n    key = f\"layers_{layers}\"\n    experiment_data[\"num_lstm_layers\"][key] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    model = BiLSTMClassifier(\n        len(vocab), 64, 128, num_labels, pad_idx=pad_id, num_layers=layers\n    ).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for epoch in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * batch[\"labels\"].size(0)\n        train_loss = running_loss / len(train_ds)\n\n        experiment_data[\"num_lstm_layers\"][key][\"losses\"][\"train\"].append(train_loss)\n        experiment_data[\"num_lstm_layers\"][key][\"metrics\"][\"train\"].append(\n            {\"epoch\": epoch, \"loss\": train_loss}\n        )\n\n        # ---- eval ----\n        model.eval()\n        val_loss, all_pred, all_true, all_seq = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                tensor_batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(tensor_batch[\"input_ids\"])\n                loss = criterion(logits, tensor_batch[\"labels\"])\n                val_loss += loss.item() * tensor_batch[\"labels\"].size(0)\n                preds = logits.argmax(-1).cpu().tolist()\n                truths = tensor_batch[\"labels\"].cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(truths)\n                all_seq.extend(batch[\"sequences\"])\n        val_loss /= len(dev_ds)\n\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) else 0.0\n\n        experiment_data[\"num_lstm_layers\"][key][\"losses\"][\"val\"].append(val_loss)\n        experiment_data[\"num_lstm_layers\"][key][\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n        )\n        if epoch == epochs:  # save preds from final epoch\n            experiment_data[\"num_lstm_layers\"][key][\"predictions\"] = all_pred\n            experiment_data[\"num_lstm_layers\"][key][\"ground_truth\"] = all_true\n\n        print(\n            f\"[layers={layers}] Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f} | val_loss={val_loss:.4f} \"\n            f\"| SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n\n    # free up CUDA memory before next run\n    del model, optimizer, criterion\n    torch.cuda.empty_cache()\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, json, math\nimport numpy as np, torch\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ----------------- reproducibility -----------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# ----------------- working dir ---------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- experiment container ------------\nexperiment_data = {\n    \"num_epochs_tuning\": {\n        \"SPR_BENCH\": {}  # will be filled with one entry per epoch-setting\n    }\n}\n\n# ----------------- device --------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ----------------- locate SPR_BENCH ----------------\ndef find_spr_bench_path() -> pathlib.Path:\n    cand = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for c in cand:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(\"Found SPR_BENCH at:\", p)\n            return p\n    raise FileNotFoundError(\"SPR_BENCH with train/dev/test csv not found.\")\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ----------------- dataset utils -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    num = sum(w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred))\n    return num / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    num = sum(w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred))\n    return num / sum(w) if sum(w) > 0 else 0.0\n\n\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ----------------- vocab / labels ------------------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\npad_id = vocab[\"<pad>\"]\nnum_labels = len(label2id)\nprint(f\"Vocab={len(vocab)}, num_labels={num_labels}\")\n\n\n# ----------------- torch dataset -------------------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dset, vocab, label2id):\n        self.data = hf_dset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        return {\n            \"input_ids\": torch.tensor(self.encode(ex[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(self.label2id[ex[\"label\"]], dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    seqs = []\n    for i, b in enumerate(batch):\n        l = len(b[\"input_ids\"])\n        input_ids[i, :l] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        seqs.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": seqs}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\n\n# ----------------- model ---------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        out, _ = self.lstm(emb)\n        mask = (x != pad_id).unsqueeze(-1)\n        summed = (out * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        mean = summed / lengths\n        return self.fc(mean)\n\n\n# ----------------- training util -------------------\ndef run_training(max_epochs: int, patience: int = 3):\n    model = BiLSTMClassifier(len(vocab), 64, 128, num_labels, pad_idx=pad_id).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n    train_loader = DataLoader(\n        train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n    )\n    dev_loader = DataLoader(\n        dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n    )\n    logs = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    best_hwa = -1\n    best_state = None\n    epochs_no_improve = 0\n    for epoch in range(1, max_epochs + 1):\n        # ---- train ----\n        model.train()\n        run_loss = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            run_loss += loss.item() * batch[\"labels\"].size(0)\n        train_loss = run_loss / len(train_ds)\n        logs[\"losses\"][\"train\"].append(train_loss)\n        logs[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"loss\": train_loss})\n        # ---- eval ----\n        model.eval()\n        val_loss = 0.0\n        all_pred = []\n        all_true = []\n        all_seq = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                t_batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(t_batch[\"input_ids\"])\n                loss = criterion(logits, t_batch[\"labels\"])\n                val_loss += loss.item() * t_batch[\"labels\"].size(0)\n                preds = logits.argmax(-1).cpu().tolist()\n                truths = t_batch[\"labels\"].cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(truths)\n                all_seq.extend(batch[\"sequences\"])\n        val_loss /= len(dev_ds)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        logs[\"losses\"][\"val\"].append(val_loss)\n        logs[\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n        )\n        print(\n            f\"[{max_epochs}e] Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} HWA={hwa:.4f}\"\n        )\n        # early stopping on HWA\n        if hwa > best_hwa + 1e-5:\n            best_hwa = hwa\n            best_state = model.state_dict()\n            epochs_no_improve = 0\n            logs[\"predictions\"] = all_pred\n            logs[\"ground_truth\"] = all_true\n        else:\n            epochs_no_improve += 1\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n    if best_state is not None:  # load best for reproducibility\n        model.load_state_dict(best_state)\n    return logs\n\n\n# ----------------- hyperparameter tuning -----------\nepoch_grid = [5, 10, 20, 30]\nfor epochs in epoch_grid:\n    print(f\"\\n=== Training for max {epochs} epochs ===\")\n    logs = run_training(epochs, patience=3)\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][str(epochs)] = logs\n\n# ----------------- save ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, json, math\nimport numpy as np, torch\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ----------------- reproducibility -----------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# ----------------- working dir ---------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- experiment container ------------\nexperiment_data = {\n    \"num_epochs_tuning\": {\n        \"SPR_BENCH\": {}  # will be filled with one entry per epoch-setting\n    }\n}\n\n# ----------------- device --------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ----------------- locate SPR_BENCH ----------------\ndef find_spr_bench_path() -> pathlib.Path:\n    cand = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for c in cand:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(\"Found SPR_BENCH at:\", p)\n            return p\n    raise FileNotFoundError(\"SPR_BENCH with train/dev/test csv not found.\")\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ----------------- dataset utils -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    num = sum(w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred))\n    return num / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    num = sum(w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred))\n    return num / sum(w) if sum(w) > 0 else 0.0\n\n\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ----------------- vocab / labels ------------------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\npad_id = vocab[\"<pad>\"]\nnum_labels = len(label2id)\nprint(f\"Vocab={len(vocab)}, num_labels={num_labels}\")\n\n\n# ----------------- torch dataset -------------------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dset, vocab, label2id):\n        self.data = hf_dset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        return {\n            \"input_ids\": torch.tensor(self.encode(ex[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(self.label2id[ex[\"label\"]], dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    seqs = []\n    for i, b in enumerate(batch):\n        l = len(b[\"input_ids\"])\n        input_ids[i, :l] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        seqs.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": seqs}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\n\n# ----------------- model ---------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        out, _ = self.lstm(emb)\n        mask = (x != pad_id).unsqueeze(-1)\n        summed = (out * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        mean = summed / lengths\n        return self.fc(mean)\n\n\n# ----------------- training util -------------------\ndef run_training(max_epochs: int, patience: int = 3):\n    model = BiLSTMClassifier(len(vocab), 64, 128, num_labels, pad_idx=pad_id).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n    train_loader = DataLoader(\n        train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n    )\n    dev_loader = DataLoader(\n        dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n    )\n    logs = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    best_hwa = -1\n    best_state = None\n    epochs_no_improve = 0\n    for epoch in range(1, max_epochs + 1):\n        # ---- train ----\n        model.train()\n        run_loss = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            run_loss += loss.item() * batch[\"labels\"].size(0)\n        train_loss = run_loss / len(train_ds)\n        logs[\"losses\"][\"train\"].append(train_loss)\n        logs[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"loss\": train_loss})\n        # ---- eval ----\n        model.eval()\n        val_loss = 0.0\n        all_pred = []\n        all_true = []\n        all_seq = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                t_batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(t_batch[\"input_ids\"])\n                loss = criterion(logits, t_batch[\"labels\"])\n                val_loss += loss.item() * t_batch[\"labels\"].size(0)\n                preds = logits.argmax(-1).cpu().tolist()\n                truths = t_batch[\"labels\"].cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(truths)\n                all_seq.extend(batch[\"sequences\"])\n        val_loss /= len(dev_ds)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        logs[\"losses\"][\"val\"].append(val_loss)\n        logs[\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n        )\n        print(\n            f\"[{max_epochs}e] Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} HWA={hwa:.4f}\"\n        )\n        # early stopping on HWA\n        if hwa > best_hwa + 1e-5:\n            best_hwa = hwa\n            best_state = model.state_dict()\n            epochs_no_improve = 0\n            logs[\"predictions\"] = all_pred\n            logs[\"ground_truth\"] = all_true\n        else:\n            epochs_no_improve += 1\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n    if best_state is not None:  # load best for reproducibility\n        model.load_state_dict(best_state)\n    return logs\n\n\n# ----------------- hyperparameter tuning -----------\nepoch_grid = [5, 10, 20, 30]\nfor epochs in epoch_grid:\n    print(f\"\\n=== Training for max {epochs} epochs ===\")\n    logs = run_training(epochs, patience=3)\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][str(epochs)] = logs\n\n# ----------------- save ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, time, json, math\nimport numpy as np, torch\nfrom datasets import load_dataset, DatasetDict\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n# ----------------- reproducibility -----------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# ----------------- working dir ---------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------- experiment container ------------\nexperiment_data = {\n    \"num_epochs_tuning\": {\n        \"SPR_BENCH\": {}  # will be filled with one entry per epoch-setting\n    }\n}\n\n# ----------------- device --------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# ----------------- locate SPR_BENCH ----------------\ndef find_spr_bench_path() -> pathlib.Path:\n    cand = [\n        os.environ.get(\"SPR_BENCH_PATH\", \"\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for c in cand:\n        if not c:\n            continue\n        p = pathlib.Path(c).expanduser().resolve()\n        if (p / \"train.csv\").exists() and (p / \"dev.csv\").exists():\n            print(\"Found SPR_BENCH at:\", p)\n            return p\n    raise FileNotFoundError(\"SPR_BENCH with train/dev/test csv not found.\")\n\n\nDATA_PATH = find_spr_bench_path()\n\n\n# ----------------- dataset utils -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=str(pathlib.Path(working_dir) / \".cache_dsets\"),\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    num = sum(w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred))\n    return num / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    num = sum(w_ if t == p else 0 for w_, t, p in zip(w, y_true, y_pred))\n    return num / sum(w) if sum(w) > 0 else 0.0\n\n\nspr = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr.items()})\n\n\n# ----------------- vocab / labels ------------------\ndef build_vocab(dataset):\n    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n    for ex in dataset:\n        for tok in ex[\"sequence\"].split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\ndef build_label_map(dataset):\n    labels = sorted({ex[\"label\"] for ex in dataset})\n    return {lab: i for i, lab in enumerate(labels)}\n\n\nvocab = build_vocab(spr[\"train\"])\nlabel2id = build_label_map(spr[\"train\"])\nid2label = {i: l for l, i in label2id.items()}\npad_id = vocab[\"<pad>\"]\nnum_labels = len(label2id)\nprint(f\"Vocab={len(vocab)}, num_labels={num_labels}\")\n\n\n# ----------------- torch dataset -------------------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dset, vocab, label2id):\n        self.data = hf_dset\n        self.vocab = vocab\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.data)\n\n    def encode(self, seq):\n        return [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in seq.split()]\n\n    def __getitem__(self, idx):\n        ex = self.data[idx]\n        return {\n            \"input_ids\": torch.tensor(self.encode(ex[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(self.label2id[ex[\"label\"]], dtype=torch.long),\n            \"sequence\": ex[\"sequence\"],\n        }\n\n\ndef collate_fn(batch):\n    max_len = max(len(b[\"input_ids\"]) for b in batch)\n    input_ids = torch.full((len(batch), max_len), pad_id, dtype=torch.long)\n    labels = torch.empty(len(batch), dtype=torch.long)\n    seqs = []\n    for i, b in enumerate(batch):\n        l = len(b[\"input_ids\"])\n        input_ids[i, :l] = b[\"input_ids\"]\n        labels[i] = b[\"label\"]\n        seqs.append(b[\"sequence\"])\n    return {\"input_ids\": input_ids, \"labels\": labels, \"sequences\": seqs}\n\n\ntrain_ds = SPRTorchDataset(spr[\"train\"], vocab, label2id)\ndev_ds = SPRTorchDataset(spr[\"dev\"], vocab, label2id)\n\n\n# ----------------- model ---------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb_dim, hidden_dim, num_labels, pad_idx=0):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        out, _ = self.lstm(emb)\n        mask = (x != pad_id).unsqueeze(-1)\n        summed = (out * mask).sum(1)\n        lengths = mask.sum(1).clamp(min=1)\n        mean = summed / lengths\n        return self.fc(mean)\n\n\n# ----------------- training util -------------------\ndef run_training(max_epochs: int, patience: int = 3):\n    model = BiLSTMClassifier(len(vocab), 64, 128, num_labels, pad_idx=pad_id).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n    train_loader = DataLoader(\n        train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn, num_workers=0\n    )\n    dev_loader = DataLoader(\n        dev_ds, batch_size=256, shuffle=False, collate_fn=collate_fn, num_workers=0\n    )\n    logs = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    best_hwa = -1\n    best_state = None\n    epochs_no_improve = 0\n    for epoch in range(1, max_epochs + 1):\n        # ---- train ----\n        model.train()\n        run_loss = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            loss.backward()\n            optimizer.step()\n            run_loss += loss.item() * batch[\"labels\"].size(0)\n        train_loss = run_loss / len(train_ds)\n        logs[\"losses\"][\"train\"].append(train_loss)\n        logs[\"metrics\"][\"train\"].append({\"epoch\": epoch, \"loss\": train_loss})\n        # ---- eval ----\n        model.eval()\n        val_loss = 0.0\n        all_pred = []\n        all_true = []\n        all_seq = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                t_batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(t_batch[\"input_ids\"])\n                loss = criterion(logits, t_batch[\"labels\"])\n                val_loss += loss.item() * t_batch[\"labels\"].size(0)\n                preds = logits.argmax(-1).cpu().tolist()\n                truths = t_batch[\"labels\"].cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(truths)\n                all_seq.extend(batch[\"sequences\"])\n        val_loss /= len(dev_ds)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        hwa = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        logs[\"losses\"][\"val\"].append(val_loss)\n        logs[\"metrics\"][\"val\"].append(\n            {\"epoch\": epoch, \"swa\": swa, \"cwa\": cwa, \"hwa\": hwa, \"loss\": val_loss}\n        )\n        print(\n            f\"[{max_epochs}e] Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} HWA={hwa:.4f}\"\n        )\n        # early stopping on HWA\n        if hwa > best_hwa + 1e-5:\n            best_hwa = hwa\n            best_state = model.state_dict()\n            epochs_no_improve = 0\n            logs[\"predictions\"] = all_pred\n            logs[\"ground_truth\"] = all_true\n        else:\n            epochs_no_improve += 1\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n    if best_state is not None:  # load best for reproducibility\n        model.load_state_dict(best_state)\n    return logs\n\n\n# ----------------- hyperparameter tuning -----------\nepoch_grid = [5, 10, 20, 30]\nfor epochs in epoch_grid:\n    print(f\"\\n=== Training for max {epochs} epochs ===\")\n    logs = run_training(epochs, patience=3)\n    experiment_data[\"num_epochs_tuning\"][\"SPR_BENCH\"][str(epochs)] = logs\n\n# ----------------- save ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# plotting aggregation code"], "term_out": ["['Using device:', ' ', 'cuda', '\\n', 'Found SPR_BENCH at:', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0\nexamples [00:00, ? examples/s]', '', '\\rGenerating train split: 20000 examples\n[00:00, 295552.52 examples/s]', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 5000 examples [00:00,\n574829.92 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 466194.36\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n',\n'Vocab=18, num_labels=2', '\\n', '\\n=== Training for max 5 epochs ===', '\\n',\n'[5e] Epoch 1: train_loss=0.2358 val_loss=0.1439 HWA=0.9564', '\\n', '[5e] Epoch\n2: train_loss=0.1108 val_loss=0.0915 HWA=0.9752', '\\n', '[5e] Epoch 3:\ntrain_loss=0.0710 val_loss=0.0565 HWA=0.9849', '\\n', '[5e] Epoch 4:\ntrain_loss=0.0461 val_loss=0.0398 HWA=0.9898', '\\n', '[5e] Epoch 5:\ntrain_loss=0.0338 val_loss=0.0333 HWA=0.9922', '\\n', '\\n=== Training for max 10\nepochs ===', '\\n', '[10e] Epoch 1: train_loss=0.2374 val_loss=0.1471\nHWA=0.9552', '\\n', '[10e] Epoch 2: train_loss=0.1137 val_loss=0.0910\nHWA=0.9738', '\\n', '[10e] Epoch 3: train_loss=0.0724 val_loss=0.0610\nHWA=0.9864', '\\n', '[10e] Epoch 4: train_loss=0.0434 val_loss=0.0415\nHWA=0.9910', '\\n', '[10e] Epoch 5: train_loss=0.0295 val_loss=0.0300\nHWA=0.9918', '\\n', '[10e] Epoch 6: train_loss=0.0219 val_loss=0.0261\nHWA=0.9955', '\\n', '[10e] Epoch 7: train_loss=0.0161 val_loss=0.0197\nHWA=0.9956', '\\n', '[10e] Epoch 8: train_loss=0.0110 val_loss=0.0188\nHWA=0.9948', '\\n', '[10e] Epoch 9: train_loss=0.0074 val_loss=0.0163\nHWA=0.9950', '\\n', '[10e] Epoch 10: train_loss=0.0045 val_loss=0.0141\nHWA=0.9963', '\\n', '\\n=== Training for max 20 epochs ===', '\\n', '[20e] Epoch 1:\ntrain_loss=0.2424 val_loss=0.1360 HWA=0.9538', '\\n', '[20e] Epoch 2:\ntrain_loss=0.0998 val_loss=0.0866 HWA=0.9796', '\\n', '[20e] Epoch 3:\ntrain_loss=0.0715 val_loss=0.0636 HWA=0.9813', '\\n', '[20e] Epoch 4:\ntrain_loss=0.0497 val_loss=0.0385 HWA=0.9903', '\\n', '[20e] Epoch 5:\ntrain_loss=0.0331 val_loss=0.0325 HWA=0.9914', '\\n', '[20e] Epoch 6:\ntrain_loss=0.0239 val_loss=0.0239 HWA=0.9952', '\\n', '[20e] Epoch 7:\ntrain_loss=0.0176 val_loss=0.0216 HWA=0.9952', '\\n', '[20e] Epoch 8:\ntrain_loss=0.0131 val_loss=0.0178 HWA=0.9947', '\\n', '[20e] Epoch 9:\ntrain_loss=0.0091 val_loss=0.0205 HWA=0.9931', '\\n', '[20e] Epoch 10:\ntrain_loss=0.0064 val_loss=0.0144 HWA=0.9960', '\\n', '[20e] Epoch 11:\ntrain_loss=0.0042 val_loss=0.0133 HWA=0.9958', '\\n', '[20e] Epoch 12:\ntrain_loss=0.0027 val_loss=0.0135 HWA=0.9961', '\\n', '[20e] Epoch 13:\ntrain_loss=0.0018 val_loss=0.0132 HWA=0.9955', '\\n', '[20e] Epoch 14:\ntrain_loss=0.0014 val_loss=0.0147 HWA=0.9953', '\\n', '[20e] Epoch 15:\ntrain_loss=0.0011 val_loss=0.0129 HWA=0.9962', '\\n', '[20e] Epoch 16:\ntrain_loss=0.0008 val_loss=0.0129 HWA=0.9961', '\\n', '[20e] Epoch 17:\ntrain_loss=0.0007 val_loss=0.0121 HWA=0.9963', '\\n', '[20e] Epoch 18:\ntrain_loss=0.0006 val_loss=0.0137 HWA=0.9959', '\\n', '[20e] Epoch 19:\ntrain_loss=0.0005 val_loss=0.0126 HWA=0.9963', '\\n', '[20e] Epoch 20:\ntrain_loss=0.0004 val_loss=0.0127 HWA=0.9961', '\\n', 'Early stopping at epoch\n20', '\\n', '\\n=== Training for max 30 epochs ===', '\\n', '[30e] Epoch 1:\ntrain_loss=0.2475 val_loss=0.1552 HWA=0.9570', '\\n', '[30e] Epoch 2:\ntrain_loss=0.1274 val_loss=0.0952 HWA=0.9681', '\\n', '[30e] Epoch 3:\ntrain_loss=0.0678 val_loss=0.0539 HWA=0.9885', '\\n', '[30e] Epoch 4:\ntrain_loss=0.0428 val_loss=0.0367 HWA=0.9924', '\\n', '[30e] Epoch 5:\ntrain_loss=0.0294 val_loss=0.0305 HWA=0.9920', '\\n', '[30e] Epoch 6:\ntrain_loss=0.0237 val_loss=0.0256 HWA=0.9942', '\\n', '[30e] Epoch 7:\ntrain_loss=0.0146 val_loss=0.0196 HWA=0.9946', '\\n', '[30e] Epoch 8:\ntrain_loss=0.0099 val_loss=0.0163 HWA=0.9959', '\\n', '[30e] Epoch 9:\ntrain_loss=0.0060 val_loss=0.0135 HWA=0.9970', '\\n', '[30e] Epoch 10:\ntrain_loss=0.0042 val_loss=0.0148 HWA=0.9965', '\\n', '[30e] Epoch 11:\ntrain_loss=0.0031 val_loss=0.0129 HWA=0.9955', '\\n', '[30e] Epoch 12:\ntrain_loss=0.0020 val_loss=0.0140 HWA=0.9959', '\\n', 'Early stopping at epoch\n12', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n10/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 412273.33\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 461704.02\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 550079.87\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize = 18, num_labels = 2', '\\n', '\\n===== Training with learning-rate 0.0005\n=====', '\\n', 'Epoch 1: lr=0.0005 train_loss=0.3042 | val_loss=0.1773 |\nSWA=0.9411 CWA=0.9382 HWA=0.9397', '\\n', 'Epoch 2: lr=0.0005 train_loss=0.1484 |\nval_loss=0.1218 | SWA=0.9623 CWA=0.9610 HWA=0.9616', '\\n', 'Epoch 3: lr=0.0005\ntrain_loss=0.1042 | val_loss=0.0892 | SWA=0.9796 CWA=0.9799 HWA=0.9797', '\\n',\n'Epoch 4: lr=0.0005 train_loss=0.0790 | val_loss=0.0775 | SWA=0.9827 CWA=0.9833\nHWA=0.9830', '\\n', 'Epoch 5: lr=0.0005 train_loss=0.0633 | val_loss=0.0559 |\nSWA=0.9835 CWA=0.9842 HWA=0.9838', '\\n', '\\n===== Training with learning-rate\n0.001 =====', '\\n', 'Epoch 1: lr=0.001 train_loss=0.2444 | val_loss=0.1264 |\nSWA=0.9603 CWA=0.9597 HWA=0.9600', '\\n', 'Epoch 2: lr=0.001 train_loss=0.0937 |\nval_loss=0.0685 | SWA=0.9824 CWA=0.9832 HWA=0.9828', '\\n', 'Epoch 3: lr=0.001\ntrain_loss=0.0544 | val_loss=0.0449 | SWA=0.9894 CWA=0.9899 HWA=0.9896', '\\n',\n'Epoch 4: lr=0.001 train_loss=0.0369 | val_loss=0.0320 | SWA=0.9921 CWA=0.9929\nHWA=0.9925', '\\n', 'Epoch 5: lr=0.001 train_loss=0.0269 | val_loss=0.0269 |\nSWA=0.9942 CWA=0.9948 HWA=0.9945', '\\n', '\\n===== Training with learning-rate\n0.002 =====', '\\n', 'Epoch 1: lr=0.002 train_loss=0.2081 | val_loss=0.1408 |\nSWA=0.9633 CWA=0.9610 HWA=0.9621', '\\n', 'Epoch 2: lr=0.002 train_loss=0.0919 |\nval_loss=0.0532 | SWA=0.9860 CWA=0.9868 HWA=0.9864', '\\n', 'Epoch 3: lr=0.002\ntrain_loss=0.0388 | val_loss=0.0301 | SWA=0.9909 CWA=0.9916 HWA=0.9913', '\\n',\n'Epoch 4: lr=0.002 train_loss=0.0211 | val_loss=0.0213 | SWA=0.9944 CWA=0.9951\nHWA=0.9948', '\\n', 'Epoch 5: lr=0.002 train_loss=0.0120 | val_loss=0.0187 |\nSWA=0.9953 CWA=0.9955 HWA=0.9954', '\\n', '\\n===== Training with learning-rate\n0.003 =====', '\\n', 'Epoch 1: lr=0.003 train_loss=0.1832 | val_loss=0.0844 |\nSWA=0.9777 CWA=0.9780 HWA=0.9779', '\\n', 'Epoch 2: lr=0.003 train_loss=0.0568 |\nval_loss=0.0350 | SWA=0.9903 CWA=0.9909 HWA=0.9906', '\\n', 'Epoch 3: lr=0.003\ntrain_loss=0.0247 | val_loss=0.0196 | SWA=0.9937 CWA=0.9945 HWA=0.9941', '\\n',\n'Epoch 4: lr=0.003 train_loss=0.0122 | val_loss=0.0118 | SWA=0.9958 CWA=0.9960\nHWA=0.9959', '\\n', 'Epoch 5: lr=0.003 train_loss=0.0046 | val_loss=0.0075 |\nSWA=0.9976 CWA=0.9977 HWA=0.9976', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n11/working/experiment_data.npy', '\\n', 'Execution time: 35 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 478703.46\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 561065.87\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 717932.29\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n', 'Vocab\nsize = 18, num_labels = 2', '\\n', '\\n--- Training with batch_size=32 ---', '\\n',\n'Epoch 1: train_loss=0.1591 | val_loss=0.0846 | SWA=0.9710 CWA=0.9713\nHWA=0.9712', '\\n', 'Epoch 2: train_loss=0.0531 | val_loss=0.0351 | SWA=0.9906\nCWA=0.9910 HWA=0.9908', '\\n', 'Epoch 3: train_loss=0.0270 | val_loss=0.0202 |\nSWA=0.9944 CWA=0.9951 HWA=0.9947', '\\n', 'Epoch 4: train_loss=0.0128 |\nval_loss=0.0133 | SWA=0.9963 CWA=0.9968 HWA=0.9966', '\\n', 'Epoch 5:\ntrain_loss=0.0067 | val_loss=0.0101 | SWA=0.9959 CWA=0.9963 HWA=0.9961', '\\n',\n'\\n--- Training with batch_size=64 ---', '\\n', 'Epoch 1: train_loss=0.1913 |\nval_loss=0.0939 | SWA=0.9716 CWA=0.9715 HWA=0.9715', '\\n', 'Epoch 2:\ntrain_loss=0.0665 | val_loss=0.0562 | SWA=0.9865 CWA=0.9874 HWA=0.9869', '\\n',\n'Epoch 3: train_loss=0.0362 | val_loss=0.0374 | SWA=0.9934 CWA=0.9940\nHWA=0.9937', '\\n', 'Epoch 4: train_loss=0.0246 | val_loss=0.0219 | SWA=0.9946\nCWA=0.9952 HWA=0.9949', '\\n', 'Epoch 5: train_loss=0.0161 | val_loss=0.0181 |\nSWA=0.9948 CWA=0.9954 HWA=0.9951', '\\n', '\\n--- Training with batch_size=128\n---', '\\n', 'Epoch 1: train_loss=0.2435 | val_loss=0.1624 | SWA=0.9530\nCWA=0.9506 HWA=0.9518', '\\n', 'Epoch 2: train_loss=0.1253 | val_loss=0.0941 |\nSWA=0.9720 CWA=0.9716 HWA=0.9718', '\\n', 'Epoch 3: train_loss=0.0743 |\nval_loss=0.0604 | SWA=0.9805 CWA=0.9807 HWA=0.9806', '\\n', 'Epoch 4:\ntrain_loss=0.0425 | val_loss=0.0378 | SWA=0.9897 CWA=0.9907 HWA=0.9902', '\\n',\n'Epoch 5: train_loss=0.0288 | val_loss=0.0284 | SWA=0.9941 CWA=0.9948\nHWA=0.9944', '\\n', '\\n--- Training with batch_size=256 ---', '\\n', 'Epoch 1:\ntrain_loss=0.3138 | val_loss=0.1771 | SWA=0.9442 CWA=0.9414 HWA=0.9428', '\\n',\n'Epoch 2: train_loss=0.1490 | val_loss=0.1343 | SWA=0.9577 CWA=0.9561\nHWA=0.9569', '\\n', 'Epoch 3: train_loss=0.1050 | val_loss=0.0890 | SWA=0.9738\nCWA=0.9743 HWA=0.9740', '\\n', 'Epoch 4: train_loss=0.0755 | val_loss=0.0655 |\nSWA=0.9824 CWA=0.9834 HWA=0.9829', '\\n', 'Epoch 5: train_loss=0.0577 |\nval_loss=0.0472 | SWA=0.9878 CWA=0.9880 HWA=0.9879', '\\n', 'Saved experiment\ndata to', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n12/working/experiment_data.npy', '\\n', 'Execution time: 39 seconds seconds (time\nlimit is 30 minutes).']", "['Device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 377543.80\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 534755.85\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 545707.00\nexamples/s]', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\", '\\n',\n'Vocab:', ' ', '18', ' ', 'Labels:', ' ', '2', '\\n', '[dropout_0.0] Epoch 1:\ntrain 0.236 | val 0.144 | HWA 0.956', '\\n', '[dropout_0.0] Epoch 2: train 0.111\n| val 0.092 | HWA 0.975', '\\n', '[dropout_0.0] Epoch 3: train 0.071 | val 0.056\n| HWA 0.985', '\\n', '[dropout_0.0] Epoch 4: train 0.046 | val 0.040 | HWA\n0.990', '\\n', '[dropout_0.0] Epoch 5: train 0.034 | val 0.033 | HWA 0.992',\n'\\n', '[dropout_0.1] Epoch 1: train 0.240 | val 0.147 | HWA 0.955', '\\n',\n'[dropout_0.1] Epoch 2: train 0.116 | val 0.090 | HWA 0.974', '\\n',\n'[dropout_0.1] Epoch 3: train 0.075 | val 0.061 | HWA 0.986', '\\n',\n'[dropout_0.1] Epoch 4: train 0.046 | val 0.042 | HWA 0.991', '\\n',\n'[dropout_0.1] Epoch 5: train 0.031 | val 0.032 | HWA 0.991', '\\n',\n'[dropout_0.3] Epoch 1: train 0.240 | val 0.149 | HWA 0.952', '\\n',\n'[dropout_0.3] Epoch 2: train 0.109 | val 0.090 | HWA 0.972', '\\n',\n'[dropout_0.3] Epoch 3: train 0.074 | val 0.063 | HWA 0.984', '\\n',\n'[dropout_0.3] Epoch 4: train 0.050 | val 0.041 | HWA 0.988', '\\n',\n'[dropout_0.3] Epoch 5: train 0.036 | val 0.033 | HWA 0.995', '\\n',\n'[dropout_0.5] Epoch 1: train 0.253 | val 0.152 | HWA 0.953', '\\n',\n'[dropout_0.5] Epoch 2: train 0.116 | val 0.078 | HWA 0.978', '\\n',\n'[dropout_0.5] Epoch 3: train 0.070 | val 0.056 | HWA 0.987', '\\n',\n'[dropout_0.5] Epoch 4: train 0.050 | val 0.042 | HWA 0.990', '\\n',\n'[dropout_0.5] Epoch 5: train 0.041 | val 0.034 | HWA 0.993', '\\n', 'Saved to',\n' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n13/working/experiment_data.npy', '\\n', 'Execution time: 35 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Found SPR_BENCH at:', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', \"{'train': 20000, 'dev':\n5000, 'test': 10000}\", '\\n', 'Vocab size:', ' ', '18', ' ', '| num_labels:', '\n', '2', '\\n', '\\n=== Training with embedding_dim=32 ===', '\\n', 'Epoch 1:\ntrain_loss=0.2648 | val_loss=0.1627 | SWA=0.9458 CWA=0.9432 HWA=0.9445', '\\n',\n'Epoch 2: train_loss=0.1326 | val_loss=0.1011 | SWA=0.9722 CWA=0.9719\nHWA=0.9720', '\\n', 'Epoch 3: train_loss=0.0921 | val_loss=0.0752 | SWA=0.9812\nCWA=0.9815 HWA=0.9813', '\\n', '\\n=== Training with embedding_dim=64 ===', '\\n',\n'Epoch 1: train_loss=0.2418 | val_loss=0.1307 | SWA=0.9604 CWA=0.9584\nHWA=0.9594', '\\n', 'Epoch 2: train_loss=0.0955 | val_loss=0.0719 | SWA=0.9793\nCWA=0.9792 HWA=0.9793', '\\n', 'Epoch 3: train_loss=0.0581 | val_loss=0.0460 |\nSWA=0.9903 CWA=0.9907 HWA=0.9905', '\\n', '\\n=== Training with embedding_dim=128\n===', '\\n', 'Epoch 1: train_loss=0.2203 | val_loss=0.1195 | SWA=0.9659\nCWA=0.9647 HWA=0.9653', '\\n', 'Epoch 2: train_loss=0.0882 | val_loss=0.0683 |\nSWA=0.9820 CWA=0.9828 HWA=0.9824', '\\n', 'Epoch 3: train_loss=0.0527 |\nval_loss=0.0417 | SWA=0.9862 CWA=0.9871 HWA=0.9867', '\\n', '\\n=== Training with\nembedding_dim=256 ===', '\\n', 'Epoch 1: train_loss=0.2086 | val_loss=0.1047 |\nSWA=0.9651 CWA=0.9640 HWA=0.9645', '\\n', 'Epoch 2: train_loss=0.0689 |\nval_loss=0.0484 | SWA=0.9856 CWA=0.9865 HWA=0.9860', '\\n', 'Epoch 3:\ntrain_loss=0.0362 | val_loss=0.0311 | SWA=0.9905 CWA=0.9913 HWA=0.9909', '\\n',\n'\\nSaved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n11/working/experiment_data.npy', '\\n', 'Execution time: 23 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Vocab size = 18, num_labels = 2', '\\n', '\\n======== Training with\nhidden_dim=64 ========', '\\n', 'hdim=64 | Epoch 1: train_loss=0.2777 |\nval_loss=0.1540 | SWA=0.9508 CWA=0.9492 HWA=0.9500', '\\n', 'hdim=64 | Epoch 2:\ntrain_loss=0.1279 | val_loss=0.1024 | SWA=0.9687 CWA=0.9686 HWA=0.9687', '\\n',\n'hdim=64 | Epoch 3: train_loss=0.0828 | val_loss=0.0673 | SWA=0.9824 CWA=0.9829\nHWA=0.9827', '\\n', 'hdim=64 | Epoch 4: train_loss=0.0564 | val_loss=0.0555 |\nSWA=0.9881 CWA=0.9885 HWA=0.9883', '\\n', 'hdim=64 | Epoch 5: train_loss=0.0433 |\nval_loss=0.0431 | SWA=0.9911 CWA=0.9918 HWA=0.9914', '\\n', '\\n======== Training\nwith hidden_dim=128 ========', '\\n', 'hdim=128 | Epoch 1: train_loss=0.2379 |\nval_loss=0.1477 | SWA=0.9553 CWA=0.9546 HWA=0.9550', '\\n', 'hdim=128 | Epoch 2:\ntrain_loss=0.1070 | val_loss=0.0828 | SWA=0.9806 CWA=0.9812 HWA=0.9809', '\\n',\n'hdim=128 | Epoch 3: train_loss=0.0679 | val_loss=0.0532 | SWA=0.9838 CWA=0.9847\nHWA=0.9843', '\\n', 'hdim=128 | Epoch 4: train_loss=0.0435 | val_loss=0.0382 |\nSWA=0.9902 CWA=0.9907 HWA=0.9904', '\\n', 'hdim=128 | Epoch 5: train_loss=0.0319\n| val_loss=0.0286 | SWA=0.9938 CWA=0.9944 HWA=0.9941', '\\n', '\\n========\nTraining with hidden_dim=256 ========', '\\n', 'hdim=256 | Epoch 1:\ntrain_loss=0.2095 | val_loss=0.1222 | SWA=0.9629 CWA=0.9609 HWA=0.9619', '\\n',\n'hdim=256 | Epoch 2: train_loss=0.0840 | val_loss=0.0553 | SWA=0.9854 CWA=0.9860\nHWA=0.9857', '\\n', 'hdim=256 | Epoch 3: train_loss=0.0416 | val_loss=0.0292 |\nSWA=0.9920 CWA=0.9929 HWA=0.9924', '\\n', 'hdim=256 | Epoch 4: train_loss=0.0243\n| val_loss=0.0230 | SWA=0.9946 CWA=0.9952 HWA=0.9949', '\\n', 'hdim=256 | Epoch\n5: train_loss=0.0159 | val_loss=0.0192 | SWA=0.9935 CWA=0.9944 HWA=0.9940',\n'\\n', '\\n======== Training with hidden_dim=512 ========', '\\n', 'hdim=512 |\nEpoch 1: train_loss=0.2096 | val_loss=0.1386 | SWA=0.9535 CWA=0.9542\nHWA=0.9538', '\\n', 'hdim=512 | Epoch 2: train_loss=0.0870 | val_loss=0.0503 |\nSWA=0.9854 CWA=0.9861 HWA=0.9857', '\\n', 'hdim=512 | Epoch 3: train_loss=0.0392\n| val_loss=0.0278 | SWA=0.9947 CWA=0.9952 HWA=0.9950', '\\n', 'hdim=512 | Epoch\n4: train_loss=0.0168 | val_loss=0.0145 | SWA=0.9958 CWA=0.9962 HWA=0.9960',\n'\\n', 'hdim=512 | Epoch 5: train_loss=0.0067 | val_loss=0.0091 | SWA=0.9966\nCWA=0.9969 HWA=0.9968', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n13/working/experiment_data.npy', '\\n', 'Execution time: 34 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Vocab size = 18, num_labels = 2', '\\n', '\\n===== Training with\nweight_decay=0.0 =====', '\\n', 'Epoch 1: train_loss=0.2358 | val_loss=0.1439 |\nSWA=0.9570 CWA=0.9557 HWA=0.9564', '\\n', 'Epoch 2: train_loss=0.1108 |\nval_loss=0.0915 | SWA=0.9749 CWA=0.9756 HWA=0.9752', '\\n', 'Epoch 3:\ntrain_loss=0.0710 | val_loss=0.0565 | SWA=0.9845 CWA=0.9853 HWA=0.9849', '\\n',\n'Epoch 4: train_loss=0.0461 | val_loss=0.0398 | SWA=0.9895 CWA=0.9901\nHWA=0.9898', '\\n', 'Epoch 5: train_loss=0.0338 | val_loss=0.0333 | SWA=0.9918\nCWA=0.9926 HWA=0.9922', '\\n', '\\n===== Training with weight_decay=1e-06 =====',\n'\\n', 'Epoch 1: train_loss=0.2374 | val_loss=0.1471 | SWA=0.9561 CWA=0.9544\nHWA=0.9552', '\\n', 'Epoch 2: train_loss=0.1138 | val_loss=0.0910 | SWA=0.9734\nCWA=0.9738 HWA=0.9736', '\\n', 'Epoch 3: train_loss=0.0725 | val_loss=0.0611 |\nSWA=0.9859 CWA=0.9868 HWA=0.9864', '\\n', 'Epoch 4: train_loss=0.0434 |\nval_loss=0.0417 | SWA=0.9904 CWA=0.9913 HWA=0.9909', '\\n', 'Epoch 5:\ntrain_loss=0.0296 | val_loss=0.0306 | SWA=0.9912 CWA=0.9920 HWA=0.9916', '\\n',\n'\\n===== Training with weight_decay=1e-05 =====', '\\n', 'Epoch 1:\ntrain_loss=0.2358 | val_loss=0.1424 | SWA=0.9548 CWA=0.9530 HWA=0.9539', '\\n',\n'Epoch 2: train_loss=0.1018 | val_loss=0.0855 | SWA=0.9749 CWA=0.9758\nHWA=0.9754', '\\n', 'Epoch 3: train_loss=0.0682 | val_loss=0.0581 | SWA=0.9838\nCWA=0.9845 HWA=0.9841', '\\n', 'Epoch 4: train_loss=0.0462 | val_loss=0.0405 |\nSWA=0.9872 CWA=0.9877 HWA=0.9874', '\\n', 'Epoch 5: train_loss=0.0318 |\nval_loss=0.0329 | SWA=0.9942 CWA=0.9951 HWA=0.9946', '\\n', '\\n===== Training\nwith weight_decay=0.0001 =====', '\\n', 'Epoch 1: train_loss=0.2458 |\nval_loss=0.1562 | SWA=0.9515 CWA=0.9510 HWA=0.9513', '\\n', 'Epoch 2:\ntrain_loss=0.1155 | val_loss=0.0822 | SWA=0.9783 CWA=0.9783 HWA=0.9783', '\\n',\n'Epoch 3: train_loss=0.0682 | val_loss=0.0546 | SWA=0.9875 CWA=0.9882\nHWA=0.9879', '\\n', 'Epoch 4: train_loss=0.0454 | val_loss=0.0470 | SWA=0.9859\nCWA=0.9869 HWA=0.9864', '\\n', 'Epoch 5: train_loss=0.0357 | val_loss=0.0326 |\nSWA=0.9924 CWA=0.9930 HWA=0.9927', '\\n', '\\n===== Training with\nweight_decay=0.001 =====', '\\n', 'Epoch 1: train_loss=0.2633 | val_loss=0.1710 |\nSWA=0.9468 CWA=0.9440 HWA=0.9454', '\\n', 'Epoch 2: train_loss=0.1616 |\nval_loss=0.1565 | SWA=0.9554 CWA=0.9530 HWA=0.9542', '\\n', 'Epoch 3:\ntrain_loss=0.1533 | val_loss=0.1518 | SWA=0.9542 CWA=0.9518 HWA=0.9530', '\\n',\n'Epoch 4: train_loss=0.1474 | val_loss=0.1453 | SWA=0.9582 CWA=0.9562\nHWA=0.9572', '\\n', 'Epoch 5: train_loss=0.1430 | val_loss=0.1386 | SWA=0.9576\nCWA=0.9553 HWA=0.9565', '\\n', '\\n===== Training with weight_decay=0.01 =====',\n'\\n', 'Epoch 1: train_loss=0.3408 | val_loss=0.2313 | SWA=0.9230 CWA=0.9229\nHWA=0.9230', '\\n', 'Epoch 2: train_loss=0.2137 | val_loss=0.2132 | SWA=0.9336\nCWA=0.9312 HWA=0.9324', '\\n', 'Epoch 3: train_loss=0.2101 | val_loss=0.2121 |\nSWA=0.9317 CWA=0.9287 HWA=0.9302', '\\n', 'Epoch 4: train_loss=0.2044 |\nval_loss=0.2076 | SWA=0.9373 CWA=0.9350 HWA=0.9361', '\\n', 'Epoch 5:\ntrain_loss=0.2068 | val_loss=0.2076 | SWA=0.9348 CWA=0.9322 HWA=0.9335', '\\n',\n'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n12/working/experiment_data.npy', '\\n', 'Execution time: 51 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', \"{'train': 20000, 'dev': 5000, 'test': 10000}\",\n'\\n', 'Vocab size = 18, num_labels = 2', '\\n', '[layers=1] Epoch 1:\ntrain_loss=0.2429 | val_loss=0.1411 | SWA=0.9505 CWA=0.9489 HWA=0.9497', '\\n',\n'[layers=1] Epoch 2: train_loss=0.1038 | val_loss=0.0847 | SWA=0.9766 CWA=0.9770\nHWA=0.9768', '\\n', '[layers=1] Epoch 3: train_loss=0.0702 | val_loss=0.0592 |\nSWA=0.9874 CWA=0.9877 HWA=0.9876', '\\n', '[layers=1] Epoch 4: train_loss=0.0442\n| val_loss=0.0369 | SWA=0.9932 CWA=0.9935 HWA=0.9934', '\\n', '[layers=1] Epoch\n5: train_loss=0.0308 | val_loss=0.0289 | SWA=0.9930 CWA=0.9936 HWA=0.9933',\n'\\n', '[layers=2] Epoch 1: train_loss=0.2219 | val_loss=0.1202 | SWA=0.9659\nCWA=0.9630 HWA=0.9645', '\\n', '[layers=2] Epoch 2: train_loss=0.0669 |\nval_loss=0.1218 | SWA=0.9638 CWA=0.9614 HWA=0.9626', '\\n', '[layers=2] Epoch 3:\ntrain_loss=0.0396 | val_loss=0.0285 | SWA=0.9923 CWA=0.9926 HWA=0.9924', '\\n',\n'[layers=2] Epoch 4: train_loss=0.0206 | val_loss=0.0179 | SWA=0.9952 CWA=0.9958\nHWA=0.9955', '\\n', '[layers=2] Epoch 5: train_loss=0.0171 | val_loss=0.0140 |\nSWA=0.9958 CWA=0.9961 HWA=0.9959', '\\n', '[layers=3] Epoch 1: train_loss=0.1907\n| val_loss=0.0647 | SWA=0.9818 CWA=0.9806 HWA=0.9812', '\\n', '[layers=3] Epoch\n2: train_loss=0.0503 | val_loss=0.0439 | SWA=0.9876 CWA=0.9876 HWA=0.9876',\n'\\n', '[layers=3] Epoch 3: train_loss=0.0352 | val_loss=0.0340 | SWA=0.9903\nCWA=0.9905 HWA=0.9904', '\\n', '[layers=3] Epoch 4: train_loss=0.0243 |\nval_loss=0.0239 | SWA=0.9938 CWA=0.9942 HWA=0.9940', '\\n', '[layers=3] Epoch 5:\ntrain_loss=0.0191 | val_loss=0.0149 | SWA=0.9953 CWA=0.9959 HWA=0.9956', '\\n',\n'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n10/working/experiment_data.npy', '\\n', 'Execution time: 29 seconds seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Found SPR_BENCH at:', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', \"{'train': 20000, 'dev':\n5000, 'test': 10000}\", '\\n', 'Vocab=18, num_labels=2', '\\n', '\\n=== Training for\nmax 5 epochs ===', '\\n', '[5e] Epoch 1: train_loss=0.2358 val_loss=0.1439\nHWA=0.9564', '\\n', '[5e] Epoch 2: train_loss=0.1108 val_loss=0.0915 HWA=0.9752',\n'\\n', '[5e] Epoch 3: train_loss=0.0710 val_loss=0.0565 HWA=0.9849', '\\n', '[5e]\nEpoch 4: train_loss=0.0461 val_loss=0.0398 HWA=0.9898', '\\n', '[5e] Epoch 5:\ntrain_loss=0.0338 val_loss=0.0333 HWA=0.9922', '\\n', '\\n=== Training for max 10\nepochs ===', '\\n', '[10e] Epoch 1: train_loss=0.2374 val_loss=0.1471\nHWA=0.9552', '\\n', '[10e] Epoch 2: train_loss=0.1137 val_loss=0.0910\nHWA=0.9738', '\\n', '[10e] Epoch 3: train_loss=0.0724 val_loss=0.0610\nHWA=0.9864', '\\n', '[10e] Epoch 4: train_loss=0.0434 val_loss=0.0415\nHWA=0.9910', '\\n', '[10e] Epoch 5: train_loss=0.0295 val_loss=0.0300\nHWA=0.9918', '\\n', '[10e] Epoch 6: train_loss=0.0219 val_loss=0.0261\nHWA=0.9955', '\\n', '[10e] Epoch 7: train_loss=0.0161 val_loss=0.0197\nHWA=0.9956', '\\n', '[10e] Epoch 8: train_loss=0.0110 val_loss=0.0188\nHWA=0.9948', '\\n', '[10e] Epoch 9: train_loss=0.0074 val_loss=0.0163\nHWA=0.9950', '\\n', '[10e] Epoch 10: train_loss=0.0045 val_loss=0.0141\nHWA=0.9963', '\\n', '\\n=== Training for max 20 epochs ===', '\\n', '[20e] Epoch 1:\ntrain_loss=0.2424 val_loss=0.1360 HWA=0.9538', '\\n', '[20e] Epoch 2:\ntrain_loss=0.0998 val_loss=0.0866 HWA=0.9796', '\\n', '[20e] Epoch 3:\ntrain_loss=0.0715 val_loss=0.0636 HWA=0.9813', '\\n', '[20e] Epoch 4:\ntrain_loss=0.0497 val_loss=0.0385 HWA=0.9903', '\\n', '[20e] Epoch 5:\ntrain_loss=0.0331 val_loss=0.0325 HWA=0.9914', '\\n', '[20e] Epoch 6:\ntrain_loss=0.0239 val_loss=0.0239 HWA=0.9952', '\\n', '[20e] Epoch 7:\ntrain_loss=0.0176 val_loss=0.0216 HWA=0.9952', '\\n', '[20e] Epoch 8:\ntrain_loss=0.0131 val_loss=0.0178 HWA=0.9947', '\\n', '[20e] Epoch 9:\ntrain_loss=0.0091 val_loss=0.0205 HWA=0.9931', '\\n', '[20e] Epoch 10:\ntrain_loss=0.0064 val_loss=0.0144 HWA=0.9960', '\\n', '[20e] Epoch 11:\ntrain_loss=0.0042 val_loss=0.0133 HWA=0.9958', '\\n', '[20e] Epoch 12:\ntrain_loss=0.0027 val_loss=0.0135 HWA=0.9961', '\\n', '[20e] Epoch 13:\ntrain_loss=0.0018 val_loss=0.0132 HWA=0.9955', '\\n', '[20e] Epoch 14:\ntrain_loss=0.0014 val_loss=0.0147 HWA=0.9953', '\\n', '[20e] Epoch 15:\ntrain_loss=0.0011 val_loss=0.0129 HWA=0.9962', '\\n', '[20e] Epoch 16:\ntrain_loss=0.0008 val_loss=0.0129 HWA=0.9961', '\\n', '[20e] Epoch 17:\ntrain_loss=0.0007 val_loss=0.0121 HWA=0.9963', '\\n', '[20e] Epoch 18:\ntrain_loss=0.0006 val_loss=0.0137 HWA=0.9959', '\\n', '[20e] Epoch 19:\ntrain_loss=0.0005 val_loss=0.0126 HWA=0.9963', '\\n', '[20e] Epoch 20:\ntrain_loss=0.0004 val_loss=0.0127 HWA=0.9961', '\\n', 'Early stopping at epoch\n20', '\\n', '\\n=== Training for max 30 epochs ===', '\\n', '[30e] Epoch 1:\ntrain_loss=0.2475 val_loss=0.1552 HWA=0.9570', '\\n', '[30e] Epoch 2:\ntrain_loss=0.1274 val_loss=0.0952 HWA=0.9681', '\\n', '[30e] Epoch 3:\ntrain_loss=0.0678 val_loss=0.0539 HWA=0.9885', '\\n', '[30e] Epoch 4:\ntrain_loss=0.0428 val_loss=0.0367 HWA=0.9924', '\\n', '[30e] Epoch 5:\ntrain_loss=0.0294 val_loss=0.0305 HWA=0.9920', '\\n', '[30e] Epoch 6:\ntrain_loss=0.0237 val_loss=0.0256 HWA=0.9942', '\\n', '[30e] Epoch 7:\ntrain_loss=0.0146 val_loss=0.0196 HWA=0.9946', '\\n', '[30e] Epoch 8:\ntrain_loss=0.0099 val_loss=0.0163 HWA=0.9959', '\\n', '[30e] Epoch 9:\ntrain_loss=0.0060 val_loss=0.0135 HWA=0.9970', '\\n', '[30e] Epoch 10:\ntrain_loss=0.0042 val_loss=0.0148 HWA=0.9965', '\\n', '[30e] Epoch 11:\ntrain_loss=0.0031 val_loss=0.0129 HWA=0.9955', '\\n', '[30e] Epoch 12:\ntrain_loss=0.0020 val_loss=0.0140 HWA=0.9959', '\\n', 'Early stopping at epoch\n12', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n11/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Found SPR_BENCH at:', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', \"{'train': 20000, 'dev':\n5000, 'test': 10000}\", '\\n', 'Vocab=18, num_labels=2', '\\n', '\\n=== Training for\nmax 5 epochs ===', '\\n', '[5e] Epoch 1: train_loss=0.2358 val_loss=0.1439\nHWA=0.9564', '\\n', '[5e] Epoch 2: train_loss=0.1108 val_loss=0.0915 HWA=0.9752',\n'\\n', '[5e] Epoch 3: train_loss=0.0710 val_loss=0.0565 HWA=0.9849', '\\n', '[5e]\nEpoch 4: train_loss=0.0461 val_loss=0.0398 HWA=0.9898', '\\n', '[5e] Epoch 5:\ntrain_loss=0.0338 val_loss=0.0333 HWA=0.9922', '\\n', '\\n=== Training for max 10\nepochs ===', '\\n', '[10e] Epoch 1: train_loss=0.2374 val_loss=0.1471\nHWA=0.9552', '\\n', '[10e] Epoch 2: train_loss=0.1137 val_loss=0.0910\nHWA=0.9738', '\\n', '[10e] Epoch 3: train_loss=0.0724 val_loss=0.0610\nHWA=0.9864', '\\n', '[10e] Epoch 4: train_loss=0.0434 val_loss=0.0415\nHWA=0.9910', '\\n', '[10e] Epoch 5: train_loss=0.0295 val_loss=0.0300\nHWA=0.9918', '\\n', '[10e] Epoch 6: train_loss=0.0219 val_loss=0.0261\nHWA=0.9955', '\\n', '[10e] Epoch 7: train_loss=0.0161 val_loss=0.0197\nHWA=0.9956', '\\n', '[10e] Epoch 8: train_loss=0.0110 val_loss=0.0188\nHWA=0.9948', '\\n', '[10e] Epoch 9: train_loss=0.0074 val_loss=0.0163\nHWA=0.9950', '\\n', '[10e] Epoch 10: train_loss=0.0045 val_loss=0.0141\nHWA=0.9963', '\\n', '\\n=== Training for max 20 epochs ===', '\\n', '[20e] Epoch 1:\ntrain_loss=0.2424 val_loss=0.1360 HWA=0.9538', '\\n', '[20e] Epoch 2:\ntrain_loss=0.0998 val_loss=0.0866 HWA=0.9796', '\\n', '[20e] Epoch 3:\ntrain_loss=0.0715 val_loss=0.0636 HWA=0.9813', '\\n', '[20e] Epoch 4:\ntrain_loss=0.0497 val_loss=0.0385 HWA=0.9903', '\\n', '[20e] Epoch 5:\ntrain_loss=0.0331 val_loss=0.0325 HWA=0.9914', '\\n', '[20e] Epoch 6:\ntrain_loss=0.0239 val_loss=0.0239 HWA=0.9952', '\\n', '[20e] Epoch 7:\ntrain_loss=0.0176 val_loss=0.0216 HWA=0.9952', '\\n', '[20e] Epoch 8:\ntrain_loss=0.0131 val_loss=0.0178 HWA=0.9947', '\\n', '[20e] Epoch 9:\ntrain_loss=0.0091 val_loss=0.0205 HWA=0.9931', '\\n', '[20e] Epoch 10:\ntrain_loss=0.0064 val_loss=0.0144 HWA=0.9960', '\\n', '[20e] Epoch 11:\ntrain_loss=0.0042 val_loss=0.0133 HWA=0.9958', '\\n', '[20e] Epoch 12:\ntrain_loss=0.0027 val_loss=0.0135 HWA=0.9961', '\\n', '[20e] Epoch 13:\ntrain_loss=0.0018 val_loss=0.0132 HWA=0.9955', '\\n', '[20e] Epoch 14:\ntrain_loss=0.0014 val_loss=0.0147 HWA=0.9953', '\\n', '[20e] Epoch 15:\ntrain_loss=0.0011 val_loss=0.0129 HWA=0.9962', '\\n', '[20e] Epoch 16:\ntrain_loss=0.0008 val_loss=0.0129 HWA=0.9961', '\\n', '[20e] Epoch 17:\ntrain_loss=0.0007 val_loss=0.0121 HWA=0.9963', '\\n', '[20e] Epoch 18:\ntrain_loss=0.0006 val_loss=0.0137 HWA=0.9959', '\\n', '[20e] Epoch 19:\ntrain_loss=0.0005 val_loss=0.0126 HWA=0.9963', '\\n', '[20e] Epoch 20:\ntrain_loss=0.0004 val_loss=0.0127 HWA=0.9961', '\\n', 'Early stopping at epoch\n20', '\\n', '\\n=== Training for max 30 epochs ===', '\\n', '[30e] Epoch 1:\ntrain_loss=0.2475 val_loss=0.1552 HWA=0.9570', '\\n', '[30e] Epoch 2:\ntrain_loss=0.1274 val_loss=0.0952 HWA=0.9681', '\\n', '[30e] Epoch 3:\ntrain_loss=0.0678 val_loss=0.0539 HWA=0.9885', '\\n', '[30e] Epoch 4:\ntrain_loss=0.0428 val_loss=0.0367 HWA=0.9924', '\\n', '[30e] Epoch 5:\ntrain_loss=0.0294 val_loss=0.0305 HWA=0.9920', '\\n', '[30e] Epoch 6:\ntrain_loss=0.0237 val_loss=0.0256 HWA=0.9942', '\\n', '[30e] Epoch 7:\ntrain_loss=0.0146 val_loss=0.0196 HWA=0.9946', '\\n', '[30e] Epoch 8:\ntrain_loss=0.0099 val_loss=0.0163 HWA=0.9959', '\\n', '[30e] Epoch 9:\ntrain_loss=0.0060 val_loss=0.0135 HWA=0.9970', '\\n', '[30e] Epoch 10:\ntrain_loss=0.0042 val_loss=0.0148 HWA=0.9965', '\\n', '[30e] Epoch 11:\ntrain_loss=0.0031 val_loss=0.0129 HWA=0.9955', '\\n', '[30e] Epoch 12:\ntrain_loss=0.0020 val_loss=0.0140 HWA=0.9959', '\\n', 'Early stopping at epoch\n12', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n13/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'Found SPR_BENCH at:', ' ',\n'/home/zxl240011/AI-Scientist-v2/SPR_BENCH', '\\n', \"{'train': 20000, 'dev':\n5000, 'test': 10000}\", '\\n', 'Vocab=18, num_labels=2', '\\n', '\\n=== Training for\nmax 5 epochs ===', '\\n', '[5e] Epoch 1: train_loss=0.2358 val_loss=0.1439\nHWA=0.9564', '\\n', '[5e] Epoch 2: train_loss=0.1108 val_loss=0.0915 HWA=0.9752',\n'\\n', '[5e] Epoch 3: train_loss=0.0710 val_loss=0.0565 HWA=0.9849', '\\n', '[5e]\nEpoch 4: train_loss=0.0461 val_loss=0.0398 HWA=0.9898', '\\n', '[5e] Epoch 5:\ntrain_loss=0.0338 val_loss=0.0333 HWA=0.9922', '\\n', '\\n=== Training for max 10\nepochs ===', '\\n', '[10e] Epoch 1: train_loss=0.2374 val_loss=0.1471\nHWA=0.9552', '\\n', '[10e] Epoch 2: train_loss=0.1137 val_loss=0.0910\nHWA=0.9738', '\\n', '[10e] Epoch 3: train_loss=0.0724 val_loss=0.0610\nHWA=0.9864', '\\n', '[10e] Epoch 4: train_loss=0.0434 val_loss=0.0415\nHWA=0.9910', '\\n', '[10e] Epoch 5: train_loss=0.0295 val_loss=0.0300\nHWA=0.9918', '\\n', '[10e] Epoch 6: train_loss=0.0219 val_loss=0.0261\nHWA=0.9955', '\\n', '[10e] Epoch 7: train_loss=0.0161 val_loss=0.0197\nHWA=0.9956', '\\n', '[10e] Epoch 8: train_loss=0.0110 val_loss=0.0188\nHWA=0.9948', '\\n', '[10e] Epoch 9: train_loss=0.0074 val_loss=0.0163\nHWA=0.9950', '\\n', '[10e] Epoch 10: train_loss=0.0045 val_loss=0.0141\nHWA=0.9963', '\\n', '\\n=== Training for max 20 epochs ===', '\\n', '[20e] Epoch 1:\ntrain_loss=0.2424 val_loss=0.1360 HWA=0.9538', '\\n', '[20e] Epoch 2:\ntrain_loss=0.0998 val_loss=0.0866 HWA=0.9796', '\\n', '[20e] Epoch 3:\ntrain_loss=0.0715 val_loss=0.0636 HWA=0.9813', '\\n', '[20e] Epoch 4:\ntrain_loss=0.0497 val_loss=0.0385 HWA=0.9903', '\\n', '[20e] Epoch 5:\ntrain_loss=0.0331 val_loss=0.0325 HWA=0.9914', '\\n', '[20e] Epoch 6:\ntrain_loss=0.0239 val_loss=0.0239 HWA=0.9952', '\\n', '[20e] Epoch 7:\ntrain_loss=0.0176 val_loss=0.0216 HWA=0.9952', '\\n', '[20e] Epoch 8:\ntrain_loss=0.0131 val_loss=0.0178 HWA=0.9947', '\\n', '[20e] Epoch 9:\ntrain_loss=0.0091 val_loss=0.0205 HWA=0.9931', '\\n', '[20e] Epoch 10:\ntrain_loss=0.0064 val_loss=0.0144 HWA=0.9960', '\\n', '[20e] Epoch 11:\ntrain_loss=0.0042 val_loss=0.0133 HWA=0.9958', '\\n', '[20e] Epoch 12:\ntrain_loss=0.0027 val_loss=0.0135 HWA=0.9961', '\\n', '[20e] Epoch 13:\ntrain_loss=0.0018 val_loss=0.0132 HWA=0.9955', '\\n', '[20e] Epoch 14:\ntrain_loss=0.0014 val_loss=0.0147 HWA=0.9953', '\\n', '[20e] Epoch 15:\ntrain_loss=0.0011 val_loss=0.0129 HWA=0.9962', '\\n', '[20e] Epoch 16:\ntrain_loss=0.0008 val_loss=0.0129 HWA=0.9961', '\\n', '[20e] Epoch 17:\ntrain_loss=0.0007 val_loss=0.0121 HWA=0.9963', '\\n', '[20e] Epoch 18:\ntrain_loss=0.0006 val_loss=0.0137 HWA=0.9959', '\\n', '[20e] Epoch 19:\ntrain_loss=0.0005 val_loss=0.0126 HWA=0.9963', '\\n', '[20e] Epoch 20:\ntrain_loss=0.0004 val_loss=0.0127 HWA=0.9961', '\\n', 'Early stopping at epoch\n20', '\\n', '\\n=== Training for max 30 epochs ===', '\\n', '[30e] Epoch 1:\ntrain_loss=0.2475 val_loss=0.1552 HWA=0.9570', '\\n', '[30e] Epoch 2:\ntrain_loss=0.1274 val_loss=0.0952 HWA=0.9681', '\\n', '[30e] Epoch 3:\ntrain_loss=0.0678 val_loss=0.0539 HWA=0.9885', '\\n', '[30e] Epoch 4:\ntrain_loss=0.0428 val_loss=0.0367 HWA=0.9924', '\\n', '[30e] Epoch 5:\ntrain_loss=0.0294 val_loss=0.0305 HWA=0.9920', '\\n', '[30e] Epoch 6:\ntrain_loss=0.0237 val_loss=0.0256 HWA=0.9942', '\\n', '[30e] Epoch 7:\ntrain_loss=0.0146 val_loss=0.0196 HWA=0.9946', '\\n', '[30e] Epoch 8:\ntrain_loss=0.0099 val_loss=0.0163 HWA=0.9959', '\\n', '[30e] Epoch 9:\ntrain_loss=0.0060 val_loss=0.0135 HWA=0.9970', '\\n', '[30e] Epoch 10:\ntrain_loss=0.0042 val_loss=0.0148 HWA=0.9965', '\\n', '[30e] Epoch 11:\ntrain_loss=0.0031 val_loss=0.0129 HWA=0.9955', '\\n', '[30e] Epoch 12:\ntrain_loss=0.0020 val_loss=0.0140 HWA=0.9959', '\\n', 'Early stopping at epoch\n12', '\\n', 'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-15_22-25-\n14_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n10/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", ""], "analysis": ["The training script executed successfully without any bugs. The output logs\nindicate that the training, validation, and evaluation processes ran smoothly\nfor all specified epoch ranges (5, 10, 20, and 30 epochs). The model achieved\nhigh harmonic-weighted accuracy (HWA), surpassing 99.5% in many cases, and the\nvalidation loss decreased consistently, meeting the sub-stage goals. Early\nstopping was also correctly applied where necessary, indicating that the\ntraining process was well-controlled. No issues were observed in the code or\noutput.", "The training script executed successfully without any errors. The learning rate\nsweep was conducted for four different learning rates, and the metrics (SWA,\nCWA, HWA, and validation loss) improved consistently across epochs for all\nlearning rates. The results were saved to a file for further analysis. No bugs\nor issues were detected in the output log.", "The execution was successful, and the training script performed as expected. It\ntested various batch sizes (32, 64, 128, and 256) and logged relevant metrics\nsuch as training loss, validation loss, Shape-Weighted Accuracy (SWA), Color-\nWeighted Accuracy (CWA), and Harmonic-Weighted Accuracy (HWA). The model showed\nconsistent improvement in validation metrics across epochs, and the results were\nsaved successfully. No bugs or issues were observed during the execution.", "", "", "", "The training script executed successfully without any bugs. The model was\ntrained with various weight decay values, and metrics such as shape-weighted\naccuracy (SWA), color-weighted accuracy (CWA), and harmonic-weighted accuracy\n(HWA) were logged for each epoch. The results show that the model achieved high\nperformance metrics for lower weight decay values, particularly for\nweight_decay=0.0 and 1e-06, with validation loss decreasing and accuracies\nimproving over epochs. The experiment data was successfully saved. No issues\nwere detected.", "", "", "", "", ""], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value computed on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.002015, "best_value": 0.000387}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value computed on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.012921, "best_value": 0.012123}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy computed on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.996919, "best_value": 0.996919}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The color-weighted accuracy computed on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.997072, "best_value": 0.997072}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy computed on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.996995, "best_value": 0.996995}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is learning.", "data": [{"dataset_name": "lr_0.0005", "final_value": 0.063297, "best_value": 0.063297}, {"dataset_name": "lr_0.001", "final_value": 0.026932, "best_value": 0.026932}, {"dataset_name": "lr_0.002", "final_value": 0.012018, "best_value": 0.012018}, {"dataset_name": "lr_0.003", "final_value": 0.004596, "best_value": 0.004596}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, indicating how well the model performs on unseen data.", "data": [{"dataset_name": "lr_0.0005", "final_value": 0.055856, "best_value": 0.055856}, {"dataset_name": "lr_0.001", "final_value": 0.026869, "best_value": 0.026869}, {"dataset_name": "lr_0.002", "final_value": 0.018733, "best_value": 0.018733}, {"dataset_name": "lr_0.003", "final_value": 0.007537, "best_value": 0.007537}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on validation data, weighted by shape categories.", "data": [{"dataset_name": "lr_0.0005", "final_value": 0.98349, "best_value": 0.98349}, {"dataset_name": "lr_0.001", "final_value": 0.994187, "best_value": 0.994187}, {"dataset_name": "lr_0.002", "final_value": 0.995291, "best_value": 0.995291}, {"dataset_name": "lr_0.003", "final_value": 0.997558, "best_value": 0.997558}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model on validation data, weighted by color categories.", "data": [{"dataset_name": "lr_0.0005", "final_value": 0.984199, "best_value": 0.984199}, {"dataset_name": "lr_0.001", "final_value": 0.994814, "best_value": 0.994814}, {"dataset_name": "lr_0.002", "final_value": 0.995546, "best_value": 0.995546}, {"dataset_name": "lr_0.003", "final_value": 0.997682, "best_value": 0.997682}]}, {"metric_name": "validation harmonic-weighted accuracy", "lower_is_better": false, "description": "The harmonic mean of shape-weighted and color-weighted accuracy on validation data.", "data": [{"dataset_name": "lr_0.0005", "final_value": 0.983844, "best_value": 0.983844}, {"dataset_name": "lr_0.001", "final_value": 0.9945, "best_value": 0.9945}, {"dataset_name": "lr_0.002", "final_value": 0.995419, "best_value": 0.995419}, {"dataset_name": "lr_0.003", "final_value": 0.99762, "best_value": 0.99762}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss during the training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0577, "best_value": 0.0067}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0472, "best_value": 0.0101}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy weighted by shape during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9878, "best_value": 0.9959}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The accuracy weighted by color during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.988, "best_value": 0.9963}]}, {"metric_name": "validation harmonic-weighted accuracy", "lower_is_better": false, "description": "The harmonic mean of accuracies weighted by shape and color during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9879, "best_value": 0.9961}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training, indicating the error between predicted and actual values.", "data": [{"dataset_name": "dropout_0.0", "final_value": 0.0338, "best_value": 0.0338}, {"dataset_name": "dropout_0.1", "final_value": 0.0313, "best_value": 0.0313}, {"dataset_name": "dropout_0.3", "final_value": 0.0361, "best_value": 0.0361}, {"dataset_name": "dropout_0.5", "final_value": 0.0408, "best_value": 0.0408}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, indicating the error between predicted and actual values on the validation dataset.", "data": [{"dataset_name": "dropout_0.0", "final_value": 0.0333, "best_value": 0.0333}, {"dataset_name": "dropout_0.1", "final_value": 0.0323, "best_value": 0.0323}, {"dataset_name": "dropout_0.3", "final_value": 0.0329, "best_value": 0.0329}, {"dataset_name": "dropout_0.5", "final_value": 0.0345, "best_value": 0.0345}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model in predicting shapes, weighted by their frequency in the dataset, on the validation set.", "data": [{"dataset_name": "dropout_0.0", "final_value": 0.9918, "best_value": 0.9918}, {"dataset_name": "dropout_0.1", "final_value": 0.9905, "best_value": 0.9905}, {"dataset_name": "dropout_0.3", "final_value": 0.9945, "best_value": 0.9945}, {"dataset_name": "dropout_0.5", "final_value": 0.9926, "best_value": 0.9926}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "The accuracy of the model in predicting colors, weighted by their frequency in the dataset, on the validation set.", "data": [{"dataset_name": "dropout_0.0", "final_value": 0.9926, "best_value": 0.9926}, {"dataset_name": "dropout_0.1", "final_value": 0.9913, "best_value": 0.9913}, {"dataset_name": "dropout_0.3", "final_value": 0.9951, "best_value": 0.9951}, {"dataset_name": "dropout_0.5", "final_value": 0.9929, "best_value": 0.9929}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic mean of shape and color weighted accuracies on the validation set.", "data": [{"dataset_name": "dropout_0.0", "final_value": 0.9922, "best_value": 0.9922}, {"dataset_name": "dropout_0.1", "final_value": 0.9908, "best_value": 0.9908}, {"dataset_name": "dropout_0.3", "final_value": 0.9948, "best_value": 0.9948}, {"dataset_name": "dropout_0.5", "final_value": 0.9928, "best_value": 0.9928}]}]}, {"metric_names": [{"metric_name": "Training LOSS", "lower_is_better": true, "description": "Measures the error during training. Lower values indicate better training performance.", "data": [{"dataset_name": "Embedding dimension 32", "final_value": 0.0921, "best_value": 0.0921}, {"dataset_name": "Embedding dimension 64", "final_value": 0.0581, "best_value": 0.0581}, {"dataset_name": "Embedding dimension 128", "final_value": 0.0527, "best_value": 0.0527}, {"dataset_name": "Embedding dimension 256", "final_value": 0.0362, "best_value": 0.0362}]}, {"metric_name": "Validation SWA", "lower_is_better": false, "description": "Measures the smoothed weighted accuracy on the validation dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Embedding dimension 32", "final_value": 0.9812, "best_value": 0.9812}, {"dataset_name": "Embedding dimension 64", "final_value": 0.9903, "best_value": 0.9903}, {"dataset_name": "Embedding dimension 128", "final_value": 0.9862, "best_value": 0.9862}, {"dataset_name": "Embedding dimension 256", "final_value": 0.9905, "best_value": 0.9905}]}, {"metric_name": "Validation CWA", "lower_is_better": false, "description": "Measures the cumulative weighted accuracy on the validation dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Embedding dimension 32", "final_value": 0.9815, "best_value": 0.9815}, {"dataset_name": "Embedding dimension 64", "final_value": 0.9907, "best_value": 0.9907}, {"dataset_name": "Embedding dimension 128", "final_value": 0.9871, "best_value": 0.9871}, {"dataset_name": "Embedding dimension 256", "final_value": 0.9913, "best_value": 0.9913}]}, {"metric_name": "Validation HWA", "lower_is_better": false, "description": "Measures the harmonic weighted accuracy on the validation dataset. Higher values indicate better performance.", "data": [{"dataset_name": "Embedding dimension 32", "final_value": 0.9813, "best_value": 0.9813}, {"dataset_name": "Embedding dimension 64", "final_value": 0.9905, "best_value": 0.9905}, {"dataset_name": "Embedding dimension 128", "final_value": 0.9867, "best_value": 0.9867}, {"dataset_name": "Embedding dimension 256", "final_value": 0.9909, "best_value": 0.9909}]}, {"metric_name": "Validation LOSS", "lower_is_better": true, "description": "Measures the error on the validation dataset. Lower values indicate better validation performance.", "data": [{"dataset_name": "Embedding dimension 32", "final_value": 0.0752, "best_value": 0.0752}, {"dataset_name": "Embedding dimension 64", "final_value": 0.046, "best_value": 0.046}, {"dataset_name": "Embedding dimension 128", "final_value": 0.0417, "best_value": 0.0417}, {"dataset_name": "Embedding dimension 256", "final_value": 0.0311, "best_value": 0.0311}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The final training loss of the model.", "data": [{"dataset_name": "SPR_BENCH (hidden_dim = 64)", "final_value": 0.04329, "best_value": 0.04329}, {"dataset_name": "SPR_BENCH (hidden_dim = 128)", "final_value": 0.031902, "best_value": 0.031902}, {"dataset_name": "SPR_BENCH (hidden_dim = 256)", "final_value": 0.015911, "best_value": 0.015911}, {"dataset_name": "SPR_BENCH (hidden_dim = 512)", "final_value": 0.006718, "best_value": 0.006718}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The final validation loss of the model.", "data": [{"dataset_name": "SPR_BENCH (hidden_dim = 64)", "final_value": 0.04311, "best_value": 0.04311}, {"dataset_name": "SPR_BENCH (hidden_dim = 128)", "final_value": 0.028635, "best_value": 0.028635}, {"dataset_name": "SPR_BENCH (hidden_dim = 256)", "final_value": 0.019242, "best_value": 0.019242}, {"dataset_name": "SPR_BENCH (hidden_dim = 512)", "final_value": 0.009059, "best_value": 0.009059}]}, {"metric_name": "validation SWA", "lower_is_better": false, "description": "The final validation Softmax Weighted Accuracy (SWA) of the model.", "data": [{"dataset_name": "SPR_BENCH (hidden_dim = 64)", "final_value": 0.991106, "best_value": 0.991106}, {"dataset_name": "SPR_BENCH (hidden_dim = 128)", "final_value": 0.993838, "best_value": 0.993838}, {"dataset_name": "SPR_BENCH (hidden_dim = 256)", "final_value": 0.993547, "best_value": 0.993547}, {"dataset_name": "SPR_BENCH (hidden_dim = 512)", "final_value": 0.996628, "best_value": 0.996628}]}, {"metric_name": "validation CWA", "lower_is_better": false, "description": "The final validation Class Weighted Accuracy (CWA) of the model.", "data": [{"dataset_name": "SPR_BENCH (hidden_dim = 64)", "final_value": 0.991764, "best_value": 0.991764}, {"dataset_name": "SPR_BENCH (hidden_dim = 128)", "final_value": 0.994387, "best_value": 0.994387}, {"dataset_name": "SPR_BENCH (hidden_dim = 256)", "final_value": 0.994448, "best_value": 0.994448}, {"dataset_name": "SPR_BENCH (hidden_dim = 512)", "final_value": 0.996889, "best_value": 0.996889}]}, {"metric_name": "validation HWA", "lower_is_better": false, "description": "The final validation Harmonic Weighted Accuracy (HWA) of the model.", "data": [{"dataset_name": "SPR_BENCH (hidden_dim = 64)", "final_value": 0.991435, "best_value": 0.991435}, {"dataset_name": "SPR_BENCH (hidden_dim = 128)", "final_value": 0.994112, "best_value": 0.994112}, {"dataset_name": "SPR_BENCH (hidden_dim = 256)", "final_value": 0.993998, "best_value": 0.993998}, {"dataset_name": "SPR_BENCH (hidden_dim = 512)", "final_value": 0.996758, "best_value": 0.996758}]}]}, {"metric_names": [{"metric_name": "Training loss", "lower_is_better": true, "description": "Final training loss for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0338, "best_value": 0.0338}, {"dataset_name": "SPR_BENCH", "final_value": 0.0296, "best_value": 0.0296}, {"dataset_name": "SPR_BENCH", "final_value": 0.0318, "best_value": 0.0318}, {"dataset_name": "SPR_BENCH", "final_value": 0.0357, "best_value": 0.0357}, {"dataset_name": "SPR_BENCH", "final_value": 0.143, "best_value": 0.143}, {"dataset_name": "SPR_BENCH", "final_value": 0.2068, "best_value": 0.2068}]}, {"metric_name": "Validation loss", "lower_is_better": true, "description": "Best validation loss for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0333, "best_value": 0.0333}, {"dataset_name": "SPR_BENCH", "final_value": 0.0306, "best_value": 0.0306}, {"dataset_name": "SPR_BENCH", "final_value": 0.0329, "best_value": 0.0329}, {"dataset_name": "SPR_BENCH", "final_value": 0.0326, "best_value": 0.0326}, {"dataset_name": "SPR_BENCH", "final_value": 0.1386, "best_value": 0.1386}, {"dataset_name": "SPR_BENCH", "final_value": 0.2076, "best_value": 0.2076}]}, {"metric_name": "Shape-weighted accuracy", "lower_is_better": false, "description": "Best shape-weighted accuracy for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9918, "best_value": 0.9918}, {"dataset_name": "SPR_BENCH", "final_value": 0.9912, "best_value": 0.9912}, {"dataset_name": "SPR_BENCH", "final_value": 0.9942, "best_value": 0.9942}, {"dataset_name": "SPR_BENCH", "final_value": 0.9924, "best_value": 0.9924}, {"dataset_name": "SPR_BENCH", "final_value": 0.9582, "best_value": 0.9582}, {"dataset_name": "SPR_BENCH", "final_value": 0.9373, "best_value": 0.9373}]}, {"metric_name": "Color-weighted accuracy", "lower_is_better": false, "description": "Best color-weighted accuracy for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9926, "best_value": 0.9926}, {"dataset_name": "SPR_BENCH", "final_value": 0.992, "best_value": 0.992}, {"dataset_name": "SPR_BENCH", "final_value": 0.9951, "best_value": 0.9951}, {"dataset_name": "SPR_BENCH", "final_value": 0.993, "best_value": 0.993}, {"dataset_name": "SPR_BENCH", "final_value": 0.9562, "best_value": 0.9562}, {"dataset_name": "SPR_BENCH", "final_value": 0.935, "best_value": 0.935}]}, {"metric_name": "Harmonic-weighted accuracy", "lower_is_better": false, "description": "Best harmonic-weighted accuracy for the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9922, "best_value": 0.9922}, {"dataset_name": "SPR_BENCH", "final_value": 0.9916, "best_value": 0.9916}, {"dataset_name": "SPR_BENCH", "final_value": 0.9946, "best_value": 0.9946}, {"dataset_name": "SPR_BENCH", "final_value": 0.9927, "best_value": 0.9927}, {"dataset_name": "SPR_BENCH", "final_value": 0.9572, "best_value": 0.9572}, {"dataset_name": "SPR_BENCH", "final_value": 0.9361, "best_value": 0.9361}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the loss of the model on the training dataset.", "data": [{"dataset_name": "layers_1", "final_value": 0.030832, "best_value": 0.030832}, {"dataset_name": "layers_2", "final_value": 0.017094, "best_value": 0.017094}, {"dataset_name": "layers_3", "final_value": 0.019071, "best_value": 0.019071}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the loss of the model on the validation dataset.", "data": [{"dataset_name": "layers_1", "final_value": 0.028873, "best_value": 0.028873}, {"dataset_name": "layers_2", "final_value": 0.013957, "best_value": 0.013957}, {"dataset_name": "layers_3", "final_value": 0.014923, "best_value": 0.014923}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "Measures the weighted accuracy of shape predictions.", "data": [{"dataset_name": "layers_1", "final_value": 0.992966, "best_value": 0.992966}, {"dataset_name": "layers_2", "final_value": 0.995756, "best_value": 0.995756}, {"dataset_name": "layers_3", "final_value": 0.995349, "best_value": 0.995349}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "Measures the weighted accuracy of color predictions.", "data": [{"dataset_name": "layers_1", "final_value": 0.993594, "best_value": 0.993594}, {"dataset_name": "layers_2", "final_value": 0.996095, "best_value": 0.996095}, {"dataset_name": "layers_3", "final_value": 0.995851, "best_value": 0.995851}]}, {"metric_name": "harmonic weighted accuracy", "lower_is_better": false, "description": "Measures the harmonic mean of shape and color weighted accuracy.", "data": [{"dataset_name": "layers_1", "final_value": 0.99328, "best_value": 0.99328}, {"dataset_name": "layers_2", "final_value": 0.995926, "best_value": 0.995926}, {"dataset_name": "layers_3", "final_value": 0.9956, "best_value": 0.9956}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value computed during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.002015, "best_value": 0.002015}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value computed on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.012921, "best_value": 0.012123}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Shape-weighted accuracy computed on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.996919, "best_value": 0.996919}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "Color-weighted accuracy computed on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.997072, "best_value": 0.997072}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "Harmonic weighted accuracy computed on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.996995, "best_value": 0.996995}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is learning.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.002015, "best_value": 0.002015}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset, used to evaluate the model's performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.012921, "best_value": 0.012123}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy weighted by shape-related metrics on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.996919, "best_value": 0.996919}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "The accuracy weighted by color-related metrics on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.997072, "best_value": 0.997072}]}, {"metric_name": "harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic mean of accuracy metrics on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.996995, "best_value": 0.996995}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Loss value during training", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.002015, "best_value": 0.002015}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss value during validation", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.012921, "best_value": 0.012123}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Shape-weighted accuracy during validation", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.996919, "best_value": 0.996919}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "Color-weighted accuracy during validation", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.997072, "best_value": 0.997072}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "Harmonic weighted accuracy during validation", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.996995, "best_value": 0.996995}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [true, false, false, false, false, false, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_c70a6808b9a045d7a11aee55dc386cd5_proc_2991852/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_c70a6808b9a045d7a11aee55dc386cd5_proc_2991852/SPR_BENCH_HWA_curves.png", "../../logs/0-run/experiment_results/experiment_c70a6808b9a045d7a11aee55dc386cd5_proc_2991852/SPR_BENCH_best_HWA_vs_epochs.png"], ["../../logs/0-run/experiment_results/experiment_d4e15b360a7a4f80b900ecd797436699_proc_2991855/spr-bench_loss_curves.png", "../../logs/0-run/experiment_results/experiment_d4e15b360a7a4f80b900ecd797436699_proc_2991855/spr-bench_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_d4e15b360a7a4f80b900ecd797436699_proc_2991855/spr-bench_final_hwa_bar.png"], ["../../logs/0-run/experiment_results/experiment_6c31e9a5cd6e4ccc914efd789244c5a5_proc_2991857/SPR_BENCH_loss_curves_batchsize.png"], ["../../logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_train_loss_dropout.png", "../../logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_val_loss_dropout.png", "../../logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_val_HWA_dropout.png", "../../logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_final_HWA_dropout.png"], ["../../logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_train_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_val_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_best_hwa_bar.png"], ["../../logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hwa_bar.png", "../../logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden64_loss_hwa.png", "../../logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden128_loss_hwa.png", "../../logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden256_loss_hwa.png", "../../logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden512_loss_hwa.png"], ["../../logs/0-run/experiment_results/experiment_cfd0d4d23503464ab9137034e9878423_proc_2991857/SPR_BENCH_loss_curves_weight_decay.png", "../../logs/0-run/experiment_results/experiment_cfd0d4d23503464ab9137034e9878423_proc_2991857/SPR_BENCH_HWA_epoch_curves.png", "../../logs/0-run/experiment_results/experiment_cfd0d4d23503464ab9137034e9878423_proc_2991857/SPR_BENCH_HWA_vs_weight_decay.png"], ["../../logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_final_hwa_bar.png", "../../logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_swa_vs_cwa_scatter.png"], ["../../logs/0-run/experiment_results/experiment_9b13a95008444d0682d39565fc5fcd0a_proc_2991855/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_9b13a95008444d0682d39565fc5fcd0a_proc_2991855/SPR_BENCH_HWA_curves.png", "../../logs/0-run/experiment_results/experiment_9b13a95008444d0682d39565fc5fcd0a_proc_2991855/SPR_BENCH_best_HWA_vs_epochs.png"], ["../../logs/0-run/experiment_results/experiment_ae2af866218b44dc9b3b4306849fd959_proc_2991858/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_ae2af866218b44dc9b3b4306849fd959_proc_2991858/SPR_BENCH_HWA_curves.png", "../../logs/0-run/experiment_results/experiment_ae2af866218b44dc9b3b4306849fd959_proc_2991858/SPR_BENCH_best_HWA_vs_epochs.png"], ["../../logs/0-run/experiment_results/experiment_3344104bff8f4846b93d6f37175d1293_proc_2991852/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_3344104bff8f4846b93d6f37175d1293_proc_2991852/SPR_BENCH_HWA_curves.png", "../../logs/0-run/experiment_results/experiment_3344104bff8f4846b93d6f37175d1293_proc_2991852/SPR_BENCH_best_HWA_vs_epochs.png"], ["../../logs/0-run/experiment_results/seed_aggregation_15da3c1f11e948fcaf756727ede2e381/SPR_BENCH_aggregated_loss_curves.png", "../../logs/0-run/experiment_results/seed_aggregation_15da3c1f11e948fcaf756727ede2e381/SPR_BENCH_aggregated_HWA_curves.png", "../../logs/0-run/experiment_results/seed_aggregation_15da3c1f11e948fcaf756727ede2e381/SPR_BENCH_aggregated_best_HWA.png"]], "plot_paths": [["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c70a6808b9a045d7a11aee55dc386cd5_proc_2991852/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c70a6808b9a045d7a11aee55dc386cd5_proc_2991852/SPR_BENCH_HWA_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c70a6808b9a045d7a11aee55dc386cd5_proc_2991852/SPR_BENCH_best_HWA_vs_epochs.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d4e15b360a7a4f80b900ecd797436699_proc_2991855/spr-bench_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d4e15b360a7a4f80b900ecd797436699_proc_2991855/spr-bench_hwa_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d4e15b360a7a4f80b900ecd797436699_proc_2991855/spr-bench_final_hwa_bar.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6c31e9a5cd6e4ccc914efd789244c5a5_proc_2991857/SPR_BENCH_loss_curves_batchsize.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_train_loss_dropout.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_val_loss_dropout.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_val_HWA_dropout.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_final_HWA_dropout.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_train_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_val_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_hwa_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_best_hwa_bar.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hwa_bar.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden64_loss_hwa.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden128_loss_hwa.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden256_loss_hwa.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden512_loss_hwa.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_cfd0d4d23503464ab9137034e9878423_proc_2991857/SPR_BENCH_loss_curves_weight_decay.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_cfd0d4d23503464ab9137034e9878423_proc_2991857/SPR_BENCH_HWA_epoch_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_cfd0d4d23503464ab9137034e9878423_proc_2991857/SPR_BENCH_HWA_vs_weight_decay.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_hwa_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_final_hwa_bar.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_swa_vs_cwa_scatter.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9b13a95008444d0682d39565fc5fcd0a_proc_2991855/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9b13a95008444d0682d39565fc5fcd0a_proc_2991855/SPR_BENCH_HWA_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9b13a95008444d0682d39565fc5fcd0a_proc_2991855/SPR_BENCH_best_HWA_vs_epochs.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ae2af866218b44dc9b3b4306849fd959_proc_2991858/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ae2af866218b44dc9b3b4306849fd959_proc_2991858/SPR_BENCH_HWA_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ae2af866218b44dc9b3b4306849fd959_proc_2991858/SPR_BENCH_best_HWA_vs_epochs.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3344104bff8f4846b93d6f37175d1293_proc_2991852/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3344104bff8f4846b93d6f37175d1293_proc_2991852/SPR_BENCH_HWA_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3344104bff8f4846b93d6f37175d1293_proc_2991852/SPR_BENCH_best_HWA_vs_epochs.png"], ["experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_15da3c1f11e948fcaf756727ede2e381/SPR_BENCH_aggregated_loss_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_15da3c1f11e948fcaf756727ede2e381/SPR_BENCH_aggregated_HWA_curves.png", "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_15da3c1f11e948fcaf756727ede2e381/SPR_BENCH_aggregated_best_HWA.png"]], "plot_analyses": [[{"analysis": "The training loss decreases consistently across all epoch settings, with minimal differences between 20 and 30 epochs. This indicates that the model converges well within 20 epochs. The validation loss also decreases initially but stabilizes after approximately 10 epochs, with no significant improvement beyond 20 epochs. This suggests that increasing epochs beyond 20 does not significantly enhance model performance and may lead to overfitting.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c70a6808b9a045d7a11aee55dc386cd5_proc_2991852/SPR_BENCH_loss_curves.png"}, {"analysis": "The harmonic-weighted accuracy (HWA) improves rapidly during the initial epochs and stabilizes after approximately 10 epochs. The performance across all epoch settings is nearly identical, with HWA exceeding 0.99 after stabilization. This indicates strong generalization capability and suggests that the model achieves optimal performance early in training.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c70a6808b9a045d7a11aee55dc386cd5_proc_2991852/SPR_BENCH_HWA_curves.png"}, {"analysis": "The best HWA achieved is consistently high across all epoch settings, with values close to 1.0. This indicates that the model's performance is robust to variations in the number of epochs and that extending training beyond 10 epochs yields diminishing returns in terms of HWA.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c70a6808b9a045d7a11aee55dc386cd5_proc_2991852/SPR_BENCH_best_HWA_vs_epochs.png"}], [{"analysis": "This plot shows the training and validation loss trends for different learning rates over five epochs. The learning rate of 0.003 demonstrates the fastest convergence with both training and validation loss reaching very low values by the fifth epoch. Learning rates of 0.002 and 0.001 also exhibit good convergence but slightly lag behind 0.003 in terms of final validation loss. The learning rate of 0.0005 converges the slowest, with higher loss values even at the fifth epoch. This indicates that higher learning rates (within this range) are more effective for faster convergence and achieving lower loss in this experiment.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d4e15b360a7a4f80b900ecd797436699_proc_2991855/spr-bench_loss_curves.png"}, {"analysis": "This plot illustrates the harmonic-weighted accuracy (HWA) on the validation set across epochs for different learning rates. The learning rate of 0.003 consistently achieves the highest HWA at every epoch, followed closely by 0.002 and 0.001. The learning rate of 0.0005 shows the slowest improvement, with a lower HWA compared to the other learning rates. This suggests that higher learning rates contribute to faster and better accuracy improvements on this task.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d4e15b360a7a4f80b900ecd797436699_proc_2991855/spr-bench_hwa_curves.png"}, {"analysis": "This bar chart compares the final epoch harmonic-weighted accuracy (HWA) across different learning rates. All learning rates achieve high HWA values close to 1.0, with negligible differences between them. This indicates that while higher learning rates like 0.003 and 0.002 may converge faster, the final performance in terms of HWA is comparable across the tested learning rates.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d4e15b360a7a4f80b900ecd797436699_proc_2991855/spr-bench_final_hwa_bar.png"}], [{"analysis": "This plot compares training and validation loss across different batch sizes (32, 64, 128, and 256) over five epochs. Smaller batch sizes (32 and 64) show lower validation loss, suggesting better generalization. Larger batch sizes (128 and 256) converge slower and exhibit higher validation loss, indicating potential overfitting or less effective learning dynamics. The training loss decreases steadily for all batch sizes, but the gap between training and validation loss is smaller for smaller batch sizes, further supporting their suitability for this task. This suggests that batch sizes of 32 or 64 may be optimal for achieving the desired validation loss below 0.01.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6c31e9a5cd6e4ccc914efd789244c5a5_proc_2991857/SPR_BENCH_loss_curves_batchsize.png"}], [{"analysis": "This plot shows the training loss across epochs for different dropout rates (0.0, 0.1, 0.3, 0.5). All dropout configurations demonstrate a consistent reduction in training loss as training progresses, indicating effective learning. Dropout 0.5 starts with slightly higher loss but converges similarly to other configurations, suggesting that higher dropout does not significantly impede convergence in this setup. Minimal differences in final training loss across dropout rates imply that dropout does not strongly affect training loss in this experiment.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_train_loss_dropout.png"}, {"analysis": "This plot illustrates the validation loss across epochs for different dropout rates. The validation loss decreases steadily for all dropout configurations, with dropout 0.5 achieving the lowest validation loss by the final epoch. This suggests that higher dropout rates may provide better generalization in this context. The consistent decline in validation loss across all dropout rates indicates that the model is learning effectively without overfitting.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_val_loss_dropout.png"}, {"analysis": "This plot shows the harmonic-weighted accuracy (HWA) on the validation set across epochs for different dropout rates. All configurations exhibit a steady increase in HWA, with dropout 0.5 achieving the highest HWA by the final epoch. This suggests that higher dropout rates may enhance the model's ability to generalize, as evidenced by improved validation performance. The trend indicates that the model benefits from dropout in terms of accuracy.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_val_HWA_dropout.png"}, {"analysis": "This bar plot compares the final-epoch harmonic-weighted accuracy (HWA) for different dropout rates. The HWA is nearly identical across all configurations, with minor variations. This implies that while dropout influences the training dynamics, its impact on the final validation accuracy is limited, and all dropout rates perform similarly well in this experiment.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3ecd9debe4c14a14b62336c21f965376_proc_2991858/SPR_BENCH_final_HWA_dropout.png"}], [{"analysis": "This plot shows the training loss decreasing steadily over the epochs for all embedding sizes. Larger embedding sizes (e.g., emb=256) result in faster convergence and lower final training loss. This suggests that increasing the embedding dimension improves the model's ability to learn during training.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_train_loss_curves.png"}, {"analysis": "The validation loss follows a similar trend to the training loss, with larger embedding sizes achieving lower validation loss. Emb=256 achieves the best validation loss, indicating better generalization to unseen data. The consistent reduction in validation loss across embedding sizes shows stable model behavior.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_val_loss_curves.png"}, {"analysis": "Harmonic Weighted Accuracy (HWA) improves with increasing epochs for all embedding sizes. Larger embedding sizes (e.g., emb=256) result in higher final HWA, indicating better performance on the SPR task. The gap between embeddings suggests that higher-dimensional embeddings capture more robust features.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_hwa_curves.png"}, {"analysis": "The bar chart shows the best validation HWA achieved for each embedding size. All embedding sizes achieve near-perfect HWA, with emb=256 slightly outperforming others. This indicates that while all configurations perform well, larger embeddings provide a marginal advantage.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6b00a3899a54412dbd00f627e8c564a3_proc_2991855/SPR_BENCH_best_hwa_bar.png"}], [{"analysis": "This plot shows the harmonic-weighted accuracy (HWA) on the development set for different hidden dimensions (64, 128, 256, 512). The performance remains consistent across all hidden dimensions, with HWA values close to 1.0. This indicates that the choice of hidden dimension has minimal impact on the model's ability to generalize, suggesting that the model can perform well with relatively small hidden dimensions, which could reduce computational overhead.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hwa_bar.png"}, {"analysis": "This set of plots displays the training and validation loss, as well as the HWA over epochs for a hidden dimension of 64. The loss curves show a steady decrease for both training and validation, indicating effective learning and minimal overfitting. The HWA curve demonstrates a consistent improvement, reaching close to 1.0 by the fifth epoch. This suggests that the model achieves strong performance and convergence with this configuration.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden64_loss_hwa.png"}, {"analysis": "These plots show the results for a hidden dimension of 128. Both training and validation losses decrease steadily, with validation loss closely tracking the training loss, indicating good generalization. The HWA curve shows a similar trend to the previous configuration, with strong performance achieved by the fifth epoch. This configuration is also effective for the task.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden128_loss_hwa.png"}, {"analysis": "For a hidden dimension of 256, the plots indicate a steady decrease in both training and validation loss, with no signs of overfitting. The HWA curve shows a rapid improvement in the early epochs, stabilizing near 1.0 by the fifth epoch. This configuration appears to provide slightly better performance compared to smaller hidden dimensions, but the improvement is marginal.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden256_loss_hwa.png"}, {"analysis": "These plots correspond to a hidden dimension of 512. Both training and validation losses decrease steadily, and the HWA curve shows strong performance, stabilizing near 1.0 by the fifth epoch. However, the performance gain compared to smaller hidden dimensions (e.g., 256) is negligible. This suggests that increasing the hidden dimension beyond 256 may not provide significant benefits and could increase computational costs unnecessarily.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e5307fd0cd24446daca3932dc3f2c251_proc_2991858/SPR_BENCH_hidden512_loss_hwa.png"}], [{"analysis": "The plot illustrates the training and validation cross-entropy loss for various weight decay values across five epochs. Lower weight decay values (e.g., 0.0001 and 1e-05) show consistently lower validation loss compared to higher values (e.g., 0.001 and 0.01). This suggests that smaller weight decay values help prevent over-regularization, leading to better generalization. The training loss also decreases steadily for all configurations, indicating effective learning without significant overfitting for the smaller weight decay values. However, configurations with higher weight decay values exhibit a plateau in validation loss, indicating potential underfitting.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_cfd0d4d23503464ab9137034e9878423_proc_2991857/SPR_BENCH_loss_curves_weight_decay.png"}, {"analysis": "This plot shows the harmonic-weighted accuracy (HWA) on the validation set over epochs for various weight decay values. Smaller weight decay values (e.g., 0.0001 and 1e-05) achieve higher HWA compared to larger values (e.g., 0.01). The HWA trends upward for all configurations, but the improvement is more pronounced for smaller weight decay values, especially in the later epochs. This aligns with the observation that smaller weight decay values yield better generalization and performance on the validation set.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_cfd0d4d23503464ab9137034e9878423_proc_2991857/SPR_BENCH_HWA_epoch_curves.png"}, {"analysis": "This bar chart compares the final harmonic-weighted accuracy (HWA) at the last epoch for different weight decay values. It confirms that smaller weight decay values (e.g., 0.0001 and 1e-05) achieve the highest final HWA, while larger values (e.g., 0.01) result in lower performance. This supports the conclusion that smaller weight decay values are more effective in balancing regularization and model performance for this task.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_cfd0d4d23503464ab9137034e9878423_proc_2991857/SPR_BENCH_HWA_vs_weight_decay.png"}], [{"analysis": "The plot shows the training and validation loss trends over epochs for three different LSTM configurations (layers_1, layers_2, and layers_3). All configurations demonstrate a consistent decrease in both training and validation loss, indicating effective learning. The validation loss for layers_2 and layers_3 converges faster and stabilizes at lower values compared to layers_1, suggesting better generalization for these configurations. This aligns with the hypothesis that increasing the number of layers enhances the model's capacity to learn complex patterns. However, the diminishing gap between training and validation loss for layers_2 and layers_3 also indicates a reduced risk of overfitting.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the harmonic weighted accuracy (HWA) over epochs for the three LSTM configurations. The HWA improves steadily for all configurations, with layers_3 achieving the highest accuracy, followed closely by layers_2. Layers_1 lags behind in terms of both the rate of improvement and final accuracy. This suggests that deeper architectures (layers_2 and layers_3) are more effective in capturing the symbolic patterns needed for the SPR task. The performance difference becomes prominent after epoch 2, highlighting the importance of sufficient training time for deeper models.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_hwa_curves.png"}, {"analysis": "The bar chart compares the final harmonic weighted accuracy (HWA) across the three LSTM configurations. Layers_2 and layers_3 achieve nearly identical final HWA, which is slightly higher than layers_1. This indicates that increasing the number of LSTM layers beyond 2 does not yield significant improvements in HWA, suggesting diminishing returns with additional layers. It might be beneficial to focus on optimizing other hyperparameters rather than further increasing the model depth.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_final_hwa_bar.png"}, {"analysis": "This scatter plot compares the final shape-weighted accuracy (SWA) and color-weighted accuracy (CWA) for the three LSTM configurations. Layers_2 and layers_3 outperform layers_1 in both metrics, with layers_3 showing a marginal advantage over layers_2. The bubble size, proportional to the number of layers, emphasizes the trade-off between model complexity and accuracy. While layers_3 achieves the highest accuracies, the improvement over layers_2 is minimal, suggesting that layers_2 might offer a better balance between performance and computational cost.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_232e9211a8e64f8e8721a9988a3e00fc_proc_2991852/SPR_BENCH_swa_vs_cwa_scatter.png"}], [{"analysis": "The training loss curves show that the model converges effectively for all epoch configurations (5, 10, 20, and 30 epochs). The loss decreases sharply during the initial epochs and plateaus around epoch 10. Increasing the number of epochs beyond 10 does not significantly reduce the training loss, indicating that the model has reached its learning capacity within this range. The validation loss curves exhibit a similar trend, with the loss stabilizing after epoch 10. This suggests that increasing the number of epochs beyond 10 provides minimal benefit in terms of validation performance and may risk overfitting.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9b13a95008444d0682d39565fc5fcd0a_proc_2991855/SPR_BENCH_loss_curves.png"}, {"analysis": "The validation HWA (Harmonic Weighted Accuracy) plot shows consistent improvement during the initial epochs, with all configurations achieving near-perfect HWA (>0.99) by epoch 10. Beyond this point, the HWA remains stable for all configurations, indicating that the model achieves optimal performance early in the training process. There is no significant advantage in extending training beyond 10 epochs for this metric.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9b13a95008444d0682d39565fc5fcd0a_proc_2991855/SPR_BENCH_HWA_curves.png"}, {"analysis": "The bar chart comparing the best HWA across different maximum epoch configurations highlights that the model achieves similar peak performance regardless of the number of epochs (5, 10, 20, or 30). This reinforces the observation that extending training beyond 10 epochs does not yield additional improvements in HWA, suggesting that the model converges effectively within this range.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9b13a95008444d0682d39565fc5fcd0a_proc_2991855/SPR_BENCH_best_HWA_vs_epochs.png"}], [{"analysis": "The training loss curves show a consistent decline across all epoch configurations, with convergence occurring after approximately 10 epochs. This suggests the model is effectively learning from the data. The validation loss curves also exhibit a decline, stabilizing after around 10 epochs, which indicates that the model is not overfitting, even at higher epoch counts (20 and 30). However, the validation loss does not drop below 0.01 as targeted, meaning there is room for further optimization.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ae2af866218b44dc9b3b4306849fd959_proc_2991858/SPR_BENCH_loss_curves.png"}, {"analysis": "The Harmonic Weighted Accuracy (HWA) across epochs indicates that all configurations reach a high level of performance, with HWA values nearing 1.0. The HWA stabilizes after approximately 10 epochs, regardless of the maximum epoch count. This suggests that extending training beyond 10 epochs does not significantly enhance HWA performance, and the model achieves high accuracy early in the training process.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ae2af866218b44dc9b3b4306849fd959_proc_2991858/SPR_BENCH_HWA_curves.png"}, {"analysis": "The bar chart comparing the best HWA across different epoch configurations shows negligible differences in performance. This further confirms that increasing the number of epochs beyond 10 does not yield substantial improvements in the best HWA achieved. Thus, training for fewer epochs might be more efficient without sacrificing performance.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ae2af866218b44dc9b3b4306849fd959_proc_2991858/SPR_BENCH_best_HWA_vs_epochs.png"}], [{"analysis": "The training loss decreases steadily across all epoch configurations, with almost identical trends for 5, 10, 20, and 30 epochs. This suggests that the model is consistently learning well during training. However, the validation loss curves show a plateau starting around 10 epochs, with minimal improvement thereafter. This indicates that increasing the epochs beyond 10 does not significantly enhance generalization, and the model may be converging or even slightly overfitting beyond this point.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3344104bff8f4846b93d6f37175d1293_proc_2991852/SPR_BENCH_loss_curves.png"}, {"analysis": "The Harmonic Weighted Accuracy (HWA) on the validation set improves rapidly in the initial epochs and stabilizes around 0.99 across all configurations. The differences between the epoch configurations are minimal, emphasizing that the model achieves near-optimal HWA performance early in training and additional epochs provide diminishing returns.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3344104bff8f4846b93d6f37175d1293_proc_2991852/SPR_BENCH_HWA_curves.png"}, {"analysis": "The bar chart comparing the best HWA across different maximum epochs shows negligible differences, with all configurations achieving nearly identical best HWA values close to 1.0. This reinforces the observation that extending training beyond 10 epochs does not yield significant performance gains and suggests that the model's capacity to generalize is not heavily dependent on extended training.", "plot_path": "experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3344104bff8f4846b93d6f37175d1293_proc_2991852/SPR_BENCH_best_HWA_vs_epochs.png"}], []], "vlm_feedback_summary": ["The plots indicate that the model achieves strong performance with early\nconvergence. Extending training epochs beyond 20 provides minimal improvements\nand may lead to overfitting. The harmonic-weighted accuracy is consistently\nhigh, demonstrating the model's robustness and generalization capabilities.", "The provided plots effectively demonstrate the impact of learning rate on\ntraining dynamics, validation accuracy, and convergence. Learning rates of 0.003\nand 0.002 show superior performance in terms of faster convergence and lower\nloss, while all learning rates achieve comparable final harmonic-weighted\naccuracy.", "The plot effectively demonstrates the impact of batch size on training and\nvalidation loss, highlighting that smaller batch sizes (32 and 64) yield better\nperformance and generalization.", "The plots demonstrate effective training and validation performance across all\ndropout configurations. Higher dropout rates show slightly better\ngeneralization, as evidenced by lower validation loss and higher harmonic-\nweighted accuracy. However, the final performance differences among dropout\nrates are minimal, suggesting robustness to dropout variations.", "The plots demonstrate that larger embedding sizes lead to better performance in\nterms of training loss, validation loss, and harmonic weighted accuracy. The\nmodel achieves near-perfect performance across configurations, with emb=256\nproviding the best results. These findings support the hypothesis that\nincreasing embedding dimensions enhances feature representation and improves\ntask performance.", "The analysis highlights that the model achieves consistent and strong\nperformance across different hidden dimensions, with harmonic-weighted accuracy\n(HWA) nearing 1.0 in all cases. Training and validation losses decrease steadily\nwithout overfitting, and the choice of hidden dimension has minimal impact on\nperformance, suggesting that smaller dimensions may be more efficient without\nsacrificing accuracy.", "The plots indicate that smaller weight decay values (e.g., 0.0001 and 1e-05)\nlead to better generalization and higher harmonic-weighted accuracy (HWA) on the\nvalidation set. Larger weight decay values (e.g., 0.01) result in underfitting\nand lower performance. The results suggest that careful tuning of weight decay\nis crucial for optimizing model performance in this task.", "The analysis reveals that increasing the number of LSTM layers improves\nperformance, with layers_2 and layers_3 achieving the best results. However, the\nmarginal gains of layers_3 over layers_2 suggest diminishing returns with\nadditional layers. The models show strong convergence and generalization, with\nlayers_2 and layers_3 excelling in all key metrics. Further optimization could\nfocus on hyperparameters other than model depth.", "The plots indicate that the model achieves convergence and optimal performance\nearly in training, with minimal gains from extending the number of epochs beyond\n10. Harmonic Weighted Accuracy stabilizes at near-perfect levels (>0.99) across\nall configurations, and the validation loss curves confirm that further training\ndoes not improve generalization. This suggests that the current hyperparameter\nsettings are effective, and additional epochs do not provide significant\nbenefits.", "The plots indicate that the model achieves high performance early in the\ntraining process, with both training and validation losses stabilizing after\naround 10 epochs. The Harmonic Weighted Accuracy (HWA) is consistently high\nacross all configurations, suggesting that extending training beyond 10 epochs\ndoes not provide additional benefits. Further optimization is needed to achieve\na validation loss below 0.01, as targeted.", "The plots indicate that the model achieves strong performance early in training,\nwith minimal gains from increasing the number of epochs beyond 10. Validation\nloss and HWA metrics stabilize quickly, suggesting convergence. Further\nhyperparameter tuning should focus on other aspects, such as learning rate or\nbatch size, rather than increasing epochs.", "[]"], "exec_time": [76.88202023506165, 35.87324404716492, 39.60763072967529, 35.8355278968811, 23.5631844997406, 34.63847470283508, 51.617974281311035, 29.690092086791992, 76.01841807365417, 76.15304470062256, 83.48091554641724, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[\"SPR_BENCH\"]"], ["[\"SPR-BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], ["['SPR_BENCH']"], ["['layers_1'", "'layers_2'", "'layers_3']"], ["['SPR_BENCH']"], ["['SPR_BENCH']"], ["['SPR_BENCH']"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# helper to get lists\ndef _get(d, *keys, default=None):\n    for k in keys:\n        d = d.get(k, {})\n    return d if d else default\n\n\nspr_runs = _get(experiment_data, \"num_epochs_tuning\", \"SPR_BENCH\", default={})\n\n# -------------- FIGURE 1 -------------------\ntry:\n    if spr_runs:\n        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n        for epochs_str, logs in spr_runs.items():\n            tr_loss = logs[\"losses\"][\"train\"]\n            val_loss = logs[\"losses\"][\"val\"]\n            epochs = range(1, len(tr_loss) + 1)\n            axes[0].plot(epochs, tr_loss, label=f\"{epochs_str}e\")\n            axes[1].plot(epochs, val_loss, label=f\"{epochs_str}e\")\n        axes[0].set_title(\"Left: Train Loss\")\n        axes[1].set_title(\"Right: Validation Loss\")\n        for ax in axes:\n            ax.set_xlabel(\"Epoch\")\n            ax.set_ylabel(\"Loss\")\n            ax.legend()\n        fig.suptitle(\"SPR_BENCH Training vs Validation Loss Curves\")\n        save_path = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# -------------- FIGURE 2 -------------------\ntry:\n    if spr_runs:\n        plt.figure(figsize=(6, 4))\n        for epochs_str, logs in spr_runs.items():\n            hwa = [m[\"hwa\"] for m in logs[\"metrics\"][\"val\"]]\n            epochs = range(1, len(hwa) + 1)\n            plt.plot(epochs, hwa, label=f\"{epochs_str}e\")\n        plt.title(\"SPR_BENCH Validation HWA Across Epochs\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HWA\")\n        plt.legend()\n        save_path = os.path.join(working_dir, \"SPR_BENCH_HWA_curves.png\")\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curves plot: {e}\")\n    plt.close()\n\n# -------------- FIGURE 3 -------------------\ntry:\n    if spr_runs:\n        best_hwa = {\n            int(k): max(m[\"hwa\"] for m in v[\"metrics\"][\"val\"])\n            for k, v in spr_runs.items()\n        }\n        xs, ys = zip(*sorted(best_hwa.items()))\n        plt.figure(figsize=(6, 4))\n        plt.bar([str(x) for x in xs], ys)\n        plt.title(\"SPR_BENCH Best HWA vs Max Epochs\")\n        plt.xlabel(\"Max Epochs\")\n        plt.ylabel(\"Best HWA\")\n        save_path = os.path.join(working_dir, \"SPR_BENCH_best_HWA_vs_epochs.png\")\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# ---------- helper ----------\ndef get_epochs(tag_dict):\n    return list(range(1, len(tag_dict[\"losses\"][\"train\"]) + 1))\n\n\nlrs = sorted(experiment_data.get(\"learning_rate\", {}).keys())\n\n# ---------- Figure 1: loss curves ----------\ntry:\n    plt.figure(figsize=(7, 5))\n    for tag in lrs:\n        ep = get_epochs(experiment_data[\"learning_rate\"][tag])\n        plt.plot(\n            ep,\n            experiment_data[\"learning_rate\"][tag][\"losses\"][\"train\"],\n            label=f\"{tag}-train\",\n            linestyle=\"-\",\n        )\n        plt.plot(\n            ep,\n            experiment_data[\"learning_rate\"][tag][\"losses\"][\"val\"],\n            label=f\"{tag}-val\",\n            linestyle=\"--\",\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR-BENCH: Training vs Validation Loss (Learning-Rate Sweep)\")\n    plt.legend(fontsize=8)\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"spr-bench_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ---------- Figure 2: HWA curves ----------\ntry:\n    plt.figure(figsize=(7, 5))\n    for tag in lrs:\n        ep = get_epochs(experiment_data[\"learning_rate\"][tag])\n        hwa = [\n            m[\"hwa\"] for m in experiment_data[\"learning_rate\"][tag][\"metrics\"][\"val\"]\n        ]\n        plt.plot(ep, hwa, marker=\"o\", label=tag)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Accuracy\")\n    plt.title(\"SPR-BENCH: Validation HWA over Epochs (Learning-Rate Sweep)\")\n    plt.legend(fontsize=8)\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"spr-bench_hwa_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curve plot: {e}\")\n    plt.close()\n\n# ---------- Figure 3: final HWA bar plot ----------\ntry:\n    plt.figure(figsize=(6, 4))\n    final_hwa = [\n        experiment_data[\"learning_rate\"][tag][\"metrics\"][\"val\"][-1][\"hwa\"]\n        for tag in lrs\n    ]\n    plt.bar(range(len(lrs)), final_hwa, tick_label=lrs)\n    plt.ylabel(\"Final Epoch HWA\")\n    plt.title(\"SPR-BENCH: Final Validation HWA vs Learning-Rate\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"spr-bench_final_hwa_bar.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------- load experiment data ----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nspr_runs = experiment_data.get(\"batch_size\", {}).get(\"SPR_BENCH\", {})\nbatch_sizes = sorted([int(k.replace(\"bs\", \"\")) for k in spr_runs.keys()])\n\n\n# helper to pull arrays\ndef fetch(run_key, category, field):\n    return [d[field] for d in spr_runs[run_key][category]]\n\n\n# -------------------------------------------------------\n# 1) Loss curves\ntry:\n    plt.figure()\n    for bs in batch_sizes:\n        rk = f\"bs{bs}\"\n        epochs = range(1, len(spr_runs[rk][\"losses\"][\"train\"]) + 1)\n        plt.plot(\n            epochs,\n            spr_runs[rk][\"losses\"][\"train\"],\n            label=f\"train bs={bs}\",\n            linestyle=\"-\",\n        )\n        plt.plot(\n            epochs,\n            spr_runs[rk][\"losses\"][\"val\"],\n            label=f\"val   bs={bs}\",\n            linestyle=\"--\",\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss (Batch-Size Sweep)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves_batchsize.png\")\n    plt.savefig(fname)\n    plt.close()\n    print(\"Saved\", fname)\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# -------------------------------------------------------\n# 2) HWA curves\ntry:\n    plt.figure()\n    for bs in batch_sizes:\n        rk = f\"bs{bs}\"\n        hwa = fetch(rk, \"metrics\", \"hwa\")\n        epochs = range(1, len(hwa) + 1)\n        plt.plot(epochs, hwa, label=f\"bs={bs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: HWA vs Epoch (Batch-Size Sweep)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves_batchsize.png\")\n    plt.savefig(fname)\n    plt.close()\n    print(\"Saved\", fname)\nexcept Exception as e:\n    print(f\"Error creating HWA curve plot: {e}\")\n    plt.close()\n\n# -------------------------------------------------------\n# 3) Final HWA bar chart\ntry:\n    plt.figure()\n    final_hwa = [fetch(f\"bs{bs}\", \"metrics\", \"hwa\")[-1] for bs in batch_sizes]\n    plt.bar([str(bs) for bs in batch_sizes], final_hwa)\n    plt.xlabel(\"Batch Size\")\n    plt.ylabel(\"Final Epoch HWA\")\n    plt.title(\"SPR_BENCH: Final Harmonic Weighted Accuracy by Batch Size\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_hwa_bar.png\")\n    plt.savefig(fname)\n    plt.close()\n    print(\"Saved\", fname)\nexcept Exception as e:\n    print(f\"Error creating final HWA bar plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ntags = sorted(experiment_data.keys())\nepochs = range(\n    1, 1 + max(len(experiment_data[t][\"SPR_BENCH\"][\"losses\"][\"train\"]) for t in tags)\n)\n\n\n# helper to fetch list safely\ndef get_list(tag, key_path):\n    d = experiment_data[tag][\"SPR_BENCH\"]\n    for k in key_path:\n        d = d[k]\n    return d\n\n\n# ---------- 1. training loss ----------\ntry:\n    plt.figure()\n    for tag in tags:\n        plt.plot(epochs, get_list(tag, [\"losses\", \"train\"]), label=tag)\n    plt.title(\"SPR_BENCH: Training Loss vs Epoch (Dropout Ablation)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_train_loss_dropout.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating training loss plot: {e}\")\n    plt.close()\n\n# ---------- 2. validation loss ----------\ntry:\n    plt.figure()\n    for tag in tags:\n        plt.plot(epochs, get_list(tag, [\"losses\", \"val\"]), label=tag)\n    plt.title(\"SPR_BENCH: Validation Loss vs Epoch (Dropout Ablation)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_loss_dropout.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating validation loss plot: {e}\")\n    plt.close()\n\n# ---------- 3. validation HWA ----------\ntry:\n    plt.figure()\n    for tag in tags:\n        hwa = [m[\"hwa\"] for m in get_list(tag, [\"metrics\", \"val\"])]\n        plt.plot(epochs, hwa, label=tag)\n    plt.title(\"SPR_BENCH: Validation HWA vs Epoch (Dropout Ablation)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"HWA\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_HWA_dropout.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curve plot: {e}\")\n    plt.close()\n\n# ---------- 4. final HWA bar chart ----------\ntry:\n    plt.figure()\n    final_hwa = [get_list(tag, [\"metrics\", \"val\"])[-1][\"hwa\"] for tag in tags]\n    plt.bar(tags, final_hwa, color=\"skyblue\")\n    plt.title(\"SPR_BENCH: Final-Epoch HWA by Dropout\")\n    plt.ylabel(\"HWA\")\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_HWA_dropout.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar plot: {e}\")\n    plt.close()\n\n# ---------- print summary ----------\nfor tag, hwa in zip(tags, final_hwa if \"final_hwa\" in locals() else []):\n    print(f\"{tag}: final validation HWA = {hwa:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------------- setup ----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    emb_dict = experiment_data.get(\"embedding_dim\", {})\n    emb_dims = sorted(emb_dict.keys())\n\n    # Helper to pull series\n    def series(emb, part, key):\n        if part == \"losses\":\n            return emb_dict[emb][\"losses\"][key]  # key='train'/'val'\n        elif part == \"metrics\":\n            return [d[key] for d in emb_dict[emb][\"metrics\"][\"val\"]]\n        else:\n            return []\n\n    # --------- 1. Training loss curves ----------\n    try:\n        plt.figure()\n        for emb in emb_dims:\n            plt.plot(series(emb, \"losses\", \"train\"), label=f\"emb={emb}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH: Training Loss vs Epoch\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_train_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(\"Saved\", fname)\n    except Exception as e:\n        print(f\"Error creating training loss plot: {e}\")\n        plt.close()\n\n    # --------- 2. Validation loss curves ----------\n    try:\n        plt.figure()\n        for emb in emb_dims:\n            plt.plot(series(emb, \"losses\", \"val\"), label=f\"emb={emb}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"SPR_BENCH: Validation Loss vs Epoch\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_val_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(\"Saved\", fname)\n    except Exception as e:\n        print(f\"Error creating validation loss plot: {e}\")\n        plt.close()\n\n    # --------- 3. Validation HWA curves ----------\n    try:\n        plt.figure()\n        for emb in emb_dims:\n            plt.plot(series(emb, \"metrics\", \"hwa\"), label=f\"emb={emb}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HWA\")\n        plt.title(\"SPR_BENCH: Harmonic Weighted Accuracy vs Epoch\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(\"Saved\", fname)\n    except Exception as e:\n        print(f\"Error creating HWA plot: {e}\")\n        plt.close()\n\n    # --------- 4. Best HWA bar chart ----------\n    try:\n        best_hwa = [max(series(emb, \"metrics\", \"hwa\")) for emb in emb_dims]\n        plt.figure()\n        plt.bar([str(e) for e in emb_dims], best_hwa)\n        plt.xlabel(\"Embedding Dimension\")\n        plt.ylabel(\"Best HWA\")\n        plt.title(\"SPR_BENCH: Best Validation HWA per Embedding Size\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_best_hwa_bar.png\")\n        plt.savefig(fname)\n        plt.close()\n        print(\"Saved\", fname)\n    except Exception as e:\n        print(f\"Error creating best HWA bar chart: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    hidden_dict = experiment_data.get(\"hidden_dim\", {})\n    # ---------- summary metrics ----------\n    best_hwa = -1\n    best_hdim = None\n    hwa_summary = {}\n    for hdim, data in hidden_dict.items():\n        hwa_curve = [m[\"hwa\"] for m in data[\"SPR_BENCH\"][\"metrics\"][\"val\"]]\n        if hwa_curve:\n            max_hwa = max(hwa_curve)\n            hwa_summary[hdim] = max_hwa\n            if max_hwa > best_hwa:\n                best_hwa, best_hdim = max_hwa, hdim\n\n    # ---------- bar chart of final HWA ----------\n    try:\n        plt.figure(figsize=(6, 4))\n        dims, hwas = zip(*sorted(hwa_summary.items()))\n        plt.bar([str(d) for d in dims], hwas, color=\"skyblue\")\n        plt.title(\"SPR_BENCH: Final Dev HWA vs Hidden Dim\")\n        plt.ylabel(\"HWA\")\n        plt.xlabel(\"Hidden Dimension\")\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_hwa_bar.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating HWA bar chart: {e}\")\n        plt.close()\n\n    # ---------- per-hidden_dim curves ----------\n    plotted = 0\n    for hdim, data in sorted(hidden_dict.items()):\n        if plotted >= 4:  # guard: at most 4 such figs (total <=5)\n            break\n        try:\n            losses = data[\"SPR_BENCH\"][\"losses\"]\n            metrics = data[\"SPR_BENCH\"][\"metrics\"]\n            train_loss = losses[\"train\"]\n            val_loss = losses[\"val\"]\n            hwa_curve = [m[\"hwa\"] for m in metrics[\"val\"]]\n\n            epochs = range(1, len(train_loss) + 1)\n            fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\n            # left subplot: losses\n            axes[0].plot(epochs, train_loss, label=\"Train\")\n            axes[0].plot(epochs, val_loss, label=\"Val\")\n            axes[0].set_title(f\"Hidden={hdim} | Loss\")\n            axes[0].set_xlabel(\"Epoch\")\n            axes[0].set_ylabel(\"Cross-Entropy\")\n            axes[0].legend()\n\n            # right subplot: HWA\n            axes[1].plot(epochs, hwa_curve, marker=\"o\", color=\"orange\")\n            axes[1].set_title(f\"Hidden={hdim} | HWA\")\n            axes[1].set_xlabel(\"Epoch\")\n            axes[1].set_ylabel(\"HWA\")\n\n            plt.suptitle(f\"SPR_BENCH Results (Hidden={hdim})\")\n            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n            fname = os.path.join(working_dir, f\"SPR_BENCH_hidden{hdim}_loss_hwa.png\")\n            plt.savefig(fname)\n            plt.close()\n            plotted += 1\n        except Exception as e:\n            print(f\"Error creating plot for hidden_dim={hdim}: {e}\")\n            plt.close()\n\n    # ---------- print summary ----------\n    print(\"=== Dev set best HWA by hidden_dim ===\")\n    for hdim, hwa in sorted(hwa_summary.items()):\n        flag = \"<-- best\" if hdim == best_hdim else \"\"\n        print(f\"hidden_dim={hdim:<4}: best_HWA={hwa:.4f} {flag}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    runs = experiment_data.get(\"weight_decay\", {}).get(\"SPR_BENCH\", {}).get(\"runs\", {})\n    colors = plt.cm.tab10(np.linspace(0, 1, len(runs)))\n\n    # --------- plot 1: loss curves ---------\n    try:\n        plt.figure()\n        for (wd, run), c in zip(runs.items(), colors):\n            epochs = range(1, len(run[\"losses\"][\"train\"]) + 1)\n            plt.plot(\n                epochs,\n                run[\"losses\"][\"train\"],\n                color=c,\n                linestyle=\"-\",\n                label=f\"train wd={wd}\",\n            )\n            plt.plot(\n                epochs,\n                run[\"losses\"][\"val\"],\n                color=c,\n                linestyle=\"--\",\n                label=f\"val   wd={wd}\",\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\n            \"SPR_BENCH Training vs Validation Loss\\nLeft: Train (solid), Right: Val (dashed)\"\n        )\n        plt.legend(fontsize=\"small\")\n        f_name = os.path.join(working_dir, \"SPR_BENCH_loss_curves_weight_decay.png\")\n        plt.savefig(f_name, dpi=150)\n        plt.close()\n        print(f\"Saved {f_name}\")\n    except Exception as e:\n        print(f\"Error creating loss curves: {e}\")\n        plt.close()\n\n    # --------- plot 2: HWA across epochs ---------\n    try:\n        plt.figure()\n        for (wd, run), c in zip(runs.items(), colors):\n            hwa = [m[\"hwa\"] for m in run[\"metrics\"][\"val\"]]\n            plt.plot(range(1, len(hwa) + 1), hwa, color=c, label=f\"wd={wd}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Harmonic Weighted Accuracy (HWA)\")\n        plt.title(\"SPR_BENCH Validation HWA Across Epochs\")\n        plt.legend(fontsize=\"small\")\n        f_name = os.path.join(working_dir, \"SPR_BENCH_HWA_epoch_curves.png\")\n        plt.savefig(f_name, dpi=150)\n        plt.close()\n        print(f\"Saved {f_name}\")\n    except Exception as e:\n        print(f\"Error creating HWA curves: {e}\")\n        plt.close()\n\n    # --------- plot 3: final HWA vs weight decay ---------\n    try:\n        plt.figure()\n        wd_vals, final_hwa = [], []\n        for wd, run in runs.items():\n            wd_vals.append(float(wd))\n            final_hwa.append(run[\"metrics\"][\"val\"][-1][\"hwa\"])\n        order = np.argsort(wd_vals)\n        wd_sorted = np.array(wd_vals)[order]\n        hwa_sorted = np.array(final_hwa)[order]\n        plt.bar(\n            range(len(wd_sorted)), hwa_sorted, tick_label=[f\"{w:g}\" for w in wd_sorted]\n        )\n        plt.xlabel(\"Weight Decay\")\n        plt.ylabel(\"Final-Epoch HWA\")\n        plt.title(\"SPR_BENCH Final HWA vs Weight Decay\")\n        f_name = os.path.join(working_dir, \"SPR_BENCH_HWA_vs_weight_decay.png\")\n        plt.savefig(f_name, dpi=150)\n        plt.close()\n        print(f\"Saved {f_name}\")\n    except Exception as e:\n        print(f\"Error creating HWA vs WD plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    layer_keys = sorted(\n        experiment_data[\"num_lstm_layers\"].keys(), key=lambda k: int(k.split(\"_\")[-1])\n    )  # e.g. ['layers_1', 'layers_2', ...]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data, layer_keys = None, []\n\n\n# ---------- helper to fetch series ----------\ndef series(key, phase, field):\n    return [m[field] for m in experiment_data[\"num_lstm_layers\"][key][\"metrics\"][phase]]\n\n\n# ---------- 1. train/val loss curves ----------\ntry:\n    if experiment_data:\n        plt.figure()\n        for k in layer_keys:\n            epochs = np.arange(1, len(series(k, \"train\", \"loss\")) + 1)\n            plt.plot(epochs, series(k, \"train\", \"loss\"), label=f\"{k}-train\")\n            plt.plot(\n                epochs,\n                experiment_data[\"num_lstm_layers\"][k][\"losses\"][\"val\"],\n                \"--\",\n                label=f\"{k}-val\",\n            )\n        plt.title(\"SPR_BENCH: Train vs. Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ---------- 2. HWA curves ----------\ntry:\n    if experiment_data:\n        plt.figure()\n        for k in layer_keys:\n            epochs = np.arange(1, len(series(k, \"val\", \"hwa\")) + 1)\n            plt.plot(epochs, series(k, \"val\", \"hwa\"), label=f\"{k}\")\n        plt.title(\"SPR_BENCH: Validation HWA over Epochs\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Harmonic Weighted Accuracy\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_hwa_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curve plot: {e}\")\n    plt.close()\n\n# ---------- 3. Final HWA bar chart ----------\ntry:\n    if experiment_data:\n        final_hwa = [series(k, \"val\", \"hwa\")[-1] for k in layer_keys]\n        plt.figure()\n        plt.bar(layer_keys, final_hwa, color=\"skyblue\")\n        plt.title(\"SPR_BENCH: Final-Epoch HWA by #LSTM Layers\")\n        plt.ylabel(\"HWA\")\n        plt.xlabel(\"# LSTM Layers\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_final_hwa_bar.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar plot: {e}\")\n    plt.close()\n\n# ---------- 4. SWA vs CWA scatter ----------\ntry:\n    if experiment_data:\n        swa_final = [series(k, \"val\", \"swa\")[-1] for k in layer_keys]\n        cwa_final = [series(k, \"val\", \"cwa\")[-1] for k in layer_keys]\n        sizes = [200 + 50 * int(k.split(\"_\")[-1]) for k in layer_keys]\n        plt.figure()\n        plt.scatter(swa_final, cwa_final, s=sizes)\n        for x, y, k in zip(swa_final, cwa_final, layer_keys):\n            plt.text(x, y, k)\n        plt.title(\"SPR_BENCH: Final SWA vs. CWA (size \u221d layers)\")\n        plt.xlabel(\"Shape Weighted Accuracy\")\n        plt.ylabel(\"Color Weighted Accuracy\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_swa_vs_cwa_scatter.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA vs CWA scatter: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# helper to get lists\ndef _get(d, *keys, default=None):\n    for k in keys:\n        d = d.get(k, {})\n    return d if d else default\n\n\nspr_runs = _get(experiment_data, \"num_epochs_tuning\", \"SPR_BENCH\", default={})\n\n# -------------- FIGURE 1 -------------------\ntry:\n    if spr_runs:\n        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n        for epochs_str, logs in spr_runs.items():\n            tr_loss = logs[\"losses\"][\"train\"]\n            val_loss = logs[\"losses\"][\"val\"]\n            epochs = range(1, len(tr_loss) + 1)\n            axes[0].plot(epochs, tr_loss, label=f\"{epochs_str}e\")\n            axes[1].plot(epochs, val_loss, label=f\"{epochs_str}e\")\n        axes[0].set_title(\"Left: Train Loss\")\n        axes[1].set_title(\"Right: Validation Loss\")\n        for ax in axes:\n            ax.set_xlabel(\"Epoch\")\n            ax.set_ylabel(\"Loss\")\n            ax.legend()\n        fig.suptitle(\"SPR_BENCH Training vs Validation Loss Curves\")\n        save_path = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# -------------- FIGURE 2 -------------------\ntry:\n    if spr_runs:\n        plt.figure(figsize=(6, 4))\n        for epochs_str, logs in spr_runs.items():\n            hwa = [m[\"hwa\"] for m in logs[\"metrics\"][\"val\"]]\n            epochs = range(1, len(hwa) + 1)\n            plt.plot(epochs, hwa, label=f\"{epochs_str}e\")\n        plt.title(\"SPR_BENCH Validation HWA Across Epochs\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HWA\")\n        plt.legend()\n        save_path = os.path.join(working_dir, \"SPR_BENCH_HWA_curves.png\")\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curves plot: {e}\")\n    plt.close()\n\n# -------------- FIGURE 3 -------------------\ntry:\n    if spr_runs:\n        best_hwa = {\n            int(k): max(m[\"hwa\"] for m in v[\"metrics\"][\"val\"])\n            for k, v in spr_runs.items()\n        }\n        xs, ys = zip(*sorted(best_hwa.items()))\n        plt.figure(figsize=(6, 4))\n        plt.bar([str(x) for x in xs], ys)\n        plt.title(\"SPR_BENCH Best HWA vs Max Epochs\")\n        plt.xlabel(\"Max Epochs\")\n        plt.ylabel(\"Best HWA\")\n        save_path = os.path.join(working_dir, \"SPR_BENCH_best_HWA_vs_epochs.png\")\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# helper to get lists\ndef _get(d, *keys, default=None):\n    for k in keys:\n        d = d.get(k, {})\n    return d if d else default\n\n\nspr_runs = _get(experiment_data, \"num_epochs_tuning\", \"SPR_BENCH\", default={})\n\n# -------------- FIGURE 1 -------------------\ntry:\n    if spr_runs:\n        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n        for epochs_str, logs in spr_runs.items():\n            tr_loss = logs[\"losses\"][\"train\"]\n            val_loss = logs[\"losses\"][\"val\"]\n            epochs = range(1, len(tr_loss) + 1)\n            axes[0].plot(epochs, tr_loss, label=f\"{epochs_str}e\")\n            axes[1].plot(epochs, val_loss, label=f\"{epochs_str}e\")\n        axes[0].set_title(\"Left: Train Loss\")\n        axes[1].set_title(\"Right: Validation Loss\")\n        for ax in axes:\n            ax.set_xlabel(\"Epoch\")\n            ax.set_ylabel(\"Loss\")\n            ax.legend()\n        fig.suptitle(\"SPR_BENCH Training vs Validation Loss Curves\")\n        save_path = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# -------------- FIGURE 2 -------------------\ntry:\n    if spr_runs:\n        plt.figure(figsize=(6, 4))\n        for epochs_str, logs in spr_runs.items():\n            hwa = [m[\"hwa\"] for m in logs[\"metrics\"][\"val\"]]\n            epochs = range(1, len(hwa) + 1)\n            plt.plot(epochs, hwa, label=f\"{epochs_str}e\")\n        plt.title(\"SPR_BENCH Validation HWA Across Epochs\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HWA\")\n        plt.legend()\n        save_path = os.path.join(working_dir, \"SPR_BENCH_HWA_curves.png\")\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curves plot: {e}\")\n    plt.close()\n\n# -------------- FIGURE 3 -------------------\ntry:\n    if spr_runs:\n        best_hwa = {\n            int(k): max(m[\"hwa\"] for m in v[\"metrics\"][\"val\"])\n            for k, v in spr_runs.items()\n        }\n        xs, ys = zip(*sorted(best_hwa.items()))\n        plt.figure(figsize=(6, 4))\n        plt.bar([str(x) for x in xs], ys)\n        plt.title(\"SPR_BENCH Best HWA vs Max Epochs\")\n        plt.xlabel(\"Max Epochs\")\n        plt.ylabel(\"Best HWA\")\n        save_path = os.path.join(working_dir, \"SPR_BENCH_best_HWA_vs_epochs.png\")\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# helper to get lists\ndef _get(d, *keys, default=None):\n    for k in keys:\n        d = d.get(k, {})\n    return d if d else default\n\n\nspr_runs = _get(experiment_data, \"num_epochs_tuning\", \"SPR_BENCH\", default={})\n\n# -------------- FIGURE 1 -------------------\ntry:\n    if spr_runs:\n        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n        for epochs_str, logs in spr_runs.items():\n            tr_loss = logs[\"losses\"][\"train\"]\n            val_loss = logs[\"losses\"][\"val\"]\n            epochs = range(1, len(tr_loss) + 1)\n            axes[0].plot(epochs, tr_loss, label=f\"{epochs_str}e\")\n            axes[1].plot(epochs, val_loss, label=f\"{epochs_str}e\")\n        axes[0].set_title(\"Left: Train Loss\")\n        axes[1].set_title(\"Right: Validation Loss\")\n        for ax in axes:\n            ax.set_xlabel(\"Epoch\")\n            ax.set_ylabel(\"Loss\")\n            ax.legend()\n        fig.suptitle(\"SPR_BENCH Training vs Validation Loss Curves\")\n        save_path = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# -------------- FIGURE 2 -------------------\ntry:\n    if spr_runs:\n        plt.figure(figsize=(6, 4))\n        for epochs_str, logs in spr_runs.items():\n            hwa = [m[\"hwa\"] for m in logs[\"metrics\"][\"val\"]]\n            epochs = range(1, len(hwa) + 1)\n            plt.plot(epochs, hwa, label=f\"{epochs_str}e\")\n        plt.title(\"SPR_BENCH Validation HWA Across Epochs\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HWA\")\n        plt.legend()\n        save_path = os.path.join(working_dir, \"SPR_BENCH_HWA_curves.png\")\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curves plot: {e}\")\n    plt.close()\n\n# -------------- FIGURE 3 -------------------\ntry:\n    if spr_runs:\n        best_hwa = {\n            int(k): max(m[\"hwa\"] for m in v[\"metrics\"][\"val\"])\n            for k, v in spr_runs.items()\n        }\n        xs, ys = zip(*sorted(best_hwa.items()))\n        plt.figure(figsize=(6, 4))\n        plt.bar([str(x) for x in xs], ys)\n        plt.title(\"SPR_BENCH Best HWA vs Max Epochs\")\n        plt.xlabel(\"Max Epochs\")\n        plt.ylabel(\"Best HWA\")\n        save_path = os.path.join(working_dir, \"SPR_BENCH_best_HWA_vs_epochs.png\")\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating summary bar plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ----------------------------------------------------\n# Load every experiment file that the system provided\n# ----------------------------------------------------\nexperiment_data_path_list = [\n    \"experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_9b13a95008444d0682d39565fc5fcd0a_proc_2991855/experiment_data.npy\",\n    \"experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ae2af866218b44dc9b3b4306849fd959_proc_2991858/experiment_data.npy\",\n    \"experiments/2025-08-15_22-25-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3344104bff8f4846b93d6f37175d1293_proc_2991852/experiment_data.npy\",\n]\n\nall_experiment_data = []\ntry:\n    for p in experiment_data_path_list:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p)\n        ed = np.load(full_path, allow_pickle=True).item()\n        all_experiment_data.append(ed)\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\n\n# Helper\ndef _get(d, *keys, default=None):\n    for k in keys:\n        d = d.get(k, {})\n    return d if d else default\n\n\n# ----------------------------------------------------\n# Aggregate across runs for SPR_BENCH\n# ----------------------------------------------------\nagg = {}  # dict[tuning_len] -> dict { 'train': [runs x T], 'val': [...], 'hwa': [...] }\nfor ed in all_experiment_data:\n    spr_runs = _get(ed, \"num_epochs_tuning\", \"SPR_BENCH\", default={})\n    if not spr_runs:\n        continue\n    for tuning_len, logs in spr_runs.items():\n        tr = np.asarray(logs[\"losses\"][\"train\"], dtype=float)\n        vl = np.asarray(logs[\"losses\"][\"val\"], dtype=float)\n        hwa = np.asarray([m[\"hwa\"] for m in logs[\"metrics\"][\"val\"]], dtype=float)\n        entry = agg.setdefault(tuning_len, {\"train\": [], \"val\": [], \"hwa\": []})\n        entry[\"train\"].append(tr)\n        entry[\"val\"].append(vl)\n        entry[\"hwa\"].append(hwa)\n\n# ----------------------------------------------------\n# Make sure all arrays in each group are same length\n# (trim to min length so we can average safely)\n# ----------------------------------------------------\nfor tun_len, d in agg.items():\n    for k in [\"train\", \"val\", \"hwa\"]:\n        if not d[k]:\n            continue\n        min_len = min(map(len, d[k]))\n        d[k] = np.stack([a[:min_len] for a in d[k]], axis=0)  # shape (R, T)\n\n# ----------------------------------------------------\n# Plot 1: Train & Val losses (mean \u00b1 SEM)\n# ----------------------------------------------------\ntry:\n    if agg:\n        fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n        for tun_len, d in sorted(agg.items(), key=lambda x: int(x[0])):\n            epochs = np.arange(1, d[\"train\"].shape[1] + 1)\n            # train\n            mean_tr = d[\"train\"].mean(axis=0)\n            sem_tr = d[\"train\"].std(axis=0, ddof=1) / np.sqrt(d[\"train\"].shape[0])\n            axes[0].plot(epochs, mean_tr, label=f\"{tun_len}e \u2013 mean\")\n            axes[0].fill_between(epochs, mean_tr - sem_tr, mean_tr + sem_tr, alpha=0.2)\n            # val\n            mean_val = d[\"val\"].mean(axis=0)\n            sem_val = d[\"val\"].std(axis=0, ddof=1) / np.sqrt(d[\"val\"].shape[0])\n            axes[1].plot(epochs, mean_val, label=f\"{tun_len}e \u2013 mean\")\n            axes[1].fill_between(\n                epochs, mean_val - sem_val, mean_val + sem_val, alpha=0.2\n            )\n        axes[0].set_title(\"Left: Train Loss (mean \u00b1 SEM)\")\n        axes[1].set_title(\"Right: Validation Loss (mean \u00b1 SEM)\")\n        for ax in axes:\n            ax.set_xlabel(\"Epoch\")\n            ax.set_ylabel(\"Loss\")\n            ax.legend()\n        fig.suptitle(\"SPR_BENCH Aggregated Loss Curves\")\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n        save_path = os.path.join(working_dir, \"SPR_BENCH_aggregated_loss_curves.png\")\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated loss plot: {e}\")\n    plt.close()\n\n# ----------------------------------------------------\n# Plot 2: HWA (mean \u00b1 SEM)\n# ----------------------------------------------------\ntry:\n    if agg:\n        plt.figure(figsize=(7, 4))\n        for tun_len, d in sorted(agg.items(), key=lambda x: int(x[0])):\n            epochs = np.arange(1, d[\"hwa\"].shape[1] + 1)\n            mean_hwa = d[\"hwa\"].mean(axis=0)\n            sem_hwa = d[\"hwa\"].std(axis=0, ddof=1) / np.sqrt(d[\"hwa\"].shape[0])\n            plt.plot(epochs, mean_hwa, label=f\"{tun_len}e \u2013 mean\")\n            plt.fill_between(epochs, mean_hwa - sem_hwa, mean_hwa + sem_hwa, alpha=0.2)\n        plt.title(\"SPR_BENCH Validation HWA (mean \u00b1 SEM)\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HWA\")\n        plt.legend()\n        save_path = os.path.join(working_dir, \"SPR_BENCH_aggregated_HWA_curves.png\")\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated HWA plot: {e}\")\n    plt.close()\n\n# ----------------------------------------------------\n# Plot 3: Best HWA per tuning length (mean \u00b1 SEM)\n# ----------------------------------------------------\ntry:\n    if agg:\n        xs, means, sems = [], [], []\n        for tun_len, d in sorted(agg.items(), key=lambda x: int(x[0])):\n            best_vals = d[\"hwa\"].max(axis=1)  # best per run\n            xs.append(str(tun_len))\n            means.append(best_vals.mean())\n            sems.append(best_vals.std(ddof=1) / np.sqrt(len(best_vals)))\n        plt.figure(figsize=(6, 4))\n        plt.bar(xs, means, yerr=sems, capsize=5, alpha=0.8)\n        plt.title(\"SPR_BENCH Best Validation HWA\\n(mean \u00b1 SEM across runs)\")\n        plt.xlabel(\"Max Epochs\")\n        plt.ylabel(\"Best HWA\")\n        save_path = os.path.join(working_dir, \"SPR_BENCH_aggregated_best_HWA.png\")\n        plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated best HWA bar plot: {e}\")\n    plt.close()\n\n# ----------------------------------------------------\n# Print out aggregated numeric arrays for quick inspection\n# ----------------------------------------------------\nfor tun_len, d in agg.items():\n    print(f\"\\n=== Tuning length {tun_len} epochs ===\")\n    print(\"Train loss mean (first 5):\", np.round(d[\"train\"].mean(axis=0)[:5], 4))\n    print(\"Val   loss mean (first 5):\", np.round(d[\"val\"].mean(axis=0)[:5], 4))\n    print(\"HWA        mean (first 5):\", np.round(d[\"hwa\"].mean(axis=0)[:5], 4))\n"], "plot_plan": ["We load the saved experiment_data.npy, loop through the four max-epoch configurations (5, 10, 20, 30) and extract per-epoch train/validation losses as well as the validation HWA.  \nFigure 1 (two sub-plots) shows training loss (left) and validation loss (right) curves for every configuration so we can inspect over-/under-fitting trends.  \nFigure 2 plots the validation HWA across epochs for the same runs, letting us see how quickly each setting converges and which reaches the highest score.  \nFigure 3 is a bar chart summarising the best HWA achieved by each max-epoch budget, giving a concise hyper-parameter tuning overview.  \nEach figure is created in an independent try-except block, saved under descriptive names inside working_dir, titled clearly with dataset and subplot descriptions, and all figures are closed after saving.  \nWe respect the \u201c\u22645 figures\u201d rule (only 3 are produced), use only the content found in experiment_data.npy, and avoid any external styling or fabricated data.  \nThe code starts with the mandated imports, defines working_dir, loads the data safely, generates the plots, prints nothing but potential error messages, and stays compact.", "We will first load the saved experiment_data.npy, extract the per-epoch training/validation losses and validation HWA for each learning-rate sweep, and then generate three concise figures (\u22645 total as required).  Figure 1 overlays training and validation loss curves for every learning-rate on the same axes so trends are directly comparable.  Figure 2 plots validation harmonic-weighted-accuracy (HWA) versus epoch for each learning-rate to visualize performance improvements.  Figure 3 summarizes the final-epoch HWA for every learning-rate as a bar chart, helping pick the best setting at a glance.  Each figure is wrapped in its own try-except block, titles explicitly mention \u201cSPR-BENCH\u201d (dataset type), and files are saved under working_dir with descriptive names.  We follow the plotting guidelines: standard matplotlib, closing each figure, plotting only existing data, and limiting to a maximum of three figures.  No synthetic values are introduced; only the contents of experiment_data.npy are used.", "We will first load the experiment_data.npy file and iterate over the four batch-size runs to gather their per-epoch logs. From those logs we extract (i) training loss, (ii) validation loss, and (iii) harmonic weighted accuracy (HWA). Next, three succinct figures are produced: (1) training/validation loss curves across epochs for every batch size, (2) HWA curves across epochs for every batch size, and (3) a bar chart that compares the final-epoch HWA achieved by each batch size. Each plot resides in an independent try-except block, is titled clearly, saved with descriptive names to working_dir, and then closed to avoid memory leakage. We restrict ourselves to these three plots so we remain well under the five-figure limit while still conveying the key training dynamics and final performance. The code obeys the required imports, path handling, and uses only the data present in experiment_data.npy\u2014no synthetic values are introduced. Finally, the script prints the path of every saved figure so users can easily locate them.", "We load experiment_data.npy, extract the training/validation losses and validation HWA per epoch for each dropout configuration, and aggregate them into simple lists. Four concise plots are generated: (1) training loss curves, (2) validation loss curves, (3) validation HWA curves across epochs (all dropouts overlaid), and (4) a bar chart summarizing the final-epoch HWA for every dropout value. Each figure is wrapped in its own try-except so one failure doesn\u2019t block others, titles include the dataset name and plot type, and every figure is saved to working_dir then closed. Only data found in experiment_data.npy are used\u2014no synthetic values. To limit redundancy we overlay all dropouts in the same curve plots, keeping total figures \u2264 5. After plotting, the script prints a small table of the final validation HWA so users can quickly see the best dropout rate. The code obeys the import order, creates the working directory if absent, and stays compact and readable. Finally, figures are named descriptively (e.g., \u201cSPR_BENCH_val_HWA_dropout.png\u201d).", "We first load the saved experiment_data.npy dictionary, which stores results for the SPR_BENCH dataset under the \u201cembedding_dim\u201d key. For each embedding dimension (32\u2006/\u200664\u2006/\u2006128\u2006/\u2006256) we extract the per-epoch training loss, validation loss and validation harmonic-weighted accuracy (HWA). We then create up to four figures: (1) training-loss curves for all embedding sizes, (2) validation-loss curves, (3) HWA curves, and (4) a bar chart showing the best (max) HWA attained by each embedding size. Every figure is wrapped in its own try-except block, given a clear title and saved in working_dir with descriptive filenames that include \u201cSPR_BENCH\u201d and the plot type. We always close each figure regardless of success or failure. No data are fabricated\u2014only values present in experiment_data.npy are plotted, and at most the three recorded epochs are displayed, satisfying the \u201c\u2264 5 figures\u201d rule. Finally, the script prints a short confirmation after each successful save so users know where to find the images.", "We will load experiment_data.npy, extract per-epoch train/validation losses and the harmonic weighted accuracy (HWA) recorded on the dev set for each hidden dimension. For readability we restrict ourselves to at most five figures: one joint bar chart comparing the final HWA for all hidden sizes and four individual figures (one per hidden size) that each contain two subplots\u2014left: loss curves, right: HWA curve. Every figure is wrapped in a try/except block; after saving we always close it. Plots are saved inside working_dir with descriptive file names that include the dataset (\u201cSPR_BENCH\u201d), the hidden dimension (if applicable), and the plot type. Finally we print a small summary that lists, for each hidden size, the best dev HWA achieved and highlights the overall best model. Only data present in experiment_data.npy are used; no synthetic data are generated.", "Load experiment_data.npy from the working directory, then iterate over the runs stored under experiment_data['weight_decay']['SPR_BENCH']['runs'].  For each weight-decay setting extract the per-epoch training/validation losses and validation metrics (SWA, CWA, HWA).  Using these, create three concise visualizations: (1) combined training/validation loss curves across epochs with a separate color per weight decay, (2) HWA curves across epochs, again color-coded by weight decay, and (3) a bar chart of the final-epoch HWA versus weight decay to illustrate the hyper-parameter sweep outcome.  Wrap each figure in its own try-except block to guard against missing keys; always save to \u201cworking\u201d and close the figure.  Limit the number of plotted epochs to those stored (\u22645) and never fabricate data.  Titles include dataset name and clear left-right subtitles when needed, filenames are descriptive.  All code is kept minimal and self-contained, starting with the required imports and directory setup, so running it in the same environment immediately produces the plots.  Finally, print a short confirmation after each successful save to help with debugging.", "We first load experiment_data.npy to access the three LSTM\u2013layer experiments. For every layer\u2010setting we extract the epoch-wise train/val losses and the validation metrics (SWA, CWA, HWA). We then generate, in separate try/except blocks, up to four figures: (1) a combined line plot showing train vs. val loss across epochs for all layer counts; (2) a combined line plot of HWA across epochs for all layer counts; (3) a bar chart comparing final-epoch HWA for each layer setting; and (4) a scatter plot of final-epoch SWA vs. CWA with point size proportional to the number of layers. Each figure is titled clearly, saved with a descriptive filename containing the dataset name \u201cSPR_BENCH\u201d, and the figure is closed afterward. All plotting code is wrapped in at most five try-except blocks, uses only data present in experiment_data.npy, limits itself to basic matplotlib calls, and stores the PNGs in working_dir.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": ["num_epochs", "learning_rate", "batch_size", "dropout_rate", "embedding_dim", "hidden_dim", "weight_decay", "num_lstm_layers", null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["We will load the saved NumPy dictionary, navigate to the \u201cnum_epochs_tuning \u2192\nSPR_BENCH \u2192 <epoch-setting> \u2192 logs\u201d structure, and for each epoch setting obtain\n(a) the last recorded training loss, (b) the lowest validation loss, and (c) the\nhighest validation shape-weighted accuracy, color-weighted accuracy, and\nharmonic weighted accuracy.   All results are printed in a clear, labelled\nfashion, with the dataset name announced first as required.", "The script will locate the NumPy file in the working directory, load it into\nmemory as a Python dictionary, and iterate over every learning-rate run stored\nunder experiment_data[\"learning_rate\"].   For each run (treated here as an\nindividual \u201cdataset\u201d), it will grab the last entry in the training/validation\nloss lists and the last entry in the validation metric list (which contains SWA,\nCWA, and HWA from the final epoch).   It then prints the dataset name followed\nby clearly labelled final metrics: training loss, validation loss, validation\nshape-weighted accuracy, validation color-weighted accuracy, and validation\nharmonic-weighted accuracy.   No execution guard or plotting code is used, so\nthe script runs immediately when executed.", "We will load the NumPy dictionary, iterate over the stored hyper-parameter runs,\nand for every dataset print the final (i.e., last-epoch) training loss,\nvalidation loss, validation shape-weighted accuracy, validation color-weighted\naccuracy, and validation harmonic-weighted accuracy. The script will execute\nimmediately on run and follow the naming requirements for each metric.", "The script will load the saved numpy dictionary, iterate over each dropout\nexperiment, and for the single dataset (SPR_BENCH) compute:   \u2022 the final train\nloss (last epoch),   \u2022 the best validation loss (minimum), and   \u2022 the best\nvalidation shape-weighted, color-weighted, and harmonic-weighted accuracies\n(maximum).   Each section begins by printing the dataset name followed by\nclearly labelled metric values.", "To analyze the stored results we load the experiment_data.npy file from the\nworking directory, iterate over every embedding-dimension entry, and for each of\nthe two datasets (\u201ctrain\u201d and \u201cvalidation\u201d) extract the list of per-epoch metric\ndictionaries.   For every metric we build the sequence of values across epochs,\nthen pick the \u201cbest\u201d value (minimum for losses, maximum for accuracy-type\nmetrics such as SWA, CWA, HWA).   The script then prints the dataset name\nfollowed by clearly-named metrics like \u201cTraining loss\u201d or \u201cValidation HWA\u201d\ntogether with their best values.   Everything runs immediately at import time\u2014no\nspecial main guard is used.", "The script will load the saved NumPy file, iterate over every hidden-dimension\nsetting inside the \u201cSPR_BENCH\u201d entry, fetch the final (last-epoch) training loss\nas well as the final validation loss, SWA, CWA and HWA, and print them with\nexplicit, descriptive names. It respects the required directory, prints the\ndataset name before its metrics, avoids an entry-point guard, and executes\nimmediately.", "The script will locate the numpy file in the \u201cworking\u201d directory, load it, and\niterate through the stored runs for the SPR_BENCH dataset.   For every weight-\ndecay run it extracts (1) the last training loss, (2) the lowest validation\nloss, and (3) the highest shape-weighted, color-weighted and harmonic-weighted\naccuracies.   Each metric is clearly labelled when printed, and the dataset name\nis shown before its corresponding results.   Everything is executed at import\ntime\u2014no `if __name__ == \"__main__\":` guard is used\u2014and no plots are produced.", "The script will load the saved NumPy dictionary, iterate over every LSTM-layer\nconfiguration, and for each configuration extract the final-epoch entries from\nthe stored lists of training and validation metrics.   For every configuration\nit will first print the configuration name, then separately print a block headed\n\u201ctraining dataset\u201d followed by the final training loss, and another block headed\n\u201cvalidation dataset\u201d followed by the final validation loss, shape-weighted\naccuracy, color-weighted accuracy, and harmonic-weighted accuracy.   Metric\nnames are spelled out explicitly to satisfy the formatting rules, and the code\nis written at global scope so it runs immediately when executed.", "We will load the saved NumPy dictionary, navigate to the \u201cnum_epochs_tuning \u2192\nSPR_BENCH \u2192 <epoch-setting> \u2192 logs\u201d structure, and for each epoch setting obtain\n(a) the last recorded training loss, (b) the lowest validation loss, and (c) the\nhighest validation shape-weighted accuracy, color-weighted accuracy, and\nharmonic weighted accuracy.   All results are printed in a clear, labelled\nfashion, with the dataset name announced first as required.", "We will load the saved NumPy dictionary, navigate to the \u201cnum_epochs_tuning \u2192\nSPR_BENCH \u2192 <epoch-setting> \u2192 logs\u201d structure, and for each epoch setting obtain\n(a) the last recorded training loss, (b) the lowest validation loss, and (c) the\nhighest validation shape-weighted accuracy, color-weighted accuracy, and\nharmonic weighted accuracy.   All results are printed in a clear, labelled\nfashion, with the dataset name announced first as required.", "We will load the saved NumPy dictionary, navigate to the \u201cnum_epochs_tuning \u2192\nSPR_BENCH \u2192 <epoch-setting> \u2192 logs\u201d structure, and for each epoch setting obtain\n(a) the last recorded training loss, (b) the lowest validation loss, and (c) the\nhighest validation shape-weighted accuracy, color-weighted accuracy, and\nharmonic weighted accuracy.   All results are printed in a clear, labelled\nfashion, with the dataset name announced first as required.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate the numpy file produced by the original training script\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nnpy_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(npy_path):\n    raise FileNotFoundError(f\"Could not locate experiment_data.npy at {npy_path}\")\n\nexperiment_data = np.load(npy_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# iterate over datasets (only SPR_BENCH is expected, but code is generic)\n# ------------------------------------------------------------------\nfor dataset_name, exp_dict in experiment_data.get(\"num_epochs_tuning\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n    # exp_dict maps epoch-setting (as str) -> logs dict\n    for epoch_setting_str, logs in exp_dict.items():\n        # ------------- extract losses -----------------\n        final_train_loss = (\n            logs[\"losses\"][\"train\"][-1] if logs[\"losses\"][\"train\"] else None\n        )\n        best_val_loss = min(logs[\"losses\"][\"val\"]) if logs[\"losses\"][\"val\"] else None\n\n        # ------------- extract validation metrics -----\n        val_metrics = logs[\"metrics\"][\"val\"]\n        # safeguard for empty list\n        if val_metrics:\n            best_val_swa = max(m[\"swa\"] for m in val_metrics)\n            best_val_cwa = max(m[\"cwa\"] for m in val_metrics)\n            best_val_hwa = max(m[\"hwa\"] for m in val_metrics)\n        else:\n            best_val_swa = best_val_cwa = best_val_hwa = None\n\n        # ------------- print nicely -------------------\n        print(f\"  Experiment with {epoch_setting_str} epochs\")\n        if final_train_loss is not None:\n            print(f\"    Final training loss: {final_train_loss:.6f}\")\n        if best_val_loss is not None:\n            print(f\"    Best validation loss: {best_val_loss:.6f}\")\n        if best_val_swa is not None:\n            print(f\"    Best validation shape-weighted accuracy: {best_val_swa:.6f}\")\n        if best_val_cwa is not None:\n            print(f\"    Best validation color-weighted accuracy: {best_val_cwa:.6f}\")\n        if best_val_hwa is not None:\n            print(f\"    Best validation harmonic weighted accuracy: {best_val_hwa:.6f}\")\n", "import os\nimport numpy as np\n\n# -------- locate experiment file --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\n# -------- load data --------\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# -------- iterate over learning-rate runs --------\nlr_runs = experiment_data.get(\"learning_rate\", {})\nfor dataset_name, run_dict in lr_runs.items():\n    print(f\"Dataset: {dataset_name}\")\n\n    # --- final / best values ---\n    train_losses = run_dict.get(\"losses\", {}).get(\"train\", [])\n    val_losses = run_dict.get(\"losses\", {}).get(\"val\", [])\n    train_final_loss = train_losses[-1] if train_losses else None\n    val_final_loss = val_losses[-1] if val_losses else None\n\n    val_metrics_list = run_dict.get(\"metrics\", {}).get(\"val\", [])\n    final_val_metrics = val_metrics_list[-1] if val_metrics_list else {}\n\n    swa = final_val_metrics.get(\"swa\", None)\n    cwa = final_val_metrics.get(\"cwa\", None)\n    hwa = final_val_metrics.get(\"hwa\", None)\n\n    # --- print metrics with explicit names ---\n    if train_final_loss is not None:\n        print(f\"  training loss: {train_final_loss:.6f}\")\n    if val_final_loss is not None:\n        print(f\"  validation loss: {val_final_loss:.6f}\")\n    if swa is not None:\n        print(f\"  validation shape-weighted accuracy: {swa:.6f}\")\n    if cwa is not None:\n        print(f\"  validation color-weighted accuracy: {cwa:.6f}\")\n    if hwa is not None:\n        print(f\"  validation harmonic-weighted accuracy: {hwa:.6f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\n# ---------- load ----------\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- traverse and report ----------\nfor hyperparam_group, datasets in experiment_data.items():  # e.g. \"batch_size\"\n    for dataset_name, runs in datasets.items():  # e.g. \"SPR_BENCH\"\n        print(f\"\\nDataset: {dataset_name}\")\n        for run_name, run_log in runs.items():  # e.g. \"bs32\", \"bs64\", ...\n            # gather final epoch values\n            final_train_loss = run_log[\"losses\"][\"train\"][-1]\n            final_val_loss = run_log[\"losses\"][\"val\"][-1]\n            final_val_metrics = run_log[\"metrics\"][\"val\"][-1]  # last epoch dict\n\n            swa = final_val_metrics[\"swa\"]\n            cwa = final_val_metrics[\"cwa\"]\n            hwa = final_val_metrics[\"hwa\"]\n\n            # print with explicit metric names\n            print(f\"  Run: {run_name}\")\n            print(f\"    training loss: {final_train_loss:.4f}\")\n            print(f\"    validation loss: {final_val_loss:.4f}\")\n            print(f\"    validation shape-weighted accuracy: {swa:.4f}\")\n            print(f\"    validation color-weighted accuracy: {cwa:.4f}\")\n            print(f\"    validation harmonic-weighted accuracy: {hwa:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\n# ---------- load ----------\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper ----------\ndef best(metric_list, key, mode=\"max\"):\n    \"\"\"Return best value (max or min) from list of dicts based on key.\"\"\"\n    if mode == \"max\":\n        return max(metric_list, key=lambda m: m[key])[key]\n    else:\n        return min(metric_list, key=lambda m: m[key])[key]\n\n\n# ---------- iterate and report ----------\nfor exp_tag, exp_content in experiment_data.items():\n    # only one dataset stored: 'SPR_BENCH'\n    dataset_name = \"SPR_BENCH\"\n    data = exp_content[dataset_name]\n\n    train_metrics = data[\"metrics\"][\"train\"]\n    val_metrics = data[\"metrics\"][\"val\"]\n\n    final_train_loss = train_metrics[-1][\"loss\"]\n    best_val_loss = best(val_metrics, \"loss\", mode=\"min\")\n    best_val_swa = best(val_metrics, \"swa\")\n    best_val_cwa = best(val_metrics, \"cwa\")\n    best_val_hwa = best(val_metrics, \"hwa\")\n\n    # ----- printing -----\n    print(f\"{dataset_name} - {exp_tag}\")\n    print(f\"final train loss: {final_train_loss:.4f}\")\n    print(f\"best validation loss: {best_val_loss:.4f}\")\n    print(f\"best validation shape weighted accuracy: {best_val_swa:.4f}\")\n    print(f\"best validation color weighted accuracy: {best_val_cwa:.4f}\")\n    print(f\"best validation harmonic weighted accuracy: {best_val_hwa:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# ------------------- locate experiment file -------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.exists(exp_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy at {exp_path}\")\n\n# ------------------- load data -------------------\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\nemb_results = experiment_data.get(\"embedding_dim\", {})\n\n\n# ------------------- helper to choose best value -------------------\ndef best_value(values, metric_key):\n    \"\"\"\n    Return the best value for a series of metric values.\n    For losses we want the minimum; for everything else the maximum.\n    \"\"\"\n    if \"loss\" in metric_key.lower():\n        return min(values)\n    return max(values)\n\n\n# ------------------- iterate and report -------------------\nfor emb_dim, result in emb_results.items():\n    print(f\"\\n===== Embedding dimension {emb_dim} =====\")\n\n    for split_key, split_readable in [(\"train\", \"Training\"), (\"val\", \"Validation\")]:\n        if split_key not in result[\"metrics\"]:\n            continue\n\n        print(f\"{split_readable} dataset:\")\n        metrics_over_epochs = result[\"metrics\"][split_key]\n\n        # Collect metric keys present (skip the 'epoch' field)\n        if not metrics_over_epochs:\n            print(\"  (no metric data)\")\n            continue\n        metric_names = [k for k in metrics_over_epochs[0].keys() if k != \"epoch\"]\n\n        for mname in metric_names:\n            values = [m[mname] for m in metrics_over_epochs if mname in m]\n            if not values:\n                continue\n            best_val = best_value(values, mname)\n            print(f\"  {split_readable} {mname.upper()}: {best_val:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate the experiment file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(exp_path):\n    raise FileNotFoundError(f\"Could not find experiment data at {exp_path}\")\n\n# ---------- load ----------\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ---------- iterate & report ----------\nfor hidden_dim, run_data in experiment_data.get(\"hidden_dim\", {}).items():\n    bench_data = run_data.get(\"SPR_BENCH\", {})\n    train_metrics = bench_data.get(\"metrics\", {}).get(\"train\", [])\n    val_metrics = bench_data.get(\"metrics\", {}).get(\"val\", [])\n\n    if not train_metrics or not val_metrics:\n        continue  # skip if anything is missing\n\n    final_train = train_metrics[-1]  # last epoch\n    final_val = val_metrics[-1]  # last epoch\n\n    print(f\"Dataset: SPR_BENCH   (hidden_dim = {hidden_dim})\")\n    print(f\"  final training loss: {final_train['loss']:.6f}\")\n    print(f\"  final validation loss: {final_val['loss']:.6f}\")\n    print(f\"  final validation SWA: {final_val['swa']:.6f}\")\n    print(f\"  final validation CWA: {final_val['cwa']:.6f}\")\n    print(f\"  final validation HWA: {final_val['hwa']:.6f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate experiment file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.exists(exp_file):\n    raise FileNotFoundError(f\"experiment_data.npy not found at {exp_file}\")\n\n# ---------- load ----------\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# ---------- parse & display ----------\nfor grouping_key, datasets in experiment_data.items():  # e.g., 'weight_decay'\n    for dataset_name, dataset_content in datasets.items():  # e.g., 'SPR_BENCH'\n        print(f\"\\nDataset: {dataset_name}\")\n        runs = dataset_content[\"runs\"]\n\n        for run_key, run_data in runs.items():  # e.g., '0.0', '1e-4', ...\n            print(f\"  Weight decay: {run_key}\")\n\n            # --- losses ---\n            final_train_loss = run_data[\"losses\"][\"train\"][-1]\n            best_val_loss = min(run_data[\"losses\"][\"val\"])\n\n            # --- metrics (validation) ---\n            val_metrics = run_data[\"metrics\"][\"val\"]\n            best_swa = max(m[\"swa\"] for m in val_metrics)\n            best_cwa = max(m[\"cwa\"] for m in val_metrics)\n            best_hwa = max(m[\"hwa\"] for m in val_metrics)\n\n            # --- pretty print ---\n            print(f\"    Training loss (final): {final_train_loss:.4f}\")\n            print(f\"    Validation loss (best): {best_val_loss:.4f}\")\n            print(f\"    Shape-weighted accuracy (best): {best_swa:.4f}\")\n            print(f\"    Color-weighted accuracy (best):  {best_cwa:.4f}\")\n            print(f\"    Harmonic-weighted accuracy (best): {best_hwa:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- working directory ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# ---------- load experiment data ----------\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\nnum_layers_dict = experiment_data.get(\"num_lstm_layers\", {})\n\nfor layer_cfg, layer_data in num_layers_dict.items():\n    print(f\"\\nConfiguration: {layer_cfg}\")\n\n    # ---- training metrics ----\n    train_metrics_list = layer_data[\"metrics\"][\"train\"]\n    if train_metrics_list:  # make sure list is not empty\n        final_train = train_metrics_list[-1]  # last epoch entry\n        print(\"training dataset:\")\n        print(f\"  training loss: {final_train['loss']:.6f}\")\n\n    # ---- validation metrics ----\n    val_metrics_list = layer_data[\"metrics\"][\"val\"]\n    if val_metrics_list:\n        final_val = val_metrics_list[-1]\n        print(\"validation dataset:\")\n        print(f\"  validation loss: {final_val['loss']:.6f}\")\n        print(f\"  shape weighted accuracy: {final_val['swa']:.6f}\")\n        print(f\"  color weighted accuracy: {final_val['cwa']:.6f}\")\n        print(f\"  harmonic weighted accuracy: {final_val['hwa']:.6f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate the numpy file produced by the original training script\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nnpy_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(npy_path):\n    raise FileNotFoundError(f\"Could not locate experiment_data.npy at {npy_path}\")\n\nexperiment_data = np.load(npy_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# iterate over datasets (only SPR_BENCH is expected, but code is generic)\n# ------------------------------------------------------------------\nfor dataset_name, exp_dict in experiment_data.get(\"num_epochs_tuning\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n    # exp_dict maps epoch-setting (as str) -> logs dict\n    for epoch_setting_str, logs in exp_dict.items():\n        # ------------- extract losses -----------------\n        final_train_loss = (\n            logs[\"losses\"][\"train\"][-1] if logs[\"losses\"][\"train\"] else None\n        )\n        best_val_loss = min(logs[\"losses\"][\"val\"]) if logs[\"losses\"][\"val\"] else None\n\n        # ------------- extract validation metrics -----\n        val_metrics = logs[\"metrics\"][\"val\"]\n        # safeguard for empty list\n        if val_metrics:\n            best_val_swa = max(m[\"swa\"] for m in val_metrics)\n            best_val_cwa = max(m[\"cwa\"] for m in val_metrics)\n            best_val_hwa = max(m[\"hwa\"] for m in val_metrics)\n        else:\n            best_val_swa = best_val_cwa = best_val_hwa = None\n\n        # ------------- print nicely -------------------\n        print(f\"  Experiment with {epoch_setting_str} epochs\")\n        if final_train_loss is not None:\n            print(f\"    Final training loss: {final_train_loss:.6f}\")\n        if best_val_loss is not None:\n            print(f\"    Best validation loss: {best_val_loss:.6f}\")\n        if best_val_swa is not None:\n            print(f\"    Best validation shape-weighted accuracy: {best_val_swa:.6f}\")\n        if best_val_cwa is not None:\n            print(f\"    Best validation color-weighted accuracy: {best_val_cwa:.6f}\")\n        if best_val_hwa is not None:\n            print(f\"    Best validation harmonic weighted accuracy: {best_val_hwa:.6f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate the numpy file produced by the original training script\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nnpy_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(npy_path):\n    raise FileNotFoundError(f\"Could not locate experiment_data.npy at {npy_path}\")\n\nexperiment_data = np.load(npy_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# iterate over datasets (only SPR_BENCH is expected, but code is generic)\n# ------------------------------------------------------------------\nfor dataset_name, exp_dict in experiment_data.get(\"num_epochs_tuning\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n    # exp_dict maps epoch-setting (as str) -> logs dict\n    for epoch_setting_str, logs in exp_dict.items():\n        # ------------- extract losses -----------------\n        final_train_loss = (\n            logs[\"losses\"][\"train\"][-1] if logs[\"losses\"][\"train\"] else None\n        )\n        best_val_loss = min(logs[\"losses\"][\"val\"]) if logs[\"losses\"][\"val\"] else None\n\n        # ------------- extract validation metrics -----\n        val_metrics = logs[\"metrics\"][\"val\"]\n        # safeguard for empty list\n        if val_metrics:\n            best_val_swa = max(m[\"swa\"] for m in val_metrics)\n            best_val_cwa = max(m[\"cwa\"] for m in val_metrics)\n            best_val_hwa = max(m[\"hwa\"] for m in val_metrics)\n        else:\n            best_val_swa = best_val_cwa = best_val_hwa = None\n\n        # ------------- print nicely -------------------\n        print(f\"  Experiment with {epoch_setting_str} epochs\")\n        if final_train_loss is not None:\n            print(f\"    Final training loss: {final_train_loss:.6f}\")\n        if best_val_loss is not None:\n            print(f\"    Best validation loss: {best_val_loss:.6f}\")\n        if best_val_swa is not None:\n            print(f\"    Best validation shape-weighted accuracy: {best_val_swa:.6f}\")\n        if best_val_cwa is not None:\n            print(f\"    Best validation color-weighted accuracy: {best_val_cwa:.6f}\")\n        if best_val_hwa is not None:\n            print(f\"    Best validation harmonic weighted accuracy: {best_val_hwa:.6f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate the numpy file produced by the original training script\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nnpy_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(npy_path):\n    raise FileNotFoundError(f\"Could not locate experiment_data.npy at {npy_path}\")\n\nexperiment_data = np.load(npy_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# iterate over datasets (only SPR_BENCH is expected, but code is generic)\n# ------------------------------------------------------------------\nfor dataset_name, exp_dict in experiment_data.get(\"num_epochs_tuning\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n    # exp_dict maps epoch-setting (as str) -> logs dict\n    for epoch_setting_str, logs in exp_dict.items():\n        # ------------- extract losses -----------------\n        final_train_loss = (\n            logs[\"losses\"][\"train\"][-1] if logs[\"losses\"][\"train\"] else None\n        )\n        best_val_loss = min(logs[\"losses\"][\"val\"]) if logs[\"losses\"][\"val\"] else None\n\n        # ------------- extract validation metrics -----\n        val_metrics = logs[\"metrics\"][\"val\"]\n        # safeguard for empty list\n        if val_metrics:\n            best_val_swa = max(m[\"swa\"] for m in val_metrics)\n            best_val_cwa = max(m[\"cwa\"] for m in val_metrics)\n            best_val_hwa = max(m[\"hwa\"] for m in val_metrics)\n        else:\n            best_val_swa = best_val_cwa = best_val_hwa = None\n\n        # ------------- print nicely -------------------\n        print(f\"  Experiment with {epoch_setting_str} epochs\")\n        if final_train_loss is not None:\n            print(f\"    Final training loss: {final_train_loss:.6f}\")\n        if best_val_loss is not None:\n            print(f\"    Best validation loss: {best_val_loss:.6f}\")\n        if best_val_swa is not None:\n            print(f\"    Best validation shape-weighted accuracy: {best_val_swa:.6f}\")\n        if best_val_cwa is not None:\n            print(f\"    Best validation color-weighted accuracy: {best_val_cwa:.6f}\")\n        if best_val_hwa is not None:\n            print(f\"    Best validation harmonic weighted accuracy: {best_val_hwa:.6f}\")\n", ""], "parse_term_out": ["['Dataset: SPR_BENCH', '\\n', '  Experiment with 5 epochs', '\\n', '    Final\ntraining loss: 0.033764', '\\n', '    Best validation loss: 0.033342', '\\n', '\nBest validation shape-weighted accuracy: 0.991803', '\\n', '    Best validation\ncolor-weighted accuracy: 0.992557', '\\n', '    Best validation harmonic weighted\naccuracy: 0.992180', '\\n', '  Experiment with 10 epochs', '\\n', '    Final\ntraining loss: 0.004489', '\\n', '    Best validation loss: 0.014087', '\\n', '\nBest validation shape-weighted accuracy: 0.996105', '\\n', '    Best validation\ncolor-weighted accuracy: 0.996400', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996253', '\\n', '  Experiment with 20 epochs', '\\n', '    Final\ntraining loss: 0.000387', '\\n', '    Best validation loss: 0.012123', '\\n', '\nBest validation shape-weighted accuracy: 0.996221', '\\n', '    Best validation\ncolor-weighted accuracy: 0.996461', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996341', '\\n', '  Experiment with 30 epochs', '\\n', '    Final\ntraining loss: 0.002015', '\\n', '    Best validation loss: 0.012921', '\\n', '\nBest validation shape-weighted accuracy: 0.996919', '\\n', '    Best validation\ncolor-weighted accuracy: 0.997072', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996995', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Dataset: lr_0.0005', '\\n', '  training loss: 0.063297', '\\n', '  validation\nloss: 0.055856', '\\n', '  validation shape-weighted accuracy: 0.983490', '\\n', '\nvalidation color-weighted accuracy: 0.984199', '\\n', '  validation harmonic-\nweighted accuracy: 0.983844', '\\n', 'Dataset: lr_0.001', '\\n', '  training loss:\n0.026932', '\\n', '  validation loss: 0.026869', '\\n', '  validation shape-\nweighted accuracy: 0.994187', '\\n', '  validation color-weighted accuracy:\n0.994814', '\\n', '  validation harmonic-weighted accuracy: 0.994500', '\\n',\n'Dataset: lr_0.002', '\\n', '  training loss: 0.012018', '\\n', '  validation\nloss: 0.018733', '\\n', '  validation shape-weighted accuracy: 0.995291', '\\n', '\nvalidation color-weighted accuracy: 0.995546', '\\n', '  validation harmonic-\nweighted accuracy: 0.995419', '\\n', 'Dataset: lr_0.003', '\\n', '  training loss:\n0.004596', '\\n', '  validation loss: 0.007537', '\\n', '  validation shape-\nweighted accuracy: 0.997558', '\\n', '  validation color-weighted accuracy:\n0.997682', '\\n', '  validation harmonic-weighted accuracy: 0.997620', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Run: bs32', '\\n', '    training loss: 0.0067',\n'\\n', '    validation loss: 0.0101', '\\n', '    validation shape-weighted\naccuracy: 0.9959', '\\n', '    validation color-weighted accuracy: 0.9963', '\\n',\n'    validation harmonic-weighted accuracy: 0.9961', '\\n', '  Run: bs64', '\\n',\n'    training loss: 0.0161', '\\n', '    validation loss: 0.0181', '\\n', '\nvalidation shape-weighted accuracy: 0.9948', '\\n', '    validation color-\nweighted accuracy: 0.9954', '\\n', '    validation harmonic-weighted accuracy:\n0.9951', '\\n', '  Run: bs128', '\\n', '    training loss: 0.0288', '\\n', '\nvalidation loss: 0.0284', '\\n', '    validation shape-weighted accuracy:\n0.9941', '\\n', '    validation color-weighted accuracy: 0.9948', '\\n', '\nvalidation harmonic-weighted accuracy: 0.9944', '\\n', '  Run: bs256', '\\n', '\ntraining loss: 0.0577', '\\n', '    validation loss: 0.0472', '\\n', '\nvalidation shape-weighted accuracy: 0.9878', '\\n', '    validation color-\nweighted accuracy: 0.9880', '\\n', '    validation harmonic-weighted accuracy:\n0.9879', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH - dropout_0.0', '\\n', 'final train loss: 0.0338', '\\n', 'best\nvalidation loss: 0.0333', '\\n', 'best validation shape weighted accuracy:\n0.9918', '\\n', 'best validation color weighted accuracy: 0.9926', '\\n', 'best\nvalidation harmonic weighted accuracy: 0.9922\\n', '\\n', 'SPR_BENCH -\ndropout_0.1', '\\n', 'final train loss: 0.0313', '\\n', 'best validation loss:\n0.0323', '\\n', 'best validation shape weighted accuracy: 0.9905', '\\n', 'best\nvalidation color weighted accuracy: 0.9913', '\\n', 'best validation harmonic\nweighted accuracy: 0.9908\\n', '\\n', 'SPR_BENCH - dropout_0.3', '\\n', 'final\ntrain loss: 0.0361', '\\n', 'best validation loss: 0.0329', '\\n', 'best\nvalidation shape weighted accuracy: 0.9945', '\\n', 'best validation color\nweighted accuracy: 0.9951', '\\n', 'best validation harmonic weighted accuracy:\n0.9948\\n', '\\n', 'SPR_BENCH - dropout_0.5', '\\n', 'final train loss: 0.0408',\n'\\n', 'best validation loss: 0.0345', '\\n', 'best validation shape weighted\naccuracy: 0.9926', '\\n', 'best validation color weighted accuracy: 0.9929',\n'\\n', 'best validation harmonic weighted accuracy: 0.9928\\n', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['\\n===== Embedding dimension 32 =====', '\\n', 'Training dataset:', '\\n', '\nTraining LOSS: 0.0921', '\\n', 'Validation dataset:', '\\n', '  Validation SWA:\n0.9812', '\\n', '  Validation CWA: 0.9815', '\\n', '  Validation HWA: 0.9813',\n'\\n', '  Validation LOSS: 0.0752', '\\n', '\\n===== Embedding dimension 64 =====',\n'\\n', 'Training dataset:', '\\n', '  Training LOSS: 0.0581', '\\n', 'Validation\ndataset:', '\\n', '  Validation SWA: 0.9903', '\\n', '  Validation CWA: 0.9907',\n'\\n', '  Validation HWA: 0.9905', '\\n', '  Validation LOSS: 0.0460', '\\n',\n'\\n===== Embedding dimension 128 =====', '\\n', 'Training dataset:', '\\n', '\nTraining LOSS: 0.0527', '\\n', 'Validation dataset:', '\\n', '  Validation SWA:\n0.9862', '\\n', '  Validation CWA: 0.9871', '\\n', '  Validation HWA: 0.9867',\n'\\n', '  Validation LOSS: 0.0417', '\\n', '\\n===== Embedding dimension 256\n=====', '\\n', 'Training dataset:', '\\n', '  Training LOSS: 0.0362', '\\n',\n'Validation dataset:', '\\n', '  Validation SWA: 0.9905', '\\n', '  Validation\nCWA: 0.9913', '\\n', '  Validation HWA: 0.9909', '\\n', '  Validation LOSS:\n0.0311', '\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH   (hidden_dim = 64)', '\\n', '  final training loss:\n0.043290', '\\n', '  final validation loss: 0.043110', '\\n', '  final validation\nSWA: 0.991106', '\\n', '  final validation CWA: 0.991764', '\\n', '  final\nvalidation HWA: 0.991435', '\\n', 'Dataset: SPR_BENCH   (hidden_dim = 128)',\n'\\n', '  final training loss: 0.031902', '\\n', '  final validation loss:\n0.028635', '\\n', '  final validation SWA: 0.993838', '\\n', '  final validation\nCWA: 0.994387', '\\n', '  final validation HWA: 0.994112', '\\n', 'Dataset:\nSPR_BENCH   (hidden_dim = 256)', '\\n', '  final training loss: 0.015911', '\\n',\n'  final validation loss: 0.019242', '\\n', '  final validation SWA: 0.993547',\n'\\n', '  final validation CWA: 0.994448', '\\n', '  final validation HWA:\n0.993998', '\\n', 'Dataset: SPR_BENCH   (hidden_dim = 512)', '\\n', '  final\ntraining loss: 0.006718', '\\n', '  final validation loss: 0.009059', '\\n', '\nfinal validation SWA: 0.996628', '\\n', '  final validation CWA: 0.996889', '\\n',\n'  final validation HWA: 0.996758', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Weight decay: 0.0', '\\n', '    Training loss\n(final): 0.0338', '\\n', '    Validation loss (best): 0.0333', '\\n', '    Shape-\nweighted accuracy (best): 0.9918', '\\n', '    Color-weighted accuracy (best):\n0.9926', '\\n', '    Harmonic-weighted accuracy (best): 0.9922', '\\n', '  Weight\ndecay: 1e-06', '\\n', '    Training loss (final): 0.0296', '\\n', '    Validation\nloss (best): 0.0306', '\\n', '    Shape-weighted accuracy (best): 0.9912', '\\n',\n'    Color-weighted accuracy (best):  0.9920', '\\n', '    Harmonic-weighted\naccuracy (best): 0.9916', '\\n', '  Weight decay: 1e-05', '\\n', '    Training\nloss (final): 0.0318', '\\n', '    Validation loss (best): 0.0329', '\\n', '\nShape-weighted accuracy (best): 0.9942', '\\n', '    Color-weighted accuracy\n(best):  0.9951', '\\n', '    Harmonic-weighted accuracy (best): 0.9946', '\\n', '\nWeight decay: 0.0001', '\\n', '    Training loss (final): 0.0357', '\\n', '\nValidation loss (best): 0.0326', '\\n', '    Shape-weighted accuracy (best):\n0.9924', '\\n', '    Color-weighted accuracy (best):  0.9930', '\\n', '\nHarmonic-weighted accuracy (best): 0.9927', '\\n', '  Weight decay: 0.001', '\\n',\n'    Training loss (final): 0.1430', '\\n', '    Validation loss (best): 0.1386',\n'\\n', '    Shape-weighted accuracy (best): 0.9582', '\\n', '    Color-weighted\naccuracy (best):  0.9562', '\\n', '    Harmonic-weighted accuracy (best):\n0.9572', '\\n', '  Weight decay: 0.01', '\\n', '    Training loss (final):\n0.2068', '\\n', '    Validation loss (best): 0.2076', '\\n', '    Shape-weighted\naccuracy (best): 0.9373', '\\n', '    Color-weighted accuracy (best):  0.9350',\n'\\n', '    Harmonic-weighted accuracy (best): 0.9361', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['\\nConfiguration: layers_1', '\\n', 'training dataset:', '\\n', '  training loss:\n0.030832', '\\n', 'validation dataset:', '\\n', '  validation loss: 0.028873',\n'\\n', '  shape weighted accuracy: 0.992966', '\\n', '  color weighted accuracy:\n0.993594', '\\n', '  harmonic weighted accuracy: 0.993280', '\\n',\n'\\nConfiguration: layers_2', '\\n', 'training dataset:', '\\n', '  training loss:\n0.017094', '\\n', 'validation dataset:', '\\n', '  validation loss: 0.013957',\n'\\n', '  shape weighted accuracy: 0.995756', '\\n', '  color weighted accuracy:\n0.996095', '\\n', '  harmonic weighted accuracy: 0.995926', '\\n',\n'\\nConfiguration: layers_3', '\\n', 'training dataset:', '\\n', '  training loss:\n0.019071', '\\n', 'validation dataset:', '\\n', '  validation loss: 0.014923',\n'\\n', '  shape weighted accuracy: 0.995349', '\\n', '  color weighted accuracy:\n0.995851', '\\n', '  harmonic weighted accuracy: 0.995600', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', '  Experiment with 5 epochs', '\\n', '    Final\ntraining loss: 0.033764', '\\n', '    Best validation loss: 0.033342', '\\n', '\nBest validation shape-weighted accuracy: 0.991803', '\\n', '    Best validation\ncolor-weighted accuracy: 0.992557', '\\n', '    Best validation harmonic weighted\naccuracy: 0.992180', '\\n', '  Experiment with 10 epochs', '\\n', '    Final\ntraining loss: 0.004489', '\\n', '    Best validation loss: 0.014087', '\\n', '\nBest validation shape-weighted accuracy: 0.996105', '\\n', '    Best validation\ncolor-weighted accuracy: 0.996400', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996253', '\\n', '  Experiment with 20 epochs', '\\n', '    Final\ntraining loss: 0.000387', '\\n', '    Best validation loss: 0.012123', '\\n', '\nBest validation shape-weighted accuracy: 0.996221', '\\n', '    Best validation\ncolor-weighted accuracy: 0.996461', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996341', '\\n', '  Experiment with 30 epochs', '\\n', '    Final\ntraining loss: 0.002015', '\\n', '    Best validation loss: 0.012921', '\\n', '\nBest validation shape-weighted accuracy: 0.996919', '\\n', '    Best validation\ncolor-weighted accuracy: 0.997072', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996995', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Dataset: SPR_BENCH', '\\n', '  Experiment with 5 epochs', '\\n', '    Final\ntraining loss: 0.033764', '\\n', '    Best validation loss: 0.033342', '\\n', '\nBest validation shape-weighted accuracy: 0.991803', '\\n', '    Best validation\ncolor-weighted accuracy: 0.992557', '\\n', '    Best validation harmonic weighted\naccuracy: 0.992180', '\\n', '  Experiment with 10 epochs', '\\n', '    Final\ntraining loss: 0.004489', '\\n', '    Best validation loss: 0.014087', '\\n', '\nBest validation shape-weighted accuracy: 0.996105', '\\n', '    Best validation\ncolor-weighted accuracy: 0.996400', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996253', '\\n', '  Experiment with 20 epochs', '\\n', '    Final\ntraining loss: 0.000387', '\\n', '    Best validation loss: 0.012123', '\\n', '\nBest validation shape-weighted accuracy: 0.996221', '\\n', '    Best validation\ncolor-weighted accuracy: 0.996461', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996341', '\\n', '  Experiment with 30 epochs', '\\n', '    Final\ntraining loss: 0.002015', '\\n', '    Best validation loss: 0.012921', '\\n', '\nBest validation shape-weighted accuracy: 0.996919', '\\n', '    Best validation\ncolor-weighted accuracy: 0.997072', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996995', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Dataset: SPR_BENCH', '\\n', '  Experiment with 5 epochs', '\\n', '    Final\ntraining loss: 0.033764', '\\n', '    Best validation loss: 0.033342', '\\n', '\nBest validation shape-weighted accuracy: 0.991803', '\\n', '    Best validation\ncolor-weighted accuracy: 0.992557', '\\n', '    Best validation harmonic weighted\naccuracy: 0.992180', '\\n', '  Experiment with 10 epochs', '\\n', '    Final\ntraining loss: 0.004489', '\\n', '    Best validation loss: 0.014087', '\\n', '\nBest validation shape-weighted accuracy: 0.996105', '\\n', '    Best validation\ncolor-weighted accuracy: 0.996400', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996253', '\\n', '  Experiment with 20 epochs', '\\n', '    Final\ntraining loss: 0.000387', '\\n', '    Best validation loss: 0.012123', '\\n', '\nBest validation shape-weighted accuracy: 0.996221', '\\n', '    Best validation\ncolor-weighted accuracy: 0.996461', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996341', '\\n', '  Experiment with 30 epochs', '\\n', '    Final\ntraining loss: 0.002015', '\\n', '    Best validation loss: 0.012921', '\\n', '\nBest validation shape-weighted accuracy: 0.996919', '\\n', '    Best validation\ncolor-weighted accuracy: 0.997072', '\\n', '    Best validation harmonic weighted\naccuracy: 0.996995', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
