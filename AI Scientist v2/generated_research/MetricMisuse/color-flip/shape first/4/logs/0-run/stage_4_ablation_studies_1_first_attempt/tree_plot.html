<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 6], [0, 7], [0, 4], [0, 2], [0, 5], [0, 8], [0, 3], [0, 1]], "layout": [[0.5, 0.0], [0.0, 1.0], [0.14285714285714285, 1.0], [0.2857142857142857, 1.0], [0.42857142857142855, 1.0], [0.5714285714285714, 1.0], [0.7142857142857143, 1.0], [0.8571428571428571, 1.0], [1.0, 1.0]], "plan": ["Hyperparam tuning name: epochs. We explore the \u201cepochs\u201d hyper-parameter by\ntraining several identical LSTM models for 5, 10, 20 and 30 epochs, logging\ntrain/validation loss and HWA after every epoch.   Each epoch\u2010setting gets its\nown entry in experiment_data['epochs']['SPR_BENCH'] so results are easy to\ncompare.   The script is completely self-contained: it builds/loads the data,\ntrains, evaluates, stores everything in experiment_data.npy and can run on CPU\nor GPU.", "Ablation name: Bag-of-Embeddings (Order-Agnostic) Classifier. The solution keeps\nthe original data-loading, metrics and training pipeline intact, introduces a\nBag-of-Embeddings (order-agnostic) classifier, and logs results for both the\noriginal LSTM and the new ablation under a unified `experiment_data` structure\nbefore persisting everything to `experiment_data.npy`.", "Ablation name: Multi-Synthetic-Dataset Generalization Ablation. We generate\nthree distinct synthetic datasets, each with its own shape/color vocabularies,\nlength distribution and binary-label rule.   For every dataset we \u2460 build a\nseparate vocabulary, \u2461 train one LSTM for 10 epochs, \u2462 record in-domain learning\ncurves, and \u2463 evaluate the trained model on the dev splits of all other datasets\n(cross-domain).  All plottable information (losses, metrics, predictions, etc.)\nis stored in the required experiment_data structure and saved as\nexperiment_data.npy.", "Ablation name: Factorized Shape-and-Color Embeddings. We keep the original data\npipeline and metrics, but extend the dataset so every token is split into its\nshape-character (A\u2013D) and color-character (a\u2013d) and encoded separately. Two\narchitectures are trained: the baseline LSTM with one embedding table over whole\ntokens and the factorized LSTM whose input vector is the sum of a shape-\nembedding and a color-embedding. Both models are trained for a small sweep of\nepochs and the usual losses and weighted accuracies are logged. Results are\nstored in a single experiment_data dictionary under the keys \"baseline\" and\n\"factorized\" and finally dumped to experiment_data.npy for later plotting.", "Ablation name: Padding-Mask Removal Ablation. The solution keeps the original\npipeline (data loading, metrics, etc.) and introduces a second LSTM variant that\nreceives zero-padded sequences directly, omitting the `pack_padded_sequence`\nmasking step. Both the length-aware baseline and the padding-mask-removal model\nare trained for several epoch settings, and their complete training records are\nstored in an `experiment_data` dictionary that follows the required structure\nand is saved to `experiment_data.npy`.", "Ablation name: Frozen-Embedding Ablation. The solution extends the original\nscript by introducing a `freeze_emb` flag in the training function. When set to\n`True`, the embedding matrix\u2019s gradients are disabled\n(`model.emb.weight.requires_grad = False`), implementing the Frozen-Embedding\nablation. We run the same epoch sweep for both the baseline and the frozen-\nembedding configurations, gather losses/metrics, and save everything in the\nrequired `experiment_data.npy` file under the keys `\"baseline\"` and\n`\"frozen_emb\"` for easy comparison.", "Ablation name: Shape-Color Split Tokenization Ablation. We keep the overall\npipeline identical to the baseline but change the tokenizer so every symbol \u201cAa\u201d\nbecomes two consecutive tokens \u201cA a\u201d.   Consequently, the vocabulary is now\ncharacter-level (capital letters for shapes and lower-case letters for colours)\nwhile the metrics continue to look at the untouched raw sequence, so they do not\nhave to be modified.   All loaders, model, training loop and hyper-parameter\nsweep stay unchanged; we only rebuild the vocabulary, adapt `encode_sequence`,\nand store the results under the ablation name `shape_color_split`.", "Ablation name: Token-Order Randomization Ablation. The solution adds a\ntraining\u2013time variant of the dataset that shuffles the token order inside every\nsequence (while keeping validation/test intact). Two train loaders are\nconstructed: one for the unchanged baseline and one with internal shuffling. We\ntrain both models for each epoch-count sweep, store all losses/metrics, and\nfinally save everything in a single experiment_data.npy file under the keys\n'baseline' and 'token_order_randomization'.", "Ablation name: Bidirectional LSTM Ablation. We duplicate the baseline pipeline\nbut add a second encoder variant whose nn.LSTM is bidirectional.  Per direction\nwe keep the same hidden size (128), so the concatenated final state fed to the\nclassifier has size 256.  We train both the original unidirectional and the new\nbidirectional models for several epoch settings, logging identical data into a\nunified experiment_data dict.  Everything is self-contained and saved to\n\u2018experiment_data.npy\u2019."], "code": ["import os, random, pathlib, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import Dataset as HFDataset, DatasetDict\n\n# ----------------- experiment data dict -----------------\nexperiment_data = {\n    \"epochs\": {\"SPR_BENCH\": {}}  # hyper-parameter we sweep  # dataset name\n}\n\n# ----------------- device & seeds -----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nrandom.seed(42)\nnp.random.seed(42)\nprint(f\"Using device: {device}\")\n\n\n# ----------------- helper metrics -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa + 1e-12)\n\n\n# ----------------- data loading -----------------\ndef load_or_create_dataset():\n    root = pathlib.Path(\"SPR_BENCH\")\n    if root.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(root)\n\n    # fallback tiny synthetic set\n    def gen_row(_id):\n        length = random.randint(4, 9)\n        shapes, colors = \"ABCD\", \"abcd\"\n        seq = \" \".join(\n            random.choice(shapes) + random.choice(colors) for _ in range(length)\n        )\n        return {\"id\": _id, \"sequence\": seq, \"label\": int(length % 2)}\n\n    train_rows = [gen_row(i) for i in range(600)]\n    dev_rows = [gen_row(1000 + i) for i in range(200)]\n    test_rows = [gen_row(2000 + i) for i in range(200)]\n    return DatasetDict(\n        {\n            \"train\": HFDataset.from_list(train_rows),\n            \"dev\": HFDataset.from_list(dev_rows),\n            \"test\": HFDataset.from_list(test_rows),\n        }\n    )\n\n\nspr = load_or_create_dataset()\nprint({k: len(v) for k, v in spr.items()})\n\n# ----------------- vocabulary -----------------\nall_text = \" \".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text.split()))\ntok2idx = {tok: i + 2 for i, tok in enumerate(vocab)}  # 0 PAD, 1 UNK\ntok2idx[\"<PAD>\"], tok2idx[\"<UNK>\"] = 0, 1\nidx2tok = {i: t for t, i in tok2idx.items()}\nvocab_size = len(tok2idx)\nprint(f\"Vocab size: {vocab_size}\")\n\n\ndef encode_sequence(seq):\n    return [tok2idx.get(tok, 1) for tok in seq.strip().split()]\n\n\n# ----------------- torch dataset -----------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs, self.labels = hf_split[\"sequence\"], hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"x\": torch.tensor(encode_sequence(self.seqs[idx]), dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    xs = [b[\"x\"] for b in batch]\n    lens = [len(x) for x in xs]\n    maxlen = max(lens)\n    xs_pad = torch.zeros(len(xs), maxlen, dtype=torch.long)\n    for i, x in enumerate(xs):\n        xs_pad[i, : len(x)] = x\n    ys = torch.stack([b[\"y\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    return {\n        \"x\": xs_pad.to(device),\n        \"len\": torch.tensor(lens, dtype=torch.long).to(device),\n        \"y\": ys.to(device),\n        \"raw_seq\": raw,\n    }\n\n\nbatch_size = 64\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\nn_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Num classes: {n_classes}\")\n\n\n# ----------------- model -----------------\nclass LSTMClassifier(nn.Module):\n    def __init__(self, vocab, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n        self.fc = nn.Linear(hid, n_out)\n\n    def forward(self, x, lengths):\n        em = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            em, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        return self.fc(h[-1])\n\n\n# ----------------- train / evaluate one run -----------------\ndef run_training(num_epochs):\n    model = LSTMClassifier(vocab_size, n_out=n_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n    run_rec = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    for ep in range(1, num_epochs + 1):\n        model.train()\n        tloss = 0.0\n        for batch in train_loader:\n            optim.zero_grad()\n            out = model(batch[\"x\"], batch[\"len\"])\n            loss = criterion(out, batch[\"y\"])\n            loss.backward()\n            optim.step()\n            tloss += loss.item() * batch[\"y\"].size(0)\n        train_loss = tloss / len(train_loader.dataset)\n\n        # eval\n        model.eval()\n        vloss, all_seq, y_true, y_pred = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                out = model(batch[\"x\"], batch[\"len\"])\n                loss = criterion(out, batch[\"y\"])\n                vloss += loss.item() * batch[\"y\"].size(0)\n                preds = torch.argmax(out, 1).cpu().tolist()\n                y_pred.extend(preds)\n                y_true.extend(batch[\"y\"].cpu().tolist())\n                all_seq.extend(batch[\"raw_seq\"])\n        val_loss = vloss / len(dev_loader.dataset)\n        swa = shape_weighted_accuracy(all_seq, y_true, y_pred)\n        cwa = color_weighted_accuracy(all_seq, y_true, y_pred)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n\n        # record\n        run_rec[\"losses\"][\"train\"].append(train_loss)\n        run_rec[\"losses\"][\"val\"].append(val_loss)\n        run_rec[\"metrics\"][\"val\"].append(hwa)\n        run_rec[\"predictions\"].append(y_pred)\n        run_rec[\"ground_truth\"].append(y_true)\n        run_rec[\"timestamps\"].append(time.time())\n        print(\n            f\"Epochs={num_epochs} | Ep {ep}: tr_loss={train_loss:.4f} val_loss={val_loss:.4f} HWA={hwa:.3f}\"\n        )\n    return run_rec\n\n\n# ----------------- hyper-parameter sweep -----------------\nepoch_options = [5, 10, 20, 30]\nfor e in epoch_options:\n    print(f\"\\n=== Training for {e} epochs ===\")\n    experiment_data[\"epochs\"][\"SPR_BENCH\"][str(e)] = run_training(e)\n\n# ----------------- save -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, random, pathlib, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import Dataset as HFDataset, DatasetDict\n\n# ---------- experiment data dict ----------\nexperiment_data = {\n    \"LSTM\": {\"SPR_BENCH\": {}},\n    \"BOE\": {\"SPR_BENCH\": {}},  # Bag-of-Embeddings ablation\n}\n\n# ---------- device & seeds ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nrandom.seed(42)\nnp.random.seed(42)\nprint(f\"Using device: {device}\")\n\n\n# ---------- helper metrics ----------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa + 1e-12)\n\n\n# ---------- data loading ----------\ndef load_or_create_dataset():\n    root = pathlib.Path(\"SPR_BENCH\")\n    if root.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(root)\n    shapes, colors = \"ABCD\", \"abcd\"\n\n    def gen_row(_id):\n        length = random.randint(4, 9)\n        seq = \" \".join(\n            random.choice(shapes) + random.choice(colors) for _ in range(length)\n        )\n        return {\"id\": _id, \"sequence\": seq, \"label\": int(length % 2)}\n\n    return DatasetDict(\n        {\n            \"train\": HFDataset.from_list([gen_row(i) for i in range(600)]),\n            \"dev\": HFDataset.from_list([gen_row(1_000 + i) for i in range(200)]),\n            \"test\": HFDataset.from_list([gen_row(2_000 + i) for i in range(200)]),\n        }\n    )\n\n\nspr = load_or_create_dataset()\nprint({k: len(v) for k, v in spr.items()})\n\n# ---------- vocabulary ----------\nall_text = \" \".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text.split()))\ntok2idx = {tok: i + 2 for i, tok in enumerate(vocab)}\ntok2idx[\"<PAD>\"], tok2idx[\"<UNK>\"] = 0, 1\nidx2tok = {i: t for t, i in tok2idx.items()}\nvocab_size = len(tok2idx)\nprint(\"Vocab size:\", vocab_size)\n\n\ndef encode_sequence(seq):\n    return [tok2idx.get(tok, 1) for tok in seq.strip().split()]\n\n\n# ---------- torch dataset ----------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs, self.labels = hf_split[\"sequence\"], hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"x\": torch.tensor(encode_sequence(self.seqs[idx]), dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    xs = [b[\"x\"] for b in batch]\n    lens = [len(x) for x in xs]\n    maxlen = max(lens)\n    xs_pad = torch.zeros(len(xs), maxlen, dtype=torch.long)\n    for i, x in enumerate(xs):\n        xs_pad[i, : len(x)] = x\n    ys = torch.stack([b[\"y\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    return {\n        \"x\": xs_pad.to(device),\n        \"len\": torch.tensor(lens, dtype=torch.long).to(device),\n        \"y\": ys.to(device),\n        \"raw_seq\": raw,\n    }\n\n\nbatch_size = 64\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\nn_classes = len(set(spr[\"train\"][\"label\"]))\nprint(\"Num classes:\", n_classes)\n\n\n# ---------- models ----------\nclass LSTMClassifier(nn.Module):\n    def __init__(self, vocab, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n        self.fc = nn.Linear(hid, n_out)\n\n    def forward(self, x, lengths):\n        em = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            em, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        return self.fc(h[-1])\n\n\nclass BagOfEmbClassifier(nn.Module):\n    def __init__(self, vocab, emb=64, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb, padding_idx=0)\n        self.fc = nn.Linear(emb, n_out)\n\n    def forward(self, x, lengths):\n        em = self.emb(x)  # (B, T, E)\n        mask = (x != 0).unsqueeze(-1)  # (B, T, 1)\n        summed = (em * mask).sum(1)  # (B, E)\n        avg = summed / lengths.unsqueeze(1)  # (B, E)\n        return self.fc(avg)\n\n\n# ---------- training routine ----------\ndef run_training(model_name, num_epochs):\n    model_cls = LSTMClassifier if model_name == \"LSTM\" else BagOfEmbClassifier\n    model = model_cls(vocab_size, n_out=n_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n    rec = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    for ep in range(1, num_epochs + 1):\n        # train\n        model.train()\n        t_loss = 0.0\n        for batch in train_loader:\n            optim.zero_grad()\n            out = model(batch[\"x\"], batch[\"len\"])\n            loss = criterion(out, batch[\"y\"])\n            loss.backward()\n            optim.step()\n            t_loss += loss.item() * batch[\"y\"].size(0)\n        train_loss = t_loss / len(train_loader.dataset)\n        # evaluate\n        model.eval()\n        v_loss = 0.0\n        y_true = []\n        y_pred = []\n        all_seq = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                out = model(batch[\"x\"], batch[\"len\"])\n                loss = criterion(out, batch[\"y\"])\n                v_loss += loss.item() * batch[\"y\"].size(0)\n                preds = torch.argmax(out, 1).cpu().tolist()\n                y_pred.extend(preds)\n                y_true.extend(batch[\"y\"].cpu().tolist())\n                all_seq.extend(batch[\"raw_seq\"])\n        val_loss = v_loss / len(dev_loader.dataset)\n        swa = shape_weighted_accuracy(all_seq, y_true, y_pred)\n        cwa = color_weighted_accuracy(all_seq, y_true, y_pred)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        # record\n        rec[\"losses\"][\"train\"].append(train_loss)\n        rec[\"losses\"][\"val\"].append(val_loss)\n        rec[\"metrics\"][\"val\"].append(hwa)\n        rec[\"predictions\"].append(y_pred)\n        rec[\"ground_truth\"].append(y_true)\n        rec[\"timestamps\"].append(time.time())\n        print(\n            f\"[{model_name}] Ep {ep}/{num_epochs} | tr_loss={train_loss:.4f} val_loss={val_loss:.4f} HWA={hwa:.3f}\"\n        )\n    return rec\n\n\n# ---------- hyper-parameter sweep ----------\nepoch_options = [5, 10, 20, 30]\nfor model_name in [\"LSTM\", \"BOE\"]:\n    for e in epoch_options:\n        print(f\"\\n=== {model_name}: training for {e} epochs ===\")\n        experiment_data[model_name][\"SPR_BENCH\"][str(e)] = run_training(model_name, e)\n\n# ---------- save ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(\n    os.path.join(working_dir, \"experiment_data.npy\"), experiment_data, allow_pickle=True\n)\nprint(\"Saved experiment_data.npy\")\n", "import os, random, time, pathlib, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import DatasetDict, Dataset as HFDataset\n\n# ---------- reproducibility & device ----------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n\n# ---------- helper metrics ----------\ndef count_shape_variety(sequence: str):  # shape = first char of token\n    return len({tok[0] for tok in sequence.split() if tok})\n\n\ndef count_color_variety(sequence: str):  # color = second char of token\n    return len({tok[1] for tok in sequence.split() if len(tok) > 1})\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa + 1e-12)\n\n\n# ---------- synthetic dataset generator ----------\ndef gen_dataset(\n    name, shapes, colors, length_rng, label_fn, n_train=600, n_dev=200, n_test=200\n):\n    def make_seq():\n        L = random.randint(*length_rng)\n        return \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n\n    def build_split(n, start_id):\n        rows = []\n        for i in range(start_id, start_id + n):\n            seq = make_seq()\n            tok_list = seq.split()\n            label = label_fn(tok_list)\n            rows.append({\"id\": i, \"sequence\": seq, \"label\": int(label)})\n        return HFDataset.from_list(rows)\n\n    return name, DatasetDict(\n        {\n            \"train\": build_split(n_train, 0),\n            \"dev\": build_split(n_dev, 10_000),\n            \"test\": build_split(n_test, 20_000),\n        }\n    )\n\n\n# label functions (binary)\ndef lbl_parity(tok_list):  # 1 if even length, else 0\n    return len(tok_list) % 2 == 0\n\n\ndef lbl_shape_gt_color(tok_list):  # 1 if #unique shapes > #unique colors\n    shapes = len({t[0] for t in tok_list})\n    colors = len({t[1] for t in tok_list})\n    return shapes > colors\n\n\ndef lbl_first_equals_last(tok_list):  # 1 if first & last shapes equal\n    return tok_list[0][0] == tok_list[-1][0]\n\n\n# ---------- create 3 synthetic datasets ----------\ndatasets = {}\ncfgs = [\n    dict(\n        name=\"SetA\",\n        shapes=\"ABCD\",\n        colors=\"abcd\",\n        length_rng=(4, 9),\n        label_fn=lbl_parity,\n    ),\n    dict(\n        name=\"SetB\",\n        shapes=\"EFGH\",\n        colors=\"efghij\",\n        length_rng=(6, 12),\n        label_fn=lbl_shape_gt_color,\n    ),\n    dict(\n        name=\"SetC\",\n        shapes=\"IJK\",\n        colors=\"klmno\",\n        length_rng=(3, 7),\n        label_fn=lbl_first_equals_last,\n    ),\n]\nfor c in cfgs:\n    n, ds = gen_dataset(**c)\n    datasets[n] = ds\nprint({k: {s: len(v[s]) for s in v} for k, v in datasets.items()})\n\n\n# ---------- torch helpers ----------\nclass TorchSeqSet(Dataset):\n    def __init__(self, hf_split, tok2idx):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.tok2idx = tok2idx\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        ids = [self.tok2idx.get(tok, 1) for tok in seq.split()]  # 1 == UNK\n        return {\"x\": torch.tensor(ids), \"y\": torch.tensor(self.labels[idx]), \"raw\": seq}\n\n\ndef build_vocab(train_sequences):\n    vocab = sorted({tok for seq in train_sequences for tok in seq.split()})\n    tok2idx = {tok: i + 2 for i, tok in enumerate(vocab)}\n    tok2idx[\"<PAD>\"] = 0\n    tok2idx[\"<UNK>\"] = 1\n    return tok2idx\n\n\ndef collate_fn(batch):\n    lens = [len(b[\"x\"]) for b in batch]\n    maxlen = max(lens)\n    xpad = torch.zeros(len(batch), maxlen, dtype=torch.long)\n    for i, b in enumerate(batch):\n        xpad[i, : lens[i]] = b[\"x\"]\n    y = torch.stack([b[\"y\"] for b in batch])\n    raw = [b[\"raw\"] for b in batch]\n    return {\n        \"x\": xpad.to(device),\n        \"len\": torch.tensor(lens).to(device),\n        \"y\": y.to(device),\n        \"raw\": raw,\n    }\n\n\n# ---------- model ----------\nclass LSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n        self.fc = nn.Linear(hid, n_out)\n\n    def forward(self, x, l):\n        e = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            e, l.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        return self.fc(h[-1])\n\n\n# ---------- experiment container ----------\nexperiment_data = {\"MultiSynthetic\": {}}\nEPOCHS = 10\nBATCH = 64\nfor train_name, ds_train in datasets.items():\n    print(f\"\\n=== Training on {train_name} ===\")\n    # vocab & loaders\n    tok2idx = build_vocab(ds_train[\"train\"][\"sequence\"])\n    train_loader = DataLoader(\n        TorchSeqSet(ds_train[\"train\"], tok2idx),\n        batch_size=BATCH,\n        shuffle=True,\n        collate_fn=collate_fn,\n    )\n    dev_loader = DataLoader(\n        TorchSeqSet(ds_train[\"dev\"], tok2idx),\n        batch_size=BATCH,\n        shuffle=False,\n        collate_fn=collate_fn,\n    )\n    n_classes = len(set(ds_train[\"train\"][\"label\"]))\n    model = LSTMClassifier(len(tok2idx), n_out=n_classes).to(device)\n    crit = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    rec = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": {\"train\": [], \"val\": []},\n        \"ground_truth\": {\"train\": [], \"val\": []},\n        \"cross_eval\": {},\n    }\n\n    # ---- training loop ----\n    for ep in range(1, EPOCHS + 1):\n        model.train()\n        tl = 0\n        for b in train_loader:\n            opt.zero_grad()\n            out = model(b[\"x\"], b[\"len\"])\n            loss = crit(out, b[\"y\"])\n            loss.backward()\n            opt.step()\n            tl += loss.item() * b[\"y\"].size(0)\n        tr_loss = tl / len(train_loader.dataset)\n        rec[\"losses\"][\"train\"].append(tr_loss)\n\n        # validation (in-domain)\n        model.eval()\n        vl = 0\n        y_true = []\n        y_pred = []\n        seqs = []\n        with torch.no_grad():\n            for b in dev_loader:\n                out = model(b[\"x\"], b[\"len\"])\n                loss = crit(out, b[\"y\"])\n                vl += loss.item() * b[\"y\"].size(0)\n                preds = torch.argmax(out, 1).cpu().tolist()\n                y_pred.extend(preds)\n                y_true.extend(b[\"y\"].cpu().tolist())\n                seqs.extend(b[\"raw\"])\n        val_loss = vl / len(dev_loader.dataset)\n        rec[\"losses\"][\"val\"].append(val_loss)\n        swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n        cwa = color_weighted_accuracy(seqs, y_true, y_pred)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        rec[\"metrics\"][\"val\"].append(hwa)\n        rec[\"predictions\"][\"val\"].append(y_pred)\n        rec[\"ground_truth\"][\"val\"].append(y_true)\n        print(\n            f\"Ep{ep:02d}: tr_loss={tr_loss:.3f} val_loss={val_loss:.3f} HWA={hwa:.3f}\"\n        )\n\n    # ---- cross-domain evaluation ----\n    model.eval()\n    for eval_name, ds_eval in datasets.items():\n        eval_loader = DataLoader(\n            TorchSeqSet(ds_eval[\"dev\"], tok2idx),\n            batch_size=BATCH,\n            shuffle=False,\n            collate_fn=collate_fn,\n        )\n        y_true = []\n        y_pred = []\n        seqs = []\n        with torch.no_grad():\n            for b in eval_loader:\n                out = model(b[\"x\"], b[\"len\"])\n                preds = torch.argmax(out, 1).cpu().tolist()\n                y_pred.extend(preds)\n                y_true.extend(b[\"y\"].cpu().tolist())\n                seqs.extend(b[\"raw\"])\n        acc = np.mean(np.array(y_true) == np.array(y_pred))\n        swa = shape_weighted_accuracy(seqs, y_true, y_pred)\n        cwa = color_weighted_accuracy(seqs, y_true, y_pred)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        rec[\"cross_eval\"][eval_name] = {\n            \"accuracy\": acc,\n            \"swa\": swa,\n            \"cwa\": cwa,\n            \"hwa\": hwa,\n            \"y_pred\": y_pred,\n            \"y_true\": y_true,\n        }\n    experiment_data[\"MultiSynthetic\"][train_name] = rec\n\n# ---------- save ----------\nwork_dir = os.path.join(os.getcwd(), \"working\")\npathlib.Path(work_dir).mkdir(exist_ok=True)\nnp.save(os.path.join(work_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, random, pathlib, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import Dataset as HFDataset, DatasetDict\n\n# ----------------------------- experiment dict -----------------------------\nexperiment_data = {\"baseline\": {}, \"factorized\": {}}\n\n# ----------------------------- device & seeds ------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nrandom.seed(42)\nnp.random.seed(42)\nprint(\"Using device:\", device)\n\n\n# ----------------------------- helper metrics ------------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa + 1e-12)\n\n\n# ----------------------------- data loading --------------------------------\ndef load_or_create_dataset():\n    root = pathlib.Path(\"SPR_BENCH\")\n    if root.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(root)\n\n    # tiny synthetic fallback\n    def gen_row(_id):\n        length = random.randint(4, 9)\n        shapes, colors = \"ABCD\", \"abcd\"\n        seq = \" \".join(\n            random.choice(shapes) + random.choice(colors) for _ in range(length)\n        )\n        return {\"id\": _id, \"sequence\": seq, \"label\": int(length % 2)}\n\n    train_rows = [gen_row(i) for i in range(600)]\n    dev_rows = [gen_row(1000 + i) for i in range(200)]\n    test_rows = [gen_row(2000 + i) for i in range(200)]\n    return DatasetDict(\n        {\n            \"train\": HFDataset.from_list(train_rows),\n            \"dev\": HFDataset.from_list(dev_rows),\n            \"test\": HFDataset.from_list(test_rows),\n        }\n    )\n\n\nspr = load_or_create_dataset()\nprint({k: len(v) for k, v in spr.items()})\n\n# ----------------------------- vocabularies --------------------------------\nall_text = \" \".join(spr[\"train\"][\"sequence\"])\ntok_vocab = sorted(set(all_text.split()))\ntok2idx = {tok: i + 2 for i, tok in enumerate(tok_vocab)}  # 0 PAD, 1 UNK\ntok2idx[\"<PAD>\"], tok2idx[\"<UNK>\"] = 0, 1\nidx2tok = {i: t for t, i in tok2idx.items()}\nvocab_size = len(tok2idx)\nprint(\"Token vocab size:\", vocab_size)\n\n# shape & color vocab\nshape_vocab = sorted({tok[0] for tok in tok_vocab})\ncolor_vocab = sorted({tok[1] for tok in tok_vocab})\nshape2idx = {s: i + 2 for i, s in enumerate(shape_vocab)}\ncolor2idx = {c: i + 2 for i, c in enumerate(color_vocab)}\nshape2idx[\"<PAD>\"], shape2idx[\"<UNK>\"] = 0, 1\ncolor2idx[\"<PAD>\"], color2idx[\"<UNK>\"] = 0, 1\nshape_vocab_size, color_vocab_size = len(shape2idx), len(color2idx)\nprint(\"Shape vocab:\", shape_vocab_size, \"Color vocab:\", color_vocab_size)\n\n\n# ----------------------------- encoders ------------------------------------\ndef encode_token(tok):\n    return tok2idx.get(tok, 1)\n\n\ndef encode_shapes(seq):\n    res = []\n    for tok in seq.strip().split():\n        res.append(shape2idx.get(tok[0], 1) if tok else 1)\n    return res\n\n\ndef encode_colors(seq):\n    res = []\n    for tok in seq.strip().split():\n        res.append(color2idx.get(tok[1], 1) if len(tok) > 1 else 1)\n    return res\n\n\n# ----------------------------- torch dataset ------------------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs, self.labels = hf_split[\"sequence\"], hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        return {\n            \"token\": torch.tensor(\n                [encode_token(t) for t in seq.split()], dtype=torch.long\n            ),\n            \"shape\": torch.tensor(encode_shapes(seq), dtype=torch.long),\n            \"color\": torch.tensor(encode_colors(seq), dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": seq,\n        }\n\n\ndef pad_batch(col, pad_val=0):\n    lengths = [len(x) for x in col]\n    maxlen = max(lengths)\n    out = torch.full((len(col), maxlen), pad_val, dtype=torch.long)\n    for i, x in enumerate(col):\n        out[i, : len(x)] = x\n    return out, torch.tensor(lengths, dtype=torch.long)\n\n\ndef collate(batch):\n    token_col = [b[\"token\"] for b in batch]\n    shape_col = [b[\"shape\"] for b in batch]\n    color_col = [b[\"color\"] for b in batch]\n    tok_pad, lens = pad_batch(token_col, 0)\n    shp_pad, _ = pad_batch(shape_col, 0)\n    col_pad, _ = pad_batch(color_col, 0)\n    ys = torch.stack([b[\"y\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    return {\n        \"token\": tok_pad.to(device),\n        \"shape\": shp_pad.to(device),\n        \"color\": col_pad.to(device),\n        \"len\": lens.to(device),\n        \"y\": ys.to(device),\n        \"raw_seq\": raw,\n    }\n\n\nbatch_size = 64\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\nn_classes = len(set(spr[\"train\"][\"label\"]))\nprint(\"Num classes:\", n_classes)\n\n\n# ----------------------------- models --------------------------------------\nclass BaselineLSTM(nn.Module):\n    def __init__(self, vocab, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n        self.fc = nn.Linear(hid, n_out)\n\n    def forward(self, token_ids, lengths):\n        em = self.emb(token_ids)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            em, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        return self.fc(h[-1])\n\n\nclass FactorizedLSTM(nn.Module):\n    def __init__(self, shape_vocab, color_vocab, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.shape_emb = nn.Embedding(shape_vocab, emb, padding_idx=0)\n        self.color_emb = nn.Embedding(color_vocab, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n        self.fc = nn.Linear(hid, n_out)\n\n    def forward(self, shape_ids, color_ids, lengths):\n        em = self.shape_emb(shape_ids) + self.color_emb(color_ids)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            em, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        return self.fc(h[-1])\n\n\n# ----------------------------- training loop ------------------------------\ndef run_training(model_type: str, num_epochs: int):\n    if model_type == \"baseline\":\n        model = BaselineLSTM(vocab_size, n_out=n_classes).to(device)\n    else:\n        model = FactorizedLSTM(shape_vocab_size, color_vocab_size, n_out=n_classes).to(\n            device\n        )\n\n    criterion = nn.CrossEntropyLoss()\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n    rec = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n\n    for ep in range(1, num_epochs + 1):\n        model.train()\n        tloss = 0.0\n        for batch in train_loader:\n            optim.zero_grad()\n            if model_type == \"baseline\":\n                out = model(batch[\"token\"], batch[\"len\"])\n            else:\n                out = model(batch[\"shape\"], batch[\"color\"], batch[\"len\"])\n            loss = criterion(out, batch[\"y\"])\n            loss.backward()\n            optim.step()\n            tloss += loss.item() * batch[\"y\"].size(0)\n        tr_loss = tloss / len(train_loader.dataset)\n\n        # validation\n        model.eval()\n        vloss, all_seq, y_true, y_pred = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                if model_type == \"baseline\":\n                    out = model(batch[\"token\"], batch[\"len\"])\n                else:\n                    out = model(batch[\"shape\"], batch[\"color\"], batch[\"len\"])\n                loss = criterion(out, batch[\"y\"])\n                vloss += loss.item() * batch[\"y\"].size(0)\n                preds = torch.argmax(out, 1).cpu().tolist()\n                y_pred.extend(preds)\n                y_true.extend(batch[\"y\"].cpu().tolist())\n                all_seq.extend(batch[\"raw_seq\"])\n        val_loss = vloss / len(dev_loader.dataset)\n        swa = shape_weighted_accuracy(all_seq, y_true, y_pred)\n        cwa = color_weighted_accuracy(all_seq, y_true, y_pred)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n\n        rec[\"losses\"][\"train\"].append(tr_loss)\n        rec[\"losses\"][\"val\"].append(val_loss)\n        rec[\"metrics\"][\"val\"].append(hwa)\n        rec[\"predictions\"].append(y_pred)\n        rec[\"ground_truth\"].append(y_true)\n        rec[\"timestamps\"].append(time.time())\n        print(\n            f\"[{model_type}] Ep {ep}/{num_epochs}  tr_loss={tr_loss:.4f}  val_loss={val_loss:.4f}  HWA={hwa:.3f}\"\n        )\n    return rec\n\n\n# ----------------------------- hyper-parameter sweep -----------------------\nepoch_options = [5, 10]\nfor variant in [\"baseline\", \"factorized\"]:\n    experiment_data[variant][\"SPR_BENCH\"] = {}\n    for e in epoch_options:\n        print(f\"\\n=== {variant.upper()} | training for {e} epochs ===\")\n        experiment_data[variant][\"SPR_BENCH\"][str(e)] = run_training(variant, e)\n\n# ----------------------------- save ----------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(\n    os.path.join(working_dir, \"experiment_data.npy\"), experiment_data, allow_pickle=True\n)\nprint(\"Saved experiment_data.npy\")\n", "import os, random, pathlib, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import Dataset as HFDataset, DatasetDict\n\n# ---------------- save dict ----------------\nexperiment_data = {\n    \"baseline\": {\"SPR_BENCH\": {}},\n    \"padding_mask_removal\": {\"SPR_BENCH\": {}},\n}\n\n# ---------------- device & seeds ----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nrandom.seed(42)\nnp.random.seed(42)\nprint(f\"Using device: {device}\")\n\n\n# ---------------- helper metrics ----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\nharmonic_weighted_accuracy = lambda swa, cwa: 2 * swa * cwa / (swa + cwa + 1e-12)\n\n\n# ---------------- data loading ----------------\ndef load_or_create_dataset():\n    root = pathlib.Path(\"SPR_BENCH\")\n    if root.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(root)\n\n    # fallback tiny synthetic set\n    def gen_row(_id):\n        length = random.randint(4, 9)\n        shapes, colors = \"ABCD\", \"abcd\"\n        seq = \" \".join(\n            random.choice(shapes) + random.choice(colors) for _ in range(length)\n        )\n        return {\"id\": _id, \"sequence\": seq, \"label\": int(length % 2)}\n\n    train_rows = [gen_row(i) for i in range(600)]\n    dev_rows = [gen_row(1000 + i) for i in range(200)]\n    test_rows = [gen_row(2000 + i) for i in range(200)]\n    return DatasetDict(\n        {\n            \"train\": HFDataset.from_list(train_rows),\n            \"dev\": HFDataset.from_list(dev_rows),\n            \"test\": HFDataset.from_list(test_rows),\n        }\n    )\n\n\nspr = load_or_create_dataset()\nprint({k: len(v) for k, v in spr.items()})\n\n# ---------------- vocabulary ----------------\nall_text = \" \".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text.split()))\ntok2idx = {tok: i + 2 for i, tok in enumerate(vocab)}  # 0 PAD, 1 UNK\ntok2idx[\"<PAD>\"], tok2idx[\"<UNK>\"] = 0, 1\nidx2tok = {i: t for t, i in tok2idx.items()}\nvocab_size = len(tok2idx)\nprint(f\"Vocab size: {vocab_size}\")\nencode_sequence = lambda seq: [tok2idx.get(tok, 1) for tok in seq.strip().split()]\n\n\n# ---------------- torch dataset ----------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs, self.labels = hf_split[\"sequence\"], hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"x\": torch.tensor(encode_sequence(self.seqs[idx]), dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    xs = [b[\"x\"] for b in batch]\n    lens = [len(x) for x in xs]\n    maxlen = max(lens)\n    xs_pad = torch.zeros(len(xs), maxlen, dtype=torch.long)\n    for i, x in enumerate(xs):\n        xs_pad[i, : len(x)] = x\n    ys = torch.stack([b[\"y\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    return {\n        \"x\": xs_pad.to(device),\n        \"len\": torch.tensor(lens, dtype=torch.long).to(device),\n        \"y\": ys.to(device),\n        \"raw_seq\": raw,\n    }\n\n\nbatch_size = 64\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\nn_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Num classes: {n_classes}\")\n\n\n# ---------------- models ----------------\nclass LSTMClassifierPacked(nn.Module):\n    \"Baseline length-aware model\"\n\n    def __init__(self, vocab, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n        self.fc = nn.Linear(hid, n_out)\n\n    def forward(self, x, lengths):\n        em = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            em, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        return self.fc(h[-1])\n\n\nclass LSTMClassifierNoMask(nn.Module):\n    \"Ablation: feed zero-padded seqs directly\"\n\n    def __init__(self, vocab, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n        self.fc = nn.Linear(hid, n_out)\n\n    def forward(self, x, lengths):\n        em = self.emb(x)  # (B,T,E)\n        _, (h, _) = self.lstm(em)  # padding tokens seen as normal\n        return self.fc(h[-1])\n\n\n# ----------------- train / evaluate one run -----------------\ndef run_training(model_cls, num_epochs):\n    model = model_cls(vocab_size, n_out=n_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n    rec = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    for ep in range(1, num_epochs + 1):\n        model.train()\n        tloss = 0.0\n        for batch in train_loader:\n            optim.zero_grad()\n            out = model(batch[\"x\"], batch[\"len\"])\n            loss = criterion(out, batch[\"y\"])\n            loss.backward()\n            optim.step()\n            tloss += loss.item() * batch[\"y\"].size(0)\n        train_loss = tloss / len(train_loader.dataset)\n\n        model.eval()\n        vloss = 0.0\n        all_seq = []\n        y_true = []\n        y_pred = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                out = model(batch[\"x\"], batch[\"len\"])\n                loss = criterion(out, batch[\"y\"])\n                vloss += loss.item() * batch[\"y\"].size(0)\n                preds = torch.argmax(out, 1).cpu().tolist()\n                y_pred.extend(preds)\n                y_true.extend(batch[\"y\"].cpu().tolist())\n                all_seq.extend(batch[\"raw_seq\"])\n        val_loss = vloss / len(dev_loader.dataset)\n        swa = shape_weighted_accuracy(all_seq, y_true, y_pred)\n        cwa = color_weighted_accuracy(all_seq, y_true, y_pred)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n\n        rec[\"losses\"][\"train\"].append(train_loss)\n        rec[\"losses\"][\"val\"].append(val_loss)\n        rec[\"metrics\"][\"val\"].append(hwa)\n        rec[\"predictions\"].append(y_pred)\n        rec[\"ground_truth\"].append(y_true)\n        rec[\"timestamps\"].append(time.time())\n        print(\n            f\"Ep {ep}/{num_epochs}: tr_loss={train_loss:.4f} val_loss={val_loss:.4f} HWA={hwa:.3f}\"\n        )\n    return rec\n\n\n# ----------------- hyper-parameter sweep -----------------\nepoch_options = [5, 10, 20, 30]\nfor e in epoch_options:\n    print(f\"\\n=== Baseline packed | epochs={e} ===\")\n    experiment_data[\"baseline\"][\"SPR_BENCH\"][str(e)] = run_training(\n        LSTMClassifierPacked, e\n    )\n    print(f\"\\n=== Padding-mask removal | epochs={e} ===\")\n    experiment_data[\"padding_mask_removal\"][\"SPR_BENCH\"][str(e)] = run_training(\n        LSTMClassifierNoMask, e\n    )\n\n# ----------------- save -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, random, pathlib, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import Dataset as HFDataset, DatasetDict\n\n# ----------------- experiment dict (baseline + ablation) -----------------\nexperiment_data = {\n    \"baseline\": {\"SPR_BENCH\": {}},\n    \"frozen_emb\": {\"SPR_BENCH\": {}},\n}\n\n# ----------------- device & seeds -----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nrandom.seed(42)\nnp.random.seed(42)\nprint(\"Using device:\", device)\n\n\n# ----------------- helper metrics -----------------\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.split() if tok))\n\n\ndef count_color_variety(seq):\n    return len(set(tok[1] for tok in seq.split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wi if t == p else 0 for wi, t, p in zip(w, y_t, y_p)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wi if t == p else 0 for wi, t, p in zip(w, y_t, y_p)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa + 1e-12)\n\n\n# ----------------- data -----------------\ndef load_or_create_dataset():\n    root = pathlib.Path(\"SPR_BENCH\")\n    if root.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(root)\n\n    def gen_row(_id):\n        L = random.randint(4, 9)\n        shapes, colors = \"ABCD\", \"abcd\"\n        seq = \" \".join(random.choice(shapes) + random.choice(colors) for _ in range(L))\n        return {\"id\": _id, \"sequence\": seq, \"label\": int(L % 2)}\n\n    train = [gen_row(i) for i in range(600)]\n    dev = [gen_row(1000 + i) for i in range(200)]\n    test = [gen_row(2000 + i) for i in range(200)]\n    return DatasetDict(\n        {\n            \"train\": HFDataset.from_list(train),\n            \"dev\": HFDataset.from_list(dev),\n            \"test\": HFDataset.from_list(test),\n        }\n    )\n\n\nspr = load_or_create_dataset()\nprint({k: len(v) for k, v in spr.items()})\n\n# ----------------- vocab -----------------\nall_text = \" \".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text.split()))\ntok2idx = {tok: i + 2 for i, tok in enumerate(vocab)}\ntok2idx[\"<PAD>\"] = 0\ntok2idx[\"<UNK>\"] = 1\nidx2tok = {i: t for t, i in tok2idx.items()}\nvocab_size = len(tok2idx)\n\n\ndef encode(seq):\n    return [tok2idx.get(tok, 1) for tok in seq.split()]\n\n\nprint(\"Vocab size:\", vocab_size)\n\n\n# ----------------- torch dataset -----------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, split):\n        self.seqs, self.labels = split[\"sequence\"], split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"x\": torch.tensor(encode(self.seqs[idx]), dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    lens = [len(b[\"x\"]) for b in batch]\n    maxlen = max(lens)\n    x_pad = torch.zeros(len(batch), maxlen, dtype=torch.long)\n    for i, b in enumerate(batch):\n        x_pad[i, : lens[i]] = b[\"x\"]\n    y = torch.stack([b[\"y\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    return {\n        \"x\": x_pad.to(device),\n        \"len\": torch.tensor(lens).to(device),\n        \"y\": y.to(device),\n        \"raw_seq\": raw,\n    }\n\n\nbatch_size = 64\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size, shuffle=False, collate_fn=collate\n)\nn_classes = len(set(spr[\"train\"][\"label\"]))\nprint(\"Num classes:\", n_classes)\n\n\n# ----------------- model -----------------\nclass LSTMClassifier(nn.Module):\n    def __init__(self, vocab, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n        self.fc = nn.Linear(hid, n_out)\n\n    def forward(self, x, lengths):\n        em = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            em, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        return self.fc(h[-1])\n\n\n# ----------------- train / eval -----------------\ndef run_training(num_epochs, freeze_emb=False):\n    model = LSTMClassifier(vocab_size, n_out=n_classes).to(device)\n    if freeze_emb:\n        model.emb.weight.requires_grad = False\n    crit = nn.CrossEntropyLoss()\n    optim = torch.optim.Adam(\n        filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3\n    )\n    rec = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    for ep in range(1, num_epochs + 1):\n        model.train()\n        tloss = 0.0\n        for batch in train_loader:\n            optim.zero_grad()\n            out = model(batch[\"x\"], batch[\"len\"])\n            loss = crit(out, batch[\"y\"])\n            loss.backward()\n            optim.step()\n            tloss += loss.item() * batch[\"y\"].size(0)\n        train_loss = tloss / len(train_loader.dataset)\n\n        model.eval()\n        vloss = 0.0\n        seqs = []\n        y_t = []\n        y_p = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                out = model(batch[\"x\"], batch[\"len\"])\n                loss = crit(out, batch[\"y\"])\n                vloss += loss.item() * batch[\"y\"].size(0)\n                preds = torch.argmax(out, 1).cpu().tolist()\n                y_p.extend(preds)\n                y_t.extend(batch[\"y\"].cpu().tolist())\n                seqs.extend(batch[\"raw_seq\"])\n        val_loss = vloss / len(dev_loader.dataset)\n        swa = shape_weighted_accuracy(seqs, y_t, y_p)\n        cwa = color_weighted_accuracy(seqs, y_t, y_p)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n\n        rec[\"losses\"][\"train\"].append(train_loss)\n        rec[\"losses\"][\"val\"].append(val_loss)\n        rec[\"metrics\"][\"val\"].append(hwa)\n        rec[\"predictions\"].append(y_p)\n        rec[\"ground_truth\"].append(y_t)\n        rec[\"timestamps\"].append(time.time())\n        tag = \"Frozen\" if freeze_emb else \"Baseline\"\n        print(\n            f\"{tag} | Epoch {ep}/{num_epochs} - tr_loss:{train_loss:.4f} val_loss:{val_loss:.4f} HWA:{hwa:.3f}\"\n        )\n    return rec\n\n\n# ----------------- sweeps -----------------\nepoch_options = [5, 10, 20, 30]\nfor e in epoch_options:\n    # baseline\n    experiment_data[\"baseline\"][\"SPR_BENCH\"][str(e)] = run_training(e, freeze_emb=False)\n    # frozen embedding ablation\n    experiment_data[\"frozen_emb\"][\"SPR_BENCH\"][str(e)] = run_training(\n        e, freeze_emb=True\n    )\n\n# ----------------- save -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, random, pathlib, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import Dataset as HFDataset, DatasetDict\n\n# ----------------- ablation data dict -----------------\nexperiment_data = {\n    \"shape_color_split\": {\"SPR_BENCH\": {}}  # ablation name  # dataset name\n}\n\n# ----------------- device & seeds -----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nrandom.seed(42)\nnp.random.seed(42)\nprint(f\"Using device: {device}\")\n\n\n# ----------------- helper metrics -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa + 1e-12)\n\n\n# ----------------- data loading -----------------\ndef load_or_create_dataset():\n    root = pathlib.Path(\"SPR_BENCH\")\n    if root.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(root)\n\n    # fallback tiny synthetic set\n    def gen_row(_id):\n        length = random.randint(4, 9)\n        shapes, colors = \"ABCD\", \"abcd\"\n        seq = \" \".join(\n            random.choice(shapes) + random.choice(colors) for _ in range(length)\n        )\n        return {\"id\": _id, \"sequence\": seq, \"label\": int(length % 2)}\n\n    train_rows = [gen_row(i) for i in range(600)]\n    dev_rows = [gen_row(1000 + i) for i in range(200)]\n    test_rows = [gen_row(2000 + i) for i in range(200)]\n    return DatasetDict(\n        {\n            \"train\": HFDataset.from_list(train_rows),\n            \"dev\": HFDataset.from_list(dev_rows),\n            \"test\": HFDataset.from_list(test_rows),\n        }\n    )\n\n\nspr = load_or_create_dataset()\nprint({k: len(v) for k, v in spr.items()})\n\n# ----------------- vocabulary (character-level) -----------------\nall_chars = set()\nfor seq in spr[\"train\"][\"sequence\"]:\n    for tok in seq.split():\n        all_chars.update(tok)  # add both shape + colour letters\n\nchar_vocab = sorted(all_chars)\ntok2idx = {ch: i + 2 for i, ch in enumerate(char_vocab)}  # 0 PAD, 1 UNK\ntok2idx[\"<PAD>\"], tok2idx[\"<UNK>\"] = 0, 1\nidx2tok = {i: t for t, i in tok2idx.items()}\nvocab_size = len(tok2idx)\nprint(f\"Char-level vocab size: {vocab_size}\")\n\n\ndef encode_sequence(seq: str):\n    \"\"\"Convert 'Aa Bb' into indices [A, a, B, b].\"\"\"\n    ids = []\n    for symbol in seq.strip().split():\n        for ch in symbol:  # split into two tokens\n            ids.append(tok2idx.get(ch, 1))\n    return ids\n\n\n# ----------------- torch dataset -----------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs, self.labels = hf_split[\"sequence\"], hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"x\": torch.tensor(encode_sequence(self.seqs[idx]), dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    xs = [b[\"x\"] for b in batch]\n    lens = [len(x) for x in xs]\n    maxlen = max(lens)\n    xs_pad = torch.zeros(len(xs), maxlen, dtype=torch.long)\n    for i, x in enumerate(xs):\n        xs_pad[i, : len(x)] = x\n    ys = torch.stack([b[\"y\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    return {\n        \"x\": xs_pad.to(device),\n        \"len\": torch.tensor(lens, dtype=torch.long).to(device),\n        \"y\": ys.to(device),\n        \"raw_seq\": raw,\n    }\n\n\nbatch_size = 64\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\nn_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Num classes: {n_classes}\")\n\n\n# ----------------- model -----------------\nclass LSTMClassifier(nn.Module):\n    def __init__(self, vocab, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n        self.fc = nn.Linear(hid, n_out)\n\n    def forward(self, x, lengths):\n        em = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            em, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        return self.fc(h[-1])\n\n\n# ----------------- train / evaluate one run -----------------\ndef run_training(num_epochs):\n    model = LSTMClassifier(vocab_size, n_out=n_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    run_rec = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    for ep in range(1, num_epochs + 1):\n        # --- train ---\n        model.train()\n        tloss = 0.0\n        for batch in train_loader:\n            optim.zero_grad()\n            out = model(batch[\"x\"], batch[\"len\"])\n            loss = criterion(out, batch[\"y\"])\n            loss.backward()\n            optim.step()\n            tloss += loss.item() * batch[\"y\"].size(0)\n        train_loss = tloss / len(train_loader.dataset)\n\n        # --- validation ---\n        model.eval()\n        vloss, all_seq, y_true, y_pred = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                out = model(batch[\"x\"], batch[\"len\"])\n                loss = criterion(out, batch[\"y\"])\n                vloss += loss.item() * batch[\"y\"].size(0)\n                preds = torch.argmax(out, 1).cpu().tolist()\n                y_pred.extend(preds)\n                y_true.extend(batch[\"y\"].cpu().tolist())\n                all_seq.extend(batch[\"raw_seq\"])\n        val_loss = vloss / len(dev_loader.dataset)\n        swa = shape_weighted_accuracy(all_seq, y_true, y_pred)\n        cwa = color_weighted_accuracy(all_seq, y_true, y_pred)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n\n        # --- record ---\n        run_rec[\"losses\"][\"train\"].append(train_loss)\n        run_rec[\"losses\"][\"val\"].append(val_loss)\n        run_rec[\"metrics\"][\"val\"].append(hwa)\n        run_rec[\"predictions\"].append(y_pred)\n        run_rec[\"ground_truth\"].append(y_true)\n        run_rec[\"timestamps\"].append(time.time())\n\n        print(\n            f\"Epochs={num_epochs} | Ep {ep}: tr_loss={train_loss:.4f} val_loss={val_loss:.4f} HWA={hwa:.3f}\"\n        )\n    return run_rec\n\n\n# ----------------- hyper-parameter sweep -----------------\nepoch_options = [5, 10, 20, 30]\nfor e in epoch_options:\n    print(f\"\\n=== Training for {e} epochs (shape_color_split) ===\")\n    experiment_data[\"shape_color_split\"][\"SPR_BENCH\"][str(e)] = run_training(e)\n\n# ----------------- save -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy in 'working' directory\")\n", "import os, random, pathlib, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import Dataset as HFDataset, DatasetDict\n\n# ----------------- experiment dict -----------------\nexperiment_data = {\n    \"baseline\": {\"SPR_BENCH\": {}},\n    \"token_order_randomization\": {\"SPR_BENCH\": {}},\n}\n\n# ----------------- device & seeds -----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nrandom.seed(42)\nnp.random.seed(42)\nprint(f\"Using device: {device}\")\n\n\n# ----------------- helper metrics -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa + 1e-12)\n\n\n# ----------------- data loading -----------------\ndef load_or_create_dataset():\n    root = pathlib.Path(\"SPR_BENCH\")\n    if root.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(root)\n\n    # tiny synthetic fallback\n    def gen_row(_id):\n        length = random.randint(4, 9)\n        shapes, colors = \"ABCD\", \"abcd\"\n        seq = \" \".join(\n            random.choice(shapes) + random.choice(colors) for _ in range(length)\n        )\n        return {\"id\": _id, \"sequence\": seq, \"label\": int(length % 2)}\n\n    train_rows = [gen_row(i) for i in range(600)]\n    dev_rows = [gen_row(1000 + i) for i in range(200)]\n    test_rows = [gen_row(2000 + i) for i in range(200)]\n    return DatasetDict(\n        {\n            \"train\": HFDataset.from_list(train_rows),\n            \"dev\": HFDataset.from_list(dev_rows),\n            \"test\": HFDataset.from_list(test_rows),\n        }\n    )\n\n\nspr = load_or_create_dataset()\nprint({k: len(v) for k, v in spr.items()})\n\n# ----------------- vocabulary -----------------\nall_text = \" \".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text.split()))\ntok2idx = {tok: i + 2 for i, tok in enumerate(vocab)}  # 0 PAD, 1 UNK\ntok2idx[\"<PAD>\"], tok2idx[\"<UNK>\"] = 0, 1\nidx2tok = {i: t for t, i in tok2idx.items()}\nvocab_size = len(tok2idx)\nprint(\"Vocab size:\", vocab_size)\n\n\ndef encode_sequence(seq):\n    return [tok2idx.get(tok, 1) for tok in seq.strip().split()]\n\n\n# ----------------- torch dataset -----------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split, shuffle_internal=False):\n        self.seqs, self.labels = hf_split[\"sequence\"], hf_split[\"label\"]\n        self.shuffle_internal = shuffle_internal\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        seq = self.seqs[idx]\n        toks = seq.strip().split()\n        if self.shuffle_internal:\n            random.shuffle(toks)  # token-order randomization\n        enc = torch.tensor([tok2idx.get(t, 1) for t in toks], dtype=torch.long)\n        return {\n            \"x\": enc,\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": seq,\n        }  # keep original for metrics\n\n\ndef collate(batch):\n    xs = [b[\"x\"] for b in batch]\n    lens = [len(x) for x in xs]\n    maxlen = max(lens)\n    xs_pad = torch.zeros(len(xs), maxlen, dtype=torch.long)\n    for i, x in enumerate(xs):\n        xs_pad[i, : len(x)] = x\n    ys = torch.stack([b[\"y\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    return {\n        \"x\": xs_pad.to(device),\n        \"len\": torch.tensor(lens, dtype=torch.long).to(device),\n        \"y\": ys.to(device),\n        \"raw_seq\": raw,\n    }\n\n\nbatch_size = 64\ntrain_loader_base = DataLoader(\n    SPRTorchSet(spr[\"train\"], shuffle_internal=False),\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=collate,\n)\ntrain_loader_rand = DataLoader(\n    SPRTorchSet(spr[\"train\"], shuffle_internal=True),\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=collate,\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"], shuffle_internal=False),\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=collate,\n)\nn_classes = len(set(spr[\"train\"][\"label\"]))\nprint(\"Num classes:\", n_classes)\n\n\n# ----------------- model -----------------\nclass LSTMClassifier(nn.Module):\n    def __init__(self, vocab, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n        self.fc = nn.Linear(hid, n_out)\n\n    def forward(self, x, lengths):\n        em = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            em, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        return self.fc(h[-1])\n\n\n# ----------------- train / evaluate -----------------\ndef run_training(train_loader, num_epochs):\n    model = LSTMClassifier(vocab_size, n_out=n_classes).to(device)\n    crit = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    rec = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    for ep in range(1, num_epochs + 1):\n        model.train()\n        tloss = 0.0\n        for batch in train_loader:\n            opt.zero_grad()\n            out = model(batch[\"x\"], batch[\"len\"])\n            loss = crit(out, batch[\"y\"])\n            loss.backward()\n            opt.step()\n            tloss += loss.item() * batch[\"y\"].size(0)\n        train_loss = tloss / len(train_loader.dataset)\n\n        # validation\n        model.eval()\n        vloss = 0.0\n        all_seq = []\n        y_true = []\n        y_pred = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                out = model(batch[\"x\"], batch[\"len\"])\n                loss = crit(out, batch[\"y\"])\n                vloss += loss.item() * batch[\"y\"].size(0)\n                preds = torch.argmax(out, 1).cpu().tolist()\n                y_pred.extend(preds)\n                y_true.extend(batch[\"y\"].cpu().tolist())\n                all_seq.extend(batch[\"raw_seq\"])\n        val_loss = vloss / len(dev_loader.dataset)\n        swa = shape_weighted_accuracy(all_seq, y_true, y_pred)\n        cwa = color_weighted_accuracy(all_seq, y_true, y_pred)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n\n        rec[\"losses\"][\"train\"].append(train_loss)\n        rec[\"losses\"][\"val\"].append(val_loss)\n        rec[\"metrics\"][\"val\"].append(hwa)\n        rec[\"predictions\"].append(y_pred)\n        rec[\"ground_truth\"].append(y_true)\n        rec[\"timestamps\"].append(time.time())\n        print(\n            f\"Ep{ep}/{num_epochs} | tr={train_loss:.3f} val={val_loss:.3f} HWA={hwa:.3f}\"\n        )\n    return rec\n\n\n# ----------------- sweep -----------------\nepoch_options = [5, 10, 20, 30]\nfor e in epoch_options:\n    print(f\"\\n=== Baseline, {e} epochs ===\")\n    experiment_data[\"baseline\"][\"SPR_BENCH\"][str(e)] = run_training(\n        train_loader_base, e\n    )\n    print(f\"\\n=== Token-Order Randomization, {e} epochs ===\")\n    experiment_data[\"token_order_randomization\"][\"SPR_BENCH\"][str(e)] = run_training(\n        train_loader_rand, e\n    )\n\n# ----------------- save -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, random, pathlib, time, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import Dataset as HFDataset, DatasetDict\n\n# ----------------- experiment data dict -----------------\nexperiment_data = {\n    \"UNI_LSTM\": {\"SPR_BENCH\": {}},  # baseline\n    \"BI_LSTM\": {\"SPR_BENCH\": {}},  # ablation\n}\n\n# ----------------- device & seeds -----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nrandom.seed(42)\nnp.random.seed(42)\nprint(f\"Using device: {device}\")\n\n\n# ----------------- helper metrics -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    c = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(c) / max(sum(w), 1)\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa + 1e-12)\n\n\n# ----------------- data loading -----------------\ndef load_or_create_dataset():\n    root = pathlib.Path(\"SPR_BENCH\")\n    if root.exists():\n        from SPR import load_spr_bench\n\n        return load_spr_bench(root)\n\n    # tiny fallback synthetic set\n    def gen_row(_id):\n        length = random.randint(4, 9)\n        shapes, colors = \"ABCD\", \"abcd\"\n        seq = \" \".join(\n            random.choice(shapes) + random.choice(colors) for _ in range(length)\n        )\n        return {\"id\": _id, \"sequence\": seq, \"label\": int(length % 2)}\n\n    train_rows = [gen_row(i) for i in range(600)]\n    dev_rows = [gen_row(1000 + i) for i in range(200)]\n    test_rows = [gen_row(2000 + i) for i in range(200)]\n    return DatasetDict(\n        {\n            \"train\": HFDataset.from_list(train_rows),\n            \"dev\": HFDataset.from_list(dev_rows),\n            \"test\": HFDataset.from_list(test_rows),\n        }\n    )\n\n\nspr = load_or_create_dataset()\nprint({k: len(v) for k, v in spr.items()})\n\n# ----------------- vocabulary -----------------\nall_text = \" \".join(spr[\"train\"][\"sequence\"])\nvocab = sorted(set(all_text.split()))\ntok2idx = {tok: i + 2 for i, tok in enumerate(vocab)}  # 0 PAD, 1 UNK\ntok2idx[\"<PAD>\"], tok2idx[\"<UNK>\"] = 0, 1\nidx2tok = {i: t for t, i in tok2idx.items()}\nvocab_size = len(tok2idx)\nprint(f\"Vocab size: {vocab_size}\")\n\n\ndef encode_sequence(seq):\n    return [tok2idx.get(tok, 1) for tok in seq.strip().split()]\n\n\n# ----------------- torch dataset -----------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs, self.labels = hf_split[\"sequence\"], hf_split[\"label\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"x\": torch.tensor(encode_sequence(self.seqs[idx]), dtype=torch.long),\n            \"y\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate(batch):\n    xs = [b[\"x\"] for b in batch]\n    lens = [len(x) for x in xs]\n    maxlen = max(lens)\n    xs_pad = torch.zeros(len(xs), maxlen, dtype=torch.long)\n    for i, x in enumerate(xs):\n        xs_pad[i, : len(x)] = x\n    ys = torch.stack([b[\"y\"] for b in batch])\n    raw = [b[\"raw_seq\"] for b in batch]\n    return {\n        \"x\": xs_pad.to(device),\n        \"len\": torch.tensor(lens, dtype=torch.long).to(device),\n        \"y\": ys.to(device),\n        \"raw_seq\": raw,\n    }\n\n\nbatch_size = 64\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=batch_size, shuffle=True, collate_fn=collate\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=batch_size, shuffle=False, collate_fn=collate\n)\nn_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Num classes: {n_classes}\")\n\n\n# ----------------- models -----------------\nclass UniLSTMClassifier(nn.Module):\n    def __init__(self, vocab, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n        self.fc = nn.Linear(hid, n_out)\n\n    def forward(self, x, lengths):\n        em = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            em, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        return self.fc(h[-1])\n\n\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab, emb=64, hid=128, n_out=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, emb, padding_idx=0)\n        self.lstm = nn.LSTM(emb, hid, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hid * 2, n_out)\n\n    def forward(self, x, lengths):\n        em = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            em, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)  # h shape: (2, B, hid)\n        h_cat = torch.cat((h[0], h[1]), dim=1)  # (B, 2*hid)\n        return self.fc(h_cat)\n\n\n# ----------------- train / evaluate one run -----------------\ndef run_training(model_cls, num_epochs):\n    model = model_cls(vocab_size, n_out=n_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n    rec = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n    for ep in range(1, num_epochs + 1):\n        # training\n        model.train()\n        tloss = 0.0\n        for batch in train_loader:\n            optim.zero_grad()\n            out = model(batch[\"x\"], batch[\"len\"])\n            loss = criterion(out, batch[\"y\"])\n            loss.backward()\n            optim.step()\n            tloss += loss.item() * batch[\"y\"].size(0)\n        train_loss = tloss / len(train_loader.dataset)\n\n        # validation\n        model.eval()\n        vloss, all_seq, y_true, y_pred = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                out = model(batch[\"x\"], batch[\"len\"])\n                loss = criterion(out, batch[\"y\"])\n                vloss += loss.item() * batch[\"y\"].size(0)\n                preds = torch.argmax(out, 1).cpu().tolist()\n                y_pred.extend(preds)\n                y_true.extend(batch[\"y\"].cpu().tolist())\n                all_seq.extend(batch[\"raw_seq\"])\n        val_loss = vloss / len(dev_loader.dataset)\n        swa = shape_weighted_accuracy(all_seq, y_true, y_pred)\n        cwa = color_weighted_accuracy(all_seq, y_true, y_pred)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n\n        # record\n        rec[\"losses\"][\"train\"].append(train_loss)\n        rec[\"losses\"][\"val\"].append(val_loss)\n        rec[\"metrics\"][\"val\"].append(hwa)\n        rec[\"predictions\"].append(y_pred)\n        rec[\"ground_truth\"].append(y_true)\n        rec[\"timestamps\"].append(time.time())\n        print(\n            f\"Ep {ep:>2d}: tr_loss={train_loss:.4f} val_loss={val_loss:.4f} HWA={hwa:.3f}\"\n        )\n    return rec\n\n\n# ----------------- hyper-parameter sweep -----------------\nepoch_options = [5, 10, 20, 30]\n\nfor e in epoch_options:\n    print(f\"\\n=== UniLSTM training for {e} epochs ===\")\n    experiment_data[\"UNI_LSTM\"][\"SPR_BENCH\"][str(e)] = run_training(\n        UniLSTMClassifier, e\n    )\n\nfor e in epoch_options:\n    print(f\"\\n=== BiLSTM training for {e} epochs ===\")\n    experiment_data[\"BI_LSTM\"][\"SPR_BENCH\"][str(e)] = run_training(BiLSTMClassifier, e)\n\n# ----------------- save -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n"], "term_out": ["['Using device: cuda', '\\n', \"{'train': 600, 'dev': 200, 'test': 200}\", '\\n',\n'Vocab size: 18', '\\n', 'Num classes: 2', '\\n', '\\n=== Training for 5 epochs\n===', '\\n', 'Epochs=5 | Ep 1: tr_loss=0.6975 val_loss=0.6823 HWA=0.575', '\\n',\n'Epochs=5 | Ep 2: tr_loss=0.6801 val_loss=0.6843 HWA=0.561', '\\n', 'Epochs=5 |\nEp 3: tr_loss=0.6710 val_loss=0.6791 HWA=0.568', '\\n', 'Epochs=5 | Ep 4:\ntr_loss=0.6533 val_loss=0.6632 HWA=0.561', '\\n', 'Epochs=5 | Ep 5:\ntr_loss=0.6330 val_loss=0.6444 HWA=0.582', '\\n', '\\n=== Training for 10 epochs\n===', '\\n', 'Epochs=10 | Ep 1: tr_loss=0.6951 val_loss=0.6873 HWA=0.569', '\\n',\n'Epochs=10 | Ep 2: tr_loss=0.6810 val_loss=0.6873 HWA=0.579', '\\n', 'Epochs=10 |\nEp 3: tr_loss=0.6656 val_loss=0.6806 HWA=0.602', '\\n', 'Epochs=10 | Ep 4:\ntr_loss=0.6435 val_loss=0.6624 HWA=0.600', '\\n', 'Epochs=10 | Ep 5:\ntr_loss=0.6130 val_loss=0.6405 HWA=0.632', '\\n', 'Epochs=10 | Ep 6:\ntr_loss=0.5831 val_loss=0.6438 HWA=0.624', '\\n', 'Epochs=10 | Ep 7:\ntr_loss=0.5726 val_loss=0.6734 HWA=0.638', '\\n', 'Epochs=10 | Ep 8:\ntr_loss=0.5492 val_loss=0.6661 HWA=0.640', '\\n', 'Epochs=10 | Ep 9:\ntr_loss=0.5291 val_loss=0.6762 HWA=0.626', '\\n', 'Epochs=10 | Ep 10:\ntr_loss=0.5117 val_loss=0.6824 HWA=0.629', '\\n', '\\n=== Training for 20 epochs\n===', '\\n', 'Epochs=20 | Ep 1: tr_loss=0.6949 val_loss=0.6878 HWA=0.567', '\\n',\n'Epochs=20 | Ep 2: tr_loss=0.6781 val_loss=0.6839 HWA=0.563', '\\n', 'Epochs=20 |\nEp 3: tr_loss=0.6623 val_loss=0.6709 HWA=0.583', '\\n', 'Epochs=20 | Ep 4:\ntr_loss=0.6442 val_loss=0.6604 HWA=0.585', '\\n', 'Epochs=20 | Ep 5:\ntr_loss=0.6169 val_loss=0.6480 HWA=0.628', '\\n', 'Epochs=20 | Ep 6:\ntr_loss=0.5952 val_loss=0.6704 HWA=0.603', '\\n', 'Epochs=20 | Ep 7:\ntr_loss=0.5821 val_loss=0.6526 HWA=0.613', '\\n', 'Epochs=20 | Ep 8:\ntr_loss=0.5521 val_loss=0.6638 HWA=0.636', '\\n', 'Epochs=20 | Ep 9:\ntr_loss=0.5362 val_loss=0.6913 HWA=0.616', '\\n', 'Epochs=20 | Ep 10:\ntr_loss=0.5120 val_loss=0.7066 HWA=0.596', '\\n', 'Epochs=20 | Ep 11:\ntr_loss=0.5016 val_loss=0.7245 HWA=0.602', '\\n', 'Epochs=20 | Ep 12:\ntr_loss=0.4667 val_loss=0.7180 HWA=0.606', '\\n', 'Epochs=20 | Ep 13:\ntr_loss=0.4408 val_loss=0.7420 HWA=0.613', '\\n', 'Epochs=20 | Ep 14:\ntr_loss=0.4038 val_loss=0.8364 HWA=0.615', '\\n', 'Epochs=20 | Ep 15:\ntr_loss=0.3702 val_loss=0.8902 HWA=0.594', '\\n', 'Epochs=20 | Ep 16:\ntr_loss=0.3405 val_loss=0.8617 HWA=0.596', '\\n', 'Epochs=20 | Ep 17:\ntr_loss=0.3129 val_loss=0.9129 HWA=0.581', '\\n', 'Epochs=20 | Ep 18:\ntr_loss=0.2723 val_loss=0.9696 HWA=0.582', '\\n', 'Epochs=20 | Ep 19:\ntr_loss=0.2473 val_loss=1.0825 HWA=0.600', '\\n', 'Epochs=20 | Ep 20:\ntr_loss=0.2033 val_loss=1.1331 HWA=0.584', '\\n', '\\n=== Training for 30 epochs\n===', '\\n', 'Epochs=30 | Ep 1: tr_loss=0.6944 val_loss=0.6896 HWA=0.557', '\\n',\n'Epochs=30 | Ep 2: tr_loss=0.6790 val_loss=0.6852 HWA=0.569', '\\n', 'Epochs=30 |\nEp 3: tr_loss=0.6640 val_loss=0.6781 HWA=0.566', '\\n', 'Epochs=30 | Ep 4:\ntr_loss=0.6373 val_loss=0.6689 HWA=0.585', '\\n', 'Epochs=30 | Ep 5:\ntr_loss=0.6152 val_loss=0.6632 HWA=0.584', '\\n', 'Epochs=30 | Ep 6:\ntr_loss=0.5914 val_loss=0.6536 HWA=0.642', '\\n', 'Epochs=30 | Ep 7:\ntr_loss=0.5648 val_loss=0.6822 HWA=0.610', '\\n', 'Epochs=30 | Ep 8:\ntr_loss=0.5609 val_loss=0.6817 HWA=0.619', '\\n', 'Epochs=30 | Ep 9:\ntr_loss=0.5325 val_loss=0.6960 HWA=0.610', '\\n', 'Epochs=30 | Ep 10:\ntr_loss=0.5204 val_loss=0.6865 HWA=0.617', '\\n', 'Epochs=30 | Ep 11:\ntr_loss=0.4905 val_loss=0.6840 HWA=0.668', '\\n', 'Epochs=30 | Ep 12:\ntr_loss=0.4632 val_loss=0.7137 HWA=0.623', '\\n', 'Epochs=30 | Ep 13:\ntr_loss=0.4356 val_loss=0.7493 HWA=0.610', '\\n', 'Epochs=30 | Ep 14:\ntr_loss=0.4354 val_loss=0.7275 HWA=0.602', '\\n', 'Epochs=30 | Ep 15:\ntr_loss=0.3747 val_loss=0.7421 HWA=0.631', '\\n', 'Epochs=30 | Ep 16:\ntr_loss=0.3285 val_loss=0.7670 HWA=0.645', '\\n', 'Epochs=30 | Ep 17:\ntr_loss=0.2889 val_loss=0.7868 HWA=0.613', '\\n', 'Epochs=30 | Ep 18:\ntr_loss=0.2498 val_loss=0.8188 HWA=0.616', '\\n', 'Epochs=30 | Ep 19:\ntr_loss=0.2050 val_loss=0.9097 HWA=0.623', '\\n', 'Epochs=30 | Ep 20:\ntr_loss=0.1823 val_loss=0.8985 HWA=0.586', '\\n', 'Epochs=30 | Ep 21:\ntr_loss=0.1450 val_loss=0.9633 HWA=0.601', '\\n', 'Epochs=30 | Ep 22:\ntr_loss=0.1127 val_loss=1.0187 HWA=0.636', '\\n', 'Epochs=30 | Ep 23:\ntr_loss=0.0934 val_loss=1.0440 HWA=0.637', '\\n', 'Epochs=30 | Ep 24:\ntr_loss=0.0711 val_loss=1.0928 HWA=0.614', '\\n', 'Epochs=30 | Ep 25:\ntr_loss=0.0535 val_loss=1.1703 HWA=0.613', '\\n', 'Epochs=30 | Ep 26:\ntr_loss=0.0414 val_loss=1.2120 HWA=0.616', '\\n', 'Epochs=30 | Ep 27:\ntr_loss=0.0329 val_loss=1.2912 HWA=0.625', '\\n', 'Epochs=30 | Ep 28:\ntr_loss=0.0255 val_loss=1.2972 HWA=0.607', '\\n', 'Epochs=30 | Ep 29:\ntr_loss=0.0209 val_loss=1.3289 HWA=0.616', '\\n', 'Epochs=30 | Ep 30:\ntr_loss=0.0171 val_loss=1.3624 HWA=0.620', '\\n', 'Saved experiment_data.npy',\n'\\n', 'Execution time: 3 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 600, 'dev': 200, 'test': 200}\", '\\n',\n'Vocab size:', ' ', '18', '\\n', 'Num classes:', ' ', '2', '\\n', '\\n=== LSTM:\ntraining for 5 epochs ===', '\\n', '[LSTM] Ep 1/5 | tr_loss=0.6975\nval_loss=0.6823 HWA=0.575', '\\n', '[LSTM] Ep 2/5 | tr_loss=0.6801\nval_loss=0.6843 HWA=0.561', '\\n', '[LSTM] Ep 3/5 | tr_loss=0.6710\nval_loss=0.6791 HWA=0.568', '\\n', '[LSTM] Ep 4/5 | tr_loss=0.6533\nval_loss=0.6632 HWA=0.561', '\\n', '[LSTM] Ep 5/5 | tr_loss=0.6330\nval_loss=0.6444 HWA=0.582', '\\n', '\\n=== LSTM: training for 10 epochs ===',\n'\\n', '[LSTM] Ep 1/10 | tr_loss=0.6951 val_loss=0.6873 HWA=0.569', '\\n', '[LSTM]\nEp 2/10 | tr_loss=0.6810 val_loss=0.6873 HWA=0.579', '\\n', '[LSTM] Ep 3/10 |\ntr_loss=0.6656 val_loss=0.6806 HWA=0.602', '\\n', '[LSTM] Ep 4/10 |\ntr_loss=0.6435 val_loss=0.6624 HWA=0.600', '\\n', '[LSTM] Ep 5/10 |\ntr_loss=0.6130 val_loss=0.6405 HWA=0.632', '\\n', '[LSTM] Ep 6/10 |\ntr_loss=0.5831 val_loss=0.6438 HWA=0.624', '\\n', '[LSTM] Ep 7/10 |\ntr_loss=0.5726 val_loss=0.6734 HWA=0.638', '\\n', '[LSTM] Ep 8/10 |\ntr_loss=0.5492 val_loss=0.6661 HWA=0.640', '\\n', '[LSTM] Ep 9/10 |\ntr_loss=0.5291 val_loss=0.6762 HWA=0.626', '\\n', '[LSTM] Ep 10/10 |\ntr_loss=0.5117 val_loss=0.6824 HWA=0.629', '\\n', '\\n=== LSTM: training for 20\nepochs ===', '\\n', '[LSTM] Ep 1/20 | tr_loss=0.6949 val_loss=0.6878 HWA=0.567',\n'\\n', '[LSTM] Ep 2/20 | tr_loss=0.6781 val_loss=0.6839 HWA=0.563', '\\n', '[LSTM]\nEp 3/20 | tr_loss=0.6623 val_loss=0.6709 HWA=0.583', '\\n', '[LSTM] Ep 4/20 |\ntr_loss=0.6442 val_loss=0.6604 HWA=0.585', '\\n', '[LSTM] Ep 5/20 |\ntr_loss=0.6169 val_loss=0.6480 HWA=0.628', '\\n', '[LSTM] Ep 6/20 |\ntr_loss=0.5952 val_loss=0.6704 HWA=0.603', '\\n', '[LSTM] Ep 7/20 |\ntr_loss=0.5821 val_loss=0.6526 HWA=0.613', '\\n', '[LSTM] Ep 8/20 |\ntr_loss=0.5521 val_loss=0.6638 HWA=0.636', '\\n', '[LSTM] Ep 9/20 |\ntr_loss=0.5362 val_loss=0.6913 HWA=0.616', '\\n', '[LSTM] Ep 10/20 |\ntr_loss=0.5120 val_loss=0.7066 HWA=0.596', '\\n', '[LSTM] Ep 11/20 |\ntr_loss=0.5016 val_loss=0.7245 HWA=0.602', '\\n', '[LSTM] Ep 12/20 |\ntr_loss=0.4667 val_loss=0.7180 HWA=0.606', '\\n', '[LSTM] Ep 13/20 |\ntr_loss=0.4408 val_loss=0.7420 HWA=0.613', '\\n', '[LSTM] Ep 14/20 |\ntr_loss=0.4038 val_loss=0.8364 HWA=0.615', '\\n', '[LSTM] Ep 15/20 |\ntr_loss=0.3702 val_loss=0.8902 HWA=0.594', '\\n', '[LSTM] Ep 16/20 |\ntr_loss=0.3405 val_loss=0.8617 HWA=0.596', '\\n', '[LSTM] Ep 17/20 |\ntr_loss=0.3129 val_loss=0.9129 HWA=0.581', '\\n', '[LSTM] Ep 18/20 |\ntr_loss=0.2723 val_loss=0.9696 HWA=0.582', '\\n', '[LSTM] Ep 19/20 |\ntr_loss=0.2473 val_loss=1.0825 HWA=0.600', '\\n', '[LSTM] Ep 20/20 |\ntr_loss=0.2033 val_loss=1.1331 HWA=0.584', '\\n', '\\n=== LSTM: training for 30\nepochs ===', '\\n', '[LSTM] Ep 1/30 | tr_loss=0.6944 val_loss=0.6896 HWA=0.557',\n'\\n', '[LSTM] Ep 2/30 | tr_loss=0.6790 val_loss=0.6852 HWA=0.569', '\\n', '[LSTM]\nEp 3/30 | tr_loss=0.6640 val_loss=0.6781 HWA=0.566', '\\n', '[LSTM] Ep 4/30 |\ntr_loss=0.6373 val_loss=0.6689 HWA=0.585', '\\n', '[LSTM] Ep 5/30 |\ntr_loss=0.6152 val_loss=0.6632 HWA=0.584', '\\n', '[LSTM] Ep 6/30 |\ntr_loss=0.5914 val_loss=0.6536 HWA=0.642', '\\n', '[LSTM] Ep 7/30 |\ntr_loss=0.5648 val_loss=0.6822 HWA=0.610', '\\n', '[LSTM] Ep 8/30 |\ntr_loss=0.5609 val_loss=0.6817 HWA=0.619', '\\n', '[LSTM] Ep 9/30 |\ntr_loss=0.5325 val_loss=0.6960 HWA=0.610', '\\n', '[LSTM] Ep 10/30 |\ntr_loss=0.5204 val_loss=0.6865 HWA=0.617', '\\n', '[LSTM] Ep 11/30 |\ntr_loss=0.4905 val_loss=0.6840 HWA=0.668', '\\n', '[LSTM] Ep 12/30 |\ntr_loss=0.4632 val_loss=0.7137 HWA=0.623', '\\n', '[LSTM] Ep 13/30 |\ntr_loss=0.4356 val_loss=0.7493 HWA=0.610', '\\n', '[LSTM] Ep 14/30 |\ntr_loss=0.4354 val_loss=0.7275 HWA=0.602', '\\n', '[LSTM] Ep 15/30 |\ntr_loss=0.3747 val_loss=0.7421 HWA=0.631', '\\n', '[LSTM] Ep 16/30 |\ntr_loss=0.3285 val_loss=0.7670 HWA=0.645', '\\n', '[LSTM] Ep 17/30 |\ntr_loss=0.2889 val_loss=0.7868 HWA=0.613', '\\n', '[LSTM] Ep 18/30 |\ntr_loss=0.2498 val_loss=0.8188 HWA=0.616', '\\n', '[LSTM] Ep 19/30 |\ntr_loss=0.2050 val_loss=0.9097 HWA=0.623', '\\n', '[LSTM] Ep 20/30 |\ntr_loss=0.1823 val_loss=0.8985 HWA=0.586', '\\n', '[LSTM] Ep 21/30 |\ntr_loss=0.1450 val_loss=0.9633 HWA=0.601', '\\n', '[LSTM] Ep 22/30 |\ntr_loss=0.1127 val_loss=1.0187 HWA=0.636', '\\n', '[LSTM] Ep 23/30 |\ntr_loss=0.0934 val_loss=1.0440 HWA=0.637', '\\n', '[LSTM] Ep 24/30 |\ntr_loss=0.0711 val_loss=1.0928 HWA=0.614', '\\n', '[LSTM] Ep 25/30 |\ntr_loss=0.0535 val_loss=1.1703 HWA=0.613', '\\n', '[LSTM] Ep 26/30 |\ntr_loss=0.0414 val_loss=1.2120 HWA=0.616', '\\n', '[LSTM] Ep 27/30 |\ntr_loss=0.0329 val_loss=1.2912 HWA=0.625', '\\n', '[LSTM] Ep 28/30 |\ntr_loss=0.0255 val_loss=1.2972 HWA=0.607', '\\n', '[LSTM] Ep 29/30 |\ntr_loss=0.0209 val_loss=1.3289 HWA=0.616', '\\n', '[LSTM] Ep 30/30 |\ntr_loss=0.0171 val_loss=1.3624 HWA=0.620', '\\n', '\\n=== BOE: training for 5\nepochs ===', '\\n', '[BOE] Ep 1/5 | tr_loss=0.7094 val_loss=0.7091 HWA=0.498',\n'\\n', '[BOE] Ep 2/5 | tr_loss=0.7007 val_loss=0.7047 HWA=0.501', '\\n', '[BOE] Ep\n3/5 | tr_loss=0.6956 val_loss=0.7011 HWA=0.505', '\\n', '[BOE] Ep 4/5 |\ntr_loss=0.6909 val_loss=0.6991 HWA=0.511', '\\n', '[BOE] Ep 5/5 | tr_loss=0.6876\nval_loss=0.6981 HWA=0.536', '\\n', '\\n=== BOE: training for 10 epochs ===', '\\n',\n'[BOE] Ep 1/10 | tr_loss=0.7110 val_loss=0.7073 HWA=0.520', '\\n', '[BOE] Ep 2/10\n| tr_loss=0.7025 val_loss=0.7016 HWA=0.503', '\\n', '[BOE] Ep 3/10 |\ntr_loss=0.6971 val_loss=0.6990 HWA=0.534', '\\n', '[BOE] Ep 4/10 | tr_loss=0.6926\nval_loss=0.6969 HWA=0.554', '\\n', '[BOE] Ep 5/10 | tr_loss=0.6895\nval_loss=0.6949 HWA=0.569', '\\n', '[BOE] Ep 6/10 | tr_loss=0.6874\nval_loss=0.6938 HWA=0.575', '\\n', '[BOE] Ep 7/10 | tr_loss=0.6849\nval_loss=0.6936 HWA=0.587', '\\n', '[BOE] Ep 8/10 | tr_loss=0.6852\nval_loss=0.6939 HWA=0.593', '\\n', '[BOE] Ep 9/10 | tr_loss=0.6831\nval_loss=0.6935 HWA=0.597', '\\n', '[BOE] Ep 10/10 | tr_loss=0.6823\nval_loss=0.6939 HWA=0.581', '\\n', '\\n=== BOE: training for 20 epochs ===', '\\n',\n'[BOE] Ep 1/20 | tr_loss=0.7018 val_loss=0.7066 HWA=0.505', '\\n', '[BOE] Ep 2/20\n| tr_loss=0.6952 val_loss=0.7037 HWA=0.520', '\\n', '[BOE] Ep 3/20 |\ntr_loss=0.6917 val_loss=0.7012 HWA=0.526', '\\n', '[BOE] Ep 4/20 | tr_loss=0.6895\nval_loss=0.6992 HWA=0.548', '\\n', '[BOE] Ep 5/20 | tr_loss=0.6878\nval_loss=0.6976 HWA=0.535', '\\n', '[BOE] Ep 6/20 | tr_loss=0.6855\nval_loss=0.6976 HWA=0.530', '\\n', '[BOE] Ep 7/20 | tr_loss=0.6843\nval_loss=0.6985 HWA=0.564', '\\n', '[BOE] Ep 8/20 | tr_loss=0.6833\nval_loss=0.6974 HWA=0.541', '\\n', '[BOE] Ep 9/20 | tr_loss=0.6829\nval_loss=0.6971 HWA=0.539', '\\n', '[BOE] Ep 10/20 | tr_loss=0.6824\nval_loss=0.6968 HWA=0.539', '\\n', '[BOE] Ep 11/20 | tr_loss=0.6815\nval_loss=0.6974 HWA=0.548', '\\n', '[BOE] Ep 12/20 | tr_loss=0.6813\nval_loss=0.6977 HWA=0.554', '\\n', '[BOE] Ep 13/20 | tr_loss=0.6808\nval_loss=0.6974 HWA=0.548', '\\n', '[BOE] Ep 14/20 | tr_loss=0.6809\nval_loss=0.6967 HWA=0.539', '\\n', '[BOE] Ep 15/20 | tr_loss=0.6804\nval_loss=0.6969 HWA=0.538', '\\n', '[BOE] Ep 16/20 | tr_loss=0.6802\nval_loss=0.6978 HWA=0.576', '\\n', '[BOE] Ep 17/20 | tr_loss=0.6798\nval_loss=0.6979 HWA=0.571', '\\n', '[BOE] Ep 18/20 | tr_loss=0.6799\nval_loss=0.6986 HWA=0.576', '\\n', '[BOE] Ep 19/20 | tr_loss=0.6802\nval_loss=0.6980 HWA=0.564', '\\n', '[BOE] Ep 20/20 | tr_loss=0.6801\nval_loss=0.6983 HWA=0.569', '\\n', '\\n=== BOE: training for 30 epochs ===', '\\n',\n'[BOE] Ep 1/30 | tr_loss=0.7022 val_loss=0.7028 HWA=0.465', '\\n', '[BOE] Ep 2/30\n| tr_loss=0.6954 val_loss=0.7004 HWA=0.468', '\\n', '[BOE] Ep 3/30 |\ntr_loss=0.6923 val_loss=0.6991 HWA=0.516', '\\n', '[BOE] Ep 4/30 | tr_loss=0.6893\nval_loss=0.6988 HWA=0.554', '\\n', '[BOE] Ep 5/30 | tr_loss=0.6873\nval_loss=0.6980 HWA=0.562', '\\n', '[BOE] Ep 6/30 | tr_loss=0.6857\nval_loss=0.6984 HWA=0.582', '\\n', '[BOE] Ep 7/30 | tr_loss=0.6845\nval_loss=0.6985 HWA=0.585', '\\n', '[BOE] Ep 8/30 | tr_loss=0.6835\nval_loss=0.6982 HWA=0.578', '\\n', '[BOE] Ep 9/30 | tr_loss=0.6829\nval_loss=0.6983 HWA=0.562', '\\n', '[BOE] Ep 10/30 | tr_loss=0.6822\nval_loss=0.6983 HWA=0.557', '\\n', '[BOE] Ep 11/30 | tr_loss=0.6817\nval_loss=0.6983 HWA=0.556', '\\n', '[BOE] Ep 12/30 | tr_loss=0.6817\nval_loss=0.6984 HWA=0.551', '\\n', '[BOE] Ep 13/30 | tr_loss=0.6813\nval_loss=0.6976 HWA=0.566', '\\n', '[BOE] Ep 14/30 | tr_loss=0.6807\nval_loss=0.6978 HWA=0.570', '\\n', '[BOE] Ep 15/30 | tr_loss=0.6806\nval_loss=0.6985 HWA=0.548', '\\n', '[BOE] Ep 16/30 | tr_loss=0.6806\nval_loss=0.6982 HWA=0.554', '\\n', '[BOE] Ep 17/30 | tr_loss=0.6802\nval_loss=0.6981 HWA=0.568', '\\n', '[BOE] Ep 18/30 | tr_loss=0.6802\nval_loss=0.6983 HWA=0.571', '\\n', '[BOE] Ep 19/30 | tr_loss=0.6801\nval_loss=0.6991 HWA=0.557', '\\n', '[BOE] Ep 20/30 | tr_loss=0.6798\nval_loss=0.6996 HWA=0.551', '\\n', '[BOE] Ep 21/30 | tr_loss=0.6800\nval_loss=0.6989 HWA=0.551', '\\n', '[BOE] Ep 22/30 | tr_loss=0.6797\nval_loss=0.6989 HWA=0.563', '\\n', '[BOE] Ep 23/30 | tr_loss=0.6795\nval_loss=0.6987 HWA=0.553', '\\n', '[BOE] Ep 24/30 | tr_loss=0.6795\nval_loss=0.6986 HWA=0.559', '\\n', '[BOE] Ep 25/30 | tr_loss=0.6794\nval_loss=0.6989 HWA=0.559', '\\n', '[BOE] Ep 26/30 | tr_loss=0.6797\nval_loss=0.6994 HWA=0.554', '\\n', '[BOE] Ep 27/30 | tr_loss=0.6792\nval_loss=0.6995 HWA=0.554', '\\n', '[BOE] Ep 28/30 | tr_loss=0.6796\nval_loss=0.6992 HWA=0.549', '\\n', '[BOE] Ep 29/30 | tr_loss=0.6794\nval_loss=0.6991 HWA=0.563', '\\n', '[BOE] Ep 30/30 | tr_loss=0.6795\nval_loss=0.6985 HWA=0.573', '\\n', 'Saved experiment_data.npy', '\\n', 'Execution\ntime: 6 seconds seconds (time limit is 30 minutes).']", "['Device:', ' ', 'cuda', '\\n', \"{'SetA': {'train': 600, 'dev': 200, 'test':\n200}, 'SetB': {'train': 600, 'dev': 200, 'test': 200}, 'SetC': {'train': 600,\n'dev': 200, 'test': 200}}\", '\\n', '\\n=== Training on SetA ===', '\\n', 'Ep01:\ntr_loss=0.699 val_loss=0.684 HWA=0.571', '\\n', 'Ep02: tr_loss=0.682\nval_loss=0.684 HWA=0.573', '\\n', 'Ep03: tr_loss=0.674 val_loss=0.681 HWA=0.577',\n'\\n', 'Ep04: tr_loss=0.658 val_loss=0.668 HWA=0.601', '\\n', 'Ep05: tr_loss=0.637\nval_loss=0.650 HWA=0.607', '\\n', 'Ep06: tr_loss=0.607 val_loss=0.651 HWA=0.591',\n'\\n', 'Ep07: tr_loss=0.586 val_loss=0.641 HWA=0.641', '\\n', 'Ep08: tr_loss=0.557\nval_loss=0.654 HWA=0.634', '\\n', 'Ep09: tr_loss=0.538 val_loss=0.660 HWA=0.626',\n'\\n', 'Ep10: tr_loss=0.520 val_loss=0.667 HWA=0.617', '\\n', '\\n=== Training on\nSetB ===', '\\n', 'Ep01: tr_loss=0.528 val_loss=0.302 HWA=0.967', '\\n', 'Ep02:\ntr_loss=0.194 val_loss=0.189 HWA=0.967', '\\n', 'Ep03: tr_loss=0.183\nval_loss=0.173 HWA=0.967', '\\n', 'Ep04: tr_loss=0.155 val_loss=0.175 HWA=0.967',\n'\\n', 'Ep05: tr_loss=0.153 val_loss=0.173 HWA=0.967', '\\n', 'Ep06: tr_loss=0.143\nval_loss=0.178 HWA=0.967', '\\n', 'Ep07: tr_loss=0.136 val_loss=0.182 HWA=0.967',\n'\\n', 'Ep08: tr_loss=0.129 val_loss=0.192 HWA=0.967', '\\n', 'Ep09: tr_loss=0.123\nval_loss=0.201 HWA=0.967', '\\n', 'Ep10: tr_loss=0.115 val_loss=0.200 HWA=0.967',\n'\\n', '\\n=== Training on SetC ===', '\\n', 'Ep01: tr_loss=0.673 val_loss=0.632\nHWA=0.707', '\\n', 'Ep02: tr_loss=0.645 val_loss=0.633 HWA=0.711', '\\n', 'Ep03:\ntr_loss=0.636 val_loss=0.639 HWA=0.673', '\\n', 'Ep04: tr_loss=0.624\nval_loss=0.641 HWA=0.658', '\\n', 'Ep05: tr_loss=0.613 val_loss=0.653 HWA=0.671',\n'\\n', 'Ep06: tr_loss=0.603 val_loss=0.671 HWA=0.590', '\\n', 'Ep07: tr_loss=0.588\nval_loss=0.660 HWA=0.638', '\\n', 'Ep08: tr_loss=0.562 val_loss=0.663 HWA=0.648',\n'\\n', 'Ep09: tr_loss=0.528 val_loss=0.653 HWA=0.646', '\\n', 'Ep10: tr_loss=0.477\nval_loss=0.634 HWA=0.661', '\\n', 'Saved experiment_data.npy', '\\n', 'Execution\ntime: 3 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', \"{'train': 600, 'dev': 200, 'test': 200}\",\n'\\n', 'Token vocab size:', ' ', '18', '\\n', 'Shape vocab:', ' ', '6', ' ',\n'Color vocab:', ' ', '6', '\\n', 'Num classes:', ' ', '2', '\\n', '\\n=== BASELINE\n| training for 5 epochs ===', '\\n', '[baseline] Ep 1/5  tr_loss=0.6975\nval_loss=0.6823  HWA=0.575', '\\n', '[baseline] Ep 2/5  tr_loss=0.6801\nval_loss=0.6843  HWA=0.561', '\\n', '[baseline] Ep 3/5  tr_loss=0.6710\nval_loss=0.6791  HWA=0.568', '\\n', '[baseline] Ep 4/5  tr_loss=0.6533\nval_loss=0.6632  HWA=0.561', '\\n', '[baseline] Ep 5/5  tr_loss=0.6330\nval_loss=0.6444  HWA=0.582', '\\n', '\\n=== BASELINE | training for 10 epochs\n===', '\\n', '[baseline] Ep 1/10  tr_loss=0.6951  val_loss=0.6873  HWA=0.569',\n'\\n', '[baseline] Ep 2/10  tr_loss=0.6810  val_loss=0.6873  HWA=0.579', '\\n',\n'[baseline] Ep 3/10  tr_loss=0.6656  val_loss=0.6806  HWA=0.602', '\\n',\n'[baseline] Ep 4/10  tr_loss=0.6435  val_loss=0.6624  HWA=0.600', '\\n',\n'[baseline] Ep 5/10  tr_loss=0.6130  val_loss=0.6405  HWA=0.632', '\\n',\n'[baseline] Ep 6/10  tr_loss=0.5831  val_loss=0.6438  HWA=0.624', '\\n',\n'[baseline] Ep 7/10  tr_loss=0.5726  val_loss=0.6734  HWA=0.638', '\\n',\n'[baseline] Ep 8/10  tr_loss=0.5492  val_loss=0.6661  HWA=0.640', '\\n',\n'[baseline] Ep 9/10  tr_loss=0.5291  val_loss=0.6762  HWA=0.626', '\\n',\n'[baseline] Ep 10/10  tr_loss=0.5117  val_loss=0.6824  HWA=0.629', '\\n', '\\n===\nFACTORIZED | training for 5 epochs ===', '\\n', '[factorized] Ep 1/5\ntr_loss=0.7076  val_loss=0.6884  HWA=0.569', '\\n', '[factorized] Ep 2/5\ntr_loss=0.6837  val_loss=0.6855  HWA=0.585', '\\n', '[factorized] Ep 3/5\ntr_loss=0.6748  val_loss=0.6789  HWA=0.560', '\\n', '[factorized] Ep 4/5\ntr_loss=0.6604  val_loss=0.6636  HWA=0.564', '\\n', '[factorized] Ep 5/5\ntr_loss=0.6314  val_loss=0.6459  HWA=0.615', '\\n', '\\n=== FACTORIZED | training\nfor 10 epochs ===', '\\n', '[factorized] Ep 1/10  tr_loss=0.6993  val_loss=0.6901\nHWA=0.508', '\\n', '[factorized] Ep 2/10  tr_loss=0.6831  val_loss=0.6817\nHWA=0.588', '\\n', '[factorized] Ep 3/10  tr_loss=0.6720  val_loss=0.6674\nHWA=0.609', '\\n', '[factorized] Ep 4/10  tr_loss=0.6442  val_loss=0.6615\nHWA=0.601', '\\n', '[factorized] Ep 5/10  tr_loss=0.6117  val_loss=0.6473\nHWA=0.596', '\\n', '[factorized] Ep 6/10  tr_loss=0.6044  val_loss=0.6604\nHWA=0.640', '\\n', '[factorized] Ep 7/10  tr_loss=0.5836  val_loss=0.6476\nHWA=0.622', '\\n', '[factorized] Ep 8/10  tr_loss=0.5659  val_loss=0.6471\nHWA=0.653', '\\n', '[factorized] Ep 9/10  tr_loss=0.5497  val_loss=0.6636\nHWA=0.635', '\\n', '[factorized] Ep 10/10  tr_loss=0.5299  val_loss=0.6716\nHWA=0.640', '\\n', 'Saved experiment_data.npy', '\\n', 'Execution time: 3 seconds\nseconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 600, 'dev': 200, 'test': 200}\", '\\n',\n'Vocab size: 18', '\\n', 'Num classes: 2', '\\n', '\\n=== Baseline packed |\nepochs=5 ===', '\\n', 'Ep 1/5: tr_loss=0.6975 val_loss=0.6823 HWA=0.575', '\\n',\n'Ep 2/5: tr_loss=0.6801 val_loss=0.6843 HWA=0.561', '\\n', 'Ep 3/5:\ntr_loss=0.6710 val_loss=0.6791 HWA=0.568', '\\n', 'Ep 4/5: tr_loss=0.6533\nval_loss=0.6632 HWA=0.561', '\\n', 'Ep 5/5: tr_loss=0.6330 val_loss=0.6444\nHWA=0.582', '\\n', '\\n=== Padding-mask removal | epochs=5 ===', '\\n', 'Ep 1/5:\ntr_loss=0.6811 val_loss=0.6617 HWA=0.569', '\\n', 'Ep 2/5: tr_loss=0.6467\nval_loss=0.6434 HWA=0.659', '\\n', 'Ep 3/5: tr_loss=0.6198 val_loss=0.6328\nHWA=0.594', '\\n', 'Ep 4/5: tr_loss=0.6057 val_loss=0.6446 HWA=0.598', '\\n', 'Ep\n5/5: tr_loss=0.5930 val_loss=0.6122 HWA=0.586', '\\n', '\\n=== Baseline packed |\nepochs=10 ===', '\\n', 'Ep 1/10: tr_loss=0.7003 val_loss=0.6920 HWA=0.536', '\\n',\n'Ep 2/10: tr_loss=0.6816 val_loss=0.6923 HWA=0.554', '\\n', 'Ep 3/10:\ntr_loss=0.6726 val_loss=0.6876 HWA=0.560', '\\n', 'Ep 4/10: tr_loss=0.6612\nval_loss=0.6795 HWA=0.571', '\\n', 'Ep 5/10: tr_loss=0.6367 val_loss=0.6738\nHWA=0.568', '\\n', 'Ep 6/10: tr_loss=0.6191 val_loss=0.6622 HWA=0.628', '\\n', 'Ep\n7/10: tr_loss=0.5925 val_loss=0.6551 HWA=0.640', '\\n', 'Ep 8/10: tr_loss=0.5601\nval_loss=0.6732 HWA=0.607', '\\n', 'Ep 9/10: tr_loss=0.5348 val_loss=0.6889\nHWA=0.613', '\\n', 'Ep 10/10: tr_loss=0.5117 val_loss=0.6897 HWA=0.612', '\\n',\n'\\n=== Padding-mask removal | epochs=10 ===', '\\n', 'Ep 1/10: tr_loss=0.6888\nval_loss=0.6718 HWA=0.520', '\\n', 'Ep 2/10: tr_loss=0.6572 val_loss=0.6484\nHWA=0.613', '\\n', 'Ep 3/10: tr_loss=0.6285 val_loss=0.6272 HWA=0.628', '\\n', 'Ep\n4/10: tr_loss=0.6038 val_loss=0.6255 HWA=0.616', '\\n', 'Ep 5/10: tr_loss=0.5865\nval_loss=0.6261 HWA=0.619', '\\n', 'Ep 6/10: tr_loss=0.5734 val_loss=0.6154\nHWA=0.620', '\\n', 'Ep 7/10: tr_loss=0.5629 val_loss=0.6113 HWA=0.616', '\\n', 'Ep\n8/10: tr_loss=0.5369 val_loss=0.6015 HWA=0.660', '\\n', 'Ep 9/10: tr_loss=0.5050\nval_loss=0.5760 HWA=0.643', '\\n', 'Ep 10/10: tr_loss=0.4595 val_loss=0.5443\nHWA=0.727', '\\n', '\\n=== Baseline packed | epochs=20 ===', '\\n', 'Ep 1/20:\ntr_loss=0.6918 val_loss=0.6899 HWA=0.570', '\\n', 'Ep 2/20: tr_loss=0.6765\nval_loss=0.6845 HWA=0.571', '\\n', 'Ep 3/20: tr_loss=0.6651 val_loss=0.6782\nHWA=0.556', '\\n', 'Ep 4/20: tr_loss=0.6445 val_loss=0.6556 HWA=0.603', '\\n', 'Ep\n5/20: tr_loss=0.6204 val_loss=0.6402 HWA=0.583', '\\n', 'Ep 6/20: tr_loss=0.5906\nval_loss=0.6386 HWA=0.591', '\\n', 'Ep 7/20: tr_loss=0.5705 val_loss=0.6448\nHWA=0.647', '\\n', 'Ep 8/20: tr_loss=0.5504 val_loss=0.6615 HWA=0.606', '\\n', 'Ep\n9/20: tr_loss=0.5304 val_loss=0.6732 HWA=0.634', '\\n', 'Ep 10/20: tr_loss=0.5009\nval_loss=0.7088 HWA=0.610', '\\n', 'Ep 11/20: tr_loss=0.4751 val_loss=0.6930\nHWA=0.617', '\\n', 'Ep 12/20: tr_loss=0.4452 val_loss=0.7221 HWA=0.626', '\\n',\n'Ep 13/20: tr_loss=0.4106 val_loss=0.8049 HWA=0.634', '\\n', 'Ep 14/20:\ntr_loss=0.3849 val_loss=0.8117 HWA=0.605', '\\n', 'Ep 15/20: tr_loss=0.3392\nval_loss=0.8309 HWA=0.615', '\\n', 'Ep 16/20: tr_loss=0.3024 val_loss=0.8847\nHWA=0.602', '\\n', 'Ep 17/20: tr_loss=0.2830 val_loss=0.9743 HWA=0.613', '\\n',\n'Ep 18/20: tr_loss=0.2361 val_loss=1.0297 HWA=0.615', '\\n', 'Ep 19/20:\ntr_loss=0.2047 val_loss=1.0666 HWA=0.621', '\\n', 'Ep 20/20: tr_loss=0.1761\nval_loss=1.1195 HWA=0.616', '\\n', '\\n=== Padding-mask removal | epochs=20 ===',\n'\\n', 'Ep 1/20: tr_loss=0.6761 val_loss=0.6592 HWA=0.612', '\\n', 'Ep 2/20:\ntr_loss=0.6441 val_loss=0.6423 HWA=0.599', '\\n', 'Ep 3/20: tr_loss=0.6195\nval_loss=0.6273 HWA=0.584', '\\n', 'Ep 4/20: tr_loss=0.6022 val_loss=0.6207\nHWA=0.633', '\\n', 'Ep 5/20: tr_loss=0.5870 val_loss=0.6173 HWA=0.627', '\\n', 'Ep\n6/20: tr_loss=0.5779 val_loss=0.5882 HWA=0.640', '\\n', 'Ep 7/20: tr_loss=0.5525\nval_loss=0.5709 HWA=0.625', '\\n', 'Ep 8/20: tr_loss=0.5175 val_loss=0.5233\nHWA=0.761', '\\n', 'Ep 9/20: tr_loss=0.4267 val_loss=0.3100 HWA=0.911', '\\n', 'Ep\n10/20: tr_loss=0.1749 val_loss=0.0610 HWA=0.989', '\\n', 'Ep 11/20:\ntr_loss=0.0345 val_loss=0.0224 HWA=1.000', '\\n', 'Ep 12/20: tr_loss=0.0136\nval_loss=0.0134 HWA=1.000', '\\n', 'Ep 13/20: tr_loss=0.0084 val_loss=0.0094\nHWA=1.000', '\\n', 'Ep 14/20: tr_loss=0.0055 val_loss=0.0097 HWA=1.000', '\\n',\n'Ep 15/20: tr_loss=0.0040 val_loss=0.0068 HWA=1.000', '\\n', 'Ep 16/20:\ntr_loss=0.0032 val_loss=0.0061 HWA=1.000', '\\n', 'Ep 17/20: tr_loss=0.0027\nval_loss=0.0058 HWA=1.000', '\\n', 'Ep 18/20: tr_loss=0.0023 val_loss=0.0052\nHWA=1.000', '\\n', 'Ep 19/20: tr_loss=0.0021 val_loss=0.0048 HWA=1.000', '\\n',\n'Ep 20/20: tr_loss=0.0019 val_loss=0.0044 HWA=1.000', '\\n', '\\n=== Baseline\npacked | epochs=30 ===', '\\n', 'Ep 1/30: tr_loss=0.6937 val_loss=0.6956\nHWA=0.518', '\\n', 'Ep 2/30: tr_loss=0.6775 val_loss=0.6888 HWA=0.559', '\\n', 'Ep\n3/30: tr_loss=0.6615 val_loss=0.6733 HWA=0.597', '\\n', 'Ep 4/30: tr_loss=0.6367\nval_loss=0.6522 HWA=0.582', '\\n', 'Ep 5/30: tr_loss=0.6145 val_loss=0.6340\nHWA=0.644', '\\n', 'Ep 6/30: tr_loss=0.5917 val_loss=0.6311 HWA=0.633', '\\n', 'Ep\n7/30: tr_loss=0.5731 val_loss=0.6426 HWA=0.625', '\\n', 'Ep 8/30: tr_loss=0.5518\nval_loss=0.6817 HWA=0.598', '\\n', 'Ep 9/30: tr_loss=0.5358 val_loss=0.6811\nHWA=0.603', '\\n', 'Ep 10/30: tr_loss=0.5245 val_loss=0.6829 HWA=0.619', '\\n',\n'Ep 11/30: tr_loss=0.4929 val_loss=0.7302 HWA=0.601', '\\n', 'Ep 12/30:\ntr_loss=0.4621 val_loss=0.7369 HWA=0.618', '\\n', 'Ep 13/30: tr_loss=0.4436\nval_loss=0.7517 HWA=0.613', '\\n', 'Ep 14/30: tr_loss=0.4155 val_loss=0.7781\nHWA=0.568', '\\n', 'Ep 15/30: tr_loss=0.3718 val_loss=0.8252 HWA=0.603', '\\n',\n'Ep 16/30: tr_loss=0.3362 val_loss=0.9073 HWA=0.608', '\\n', 'Ep 17/30:\ntr_loss=0.3272 val_loss=0.9178 HWA=0.609', '\\n', 'Ep 18/30: tr_loss=0.2682\nval_loss=0.9309 HWA=0.608', '\\n', 'Ep 19/30: tr_loss=0.2297 val_loss=1.0615\nHWA=0.592', '\\n', 'Ep 20/30: tr_loss=0.2104 val_loss=1.0541 HWA=0.604', '\\n',\n'Ep 21/30: tr_loss=0.1738 val_loss=1.1077 HWA=0.599', '\\n', 'Ep 22/30:\ntr_loss=0.1545 val_loss=1.1948 HWA=0.598', '\\n', 'Ep 23/30: tr_loss=0.1188\nval_loss=1.2864 HWA=0.592', '\\n', 'Ep 24/30: tr_loss=0.0922 val_loss=1.3846\nHWA=0.595', '\\n', 'Ep 25/30: tr_loss=0.0772 val_loss=1.4852 HWA=0.604', '\\n',\n'Ep 26/30: tr_loss=0.0617 val_loss=1.5413 HWA=0.603', '\\n', 'Ep 27/30:\ntr_loss=0.0516 val_loss=1.6306 HWA=0.597', '\\n', 'Ep 28/30: tr_loss=0.0394\nval_loss=1.7137 HWA=0.602', '\\n', 'Ep 29/30: tr_loss=0.0320 val_loss=1.8186\nHWA=0.591', '\\n', 'Ep 30/30: tr_loss=0.0273 val_loss=1.8470 HWA=0.585', '\\n',\n'\\n=== Padding-mask removal | epochs=30 ===', '\\n', 'Ep 1/30: tr_loss=0.6819\nval_loss=0.6671 HWA=0.526', '\\n', 'Ep 2/30: tr_loss=0.6496 val_loss=0.6457\nHWA=0.615', '\\n', 'Ep 3/30: tr_loss=0.6252 val_loss=0.6340 HWA=0.601', '\\n', 'Ep\n4/30: tr_loss=0.6074 val_loss=0.6252 HWA=0.611', '\\n', 'Ep 5/30: tr_loss=0.5951\nval_loss=0.6184 HWA=0.611', '\\n', 'Ep 6/30: tr_loss=0.5776 val_loss=0.6043\nHWA=0.626', '\\n', 'Ep 7/30: tr_loss=0.5599 val_loss=0.6019 HWA=0.622', '\\n', 'Ep\n8/30: tr_loss=0.5446 val_loss=0.5950 HWA=0.679', '\\n', 'Ep 9/30: tr_loss=0.5144\nval_loss=0.5530 HWA=0.653', '\\n', 'Ep 10/30: tr_loss=0.4762 val_loss=0.5190\nHWA=0.726', '\\n', 'Ep 11/30: tr_loss=0.4085 val_loss=0.4344 HWA=0.774', '\\n',\n'Ep 12/30: tr_loss=0.2592 val_loss=0.1691 HWA=0.964', '\\n', 'Ep 13/30:\ntr_loss=0.0640 val_loss=0.0517 HWA=0.995', '\\n', 'Ep 14/30: tr_loss=0.0286\nval_loss=0.0342 HWA=0.995', '\\n', 'Ep 15/30: tr_loss=0.0174 val_loss=0.0203\nHWA=1.000', '\\n', 'Ep 16/30: tr_loss=0.0096 val_loss=0.0153 HWA=1.000', '\\n',\n'Ep 17/30: tr_loss=0.0074 val_loss=0.0135 HWA=1.000', '\\n', 'Ep 18/30:\ntr_loss=0.0058 val_loss=0.0122 HWA=1.000', '\\n', 'Ep 19/30: tr_loss=0.0049\nval_loss=0.0120 HWA=1.000', '\\n', 'Ep 20/30: tr_loss=0.0041 val_loss=0.0108\nHWA=1.000', '\\n', 'Ep 21/30: tr_loss=0.0037 val_loss=0.0102 HWA=1.000', '\\n',\n'Ep 22/30: tr_loss=0.0032 val_loss=0.0098 HWA=1.000', '\\n', 'Ep 23/30:\ntr_loss=0.0029 val_loss=0.0096 HWA=1.000', '\\n', 'Ep 24/30: tr_loss=0.0026\nval_loss=0.0091 HWA=1.000', '\\n', 'Ep 25/30: tr_loss=0.0024 val_loss=0.0089\nHWA=1.000', '\\n', 'Ep 26/30: tr_loss=0.0022 val_loss=0.0088 HWA=1.000', '\\n',\n'Ep 27/30: tr_loss=0.0020 val_loss=0.0085 HWA=1.000', '\\n', 'Ep 28/30:\ntr_loss=0.0019 val_loss=0.0086 HWA=1.000', '\\n', 'Ep 29/30: tr_loss=0.0017\nval_loss=0.0085 HWA=1.000', '\\n', 'Ep 30/30: tr_loss=0.0016 val_loss=0.0083\nHWA=1.000', '\\n', 'Saved experiment_data.npy', '\\n', 'Execution time: 5 seconds\nseconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', \"{'train': 600, 'dev': 200, 'test': 200}\",\n'\\n', 'Vocab size:', ' ', '18', '\\n', 'Num classes:', ' ', '2', '\\n', 'Baseline\n| Epoch 1/5 - tr_loss:0.6975 val_loss:0.6823 HWA:0.575', '\\n', 'Baseline | Epoch\n2/5 - tr_loss:0.6801 val_loss:0.6843 HWA:0.561', '\\n', 'Baseline | Epoch 3/5 -\ntr_loss:0.6710 val_loss:0.6791 HWA:0.568', '\\n', 'Baseline | Epoch 4/5 -\ntr_loss:0.6533 val_loss:0.6632 HWA:0.561', '\\n', 'Baseline | Epoch 5/5 -\ntr_loss:0.6330 val_loss:0.6444 HWA:0.582', '\\n', 'Frozen | Epoch 1/5 -\ntr_loss:0.6951 val_loss:0.6874 HWA:0.569', '\\n', 'Frozen | Epoch 2/5 -\ntr_loss:0.6811 val_loss:0.6874 HWA:0.579', '\\n', 'Frozen | Epoch 3/5 -\ntr_loss:0.6659 val_loss:0.6808 HWA:0.596', '\\n', 'Frozen | Epoch 4/5 -\ntr_loss:0.6438 val_loss:0.6625 HWA:0.600', '\\n', 'Frozen | Epoch 5/5 -\ntr_loss:0.6132 val_loss:0.6405 HWA:0.632', '\\n', 'Baseline | Epoch 1/10 -\ntr_loss:0.7003 val_loss:0.6920 HWA:0.536', '\\n', 'Baseline | Epoch 2/10 -\ntr_loss:0.6816 val_loss:0.6923 HWA:0.554', '\\n', 'Baseline | Epoch 3/10 -\ntr_loss:0.6726 val_loss:0.6876 HWA:0.560', '\\n', 'Baseline | Epoch 4/10 -\ntr_loss:0.6612 val_loss:0.6795 HWA:0.571', '\\n', 'Baseline | Epoch 5/10 -\ntr_loss:0.6367 val_loss:0.6738 HWA:0.568', '\\n', 'Baseline | Epoch 6/10 -\ntr_loss:0.6191 val_loss:0.6622 HWA:0.628', '\\n', 'Baseline | Epoch 7/10 -\ntr_loss:0.5925 val_loss:0.6551 HWA:0.640', '\\n', 'Baseline | Epoch 8/10 -\ntr_loss:0.5601 val_loss:0.6732 HWA:0.607', '\\n', 'Baseline | Epoch 9/10 -\ntr_loss:0.5348 val_loss:0.6889 HWA:0.613', '\\n', 'Baseline | Epoch 10/10 -\ntr_loss:0.5117 val_loss:0.6897 HWA:0.612', '\\n', 'Frozen | Epoch 1/10 -\ntr_loss:0.7013 val_loss:0.6903 HWA:0.583', '\\n', 'Frozen | Epoch 2/10 -\ntr_loss:0.6840 val_loss:0.6883 HWA:0.568', '\\n', 'Frozen | Epoch 3/10 -\ntr_loss:0.6749 val_loss:0.6864 HWA:0.591', '\\n', 'Frozen | Epoch 4/10 -\ntr_loss:0.6632 val_loss:0.6828 HWA:0.579', '\\n', 'Frozen | Epoch 5/10 -\ntr_loss:0.6410 val_loss:0.6772 HWA:0.547', '\\n', 'Frozen | Epoch 6/10 -\ntr_loss:0.6137 val_loss:0.6576 HWA:0.620', '\\n', 'Frozen | Epoch 7/10 -\ntr_loss:0.5837 val_loss:0.6641 HWA:0.611', '\\n', 'Frozen | Epoch 8/10 -\ntr_loss:0.5571 val_loss:0.6731 HWA:0.613', '\\n', 'Frozen | Epoch 9/10 -\ntr_loss:0.5314 val_loss:0.7026 HWA:0.605', '\\n', 'Frozen | Epoch 10/10 -\ntr_loss:0.5073 val_loss:0.6906 HWA:0.592', '\\n', 'Baseline | Epoch 1/20 -\ntr_loss:0.6918 val_loss:0.6899 HWA:0.570', '\\n', 'Baseline | Epoch 2/20 -\ntr_loss:0.6765 val_loss:0.6845 HWA:0.571', '\\n', 'Baseline | Epoch 3/20 -\ntr_loss:0.6651 val_loss:0.6782 HWA:0.556', '\\n', 'Baseline | Epoch 4/20 -\ntr_loss:0.6445 val_loss:0.6556 HWA:0.603', '\\n', 'Baseline | Epoch 5/20 -\ntr_loss:0.6204 val_loss:0.6402 HWA:0.583', '\\n', 'Baseline | Epoch 6/20 -\ntr_loss:0.5906 val_loss:0.6386 HWA:0.591', '\\n', 'Baseline | Epoch 7/20 -\ntr_loss:0.5705 val_loss:0.6448 HWA:0.647', '\\n', 'Baseline | Epoch 8/20 -\ntr_loss:0.5504 val_loss:0.6615 HWA:0.606', '\\n', 'Baseline | Epoch 9/20 -\ntr_loss:0.5304 val_loss:0.6732 HWA:0.634', '\\n', 'Baseline | Epoch 10/20 -\ntr_loss:0.5009 val_loss:0.7088 HWA:0.610', '\\n', 'Baseline | Epoch 11/20 -\ntr_loss:0.4751 val_loss:0.6930 HWA:0.617', '\\n', 'Baseline | Epoch 12/20 -\ntr_loss:0.4452 val_loss:0.7221 HWA:0.626', '\\n', 'Baseline | Epoch 13/20 -\ntr_loss:0.4106 val_loss:0.8049 HWA:0.634', '\\n', 'Baseline | Epoch 14/20 -\ntr_loss:0.3849 val_loss:0.8117 HWA:0.605', '\\n', 'Baseline | Epoch 15/20 -\ntr_loss:0.3392 val_loss:0.8309 HWA:0.615', '\\n', 'Baseline | Epoch 16/20 -\ntr_loss:0.3024 val_loss:0.8847 HWA:0.602', '\\n', 'Baseline | Epoch 17/20 -\ntr_loss:0.2830 val_loss:0.9743 HWA:0.613', '\\n', 'Baseline | Epoch 18/20 -\ntr_loss:0.2361 val_loss:1.0297 HWA:0.615', '\\n', 'Baseline | Epoch 19/20 -\ntr_loss:0.2047 val_loss:1.0666 HWA:0.621', '\\n', 'Baseline | Epoch 20/20 -\ntr_loss:0.1761 val_loss:1.1195 HWA:0.616', '\\n', 'Frozen | Epoch 1/20 -\ntr_loss:0.6962 val_loss:0.6883 HWA:0.556', '\\n', 'Frozen | Epoch 2/20 -\ntr_loss:0.6795 val_loss:0.6866 HWA:0.588', '\\n', 'Frozen | Epoch 3/20 -\ntr_loss:0.6659 val_loss:0.6780 HWA:0.554', '\\n', 'Frozen | Epoch 4/20 -\ntr_loss:0.6435 val_loss:0.6622 HWA:0.573', '\\n', 'Frozen | Epoch 5/20 -\ntr_loss:0.6144 val_loss:0.6587 HWA:0.579', '\\n', 'Frozen | Epoch 6/20 -\ntr_loss:0.5986 val_loss:0.6525 HWA:0.634', '\\n', 'Frozen | Epoch 7/20 -\ntr_loss:0.5693 val_loss:0.6798 HWA:0.622', '\\n', 'Frozen | Epoch 8/20 -\ntr_loss:0.5518 val_loss:0.6722 HWA:0.626', '\\n', 'Frozen | Epoch 9/20 -\ntr_loss:0.5269 val_loss:0.6790 HWA:0.625', '\\n', 'Frozen | Epoch 10/20 -\ntr_loss:0.5037 val_loss:0.6910 HWA:0.625', '\\n', 'Frozen | Epoch 11/20 -\ntr_loss:0.4824 val_loss:0.6988 HWA:0.593', '\\n', 'Frozen | Epoch 12/20 -\ntr_loss:0.4565 val_loss:0.7302 HWA:0.628', '\\n', 'Frozen | Epoch 13/20 -\ntr_loss:0.4366 val_loss:0.7998 HWA:0.622', '\\n', 'Frozen | Epoch 14/20 -\ntr_loss:0.4183 val_loss:0.7520 HWA:0.594', '\\n', 'Frozen | Epoch 15/20 -\ntr_loss:0.3607 val_loss:0.7993 HWA:0.631', '\\n', 'Frozen | Epoch 16/20 -\ntr_loss:0.3295 val_loss:0.8330 HWA:0.610', '\\n', 'Frozen | Epoch 17/20 -\ntr_loss:0.2983 val_loss:0.9011 HWA:0.598', '\\n', 'Frozen | Epoch 18/20 -\ntr_loss:0.2766 val_loss:0.9137 HWA:0.604', '\\n', 'Frozen | Epoch 19/20 -\ntr_loss:0.2310 val_loss:0.9338 HWA:0.601', '\\n', 'Frozen | Epoch 20/20 -\ntr_loss:0.2046 val_loss:1.0390 HWA:0.615', '\\n', 'Baseline | Epoch 1/30 -\ntr_loss:0.6937 val_loss:0.6956 HWA:0.518', '\\n', 'Baseline | Epoch 2/30 -\ntr_loss:0.6775 val_loss:0.6888 HWA:0.559', '\\n', 'Baseline | Epoch 3/30 -\ntr_loss:0.6615 val_loss:0.6733 HWA:0.597', '\\n', 'Baseline | Epoch 4/30 -\ntr_loss:0.6367 val_loss:0.6522 HWA:0.582', '\\n', 'Baseline | Epoch 5/30 -\ntr_loss:0.6145 val_loss:0.6340 HWA:0.644', '\\n', 'Baseline | Epoch 6/30 -\ntr_loss:0.5917 val_loss:0.6311 HWA:0.633', '\\n', 'Baseline | Epoch 7/30 -\ntr_loss:0.5731 val_loss:0.6426 HWA:0.625', '\\n', 'Baseline | Epoch 8/30 -\ntr_loss:0.5518 val_loss:0.6817 HWA:0.598', '\\n', 'Baseline | Epoch 9/30 -\ntr_loss:0.5358 val_loss:0.6811 HWA:0.603', '\\n', 'Baseline | Epoch 10/30 -\ntr_loss:0.5245 val_loss:0.6829 HWA:0.619', '\\n', 'Baseline | Epoch 11/30 -\ntr_loss:0.4929 val_loss:0.7302 HWA:0.601', '\\n', 'Baseline | Epoch 12/30 -\ntr_loss:0.4621 val_loss:0.7369 HWA:0.618', '\\n', 'Baseline | Epoch 13/30 -\ntr_loss:0.4436 val_loss:0.7517 HWA:0.613', '\\n', 'Baseline | Epoch 14/30 -\ntr_loss:0.4155 val_loss:0.7781 HWA:0.568', '\\n', 'Baseline | Epoch 15/30 -\ntr_loss:0.3718 val_loss:0.8252 HWA:0.603', '\\n', 'Baseline | Epoch 16/30 -\ntr_loss:0.3362 val_loss:0.9073 HWA:0.608', '\\n', 'Baseline | Epoch 17/30 -\ntr_loss:0.3272 val_loss:0.9178 HWA:0.609', '\\n', 'Baseline | Epoch 18/30 -\ntr_loss:0.2682 val_loss:0.9309 HWA:0.608', '\\n', 'Baseline | Epoch 19/30 -\ntr_loss:0.2297 val_loss:1.0615 HWA:0.592', '\\n', 'Baseline | Epoch 20/30 -\ntr_loss:0.2104 val_loss:1.0541 HWA:0.604', '\\n', 'Baseline | Epoch 21/30 -\ntr_loss:0.1738 val_loss:1.1077 HWA:0.599', '\\n', 'Baseline | Epoch 22/30 -\ntr_loss:0.1545 val_loss:1.1948 HWA:0.598', '\\n', 'Baseline | Epoch 23/30 -\ntr_loss:0.1188 val_loss:1.2864 HWA:0.592', '\\n', 'Baseline | Epoch 24/30 -\ntr_loss:0.0922 val_loss:1.3846 HWA:0.595', '\\n', 'Baseline | Epoch 25/30 -\ntr_loss:0.0772 val_loss:1.4852 HWA:0.604', '\\n', 'Baseline | Epoch 26/30 -\ntr_loss:0.0617 val_loss:1.5413 HWA:0.603', '\\n', 'Baseline | Epoch 27/30 -\ntr_loss:0.0516 val_loss:1.6306 HWA:0.597', '\\n', 'Baseline | Epoch 28/30 -\ntr_loss:0.0394 val_loss:1.7137 HWA:0.602', '\\n', 'Baseline | Epoch 29/30 -\ntr_loss:0.0320 val_loss:1.8186 HWA:0.591', '\\n', 'Baseline | Epoch 30/30 -\ntr_loss:0.0273 val_loss:1.8470 HWA:0.585', '\\n', 'Frozen | Epoch 1/30 -\ntr_loss:0.6982 val_loss:0.6930 HWA:0.532', '\\n', 'Frozen | Epoch 2/30 -\ntr_loss:0.6813 val_loss:0.6874 HWA:0.507', '\\n', 'Frozen | Epoch 3/30 -\ntr_loss:0.6701 val_loss:0.6817 HWA:0.523', '\\n', 'Frozen | Epoch 4/30 -\ntr_loss:0.6531 val_loss:0.6765 HWA:0.597', '\\n', 'Frozen | Epoch 5/30 -\ntr_loss:0.6297 val_loss:0.6607 HWA:0.578', '\\n', 'Frozen | Epoch 6/30 -\ntr_loss:0.6132 val_loss:0.6648 HWA:0.610', '\\n', 'Frozen | Epoch 7/30 -\ntr_loss:0.5875 val_loss:0.6550 HWA:0.647', '\\n', 'Frozen | Epoch 8/30 -\ntr_loss:0.5634 val_loss:0.6669 HWA:0.653', '\\n', 'Frozen | Epoch 9/30 -\ntr_loss:0.5268 val_loss:0.6805 HWA:0.626', '\\n', 'Frozen | Epoch 10/30 -\ntr_loss:0.5082 val_loss:0.6832 HWA:0.643', '\\n', 'Frozen | Epoch 11/30 -\ntr_loss:0.4676 val_loss:0.7125 HWA:0.641', '\\n', 'Frozen | Epoch 12/30 -\ntr_loss:0.4480 val_loss:0.7122 HWA:0.652', '\\n', 'Frozen | Epoch 13/30 -\ntr_loss:0.4067 val_loss:0.7287 HWA:0.629', '\\n', 'Frozen | Epoch 14/30 -\ntr_loss:0.3736 val_loss:0.7688 HWA:0.639', '\\n', 'Frozen | Epoch 15/30 -\ntr_loss:0.3250 val_loss:0.8115 HWA:0.607', '\\n', 'Frozen | Epoch 16/30 -\ntr_loss:0.2898 val_loss:0.8862 HWA:0.591', '\\n', 'Frozen | Epoch 17/30 -\ntr_loss:0.2595 val_loss:0.9819 HWA:0.582', '\\n', 'Frozen | Epoch 18/30 -\ntr_loss:0.2321 val_loss:0.9615 HWA:0.596', '\\n', 'Frozen | Epoch 19/30 -\ntr_loss:0.1837 val_loss:1.0212 HWA:0.616', '\\n', 'Frozen | Epoch 20/30 -\ntr_loss:0.1507 val_loss:1.0622 HWA:0.620', '\\n', 'Frozen | Epoch 21/30 -\ntr_loss:0.1301 val_loss:1.1523 HWA:0.601', '\\n', 'Frozen | Epoch 22/30 -\ntr_loss:0.1168 val_loss:1.1892 HWA:0.576', '\\n', 'Frozen | Epoch 23/30 -\ntr_loss:0.1021 val_loss:1.2450 HWA:0.615', '\\n', 'Frozen | Epoch 24/30 -\ntr_loss:0.0788 val_loss:1.2563 HWA:0.628', '\\n', 'Frozen | Epoch 25/30 -\ntr_loss:0.0763 val_loss:1.3395 HWA:0.606', '\\n', 'Frozen | Epoch 26/30 -\ntr_loss:0.0530 val_loss:1.3687 HWA:0.585', '\\n', 'Frozen | Epoch 27/30 -\ntr_loss:0.0410 val_loss:1.3716 HWA:0.603', '\\n', 'Frozen | Epoch 28/30 -\ntr_loss:0.0312 val_loss:1.4718 HWA:0.617', '\\n', 'Frozen | Epoch 29/30 -\ntr_loss:0.0243 val_loss:1.5084 HWA:0.606', '\\n', 'Frozen | Epoch 30/30 -\ntr_loss:0.0206 val_loss:1.5720 HWA:0.589', '\\n', 'Saved experiment_data.npy',\n'\\n', 'Execution time: 7 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 600, 'dev': 200, 'test': 200}\", '\\n',\n'Char-level vocab size: 10', '\\n', 'Num classes: 2', '\\n', '\\n=== Training for 5\nepochs (shape_color_split) ===', '\\n', 'Epochs=5 | Ep 1: tr_loss=0.6993\nval_loss=0.6952 HWA=0.512', '\\n', 'Epochs=5 | Ep 2: tr_loss=0.6912\nval_loss=0.6958 HWA=0.491', '\\n', 'Epochs=5 | Ep 3: tr_loss=0.6904\nval_loss=0.6953 HWA=0.487', '\\n', 'Epochs=5 | Ep 4: tr_loss=0.6874\nval_loss=0.6930 HWA=0.506', '\\n', 'Epochs=5 | Ep 5: tr_loss=0.6873\nval_loss=0.6914 HWA=0.545', '\\n', '\\n=== Training for 10 epochs\n(shape_color_split) ===', '\\n', 'Epochs=10 | Ep 1: tr_loss=0.6965\nval_loss=0.6929 HWA=0.522', '\\n', 'Epochs=10 | Ep 2: tr_loss=0.6893\nval_loss=0.6953 HWA=0.490', '\\n', 'Epochs=10 | Ep 3: tr_loss=0.6875\nval_loss=0.6931 HWA=0.498', '\\n', 'Epochs=10 | Ep 4: tr_loss=0.6842\nval_loss=0.6886 HWA=0.543', '\\n', 'Epochs=10 | Ep 5: tr_loss=0.6779\nval_loss=0.6793 HWA=0.581', '\\n', 'Epochs=10 | Ep 6: tr_loss=0.6623\nval_loss=0.6606 HWA=0.632', '\\n', 'Epochs=10 | Ep 7: tr_loss=0.6388\nval_loss=0.6652 HWA=0.585', '\\n', 'Epochs=10 | Ep 8: tr_loss=0.6179\nval_loss=0.6495 HWA=0.597', '\\n', 'Epochs=10 | Ep 9: tr_loss=0.6320\nval_loss=0.6637 HWA=0.598', '\\n', 'Epochs=10 | Ep 10: tr_loss=0.5923\nval_loss=0.6567 HWA=0.585', '\\n', '\\n=== Training for 20 epochs\n(shape_color_split) ===', '\\n', 'Epochs=20 | Ep 1: tr_loss=0.7009\nval_loss=0.6913 HWA=0.530', '\\n', 'Epochs=20 | Ep 2: tr_loss=0.6906\nval_loss=0.6967 HWA=0.501', '\\n', 'Epochs=20 | Ep 3: tr_loss=0.6893\nval_loss=0.6955 HWA=0.520', '\\n', 'Epochs=20 | Ep 4: tr_loss=0.6856\nval_loss=0.6891 HWA=0.536', '\\n', 'Epochs=20 | Ep 5: tr_loss=0.6822\nval_loss=0.6866 HWA=0.523', '\\n', 'Epochs=20 | Ep 6: tr_loss=0.6786\nval_loss=0.6809 HWA=0.606', '\\n', 'Epochs=20 | Ep 7: tr_loss=0.6671\nval_loss=0.6637 HWA=0.659', '\\n', 'Epochs=20 | Ep 8: tr_loss=0.6472\nval_loss=0.6804 HWA=0.604', '\\n', 'Epochs=20 | Ep 9: tr_loss=0.6179\nval_loss=0.6450 HWA=0.618', '\\n', 'Epochs=20 | Ep 10: tr_loss=0.5946\nval_loss=0.6608 HWA=0.620', '\\n', 'Epochs=20 | Ep 11: tr_loss=0.5715\nval_loss=0.6678 HWA=0.639', '\\n', 'Epochs=20 | Ep 12: tr_loss=0.5483\nval_loss=0.6857 HWA=0.615', '\\n', 'Epochs=20 | Ep 13: tr_loss=0.5384\nval_loss=0.6853 HWA=0.622', '\\n', 'Epochs=20 | Ep 14: tr_loss=0.5178\nval_loss=0.6869 HWA=0.650', '\\n', 'Epochs=20 | Ep 15: tr_loss=0.4917\nval_loss=0.7207 HWA=0.632', '\\n', 'Epochs=20 | Ep 16: tr_loss=0.5065\nval_loss=0.7293 HWA=0.643', '\\n', 'Epochs=20 | Ep 17: tr_loss=0.4733\nval_loss=0.7101 HWA=0.674', '\\n', 'Epochs=20 | Ep 18: tr_loss=0.4558\nval_loss=0.7521 HWA=0.640', '\\n', 'Epochs=20 | Ep 19: tr_loss=0.3900\nval_loss=0.7410 HWA=0.672', '\\n', 'Epochs=20 | Ep 20: tr_loss=0.3522\nval_loss=0.7954 HWA=0.665', '\\n', '\\n=== Training for 30 epochs\n(shape_color_split) ===', '\\n', 'Epochs=30 | Ep 1: tr_loss=0.7007\nval_loss=0.6925 HWA=0.467', '\\n', 'Epochs=30 | Ep 2: tr_loss=0.6911\nval_loss=0.6947 HWA=0.529', '\\n', 'Epochs=30 | Ep 3: tr_loss=0.6876\nval_loss=0.6924 HWA=0.529', '\\n', 'Epochs=30 | Ep 4: tr_loss=0.6859\nval_loss=0.6914 HWA=0.516', '\\n', 'Epochs=30 | Ep 5: tr_loss=0.6829\nval_loss=0.6866 HWA=0.560', '\\n', 'Epochs=30 | Ep 6: tr_loss=0.6760\nval_loss=0.6760 HWA=0.589', '\\n', 'Epochs=30 | Ep 7: tr_loss=0.6588\nval_loss=0.6579 HWA=0.603', '\\n', 'Epochs=30 | Ep 8: tr_loss=0.6318\nval_loss=0.6693 HWA=0.621', '\\n', 'Epochs=30 | Ep 9: tr_loss=0.6119\nval_loss=0.6782 HWA=0.557', '\\n', 'Epochs=30 | Ep 10: tr_loss=0.6021\nval_loss=0.6682 HWA=0.613', '\\n', 'Epochs=30 | Ep 11: tr_loss=0.5812\nval_loss=0.6886 HWA=0.608', '\\n', 'Epochs=30 | Ep 12: tr_loss=0.5650\nval_loss=0.7104 HWA=0.597', '\\n', 'Epochs=30 | Ep 13: tr_loss=0.5455\nval_loss=0.7205 HWA=0.609', '\\n', 'Epochs=30 | Ep 14: tr_loss=0.5264\nval_loss=0.7141 HWA=0.600', '\\n', 'Epochs=30 | Ep 15: tr_loss=0.4977\nval_loss=0.7214 HWA=0.603', '\\n', 'Epochs=30 | Ep 16: tr_loss=0.4894\nval_loss=0.7251 HWA=0.626', '\\n', 'Epochs=30 | Ep 17: tr_loss=0.4560\nval_loss=0.7348 HWA=0.631', '\\n', 'Epochs=30 | Ep 18: tr_loss=0.4383\nval_loss=0.7669 HWA=0.631', '\\n', 'Epochs=30 | Ep 19: tr_loss=0.4082\nval_loss=0.7882 HWA=0.622', '\\n', 'Epochs=30 | Ep 20: tr_loss=0.3920\nval_loss=0.8449 HWA=0.614', '\\n', 'Epochs=30 | Ep 21: tr_loss=0.3600\nval_loss=0.8452 HWA=0.597', '\\n', 'Epochs=30 | Ep 22: tr_loss=0.3163\nval_loss=0.8306 HWA=0.619', '\\n', 'Epochs=30 | Ep 23: tr_loss=0.2716\nval_loss=0.9332 HWA=0.626', '\\n', 'Epochs=30 | Ep 24: tr_loss=0.2397\nval_loss=1.0180 HWA=0.618', '\\n', 'Epochs=30 | Ep 25: tr_loss=0.2053\nval_loss=1.0655 HWA=0.615', '\\n', 'Epochs=30 | Ep 26: tr_loss=0.1588\nval_loss=1.0803 HWA=0.612', '\\n', 'Epochs=30 | Ep 27: tr_loss=0.1390\nval_loss=1.1717 HWA=0.631', '\\n', 'Epochs=30 | Ep 28: tr_loss=0.1195\nval_loss=1.3007 HWA=0.593', '\\n', 'Epochs=30 | Ep 29: tr_loss=0.1065\nval_loss=1.3403 HWA=0.635', '\\n', 'Epochs=30 | Ep 30: tr_loss=0.0923\nval_loss=1.2908 HWA=0.605', '\\n', \"Saved experiment_data.npy in 'working'\ndirectory\", '\\n', 'Execution time: 5 seconds seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', \"{'train': 600, 'dev': 200, 'test': 200}\", '\\n',\n'Vocab size:', ' ', '18', '\\n', 'Num classes:', ' ', '2', '\\n', '\\n=== Baseline,\n5 epochs ===', '\\n', 'Ep1/5 | tr=0.697 val=0.682 HWA=0.575', '\\n', 'Ep2/5 |\ntr=0.680 val=0.684 HWA=0.561', '\\n', 'Ep3/5 | tr=0.671 val=0.679 HWA=0.568',\n'\\n', 'Ep4/5 | tr=0.653 val=0.663 HWA=0.561', '\\n', 'Ep5/5 | tr=0.633 val=0.644\nHWA=0.582', '\\n', '\\n=== Token-Order Randomization, 5 epochs ===', '\\n', 'Ep1/5\n| tr=0.694 val=0.688 HWA=0.583', '\\n', 'Ep2/5 | tr=0.690 val=0.687 HWA=0.580',\n'\\n', 'Ep3/5 | tr=0.684 val=0.683 HWA=0.564', '\\n', 'Ep4/5 | tr=0.669 val=0.671\nHWA=0.591', '\\n', 'Ep5/5 | tr=0.650 val=0.653 HWA=0.591', '\\n', '\\n=== Baseline,\n10 epochs ===', '\\n', 'Ep1/10 | tr=0.700 val=0.692 HWA=0.536', '\\n', 'Ep2/10 |\ntr=0.682 val=0.692 HWA=0.554', '\\n', 'Ep3/10 | tr=0.673 val=0.688 HWA=0.560',\n'\\n', 'Ep4/10 | tr=0.661 val=0.680 HWA=0.571', '\\n', 'Ep5/10 | tr=0.637\nval=0.674 HWA=0.568', '\\n', 'Ep6/10 | tr=0.619 val=0.662 HWA=0.628', '\\n',\n'Ep7/10 | tr=0.592 val=0.655 HWA=0.640', '\\n', 'Ep8/10 | tr=0.560 val=0.673\nHWA=0.607', '\\n', 'Ep9/10 | tr=0.535 val=0.689 HWA=0.613', '\\n', 'Ep10/10 |\ntr=0.512 val=0.690 HWA=0.612', '\\n', '\\n=== Token-Order Randomization, 10 epochs\n===', '\\n', 'Ep1/10 | tr=0.702 val=0.689 HWA=0.563', '\\n', 'Ep2/10 | tr=0.691\nval=0.693 HWA=0.519', '\\n', 'Ep3/10 | tr=0.689 val=0.693 HWA=0.556', '\\n',\n'Ep4/10 | tr=0.682 val=0.690 HWA=0.582', '\\n', 'Ep5/10 | tr=0.673 val=0.685\nHWA=0.538', '\\n', 'Ep6/10 | tr=0.660 val=0.675 HWA=0.579', '\\n', 'Ep7/10 |\ntr=0.638 val=0.677 HWA=0.573', '\\n', 'Ep8/10 | tr=0.623 val=0.667 HWA=0.589',\n'\\n', 'Ep9/10 | tr=0.618 val=0.682 HWA=0.574', '\\n', 'Ep10/10 | tr=0.606\nval=0.669 HWA=0.606', '\\n', '\\n=== Baseline, 20 epochs ===', '\\n', 'Ep1/20 |\ntr=0.692 val=0.690 HWA=0.570', '\\n', 'Ep2/20 | tr=0.676 val=0.685 HWA=0.571',\n'\\n', 'Ep3/20 | tr=0.665 val=0.678 HWA=0.556', '\\n', 'Ep4/20 | tr=0.644\nval=0.656 HWA=0.603', '\\n', 'Ep5/20 | tr=0.620 val=0.640 HWA=0.583', '\\n',\n'Ep6/20 | tr=0.591 val=0.639 HWA=0.591', '\\n', 'Ep7/20 | tr=0.570 val=0.645\nHWA=0.647', '\\n', 'Ep8/20 | tr=0.550 val=0.662 HWA=0.606', '\\n', 'Ep9/20 |\ntr=0.530 val=0.673 HWA=0.634', '\\n', 'Ep10/20 | tr=0.501 val=0.709 HWA=0.610',\n'\\n', 'Ep11/20 | tr=0.475 val=0.693 HWA=0.617', '\\n', 'Ep12/20 | tr=0.445\nval=0.722 HWA=0.626', '\\n', 'Ep13/20 | tr=0.411 val=0.805 HWA=0.634', '\\n',\n'Ep14/20 | tr=0.385 val=0.812 HWA=0.605', '\\n', 'Ep15/20 | tr=0.339 val=0.831\nHWA=0.615', '\\n', 'Ep16/20 | tr=0.302 val=0.885 HWA=0.602', '\\n', 'Ep17/20 |\ntr=0.283 val=0.974 HWA=0.613', '\\n', 'Ep18/20 | tr=0.236 val=1.030 HWA=0.615',\n'\\n', 'Ep19/20 | tr=0.205 val=1.067 HWA=0.621', '\\n', 'Ep20/20 | tr=0.176\nval=1.119 HWA=0.616', '\\n', '\\n=== Token-Order Randomization, 20 epochs ===',\n'\\n', 'Ep1/20 | tr=0.696 val=0.692 HWA=0.532', '\\n', 'Ep2/20 | tr=0.687\nval=0.695 HWA=0.536', '\\n', 'Ep3/20 | tr=0.681 val=0.692 HWA=0.542', '\\n',\n'Ep4/20 | tr=0.669 val=0.681 HWA=0.545', '\\n', 'Ep5/20 | tr=0.651 val=0.665\nHWA=0.576', '\\n', 'Ep6/20 | tr=0.642 val=0.660 HWA=0.618', '\\n', 'Ep7/20 |\ntr=0.620 val=0.680 HWA=0.596', '\\n', 'Ep8/20 | tr=0.619 val=0.662 HWA=0.629',\n'\\n', 'Ep9/20 | tr=0.626 val=0.660 HWA=0.609', '\\n', 'Ep10/20 | tr=0.610\nval=0.663 HWA=0.606', '\\n', 'Ep11/20 | tr=0.609 val=0.664 HWA=0.616', '\\n',\n'Ep12/20 | tr=0.619 val=0.659 HWA=0.602', '\\n', 'Ep13/20 | tr=0.613 val=0.655\nHWA=0.602', '\\n', 'Ep14/20 | tr=0.621 val=0.658 HWA=0.591', '\\n', 'Ep15/20 |\ntr=0.611 val=0.663 HWA=0.587', '\\n', 'Ep16/20 | tr=0.598 val=0.670 HWA=0.600',\n'\\n', 'Ep17/20 | tr=0.595 val=0.680 HWA=0.593', '\\n', 'Ep18/20 | tr=0.581\nval=0.681 HWA=0.610', '\\n', 'Ep19/20 | tr=0.583 val=0.681 HWA=0.607', '\\n',\n'Ep20/20 | tr=0.593 val=0.673 HWA=0.604', '\\n', '\\n=== Baseline, 30 epochs ===',\n'\\n', 'Ep1/30 | tr=0.694 val=0.696 HWA=0.518', '\\n', 'Ep2/30 | tr=0.677\nval=0.689 HWA=0.559', '\\n', 'Ep3/30 | tr=0.662 val=0.673 HWA=0.597', '\\n',\n'Ep4/30 | tr=0.637 val=0.652 HWA=0.582', '\\n', 'Ep5/30 | tr=0.614 val=0.634\nHWA=0.644', '\\n', 'Ep6/30 | tr=0.592 val=0.631 HWA=0.633', '\\n', 'Ep7/30 |\ntr=0.573 val=0.643 HWA=0.625', '\\n', 'Ep8/30 | tr=0.552 val=0.682 HWA=0.598',\n'\\n', 'Ep9/30 | tr=0.536 val=0.681 HWA=0.603', '\\n', 'Ep10/30 | tr=0.525\nval=0.683 HWA=0.619', '\\n', 'Ep11/30 | tr=0.493 val=0.730 HWA=0.601', '\\n',\n'Ep12/30 | tr=0.462 val=0.737 HWA=0.618', '\\n', 'Ep13/30 | tr=0.444 val=0.752\nHWA=0.613', '\\n', 'Ep14/30 | tr=0.415 val=0.778 HWA=0.568', '\\n', 'Ep15/30 |\ntr=0.372 val=0.825 HWA=0.603', '\\n', 'Ep16/30 | tr=0.336 val=0.907 HWA=0.608',\n'\\n', 'Ep17/30 | tr=0.327 val=0.918 HWA=0.609', '\\n', 'Ep18/30 | tr=0.268\nval=0.931 HWA=0.608', '\\n', 'Ep19/30 | tr=0.230 val=1.061 HWA=0.592', '\\n',\n'Ep20/30 | tr=0.210 val=1.054 HWA=0.604', '\\n', 'Ep21/30 | tr=0.174 val=1.108\nHWA=0.599', '\\n', 'Ep22/30 | tr=0.154 val=1.195 HWA=0.598', '\\n', 'Ep23/30 |\ntr=0.119 val=1.286 HWA=0.592', '\\n', 'Ep24/30 | tr=0.092 val=1.385 HWA=0.595',\n'\\n', 'Ep25/30 | tr=0.077 val=1.485 HWA=0.604', '\\n', 'Ep26/30 | tr=0.062\nval=1.541 HWA=0.603', '\\n', 'Ep27/30 | tr=0.052 val=1.631 HWA=0.597', '\\n',\n'Ep28/30 | tr=0.039 val=1.714 HWA=0.602', '\\n', 'Ep29/30 | tr=0.032 val=1.819\nHWA=0.591', '\\n', 'Ep30/30 | tr=0.027 val=1.847 HWA=0.585', '\\n', '\\n=== Token-\nOrder Randomization, 30 epochs ===', '\\n', 'Ep1/30 | tr=0.700 val=0.698\nHWA=0.510', '\\n', 'Ep2/30 | tr=0.688 val=0.696 HWA=0.532', '\\n', 'Ep3/30 |\ntr=0.686 val=0.696 HWA=0.519', '\\n', 'Ep4/30 | tr=0.681 val=0.694 HWA=0.534',\n'\\n', 'Ep5/30 | tr=0.667 val=0.679 HWA=0.584', '\\n', 'Ep6/30 | tr=0.667\nval=0.667 HWA=0.559', '\\n', 'Ep7/30 | tr=0.633 val=0.654 HWA=0.603', '\\n',\n'Ep8/30 | tr=0.626 val=0.666 HWA=0.629', '\\n', 'Ep9/30 | tr=0.611 val=0.671\nHWA=0.569', '\\n', 'Ep10/30 | tr=0.618 val=0.669 HWA=0.610', '\\n', 'Ep11/30 |\ntr=0.609 val=0.674 HWA=0.613', '\\n', 'Ep12/30 | tr=0.606 val=0.660 HWA=0.603',\n'\\n', 'Ep13/30 | tr=0.606 val=0.671 HWA=0.593', '\\n', 'Ep14/30 | tr=0.597\nval=0.665 HWA=0.615', '\\n', 'Ep15/30 | tr=0.600 val=0.654 HWA=0.610', '\\n',\n'Ep16/30 | tr=0.588 val=0.653 HWA=0.610', '\\n', 'Ep17/30 | tr=0.585 val=0.655\nHWA=0.587', '\\n', 'Ep18/30 | tr=0.585 val=0.655 HWA=0.606', '\\n', 'Ep19/30 |\ntr=0.579 val=0.663 HWA=0.618', '\\n', 'Ep20/30 | tr=0.593 val=0.665 HWA=0.597',\n'\\n', 'Ep21/30 | tr=0.569 val=0.666 HWA=0.622', '\\n', 'Ep22/30 | tr=0.570\nval=0.661 HWA=0.594', '\\n', 'Ep23/30 | tr=0.579 val=0.657 HWA=0.598', '\\n',\n'Ep24/30 | tr=0.565 val=0.669 HWA=0.616', '\\n', 'Ep25/30 | tr=0.564 val=0.686\nHWA=0.603', '\\n', 'Ep26/30 | tr=0.552 val=0.680 HWA=0.619', '\\n', 'Ep27/30 |\ntr=0.559 val=0.686 HWA=0.597', '\\n', 'Ep28/30 | tr=0.535 val=0.701 HWA=0.562',\n'\\n', 'Ep29/30 | tr=0.545 val=0.706 HWA=0.588', '\\n', 'Ep30/30 | tr=0.547\nval=0.694 HWA=0.560', '\\n', 'Saved experiment_data.npy', '\\n', 'Execution time:\n8 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', \"{'train': 600, 'dev': 200, 'test': 200}\", '\\n',\n'Vocab size: 18', '\\n', 'Num classes: 2', '\\n', '\\n=== UniLSTM training for 5\nepochs ===', '\\n', 'Ep  1: tr_loss=0.6975 val_loss=0.6823 HWA=0.575', '\\n', 'Ep\n2: tr_loss=0.6801 val_loss=0.6843 HWA=0.561', '\\n', 'Ep  3: tr_loss=0.6710\nval_loss=0.6791 HWA=0.568', '\\n', 'Ep  4: tr_loss=0.6533 val_loss=0.6632\nHWA=0.561', '\\n', 'Ep  5: tr_loss=0.6330 val_loss=0.6444 HWA=0.582', '\\n',\n'\\n=== UniLSTM training for 10 epochs ===', '\\n', 'Ep  1: tr_loss=0.6951\nval_loss=0.6873 HWA=0.569', '\\n', 'Ep  2: tr_loss=0.6810 val_loss=0.6873\nHWA=0.579', '\\n', 'Ep  3: tr_loss=0.6656 val_loss=0.6806 HWA=0.602', '\\n', 'Ep\n4: tr_loss=0.6435 val_loss=0.6624 HWA=0.600', '\\n', 'Ep  5: tr_loss=0.6130\nval_loss=0.6405 HWA=0.632', '\\n', 'Ep  6: tr_loss=0.5831 val_loss=0.6438\nHWA=0.624', '\\n', 'Ep  7: tr_loss=0.5726 val_loss=0.6734 HWA=0.638', '\\n', 'Ep\n8: tr_loss=0.5492 val_loss=0.6661 HWA=0.640', '\\n', 'Ep  9: tr_loss=0.5291\nval_loss=0.6762 HWA=0.626', '\\n', 'Ep 10: tr_loss=0.5117 val_loss=0.6824\nHWA=0.629', '\\n', '\\n=== UniLSTM training for 20 epochs ===', '\\n', 'Ep  1:\ntr_loss=0.6949 val_loss=0.6878 HWA=0.567', '\\n', 'Ep  2: tr_loss=0.6781\nval_loss=0.6839 HWA=0.563', '\\n', 'Ep  3: tr_loss=0.6623 val_loss=0.6709\nHWA=0.583', '\\n', 'Ep  4: tr_loss=0.6442 val_loss=0.6604 HWA=0.585', '\\n', 'Ep\n5: tr_loss=0.6169 val_loss=0.6480 HWA=0.628', '\\n', 'Ep  6: tr_loss=0.5952\nval_loss=0.6704 HWA=0.603', '\\n', 'Ep  7: tr_loss=0.5821 val_loss=0.6526\nHWA=0.613', '\\n', 'Ep  8: tr_loss=0.5521 val_loss=0.6638 HWA=0.636', '\\n', 'Ep\n9: tr_loss=0.5362 val_loss=0.6913 HWA=0.616', '\\n', 'Ep 10: tr_loss=0.5120\nval_loss=0.7066 HWA=0.596', '\\n', 'Ep 11: tr_loss=0.5016 val_loss=0.7245\nHWA=0.602', '\\n', 'Ep 12: tr_loss=0.4667 val_loss=0.7180 HWA=0.606', '\\n', 'Ep\n13: tr_loss=0.4408 val_loss=0.7420 HWA=0.613', '\\n', 'Ep 14: tr_loss=0.4038\nval_loss=0.8364 HWA=0.615', '\\n', 'Ep 15: tr_loss=0.3702 val_loss=0.8902\nHWA=0.594', '\\n', 'Ep 16: tr_loss=0.3405 val_loss=0.8617 HWA=0.596', '\\n', 'Ep\n17: tr_loss=0.3129 val_loss=0.9129 HWA=0.581', '\\n', 'Ep 18: tr_loss=0.2723\nval_loss=0.9696 HWA=0.582', '\\n', 'Ep 19: tr_loss=0.2473 val_loss=1.0825\nHWA=0.600', '\\n', 'Ep 20: tr_loss=0.2033 val_loss=1.1331 HWA=0.584', '\\n',\n'\\n=== UniLSTM training for 30 epochs ===', '\\n', 'Ep  1: tr_loss=0.6944\nval_loss=0.6896 HWA=0.557', '\\n', 'Ep  2: tr_loss=0.6790 val_loss=0.6852\nHWA=0.569', '\\n', 'Ep  3: tr_loss=0.6640 val_loss=0.6781 HWA=0.566', '\\n', 'Ep\n4: tr_loss=0.6373 val_loss=0.6689 HWA=0.585', '\\n', 'Ep  5: tr_loss=0.6152\nval_loss=0.6632 HWA=0.584', '\\n', 'Ep  6: tr_loss=0.5914 val_loss=0.6536\nHWA=0.642', '\\n', 'Ep  7: tr_loss=0.5648 val_loss=0.6822 HWA=0.610', '\\n', 'Ep\n8: tr_loss=0.5609 val_loss=0.6817 HWA=0.619', '\\n', 'Ep  9: tr_loss=0.5325\nval_loss=0.6960 HWA=0.610', '\\n', 'Ep 10: tr_loss=0.5204 val_loss=0.6865\nHWA=0.617', '\\n', 'Ep 11: tr_loss=0.4905 val_loss=0.6840 HWA=0.668', '\\n', 'Ep\n12: tr_loss=0.4632 val_loss=0.7137 HWA=0.623', '\\n', 'Ep 13: tr_loss=0.4356\nval_loss=0.7493 HWA=0.610', '\\n', 'Ep 14: tr_loss=0.4354 val_loss=0.7275\nHWA=0.602', '\\n', 'Ep 15: tr_loss=0.3747 val_loss=0.7421 HWA=0.631', '\\n', 'Ep\n16: tr_loss=0.3285 val_loss=0.7670 HWA=0.645', '\\n', 'Ep 17: tr_loss=0.2889\nval_loss=0.7868 HWA=0.613', '\\n', 'Ep 18: tr_loss=0.2498 val_loss=0.8188\nHWA=0.616', '\\n', 'Ep 19: tr_loss=0.2050 val_loss=0.9097 HWA=0.623', '\\n', 'Ep\n20: tr_loss=0.1823 val_loss=0.8985 HWA=0.586', '\\n', 'Ep 21: tr_loss=0.1450\nval_loss=0.9633 HWA=0.601', '\\n', 'Ep 22: tr_loss=0.1127 val_loss=1.0187\nHWA=0.636', '\\n', 'Ep 23: tr_loss=0.0934 val_loss=1.0440 HWA=0.637', '\\n', 'Ep\n24: tr_loss=0.0711 val_loss=1.0928 HWA=0.614', '\\n', 'Ep 25: tr_loss=0.0535\nval_loss=1.1703 HWA=0.613', '\\n', 'Ep 26: tr_loss=0.0414 val_loss=1.2120\nHWA=0.616', '\\n', 'Ep 27: tr_loss=0.0329 val_loss=1.2912 HWA=0.625', '\\n', 'Ep\n28: tr_loss=0.0255 val_loss=1.2972 HWA=0.607', '\\n', 'Ep 29: tr_loss=0.0209\nval_loss=1.3289 HWA=0.616', '\\n', 'Ep 30: tr_loss=0.0171 val_loss=1.3624\nHWA=0.620', '\\n', '\\n=== BiLSTM training for 5 epochs ===', '\\n', 'Ep  1:\ntr_loss=0.6945 val_loss=0.6853 HWA=0.563', '\\n', 'Ep  2: tr_loss=0.6712\nval_loss=0.6840 HWA=0.590', '\\n', 'Ep  3: tr_loss=0.6527 val_loss=0.6808\nHWA=0.565', '\\n', 'Ep  4: tr_loss=0.6336 val_loss=0.6789 HWA=0.569', '\\n', 'Ep\n5: tr_loss=0.6039 val_loss=0.6645 HWA=0.603', '\\n', '\\n=== BiLSTM training for\n10 epochs ===', '\\n', 'Ep  1: tr_loss=0.6935 val_loss=0.6855 HWA=0.584', '\\n',\n'Ep  2: tr_loss=0.6711 val_loss=0.6806 HWA=0.567', '\\n', 'Ep  3: tr_loss=0.6508\nval_loss=0.6800 HWA=0.584', '\\n', 'Ep  4: tr_loss=0.6343 val_loss=0.6701\nHWA=0.608', '\\n', 'Ep  5: tr_loss=0.5944 val_loss=0.6883 HWA=0.562', '\\n', 'Ep\n6: tr_loss=0.5696 val_loss=0.6837 HWA=0.620', '\\n', 'Ep  7: tr_loss=0.5442\nval_loss=0.6908 HWA=0.603', '\\n', 'Ep  8: tr_loss=0.5300 val_loss=0.7089\nHWA=0.585', '\\n', 'Ep  9: tr_loss=0.5088 val_loss=0.7023 HWA=0.610', '\\n', 'Ep\n10: tr_loss=0.4688 val_loss=0.7078 HWA=0.603', '\\n', '\\n=== BiLSTM training for\n20 epochs ===', '\\n', 'Ep  1: tr_loss=0.6936 val_loss=0.6886 HWA=0.541', '\\n',\n'Ep  2: tr_loss=0.6687 val_loss=0.6863 HWA=0.554', '\\n', 'Ep  3: tr_loss=0.6519\nval_loss=0.6845 HWA=0.569', '\\n', 'Ep  4: tr_loss=0.6298 val_loss=0.6829\nHWA=0.569', '\\n', 'Ep  5: tr_loss=0.5957 val_loss=0.6963 HWA=0.545', '\\n', 'Ep\n6: tr_loss=0.5728 val_loss=0.6949 HWA=0.583', '\\n', 'Ep  7: tr_loss=0.5362\nval_loss=0.6949 HWA=0.589', '\\n', 'Ep  8: tr_loss=0.5166 val_loss=0.7335\nHWA=0.579', '\\n', 'Ep  9: tr_loss=0.4806 val_loss=0.7287 HWA=0.622', '\\n', 'Ep\n10: tr_loss=0.4407 val_loss=0.7931 HWA=0.606', '\\n', 'Ep 11: tr_loss=0.4029\nval_loss=0.7633 HWA=0.616', '\\n', 'Ep 12: tr_loss=0.3586 val_loss=0.8246\nHWA=0.603', '\\n', 'Ep 13: tr_loss=0.3102 val_loss=0.8954 HWA=0.609', '\\n', 'Ep\n14: tr_loss=0.2718 val_loss=0.8995 HWA=0.578', '\\n', 'Ep 15: tr_loss=0.2151\nval_loss=0.9550 HWA=0.588', '\\n', 'Ep 16: tr_loss=0.1728 val_loss=1.0573\nHWA=0.603', '\\n', 'Ep 17: tr_loss=0.1416 val_loss=1.0804 HWA=0.591', '\\n', 'Ep\n18: tr_loss=0.1016 val_loss=1.2142 HWA=0.603', '\\n', 'Ep 19: tr_loss=0.0753\nval_loss=1.2628 HWA=0.583', '\\n', 'Ep 20: tr_loss=0.0539 val_loss=1.3026\nHWA=0.591', '\\n', '\\n=== BiLSTM training for 30 epochs ===', '\\n', 'Ep  1:\ntr_loss=0.6946 val_loss=0.6815 HWA=0.558', '\\n', 'Ep  2: tr_loss=0.6715\nval_loss=0.6786 HWA=0.582', '\\n', 'Ep  3: tr_loss=0.6522 val_loss=0.6772\nHWA=0.561', '\\n', 'Ep  4: tr_loss=0.6316 val_loss=0.6742 HWA=0.555', '\\n', 'Ep\n5: tr_loss=0.6022 val_loss=0.6646 HWA=0.616', '\\n', 'Ep  6: tr_loss=0.5710\nval_loss=0.6938 HWA=0.591', '\\n', 'Ep  7: tr_loss=0.5559 val_loss=0.6876\nHWA=0.611', '\\n', 'Ep  8: tr_loss=0.5262 val_loss=0.6933 HWA=0.621', '\\n', 'Ep\n9: tr_loss=0.4967 val_loss=0.7294 HWA=0.592', '\\n', 'Ep 10: tr_loss=0.4627\nval_loss=0.7231 HWA=0.640', '\\n', 'Ep 11: tr_loss=0.4163 val_loss=0.7620\nHWA=0.606', '\\n', 'Ep 12: tr_loss=0.3785 val_loss=0.8086 HWA=0.609', '\\n', 'Ep\n13: tr_loss=0.3265 val_loss=0.8630 HWA=0.594', '\\n', 'Ep 14: tr_loss=0.2653\nval_loss=0.9140 HWA=0.617', '\\n', 'Ep 15: tr_loss=0.2267 val_loss=1.0073\nHWA=0.597', '\\n', 'Ep 16: tr_loss=0.1763 val_loss=1.1160 HWA=0.606', '\\n', 'Ep\n17: tr_loss=0.1396 val_loss=1.1288 HWA=0.632', '\\n', 'Ep 18: tr_loss=0.1071\nval_loss=1.2339 HWA=0.591', '\\n', 'Ep 19: tr_loss=0.0780 val_loss=1.3329\nHWA=0.616', '\\n', 'Ep 20: tr_loss=0.0546 val_loss=1.3855 HWA=0.608', '\\n', 'Ep\n21: tr_loss=0.0398 val_loss=1.4943 HWA=0.583', '\\n', 'Ep 22: tr_loss=0.0269\nval_loss=1.6219 HWA=0.602', '\\n', 'Ep 23: tr_loss=0.0201 val_loss=1.7133\nHWA=0.591', '\\n', 'Ep 24: tr_loss=0.0153 val_loss=1.7706 HWA=0.600', '\\n', 'Ep\n25: tr_loss=0.0116 val_loss=1.8269 HWA=0.600', '\\n', 'Ep 26: tr_loss=0.0095\nval_loss=1.8654 HWA=0.597', '\\n', 'Ep 27: tr_loss=0.0079 val_loss=1.9274\nHWA=0.600', '\\n', 'Ep 28: tr_loss=0.0067 val_loss=1.9820 HWA=0.597', '\\n', 'Ep\n29: tr_loss=0.0058 val_loss=2.0269 HWA=0.597', '\\n', 'Ep 30: tr_loss=0.0050\nval_loss=2.0219 HWA=0.592', '\\n', 'Saved experiment_data.npy', '\\n', 'Execution\ntime: 7 seconds seconds (time limit is 30 minutes).']"], "analysis": ["The execution successfully completed without any errors or bugs. The training\nprocess was carried out for different epoch configurations (5, 10, 20, and 30\nepochs), and the results were logged. The harmonic weighted accuracy (HWA)\nmetric was used as the key evaluation metric, and the model's performance was\ntracked over epochs. The results show expected behavior with some overfitting\nobserved in longer training durations. The experiment data was successfully\nsaved to a file for further analysis.", "The execution of the training script completed successfully without any errors\nor bugs. The models (LSTM and Bag-of-Embeddings) were trained for various\nepochs, and their performance was logged in terms of training loss, validation\nloss, and Harmonic Weighted Accuracy (HWA). The results were saved in a file\nnamed 'experiment_data.npy'. There were no runtime issues or inconsistencies in\nthe output.", "", "", "The training script executed successfully without any errors. It tested two LSTM\nmodel variants (Baseline with packed sequences and Ablation without padding\nmasks) across different numbers of epochs. Both models showed improvement in\ntraining and validation losses, as well as in the Harmonic Weighted Accuracy\n(HWA). Notably, the Ablation model (without padding masks) achieved better\nperformance, reaching an HWA of 1.000 after 30 epochs. The results were saved to\n'experiment_data.npy'. There are no bugs or issues to address.", "", "", "The training script executed successfully without any apparent bugs. The script\nconducted experiments for both baseline and token-order randomization scenarios\nacross 5, 10, 20, and 30 epochs. The results were logged, and an\n`experiment_data.npy` file was saved. The Harmonic Weighted Accuracy (HWA)\nvalues showed some variance but no unexpected anomalies. The script appears to\nfunction as intended.", ""], "exc_type": [null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training; lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH (epochs = 5)", "final_value": 0.633, "best_value": 0.633}, {"dataset_name": "SPR_BENCH (epochs = 10)", "final_value": 0.5117, "best_value": 0.5117}, {"dataset_name": "SPR_BENCH (epochs = 20)", "final_value": 0.2033, "best_value": 0.2033}, {"dataset_name": "SPR_BENCH (epochs = 30)", "final_value": 0.0171, "best_value": 0.0171}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error during validation; lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH (epochs = 5)", "final_value": 0.6444, "best_value": 0.6444}, {"dataset_name": "SPR_BENCH (epochs = 10)", "final_value": 0.6824, "best_value": 0.6824}, {"dataset_name": "SPR_BENCH (epochs = 20)", "final_value": 1.1331, "best_value": 1.1331}, {"dataset_name": "SPR_BENCH (epochs = 30)", "final_value": 1.3624, "best_value": 1.3624}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "Measures the weighted accuracy during validation; higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH (epochs = 5)", "final_value": 0.582, "best_value": 0.582}, {"dataset_name": "SPR_BENCH (epochs = 10)", "final_value": 0.64, "best_value": 0.64}, {"dataset_name": "SPR_BENCH (epochs = 20)", "final_value": 0.636, "best_value": 0.636}, {"dataset_name": "SPR_BENCH (epochs = 30)", "final_value": 0.668, "best_value": 0.668}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH | Model: LSTM", "final_value": 0.0171, "best_value": 0.0171}, {"dataset_name": "SPR_BENCH | Model: BOE", "final_value": 0.6795, "best_value": 0.6795}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error during validation. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH | Model: LSTM", "final_value": 0.6444, "best_value": 0.6444}, {"dataset_name": "SPR_BENCH | Model: BOE", "final_value": 0.6939, "best_value": 0.6939}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "Measures the harmonic weighted accuracy during validation. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH | Model: LSTM", "final_value": 0.629, "best_value": 0.629}, {"dataset_name": "SPR_BENCH | Model: BOE", "final_value": 0.581, "best_value": 0.581}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value observed during training, which measures the error of the model on the training dataset.", "data": [{"dataset_name": "SetA", "final_value": 0.5197, "best_value": 0.5197}, {"dataset_name": "SetB", "final_value": 0.1146, "best_value": 0.1146}, {"dataset_name": "SetC", "final_value": 0.4771, "best_value": 0.4771}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value observed during validation, which measures the error of the model on the validation dataset.", "data": [{"dataset_name": "SetA", "final_value": 0.641, "best_value": 0.641}, {"dataset_name": "SetB", "final_value": 0.1731, "best_value": 0.1731}, {"dataset_name": "SetC", "final_value": 0.6321, "best_value": 0.6321}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy observed during validation, which is a measure of the model's accuracy on the validation dataset.", "data": [{"dataset_name": "SetA", "final_value": 0.6412, "best_value": 0.6412}, {"dataset_name": "SetB", "final_value": 0.967, "best_value": 0.967}, {"dataset_name": "SetC", "final_value": 0.7105, "best_value": 0.7105}]}, {"metric_name": "cross-evaluation accuracy", "lower_is_better": false, "description": "The accuracy of the model when evaluated on datasets other than the one it was trained on.", "data": [{"dataset_name": "SetA", "final_value": 0.495, "best_value": 0.615}, {"dataset_name": "SetB", "final_value": 0.04, "best_value": 0.96}, {"dataset_name": "SetC", "final_value": 0.66, "best_value": 0.695}]}, {"metric_name": "cross-evaluation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy of the model when evaluated on datasets other than the one it was trained on.", "data": [{"dataset_name": "SetA", "final_value": 0.4793, "best_value": 0.6171}, {"dataset_name": "SetB", "final_value": 0.0302, "best_value": 0.967}, {"dataset_name": "SetC", "final_value": 0.6612, "best_value": 0.707}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss calculated on the training dataset during model training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5299, "best_value": 0.5117}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset to evaluate model performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6716, "best_value": 0.6444}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6405, "best_value": 0.6405}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures how well the model fits the training data.", "data": [{"dataset_name": "SPR_BENCH (baseline)", "final_value": 0.0273, "best_value": 0.0273}, {"dataset_name": "SPR_BENCH (padding_mask_removal)", "final_value": 0.0016, "best_value": 0.0016}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures how well the model generalizes to unseen validation data.", "data": [{"dataset_name": "SPR_BENCH (baseline)", "final_value": 0.6444, "best_value": 0.6444}, {"dataset_name": "SPR_BENCH (padding_mask_removal)", "final_value": 0.0044, "best_value": 0.0044}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "Evaluates the model's accuracy on validation data, weighted harmonically.", "data": [{"dataset_name": "SPR_BENCH (baseline)", "final_value": 0.6155, "best_value": 0.6155}, {"dataset_name": "SPR_BENCH (padding_mask_removal)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss calculated on the training dataset.", "data": [{"dataset_name": "SPR_BENCH | baseline", "final_value": 0.1761, "best_value": 0.1761}, {"dataset_name": "SPR_BENCH | frozen_emb", "final_value": 0.6132, "best_value": 0.6132}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH | baseline", "final_value": 1.1195, "best_value": 1.1195}, {"dataset_name": "SPR_BENCH | frozen_emb", "final_value": 0.6405, "best_value": 0.6405}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH | baseline", "final_value": 0.6155, "best_value": 0.6155}, {"dataset_name": "SPR_BENCH | frozen_emb", "final_value": 0.6322, "best_value": 0.6322}]}]}, {"metric_names": [{"metric_name": "harmonic weighted accuracy", "lower_is_better": false, "description": "The best harmonic weighted accuracy achieved during execution.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6745, "best_value": 0.6745}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The lowest validation loss achieved during execution.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.645, "best_value": 0.645}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "The lowest training loss achieved during execution.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0923, "best_value": 0.0923}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss calculated during the training phase of the model.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0273, "best_value": 0.0273}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss calculated on the validation set to assess model generalization.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6444, "best_value": 0.6444}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy calculated on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6435, "best_value": 0.6473}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value on the training dataset at the end of training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0171, "best_value": 0.0171}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset at the end of training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.3624, "best_value": 0.6444}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy on the validation dataset at the end of training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6201, "best_value": 0.6292}]}]}], "is_best_node": [false, false, false, false, true, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_05c15e4cd885474784d82b668a6f6b01_proc_3023913/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_05c15e4cd885474784d82b668a6f6b01_proc_3023913/SPR_BENCH_HWA_curves.png"], ["../../logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/LSTM_SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/LSTM_SPR_BENCH_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/BOE_SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/BOE_SPR_BENCH_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/SPR_BENCH_final_hwa_comparison.png"], [], ["../../logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_baseline_loss_curves.png", "../../logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_baseline_hwa.png", "../../logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_factorized_loss_curves.png", "../../logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_factorized_hwa.png"], ["../../logs/0-run/experiment_results/experiment_6279441767534ae892b597c077c2572d_proc_3040259/SPR_BENCH_baseline_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6279441767534ae892b597c077c2572d_proc_3040259/SPR_BENCH_nomask_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6279441767534ae892b597c077c2572d_proc_3040259/SPR_BENCH_final_HWA_comparison.png"], ["../../logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e5_curves.png", "../../logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e10_curves.png", "../../logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e20_curves.png", "../../logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e30_curves.png"], ["../../logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_5ep.png", "../../logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_10ep.png", "../../logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_20ep.png", "../../logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_30ep.png"], ["../../logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_baseline_losses.png", "../../logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_baseline_hwa.png", "../../logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_randomization_losses.png", "../../logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_randomization_hwa.png", "../../logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_hwa_comparison.png"], ["../../logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_HWA_vs_epochs.png", "../../logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_UNI_LSTM_loss_curves_30ep.png", "../../logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_BI_LSTM_loss_curves_30ep.png", "../../logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_HWA_curves_longest_runs.png"]], "plot_paths": [["experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_05c15e4cd885474784d82b668a6f6b01_proc_3023913/SPR_BENCH_loss_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_05c15e4cd885474784d82b668a6f6b01_proc_3023913/SPR_BENCH_HWA_curves.png"], ["experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/LSTM_SPR_BENCH_loss_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/LSTM_SPR_BENCH_hwa_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/BOE_SPR_BENCH_loss_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/BOE_SPR_BENCH_hwa_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/SPR_BENCH_final_hwa_comparison.png"], [], ["experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_baseline_loss_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_baseline_hwa.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_factorized_loss_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_factorized_hwa.png"], ["experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6279441767534ae892b597c077c2572d_proc_3040259/SPR_BENCH_baseline_loss_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6279441767534ae892b597c077c2572d_proc_3040259/SPR_BENCH_nomask_loss_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6279441767534ae892b597c077c2572d_proc_3040259/SPR_BENCH_final_HWA_comparison.png"], ["experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e5_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e10_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e20_curves.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e30_curves.png"], ["experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_5ep.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_10ep.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_20ep.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_30ep.png"], ["experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_baseline_losses.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_baseline_hwa.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_randomization_losses.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_randomization_hwa.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_hwa_comparison.png"], ["experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_HWA_vs_epochs.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_UNI_LSTM_loss_curves_30ep.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_BI_LSTM_loss_curves_30ep.png", "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_HWA_curves_longest_runs.png"]], "plot_analyses": [[{"analysis": "The training and validation loss curves show a clear trend of overfitting as the number of epochs increases. For the 5-epoch and 10-epoch configurations, the validation loss remains relatively stable and close to the training loss, indicating a good balance between model complexity and data fit. However, for the 20-epoch and 30-epoch configurations, the validation loss starts to increase significantly after around 10 epochs, while the training loss continues to decrease. This divergence suggests that the model is overfitting to the training data, especially in the longer training durations. The 30-epoch configuration exhibits the most pronounced overfitting, with validation loss increasing steeply after approximately 15 epochs. This indicates that early stopping should be implemented to prevent overfitting and improve generalization.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_05c15e4cd885474784d82b668a6f6b01_proc_3023913/SPR_BENCH_loss_curves.png"}, {"analysis": "The harmonic weighted accuracy (HWA) curves provide insights into the model's performance across epochs. The 30-epoch configuration achieves the highest peak HWA value, indicating that it can reach the best performance at some point during training. However, the performance fluctuates significantly, and the HWA decreases as training progresses, which is consistent with the overfitting observed in the loss curves. The 10-epoch configuration demonstrates relatively stable and consistent performance, with less fluctuation compared to the longer training durations. The 5-epoch configuration has the lowest overall HWA, suggesting that it does not allow sufficient time for the model to learn effectively. Based on these observations, the 10-epoch configuration appears to strike the best balance between training duration and model performance, but early stopping should be used to capture the peak performance in the 20-epoch and 30-epoch configurations before overfitting sets in.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_05c15e4cd885474784d82b668a6f6b01_proc_3023913/SPR_BENCH_HWA_curves.png"}], [{"analysis": "This plot shows the training and validation loss curves for an LSTM model evaluated on the SPR_BENCH dataset. The training loss decreases steadily for all configurations (5, 10, 20, 30 epochs), indicating successful learning. However, the validation loss starts increasing after a certain point for higher epoch configurations (e.g., 20 and 30 epochs), which suggests overfitting. The 5 and 10 epoch configurations seem to strike a better balance between training and validation loss, making them more suitable for this task.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/LSTM_SPR_BENCH_loss_curves.png"}, {"analysis": "This plot presents the Harmonic Weighted Accuracy (HWA) on the validation set for the LSTM model. The 30-epoch configuration occasionally achieves the highest HWA but shows significant fluctuations, indicating instability. The 10-epoch configuration appears more stable and consistent, reaching competitive HWA values without large oscillations. This suggests that a moderate number of training epochs provides a better trade-off between performance and stability.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/LSTM_SPR_BENCH_hwa_curves.png"}, {"analysis": "This plot illustrates the training and validation loss curves for a BOE model on the SPR_BENCH dataset. The training loss decreases for all configurations, with the 30-epoch configuration achieving the lowest final training loss. However, the validation loss does not show a clear improvement and remains relatively flat, particularly for the 20 and 30-epoch configurations, indicating potential overfitting. The 5 and 10-epoch configurations maintain a better balance, with lower validation loss compared to the higher epoch configurations.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/BOE_SPR_BENCH_loss_curves.png"}, {"analysis": "This plot shows the Harmonic Weighted Accuracy (HWA) on the validation set for the BOE model. The 10-epoch configuration achieves the highest and most stable HWA, while the 5-epoch configuration shows the lowest performance. The 20 and 30-epoch configurations exhibit fluctuating validation HWA, suggesting overfitting or instability in the learned representations. The results highlight that the 10-epoch configuration is optimal for achieving high and stable HWA for the BOE model.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/BOE_SPR_BENCH_hwa_curves.png"}, {"analysis": "This bar chart compares the final Harmonic Weighted Accuracy (HWA) across different models (LSTM and BOE) and epoch configurations. The LSTM model consistently outperforms the BOE model in HWA, particularly at 10 and 30 epochs. Among all configurations, LSTM with 10 epochs achieves the highest HWA, making it the most effective configuration for the SPR_BENCH dataset. The results suggest that the LSTM model is better suited for this task compared to the BOE model, especially when trained for a moderate number of epochs.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8ff930f34744f809cf667f2a65760b4_proc_3040256/SPR_BENCH_final_hwa_comparison.png"}], [], [{"analysis": "The loss curves indicate a steady decrease in training loss over epochs, suggesting that the model is learning effectively on the training data. However, the validation loss plateaus after the initial epochs and exhibits fluctuations, which might indicate overfitting or challenges in generalization. The gap between training and validation loss is notable, suggesting potential room for improvement in regularization or data augmentation strategies.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_baseline_loss_curves.png"}, {"analysis": "The harmonic weighted accuracy (HWA) improves steadily across epochs, peaking around epoch 7 before stabilizing. This indicates that the model is effectively capturing the patterns in the validation data. However, the fluctuations between epochs suggest that the model's performance might still be sensitive to hyperparameter tuning or data variability.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_baseline_hwa.png"}, {"analysis": "The loss curves exhibit a similar trend as in the baseline case, with a steady decrease in training loss and a more fluctuating validation loss. Interestingly, the validation loss seems to stabilize at a slightly lower value compared to the baseline, which might indicate improved generalization due to the factorization approach. However, the gap between training and validation loss persists, pointing to potential overfitting.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_factorized_loss_curves.png"}, {"analysis": "The harmonic weighted accuracy (HWA) for the factorized approach shows a steady improvement over epochs, with slightly higher peak and stabilization values compared to the baseline. This suggests that the factorization strategy is effectively enhancing the model's ability to generalize to the validation set, providing a performance boost over the baseline.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_eb75560787494effa0d1b600ca95c534_proc_3040258/SPR_BENCH_factorized_hwa.png"}], [{"analysis": "The first plot shows the cross-entropy loss trends for both training and validation sets over 5, 10, 20, and 30 epochs using the baseline LSTM model with packed sequences. Training loss consistently decreases across all configurations, indicating effective optimization. However, validation loss initially decreases but then increases for longer training durations (20 and 30 epochs), suggesting overfitting. The divergence between training and validation losses becomes more pronounced as the number of epochs increases, highlighting the need for regularization or early stopping.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6279441767534ae892b597c077c2572d_proc_3040259/SPR_BENCH_baseline_loss_curves.png"}, {"analysis": "The second plot depicts the cross-entropy loss curves for the LSTM model without a padding mask. Both training and validation losses decrease rapidly, achieving near-zero loss by approximately 10 epochs. The absence of overfitting in this configuration, even with extended training durations, indicates that the no-padding-mask approach may inherently regularize the model, possibly due to improved sequence representation or reduced noise during training.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6279441767534ae892b597c077c2572d_proc_3040259/SPR_BENCH_nomask_loss_curves.png"}, {"analysis": "The third plot compares the final harmonic weighted accuracy (HWA) for the baseline model and the no-padding-mask model across different training epochs. The no-padding-mask model consistently outperforms the baseline in HWA across all configurations, with a significant margin at higher epochs (20 and 30). This demonstrates that the no-padding-mask approach not only mitigates overfitting but also enhances the model's ability to generalize and achieve better accuracy, particularly for longer training durations.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6279441767534ae892b597c077c2572d_proc_3040259/SPR_BENCH_final_HWA_comparison.png"}], [{"analysis": "The loss curves for both training and validation show a steady decrease for the baseline and frozen embedding models, indicating effective learning. However, the frozen embedding model demonstrates a slightly faster convergence. In terms of Harmonic Weighted Accuracy (HWA), the frozen embedding model consistently outperforms the baseline, showing a clear advantage in capturing contextual relationships within the data.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e5_curves.png"}, {"analysis": "The training loss for both models continues to decrease, but the validation loss for the frozen embedding model shows signs of overfitting after epoch 6. The baseline model maintains a more stable validation loss. In terms of HWA, the frozen embedding model initially outperforms the baseline but fluctuates significantly, suggesting instability or sensitivity in the learning process. The baseline model demonstrates more consistent performance.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e10_curves.png"}, {"analysis": "The training loss for both models decreases steadily, but the validation loss for the frozen embedding model diverges significantly after epoch 10, indicating overfitting. The HWA plot shows that the frozen embedding model performs comparably to the baseline, with both models exhibiting significant fluctuations, suggesting that neither model has fully stabilized.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e20_curves.png"}, {"analysis": "The training loss for both models decreases steadily, but the validation loss for both models increases significantly after epoch 15, indicating severe overfitting. The HWA plot shows that both models achieve similar peak performances but fluctuate heavily, suggesting that the models are not generalizing well to unseen data.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_996ff291e5c14f6dab03fc25b1490baf_proc_3040256/SPR_BENCH_e30_curves.png"}], [{"analysis": "The training loss decreases consistently over the 5 epochs, indicating that the model is learning from the training data. However, the validation loss decreases only slightly, suggesting potential underfitting or insufficient training duration. The Validation Harmonic Weighted Accuracy (HWA) initially decreases, then starts to improve after epoch 3, which could indicate that the model needs more epochs to stabilize and generalize effectively.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_5ep.png"}, {"analysis": "Training loss decreases steadily over 10 epochs, showing effective learning. Validation loss follows a similar trend but fluctuates slightly after epoch 6, suggesting some instability in generalization. Validation HWA improves significantly up to epoch 6, then stabilizes with minor fluctuations. This indicates that the model benefits from additional training but may require further regularization to prevent overfitting after epoch 6.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_10ep.png"}, {"analysis": "Training loss continues to decrease steadily over 20 epochs, showcasing effective learning. Validation loss, however, starts to increase after epoch 15, indicating overfitting. Validation HWA improves significantly up to epoch 8, stabilizes, and then fluctuates slightly. This suggests that the model performs well initially but struggles to maintain generalization with extended training.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_20ep.png"}, {"analysis": "Training loss decreases steadily over 30 epochs, but validation loss increases significantly after epoch 20, indicating strong overfitting. Validation HWA improves consistently up to epoch 15 but fluctuates afterward, showing diminishing returns with extended training. This highlights the need for early stopping or additional regularization to prevent overfitting and maintain generalization.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_94d8a87f991c48c6834cddea84dfde40_proc_3040257/SPR_BENCH_loss_hwa_30ep.png"}], [{"analysis": "This plot compares training and validation loss for different numbers of epochs in the baseline SPR_BENCH setup. The training loss consistently decreases for all epoch configurations, indicating that the model is learning from the data. However, the validation loss decreases initially but starts to increase for higher epoch counts (e.g., 30 epochs), suggesting potential overfitting. The model performs best in terms of validation loss at around 10 to 20 epochs, emphasizing the importance of early stopping to prevent overfitting.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_baseline_losses.png"}, {"analysis": "This plot shows the harmonic-weighted accuracy (HWA) for different epochs in the baseline setup. The HWA initially increases for all epoch configurations, peaking around 10 to 20 epochs. However, for 30 epochs, the accuracy decreases, indicating diminishing returns or overfitting when training for too long. The variability in HWA across epochs highlights the importance of selecting an optimal training duration.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_baseline_hwa.png"}, {"analysis": "This plot evaluates the impact of token-order randomization on training and validation loss. Similar to the baseline setup, the training loss decreases steadily. However, the validation loss exhibits more variability and does not decrease as consistently, especially for longer training durations (30 epochs). This suggests that token-order randomization introduces additional complexity, potentially affecting the model's ability to generalize.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_randomization_losses.png"}, {"analysis": "This plot illustrates the harmonic-weighted accuracy (HWA) under the token-order randomization setup. The model achieves its peak HWA between 10 to 20 epochs, similar to the baseline. However, the HWA generally appears lower than the baseline, indicating that token-order randomization might negatively impact performance. The fluctuations in HWA also suggest that the randomization introduces instability in the learning process.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_randomization_hwa.png"}, {"analysis": "This plot compares the final harmonic-weighted accuracy (HWA) between the baseline and token-order randomization setups across different epoch configurations. The baseline consistently outperforms the token-order randomization setup, particularly for 20 epochs, where the difference is most pronounced. This indicates that token-order randomization might hinder the model's ability to learn effective representations, especially as training progresses. The drop in performance for both setups at 30 epochs further supports the observation of overfitting.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7bb4990a50d54779b09f9b42c40e3e2a_proc_3040259/SPR_BENCH_hwa_comparison.png"}], [{"analysis": "This plot compares the Final Harmonic Weighted Accuracy (HWA) for UNI_LSTM and BI_LSTM models over 30 training epochs. The UNI_LSTM model shows a significant peak in HWA at epoch 10, followed by a sharp decline and recovery by epoch 30. On the other hand, the BI_LSTM model exhibits a more stable but consistently lower HWA throughout the epochs. The results suggest that UNI_LSTM has higher variability but achieves better peak performance, whereas BI_LSTM maintains steadier but less competitive accuracy.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_HWA_vs_epochs.png"}, {"analysis": "This plot shows the training and validation loss curves for the UNI_LSTM model over 30 epochs. The training loss decreases steadily, indicating effective learning on the training data. However, the validation loss starts increasing after epoch 10, highlighting overfitting. This suggests that while the model learns the training data well, its generalization to unseen data diminishes as training progresses.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_UNI_LSTM_loss_curves_30ep.png"}, {"analysis": "This plot shows the training and validation loss curves for the BI_LSTM model over 30 epochs. The training loss decreases steadily, demonstrating effective learning on the training data. However, the validation loss increases significantly after epoch 10, indicating severe overfitting. This suggests that the BI_LSTM model struggles to generalize to unseen data despite its ability to minimize training loss.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_BI_LSTM_loss_curves_30ep.png"}, {"analysis": "This plot illustrates the per-epoch Harmonic Weighted Accuracy (HWA) for the longest runs of UNI_LSTM and BI_LSTM models. The UNI_LSTM model shows higher variability in HWA, with peaks exceeding 0.66, whereas the BI_LSTM model demonstrates a more stable but consistently lower HWA. This pattern reinforces the observation that UNI_LSTM achieves better peak performance but at the cost of stability, while BI_LSTM provides steadier but less competitive results.", "plot_path": "experiments/2025-08-15_23-37-14_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1749558b632141b096b5eabcf0cac7fc_proc_3040258/SPR_BENCH_HWA_curves_longest_runs.png"}]], "vlm_feedback_summary": ["The plots indicate that overfitting is a significant issue in longer training\ndurations, as evidenced by the divergence between training and validation loss.\nThe harmonic weighted accuracy (HWA) metric suggests that while longer training\ndurations can achieve higher peak performance, they also introduce instability\nand performance degradation over time. Early stopping and refined hyperparameter\ntuning are recommended to mitigate overfitting and capture optimal performance.", "The plots reveal that the LSTM model generally outperforms the BOE model for the\nSPR_BENCH task, particularly in terms of Harmonic Weighted Accuracy (HWA). The\noptimal configuration for the LSTM model is 10 epochs, which provides the best\ntrade-off between performance and stability. For the BOE model, the 10-epoch\nconfiguration also performs best, but its overall performance is inferior to the\nLSTM model. Overfitting is observed in both models at higher epoch\nconfigurations (20 and 30 epochs), indicating the need for regularization or\nearly stopping in future experiments.", "[]", "The plots show that the factorized approach outperforms the baseline in terms of\nvalidation accuracy and stabilization of loss. However, both approaches exhibit\na consistent gap between training and validation loss, indicating potential\noverfitting. The harmonic weighted accuracy metrics suggest that the models are\nlearning effectively, but further optimization might be necessary to achieve\nmore robust generalization.", "The provided plots effectively illustrate the impact of different training\nconfigurations on model performance. Key insights include evidence of\noverfitting in the baseline model, the regularization benefits of the no-\npadding-mask approach, and the superior accuracy achieved with the no-padding-\nmask model, especially at higher training epochs.", "The plots reveal that while the frozen embedding model shows initial performance\nimprovements, it suffers from instability and overfitting as training\nprogresses. Both models exhibit generalization issues, particularly in later\nepochs, as evidenced by increased validation loss and fluctuating HWA scores.", "The results indicate that the model learns effectively during training, but\nthere are challenges with generalization, particularly with extended training.\nValidation loss and HWA trends suggest the need for regularization techniques or\nearly stopping to mitigate overfitting and improve performance stability.", "The analysis highlights the impact of training duration and token-order\nrandomization on model performance. Overfitting is observed at higher epochs\n(30), while token-order randomization introduces complexity that negatively\naffects generalization. Optimal performance is achieved between 10 to 20 epochs,\nwith the baseline consistently outperforming the token-order randomization\nsetup. The results suggest that careful tuning of training duration and\nunderstanding the effects of data augmentation techniques like token-order\nrandomization are critical for improving model performance on the SPR task.", "The experimental results highlight key differences between the UNI_LSTM and\nBI_LSTM models. UNI_LSTM achieves higher peak performance but exhibits\nsignificant variability and overfitting, as evidenced by the loss curves and HWA\ntrends. BI_LSTM, while more stable, consistently underperforms compared to\nUNI_LSTM. These findings suggest that UNI_LSTM has greater potential for\noptimization and achieving state-of-the-art results, provided overfitting can be\nmitigated."], "exec_time": [3.8843212127685547, 6.609461307525635, 3.975054979324341, 3.301539659500122, 5.753324031829834, 7.0842368602752686, 5.629026889801025, 8.380277156829834, 7.205730199813843], "exec_time_feedback": ["", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], [], ["['baseline'", "'factorized']"], ["[\"no-padding-mask\"]"], ["[]"], ["['plot 2']"], ["[\"baseline\"", "\"token_order_randomization\"]"], ["['SPR_BENCH']"]], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# setup paths\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    runs = experiment_data[\"epochs\"][\"SPR_BENCH\"]  # dict keyed by epoch count\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    runs = {}\n\n# ---------- Plot 1: Train / Val loss curves ----------\ntry:\n    if runs:\n        plt.figure(figsize=(7, 5))\n        for run_name, rec in runs.items():\n            x = np.arange(1, len(rec[\"losses\"][\"train\"]) + 1)\n            plt.plot(\n                x, rec[\"losses\"][\"train\"], label=f\"{run_name}ep-train\", linestyle=\"--\"\n            )\n            plt.plot(x, rec[\"losses\"][\"val\"], label=f\"{run_name}ep-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH: Training vs Validation Loss Curves\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    else:\n        print(\"No runs to plot for loss curves.\")\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\nfinally:\n    plt.close()\n\n# ---------- Plot 2: Validation HWA curves ----------\ntry:\n    if runs:\n        plt.figure(figsize=(7, 5))\n        for run_name, rec in runs.items():\n            x = np.arange(1, len(rec[\"metrics\"][\"val\"]) + 1)\n            plt.plot(x, rec[\"metrics\"][\"val\"], label=f\"{run_name}ep\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Harmonic Weighted Accuracy\")\n        plt.title(\"SPR_BENCH: Validation HWA Across Epochs\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_HWA_curves.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    else:\n        print(\"No runs to plot for HWA curves.\")\nexcept Exception as e:\n    print(f\"Error creating HWA plot: {e}\")\nfinally:\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# ---------- helper for final metric table ----------\nfinal_hwa = {}  # {(model, epochs): value}\n\nmodels = [\"LSTM\", \"BOE\"]\ndataset = \"SPR_BENCH\"\nmax_figs = 5\nfig_count = 0\n\nfor model in models:\n    mdl_dict = experiment_data.get(model, {}).get(dataset, {})\n    # ----------------- LOSS CURVES FIG -----------------\n    try:\n        fig = plt.figure(figsize=(6, 4))\n        for run_id, rec in mdl_dict.items():\n            tr = rec[\"losses\"][\"train\"]\n            val = rec[\"losses\"][\"val\"]\n            xs = list(range(1, len(tr) + 1))\n            plt.plot(xs, tr, linestyle=\"--\", label=f\"train_{run_id}ep\")\n            plt.plot(xs, val, linestyle=\"-\", label=f\"val_{run_id}ep\")\n            # store last hwa for table/bar\n            final_hwa[(model, run_id)] = rec[\"metrics\"][\"val\"][-1]\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{model} - {dataset} Training & Validation Loss\")\n        plt.legend(fontsize=7)\n        out_path = os.path.join(working_dir, f\"{model}_{dataset}_loss_curves.png\")\n        plt.tight_layout()\n        plt.savefig(out_path)\n        plt.close()\n        fig_count += 1\n    except Exception as e:\n        print(f\"Error creating loss plot for {model}: {e}\")\n        plt.close()\n    # ----------------- HWA CURVES FIG -----------------\n    try:\n        fig = plt.figure(figsize=(6, 4))\n        for run_id, rec in mdl_dict.items():\n            hwa = rec[\"metrics\"][\"val\"]\n            xs = list(range(1, len(hwa) + 1))\n            plt.plot(xs, hwa, label=f\"{run_id}ep\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Harmonic Weighted Accuracy\")\n        plt.title(f\"{model} - {dataset} Validation HWA\")\n        plt.legend(fontsize=7)\n        out_path = os.path.join(working_dir, f\"{model}_{dataset}_hwa_curves.png\")\n        plt.tight_layout()\n        plt.savefig(out_path)\n        plt.close()\n        fig_count += 1\n    except Exception as e:\n        print(f\"Error creating HWA plot for {model}: {e}\")\n        plt.close()\n\n# ---------- BAR CHART COMPARISON (at most 5th fig) ----------\ntry:\n    labels = []\n    values = []\n    for (m, ep), v in final_hwa.items():\n        labels.append(f\"{m}_{ep}\")\n        values.append(v)\n    fig = plt.figure(figsize=(8, 4))\n    plt.bar(labels, values, color=\"skyblue\")\n    plt.ylabel(\"Final-Epoch HWA\")\n    plt.xticks(rotation=45, ha=\"right\")\n    plt.title(f\"Final HWA Comparison - {dataset}\")\n    plt.tight_layout()\n    out_path = os.path.join(working_dir, f\"{dataset}_final_hwa_comparison.png\")\n    plt.savefig(out_path)\n    plt.close()\n    fig_count += 1\nexcept Exception as e:\n    print(f\"Error creating comparison bar chart: {e}\")\n    plt.close()\n\n# ---------- PRINT METRIC TABLE ----------\nprint(\"\\nFinal HWA scores:\")\nfor (m, ep), v in sorted(final_hwa.items()):\n    print(f\"{m:4s} | {ep:>2s} epochs : {v:.3f}\")\n\nprint(f\"\\nTotal figures created: {fig_count}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nexp_key = next(iter(experiment_data.keys())) if experiment_data else None\nif exp_key is None:\n    print(\"No experiment data to plot.\")\n    quit()\n\nruns = experiment_data[exp_key]  # e.g. \"MultiSynthetic\"\nepochs = len(next(iter(runs.values()))[\"losses\"][\"train\"])\n\n\n# ---------- gather helpers ----------\ndef get_curve(runs, field):\n    curves = {}\n    for train_ds, rec in runs.items():\n        curves[train_ds] = rec[field]\n    return curves\n\n\nloss_train = get_curve(runs, (\"losses\", \"train\"))\nloss_val = get_curve(runs, (\"losses\", \"val\"))\nhwa_val = get_curve(runs, (\"metrics\", \"val\"))\n\n\ndef nested_get(dic, keys):\n    d = dic\n    for k in keys:\n        d = d[k]\n    return d\n\n\n# ---------- 1) loss curves ----------\ntry:\n    plt.figure()\n    x = np.arange(1, epochs + 1)\n    for ds in runs:\n        plt.plot(\n            x, nested_get(runs[ds], (\"losses\", \"train\")), \"--\", label=f\"{ds}-train\"\n        )\n        plt.plot(x, nested_get(runs[ds], (\"losses\", \"val\")), \"-\", label=f\"{ds}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(f\"{exp_key}: Train vs Validation Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{exp_key}_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ---------- 2) validation HWA curves ----------\ntry:\n    plt.figure()\n    for ds in runs:\n        plt.plot(x, nested_get(runs[ds], (\"metrics\", \"val\")), label=ds)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Accuracy\")\n    plt.title(f\"{exp_key}: Validation HWA Across Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{exp_key}_HWA_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA plot: {e}\")\n    plt.close()\n\n# ---------- 3) cross-domain HWA heatmap ----------\ntry:\n    train_names = list(runs.keys())\n    eval_names = list(train_names)\n    heat = np.zeros((len(train_names), len(eval_names)))\n    for r, tr_ds in enumerate(train_names):\n        for c, ev_ds in enumerate(eval_names):\n            heat[r, c] = runs[tr_ds][\"cross_eval\"][ev_ds][\"hwa\"]\n    plt.figure()\n    im = plt.imshow(heat, cmap=\"viridis\", vmin=0, vmax=1)\n    plt.colorbar(im, fraction=0.046, pad=0.04)\n    plt.xticks(range(len(eval_names)), eval_names, rotation=45, ha=\"right\")\n    plt.yticks(range(len(train_names)), train_names)\n    plt.title(f\"{exp_key}: Cross-Domain HWA (rows=train, cols=eval)\")\n    for r in range(len(train_names)):\n        for c in range(len(eval_names)):\n            plt.text(\n                c,\n                r,\n                f\"{heat[r,c]:.2f}\",\n                ha=\"center\",\n                va=\"center\",\n                color=\"white\" if heat[r, c] < 0.5 else \"black\",\n            )\n    fname = os.path.join(working_dir, f\"{exp_key}_cross_domain_HWA.png\")\n    plt.savefig(fname, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating cross-domain heatmap: {e}\")\n    plt.close()\n\n# ---------- print metrics ----------\nprint(\"\\nCross-Domain HWA (train -> eval):\")\nfor tr_ds in runs:\n    row = []\n    for ev_ds in runs:\n        h = runs[tr_ds][\"cross_eval\"][ev_ds][\"hwa\"]\n        row.append(f\"{h:.3f}\")\n    print(f\"{tr_ds:>8}:\", \"  \".join(row))\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# Helper to fetch data safely\ndef get_run_record(variant, epochs_str):\n    return experiment_data.get(variant, {}).get(\"SPR_BENCH\", {}).get(epochs_str, {})\n\n\nvariants = [\"baseline\", \"factorized\"]\nfor var in variants:\n    rec = get_run_record(var, \"10\")  # use the 10-epoch run for full curves\n    if not rec:\n        print(f\"No record found for {var} 10 epochs\")\n        continue\n    train_loss = rec[\"losses\"][\"train\"]\n    val_loss = rec[\"losses\"][\"val\"]\n    val_hwa = rec[\"metrics\"][\"val\"]\n    epochs = np.arange(1, len(train_loss) + 1)\n\n    # -------- Loss curves --------\n    try:\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train Loss\")\n        plt.plot(epochs, val_loss, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"SPR_BENCH {var.capitalize()} \u2013 Loss Curves\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"SPR_BENCH_{var}_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {var}: {e}\")\n        plt.close()\n\n    # -------- HWA curve --------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_hwa, marker=\"o\", label=\"Val HWA\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Harmonic Weighted Accuracy\")\n        plt.title(f\"SPR_BENCH {var.capitalize()} \u2013 Validation HWA\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"SPR_BENCH_{var}_hwa.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating HWA plot for {var}: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\ndef get_runs(model_key):\n    runs = experiment_data.get(model_key, {}).get(\"SPR_BENCH\", {})\n    # sort by number of epochs (string keys -> int)\n    return {int(k): v for k, v in runs.items()}\n\n\n# ----- 1) aggregate loss curves for baseline -----\ntry:\n    plt.figure(figsize=(6, 4))\n    runs = get_runs(\"baseline\")\n    for epochs, rec in sorted(runs.items()):\n        x = np.arange(1, len(rec[\"losses\"][\"train\"]) + 1)\n        plt.plot(x, rec[\"losses\"][\"train\"], label=f\"{epochs}ep-train\")\n        plt.plot(x, rec[\"losses\"][\"val\"], \"--\", label=f\"{epochs}ep-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH Baseline LSTM (Packed)\\nLeft: Train, Right: Val Loss Curves\")\n    plt.legend(fontsize=8)\n    fname = os.path.join(working_dir, \"SPR_BENCH_baseline_loss_curves.png\")\n    plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error plotting baseline loss curves: {e}\")\n    plt.close()\n\n# ----- 2) aggregate loss curves for no-mask model -----\ntry:\n    plt.figure(figsize=(6, 4))\n    runs = get_runs(\"padding_mask_removal\")\n    for epochs, rec in sorted(runs.items()):\n        x = np.arange(1, len(rec[\"losses\"][\"train\"]) + 1)\n        plt.plot(x, rec[\"losses\"][\"train\"], label=f\"{epochs}ep-train\")\n        plt.plot(x, rec[\"losses\"][\"val\"], \"--\", label=f\"{epochs}ep-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH LSTM (No Padding Mask)\\nLeft: Train, Right: Val Loss Curves\")\n    plt.legend(fontsize=8)\n    fname = os.path.join(working_dir, \"SPR_BENCH_nomask_loss_curves.png\")\n    plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error plotting nomask loss curves: {e}\")\n    plt.close()\n\n# ----- 3) final HWA comparison bar plot -----\ntry:\n    plt.figure(figsize=(5, 3))\n    epoch_vals = sorted(\n        set(\n            list(get_runs(\"baseline\").keys())\n            + list(get_runs(\"padding_mask_removal\").keys())\n        )\n    )\n    width = 0.35\n    idx = np.arange(len(epoch_vals))\n    hwa_base = [\n        (\n            get_runs(\"baseline\").get(e, {\"metrics\": {\"val\": [np.nan]}})[\"metrics\"][\n                \"val\"\n            ][-1]\n            if e in get_runs(\"baseline\")\n            else np.nan\n        )\n        for e in epoch_vals\n    ]\n    hwa_nomask = [\n        (\n            get_runs(\"padding_mask_removal\").get(e, {\"metrics\": {\"val\": [np.nan]}})[\n                \"metrics\"\n            ][\"val\"][-1]\n            if e in get_runs(\"padding_mask_removal\")\n            else np.nan\n        )\n        for e in epoch_vals\n    ]\n    plt.bar(idx - width / 2, hwa_base, width, label=\"Baseline\")\n    plt.bar(idx + width / 2, hwa_nomask, width, label=\"NoMask\")\n    plt.xlabel(\"Training Epochs\")\n    plt.ylabel(\"Final HWA\")\n    plt.xticks(idx, epoch_vals)\n    plt.title(\"SPR_BENCH Final Harmonic Weighted Accuracy\\nBaseline vs No Padding Mask\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_HWA_comparison.png\")\n    plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error plotting HWA comparison: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set up working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# parameters\ndataset = \"SPR_BENCH\"\nepoch_options = [\"5\", \"10\", \"20\", \"30\"]\nvariants = {\"baseline\": \"Baseline\", \"frozen_emb\": \"Frozen-Emb\"}\n\n# plotting\nfor e in epoch_options[:5]:  # ensure at most 5 figs\n    try:\n        plt.figure(figsize=(10, 4))\n        # Left subplot: loss curves\n        ax1 = plt.subplot(1, 2, 1)\n        for var_key, var_name in variants.items():\n            rec = experiment_data.get(var_key, {}).get(dataset, {}).get(e, {})\n            tr = rec.get(\"losses\", {}).get(\"train\", [])\n            va = rec.get(\"losses\", {}).get(\"val\", [])\n            if tr:\n                ax1.plot(range(1, len(tr) + 1), tr, label=f\"{var_name} Train\")\n            if va:\n                ax1.plot(range(1, len(va) + 1), va, \"--\", label=f\"{var_name} Val\")\n        ax1.set_xlabel(\"Epoch\")\n        ax1.set_ylabel(\"Loss\")\n        ax1.set_title(\"Training vs Validation Loss\")\n        ax1.legend()\n\n        # Right subplot: HWA curves\n        ax2 = plt.subplot(1, 2, 2)\n        for var_key, var_name in variants.items():\n            rec = experiment_data.get(var_key, {}).get(dataset, {}).get(e, {})\n            hwa = rec.get(\"metrics\", {}).get(\"val\", [])\n            if hwa:\n                ax2.plot(range(1, len(hwa) + 1), hwa, label=f\"{var_name} HWA\")\n        ax2.set_xlabel(\"Epoch\")\n        ax2.set_ylabel(\"HWA\")\n        ax2.set_title(\"Harmonic Weighted Accuracy\")\n        ax2.legend()\n\n        plt.suptitle(\n            f\"{dataset} Epochs={e}\\nLeft: Train/Val Loss, Right: HWA (SPR_BENCH)\"\n        )\n        fname = f\"{dataset}_e{e}_curves.png\"\n        plt.tight_layout(rect=[0, 0.03, 1, 0.90])\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as err:\n        print(f\"Error creating plot for epoch {e}: {err}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    runs = experiment_data.get(\"shape_color_split\", {}).get(\"SPR_BENCH\", {})\n    # plot at most five runs\n    for i, (epochs_str, run) in enumerate(\n        sorted(runs.items(), key=lambda x: int(x[0]))\n    ):\n        if i >= 5:\n            break\n        try:\n            # extract data\n            train_loss = run[\"losses\"][\"train\"]\n            val_loss = run[\"losses\"][\"val\"]\n            hwa = run[\"metrics\"][\"val\"]\n            ep_range = np.arange(1, len(train_loss) + 1)\n\n            # figure\n            fig, ax = plt.subplots(2, 1, figsize=(6, 8), sharex=True)\n            fig.suptitle(f\"SPR_BENCH \u2013 {epochs_str} Epochs\")\n\n            # losses\n            ax[0].plot(ep_range, train_loss, label=\"Train Loss\")\n            ax[0].plot(ep_range, val_loss, label=\"Val Loss\")\n            ax[0].set_ylabel(\"Cross-Entropy Loss\")\n            ax[0].legend()\n            ax[0].set_title(\"Training vs. Validation Loss\")\n\n            # HWA\n            ax[1].plot(ep_range, hwa, color=\"green\", label=\"Val HWA\")\n            ax[1].set_xlabel(\"Epoch\")\n            ax[1].set_ylabel(\"HWA\")\n            ax[1].legend()\n            ax[1].set_title(\"Validation Harmonic Weighted Accuracy\")\n\n            # save\n            fname = f\"SPR_BENCH_loss_hwa_{epochs_str}ep.png\"\n            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close(fig)\n\n            # print final metric\n            print(f\"Run {epochs_str} epochs \u2013 final HWA: {hwa[-1]:.3f}\")\n        except Exception as e:\n            print(f\"Error creating plot for {epochs_str} epochs: {e}\")\n            plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------ load data ------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\ndef get_runs(setting):\n    return experiment_data.get(setting, {}).get(\"SPR_BENCH\", {})\n\n\nbaseline_runs = get_runs(\"baseline\")\nrand_runs = get_runs(\"token_order_randomization\")\n\n\n# helper to extract per-run arrays\ndef extract_curves(runs, key):\n    out = {}\n    for epochs, rec in runs.items():\n        out[int(epochs)] = rec[key]\n    return out  # {num_epochs: list}\n\n\n# ------------------ plotting ------------------\n# 1) Baseline losses\ntry:\n    curves_tr = (\n        extract_curves(baseline_runs, \"losses\")[\"train\"] if False else None\n    )  # placeholder to trigger except if not exist\nexcept Exception:\n    pass  # dummy so that pylint doesn't complain about undefined\ntry:\n    loss_dict = extract_curves(baseline_runs, \"losses\")\n    if loss_dict:\n        plt.figure()\n        for ep, losses in loss_dict.items():\n            plt.plot(\n                range(1, len(losses[\"train\"]) + 1),\n                losses[\"train\"],\n                label=f\"{ep}ep-train\",\n            )\n            plt.plot(\n                range(1, len(losses[\"val\"]) + 1),\n                losses[\"val\"],\n                linestyle=\"--\",\n                label=f\"{ep}ep-val\",\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"Baseline SPR_BENCH: Training vs Validation Loss\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_baseline_losses.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating Baseline Loss plot: {e}\")\n    plt.close()\n\n# 2) Baseline HWA\ntry:\n    hwa_dict = {int(ep): rec[\"metrics\"][\"val\"] for ep, rec in baseline_runs.items()}\n    if hwa_dict:\n        plt.figure()\n        for ep, hwa in hwa_dict.items():\n            plt.plot(range(1, len(hwa) + 1), hwa, label=f\"{ep} epochs\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HWA\")\n        plt.title(\"Baseline SPR_BENCH: Harmonic-Weighted Accuracy\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_baseline_hwa.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating Baseline HWA plot: {e}\")\n    plt.close()\n\n# 3) Randomization losses\ntry:\n    loss_dict = extract_curves(rand_runs, \"losses\")\n    if loss_dict:\n        plt.figure()\n        for ep, losses in loss_dict.items():\n            plt.plot(\n                range(1, len(losses[\"train\"]) + 1),\n                losses[\"train\"],\n                label=f\"{ep}ep-train\",\n            )\n            plt.plot(\n                range(1, len(losses[\"val\"]) + 1),\n                losses[\"val\"],\n                linestyle=\"--\",\n                label=f\"{ep}ep-val\",\n            )\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"Token-Order Randomization SPR_BENCH: Training vs Validation Loss\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_randomization_losses.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating Randomization Loss plot: {e}\")\n    plt.close()\n\n# 4) Randomization HWA\ntry:\n    hwa_dict = {int(ep): rec[\"metrics\"][\"val\"] for ep, rec in rand_runs.items()}\n    if hwa_dict:\n        plt.figure()\n        for ep, hwa in hwa_dict.items():\n            plt.plot(range(1, len(hwa) + 1), hwa, label=f\"{ep} epochs\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"HWA\")\n        plt.title(\"Token-Order Randomization SPR_BENCH: Harmonic-Weighted Accuracy\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_randomization_hwa.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating Randomization HWA plot: {e}\")\n    plt.close()\n\n# 5) Final-epoch HWA comparison\ntry:\n    if baseline_runs and rand_runs:\n        epochs_sorted = sorted(\n            set(int(e) for e in baseline_runs) & set(int(e) for e in rand_runs)\n        )\n        base_final = [\n            baseline_runs[str(e)][\"metrics\"][\"val\"][-1] for e in epochs_sorted\n        ]\n        rand_final = [rand_runs[str(e)][\"metrics\"][\"val\"][-1] for e in epochs_sorted]\n        plt.figure()\n        plt.plot(epochs_sorted, base_final, marker=\"o\", label=\"Baseline\")\n        plt.plot(epochs_sorted, rand_final, marker=\"s\", label=\"Token-Order Rand.\")\n        plt.xlabel(\"Training Epochs\")\n        plt.ylabel(\"Final HWA\")\n        plt.title(\"SPR_BENCH: Final HWA vs Epochs (Baseline vs Token-Order Rand.)\")\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_hwa_comparison.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA comparison plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set up working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load the stored experiment dict\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nmodels = [\"UNI_LSTM\", \"BI_LSTM\"]\ndataset = \"SPR_BENCH\"\n\n# 1) Final HWA vs epochs (both models)\ntry:\n    plt.figure()\n    for m in models:\n        epochs = sorted(int(k) for k in experiment_data[m][dataset].keys())\n        hwas = [\n            experiment_data[m][dataset][str(e)][\"metrics\"][\"val\"][-1] for e in epochs\n        ]\n        plt.plot(epochs, hwas, marker=\"o\", label=m)\n    plt.title(\"Final Harmonic Weighted Accuracy vs Epochs (SPR_BENCH)\")\n    plt.xlabel(\"Training epochs\")\n    plt.ylabel(\"HWA\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_HWA_vs_epochs.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA_vs_epochs: {e}\")\n    plt.close()\n\n\n# helper to fetch the longest run record for a model\ndef longest_run(model):\n    ep = max(int(k) for k in experiment_data[model][dataset].keys())\n    return ep, experiment_data[model][dataset][str(ep)]\n\n\n# 2) & 3) Loss curves for longest runs\nfor m in models:\n    try:\n        ep, rec = longest_run(m)\n        plt.figure()\n        plt.plot(range(1, ep + 1), rec[\"losses\"][\"train\"], label=\"Train\")\n        plt.plot(range(1, ep + 1), rec[\"losses\"][\"val\"], label=\"Validation\")\n        plt.title(f\"{m} Loss Curves ({ep} Epochs) - SPR_BENCH\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"SPR_BENCH_{m}_loss_curves_{ep}ep.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curves for {m}: {e}\")\n        plt.close()\n\n# 4) Per-epoch HWA for longest runs (both models)\ntry:\n    plt.figure()\n    for m in models:\n        ep, rec = longest_run(m)\n        plt.plot(range(1, ep + 1), rec[\"metrics\"][\"val\"], label=f\"{m} ({ep}ep)\")\n    plt.title(\"Per-Epoch HWA (Longest Runs) - SPR_BENCH\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"HWA\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_HWA_curves_longest_runs.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating per-epoch HWA curves: {e}\")\n    plt.close()\n"], "plot_plan": ["We load experiment_data.npy, extract the four training runs stored under experiment_data['epochs']['SPR_BENCH'], and iterate through each run\u2019s recorded history. For every run we have parallel lists of training losses, validation losses, and validation Harmonic-Weighted-Accuracy (HWA). We create at most two figures: (1) a two-line (train/val) loss curve for every epoch-length setting, all overlaid in a single figure so the reader can compare convergence behaviour; (2) a single HWA curve for each run, likewise overlaid. Each figure is wrapped in an independent try-except block, given a descriptive title that includes the dataset name, saved to working_dir with an informative filename, and closed. We respect the plotting guideline by not inventing data, plotting no more than the available 4 runs (\u22645), always closing figures, and using basic matplotlib defaults. If the data file is missing or malformed the code prints an error but still exits gracefully. All plotting logic is concise and self-contained.", "We will first load experiment_data.npy and iterate through the two stored models (\u201cLSTM\u201d and \u201cBOE\u201d).  \nFor each model we gather, per training-duration run (5/10/20/30 epochs), lists of training losses, validation losses, and validation HWA (harmonic weighted accuracy).  \nWe then create four figures: one loss-curve figure and one HWA-curve figure for each model.  \nWithin a figure we plot the curves for every run (color-coded), provide axes labels, legends and a descriptive title that includes the dataset name.  \nAll plotting is wrapped in individual try-except blocks, figures are saved to working_dir with descriptive filenames, and plt.close() is always called.  \nFinally, we compute the final-epoch HWA for every (model, epoch-setting) pair, print these values, and summarize them with a fifth bar-chart figure comparing models at each epoch length (again wrapped in try-except).  \nNo artificial data are generated; only values inside experiment_data.npy are used.  \nThis yields at most five clear plots plus a concise printed table of evaluation metrics.", "We first load the saved experiment dictionary, then gather per-epoch losses and harmonic weighted accuracies (HWA) for every training dataset.  Three concise visualizations are produced: (1) a combined train/validation loss curve, (2) a combined validation-HWA curve, and (3) a heat-map of cross-domain HWA where rows are training datasets and columns are evaluation datasets.  Each figure is enclosed in its own try-except block, titled clearly, saved under a descriptive name in the working directory, and closed regardless of success.  We limit ourselves to these three plots (\u22645), satisfying the interval rule while conveying all important trends.  After plotting, the script prints a table of cross-domain HWA values so users can inspect metrics directly from stdout.  No data are invented; everything is extracted from experiment_data.npy.  The code follows the required imports, directory setup, and figure-handling conventions, using only standard matplotlib functionality.  Execution is therefore self-contained, robust, and fully compliant with the provided guidelines.", "We first load the stored experiment_data.npy from the working directory and extract the nested results for each model variant (\u201cbaseline\u201d and \u201cfactorized\u201d) and the 10-epoch run (the longest run gives the full curves). For every variant we build two 1-D arrays: train_loss, val_loss and val_HWA, each having length equal to the number of epochs. We create two plots per variant: one showing train vs. validation loss and another showing validation harmonic-weighted accuracy; thus four plots total (< 5 allowed). Each plot is wrapped in its own try-except block, given a clear title that mentions the dataset (\u201cSPR_BENCH\u201d) and the content (\u201cLoss Curves\u201d or \u201cHWA\u201d), and saved with a descriptive filename into working_dir. Figures are always closed in both success and exception paths to prevent memory leaks. Epoch numbers are shown on the x-axis and legends differentiate the series. The script follows the required import order, never fabricates data, and respects the plotting guidelines.", "We will load the saved experiment_data.npy, extract the per-epoch train/validation losses and harmonic weighted accuracy (HWA) for both the baseline (packed) and padding-mask-removal models on SPR_BENCH. For clarity we generate at most five figures: one loss-curve figure per epoch setting for the baseline, one loss-curve figure per epoch setting for the ablation (4 + 4 = 8 would exceed the limit), so instead we aggregate all epoch settings for each model into a single figure (two figures total). We then make a third figure that compares the final-epoch HWA across epoch settings for both models. Each figure is wrapped in a try-except block, given a descriptive title/sub-title, saved into working_dir, and closed afterwards. Only data present in the file are used; no values are fabricated. All plotting uses basic matplotlib and respects the requirement to close figures even when errors occur.", "We will first load experiment_data.npy, create the working directory, and iterate over each recorded epoch setting (5, 10, 20, 30). For every setting we extract the lists of training loss, validation loss, and validation HWA for both the baseline and frozen-embedding runs. Inside a try-except block (one per figure) we create a 1\u00d72 subplot: the left panel compares training/validation loss curves and the right panel compares HWA curves for the two systems. Axes are labelled, legends added, and the main title includes the dataset name and epoch count, while the subtitle clarifies \u201cLeft: Train/Val Loss, Right: HWA (SPR_BENCH)\u201d. Figures are saved with descriptive names such as \u2018SPR_BENCH_e5_curves.png\u2019, then closed. We limit ourselves to these four figures (\u22645 as required) and handle any loading/plotting errors gracefully, always closing figures in finally/except blocks.", "We load the saved experiment_data, loop over at most five hyper-parameter runs, and for each run pull out the training/validation losses and harmonic weighted accuracies that were recorded every epoch.  Each run gets its own figure containing two stacked subplots: the first shows the loss curves (train vs. validation) and the second shows the validation HWA curve.  Titles and filenames include the dataset name (\u201cSPR_BENCH\u201d) and the number of epochs to keep things descriptive.  Every plotting block is wrapped in try-except so a failure in one run doesn\u2019t stop the rest, and all figures are closed after saving.  We also print the final HWA for quick inspection in the notebook / logs.  Plots are written to the provided working directory which is created if missing, and we make no assumptions beyond what is stored inside experiment_data.npy.  This satisfies the requirement of standard visualizations while respecting the five-figure limit, basic matplotlib usage, and clear titling.", "The script loads the saved experiment_data, then in up to five figures it visualizes: (1) baseline training/validation losses for each epoch budget, (2) baseline harmonic-weighted accuracy (HWA) curves, (3) token-order-randomization losses, (4) token-order-randomization HWA, and (5) a comparison of the final-epoch HWA of both settings versus the number of training epochs.  Each figure is generated in its own try-except block, saved in the working directory with a descriptive name containing the dataset and plot type, given a clear title, and the figure is always closed afterwards.  Only values actually present in experiment_data.npy are used; if the file is missing or a plot cannot be produced, the code prints an informative error and still proceeds.  No custom styles are applied beyond default matplotlib.  For runs longer than five epochs, all epochs are plotted because the maximum run length in the data is thirty, which keeps total plotted points reasonable.  The code respects the provided directory structure, creates the working directory if needed, and limits itself to the required imports.  It prints nothing except possible error messages and therefore can be used as a drop-in visualization step after the experiments finish.", "We will load experiment_data.npy, extract per-epoch training/validation losses and harmonic weighted accuracy (HWA) for both UNI_LSTM and BI_LSTM on the SPR_BENCH dataset, and create at most four clear figures: (1) final HWA versus number of training epochs comparing the two models, (2) loss curves (train/val) for the longest UNI_LSTM run (30 epochs), (3) loss curves for the longest BI_LSTM run, and (4) per-epoch HWA for both models in their longest runs. Each figure is wrapped in its own try-except block, saved with descriptive filenames in working_dir, titled appropriately, closed after saving, and only plots data that actually exist in experiment_data.npy."], "ablation_name": [null, "Bag-of-Embeddings (Order-Agnostic) Classifier", "Multi-Synthetic-Dataset Generalization Ablation", "Factorized Shape-and-Color Embeddings", "Padding-Mask Removal Ablation", "Frozen-Embedding Ablation", "Shape-Color Split Tokenization Ablation", "Token-Order Randomization Ablation", "Bidirectional LSTM Ablation"], "hyperparam_name": ["epochs", null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false], "parse_metrics_plan": ["The script loads the saved experiment_data.npy file, navigates its nested\ndictionary to reach each training run, and for every set of epochs extracts the\nlast logged training loss, the last logged validation loss, and the best\n(maximum) validation harmonic-weighted accuracy. It then prints the dataset name\nfirst, followed by each metric name and its corresponding value with clear,\nexplicit labels. The entire procedure is executed immediately at import time and\ncontains no guarded entry point.", "The script reads the saved NumPy file, drills down through the nested dictionary\n(model \u2192 dataset \u2192 epoch\u2010run) and collects the final values of each metric\nrecorded during training.   For every model (LSTM and BOE) inside the single\ndataset (SPR_BENCH) it keeps the best value across all epoch settings: lowest\ntraining loss, lowest validation loss, and highest validation harmonic-weighted\naccuracy.   It then prints the dataset name first, followed by clearly labelled\nmetric lines for every model.", "The script will load experiment_data.npy from the \u201cworking\u201d sub-directory, which\ncontains the saved dictionary experiment_data[\"MultiSynthetic\"] produced by the\noriginal training script.   For each training dataset (SetA, SetB, SetC) it will\nreport:   \u2022 the lowest (best) training loss across epochs,   \u2022 the lowest\nvalidation loss across epochs,   \u2022 the highest validation harmonic-weighted\naccuracy across epochs.   It will then iterate over the stored cross-domain\nevaluation results and print, for every target dataset, the final accuracy and\nharmonic-weighted accuracy obtained by the model.   All metric names are printed\nexplicitly so the output is self-explanatory, and the code runs immediately on\nexecution.", "Below is a short outline followed by the full script.   The script loads the\nsaved NumPy dictionary, navigates its nested structure (variant \u2192 dataset \u2192\n#epochs), and prints\u2014per configuration\u2014the final training loss, final validation\nloss, and final validation harmonic-weighted accuracy (HWA).   The dataset name\n(\u201cSPR_BENCH\u201d) is printed once before all metrics, and every metric is explicitly\nnamed.", "The code will locate the saved NumPy file inside the \u201cworking\u201d directory, load\nit as a regular Python dictionary, and iterate through every stored experiment.\nFor every experiment (e.g., \u201cbaseline\u201d or \u201cpadding_mask_removal\u201d) and every\ndataset within it (here only \u201cSPR_BENCH\u201d), the script scans all epoch-variants,\ncollects the final values of each metric series, and retains the best\none\u2014minimum for the two losses and maximum for the harmonic weighted accuracy.\nEach dataset name is printed first, followed by clearly labelled lines for\n\u201ctraining loss,\u201d \u201cvalidation loss,\u201d and \u201cvalidation harmonic weighted accuracy,\u201d\nshowing the best value observed across the sweep.", "The script will load the numpy dictionary from the working directory, iterate\nover each experimental variant (baseline and frozen\u2006_emb) and their stored epoch\nruns for the SPR_BENCH dataset, pick the run that ends with the highest\nvalidation harmonic-weighted accuracy, and then print the final values of train\nloss, validation loss, and validation harmonic-weighted accuracy.   Each block\nof output begins with \u201cDataset: SPR_BENCH | Variant: \u2026\u201d so the dataset name is\nalways shown first, followed by clearly labelled metric lines.   The code lives\nat the global scope, executes immediately, and produces no plots.", "We first load experiment_data.npy from the \u201cworking\u201d directory and convert it\nback to a Python dict.   For each ablation \u2192 dataset combination (here only\nSPR_BENCH), we iterate over every hyper-parameter run, gather the per-epoch\nmetric arrays, and keep track of:   \u2022 the best (highest) harmonic weighted\naccuracy,   \u2022 the lowest validation loss, and   \u2022 the lowest training loss\nacross all epochs and runs.   Finally, we print the dataset name followed by\neach metric name and its best/final value.", "The solution loads the serialized dictionary from the working directory,\niterates through every experiment \u2192 dataset \u2192 epoch configuration, and then\nprints three clearly-labelled metrics: the final training loss, the final\nvalidation loss, and the best (maximum) validation harmonic weighted accuracy.\nEach printout is preceded by the dataset/experiment/epoch identifier so results\nare easy to follow. No plotting or main-guard is used; the script executes\nimmediately.", "The script will load the stored numpy dictionary, iterate through each dataset\n(e.g., SPR_BENCH), model (UNI_LSTM, BI_LSTM), and epoch run, then print the\nfinal recorded values for train loss, validation loss, and validation harmonic-\nweighted accuracy (HWA). All code executes immediately at import time and stays\noutside any `if __name__ == \"__main__\":` block."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ----------------- locate and load -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ----------------- traverse and print -----------------\n# experiment_data structure:\n# experiment_data[\"epochs\"][DATASET_NAME][EPOCHS_STR] -> run_rec dict\nfor dataset_name, epoch_dict in experiment_data.get(\"epochs\", {}).items():\n    for epochs_str, run_rec in epoch_dict.items():\n        # Extract final (last) losses\n        final_train_loss = (\n            run_rec[\"losses\"][\"train\"][-1] if run_rec[\"losses\"][\"train\"] else None\n        )\n        final_val_loss = (\n            run_rec[\"losses\"][\"val\"][-1] if run_rec[\"losses\"][\"val\"] else None\n        )\n\n        # Extract best validation HWA\n        val_hwa_list = run_rec.get(\"metrics\", {}).get(\"val\", [])\n        best_val_hwa = max(val_hwa_list) if val_hwa_list else None\n\n        # ----------------- printing -----------------\n        print(f\"Dataset: {dataset_name} (epochs = {epochs_str})\")\n        if final_train_loss is not None:\n            print(f\"training loss: {final_train_loss:.4f}\")\n        if final_val_loss is not None:\n            print(f\"validation loss: {final_val_loss:.4f}\")\n        if best_val_hwa is not None:\n            print(f\"best validation harmonic weighted accuracy: {best_val_hwa:.3f}\")\n        print()  # blank line for readability\n", "import os\nimport numpy as np\n\n# ---------- load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- aggregate & print ----------\nfor model_name, dataset_dict in experiment_data.items():\n    for dataset_name, runs in dataset_dict.items():\n        best_train_loss = float(\"inf\")\n        best_val_loss = float(\"inf\")\n        best_val_hwa = -float(\"inf\")\n\n        for run_key, record in runs.items():\n            # final values for this particular run (e.g. \"5\", \"10\", \"20\", \"30\" epochs)\n            if record[\"losses\"][\"train\"]:\n                final_train_loss = record[\"losses\"][\"train\"][-1]\n                best_train_loss = min(best_train_loss, final_train_loss)\n\n            if record[\"losses\"][\"val\"]:\n                final_val_loss = record[\"losses\"][\"val\"][-1]\n                best_val_loss = min(best_val_loss, final_val_loss)\n\n            if record[\"metrics\"][\"val\"]:\n                final_val_hwa = record[\"metrics\"][\"val\"][-1]\n                best_val_hwa = max(best_val_hwa, final_val_hwa)\n\n        # ---- output ----\n        print(f\"{dataset_name}  |  Model: {model_name}\")\n        print(f\"  best training loss: {best_train_loss:.4f}\")\n        print(f\"  best validation loss: {best_val_loss:.4f}\")\n        print(f\"  best validation harmonic weighted accuracy: {best_val_hwa:.3f}\")\n", "import os\nimport numpy as np\n\n# ---------- load ----------\nwork_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(work_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\nmulti_syn = experiment_data.get(\"MultiSynthetic\", {})\n\nfor train_dataset, rec in multi_syn.items():\n    print(f\"\\nDataset trained on: {train_dataset}\")\n\n    # --- in-domain metrics (per-epoch lists) ---\n    best_train_loss = min(rec[\"losses\"][\"train\"])\n    best_val_loss = min(rec[\"losses\"][\"val\"])\n    best_val_hwa = max(rec[\"metrics\"][\"val\"])\n\n    print(f\"best training loss: {best_train_loss:.4f}\")\n    print(f\"best validation loss: {best_val_loss:.4f}\")\n    print(f\"best validation harmonic weighted accuracy: {best_val_hwa:.4f}\")\n\n    # --- cross-domain metrics ---\n    for eval_dataset, m in rec[\"cross_eval\"].items():\n        acc = m[\"accuracy\"]\n        hwa = m[\"hwa\"]\n        print(f\"cross-evaluation accuracy on {eval_dataset}: {acc:.4f}\")\n        print(\n            f\"cross-evaluation harmonic weighted accuracy on {eval_dataset}: {hwa:.4f}\"\n        )\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------------\n# Load experiment data\n# ------------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------------\n# Pretty printing helper\n# ------------------------------------------------------------------------\ndef print_config_metrics(variant_name: str, epoch_key: str, record: dict):\n    \"\"\"Print final values for the desired metrics for one training run.\"\"\"\n    final_train_loss = record[\"losses\"][\"train\"][-1]\n    final_val_loss = record[\"losses\"][\"val\"][-1]\n    final_val_hwa = record[\"metrics\"][\"val\"][-1]\n\n    print(f\"\\n{variant_name.capitalize()} model trained for {epoch_key} epochs:\")\n    print(f\"  train loss: {final_train_loss:.4f}\")\n    print(f\"  validation loss: {final_val_loss:.4f}\")\n    print(f\"  validation harmonic weighted accuracy: {final_val_hwa:.4f}\")\n\n\n# ------------------------------------------------------------------------\n# Iterate over datasets, variants and epochs\n# ------------------------------------------------------------------------\nfor variant, datasets in experiment_data.items():\n    for dataset_name, epoch_dict in datasets.items():\n        # Print dataset name once (as required)\n        print(f\"\\n=== Dataset: {dataset_name} ===\")\n        for epoch_key, rec in epoch_dict.items():\n            print_config_metrics(variant, epoch_key, rec)\n", "import os\nimport numpy as np\n\n# ----------------- load data -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ----------------- metric extraction & display -----------------\nfor experiment_name, datasets in experiment_data.items():\n    for dataset_name, runs in datasets.items():\n        # initialise trackers\n        best_train_loss = float(\"inf\")\n        best_val_loss = float(\"inf\")\n        best_hwa = -float(\"inf\")\n\n        # iterate over each hyper-parameter setting (\u2018runs\u2019 are keyed by epoch count)\n        for epoch_setting, record in runs.items():\n            # take the final value in each recorded list\n            final_train_loss = record[\"losses\"][\"train\"][-1]\n            final_val_loss = record[\"losses\"][\"val\"][-1]\n            final_hwa = record[\"metrics\"][\"val\"][-1]\n\n            # update bests\n            best_train_loss = min(best_train_loss, final_train_loss)\n            best_val_loss = min(best_val_loss, final_val_loss)\n            best_hwa = max(best_hwa, final_hwa)\n\n        # print results: dataset first, then clearly labelled metrics\n        print(f\"{dataset_name} ({experiment_name})\")\n        print(f\"best training loss: {best_train_loss:.4f}\")\n        print(f\"best validation loss: {best_val_loss:.4f}\")\n        print(f\"best validation harmonic weighted accuracy: {best_hwa:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# ---------- load the saved experiment dictionary ----------\ndata_path = os.path.join(os.getcwd(), \"working\", \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n\ndef print_best_metrics(exp_dict):\n    \"\"\"\n    For each variant and dataset, print metrics from the run that achieves the\n    highest final validation harmonic-weighted accuracy (HWA).\n    \"\"\"\n    for variant_name, datasets in exp_dict.items():\n        for dataset_name, epoch_runs in datasets.items():\n\n            # Select the run (i.e., epoch setting) with the best final HWA\n            best_ep_key, best_record, best_hwa = None, None, -float(\"inf\")\n            for ep_key, record in epoch_runs.items():\n                if not record[\"metrics\"][\"val\"]:  # safety check\n                    continue\n                hwa_final = record[\"metrics\"][\"val\"][-1]\n                if hwa_final > best_hwa:\n                    best_hwa = hwa_final\n                    best_ep_key = ep_key\n                    best_record = record\n\n            if best_record is None:  # nothing to report\n                continue\n\n            train_loss_final = best_record[\"losses\"][\"train\"][-1]\n            val_loss_final = best_record[\"losses\"][\"val\"][-1]\n\n            # ---------- formatted printing ----------\n            print(\n                f\"Dataset: {dataset_name} | Variant: {variant_name} | Epochs: {best_ep_key}\"\n            )\n            print(f\"final train loss: {train_loss_final:.4f}\")\n            print(f\"final validation loss: {val_loss_final:.4f}\")\n            print(f\"final validation harmonic weighted accuracy: {best_hwa:.4f}\\n\")\n\n\n# Execute summary printing\nprint_best_metrics(experiment_data)\n", "import os\nimport numpy as np\n\n# ----------------- load data -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ----------------- aggregate + report -----------------\nfor ablation_name, dataset_dict in experiment_data.items():\n    for dataset_name, runs_dict in dataset_dict.items():\n        best_hwa = -float(\"inf\")\n        lowest_val_loss = float(\"inf\")\n        lowest_train_loss = float(\"inf\")\n\n        # iterate over all hyper-parameter runs (e.g., \"5\", \"10\", \"20\", \"30\" epochs)\n        for run_id, rec in runs_dict.items():\n            train_losses = rec[\"losses\"][\"train\"]  # list of floats per epoch\n            val_losses = rec[\"losses\"][\"val\"]  # list of floats per epoch\n            hwa_values = rec[\"metrics\"][\"val\"]  # list of harmonic weighted accuracies\n\n            # update aggregated best/lowest values\n            best_hwa = max(best_hwa, max(hwa_values))\n            lowest_val_loss = min(lowest_val_loss, min(val_losses))\n            lowest_train_loss = min(lowest_train_loss, min(train_losses))\n\n        # ------------ print results for this dataset ------------\n        print(dataset_name)\n        print(f\"best harmonic weighted accuracy: {best_hwa:.4f}\")\n        print(f\"lowest validation loss: {lowest_val_loss:.4f}\")\n        print(f\"lowest training loss: {lowest_train_loss:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# ----------------- load experiment data -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ----------------- metric extraction & printing -----------------\nfor experiment_name, datasets in experiment_data.items():\n    for dataset_name, epochs_dict in datasets.items():\n        # print dataset header once per dataset to satisfy the requirement\n        print(f\"\\nDataset: {dataset_name}\")\n        for epoch_str, record in epochs_dict.items():\n            # safety checks\n            train_losses = record.get(\"losses\", {}).get(\"train\", [])\n            val_losses = record.get(\"losses\", {}).get(\"val\", [])\n            val_hwa = record.get(\"metrics\", {}).get(\"val\", [])\n\n            final_train_loss = train_losses[-1] if train_losses else None\n            final_val_loss = val_losses[-1] if val_losses else None\n            best_val_hwa = max(val_hwa) if val_hwa else None\n\n            header = (\n                f\"  Experiment variant: {experiment_name} | \"\n                f\"Epoch setting: {epoch_str}\"\n            )\n            print(header)\n            if final_train_loss is not None:\n                print(f\"    Final training loss: {final_train_loss:.4f}\")\n            if final_val_loss is not None:\n                print(f\"    Final validation loss: {final_val_loss:.4f}\")\n            if best_val_hwa is not None:\n                print(\n                    f\"    Best validation harmonic weighted accuracy: \"\n                    f\"{best_val_hwa:.4f}\"\n                )\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 1. Locate and load the saved experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy at {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# 2. Traverse the nested structure and report the final statistics\n# ------------------------------------------------------------------\nfor dataset_name in {\n    ds for model_dict in experiment_data.values() for ds in model_dict\n}:\n    print(f\"Dataset: {dataset_name}\")\n    for model_name, model_content in experiment_data.items():\n        if dataset_name not in model_content:\n            continue\n        print(f\"  Model: {model_name}\")\n        for epoch_str, run_record in model_content[dataset_name].items():\n            # Extract the final recorded values\n            final_train_loss = run_record[\"losses\"][\"train\"][-1]\n            final_val_loss = run_record[\"losses\"][\n                \"validation\" if \"validation\" in run_record[\"losses\"] else \"val\"\n            ][-1]\n            final_hwa = run_record[\"metrics\"][\n                \"validation\" if \"validation\" in run_record[\"metrics\"] else \"val\"\n            ][-1]\n\n            print(f\"    Epochs: {epoch_str}\")\n            print(f\"      final train loss: {final_train_loss:.4f}\")\n            print(f\"      final validation loss: {final_val_loss:.4f}\")\n            print(f\"      final validation harmonic weighted accuracy: {final_hwa:.4f}\")\n"], "parse_term_out": ["['Dataset: SPR_BENCH (epochs = 5)', '\\n', 'training loss: 0.6330', '\\n',\n'validation loss: 0.6444', '\\n', 'best validation harmonic weighted accuracy:\n0.582', '\\n', '\\n', 'Dataset: SPR_BENCH (epochs = 10)', '\\n', 'training loss:\n0.5117', '\\n', 'validation loss: 0.6824', '\\n', 'best validation harmonic\nweighted accuracy: 0.640', '\\n', '\\n', 'Dataset: SPR_BENCH (epochs = 20)', '\\n',\n'training loss: 0.2033', '\\n', 'validation loss: 1.1331', '\\n', 'best validation\nharmonic weighted accuracy: 0.636', '\\n', '\\n', 'Dataset: SPR_BENCH (epochs =\n30)', '\\n', 'training loss: 0.0171', '\\n', 'validation loss: 1.3624', '\\n',\n'best validation harmonic weighted accuracy: 0.668', '\\n', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH  |  Model: LSTM', '\\n', '  best training loss: 0.0171', '\\n', '\nbest validation loss: 0.6444', '\\n', '  best validation harmonic weighted\naccuracy: 0.629', '\\n', 'SPR_BENCH  |  Model: BOE', '\\n', '  best training loss:\n0.6795', '\\n', '  best validation loss: 0.6939', '\\n', '  best validation\nharmonic weighted accuracy: 0.581', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['\\nDataset trained on: SetA', '\\n', 'best training loss: 0.5197', '\\n', 'best\nvalidation loss: 0.6410', '\\n', 'best validation harmonic weighted accuracy:\n0.6412', '\\n', 'cross-evaluation accuracy on SetA: 0.6150', '\\n', 'cross-\nevaluation harmonic weighted accuracy on SetA: 0.6171', '\\n', 'cross-evaluation\naccuracy on SetB: 0.9600', '\\n', 'cross-evaluation harmonic weighted accuracy on\nSetB: 0.9670', '\\n', 'cross-evaluation accuracy on SetC: 0.6950', '\\n', 'cross-\nevaluation harmonic weighted accuracy on SetC: 0.7070', '\\n', '\\nDataset trained\non: SetB', '\\n', 'best training loss: 0.1146', '\\n', 'best validation loss:\n0.1731', '\\n', 'best validation harmonic weighted accuracy: 0.9670', '\\n',\n'cross-evaluation accuracy on SetA: 0.3200', '\\n', 'cross-evaluation harmonic\nweighted accuracy on SetA: 0.3350', '\\n', 'cross-evaluation accuracy on SetB:\n0.9600', '\\n', 'cross-evaluation harmonic weighted accuracy on SetB: 0.9670',\n'\\n', 'cross-evaluation accuracy on SetC: 0.4950', '\\n', 'cross-evaluation\nharmonic weighted accuracy on SetC: 0.4764', '\\n', '\\nDataset trained on: SetC',\n'\\n', 'best training loss: 0.4771', '\\n', 'best validation loss: 0.6321', '\\n',\n'best validation harmonic weighted accuracy: 0.7105', '\\n', 'cross-evaluation\naccuracy on SetA: 0.4950', '\\n', 'cross-evaluation harmonic weighted accuracy on\nSetA: 0.4793', '\\n', 'cross-evaluation accuracy on SetB: 0.0400', '\\n', 'cross-\nevaluation harmonic weighted accuracy on SetB: 0.0302', '\\n', 'cross-evaluation\naccuracy on SetC: 0.6600', '\\n', 'cross-evaluation harmonic weighted accuracy on\nSetC: 0.6612', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\n=== Dataset: SPR_BENCH ===', '\\n', '\\nBaseline model trained for 5 epochs:',\n'\\n', '  train loss: 0.6330', '\\n', '  validation loss: 0.6444', '\\n', '\nvalidation harmonic weighted accuracy: 0.5823', '\\n', '\\nBaseline model trained\nfor 10 epochs:', '\\n', '  train loss: 0.5117', '\\n', '  validation loss:\n0.6824', '\\n', '  validation harmonic weighted accuracy: 0.6292', '\\n', '\\n===\nDataset: SPR_BENCH ===', '\\n', '\\nFactorized model trained for 5 epochs:', '\\n',\n'  train loss: 0.6314', '\\n', '  validation loss: 0.6459', '\\n', '  validation\nharmonic weighted accuracy: 0.6148', '\\n', '\\nFactorized model trained for 10\nepochs:', '\\n', '  train loss: 0.5299', '\\n', '  validation loss: 0.6716', '\\n',\n'  validation harmonic weighted accuracy: 0.6405', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['SPR_BENCH (baseline)', '\\n', 'best training loss: 0.0273', '\\n', 'best\nvalidation loss: 0.6444', '\\n', 'best validation harmonic weighted accuracy:\n0.6155\\n', '\\n', 'SPR_BENCH (padding_mask_removal)', '\\n', 'best training loss:\n0.0016', '\\n', 'best validation loss: 0.0044', '\\n', 'best validation harmonic\nweighted accuracy: 1.0000\\n', '\\n', 'Execution time: a moment seconds (time\nlimit is 30 minutes).']", "['Dataset: SPR_BENCH | Variant: baseline | Epochs: 20', '\\n', 'final train loss:\n0.1761', '\\n', 'final validation loss: 1.1195', '\\n', 'final validation harmonic\nweighted accuracy: 0.6155\\n', '\\n', 'Dataset: SPR_BENCH | Variant: frozen_emb |\nEpochs: 5', '\\n', 'final train loss: 0.6132', '\\n', 'final validation loss:\n0.6405', '\\n', 'final validation harmonic weighted accuracy: 0.6322\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'best harmonic weighted accuracy: 0.6745', '\\n', 'lowest\nvalidation loss: 0.6450', '\\n', 'lowest training loss: 0.0923\\n', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Experiment variant: baseline | Epoch setting:\n5', '\\n', '    Final training loss: 0.6330', '\\n', '    Final validation loss:\n0.6444', '\\n', '    Best validation harmonic weighted accuracy: 0.5823', '\\n', '\nExperiment variant: baseline | Epoch setting: 10', '\\n', '    Final training\nloss: 0.5117', '\\n', '    Final validation loss: 0.6897', '\\n', '    Best\nvalidation harmonic weighted accuracy: 0.6405', '\\n', '  Experiment variant:\nbaseline | Epoch setting: 20', '\\n', '    Final training loss: 0.1761', '\\n', '\nFinal validation loss: 1.1195', '\\n', '    Best validation harmonic weighted\naccuracy: 0.6473', '\\n', '  Experiment variant: baseline | Epoch setting: 30',\n'\\n', '    Final training loss: 0.0273', '\\n', '    Final validation loss:\n1.8470', '\\n', '    Best validation harmonic weighted accuracy: 0.6435', '\\n',\n'\\nDataset: SPR_BENCH', '\\n', '  Experiment variant: token_order_randomization |\nEpoch setting: 5', '\\n', '    Final training loss: 0.6503', '\\n', '    Final\nvalidation loss: 0.6534', '\\n', '    Best validation harmonic weighted accuracy:\n0.5914', '\\n', '  Experiment variant: token_order_randomization | Epoch setting:\n10', '\\n', '    Final training loss: 0.6058', '\\n', '    Final validation loss:\n0.6688', '\\n', '    Best validation harmonic weighted accuracy: 0.6065', '\\n', '\nExperiment variant: token_order_randomization | Epoch setting: 20', '\\n', '\nFinal training loss: 0.5932', '\\n', '    Final validation loss: 0.6726', '\\n', '\nBest validation harmonic weighted accuracy: 0.6291', '\\n', '  Experiment\nvariant: token_order_randomization | Epoch setting: 30', '\\n', '    Final\ntraining loss: 0.5468', '\\n', '    Final validation loss: 0.6944', '\\n', '\nBest validation harmonic weighted accuracy: 0.6291', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', '  Model: UNI_LSTM', '\\n', '    Epochs: 5', '\\n', '\nfinal train loss: 0.6330', '\\n', '      final validation loss: 0.6444', '\\n', '\nfinal validation harmonic weighted accuracy: 0.5823', '\\n', '    Epochs: 10',\n'\\n', '      final train loss: 0.5117', '\\n', '      final validation loss:\n0.6824', '\\n', '      final validation harmonic weighted accuracy: 0.6292',\n'\\n', '    Epochs: 20', '\\n', '      final train loss: 0.2033', '\\n', '\nfinal validation loss: 1.1331', '\\n', '      final validation harmonic weighted\naccuracy: 0.5838', '\\n', '    Epochs: 30', '\\n', '      final train loss:\n0.0171', '\\n', '      final validation loss: 1.3624', '\\n', '      final\nvalidation harmonic weighted accuracy: 0.6201', '\\n', '  Model: BI_LSTM', '\\n',\n'    Epochs: 5', '\\n', '      final train loss: 0.6039', '\\n', '      final\nvalidation loss: 0.6645', '\\n', '      final validation harmonic weighted\naccuracy: 0.6027', '\\n', '    Epochs: 10', '\\n', '      final train loss:\n0.4688', '\\n', '      final validation loss: 0.7078', '\\n', '      final\nvalidation harmonic weighted accuracy: 0.6026', '\\n', '    Epochs: 20', '\\n', '\nfinal train loss: 0.0539', '\\n', '      final validation loss: 1.3026', '\\n', '\nfinal validation harmonic weighted accuracy: 0.5914', '\\n', '    Epochs: 30',\n'\\n', '      final train loss: 0.0050', '\\n', '      final validation loss:\n2.0219', '\\n', '      final validation harmonic weighted accuracy: 0.5921',\n'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']"], "parse_exc_type": [null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
