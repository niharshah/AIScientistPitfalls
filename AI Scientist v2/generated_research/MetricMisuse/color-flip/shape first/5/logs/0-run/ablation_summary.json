[
  {
    "overall_plan": "The overall plan involves a sequence representation and classification pipeline initially developed with a contrastive pre-training phase followed by supervised fine-tuning. The pipeline starts by tokenizing SPR sequences, constructing a vocabulary, and encoding sequences using an embedding layer and bi-directional LSTM. The contrastive pre-training phase involved augmenting sequences with random masking and local shuffling, optimizing an InfoNCE loss, and employing a projection head to learn rich representations before attaching a linear classifier for fine-tuning. Evaluation metrics include Shape-Weighted Accuracy, Color-Weighted Accuracy, and Complexity-Weighted Composite Accuracy (CWCA), with all results and a t-SNE visualization stored for analysis. The current plan, under the ablation name 'NoContrastivePretraining,' removes the contrastive pre-training entirely, initializing the encoder randomly and proceeding directly to supervised fine-tuning, while keeping other parameters and architecture identical. This ablation aims to evaluate the necessity and impact of the pre-training phase, helping to understand its contribution to the overall performance and informing future pipeline enhancements.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "CWCA",
            "lower_is_better": false,
            "description": "A metric for evaluating classification performance.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.5107,
                "best_value": 0.5107
              }
            ]
          },
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "The loss value during training, indicating the error between predictions and actual values.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.683,
                "best_value": 0.683
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "The loss value during validation, used to evaluate model performance on unseen data.",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.6976,
                "best_value": 0.6976
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "# NoContrastivePretraining \u2013 single-file ablation\nimport os, random, math, pathlib, time, itertools, warnings\nimport numpy as np\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List, Dict\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------------------------------------------------\n# Try to load SPR_BENCH, else build synthetic toy data\ndef safe_load_spr():\n    try:\n        from SPR import load_spr_bench\n\n        DATA_PATH = pathlib.Path(\"SPR_BENCH\")\n        if DATA_PATH.exists():\n            return load_spr_bench(DATA_PATH)\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH; falling back to synthetic.\", e)\n\n    shapes, colors = list(\"ABCDEFG\"), list(\"123456\")\n\n    def random_token():\n        return random.choice(shapes) + random.choice(colors)\n\n    def random_seq():\n        return \" \".join(random_token() for _ in range(random.randint(4, 10)))\n\n    def label_fn(seq):\n        return 1 if sum(tok[0] in \"ABC\" for tok in seq.split()) % 2 == 0 else 0\n\n    synthetic = {\"train\": [], \"dev\": [], \"test\": []}\n    for split, n in [(\"train\", 2000), (\"dev\", 400), (\"test\", 400)]:\n        for i in range(n):\n            seq = random_seq()\n            synthetic[split].append({\"id\": i, \"sequence\": seq, \"label\": label_fn(seq)})\n    return synthetic\n\n\ndset = safe_load_spr()\nprint({k: len(v) for k, v in dset.items()})\n\n\n# ------------------------------------------------------------\n# metrics\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef cwca(seqs, y_true, y_pred):\n    weights = [(count_shape_variety(s) + count_color_variety(s)) / 2 for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\n# ------------------------------------------------------------\n# vocab\nPAD, MASK, UNK = \"<PAD>\", \"<MASK>\", \"<UNK>\"\n\n\ndef build_vocab(seqs):\n    vocab = set(itertools.chain.from_iterable(s.split() for s in seqs))\n    vocab = [PAD, MASK, UNK] + sorted(vocab)\n    stoi = {tok: i for i, tok in enumerate(vocab)}\n    return vocab, stoi\n\n\nvocab, stoi = build_vocab([ex[\"sequence\"] for ex in dset[\"train\"]])\nitos = {i: s for s, i in stoi.items()}\n\n\ndef encode(seq: str) -> List[int]:\n    return [stoi.get(tok, stoi[UNK]) for tok in seq.split()]\n\n\n# ------------------------------------------------------------\nclass SPRDataset(Dataset):\n    def __init__(self, recs, with_label=True):\n        self.recs = recs\n        self.with_label = with_label\n\n    def __len__(self):\n        return len(self.recs)\n\n    def __getitem__(self, idx):\n        rec = self.recs[idx]\n        item = {\"input_ids\": torch.tensor(encode(rec[\"sequence\"]), dtype=torch.long)}\n        if self.with_label:\n            item[\"label\"] = torch.tensor(rec[\"label\"], dtype=torch.long)\n        return item\n\n\ndef collate_classification(batch):\n    seqs = [b[\"input_ids\"] for b in batch]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    lengths = [len(s) for s in seqs]\n    max_len = max(lengths)\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    for i, s in enumerate(seqs):\n        padded[i, : len(s)] = s\n    return {\n        \"input_ids\": padded.to(device),\n        \"label\": labels.to(device),\n        \"lengths\": torch.tensor(lengths).to(device),\n    }\n\n\n# ------------------------------------------------------------\n# model\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, d_model=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        self.lstm = nn.LSTM(d_model, d_model, batch_first=True, bidirectional=True)\n        self.linear = nn.Linear(d_model * 2, d_model)\n\n    def forward(self, x, lens):\n        emb = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        h, _ = self.lstm(packed)\n        h, _ = nn.utils.rnn.pad_packed_sequence(h, batch_first=True)\n        mask = (x != 0).unsqueeze(-1)\n        h_mean = (h * mask).sum(1) / (mask.sum(1) + 1e-6)\n        return self.linear(h_mean)\n\n\nclass SPRModel(nn.Module):\n    def __init__(self, vocab_size, num_labels):\n        super().__init__()\n        self.encoder = Encoder(vocab_size)\n        self.classifier = nn.Linear(128, num_labels)\n\n    def forward(self, x, lens):\n        rep = self.encoder(x, lens)\n        return self.classifier(rep), rep\n\n\n# ------------------------------------------------------------\n# data loaders\ntrain_loader = DataLoader(\n    SPRDataset(dset[\"train\"]),\n    batch_size=64,\n    shuffle=True,\n    collate_fn=collate_classification,\n)\ndev_loader = DataLoader(\n    SPRDataset(dset[\"dev\"]),\n    batch_size=64,\n    shuffle=False,\n    collate_fn=collate_classification,\n)\ntest_loader = DataLoader(\n    SPRDataset(dset[\"test\"]),\n    batch_size=64,\n    shuffle=False,\n    collate_fn=collate_classification,\n)\n\n# ------------------------------------------------------------\n# experiment logging dict\nexperiment_data = {\n    \"NoContrastivePretraining\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# ------------------------------------------------------------\n# initialise model (random) \u2013 no contrastive pre-training\nmodel = SPRModel(len(vocab), num_labels=len(set(r[\"label\"] for r in dset[\"train\"]))).to(\n    device\n)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\nclf_epochs = 5\n\n\ndef run_epoch(loader, train=True):\n    model.train() if train else model.eval()\n    total_loss, preds, trues, seqs = 0.0, [], [], []\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            logits, _ = model(batch[\"input_ids\"], batch[\"lengths\"])\n            loss = criterion(logits, batch[\"label\"])\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            total_loss += loss.item() * batch[\"label\"].size(0)\n            pred = logits.argmax(1).detach().cpu().numpy()\n            true = batch[\"label\"].detach().cpu().numpy()\n            preds.extend(pred)\n            trues.extend(true)\n            seqs.extend(\n                [\n                    \" \".join(itos[idx.item()] for idx in row if idx.item() != 0)\n                    for row in batch[\"input_ids\"].cpu()\n                ]\n            )\n    cwca_val = cwca(seqs, trues, preds)\n    return total_loss / len(loader.dataset), cwca_val, preds, trues\n\n\nbest_val = 0\nfor epoch in range(1, clf_epochs + 1):\n    tr_loss, tr_cwca, _, _ = run_epoch(train_loader, True)\n    val_loss, val_cwca, _, _ = run_epoch(dev_loader, False)\n    experiment_data[\"NoContrastivePretraining\"][\"SPR_BENCH\"][\"losses\"][\"train\"].append(\n        tr_loss\n    )\n    experiment_data[\"NoContrastivePretraining\"][\"SPR_BENCH\"][\"losses\"][\"val\"].append(\n        val_loss\n    )\n    experiment_data[\"NoContrastivePretraining\"][\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        tr_cwca\n    )\n    experiment_data[\"NoContrastivePretraining\"][\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        val_cwca\n    )\n    print(\n        f\"Epoch {epoch}: train_loss={tr_loss:.4f}  val_loss={val_loss:.4f}  val_CWCA={val_cwca:.4f}\"\n    )\n    best_val = max(best_val, val_cwca)\n\n# ------------------------------------------------------------\n# final test evaluation\ntest_loss, test_cwca, preds, trues = run_epoch(test_loader, False)\nprint(f\"Test CWCA = {test_cwca:.4f}\")\nexperiment_data[\"NoContrastivePretraining\"][\"SPR_BENCH\"][\"metrics\"][\"test\"].append(\n    test_cwca\n)\nexperiment_data[\"NoContrastivePretraining\"][\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"NoContrastivePretraining\"][\"SPR_BENCH\"][\"ground_truth\"] = trues\n\n# ------------------------------------------------------------\n# t-SNE visualisation on dev embeddings\nmodel.eval()\nembs, labels = [], []\nwith torch.no_grad():\n    for batch in dev_loader:\n        _, reps = model(batch[\"input_ids\"], batch[\"lengths\"])\n        embs.append(reps.cpu().numpy())\n        labels.extend(batch[\"label\"].cpu().numpy())\nembs = np.concatenate(embs, 0)\ntsne = TSNE(n_components=2, init=\"random\", perplexity=30, random_state=0).fit_transform(\n    embs\n)\nplt.figure(figsize=(6, 5))\nplt.scatter(tsne[:, 0], tsne[:, 1], c=labels, cmap=\"tab10\", s=10)\nplt.title(\"t-SNE of dev embeddings (NoContrastivePretraining)\")\nplt.tight_layout()\nplt.savefig(os.path.join(working_dir, \"tsne_dev.png\"))\n\n# ------------------------------------------------------------\n# save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data and plot to ./working/\")\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nexp_key = \"NoContrastivePretraining\"\ndset_key = \"SPR_BENCH\"\nif exp_key in experiment_data and dset_key in experiment_data[exp_key]:\n    data = experiment_data[exp_key][dset_key]\n    losses_tr = data[\"losses\"][\"train\"]\n    losses_val = data[\"losses\"][\"val\"]\n    cwca_tr = data[\"metrics\"][\"train\"]\n    cwca_val = data[\"metrics\"][\"val\"]\n    cwca_test = data[\"metrics\"][\"test\"][0] if data[\"metrics\"][\"test\"] else None\n    y_pred = np.array(data[\"predictions\"])\n    y_true = np.array(data[\"ground_truth\"])\nelse:\n    print(\"Required keys not found in experiment_data.\")\n    losses_tr = losses_val = cwca_tr = cwca_val = []\n    cwca_test = None\n    y_pred = y_true = np.array([])\n\n# ------------------------------------------------------------------\n# 1) Loss curves\ntry:\n    plt.figure()\n    epochs = range(1, len(losses_tr) + 1)\n    plt.plot(epochs, losses_tr, label=\"Train\")\n    plt.plot(epochs, losses_val, label=\"Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"Loss Curves \u2013 SPR_BENCH\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------\n# 2) CWCA curves (+ test point)\ntry:\n    plt.figure()\n    plt.plot(epochs, cwca_tr, label=\"Train\")\n    plt.plot(epochs, cwca_val, label=\"Validation\")\n    if cwca_test is not None:\n        plt.scatter(\n            [epochs[-1]], [cwca_test], color=\"red\", label=f\"Test ({cwca_test:.3f})\"\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CWCA\")\n    plt.title(\"CWCA Curves \u2013 SPR_BENCH\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_cwca_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CWCA plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------\n# 3) Confusion matrix heat-map\ntry:\n    if y_true.size and y_pred.size:\n        n_lbl = int(max(y_true.max(), y_pred.max()) + 1)\n        cm = np.zeros((n_lbl, n_lbl), int)\n        for t, p in zip(y_true, y_pred):\n            cm[t, p] += 1\n        plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.title(\n            \"Confusion Matrix \u2013 SPR_BENCH\\nLeft: Ground Truth (rows), Right: Predictions (cols)\"\n        )\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        for i in range(n_lbl):\n            for j in range(n_lbl):\n                plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n        plt.colorbar()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n        plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------\nif cwca_test is not None:\n    print(f\"Final Test CWCA: {cwca_test:.4f}\")\n",
    "plot_plan": "We will load the saved NumPy dictionary, extract the loss arrays, CWCA scores, predictions and ground-truth labels, then generate at most three plots: (1) training/validation loss curves, (2) training/validation CWCA curves together with a single red dot for the final test CWCA, and (3) a confusion-matrix heat-map of the test set.  Each plot is wrapped in a try-except block, saved with a descriptive name that contains the dataset and plot type, and the figure is always closed.  After plotting, we print the final test CWCA so the notebook logs an easy-to-see metric.  The code respects all the given plotting guidelines, only uses data present in experiment_data.npy, and stores everything under working_dir.",
    "plot_analyses": [
      {
        "analysis": "The t-SNE visualization of the embeddings from the development set without contrastive pretraining demonstrates that the embeddings are not well-clustered. There is no clear separation between different classes, indicating that the current embedding space lacks discriminative power for the SPR task. This suggests that the absence of contrastive pretraining may have resulted in suboptimal feature representations.",
        "plot_path": "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df0775e215054ec2a8865131b33b4ba6_proc_3078651/tsne_dev.png"
      },
      {
        "analysis": "The loss curves indicate that while the training loss decreases steadily over the epochs, the validation loss remains relatively flat and even shows an increasing trend towards the end. This suggests that the model is overfitting to the training data and is unable to generalize well to the validation set. The lack of validation loss improvement may also point to limitations in the current training strategy or model architecture.",
        "plot_path": "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df0775e215054ec2a8865131b33b4ba6_proc_3078651/SPR_BENCH_loss_curves.png"
      },
      {
        "analysis": "The CWCA curves show that the training performance improves consistently over the epochs, but the validation performance stagnates and even slightly decreases. The test performance, represented by the red dot, is relatively low at 0.511. This again highlights the model's inability to generalize effectively, which could be attributed to insufficient regularization or the lack of context-aware pretraining.",
        "plot_path": "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df0775e215054ec2a8865131b33b4ba6_proc_3078651/SPR_BENCH_cwca_curves.png"
      },
      {
        "analysis": "The confusion matrix reveals a significant number of misclassifications, particularly in one of the classes (lower right quadrant). This imbalance in prediction accuracy across classes suggests that the model struggles to handle certain symbolic patterns, possibly due to inadequate feature representation or an imbalanced dataset.",
        "plot_path": "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df0775e215054ec2a8865131b33b4ba6_proc_3078651/SPR_BENCH_confusion_matrix.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df0775e215054ec2a8865131b33b4ba6_proc_3078651/tsne_dev.png",
      "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df0775e215054ec2a8865131b33b4ba6_proc_3078651/SPR_BENCH_loss_curves.png",
      "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df0775e215054ec2a8865131b33b4ba6_proc_3078651/SPR_BENCH_cwca_curves.png",
      "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df0775e215054ec2a8865131b33b4ba6_proc_3078651/SPR_BENCH_confusion_matrix.png"
    ],
    "vlm_feedback_summary": "The provided plots indicate that the current model setup struggles with generalization and effective feature representation. The t-SNE visualization highlights weak class separation, the loss and CWCA curves suggest overfitting and limited validation performance, and the confusion matrix points to class-specific prediction issues. These findings emphasize the need for improved pretraining strategies, such as context-aware contrastive learning, and better regularization techniques.",
    "exp_results_dir": "experiment_results/experiment_df0775e215054ec2a8865131b33b4ba6_proc_3078651",
    "ablation_name": "NoContrastivePretraining",
    "exp_results_npy_files": [
      "experiment_results/experiment_df0775e215054ec2a8865131b33b4ba6_proc_3078651/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "The overall plan begins with a baseline model that tokenizes SPR sequences and uses a bi-directional LSTM to encode sequences during a contrastive pre-training stage. This involves optimizing an InfoNCE loss with stochastic augmentations to ensure paired views stay close while others repel, with a two-layer projection head used during this stage. A linear classifier is then attached for fine-tuning with cross-entropy loss. The evaluation process monitors different weighted accuracies, and t-SNE visualizations provide qualitative insights. The implementation is robust, self-contained, and efficient, accommodating scenarios with and without the SPR_BENCH dataset. The current plan introduces an ablation named BagOfTokensEncoder, which replaces the BiLSTM with a mean-pooling of token embeddings, maintaining other aspects of the training and evaluation process. This ablation is designed to assess the impact of the LSTM component, thereby providing insights into the model's reliance on sequential information. The integrated approach combines the establishment of a sophisticated baseline with ablation studies to elucidate the roles of individual components in the model.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "CWCA",
            "lower_is_better": false,
            "description": "Class-weighted classification accuracy",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.4897,
                "best_value": 0.5436
              }
            ]
          },
          {
            "metric_name": "loss",
            "lower_is_better": true,
            "description": "Cross-entropy loss",
            "data": [
              {
                "dataset_name": "SPR_BENCH",
                "final_value": 0.6949,
                "best_value": 0.685
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "# Bag-of-Tokens ablation of the SPR baseline -------------------------------\n# (self-contained single-file programme)\n\nimport os, random, math, pathlib, time, itertools\nimport numpy as np\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List, Dict\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n\n# --------------------------------------------------------------------------\n# mandatory working dir + gpu setup\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# --------------------------------------------------------------------------\n# SPR dataset (real or synthetic fallback)\ndef safe_load_spr():\n    try:\n        from SPR import load_spr_bench\n\n        DATA_PATH = pathlib.Path(\"SPR_BENCH\")\n        if DATA_PATH.exists():\n            return load_spr_bench(DATA_PATH)\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH, falling back to synthetic.\", e)\n\n    shapes, colors = list(\"ABCDEFG\"), list(\"123456\")\n\n    def random_token():\n        return random.choice(shapes) + random.choice(colors)\n\n    def random_seq():\n        return \" \".join(random_token() for _ in range(random.randint(4, 10)))\n\n    def label_fn(seq):\n        return 1 if sum(tok[0] in \"ABC\" for tok in seq.split()) % 2 == 0 else 0\n\n    data = {\"train\": [], \"dev\": [], \"test\": []}\n    for split, n in [(\"train\", 2000), (\"dev\", 400), (\"test\", 400)]:\n        for i in range(n):\n            seq = random_seq()\n            data[split].append({\"id\": i, \"sequence\": seq, \"label\": label_fn(seq)})\n    return data\n\n\ndset = safe_load_spr()\nprint({k: len(v) for k, v in dset.items()})\n\n\n# --------------------------------------------------------------------------\n# metrics\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef cwca(seqs, y_true, y_pred):\n    w = [(count_shape_variety(s) + count_color_variety(s)) / 2 for s in seqs]\n    correct = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(correct) / sum(w) if sum(w) > 0 else 0.0\n\n\n# --------------------------------------------------------------------------\n# vocab + tokenisation\nPAD, MASK, UNK = \"<PAD>\", \"<MASK>\", \"<UNK>\"\n\n\ndef build_vocab(sequences):\n    vocab = set(itertools.chain.from_iterable(s.split() for s in sequences))\n    vocab = [PAD, MASK, UNK] + sorted(vocab)\n    stoi = {tok: i for i, tok in enumerate(vocab)}\n    return vocab, stoi\n\n\nvocab, stoi = build_vocab([r[\"sequence\"] for r in dset[\"train\"]])\nitos = {i: s for s, i in stoi.items()}\n\n\ndef encode(seq: str) -> List[int]:\n    return [stoi.get(tok, stoi[UNK]) for tok in seq.split()]\n\n\n# --------------------------------------------------------------------------\n# datasets / dataloaders\nclass SPRDataset(Dataset):\n    def __init__(self, records, with_label=True):\n        self.records = records\n        self.with_label = with_label\n\n    def __len__(self):\n        return len(self.records)\n\n    def __getitem__(self, idx):\n        rec = self.records[idx]\n        out = {\"input_ids\": torch.tensor(encode(rec[\"sequence\"]), dtype=torch.long)}\n        if self.with_label:\n            out[\"label\"] = torch.tensor(rec[\"label\"], dtype=torch.long)\n        return out\n\n\ndef collate_classification(batch):\n    seqs = [b[\"input_ids\"] for b in batch]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    lengths = [len(s) for s in seqs]\n    max_len = max(lengths)\n    padded = torch.zeros(len(batch), max_len, dtype=torch.long)\n    for i, s in enumerate(seqs):\n        padded[i, : len(s)] = s\n    return {\n        \"input_ids\": padded.to(device),\n        \"label\": labels.to(device),\n        \"lengths\": torch.tensor(lengths).to(device),\n    }\n\n\n# contrastive augmentation\ndef augment(ids: List[int]) -> List[int]:\n    ids = ids.copy()\n    for i in range(len(ids)):\n        if random.random() < 0.15:\n            ids[i] = stoi[MASK]\n    for i in range(len(ids) - 1):\n        if random.random() < 0.1:\n            ids[i], ids[i + 1] = ids[i + 1], ids[i]\n    if len(ids) > 4 and random.random() < 0.3:\n        del ids[random.randint(0, len(ids) - 1)]\n    return ids\n\n\ndef collate_contrastive(batch):\n    base = [b[\"input_ids\"] for b in batch]\n    views = []\n    for ids in base:\n        views.append(torch.tensor(augment(ids.tolist()), dtype=torch.long))\n        views.append(torch.tensor(augment(ids.tolist()), dtype=torch.long))\n    lengths = [len(v) for v in views]\n    max_len = max(lengths)\n    padded = torch.zeros(len(views), max_len, dtype=torch.long)\n    for i, v in enumerate(views):\n        padded[i, : len(v)] = v\n    return {\"input_ids\": padded.to(device), \"lengths\": torch.tensor(lengths).to(device)}\n\n\nbatch_c = 128\ntrain_contrastive_loader = DataLoader(\n    SPRDataset(dset[\"train\"], with_label=False),\n    batch_size=batch_c // 2,\n    shuffle=True,\n    collate_fn=collate_contrastive,\n    drop_last=True,\n)\ntrain_loader = DataLoader(\n    SPRDataset(dset[\"train\"]),\n    batch_size=64,\n    shuffle=True,\n    collate_fn=collate_classification,\n)\ndev_loader = DataLoader(\n    SPRDataset(dset[\"dev\"]),\n    batch_size=64,\n    shuffle=False,\n    collate_fn=collate_classification,\n)\ntest_loader = DataLoader(\n    SPRDataset(dset[\"test\"]),\n    batch_size=64,\n    shuffle=False,\n    collate_fn=collate_classification,\n)\n\n\n# --------------------------------------------------------------------------\n# Bag-of-Tokens encoder (ablation)\nclass BagOfTokensEncoder(nn.Module):\n    def __init__(self, vocab_size, d_model=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=0)\n        self.linear = nn.Linear(d_model, d_model)  # optional projection\n\n    def forward(self, x, lengths):\n        emb = self.emb(x)  # (B,L,D)\n        mask = (x != 0).unsqueeze(-1)  # (B,L,1)\n        summed = (emb * mask).sum(1)  # (B,D)\n        mean = summed / ((mask.sum(1)) + 1e-6)\n        return self.linear(mean)  # (B,D)\n\n\n# projection head and full model\nclass ProjectionHead(nn.Module):\n    def __init__(self, dim, proj_dim=128):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(dim, dim), nn.ReLU(), nn.Linear(dim, proj_dim)\n        )\n\n    def forward(self, x):\n        return self.mlp(x)\n\n\nclass SPRModel(nn.Module):\n    def __init__(self, vocab_size, num_labels):\n        super().__init__()\n        self.encoder = BagOfTokensEncoder(vocab_size)\n        self.classifier = nn.Linear(128, num_labels)\n\n    def forward(self, x, lengths):\n        rep = self.encoder(x, lengths)\n        logits = self.classifier(rep)\n        return logits, rep\n\n\n# --------------------------------------------------------------------------\n# contrastive loss (NT-Xent as in SimCLR)\ndef nt_xent(z, temperature=0.5):\n    N = z.size(0) // 2\n    z = F.normalize(z, dim=1)\n    sim = torch.exp(torch.matmul(z, z.T) / temperature)\n    mask = ~torch.eye(2 * N, dtype=torch.bool, device=z.device)\n    sim = sim * mask\n    pos = torch.cat([torch.diag(sim, N), torch.diag(sim, -N)], 0)\n    denom = sim.sum(1)\n    loss = -torch.log(pos / denom)\n    return loss.mean()\n\n\n# --------------------------------------------------------------------------\n# experiment logging skeleton\nexperiment_data = {\n    \"BagOfTokensEncoder\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": [], \"test\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# --------------------------------------------------------------------------\n# build model & optimisers\nmodel = SPRModel(len(vocab), num_labels=len(set(r[\"label\"] for r in dset[\"train\"]))).to(\n    device\n)\nproj_head = ProjectionHead(128).to(device)\nopt_contrastive = torch.optim.Adam(\n    list(model.encoder.parameters()) + list(proj_head.parameters()), lr=1e-3\n)\n\n# --------------------------------------------------------------------------\n# 1) contrastive pre-training\nepochs_ct = 3\nfor epoch in range(1, epochs_ct + 1):\n    model.train()\n    proj_head.train()\n    losses = []\n    for batch in train_contrastive_loader:\n        reps = model.encoder(batch[\"input_ids\"], batch[\"lengths\"])\n        feats = proj_head(reps)\n        loss = nt_xent(feats)\n        opt_contrastive.zero_grad()\n        loss.backward()\n        opt_contrastive.step()\n        losses.append(loss.item())\n    print(f\"[Pretrain] Epoch {epoch}/{epochs_ct} loss={np.mean(losses):.4f}\")\n\n# --------------------------------------------------------------------------\n# 2) supervised fine-tuning\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n\n\ndef run_epoch(loader, train=True):\n    (model.train() if train else model.eval())\n    total_loss, preds, trues, seqs = 0.0, [], [], []\n    with torch.set_grad_enabled(train):\n        for batch in loader:\n            logits, rep = model(batch[\"input_ids\"], batch[\"lengths\"])\n            loss = criterion(logits, batch[\"label\"])\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            total_loss += loss.item() * batch[\"label\"].size(0)\n            p = logits.argmax(1).detach().cpu().numpy()\n            t = batch[\"label\"].detach().cpu().numpy()\n            preds.extend(p)\n            trues.extend(t)\n            seqs.extend(\n                [\n                    \" \".join(itos[idx.item()] for idx in row if idx.item() != 0)\n                    for row in batch[\"input_ids\"].cpu()\n                ]\n            )\n    cwca_val = cwca(seqs, trues, preds)\n    return total_loss / len(loader.dataset), cwca_val, preds, trues\n\n\nbest_val = 0\nclf_epochs = 5\nfor epoch in range(1, clf_epochs + 1):\n    train_loss, train_cwca, _, _ = run_epoch(train_loader, True)\n    val_loss, val_cwca, _, _ = run_epoch(dev_loader, False)\n    experiment_data[\"BagOfTokensEncoder\"][\"SPR_BENCH\"][\"losses\"][\"train\"].append(\n        train_loss\n    )\n    experiment_data[\"BagOfTokensEncoder\"][\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"BagOfTokensEncoder\"][\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n        train_cwca\n    )\n    experiment_data[\"BagOfTokensEncoder\"][\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n        val_cwca\n    )\n    print(\n        f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} val_CWCA={val_cwca:.4f}\"\n    )\n    if val_cwca > best_val:\n        best_val = val_cwca\n\n# --------------------------------------------------------------------------\n# 3) final test\ntest_loss, test_cwca, preds, trues = run_epoch(test_loader, False)\nprint(f\"Test CWCA = {test_cwca:.4f}\")\nexperiment_data[\"BagOfTokensEncoder\"][\"SPR_BENCH\"][\"metrics\"][\"test\"].append(test_cwca)\nexperiment_data[\"BagOfTokensEncoder\"][\"SPR_BENCH\"][\"predictions\"] = preds\nexperiment_data[\"BagOfTokensEncoder\"][\"SPR_BENCH\"][\"ground_truth\"] = trues\n\n# --------------------------------------------------------------------------\n# 4) t-SNE visualisation\nmodel.eval()\nembeddings, labels = [], []\nwith torch.no_grad():\n    for batch in dev_loader:\n        _, reps = model(batch[\"input_ids\"], batch[\"lengths\"])\n        embeddings.append(reps.cpu().numpy())\n        labels.extend(batch[\"label\"].cpu().numpy())\nembeddings = np.concatenate(embeddings, 0)\ntsne = TSNE(n_components=2, init=\"random\", perplexity=30, random_state=0).fit_transform(\n    embeddings\n)\nplt.figure(figsize=(6, 5))\nplt.scatter(tsne[:, 0], tsne[:, 1], c=labels, cmap=\"tab10\", s=10)\nplt.title(\"t-SNE of dev embeddings (Bag-of-Tokens)\")\nplt.savefig(os.path.join(working_dir, \"tsne_dev.png\"))\n\n# --------------------------------------------------------------------------\n# save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data and plot to ./working/\")\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\n\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# iterate over model/dataset combinations\nfor model_name, dsets in experiment_data.items():\n    for dset_name, content in dsets.items():\n        losses = content.get(\"losses\", {})\n        metrics = content.get(\"metrics\", {})\n        preds = content.get(\"predictions\", [])\n        gts = content.get(\"ground_truth\", [])\n\n        # 1) train/val loss curve -------------------------------------------------\n        try:\n            train_loss = losses.get(\"train\", [])\n            val_loss = losses.get(\"val\", [])\n            if train_loss and val_loss:\n                plt.figure()\n                epochs = range(1, len(train_loss) + 1)\n                plt.plot(epochs, train_loss, label=\"Train\")\n                plt.plot(epochs, val_loss, label=\"Validation\")\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(\"Cross-Entropy Loss\")\n                plt.title(f\"{dset_name} - {model_name} - Loss Curve\")\n                plt.legend()\n                fname = f\"{dset_name}_{model_name}_loss_curve.png\".replace(\" \", \"_\")\n                plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss curve: {e}\")\n            plt.close()\n\n        # 2) train/val CWCA curve -------------------------------------------------\n        try:\n            train_cwca = metrics.get(\"train\", [])\n            val_cwca = metrics.get(\"val\", [])\n            if train_cwca and val_cwca:\n                plt.figure()\n                epochs = range(1, len(train_cwca) + 1)\n                plt.plot(epochs, train_cwca, label=\"Train\")\n                plt.plot(epochs, val_cwca, label=\"Validation\")\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(\"CWCA\")\n                plt.title(f\"{dset_name} - {model_name} - CWCA Curve\")\n                plt.legend()\n                fname = f\"{dset_name}_{model_name}_cwca_curve.png\".replace(\" \", \"_\")\n                plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating CWCA curve: {e}\")\n            plt.close()\n\n        # 3) confusion matrix on test set ----------------------------------------\n        try:\n            if preds and gts:\n                cm = confusion_matrix(gts, preds)\n                plt.figure()\n                im = plt.imshow(cm, cmap=\"Blues\")\n                plt.colorbar(im, fraction=0.046, pad=0.04)\n                plt.xlabel(\"Predicted label\")\n                plt.ylabel(\"True label\")\n                plt.title(f\"{dset_name} - {model_name} - Confusion Matrix (Test Set)\")\n                for (i, j), v in np.ndenumerate(cm):\n                    plt.text(j, i, str(v), ha=\"center\", va=\"center\", color=\"black\")\n                fname = f\"{dset_name}_{model_name}_confusion_matrix.png\".replace(\n                    \" \", \"_\"\n                )\n                plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating confusion matrix: {e}\")\n            plt.close()\n\n        # print evaluation metric -------------------------------------------------\n        try:\n            test_cwca = metrics.get(\"test\", [None])[0]\n            print(f\"{model_name} on {dset_name} - Test CWCA: {test_cwca}\")\n        except Exception as e:\n            print(f\"Error printing test CWCA: {e}\")\n",
    "plot_plan": "The script will load the stored experiment_data.npy, iterate over the available model\u2013dataset pair(s), and, if data exist, generate up-to-five standard diagnostic plots: (1) train/val loss curve, (2) train/val CWCA curve, and (3) a test-set confusion matrix built from the recorded predictions vs. ground-truth labels. Each figure is created inside its own try-except block, titled clearly, saved to working_dir with descriptive names, and then closed to free resources. Any missing data silently skips the corresponding plot. Finally, the code prints the test CWCA so users can see the main evaluation metric in the notebook/console alongside the figures.",
    "plot_analyses": [
      {
        "analysis": "The t-SNE visualization of the development set embeddings indicates that the embeddings generated by the Bag-of-Tokens encoder do not form well-separated clusters. This suggests that the learned embeddings lack strong discriminative power for the symbolic sequences in the SPR task. The lack of clear clusters might indicate insufficient contextual awareness in the learned representations.",
        "plot_path": "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c078a069eb1b4509afe27acab2d633f8_proc_3078654/tsne_dev.png"
      },
      {
        "analysis": "The loss curve shows a decreasing trend for the training loss, indicating that the model is learning from the training data. However, the validation loss increases steadily after the first epoch, suggesting overfitting. The model appears to generalize poorly to the validation set, which could be due to insufficient regularization or ineffective data augmentation strategies.",
        "plot_path": "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c078a069eb1b4509afe27acab2d633f8_proc_3078654/SPR_BENCH_BagOfTokensEncoder_loss_curve.png"
      },
      {
        "analysis": "The CWCA curve reveals a concerning divergence between the training and validation performance. While the training CWCA improves consistently, the validation CWCA decreases after the second epoch. This further supports the observation of overfitting and indicates that the embeddings learned by the Bag-of-Tokens encoder are not generalizing well to unseen data.",
        "plot_path": "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c078a069eb1b4509afe27acab2d633f8_proc_3078654/SPR_BENCH_BagOfTokensEncoder_cwca_curve.png"
      },
      {
        "analysis": "The confusion matrix for the test set shows a significant number of misclassifications, particularly in the off-diagonal cells. This indicates that the model struggles to correctly classify symbolic sequences, further emphasizing the need for improvements in the encoder's ability to capture context-aware features.",
        "plot_path": "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c078a069eb1b4509afe27acab2d633f8_proc_3078654/SPR_BENCH_BagOfTokensEncoder_confusion_matrix.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c078a069eb1b4509afe27acab2d633f8_proc_3078654/tsne_dev.png",
      "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c078a069eb1b4509afe27acab2d633f8_proc_3078654/SPR_BENCH_BagOfTokensEncoder_loss_curve.png",
      "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c078a069eb1b4509afe27acab2d633f8_proc_3078654/SPR_BENCH_BagOfTokensEncoder_cwca_curve.png",
      "experiments/2025-08-16_00-46-17_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c078a069eb1b4509afe27acab2d633f8_proc_3078654/SPR_BENCH_BagOfTokensEncoder_confusion_matrix.png"
    ],
    "vlm_feedback_summary": "The results suggest that the Bag-of-Tokens encoder struggles to generalize effectively, as evidenced by poor clustering in the t-SNE plot, increasing validation loss, declining validation CWCA, and a high number of misclassifications in the confusion matrix. These issues highlight the need for better regularization, improved data augmentation, and potentially a more sophisticated encoder architecture to enhance performance on the SPR task.",
    "exp_results_dir": "experiment_results/experiment_c078a069eb1b4509afe27acab2d633f8_proc_3078654",
    "ablation_name": "BagOfTokensEncoder",
    "exp_results_npy_files": [
      "experiment_results/experiment_c078a069eb1b4509afe27acab2d633f8_proc_3078654/experiment_data.npy"
    ]
  }
]