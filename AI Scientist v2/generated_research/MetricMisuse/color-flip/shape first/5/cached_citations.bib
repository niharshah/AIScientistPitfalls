
% The SimCLR framework by Chen et al., 2020, is a foundational work on contrastive learning. It simplifies the self-supervised learning process by removing the need for specialized architectures or memory banks and introduces key elements such as data augmentation and a learnable nonlinear transformation. This work is relevant to the proposed context-aware contrastive learning framework in the study, as it serves as the basis for the design of the pre-training stage. It should be cited in the introduction and methodology sections where contrastive learning is discussed.
@article{chen2020asf,
 author = {Ting Chen and Simon Kornblith and Mohammad Norouzi and Geoffrey E. Hinton},
 booktitle = {International Conference on Machine Learning},
 journal = {ArXiv},
 title = {A Simple Framework for Contrastive Learning of Visual Representations},
 volume = {abs/2002.05709},
 year = {2020}
}

% The paper 'Neural Sequence-to-grid Module for Learning Symbolic Rules' discusses the challenges of out-of-distribution generalization in symbolic reasoning tasks and proposes a neural sequence-to-grid module to address these issues. It is relevant for highlighting the research gap in symbolic reasoning, particularly the limitations of current neural network methods, and motivating the use of contrastive learning in our work. This citation should be included in the introduction and related work sections of the paper to establish context and support the motivation for the proposed methodology.
@article{kim2021neuralsm,
 author = {Segwang Kim and Hyoungwook Nam and Joonyoung Kim and Kyomin Jung},
 booktitle = {AAAI Conference on Artificial Intelligence},
 journal = {ArXiv},
 title = {Neural Sequence-to-grid Module for Learning Symbolic Rules},
 volume = {abs/2101.04921},
 year = {2021}
}

% The paper 'Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models' discusses integrating denoising techniques and data augmentation into contrastive learning frameworks. It introduces a novel data augmentation approach specifically tailored for supervised contrastive learning. This work is relevant to the methodology of the proposed context-aware contrastive learning framework, particularly for the design and application of data augmentation and denoising strategies. It should be cited in the methodology section of the paper to support the proposed techniques.
@article{lopez-avila2024combiningda,
 author = {Alejo Lopez-Avila and Víctor Suárez-Paniagua},
 booktitle = {Conference on Empirical Methods in Natural Language Processing},
 journal = {ArXiv},
 title = {Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models},
 volume = {abs/2405.14437},
 year = {2024}
}

% The KANDY Benchmark introduces a framework for learning and reasoning tasks inspired by Kandinsky patterns, focusing on symbol compositionality and semi-supervised learning. It highlights the challenges and limitations of current neural and symbolic methods, making it relevant for discussing the SPR_BENCH dataset and the evaluation of symbolic reasoning models. This citation should be included in the related work and evaluation sections to contextualize the challenges addressed by the proposed contrastive learning framework.
@article{lorello2024thekb,
 author = {Luca Salvatore Lorello and Marco Lippi and S. Melacci},
 booktitle = {Machine-mediated learning},
 journal = {Mach. Learn.},
 pages = {161},
 title = {The KANDY Benchmark: Incremental Neuro-Symbolic Learning and Reasoning with Kandinsky Patterns},
 volume = {114},
 year = {2024}
}

% The paper 'C^2DA: Contrastive and Context-aware Domain Adaptive Semantic Segmentation' introduces a framework that integrates context-aware knowledge with contrastive learning to address domain adaptation challenges. It highlights the effectiveness of combining context-aware and contrastive learning techniques for robust feature representation, particularly in structured data domains. This citation is relevant to the methodology and results sections, where the importance of context-aware techniques in enhancing contrastive learning is discussed and their potential applications in symbolic reasoning tasks are explored.
@article{khan2024c2daca,
 author = {Md. Al-Masrur Khan and Zheng Chen and Lantao Liu},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {C^2DA: Contrastive and Context-aware Domain Adaptive Semantic Segmentation},
 volume = {abs/2410.19748},
 year = {2024}
}
