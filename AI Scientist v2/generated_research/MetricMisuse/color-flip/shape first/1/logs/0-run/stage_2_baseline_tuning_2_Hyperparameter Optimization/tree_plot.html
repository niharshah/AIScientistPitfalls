<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 4], [2, 8], [2, 10], [2, 11], [2, 9]], "layout": [[0.0, 0.0], [0.15384615384615385, 0.0], [0.38461538461538464, 0.0], [0.5384615384615384, 0.0], [0.0, 1.0], [0.6923076923076923, 0.0], [0.8461538461538461, 0.0], [1.0, 0.0], [0.15384615384615385, 1.0], [0.3076923076923077, 1.0], [0.46153846153846156, 1.0], [0.6153846153846154, 1.0]], "plan": ["Hyperparam tuning name: fine_tune_epochs. We keep the two-epoch contrastive pre-\ntraining unchanged, cache the resulting encoder weights, and then conduct four\nindependent fine-tuning runs that differ only in the number of epochs (3, 5, 10,\n20).  Each run trains the classifier from the same pre-trained weights, records\ntrain/validation loss plus SWA/CWA/SCHM every epoch, and employs an optional\nearly-stopping mechanism with patience = 3.  All curves, predictions and ground-\ntruth labels are stored in an `experiment_data` dictionary under the key\n`fine_tune_epochs`, saved to the mandatory file `experiment_data.npy`, and a\nloss-curve plot for every run is written to `./working/`.", "Hyperparam tuning name: learning_rate. We sweep a range of fine-tuning learning-\nrates (1e-3, 5e-4, 3e-4, 1e-4) while keeping the pre-training rate at 1e-3.\nFor each rate we (1) re-instantiate the encoder/classifier, (2) run two\ncontrastive pre-training epochs, (3) fine-tune three epochs, and (4) log losses\nand SPR metrics.   All results are stored under\nexperiment_data['learning_rate']['SPR_BENCH']['runs'] and finally written to\nworking/experiment_data.npy; a loss curve is also saved for every run.", "Hyperparam tuning name: pretrain_epochs. The solution repeats the original\npipeline for several values of pretrain_epochs (2, 4, 6, 8, 10).   For every\nsetting it re-initialises the encoder / classifier, runs contrastive pre-\ntraining for the chosen number of epochs, fine-tunes for three epochs, and\nstores all losses and metrics in the mandatory experiment_data dictionary\n(organised as\nexperiment_data['pretrain_epochs']['SPR_BENCH'][str(pretrain_epochs)] = \u2026).\nFinally it saves the dictionary to working/experiment_data.npy and produces a\nloss-curve PNG for each run.", "Hyperparam tuning name: batch_size. We loop over candidate batch sizes [32, 64,\n128, 256].   For each size we (1) build fresh DataLoaders that use this mini-\nbatch size for both the contrastive pre-training and supervised fine-tuning\nstages, (2) train a new encoder/classifier pair, (3) log per-epoch losses and\nmetrics, and (4) store everything in `experiment_data`.   After all runs we save\n`experiment_data.npy` and draw a loss-curve summary.", "The error arose because `datasets.load_dataset` cannot ingest in-memory Python\nobjects; in the synthetic fallback we passed `None` as a data-file, producing an\ninvalid URL string that triggered the `bytes` concatenation crash.   Replace\nthat call with `datasets.Dataset.from_dict`, which correctly builds a\nHuggingFace `Dataset` from a Python dictionary, and add the requested\nAugmentation Consistency Score (ACS) during validation.   The script below\nimplements these fixes, follows all GPU/CPU handling guidelines, logs/plots all\nmetrics, and stores them under `./working/experiment_data.npy`.", "Hyperparam tuning name: weight_decay (L2 regularization factor applied in Adam\noptimizer). We introduce a simple hyper-parameter sweep over Adam\u2019s\nweight_decay.   For every value in [0, 1e-5, 1e-4, 1e-3] we:   1. build fresh\nEncoder + Classifier models,   2. pre-train the encoder with contrastive loss\nusing that weight_decay,   3. fine-tune the classifier with the same\nweight_decay,   4. log all losses and metrics in a structured experiment_data\ndict under the key 'weight_decay' \u2192 str(decay).   Everything is saved to\nexperiment_data.npy, and a loss curve for every decay is stored in ./working/.\nThe rest of the pipeline (data, model, loss functions) remains unchanged, so any\nperformance difference stems from the regularization factor.", "Hyperparam tuning name: contrastive_temperature. We sweep six NT-Xent\ntemperatures (0.07, 0.1, 0.2, 0.5, 0.75, 1.0).   For every temperature we (1)\nbuild a fresh encoder/classifier, (2) pre-train with that temperature, (3) fine-\ntune and evaluate on the dev split, and (4) log all losses/metrics in\nexperiment_data['contrastive_temperature'][str(temp)].   After the sweep we save\nexperiment_data (and loss curves) under ./working/.", "Hyperparam tuning name: dropout_rate. We add an nn.Dropout layer inside the\nEncoder and run the whole \u201cpre-train \u2192 fine-tune\u201d pipeline four times with\ndropout rates {0.0, 0.1, 0.3, 0.5}.   For each rate a fresh model is built,\ntrained and evaluated; train/val losses plus weighted accuracies are stored in\nexperiment_data['dropout_tuning'][rate].   The same data loaders, loss functions\nand training routines are reused, only the encoder/classifier vary.   All\ncollected results are saved in \u2018working/experiment_data.npy\u2019; a loss curve for\nevery rate is also dumped for quick inspection.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, random, math, time, json, copy\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\nfrom datasets import load_dataset, DatasetDict\n\n# -------------------------------------------------\n# mandatory working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------\n# Device handling\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------------------------------------------\n# Helper ------------------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for s in [\"train\", \"dev\", \"test\"]:\n        d[s] = _load(f\"{s}.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# -------------------------------------------------\n# Dataset ---------------------------------------------------------------\ndata_root_candidates = [pathlib.Path(\"SPR_BENCH\"), pathlib.Path(\"./data/SPR_BENCH\")]\nspr_bench = None\nfor p in data_root_candidates:\n    if (p / \"train.csv\").exists():\n        spr_bench = load_spr_bench(p)\n        print(f\"Loaded data from {p}\")\n        break\nif spr_bench is None:\n    print(\"SPR_BENCH not found \u2013 generating synthetic toy data.\")\n\n    def synth(n):\n        seqs, labels = [], []\n        shapes, colors = \"ABCD\", \"1234\"\n        for _ in range(n):\n            L = random.randint(4, 9)\n            seqs.append(\n                \" \".join(\n                    random.choice(shapes) + random.choice(colors) for _ in range(L)\n                )\n            )\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    spr_bench = DatasetDict()\n    for split, n in [(\"train\", 600), (\"dev\", 150), (\"test\", 100)]:\n        spr_bench[split] = load_dataset(\n            \"json\", data_files={\"train\": None}, split=\"train\", data=synth(n)\n        )\n\n\ndef tokenize(seq):\n    return seq.strip().split()\n\n\n# Build vocabulary\nvocab = {\"<PAD>\": 0, \"<MASK>\": 1}\nfor split in spr_bench.values():\n    for seq in split[\"sequence\"]:\n        for tok in tokenize(seq):\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\nvocab_size, mask_id = len(vocab), vocab[\"<MASK>\"]\nprint(\"Vocabulary size =\", vocab_size)\n\n\n# -------------------------------------------------\n# PyTorch datasets -------------------------------------------------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def _augment(self, toks, p=0.15):\n        out = [t for t in toks if random.random() >= p]\n        if not out:\n            out.append(random.choice(toks))\n        return out\n\n    def __getitem__(self, idx):\n        toks = tokenize(self.seqs[idx])\n        return self._augment(toks), self._augment(toks)\n\n\nclass SPRClassifierDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs, self.labels = hf_ds[\"sequence\"], hf_ds[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return tokenize(self.seqs[idx]), self.labels[idx], self.seqs[idx]\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n\n    def encode(l_tok):\n        ids = [torch.tensor([vocab[t] for t in toks]) for toks in l_tok]\n        lens = torch.tensor([len(i) for i in ids])\n        ids = pad_sequence(ids, batch_first=True, padding_value=0)\n        return ids.to(device), lens.to(device)\n\n    ids1, len1 = encode(v1)\n    ids2, len2 = encode(v2)\n    return {\"ids1\": ids1, \"len1\": len1, \"ids2\": ids2, \"len2\": len2}\n\n\ndef collate_classifier(batch):\n    toks, labels, raw = zip(*batch)\n    ids = [torch.tensor([vocab[t] for t in t]) for t in toks]\n    lens = torch.tensor([len(i) for i in ids])\n    ids = pad_sequence(ids, batch_first=True, padding_value=0)\n    return {\n        \"ids\": ids.to(device),\n        \"len\": lens.to(device),\n        \"label\": torch.tensor(labels).to(device),\n        \"sequence\": raw,\n    }\n\n\npretrain_loader = DataLoader(\n    SPRContrastiveDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_contrastive,\n)\ntrain_loader = DataLoader(\n    SPRClassifierDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_classifier,\n)\ndev_loader = DataLoader(\n    SPRClassifierDataset(spr_bench[\"dev\"]),\n    batch_size=256,\n    shuffle=False,\n    collate_fn=collate_classifier,\n)\n\n\n# -------------------------------------------------\n# Model --------------------------------------------------------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, emb_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden, batch_first=True, bidirectional=True)\n        self.proj = nn.Linear(hidden * 2, hidden)\n\n    def forward(self, ids, lens):\n        x = self.emb(ids)\n        packed = pack_padded_sequence(\n            x, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[-2], h[-1]], 1)\n        return self.proj(h)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(encoder.proj.out_features, num_classes)\n\n    def forward(self, ids, lens):\n        return self.head(self.encoder(ids, lens))\n\n\n# -------------------------------------------------\n# Contrastive loss\ndef nt_xent_loss(z1, z2, temp=0.5):\n    z1, z2 = nn.functional.normalize(z1, dim=1), nn.functional.normalize(z2, dim=1)\n    N, z = z1.size(0), torch.cat([z1, z2], 0)\n    sim = torch.matmul(z, z.T) / temp\n    sim.fill_diagonal_(-9e15)\n    targets = torch.arange(N, 2 * N, device=z.device)\n    loss = (\n        -(sim[:N, N:].diag())\n        + torch.logsumexp(sim[:N], 1)\n        - (sim[N:, :N].diag())\n        + torch.logsumexp(sim[N:], 1)\n    ).mean() * 0.5\n    return loss\n\n\n# -------------------------------------------------\n# Experiment data dict --------------------------------------------------\nexperiment_data = {\"fine_tune_epochs\": {\"SPR_BENCH\": {\"runs\": {}}}}\n\n# -------------------------------------------------\n# Pre-training ----------------------------------------------------------\nencoder = Encoder(vocab_size).to(device)\noptimizer_pt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\npretrain_epochs = 2\nfor ep in range(1, pretrain_epochs + 1):\n    encoder.train()\n    total = 0.0\n    for batch in pretrain_loader:\n        optimizer_pt.zero_grad()\n        z1 = encoder(batch[\"ids1\"], batch[\"len1\"])\n        z2 = encoder(batch[\"ids2\"], batch[\"len2\"])\n        loss = nt_xent_loss(z1, z2)\n        loss.backward()\n        optimizer_pt.step()\n        total += loss.item() * batch[\"ids1\"].size(0)\n    print(f\"Pre-train epoch {ep}: loss={total/len(pretrain_loader.dataset):.4f}\")\n\nbase_encoder_state = copy.deepcopy(encoder.state_dict())  # snapshot for reuse\n\n# -------------------------------------------------\n# Fine-tuning hyper-parameter sweep -------------------------------------\nft_epoch_options = [3, 5, 10, 20]\ncriterion = nn.CrossEntropyLoss()\n\nfor ft_epochs in ft_epoch_options:\n    # Re-create encoder & classifier with identical pre-trained weights\n    enc = Encoder(vocab_size).to(device)\n    enc.load_state_dict(base_encoder_state)\n    clf = Classifier(enc, num_classes=len(set(spr_bench[\"train\"][\"label\"]))).to(device)\n    opt = torch.optim.Adam(clf.parameters(), lr=1e-3)\n    # storage for this run\n    run_key = str(ft_epochs)\n    experiment_data[\"fine_tune_epochs\"][\"SPR_BENCH\"][\"runs\"][run_key] = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"SCHM\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    best_val, patience, wait = float(\"inf\"), 3, 0\n    for ep in range(1, ft_epochs + 1):\n        # ---- training ----\n        clf.train()\n        running = 0.0\n        for batch in train_loader:\n            opt.zero_grad()\n            logits = clf(batch[\"ids\"], batch[\"len\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            opt.step()\n            running += loss.item() * batch[\"ids\"].size(0)\n        train_loss = running / len(train_loader.dataset)\n        # ---- validation ----\n        clf.eval()\n        vloss, preds, trues, seqs = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                logits = clf(batch[\"ids\"], batch[\"len\"])\n                loss = criterion(logits, batch[\"label\"])\n                vloss += loss.item() * batch[\"ids\"].size(0)\n                preds.extend(logits.argmax(1).cpu().tolist())\n                trues.extend(batch[\"label\"].cpu().tolist())\n                seqs.extend(batch[\"sequence\"])\n        val_loss = vloss / len(dev_loader.dataset)\n        swa = shape_weighted_accuracy(seqs, trues, preds)\n        cwa = color_weighted_accuracy(seqs, trues, preds)\n        schm = 2 * swa * cwa / (swa + cwa) if swa + cwa else 0.0\n        # log\n        ed = experiment_data[\"fine_tune_epochs\"][\"SPR_BENCH\"][\"runs\"][run_key]\n        ed[\"losses\"][\"train\"].append(train_loss)\n        ed[\"losses\"][\"val\"].append(val_loss)\n        ed[\"metrics\"][\"SWA\"].append(swa)\n        ed[\"metrics\"][\"CWA\"].append(cwa)\n        ed[\"metrics\"][\"SCHM\"].append(schm)\n        print(\n            f\"[{ft_epochs}ep-run] epoch {ep}: train={train_loss:.4f} val={val_loss:.4f} SWA={swa:.3f} CWA={cwa:.3f} SCHM={schm:.3f}\"\n        )\n        # early stopping\n        if val_loss < best_val - 1e-4:\n            best_val, wait = val_loss, 0\n            ed[\"predictions\"], ed[\"ground_truth\"] = preds.copy(), trues.copy()\n        else:\n            wait += 1\n            if wait >= patience:\n                print(f\"Early stopping triggered after epoch {ep}\")\n                break\n    # Plot loss curve for this run\n    plt.figure()\n    plt.plot(ed[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(ed[\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"Fine-tune loss (max {ft_epochs} epochs)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_ft{ft_epochs}.png\"))\n    plt.close()\n\n# -------------------------------------------------\n# Save experiment data ----------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data and plots to ./working/\")\n", "import os, pathlib, random, math, json, time\nimport numpy as np\nimport torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\nfrom datasets import load_dataset, DatasetDict\n\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# -------------------------------------------------\n# -------- SPR helpers ----------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for s in [\"train\", \"dev\", \"test\"]:\n        d[s] = _load(f\"{s}.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# -------------------------------------------------\n# --------- Load / synthesize data ----------------\ndata_root_candidates = [\n    pathlib.Path(\"SPR_BENCH\"),\n    pathlib.Path(\"./data/SPR_BENCH\"),\n    pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n]\nspr_bench = None\nfor p in data_root_candidates:\n    if (p / \"train.csv\").exists():\n        spr_bench = load_spr_bench(p)\n        print(\"Loaded dataset from\", p)\n        break\nif spr_bench is None:\n    print(\"SPR_BENCH not found, generating tiny synthetic data.\")\n\n    def synth(n):\n        seqs, labels = [], []\n        shapes, colors = \"ABCD\", \"1234\"\n        for _ in range(n):\n            L = random.randint(4, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(L)\n            )\n            seqs.append(seq)\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    spr_bench = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        spr_bench[split] = load_dataset(\n            \"json\", data_files={\"train\": None}, split=\"train\", data=synth(n)\n        )\n\n\n# -------------------------------------------------\n# --------- Vocabulary ----------------------------\ndef tokenize(seq):\n    return seq.strip().split()\n\n\nvocab = {\"<PAD>\": 0, \"<MASK>\": 1}\nfor split in spr_bench.values():\n    for seq in split[\"sequence\"]:\n        for tok in tokenize(seq):\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\nvocab_size, mask_id = len(vocab), vocab[\"<MASK>\"]\nprint(\"Vocab size =\", vocab_size)\n\n\n# -------------------------------------------------\n# --------- Datasets / loaders --------------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def _augment(self, toks, p=0.15):\n        out = [t for t in toks if random.random() >= p]\n        if not out:\n            out.append(random.choice(toks))\n        return out\n\n    def __getitem__(self, idx):\n        toks = tokenize(self.seqs[idx])\n        return self._augment(toks), self._augment(toks)\n\n\nclass SPRClassifierDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs, self.labels = hf_ds[\"sequence\"], hf_ds[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return tokenize(self.seqs[idx]), self.labels[idx], self.seqs[idx]\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n\n    def encode(list_tokens):\n        ids = [torch.tensor([vocab[t] for t in toks]) for toks in list_tokens]\n        lens = torch.tensor([len(i) for i in ids])\n        ids = pad_sequence(ids, batch_first=True, padding_value=0)\n        return ids.to(device), lens.to(device)\n\n    ids1, len1 = encode(v1)\n    ids2, len2 = encode(v2)\n    return {\"ids1\": ids1, \"len1\": len1, \"ids2\": ids2, \"len2\": len2}\n\n\ndef collate_classifier(batch):\n    toks, labels, raw = zip(*batch)\n    ids = [torch.tensor([vocab[t] for t in tk]) for tk in toks]\n    lens = torch.tensor([len(i) for i in ids])\n    ids = pad_sequence(ids, batch_first=True, padding_value=0)\n    return {\n        \"ids\": ids.to(device),\n        \"len\": lens.to(device),\n        \"label\": torch.tensor(labels).to(device),\n        \"sequence\": raw,\n    }\n\n\npretrain_loader = DataLoader(\n    SPRContrastiveDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_contrastive,\n)\ntrain_loader = DataLoader(\n    SPRClassifierDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_classifier,\n)\ndev_loader = DataLoader(\n    SPRClassifierDataset(spr_bench[\"dev\"]),\n    batch_size=256,\n    shuffle=False,\n    collate_fn=collate_classifier,\n)\n\n\n# -------------------------------------------------\n# --------- Models --------------------------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, emb_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden, batch_first=True, bidirectional=True)\n        self.proj = nn.Linear(hidden * 2, hidden)\n\n    def forward(self, ids, lens):\n        x = self.emb(ids)\n        packed = pack_padded_sequence(\n            x, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[-2], h[-1]], 1)\n        return self.proj(h)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(encoder.proj.out_features, num_classes)\n\n    def forward(self, ids, lens):\n        return self.head(self.encoder(ids, lens))\n\n\n# -------------------------------------------------\n# --------- Loss utilities ------------------------\ndef nt_xent_loss(z1, z2, temp=0.5):\n    z1, z2 = nn.functional.normalize(z1, 1), nn.functional.normalize(z2, 1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    sim = torch.matmul(z, z.T) / temp\n    sim.fill_diagonal_(-9e15)\n    pos = torch.cat([torch.arange(N, 2 * N), torch.arange(0, N)]).to(device)\n    loss = nn.functional.cross_entropy(sim, pos)\n    return loss\n\n\n# -------------------------------------------------\n# --------- Hyper-parameter sweep -----------------\nfinetune_lrs = [1e-3, 5e-4, 3e-4, 1e-4]  # values to try\nexperiment_data = {\"learning_rate\": {\"SPR_BENCH\": {\"runs\": []}}}\n\nfor lr_ft in finetune_lrs:\n    print(f\"\\n============= Fine-tune LR = {lr_ft:.1e} =============\")\n    random.seed(0)\n    np.random.seed(0)\n    torch.manual_seed(0)\n    encoder = Encoder(vocab_size).to(device)\n    clf_model = Classifier(\n        encoder, num_classes=len(set(spr_bench[\"train\"][\"label\"]))\n    ).to(device)\n\n    record = {\n        \"lr_ft\": lr_ft,\n        \"losses\": {\"pretrain\": [], \"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"SCHM\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    # ---- pre-training ----\n    optimizer_pt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n    for ep in range(1, 3):\n        encoder.train()\n        ep_loss = 0.0\n        for b in pretrain_loader:\n            optimizer_pt.zero_grad()\n            z1, z2 = encoder(b[\"ids1\"], b[\"len1\"]), encoder(b[\"ids2\"], b[\"len2\"])\n            loss = nt_xent_loss(z1, z2)\n            loss.backward()\n            optimizer_pt.step()\n            ep_loss += loss.item() * b[\"ids1\"].size(0)\n        ep_loss /= len(pretrain_loader.dataset)\n        record[\"losses\"][\"pretrain\"].append(ep_loss)\n        print(f\"  Pretrain  ep{ep}: loss={ep_loss:.4f}\")\n\n    # ---- fine-tuning ----\n    optimizer_ft = torch.optim.Adam(clf_model.parameters(), lr=lr_ft)\n    ce = nn.CrossEntropyLoss()\n    for ep in range(1, 4):\n        # train\n        clf_model.train()\n        run_loss = 0.0\n        for b in train_loader:\n            optimizer_ft.zero_grad()\n            logits = clf_model(b[\"ids\"], b[\"len\"])\n            loss = ce(logits, b[\"label\"])\n            loss.backward()\n            optimizer_ft.step()\n            run_loss += loss.item() * b[\"ids\"].size(0)\n        tr_loss = run_loss / len(train_loader.dataset)\n        record[\"losses\"][\"train\"].append(tr_loss)\n\n        # val\n        clf_model.eval()\n        v_loss = 0.0\n        all_p, all_t, all_s = [], [], []\n        with torch.no_grad():\n            for b in dev_loader:\n                logits = clf_model(b[\"ids\"], b[\"len\"])\n                loss = ce(logits, b[\"label\"])\n                v_loss += loss.item() * b[\"ids\"].size(0)\n                preds = logits.argmax(1).cpu().tolist()\n                all_p += preds\n                all_t += b[\"label\"].cpu().tolist()\n                all_s += b[\"sequence\"]\n        v_loss /= len(dev_loader.dataset)\n        record[\"losses\"][\"val\"].append(v_loss)\n\n        swa = shape_weighted_accuracy(all_s, all_t, all_p)\n        cwa = color_weighted_accuracy(all_s, all_t, all_p)\n        schm = 2 * swa * cwa / (swa + cwa) if (swa + cwa) else 0.0\n        record[\"metrics\"][\"SWA\"].append(swa)\n        record[\"metrics\"][\"CWA\"].append(cwa)\n        record[\"metrics\"][\"SCHM\"].append(schm)\n        if ep == 3:  # store predictions only once\n            record[\"predictions\"] = all_p\n            record[\"ground_truth\"] = all_t\n        print(\n            f\"  Finetune ep{ep}: train={tr_loss:.4f} val={v_loss:.4f} | SWA={swa:.3f} CWA={cwa:.3f} SCHM={schm:.3f}\"\n        )\n\n    # ---- plot ----\n    plt.figure()\n    plt.plot(record[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(record[\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"Loss (ft-lr={lr_ft:.1e})\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_lr_{lr_ft:.1e}.png\"))\n    plt.close()\n\n    experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"runs\"].append(record)\n\n# -------------------------------------------------\n# --------- save all experiment data --------------\nnp.save(\n    os.path.join(working_dir, \"experiment_data.npy\"), experiment_data, allow_pickle=True\n)\nprint(\"Saved logs & plots to\", working_dir)\n", "import os, pathlib, random, math, time, json, gc\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\nimport matplotlib.pyplot as plt\n\n# ------------------------- I/O -----------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------- Device --------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------------- Data loading -----------------------\nfrom datasets import load_dataset, DatasetDict\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for s in [\"train\", \"dev\", \"test\"]:\n        d[s] = _load(f\"{s}.csv\")\n    return d\n\n\ndata_root_candidates = [\n    pathlib.Path(\"SPR_BENCH\"),\n    pathlib.Path(\"./data/SPR_BENCH\"),\n    pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n]\nspr_bench = None\nfor p in data_root_candidates:\n    if (p / \"train.csv\").exists():\n        spr_bench = load_spr_bench(p)\n        print(f\"Loaded data from {p}\")\n        break\nif spr_bench is None:\n    print(\"SPR_BENCH not found, generating synthetic data.\")\n\n    def synth(n):\n        seqs, labels = [], []\n        shapes, colors = \"ABCD\", \"1234\"\n        for _ in range(n):\n            L = random.randint(4, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(L)\n            )\n            seqs.append(seq)\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    spr_bench = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        spr_bench[split] = load_dataset(\n            \"json\", data_files={\"train\": None}, split=\"train\", data=synth(n)\n        )\n\n\ndef tokenize(seq):\n    return seq.strip().split()\n\n\n# ---------------------- Vocabulary -------------------------\nvocab = {\"<PAD>\": 0, \"<MASK>\": 1}\nfor split in spr_bench.values():\n    for seq in split[\"sequence\"]:\n        for tok in tokenize(seq):\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\nvocab_size = len(vocab)\nmask_id = vocab[\"<MASK>\"]\nprint(\"Vocab size:\", vocab_size)\n\n\n# ---------------------- Metrics ----------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# --------------------- Datasets ----------------------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def _augment(self, toks, p=0.15):\n        out = [t for t in toks if random.random() >= p]\n        if not out:\n            out = [random.choice(toks)]\n        return out\n\n    def __getitem__(self, idx):\n        toks = tokenize(self.seqs[idx])\n        return self._augment(toks), self._augment(toks)\n\n\nclass SPRClassifierDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n        self.labels = hf_ds[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return tokenize(self.seqs[idx]), self.labels[idx], self.seqs[idx]\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n\n    def encode(tok_list):\n        ids = [\n            torch.tensor([vocab[t] for t in toks], dtype=torch.long)\n            for toks in tok_list\n        ]\n        lens = [len(i) for i in ids]\n        ids = pad_sequence(ids, batch_first=True, padding_value=0)\n        return ids.to(device), torch.tensor(lens, dtype=torch.long).to(device)\n\n    ids1, len1 = encode(v1)\n    ids2, len2 = encode(v2)\n    return {\"ids1\": ids1, \"len1\": len1, \"ids2\": ids2, \"len2\": len2}\n\n\ndef collate_classifier(batch):\n    toks, labels, raw_seq = zip(*batch)\n    ids = [torch.tensor([vocab[t] for t in t], dtype=torch.long) for t in toks]\n    lens = [len(i) for i in ids]\n    ids = pad_sequence(ids, batch_first=True, padding_value=0).to(device)\n    return {\n        \"ids\": ids,\n        \"len\": torch.tensor(lens, dtype=torch.long).to(device),\n        \"label\": torch.tensor(labels, dtype=torch.long).to(device),\n        \"sequence\": raw_seq,\n    }\n\n\n# ---------------------- Model ------------------------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab, emb_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(len(vocab), emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden, batch_first=True, bidirectional=True)\n        self.proj = nn.Linear(hidden * 2, hidden)\n\n    def forward(self, ids, lens):\n        x = self.emb(ids)\n        packed = pack_padded_sequence(\n            x, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[-2], h[-1]], dim=1)\n        return self.proj(h)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(encoder.proj.out_features, num_classes)\n\n    def forward(self, ids, lens):\n        return self.head(self.encoder(ids, lens))\n\n\n# ---------------- Contrastive loss -------------------------\ndef nt_xent_loss(z1, z2, temp=0.5):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2], dim=0)\n    sim = torch.matmul(z, z.T) / temp\n    mask = torch.eye(2 * N, dtype=torch.bool, device=z.device)\n    sim.masked_fill_(mask, -9e15)\n    targets = torch.arange(N, 2 * N, device=z.device)\n    logits_12 = sim[:N, N:]\n    logits_21 = sim[N:, :N]\n    denom_12 = torch.logsumexp(sim[:N], dim=1)\n    denom_21 = torch.logsumexp(sim[N:], dim=1)\n    loss = (-logits_12.diag() + denom_12 + -logits_21.diag() + denom_21).mean() * 0.5\n    return loss\n\n\n# ---------------- Experiment container ---------------------\nexperiment_data = {\"pretrain_epochs\": {\"SPR_BENCH\": {}}}\n\n# ------------- Hyperparameter values to try ----------------\nepoch_settings = [2, 4, 6, 8, 10]\n\nfor pretrain_epochs in epoch_settings:\n    print(f\"\\n=== Running experiment with pretrain_epochs={pretrain_epochs} ===\")\n    run_dict = {\n        \"losses\": {\"pretrain\": [], \"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"SCHM\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    # Dataloaders (fresh shuffle each run)\n    pretrain_loader = DataLoader(\n        SPRContrastiveDataset(spr_bench[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_contrastive,\n    )\n    train_loader = DataLoader(\n        SPRClassifierDataset(spr_bench[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_classifier,\n    )\n    dev_loader = DataLoader(\n        SPRClassifierDataset(spr_bench[\"dev\"]),\n        batch_size=256,\n        shuffle=False,\n        collate_fn=collate_classifier,\n    )\n\n    # Model instantiation\n    encoder = Encoder(vocab).to(device)\n    clf_model = Classifier(\n        encoder, num_classes=len(set(spr_bench[\"train\"][\"label\"]))\n    ).to(device)\n\n    # -------- Contrastive pre-training ----------\n    optimizer_pt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n    for ep in range(1, pretrain_epochs + 1):\n        encoder.train()\n        epoch_loss = 0.0\n        for batch in pretrain_loader:\n            optimizer_pt.zero_grad()\n            z1 = encoder(batch[\"ids1\"], batch[\"len1\"])\n            z2 = encoder(batch[\"ids2\"], batch[\"len2\"])\n            loss = nt_xent_loss(z1, z2)\n            loss.backward()\n            optimizer_pt.step()\n            epoch_loss += loss.item() * batch[\"ids1\"].size(0)\n        epoch_loss /= len(pretrain_loader.dataset)\n        run_dict[\"losses\"][\"pretrain\"].append(epoch_loss)\n        print(f\"  Pretrain epoch {ep}/{pretrain_epochs} loss={epoch_loss:.4f}\")\n\n    # --------------- Fine-tuning ----------------\n    optimizer_ft = torch.optim.Adam(clf_model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n    ft_epochs = 3\n    for ep in range(1, ft_epochs + 1):\n        # train\n        clf_model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            optimizer_ft.zero_grad()\n            logits = clf_model(batch[\"ids\"], batch[\"len\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer_ft.step()\n            running_loss += loss.item() * batch[\"ids\"].size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        run_dict[\"losses\"][\"train\"].append(train_loss)\n        # evaluate\n        clf_model.eval()\n        val_loss = 0.0\n        all_pred = []\n        all_true = []\n        all_seq = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                logits = clf_model(batch[\"ids\"], batch[\"len\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss += loss.item() * batch[\"ids\"].size(0)\n                preds = logits.argmax(1).cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(batch[\"label\"].cpu().tolist())\n                all_seq.extend(batch[\"sequence\"])\n        val_loss /= len(dev_loader.dataset)\n        run_dict[\"losses\"][\"val\"].append(val_loss)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        schm = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        run_dict[\"metrics\"][\"SWA\"].append(swa)\n        run_dict[\"metrics\"][\"CWA\"].append(cwa)\n        run_dict[\"metrics\"][\"SCHM\"].append(schm)\n        print(\n            f\"  FT epoch {ep}/{ft_epochs} train_loss={train_loss:.4f} val_loss={val_loss:.4f} | SWA={swa:.3f} CWA={cwa:.3f} SCHM={schm:.3f}\"\n        )\n\n    # store final preds/gt from last epoch\n    run_dict[\"predictions\"] = all_pred\n    run_dict[\"ground_truth\"] = all_true\n    experiment_data[\"pretrain_epochs\"][\"SPR_BENCH\"][str(pretrain_epochs)] = run_dict\n\n    # plot loss curves for this run\n    plt.figure()\n    plt.plot(run_dict[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(run_dict[\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"FT Loss (pretrain_epochs={pretrain_epochs})\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_ep{pretrain_epochs}.png\"))\n    plt.close()\n\n    # free memory\n    del encoder, clf_model, optimizer_pt, optimizer_ft\n    torch.cuda.empty_cache()\n    gc.collect()\n\n# --------------- Save experiment data ----------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment data and plots to ./working/\")\n", "import os, pathlib, random, math, time, json\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\nfrom datasets import load_dataset, DatasetDict\n\n# -------------------- house-keeping --------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# -------------------- data -----------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):  # helper to load csv split\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    out = DatasetDict()\n    for s in [\"train\", \"dev\", \"test\"]:\n        out[s] = _load(f\"{s}.csv\")\n    return out\n\n\ndata_root_candidates = [pathlib.Path(\"SPR_BENCH\"), pathlib.Path(\"./data/SPR_BENCH\")]\nspr_bench = None\nfor p in data_root_candidates:\n    if (p / \"train.csv\").exists():\n        spr_bench = load_spr_bench(p)\n        print(f\"Loaded data from {p}\")\n        break\nif spr_bench is None:  # small synthetic fallback\n    print(\"SPR_BENCH not found, generating synthetic data.\")\n\n    def synth(n):\n        seqs, labels = [], []\n        shapes, colors = \"ABCD\", \"1234\"\n        for _ in range(n):\n            L = random.randint(4, 9)\n            seqs.append(\n                \" \".join(\n                    random.choice(shapes) + random.choice(colors) for _ in range(L)\n                )\n            )\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    spr_bench = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        spr_bench[split] = load_dataset(\n            \"json\", data_files={\"train\": None}, split=\"train\", data=synth(n)\n        )\n\n\n# -------------------- misc helpers ---------------------\ndef tokenize(seq):\n    return seq.strip().split()\n\n\nvocab = {\"<PAD>\": 0, \"<MASK>\": 1}\nfor split in spr_bench.values():\n    for seq in split[\"sequence\"]:\n        for tok in tokenize(seq):\n            vocab.setdefault(tok, len(vocab))\nmask_id, vocab_size = vocab[\"<MASK>\"], len(vocab)\nprint(\"Vocab size =\", vocab_size)\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split()))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wi for wi, yt, yp in zip(w, y_t, y_p) if yt == yp) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wi for wi, yt, yp in zip(w, y_t, y_p) if yt == yp) / max(sum(w), 1)\n\n\n# -------------------- Dataset classes ------------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def _augment(self, toks, p=0.15):\n        out = [t for t in toks if random.random() >= p]\n        return out or [random.choice(toks)]\n\n    def __getitem__(self, idx):\n        toks = tokenize(self.seqs[idx])\n        return self._augment(toks), self._augment(toks)\n\n\nclass SPRClassifierDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs, self.labels = hf_ds[\"sequence\"], hf_ds[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return tokenize(self.seqs[idx]), self.labels[idx], self.seqs[idx]\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n\n    def encode(lst):\n        ids = [torch.tensor([vocab[t] for t in toks]) for toks in lst]\n        lens = [len(i) for i in ids]\n        return pad_sequence(ids, batch_first=True), torch.tensor(lens)\n\n    ids1, len1 = encode(v1)\n    ids2, len2 = encode(v2)\n    return {\n        \"ids1\": ids1.to(device),\n        \"len1\": len1.to(device),\n        \"ids2\": ids2.to(device),\n        \"len2\": len2.to(device),\n    }\n\n\ndef collate_classifier(batch):\n    toks, labels, raw = zip(*batch)\n    ids = [torch.tensor([vocab[t] for t in t]) for t in toks]\n    lens = [len(i) for i in ids]\n    return {\n        \"ids\": pad_sequence(ids, batch_first=True).to(device),\n        \"len\": torch.tensor(lens).to(device),\n        \"label\": torch.tensor(labels).to(device),\n        \"sequence\": raw,\n    }\n\n\n# -------------------- Model ----------------------------\nclass Encoder(nn.Module):\n    def __init__(self, emb=64, hid=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb, padding_idx=0)\n        self.gru = nn.GRU(emb, hid, batch_first=True, bidirectional=True)\n        self.proj = nn.Linear(hid * 2, hid)\n\n    def forward(self, ids, lens):\n        x = self.emb(ids)\n        packed = pack_padded_sequence(\n            x, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[-2], h[-1]], 1)\n        return self.proj(h)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, enc, num_cls):\n        super().__init__()\n        self.enc = enc\n        self.head = nn.Linear(enc.proj.out_features, num_cls)\n\n    def forward(self, ids, lens):\n        return self.head(self.enc(ids, lens))\n\n\n# -------------------- Contrastive loss -----------------\ndef nt_xent_loss(z1, z2, temp=0.5):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    sim = torch.matmul(z, z.T) / temp\n    mask = torch.eye(2 * N, device=z.device, dtype=torch.bool)\n    sim.masked_fill_(mask, -9e15)\n    pos = torch.arange(N, device=z.device)\n    loss = (\n        -(sim[:N, N + pos].diag() + sim[N:, pos].diag()).mean() / 2\n        + (torch.logsumexp(sim[:N], 1).mean() + torch.logsumexp(sim[N:], 1).mean()) / 2\n    )\n    return loss\n\n\n# -------------------- experiment container --------------\nexperiment_data = {\"batch_size\": {}}\n\n# -------------------- training loop --------------------\nbatch_sizes = [32, 64, 128, 256]\npretrain_epochs, finetune_epochs = 2, 3\nnum_classes = len(set(spr_bench[\"train\"][\"label\"]))\n\nfor bs in batch_sizes:\n    tag = f\"bs_{bs}\"\n    print(f\"\\n===== Running experiment {tag} =====\")\n    # dataloaders\n    pretrain_loader = DataLoader(\n        SPRContrastiveDataset(spr_bench[\"train\"]),\n        batch_size=bs,\n        shuffle=True,\n        collate_fn=collate_contrastive,\n    )\n    train_loader = DataLoader(\n        SPRClassifierDataset(spr_bench[\"train\"]),\n        batch_size=bs,\n        shuffle=True,\n        collate_fn=collate_classifier,\n    )\n    dev_loader = DataLoader(\n        SPRClassifierDataset(spr_bench[\"dev\"]),\n        batch_size=512,\n        shuffle=False,\n        collate_fn=collate_classifier,\n    )\n    # model fresh\n    encoder = Encoder().to(device)\n    clf = Classifier(encoder, num_classes).to(device)\n    # log dict\n    experiment_data[\"batch_size\"][tag] = {\n        \"losses\": {\"pretrain\": [], \"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"SCHM\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    # -------- contrastive pretrain ----------\n    opt_pt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n    for ep in range(1, pretrain_epochs + 1):\n        encoder.train()\n        epoch_loss = 0.0\n        for batch in pretrain_loader:\n            opt_pt.zero_grad()\n            z1 = encoder(batch[\"ids1\"], batch[\"len1\"])\n            z2 = encoder(batch[\"ids2\"], batch[\"len2\"])\n            loss = nt_xent_loss(z1, z2)\n            loss.backward()\n            opt_pt.step()\n            epoch_loss += loss.item() * batch[\"ids1\"].size(0)\n        epoch_loss /= len(pretrain_loader.dataset)\n        experiment_data[\"batch_size\"][tag][\"losses\"][\"pretrain\"].append(epoch_loss)\n        print(f\"{tag} Pretrain Ep{ep}: loss={epoch_loss:.4f}\")\n    # -------- supervised fine-tune ----------\n    opt_ft = torch.optim.Adam(clf.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n    for ep in range(1, finetune_epochs + 1):\n        clf.train()\n        run_loss = 0.0\n        for batch in train_loader:\n            opt_ft.zero_grad()\n            logits = clf(batch[\"ids\"], batch[\"len\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            opt_ft.step()\n            run_loss += loss.item() * batch[\"ids\"].size(0)\n        train_loss = run_loss / len(train_loader.dataset)\n        experiment_data[\"batch_size\"][tag][\"losses\"][\"train\"].append(train_loss)\n        # ---- evaluation\n        clf.eval()\n        val_loss, all_pred, all_true, all_seq = 0.0, [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                logits = clf(batch[\"ids\"], batch[\"len\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss += loss.item() * batch[\"ids\"].size(0)\n                preds = logits.argmax(1).cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(batch[\"label\"].cpu().tolist())\n                all_seq.extend(batch[\"sequence\"])\n        val_loss /= len(dev_loader.dataset)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        schm = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        # logging\n        ed = experiment_data[\"batch_size\"][tag]\n        ed[\"losses\"][\"val\"].append(val_loss)\n        ed[\"metrics\"][\"SWA\"].append(swa)\n        ed[\"metrics\"][\"CWA\"].append(cwa)\n        ed[\"metrics\"][\"SCHM\"].append(schm)\n        ed[\"predictions\"].append(all_pred)\n        ed[\"ground_truth\"].append(all_true)\n        print(\n            f\"{tag} Ep{ep}: train={train_loss:.4f} val={val_loss:.4f} \"\n            f\"SWA={swa:.3f} CWA={cwa:.3f} SCHM={schm:.3f}\"\n        )\n\n# -------------------- save & plot ----------------------\nnp.save(\n    os.path.join(working_dir, \"experiment_data.npy\"), experiment_data, allow_pickle=True\n)\nprint(\"Saved experiment data to\", working_dir)\n\nplt.figure()\nfor tag in experiment_data[\"batch_size\"]:\n    plt.plot(experiment_data[\"batch_size\"][tag][\"losses\"][\"val\"], label=f\"{tag}-val\")\nplt.title(\"Validation loss across batch sizes\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\nprint(\"Plot saved.\")\n", "import os, pathlib, random, time, copy, math, json, itertools\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict, Dataset as HFDataset\n\n# -------------------------------------------------\n# mandatory working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------\n# Device handling\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------------------------------------------\n# Helper ------------------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for sp in [\"train\", \"dev\", \"test\"]:\n        d[sp] = _load(f\"{sp}.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# -------------------------------------------------\n# Dataset ---------------------------------------------------------------\ndef find_or_create_dataset() -> DatasetDict:\n    data_root_candidates = [pathlib.Path(\"SPR_BENCH\"), pathlib.Path(\"./data/SPR_BENCH\")]\n    for p in data_root_candidates:\n        if (p / \"train.csv\").exists():\n            print(f\"Loaded SPR_BENCH from {p}\")\n            return load_spr_bench(p)\n\n    print(\"SPR_BENCH not found \u2013 generating synthetic toy data.\")\n    shapes, colors = \"ABCD\", \"1234\"\n\n    def synth(n: int):\n        seqs, labels = [], []\n        for idx in range(n):\n            L = random.randint(4, 9)\n            seqs.append(\n                \" \".join(\n                    random.choice(shapes) + random.choice(colors) for _ in range(L)\n                )\n            )\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    ds_dict = DatasetDict()\n    for split, n in [(\"train\", 600), (\"dev\", 150), (\"test\", 100)]:\n        ds_dict[split] = HFDataset.from_dict(synth(n))\n    return ds_dict\n\n\nspr_bench = find_or_create_dataset()\n\n\ndef tokenize(seq: str):\n    return seq.strip().split()\n\n\n# Build vocabulary\nvocab = {\"<PAD>\": 0}\nfor split in spr_bench.values():\n    for seq in split[\"sequence\"]:\n        for tok in tokenize(seq):\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\nvocab_size = len(vocab)\npad_id = vocab[\"<PAD>\"]\nprint(f\"Vocabulary size = {vocab_size}\")\n\n\n# -------------------------------------------------\n# PyTorch datasets -------------------------------------------------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n\n    @staticmethod\n    def augment(tokens, p=0.15):\n        kept = [t for t in tokens if random.random() >= p]\n        if not kept:\n            kept.append(random.choice(tokens))\n        return kept\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        toks = tokenize(self.seqs[idx])\n        return self.augment(toks), self.augment(toks)\n\n\nclass SPRClassifierDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n        self.labels = hf_ds[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return tokenize(self.seqs[idx]), self.labels[idx], self.seqs[idx]\n\n\ndef encode_batch(token_lists):\n    idx_seqs = [\n        torch.tensor([vocab[t] for t in toks], dtype=torch.long) for toks in token_lists\n    ]\n    lengths = torch.tensor([len(s) for s in idx_seqs], dtype=torch.long)\n    padded = pad_sequence(idx_seqs, batch_first=True, padding_value=pad_id)\n    return padded.to(device), lengths.to(device)\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n    ids1, len1 = encode_batch(v1)\n    ids2, len2 = encode_batch(v2)\n    return {\"ids1\": ids1, \"len1\": len1, \"ids2\": ids2, \"len2\": len2}\n\n\ndef collate_classifier(batch):\n    toks, labels, raw = zip(*batch)\n    ids, lens = encode_batch(toks)\n    return {\n        \"ids\": ids,\n        \"len\": lens,\n        \"label\": torch.tensor(labels, device=device),\n        \"sequence\": raw,\n    }\n\n\npretrain_loader = DataLoader(\n    SPRContrastiveDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_contrastive,\n)\ntrain_loader = DataLoader(\n    SPRClassifierDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_classifier,\n)\ndev_loader = DataLoader(\n    SPRClassifierDataset(spr_bench[\"dev\"]),\n    batch_size=256,\n    shuffle=False,\n    collate_fn=collate_classifier,\n)\n\n\n# -------------------------------------------------\n# Model --------------------------------------------------------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, emb_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n        self.gru = nn.GRU(emb_dim, hidden, batch_first=True, bidirectional=True)\n        self.proj = nn.Linear(hidden * 2, hidden)\n\n    def forward(self, ids, lens):\n        emb = self.emb(ids)\n        packed = pack_padded_sequence(\n            emb, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[-2], h[-1]], dim=1)\n        return self.proj(h)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder: Encoder, num_classes: int):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(encoder.proj.out_features, num_classes)\n\n    def forward(self, ids, lens):\n        return self.head(self.encoder(ids, lens))\n\n\n# -------------------------------------------------\n# Contrastive loss (NT_Xent)\ndef nt_xent_loss(z1, z2, temp=0.5):\n    z1, z2 = nn.functional.normalize(z1, dim=1), nn.functional.normalize(z2, dim=1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2], dim=0)\n    sim = torch.matmul(z, z.T) / temp\n    sim.fill_diagonal_(-9e15)\n    targets = torch.arange(N, 2 * N, device=device)\n    pos_sim = torch.cat([sim[:N, N:].diag(), sim[N:, :N].diag()])\n    loss = -pos_sim + torch.logsumexp(sim, dim=1)\n    return loss.mean()\n\n\n# -------------------------------------------------\n# Experiment tracking dict ------------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"ACS\": [], \"SCHM\": []},\n        \"epochs\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n}\n\n# -------------------------------------------------\n# Pre-training ----------------------------------------------------------\nencoder = Encoder(vocab_size).to(device)\noptim_pt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\npre_epochs = 2\nfor ep in range(1, pre_epochs + 1):\n    encoder.train()\n    running = 0.0\n    for batch in pretrain_loader:\n        optim_pt.zero_grad()\n        z1 = encoder(batch[\"ids1\"], batch[\"len1\"])\n        z2 = encoder(batch[\"ids2\"], batch[\"len2\"])\n        loss = nt_xent_loss(z1, z2)\n        loss.backward()\n        optim_pt.step()\n        running += loss.item() * batch[\"ids1\"].size(0)\n    print(\n        f\"Pre-train epoch {ep}/{pre_epochs}: loss={running/len(pretrain_loader.dataset):.4f}\"\n    )\n\nbase_state = copy.deepcopy(encoder.state_dict())\n\n# -------------------------------------------------\n# Fine-tuning -----------------------------------------------------------\nnum_classes = len(set(spr_bench[\"train\"][\"label\"]))\ncriterion = nn.CrossEntropyLoss()\nepochs = 20\npatience, wait, best_val = 3, 0, float(\"inf\")\n\nencoder = Encoder(vocab_size).to(device)\nencoder.load_state_dict(base_state)\nclf = Classifier(encoder, num_classes=num_classes).to(device)\noptim_ft = torch.optim.Adam(clf.parameters(), lr=0.003)  # tuned lr\n\n\ndef compute_acs(model, sequences, K=3):\n    model.eval()\n    consistent = 0\n    total = len(sequences)\n    with torch.no_grad():\n        for seq in sequences:\n            toks = tokenize(seq)\n            ids, lens = encode_batch([toks])\n            base_pred = model(ids, lens).argmax(1)\n            ok = True\n            for _ in range(K):\n                aug = SPRContrastiveDataset.augment(toks)\n                ids_a, lens_a = encode_batch([aug])\n                if model(ids_a, lens_a).argmax(1) != base_pred:\n                    ok = False\n                    break\n            consistent += int(ok)\n    return consistent / total if total else 0.0\n\n\nfor ep in range(1, epochs + 1):\n    clf.train()\n    train_loss = 0.0\n    for batch in train_loader:\n        optim_ft.zero_grad()\n        logits = clf(batch[\"ids\"], batch[\"len\"])\n        loss = criterion(logits, batch[\"label\"])\n        loss.backward()\n        optim_ft.step()\n        train_loss += loss.item() * batch[\"ids\"].size(0)\n    train_loss /= len(train_loader.dataset)\n\n    # -------- validation ---------\n    clf.eval()\n    val_loss, preds, trues, seqs = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in dev_loader:\n            logits = clf(batch[\"ids\"], batch[\"len\"])\n            loss = criterion(logits, batch[\"label\"])\n            val_loss += loss.item() * batch[\"ids\"].size(0)\n            preds.extend(logits.argmax(1).cpu().tolist())\n            trues.extend(batch[\"label\"].cpu().tolist())\n            seqs.extend(batch[\"sequence\"])\n    val_loss /= len(dev_loader.dataset)\n\n    swa = shape_weighted_accuracy(seqs, trues, preds)\n    cwa = color_weighted_accuracy(seqs, trues, preds)\n    acs = compute_acs(clf, seqs, K=3)\n    schm = 2 * swa * cwa / (swa + cwa) if swa + cwa else 0.0\n\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"SWA\"].append(swa)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"CWA\"].append(cwa)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"ACS\"].append(acs)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"SCHM\"].append(schm)\n    experiment_data[\"SPR_BENCH\"][\"epochs\"].append(ep)\n\n    print(\n        f\"Epoch {ep}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n        f\"SWA={swa:.3f} CWA={cwa:.3f} ACS={acs:.3f} SCHM={schm:.3f}\"\n    )\n\n    # early stopping\n    if val_loss < best_val - 1e-4:\n        best_val, wait = val_loss, 0\n        experiment_data[\"SPR_BENCH\"][\"predictions\"] = preds.copy()\n        experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = trues.copy()\n        torch.save(clf.state_dict(), os.path.join(working_dir, \"best_model.pt\"))\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n# -------------------------------------------------\n# Plot & Save ----------------------------------------------------------\nplt.figure()\nplt.plot(experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"], label=\"train\")\nplt.plot(experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"], label=\"val\")\nplt.title(\"Fine-tune Loss Curve\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"loss_curve.png\"))\nplt.close()\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Training complete. Artifacts saved to ./working/\")\n", "import os, pathlib, random, math, time, json\nimport numpy as np\nimport torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\nfrom datasets import load_dataset, DatasetDict\n\n# -------------------------------------------------\n# mandatory working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------\n# Device handling\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------------------------------------------\n# -------- SPR helper functions -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for s in [\"train\", \"dev\", \"test\"]:\n        d[s] = _load(f\"{s}.csv\")\n    return d\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# -------------------------------------------------\n# -------- Dataset preparation --------------------\ndata_root_candidates = [\n    pathlib.Path(\"SPR_BENCH\"),\n    pathlib.Path(\"./data/SPR_BENCH\"),\n    pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n]\nspr_bench = None\nfor p in data_root_candidates:\n    if (p / \"train.csv\").exists():\n        spr_bench = load_spr_bench(p)\n        print(f\"Loaded data from {p}\")\n        break\nif spr_bench is None:\n    print(\"SPR_BENCH not found, generating tiny synthetic data.\")\n\n    def synth(n):\n        seqs, labels = [], []\n        shapes, colors = \"ABCD\", \"1234\"\n        for _ in range(n):\n            L = random.randint(4, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(L)\n            )\n            seqs.append(seq)\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    spr_bench = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        spr_bench[split] = load_dataset(\n            \"json\", data_files={\"train\": None}, split=\"train\", data=synth(n)\n        )\n\n\n# Build vocabulary\ndef tokenize(seq):\n    return seq.strip().split()\n\n\nvocab = {\"<PAD>\": 0, \"<MASK>\": 1}\nfor split in spr_bench.values():\n    for seq in split[\"sequence\"]:\n        for tok in tokenize(seq):\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\nvocab_size, mask_id = len(vocab), vocab[\"<MASK>\"]\nprint(f\"Vocab size = {vocab_size}\")\n\n\n# -------------------------------------------------\n# Torch datasets\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, ds):\n        self.seqs = ds[\"sequence\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def _augment(self, toks, p=0.15):\n        out = [t for t in toks if random.random() >= p]\n        if not out:\n            out = [random.choice(toks)]\n        return out\n\n    def __getitem__(self, idx):\n        toks = tokenize(self.seqs[idx])\n        return self._augment(toks), self._augment(toks)\n\n\nclass SPRClassifierDataset(Dataset):\n    def __init__(self, ds):\n        self.seqs, self.labels = ds[\"sequence\"], ds[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return tokenize(self.seqs[idx]), self.labels[idx], self.seqs[idx]\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n\n    def encode(lst):\n        ids = [torch.tensor([vocab[t] for t in toks]) for toks in lst]\n        lens = [len(i) for i in ids]\n        return pad_sequence(ids, batch_first=True), torch.tensor(lens)\n\n    ids1, len1 = encode(v1)\n    ids2, len2 = encode(v2)\n    return {\n        \"ids1\": ids1.to(device),\n        \"len1\": len1.to(device),\n        \"ids2\": ids2.to(device),\n        \"len2\": len2.to(device),\n    }\n\n\ndef collate_classifier(batch):\n    toks, labels, raw = zip(*batch)\n    ids = [torch.tensor([vocab[t] for t in t]) for t in toks]\n    lens = [len(i) for i in ids]\n    return {\n        \"ids\": pad_sequence(ids, batch_first=True).to(device),\n        \"len\": torch.tensor(lens).to(device),\n        \"label\": torch.tensor(labels).to(device),\n        \"sequence\": raw,\n    }\n\n\npretrain_loader = DataLoader(\n    SPRContrastiveDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_contrastive,\n)\ntrain_loader = DataLoader(\n    SPRClassifierDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_classifier,\n)\ndev_loader = DataLoader(\n    SPRClassifierDataset(spr_bench[\"dev\"]),\n    batch_size=256,\n    shuffle=False,\n    collate_fn=collate_classifier,\n)\n\n\n# -------------------------------------------------\n# Model\nclass Encoder(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_sz, emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden, batch_first=True, bidirectional=True)\n        self.proj = nn.Linear(hidden * 2, hidden)\n\n    def forward(self, ids, lens):\n        x = self.emb(ids)\n        packed = pack_padded_sequence(\n            x, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[-2], h[-1]], 1)\n        return self.proj(h)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, enc, num_cls):\n        super().__init__()\n        self.enc = enc\n        self.head = nn.Linear(enc.proj.out_features, num_cls)\n\n    def forward(self, ids, lens):\n        return self.head(self.enc(ids, lens))\n\n\n# -------------------------------------------------\n# Losses\ndef nt_xent_loss(z1, z2, temp=0.5):\n    z1, z2 = nn.functional.normalize(z1, 1), nn.functional.normalize(z2, 1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    sim = torch.matmul(z, z.T) / temp\n    mask = torch.eye(2 * N, device=z.device, dtype=torch.bool)\n    sim.masked_fill_(mask, -9e15)\n    targets = torch.arange(N, 2 * N, device=z.device)\n    logits_12, logits_21 = sim[:N, N:], sim[N:, :N]\n    denom_12 = torch.logsumexp(sim[:N], 1)\n    denom_21 = torch.logsumexp(sim[N:], 1)\n    return (\n        (-logits_12.diag() + denom_12) + (-logits_21.diag() + denom_21)\n    ).mean() * 0.5\n\n\n# -------------------------------------------------\n# Experiment dictionary\nexperiment_data = {\"weight_decay\": {}}\n\n\n# -------------------------------------------------\n# Training routine\ndef run_experiment(weight_decay_value):\n    tag = str(weight_decay_value)\n    experiment_data[\"weight_decay\"][tag] = {\n        \"losses\": {\"pretrain\": [], \"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"SCHM\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    # build models\n    encoder = Encoder(vocab_size).to(device)\n    clf = Classifier(encoder, num_cls=len(set(spr_bench[\"train\"][\"label\"]))).to(device)\n    # pretrain\n    opt_pt = torch.optim.Adam(\n        encoder.parameters(), lr=1e-3, weight_decay=weight_decay_value\n    )\n    for ep in range(2):\n        encoder.train()\n        running = 0.0\n        for b in pretrain_loader:\n            opt_pt.zero_grad()\n            z1 = encoder(b[\"ids1\"], b[\"len1\"])\n            z2 = encoder(b[\"ids2\"], b[\"len2\"])\n            loss = nt_xent_loss(z1, z2)\n            loss.backward()\n            opt_pt.step()\n            running += loss.item() * b[\"ids1\"].size(0)\n        epoch_loss = running / len(pretrain_loader.dataset)\n        experiment_data[\"weight_decay\"][tag][\"losses\"][\"pretrain\"].append(epoch_loss)\n        print(f\"[WD={tag}] Pretrain epoch {ep+1}: {epoch_loss:.4f}\")\n    # fine-tune\n    opt_ft = torch.optim.Adam(\n        clf.parameters(), lr=1e-3, weight_decay=weight_decay_value\n    )\n    crit = nn.CrossEntropyLoss()\n    for ep in range(3):\n        clf.train()\n        running = 0.0\n        for b in train_loader:\n            opt_ft.zero_grad()\n            logits = clf(b[\"ids\"], b[\"len\"])\n            loss = crit(logits, b[\"label\"])\n            loss.backward()\n            opt_ft.step()\n            running += loss.item() * b[\"ids\"].size(0)\n        tr_loss = running / len(train_loader.dataset)\n        experiment_data[\"weight_decay\"][tag][\"losses\"][\"train\"].append(tr_loss)\n        # eval\n        clf.eval()\n        val_loss = 0.0\n        preds, truth, seqs = [], [], []\n        with torch.no_grad():\n            for b in dev_loader:\n                logits = clf(b[\"ids\"], b[\"len\"])\n                loss = crit(logits, b[\"label\"])\n                val_loss += loss.item() * b[\"ids\"].size(0)\n                p = logits.argmax(1).cpu().tolist()\n                preds.extend(p)\n                truth.extend(b[\"label\"].cpu().tolist())\n                seqs.extend(b[\"sequence\"])\n        val_loss /= len(dev_loader.dataset)\n        experiment_data[\"weight_decay\"][tag][\"losses\"][\"val\"].append(val_loss)\n        swa = shape_weighted_accuracy(seqs, truth, preds)\n        cwa = color_weighted_accuracy(seqs, truth, preds)\n        schm = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        experiment_data[\"weight_decay\"][tag][\"metrics\"][\"SWA\"].append(swa)\n        experiment_data[\"weight_decay\"][tag][\"metrics\"][\"CWA\"].append(cwa)\n        experiment_data[\"weight_decay\"][tag][\"metrics\"][\"SCHM\"].append(schm)\n        print(\n            f\"[WD={tag}] FT epoch {ep+1}: train={tr_loss:.4f} val={val_loss:.4f} | SWA={swa:.3f} CWA={cwa:.3f} SCHM={schm:.3f}\"\n        )\n    experiment_data[\"weight_decay\"][tag][\"predictions\"] = preds\n    experiment_data[\"weight_decay\"][tag][\"ground_truth\"] = truth\n    # Plot curve\n    plt.figure()\n    plt.plot(experiment_data[\"weight_decay\"][tag][\"losses\"][\"train\"], label=\"train\")\n    plt.plot(experiment_data[\"weight_decay\"][tag][\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"Loss curve (weight_decay={tag})\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_wd_{tag}.png\"))\n    plt.close()\n    del encoder, clf\n    torch.cuda.empty_cache()\n\n\n# -------------------------------------------------\n# Hyper-parameter sweep\nfor wd in [0.0, 1e-5, 1e-4, 1e-3]:\n    run_experiment(wd)\n\n# -------------------------------------------------\n# Save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data and plots in ./working/\")\n", "import os, pathlib, random, math, time, json\nimport numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset, DatasetDict\n\n# -------------------- misc setup --------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\ntorch.manual_seed(42)\nrandom.seed(42)\nnp.random.seed(42)\n\n\n# -------------------- data utils --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for split in [\"train\", \"dev\", \"test\"]:\n        d[split] = _load(f\"{split}.csv\")\n    return d\n\n\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.strip().split() if tok))\n\n\ndef count_color_variety(seq):\n    return len(set(tok[1] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wi if t == p else 0 for wi, t, p in zip(w, y_t, y_p)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_t, y_p):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wi if t == p else 0 for wi, t, p in zip(w, y_t, y_p)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# -------------------- dataset load / fallback --------------------\ndata_root_candidates = [pathlib.Path(\"SPR_BENCH\"), pathlib.Path(\"./data/SPR_BENCH\")]\nspr_bench = None\nfor p in data_root_candidates:\n    if (p / \"train.csv\").exists():\n        spr_bench = load_spr_bench(p)\n        print(\"Loaded data from\", p)\n        break\nif spr_bench is None:\n    print(\"SPR_BENCH not found, creating synthetic dataset.\")\n\n    def synth(n):\n        shapes, colors = \"ABCD\", \"1234\"\n        seqs, labels = [], []\n        for _ in range(n):\n            L = random.randint(4, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(L)\n            )\n            seqs.append(seq)\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    spr_bench = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        spr_bench[split] = load_dataset(\n            \"json\", data_files={\"train\": None}, split=\"train\", data=synth(n)\n        )\n\n\n# -------------------- vocab --------------------\ndef tokenize(seq):\n    return seq.strip().split()\n\n\nvocab = {\"<PAD>\": 0, \"<MASK>\": 1}\nfor split in spr_bench.values():\n    for seq in split[\"sequence\"]:\n        for tok in tokenize(seq):\n            vocab.setdefault(tok, len(vocab))\nvocab_size = len(vocab)\nmask_id = vocab[\"<MASK>\"]\nprint(\"Vocab size:\", vocab_size)\n\n\n# -------------------- torch datasets --------------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, hf):\n        self.seqs = hf[\"sequence\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def _augment(self, toks, p=0.15):\n        out = [t for t in toks if random.random() >= p]\n        if not out:\n            out.append(random.choice(toks))\n        return out\n\n    def __getitem__(self, idx):\n        toks = tokenize(self.seqs[idx])\n        return self._augment(toks), self._augment(toks)\n\n\nclass SPRClassifierDataset(Dataset):\n    def __init__(self, hf):\n        self.seqs = hf[\"sequence\"]\n        self.labels = hf[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return tokenize(self.seqs[idx]), self.labels[idx], self.seqs[idx]\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n\n    def encode(list_tokens):\n        ids = [torch.tensor([vocab[t] for t in toks]) for toks in list_tokens]\n        lens = [len(i) for i in ids]\n        return pad_sequence(ids, batch_first=True), torch.tensor(lens)\n\n    ids1, len1 = encode(v1)\n    ids2, len2 = encode(v2)\n    return {\n        \"ids1\": ids1.to(device),\n        \"len1\": len1.to(device),\n        \"ids2\": ids2.to(device),\n        \"len2\": len2.to(device),\n    }\n\n\ndef collate_classifier(batch):\n    toks, lbls, seqs = zip(*batch)\n    ids = [torch.tensor([vocab[t] for t in t]) for t in toks]\n    lens = [len(i) for i in ids]\n    return {\n        \"ids\": pad_sequence(ids, batch_first=True).to(device),\n        \"len\": torch.tensor(lens).to(device),\n        \"label\": torch.tensor(lbls).to(device),\n        \"sequence\": seqs,\n    }\n\n\npretrain_loader_full = lambda: DataLoader(\n    SPRContrastiveDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_contrastive,\n)\ntrain_loader_full = lambda: DataLoader(\n    SPRClassifierDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_classifier,\n)\ndev_loader = lambda: DataLoader(\n    SPRClassifierDataset(spr_bench[\"dev\"]),\n    batch_size=256,\n    shuffle=False,\n    collate_fn=collate_classifier,\n)\n\n\n# -------------------- model --------------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab, emb_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(len(vocab), emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden, batch_first=True, bidirectional=True)\n        self.proj = nn.Linear(hidden * 2, hidden)\n\n    def forward(self, ids, lens):\n        x = self.emb(ids)\n        packed = pack_padded_sequence(\n            x, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[-2], h[-1]], 1)\n        return self.proj(h)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, enc, num_cls):\n        super().__init__()\n        self.encoder = enc\n        self.head = nn.Linear(enc.proj.out_features, num_cls)\n\n    def forward(self, ids, lens):\n        return self.head(self.encoder(ids, lens))\n\n\n# -------------------- contrastive loss --------------------\ndef nt_xent_loss(z1, z2, temp):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    sim = torch.matmul(z, z.T) / temp\n    mask = torch.eye(2 * N, dtype=torch.bool, device=z.device)\n    sim.masked_fill_(mask, -9e15)\n    targets = torch.arange(N, 2 * N, device=z.device)\n    logits_12, logits_21 = sim[:N, N:], sim[N:, :N]\n    loss = (\n        -logits_12.diag()\n        + torch.logsumexp(sim[:N], 1)\n        - logits_21.diag()\n        + torch.logsumexp(sim[N:], 1)\n    ).mean() * 0.5\n    return loss\n\n\n# -------------------- experiment container --------------------\nexperiment_data = {\"contrastive_temperature\": {}}\n\ntemps = [0.07, 0.1, 0.2, 0.5, 0.75, 1.0]\nnum_classes = len(set(spr_bench[\"train\"][\"label\"]))\n\nfor temp in temps:\n    tag = str(temp)\n    print(f\"\\n=== Temperature {temp} ===\")\n    exp = {\n        \"losses\": {\"pretrain\": [], \"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"SCHM\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    experiment_data[\"contrastive_temperature\"][tag] = exp\n\n    # dataloaders\n    pretrain_loader = pretrain_loader_full()\n    train_loader = train_loader_full()\n    dev_dl = dev_loader()\n\n    # fresh model\n    encoder = Encoder(vocab).to(device)\n    clf = Classifier(encoder, num_classes).to(device)\n\n    # -------- pretrain --------\n    opt_pt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n    for ep in range(2):\n        encoder.train()\n        epoch_loss = 0.0\n        for batch in pretrain_loader:\n            opt_pt.zero_grad()\n            z1 = encoder(batch[\"ids1\"], batch[\"len1\"])\n            z2 = encoder(batch[\"ids2\"], batch[\"len2\"])\n            loss = nt_xent_loss(z1, z2, temp)\n            loss.backward()\n            opt_pt.step()\n            epoch_loss += loss.item() * batch[\"ids1\"].size(0)\n        epoch_loss /= len(pretrain_loader.dataset)\n        exp[\"losses\"][\"pretrain\"].append(epoch_loss)\n        print(f\"  Pretrain ep{ep+1} loss={epoch_loss:.4f}\")\n\n    # -------- fine-tune --------\n    opt_ft = torch.optim.Adam(clf.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n    for ep in range(3):\n        # train\n        clf.train()\n        run_loss = 0.0\n        for batch in train_loader:\n            opt_ft.zero_grad()\n            logits = clf(batch[\"ids\"], batch[\"len\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            opt_ft.step()\n            run_loss += loss.item() * batch[\"ids\"].size(0)\n        train_loss = run_loss / len(train_loader.dataset)\n        exp[\"losses\"][\"train\"].append(train_loss)\n        # val\n        clf.eval()\n        val_loss = 0.0\n        all_pred = []\n        all_true = []\n        all_seq = []\n        with torch.no_grad():\n            for batch in dev_dl:\n                logits = clf(batch[\"ids\"], batch[\"len\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss += loss.item() * batch[\"ids\"].size(0)\n                p = logits.argmax(1).cpu().tolist()\n                all_pred.extend(p)\n                all_true.extend(batch[\"label\"].cpu().tolist())\n                all_seq.extend(batch[\"sequence\"])\n        val_loss /= len(dev_dl.dataset)\n        exp[\"losses\"][\"val\"].append(val_loss)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        schm = 2 * swa * cwa / (swa + cwa) if swa + cwa > 0 else 0.0\n        exp[\"metrics\"][\"SWA\"].append(swa)\n        exp[\"metrics\"][\"CWA\"].append(cwa)\n        exp[\"metrics\"][\"SCHM\"].append(schm)\n        print(\n            f\"  FT ep{ep+1}: train={train_loss:.4f} val={val_loss:.4f} SWA={swa:.3f} CWA={cwa:.3f} SCHM={schm:.3f}\"\n        )\n        if ep == 2:  # save preds from last epoch\n            exp[\"predictions\"] = all_pred\n            exp[\"ground_truth\"] = all_true\n    torch.cuda.empty_cache()\n\n# -------------------- save & plot --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n# simple plot: val SCHM per temp\nplt.figure()\nfor temp in temps:\n    plt.plot(\n        experiment_data[\"contrastive_temperature\"][str(temp)][\"metrics\"][\"SCHM\"],\n        label=f\"T={temp}\",\n    )\nplt.xlabel(\"Fine-tune epoch\")\nplt.ylabel(\"Dev SCHM\")\nplt.title(\"Temperature sweep\")\nplt.legend()\nplt.savefig(os.path.join(working_dir, \"temp_sweep_schm.png\"))\nprint(\"Saved experiment data and plots to ./working/\")\n", "import os, pathlib, random, math, time, json, gc\nimport numpy as np, torch, matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\nfrom datasets import load_dataset, DatasetDict\n\n# ----------------- I/O ---------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n\n# ----------------- SPR helpers -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv):  # inner\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for s in [\"train\", \"dev\", \"test\"]:\n        d[s] = _load(f\"{s}.csv\")\n    return d\n\n\ndef count_shape_variety(sequence):\n    return len(set(tok[0] for tok in sequence.split() if tok))\n\n\ndef count_color_variety(sequence):\n    return len(set(tok[1] for tok in sequence.split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# -------------- Load / synth dataset -------------\ndata_root_candidates = [pathlib.Path(\"SPR_BENCH\"), pathlib.Path(\"./data/SPR_BENCH\")]\nspr_bench = None\nfor p in data_root_candidates:\n    if (p / \"train.csv\").exists():\n        spr_bench = load_spr_bench(p)\n        print(\"Loaded\", p)\n        break\nif spr_bench is None:\n    print(\"Dataset not found, creating tiny synthetic.\")\n\n    def synth(n):\n        shapes, colors = \"ABCD\", \"1234\"\n        seqs, labels = [], []\n        for _ in range(n):\n            L = random.randint(4, 9)\n            seq = []\n            for _ in range(L):\n                seq.append(random.choice(shapes) + random.choice(colors))\n            seqs.append(\" \".join(seq))\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    spr_bench = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        spr_bench[split] = load_dataset(\n            \"json\", data_files={\"train\": None}, split=\"train\", data=synth(n)\n        )\n\n\n# ---------------- Vocabulary ---------------------\ndef tokenize(s):\n    return s.strip().split()\n\n\nvocab = {\"<PAD>\": 0, \"<MASK>\": 1}\nfor split in spr_bench.values():\n    for seq in split[\"sequence\"]:\n        for tok in tokenize(seq):\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\nvocab_size = len(vocab)\nmask_id = vocab[\"<MASK>\"]\nprint(\"Vocab size:\", vocab_size)\n\n\n# --------------- Dataset objects -----------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, hf):\n        self.seqs = hf[\"sequence\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def _augment(self, toks, p=0.15):\n        out = [t for t in toks if random.random() >= p]\n        if not out:\n            out.append(random.choice(toks))\n            return out\n\n    def __getitem__(self, idx):\n        toks = tokenize(self.seqs[idx])\n        return self._augment(toks), self._augment(toks)\n\n\nclass SPRClassifierDataset(Dataset):\n    def __init__(self, hf):\n        self.seqs = hf[\"sequence\"]\n        self.labels = hf[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return tokenize(self.seqs[idx]), self.labels[idx], self.seqs[idx]\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n\n    def encode(view):\n        ids = [torch.tensor([vocab[t] for t in toks]) for toks in view]\n        lens = [len(i) for i in ids]\n        return pad_sequence(ids, batch_first=True), torch.tensor(lens)\n\n    ids1, len1 = encode(v1)\n    ids2, len2 = encode(v2)\n    return {\n        \"ids1\": ids1.to(device),\n        \"len1\": len1.to(device),\n        \"ids2\": ids2.to(device),\n        \"len2\": len2.to(device),\n    }\n\n\ndef collate_classifier(batch):\n    toks, labels, raw = zip(*batch)\n    ids = [torch.tensor([vocab[t] for t in tok]) for tok in toks]\n    lens = [len(i) for i in ids]\n    return {\n        \"ids\": pad_sequence(ids, batch_first=True).to(device),\n        \"len\": torch.tensor(lens).to(device),\n        \"label\": torch.tensor(labels).to(device),\n        \"sequence\": raw,\n    }\n\n\npretrain_loader = DataLoader(\n    SPRContrastiveDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_contrastive,\n)\ntrain_loader = DataLoader(\n    SPRClassifierDataset(spr_bench[\"train\"]),\n    batch_size=128,\n    shuffle=True,\n    collate_fn=collate_classifier,\n)\ndev_loader = DataLoader(\n    SPRClassifierDataset(spr_bench[\"dev\"]),\n    batch_size=256,\n    shuffle=False,\n    collate_fn=collate_classifier,\n)\n\n\n# ----------------- Model defs --------------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab, emb_dim=64, hidden=128, dropout_rate=0.0):\n        super().__init__()\n        self.emb = nn.Embedding(len(vocab), emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden, batch_first=True, bidirectional=True)\n        self.proj = nn.Linear(hidden * 2, hidden)\n        self.dropout = nn.Dropout(dropout_rate)\n\n    def forward(self, ids, lens):\n        x = self.emb(ids)\n        packed = pack_padded_sequence(\n            x, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[-2], h[-1]], dim=1)\n        return self.dropout(self.proj(h))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(encoder.proj.out_features, num_classes)\n\n    def forward(self, ids, lens):\n        return self.head(self.encoder(ids, lens))\n\n\n# ----------------- Losses ------------------------\ndef nt_xent_loss(z1, z2, temp=0.5):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2])\n    sim = torch.matmul(z, z.T) / temp\n    mask = torch.eye(2 * N, dtype=torch.bool, device=z.device)\n    sim.masked_fill_(mask, -9e15)\n    targets = torch.arange(N, 2 * N, device=z.device)\n    loss = (\n        -sim[:N, targets].diag()\n        + torch.logsumexp(sim[:N], dim=1)\n        - sim[N:, targets - N].diag()\n        + torch.logsumexp(sim[N:], dim=1)\n    ).mean() * 0.5\n    return loss\n\n\n# ----------------- Hyper-param loop --------------\ndropout_rates = [0.0, 0.1, 0.3, 0.5]\nexperiment_data = {\"dropout_tuning\": {}}\n\nfor dr in dropout_rates:\n    tag = f\"{dr:.1f}\"\n    experiment_data[\"dropout_tuning\"][tag] = {\n        \"losses\": {\"pretrain\": [], \"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"SCHM\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    encoder = Encoder(vocab, dropout_rate=dr).to(device)\n    clf = Classifier(encoder, num_classes=len(set(spr_bench[\"train\"][\"label\"]))).to(\n        device\n    )\n    # ----- pretrain -----\n    opt_pt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n    for ep in range(2):\n        encoder.train()\n        epoch_loss = 0.0\n        for batch in pretrain_loader:\n            opt_pt.zero_grad()\n            loss = nt_xent_loss(\n                encoder(batch[\"ids1\"], batch[\"len1\"]),\n                encoder(batch[\"ids2\"], batch[\"len2\"]),\n            )\n            loss.backward()\n            opt_pt.step()\n            epoch_loss += loss.item() * batch[\"ids1\"].size(0)\n        epoch_loss /= len(pretrain_loader.dataset)\n        experiment_data[\"dropout_tuning\"][tag][\"losses\"][\"pretrain\"].append(epoch_loss)\n        print(f\"[dr={dr}] Pretrain {ep+1} loss {epoch_loss:.4f}\")\n    # ----- fine-tune -----\n    opt_ft = torch.optim.Adam(clf.parameters(), lr=1e-3)\n    crit = nn.CrossEntropyLoss()\n    for ep in range(3):\n        clf.train()\n        run_loss = 0.0\n        for batch in train_loader:\n            opt_ft.zero_grad()\n            loss = crit(clf(batch[\"ids\"], batch[\"len\"]), batch[\"label\"])\n            loss.backward()\n            opt_ft.step()\n            run_loss += loss.item() * batch[\"ids\"].size(0)\n        train_loss = run_loss / len(train_loader.dataset)\n        experiment_data[\"dropout_tuning\"][tag][\"losses\"][\"train\"].append(train_loss)\n        # eval\n        clf.eval()\n        val_loss = 0.0\n        preds = []\n        trues = []\n        seqs = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                logits = clf(batch[\"ids\"], batch[\"len\"])\n                loss = crit(logits, batch[\"label\"])\n                val_loss += loss.item() * batch[\"ids\"].size(0)\n                preds.extend(logits.argmax(1).cpu().tolist())\n                trues.extend(batch[\"label\"].cpu().tolist())\n                seqs.extend(batch[\"sequence\"])\n        val_loss /= len(dev_loader.dataset)\n        swa = shape_weighted_accuracy(seqs, trues, preds)\n        cwa = color_weighted_accuracy(seqs, trues, preds)\n        schm = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        d = experiment_data[\"dropout_tuning\"][tag]\n        d[\"losses\"][\"val\"].append(val_loss)\n        d[\"metrics\"][\"SWA\"].append(swa)\n        d[\"metrics\"][\"CWA\"].append(cwa)\n        d[\"metrics\"][\"SCHM\"].append(schm)\n        print(\n            f\"[dr={dr}] FT{ep+1} train {train_loss:.4f} val {val_loss:.4f} SWA {swa:.3f} CWA {cwa:.3f} SCHM {schm:.3f}\"\n        )\n    experiment_data[\"dropout_tuning\"][tag][\"predictions\"] = preds\n    experiment_data[\"dropout_tuning\"][tag][\"ground_truth\"] = trues\n    # free\n    del encoder, clf, opt_ft, opt_pt\n    torch.cuda.empty_cache()\n    gc.collect()\n\n# ----------------- Save & plot -------------------\nnp.save(\n    os.path.join(working_dir, \"experiment_data.npy\"), experiment_data, allow_pickle=True\n)\nfor key in experiment_data[\"dropout_tuning\"]:\n    plt.figure()\n    plt.plot(experiment_data[\"dropout_tuning\"][key][\"losses\"][\"train\"], label=\"train\")\n    plt.plot(experiment_data[\"dropout_tuning\"][key][\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"Loss dr={key}\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_dr_{key}.png\"))\n    plt.close()\nprint(\"Saved experiment data & plots in\", working_dir)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, math, time, json, gc\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\nimport matplotlib.pyplot as plt\n\n# ------------------------- I/O -----------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------- Device --------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------------- Data loading -----------------------\nfrom datasets import load_dataset, DatasetDict\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for s in [\"train\", \"dev\", \"test\"]:\n        d[s] = _load(f\"{s}.csv\")\n    return d\n\n\ndata_root_candidates = [\n    pathlib.Path(\"SPR_BENCH\"),\n    pathlib.Path(\"./data/SPR_BENCH\"),\n    pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n]\nspr_bench = None\nfor p in data_root_candidates:\n    if (p / \"train.csv\").exists():\n        spr_bench = load_spr_bench(p)\n        print(f\"Loaded data from {p}\")\n        break\nif spr_bench is None:\n    print(\"SPR_BENCH not found, generating synthetic data.\")\n\n    def synth(n):\n        seqs, labels = [], []\n        shapes, colors = \"ABCD\", \"1234\"\n        for _ in range(n):\n            L = random.randint(4, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(L)\n            )\n            seqs.append(seq)\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    spr_bench = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        spr_bench[split] = load_dataset(\n            \"json\", data_files={\"train\": None}, split=\"train\", data=synth(n)\n        )\n\n\ndef tokenize(seq):\n    return seq.strip().split()\n\n\n# ---------------------- Vocabulary -------------------------\nvocab = {\"<PAD>\": 0, \"<MASK>\": 1}\nfor split in spr_bench.values():\n    for seq in split[\"sequence\"]:\n        for tok in tokenize(seq):\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\nvocab_size = len(vocab)\nmask_id = vocab[\"<MASK>\"]\nprint(\"Vocab size:\", vocab_size)\n\n\n# ---------------------- Metrics ----------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# --------------------- Datasets ----------------------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def _augment(self, toks, p=0.15):\n        out = [t for t in toks if random.random() >= p]\n        if not out:\n            out = [random.choice(toks)]\n        return out\n\n    def __getitem__(self, idx):\n        toks = tokenize(self.seqs[idx])\n        return self._augment(toks), self._augment(toks)\n\n\nclass SPRClassifierDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n        self.labels = hf_ds[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return tokenize(self.seqs[idx]), self.labels[idx], self.seqs[idx]\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n\n    def encode(tok_list):\n        ids = [\n            torch.tensor([vocab[t] for t in toks], dtype=torch.long)\n            for toks in tok_list\n        ]\n        lens = [len(i) for i in ids]\n        ids = pad_sequence(ids, batch_first=True, padding_value=0)\n        return ids.to(device), torch.tensor(lens, dtype=torch.long).to(device)\n\n    ids1, len1 = encode(v1)\n    ids2, len2 = encode(v2)\n    return {\"ids1\": ids1, \"len1\": len1, \"ids2\": ids2, \"len2\": len2}\n\n\ndef collate_classifier(batch):\n    toks, labels, raw_seq = zip(*batch)\n    ids = [torch.tensor([vocab[t] for t in t], dtype=torch.long) for t in toks]\n    lens = [len(i) for i in ids]\n    ids = pad_sequence(ids, batch_first=True, padding_value=0).to(device)\n    return {\n        \"ids\": ids,\n        \"len\": torch.tensor(lens, dtype=torch.long).to(device),\n        \"label\": torch.tensor(labels, dtype=torch.long).to(device),\n        \"sequence\": raw_seq,\n    }\n\n\n# ---------------------- Model ------------------------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab, emb_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(len(vocab), emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden, batch_first=True, bidirectional=True)\n        self.proj = nn.Linear(hidden * 2, hidden)\n\n    def forward(self, ids, lens):\n        x = self.emb(ids)\n        packed = pack_padded_sequence(\n            x, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[-2], h[-1]], dim=1)\n        return self.proj(h)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(encoder.proj.out_features, num_classes)\n\n    def forward(self, ids, lens):\n        return self.head(self.encoder(ids, lens))\n\n\n# ---------------- Contrastive loss -------------------------\ndef nt_xent_loss(z1, z2, temp=0.5):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2], dim=0)\n    sim = torch.matmul(z, z.T) / temp\n    mask = torch.eye(2 * N, dtype=torch.bool, device=z.device)\n    sim.masked_fill_(mask, -9e15)\n    targets = torch.arange(N, 2 * N, device=z.device)\n    logits_12 = sim[:N, N:]\n    logits_21 = sim[N:, :N]\n    denom_12 = torch.logsumexp(sim[:N], dim=1)\n    denom_21 = torch.logsumexp(sim[N:], dim=1)\n    loss = (-logits_12.diag() + denom_12 + -logits_21.diag() + denom_21).mean() * 0.5\n    return loss\n\n\n# ---------------- Experiment container ---------------------\nexperiment_data = {\"pretrain_epochs\": {\"SPR_BENCH\": {}}}\n\n# ------------- Hyperparameter values to try ----------------\nepoch_settings = [2, 4, 6, 8, 10]\n\nfor pretrain_epochs in epoch_settings:\n    print(f\"\\n=== Running experiment with pretrain_epochs={pretrain_epochs} ===\")\n    run_dict = {\n        \"losses\": {\"pretrain\": [], \"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"SCHM\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    # Dataloaders (fresh shuffle each run)\n    pretrain_loader = DataLoader(\n        SPRContrastiveDataset(spr_bench[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_contrastive,\n    )\n    train_loader = DataLoader(\n        SPRClassifierDataset(spr_bench[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_classifier,\n    )\n    dev_loader = DataLoader(\n        SPRClassifierDataset(spr_bench[\"dev\"]),\n        batch_size=256,\n        shuffle=False,\n        collate_fn=collate_classifier,\n    )\n\n    # Model instantiation\n    encoder = Encoder(vocab).to(device)\n    clf_model = Classifier(\n        encoder, num_classes=len(set(spr_bench[\"train\"][\"label\"]))\n    ).to(device)\n\n    # -------- Contrastive pre-training ----------\n    optimizer_pt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n    for ep in range(1, pretrain_epochs + 1):\n        encoder.train()\n        epoch_loss = 0.0\n        for batch in pretrain_loader:\n            optimizer_pt.zero_grad()\n            z1 = encoder(batch[\"ids1\"], batch[\"len1\"])\n            z2 = encoder(batch[\"ids2\"], batch[\"len2\"])\n            loss = nt_xent_loss(z1, z2)\n            loss.backward()\n            optimizer_pt.step()\n            epoch_loss += loss.item() * batch[\"ids1\"].size(0)\n        epoch_loss /= len(pretrain_loader.dataset)\n        run_dict[\"losses\"][\"pretrain\"].append(epoch_loss)\n        print(f\"  Pretrain epoch {ep}/{pretrain_epochs} loss={epoch_loss:.4f}\")\n\n    # --------------- Fine-tuning ----------------\n    optimizer_ft = torch.optim.Adam(clf_model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n    ft_epochs = 3\n    for ep in range(1, ft_epochs + 1):\n        # train\n        clf_model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            optimizer_ft.zero_grad()\n            logits = clf_model(batch[\"ids\"], batch[\"len\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer_ft.step()\n            running_loss += loss.item() * batch[\"ids\"].size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        run_dict[\"losses\"][\"train\"].append(train_loss)\n        # evaluate\n        clf_model.eval()\n        val_loss = 0.0\n        all_pred = []\n        all_true = []\n        all_seq = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                logits = clf_model(batch[\"ids\"], batch[\"len\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss += loss.item() * batch[\"ids\"].size(0)\n                preds = logits.argmax(1).cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(batch[\"label\"].cpu().tolist())\n                all_seq.extend(batch[\"sequence\"])\n        val_loss /= len(dev_loader.dataset)\n        run_dict[\"losses\"][\"val\"].append(val_loss)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        schm = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        run_dict[\"metrics\"][\"SWA\"].append(swa)\n        run_dict[\"metrics\"][\"CWA\"].append(cwa)\n        run_dict[\"metrics\"][\"SCHM\"].append(schm)\n        print(\n            f\"  FT epoch {ep}/{ft_epochs} train_loss={train_loss:.4f} val_loss={val_loss:.4f} | SWA={swa:.3f} CWA={cwa:.3f} SCHM={schm:.3f}\"\n        )\n\n    # store final preds/gt from last epoch\n    run_dict[\"predictions\"] = all_pred\n    run_dict[\"ground_truth\"] = all_true\n    experiment_data[\"pretrain_epochs\"][\"SPR_BENCH\"][str(pretrain_epochs)] = run_dict\n\n    # plot loss curves for this run\n    plt.figure()\n    plt.plot(run_dict[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(run_dict[\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"FT Loss (pretrain_epochs={pretrain_epochs})\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_ep{pretrain_epochs}.png\"))\n    plt.close()\n\n    # free memory\n    del encoder, clf_model, optimizer_pt, optimizer_ft\n    torch.cuda.empty_cache()\n    gc.collect()\n\n# --------------- Save experiment data ----------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment data and plots to ./working/\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, math, time, json, gc\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\nimport matplotlib.pyplot as plt\n\n# ------------------------- I/O -----------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------- Device --------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------------- Data loading -----------------------\nfrom datasets import load_dataset, DatasetDict\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for s in [\"train\", \"dev\", \"test\"]:\n        d[s] = _load(f\"{s}.csv\")\n    return d\n\n\ndata_root_candidates = [\n    pathlib.Path(\"SPR_BENCH\"),\n    pathlib.Path(\"./data/SPR_BENCH\"),\n    pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n]\nspr_bench = None\nfor p in data_root_candidates:\n    if (p / \"train.csv\").exists():\n        spr_bench = load_spr_bench(p)\n        print(f\"Loaded data from {p}\")\n        break\nif spr_bench is None:\n    print(\"SPR_BENCH not found, generating synthetic data.\")\n\n    def synth(n):\n        seqs, labels = [], []\n        shapes, colors = \"ABCD\", \"1234\"\n        for _ in range(n):\n            L = random.randint(4, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(L)\n            )\n            seqs.append(seq)\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    spr_bench = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        spr_bench[split] = load_dataset(\n            \"json\", data_files={\"train\": None}, split=\"train\", data=synth(n)\n        )\n\n\ndef tokenize(seq):\n    return seq.strip().split()\n\n\n# ---------------------- Vocabulary -------------------------\nvocab = {\"<PAD>\": 0, \"<MASK>\": 1}\nfor split in spr_bench.values():\n    for seq in split[\"sequence\"]:\n        for tok in tokenize(seq):\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\nvocab_size = len(vocab)\nmask_id = vocab[\"<MASK>\"]\nprint(\"Vocab size:\", vocab_size)\n\n\n# ---------------------- Metrics ----------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# --------------------- Datasets ----------------------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def _augment(self, toks, p=0.15):\n        out = [t for t in toks if random.random() >= p]\n        if not out:\n            out = [random.choice(toks)]\n        return out\n\n    def __getitem__(self, idx):\n        toks = tokenize(self.seqs[idx])\n        return self._augment(toks), self._augment(toks)\n\n\nclass SPRClassifierDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n        self.labels = hf_ds[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return tokenize(self.seqs[idx]), self.labels[idx], self.seqs[idx]\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n\n    def encode(tok_list):\n        ids = [\n            torch.tensor([vocab[t] for t in toks], dtype=torch.long)\n            for toks in tok_list\n        ]\n        lens = [len(i) for i in ids]\n        ids = pad_sequence(ids, batch_first=True, padding_value=0)\n        return ids.to(device), torch.tensor(lens, dtype=torch.long).to(device)\n\n    ids1, len1 = encode(v1)\n    ids2, len2 = encode(v2)\n    return {\"ids1\": ids1, \"len1\": len1, \"ids2\": ids2, \"len2\": len2}\n\n\ndef collate_classifier(batch):\n    toks, labels, raw_seq = zip(*batch)\n    ids = [torch.tensor([vocab[t] for t in t], dtype=torch.long) for t in toks]\n    lens = [len(i) for i in ids]\n    ids = pad_sequence(ids, batch_first=True, padding_value=0).to(device)\n    return {\n        \"ids\": ids,\n        \"len\": torch.tensor(lens, dtype=torch.long).to(device),\n        \"label\": torch.tensor(labels, dtype=torch.long).to(device),\n        \"sequence\": raw_seq,\n    }\n\n\n# ---------------------- Model ------------------------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab, emb_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(len(vocab), emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden, batch_first=True, bidirectional=True)\n        self.proj = nn.Linear(hidden * 2, hidden)\n\n    def forward(self, ids, lens):\n        x = self.emb(ids)\n        packed = pack_padded_sequence(\n            x, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[-2], h[-1]], dim=1)\n        return self.proj(h)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(encoder.proj.out_features, num_classes)\n\n    def forward(self, ids, lens):\n        return self.head(self.encoder(ids, lens))\n\n\n# ---------------- Contrastive loss -------------------------\ndef nt_xent_loss(z1, z2, temp=0.5):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2], dim=0)\n    sim = torch.matmul(z, z.T) / temp\n    mask = torch.eye(2 * N, dtype=torch.bool, device=z.device)\n    sim.masked_fill_(mask, -9e15)\n    targets = torch.arange(N, 2 * N, device=z.device)\n    logits_12 = sim[:N, N:]\n    logits_21 = sim[N:, :N]\n    denom_12 = torch.logsumexp(sim[:N], dim=1)\n    denom_21 = torch.logsumexp(sim[N:], dim=1)\n    loss = (-logits_12.diag() + denom_12 + -logits_21.diag() + denom_21).mean() * 0.5\n    return loss\n\n\n# ---------------- Experiment container ---------------------\nexperiment_data = {\"pretrain_epochs\": {\"SPR_BENCH\": {}}}\n\n# ------------- Hyperparameter values to try ----------------\nepoch_settings = [2, 4, 6, 8, 10]\n\nfor pretrain_epochs in epoch_settings:\n    print(f\"\\n=== Running experiment with pretrain_epochs={pretrain_epochs} ===\")\n    run_dict = {\n        \"losses\": {\"pretrain\": [], \"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"SCHM\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    # Dataloaders (fresh shuffle each run)\n    pretrain_loader = DataLoader(\n        SPRContrastiveDataset(spr_bench[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_contrastive,\n    )\n    train_loader = DataLoader(\n        SPRClassifierDataset(spr_bench[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_classifier,\n    )\n    dev_loader = DataLoader(\n        SPRClassifierDataset(spr_bench[\"dev\"]),\n        batch_size=256,\n        shuffle=False,\n        collate_fn=collate_classifier,\n    )\n\n    # Model instantiation\n    encoder = Encoder(vocab).to(device)\n    clf_model = Classifier(\n        encoder, num_classes=len(set(spr_bench[\"train\"][\"label\"]))\n    ).to(device)\n\n    # -------- Contrastive pre-training ----------\n    optimizer_pt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n    for ep in range(1, pretrain_epochs + 1):\n        encoder.train()\n        epoch_loss = 0.0\n        for batch in pretrain_loader:\n            optimizer_pt.zero_grad()\n            z1 = encoder(batch[\"ids1\"], batch[\"len1\"])\n            z2 = encoder(batch[\"ids2\"], batch[\"len2\"])\n            loss = nt_xent_loss(z1, z2)\n            loss.backward()\n            optimizer_pt.step()\n            epoch_loss += loss.item() * batch[\"ids1\"].size(0)\n        epoch_loss /= len(pretrain_loader.dataset)\n        run_dict[\"losses\"][\"pretrain\"].append(epoch_loss)\n        print(f\"  Pretrain epoch {ep}/{pretrain_epochs} loss={epoch_loss:.4f}\")\n\n    # --------------- Fine-tuning ----------------\n    optimizer_ft = torch.optim.Adam(clf_model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n    ft_epochs = 3\n    for ep in range(1, ft_epochs + 1):\n        # train\n        clf_model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            optimizer_ft.zero_grad()\n            logits = clf_model(batch[\"ids\"], batch[\"len\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer_ft.step()\n            running_loss += loss.item() * batch[\"ids\"].size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        run_dict[\"losses\"][\"train\"].append(train_loss)\n        # evaluate\n        clf_model.eval()\n        val_loss = 0.0\n        all_pred = []\n        all_true = []\n        all_seq = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                logits = clf_model(batch[\"ids\"], batch[\"len\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss += loss.item() * batch[\"ids\"].size(0)\n                preds = logits.argmax(1).cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(batch[\"label\"].cpu().tolist())\n                all_seq.extend(batch[\"sequence\"])\n        val_loss /= len(dev_loader.dataset)\n        run_dict[\"losses\"][\"val\"].append(val_loss)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        schm = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        run_dict[\"metrics\"][\"SWA\"].append(swa)\n        run_dict[\"metrics\"][\"CWA\"].append(cwa)\n        run_dict[\"metrics\"][\"SCHM\"].append(schm)\n        print(\n            f\"  FT epoch {ep}/{ft_epochs} train_loss={train_loss:.4f} val_loss={val_loss:.4f} | SWA={swa:.3f} CWA={cwa:.3f} SCHM={schm:.3f}\"\n        )\n\n    # store final preds/gt from last epoch\n    run_dict[\"predictions\"] = all_pred\n    run_dict[\"ground_truth\"] = all_true\n    experiment_data[\"pretrain_epochs\"][\"SPR_BENCH\"][str(pretrain_epochs)] = run_dict\n\n    # plot loss curves for this run\n    plt.figure()\n    plt.plot(run_dict[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(run_dict[\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"FT Loss (pretrain_epochs={pretrain_epochs})\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_ep{pretrain_epochs}.png\"))\n    plt.close()\n\n    # free memory\n    del encoder, clf_model, optimizer_pt, optimizer_ft\n    torch.cuda.empty_cache()\n    gc.collect()\n\n# --------------- Save experiment data ----------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment data and plots to ./working/\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, random, math, time, json, gc\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\nimport matplotlib.pyplot as plt\n\n# ------------------------- I/O -----------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------- Device --------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ---------------------- Data loading -----------------------\nfrom datasets import load_dataset, DatasetDict\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    d = DatasetDict()\n    for s in [\"train\", \"dev\", \"test\"]:\n        d[s] = _load(f\"{s}.csv\")\n    return d\n\n\ndata_root_candidates = [\n    pathlib.Path(\"SPR_BENCH\"),\n    pathlib.Path(\"./data/SPR_BENCH\"),\n    pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n]\nspr_bench = None\nfor p in data_root_candidates:\n    if (p / \"train.csv\").exists():\n        spr_bench = load_spr_bench(p)\n        print(f\"Loaded data from {p}\")\n        break\nif spr_bench is None:\n    print(\"SPR_BENCH not found, generating synthetic data.\")\n\n    def synth(n):\n        seqs, labels = [], []\n        shapes, colors = \"ABCD\", \"1234\"\n        for _ in range(n):\n            L = random.randint(4, 9)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(L)\n            )\n            seqs.append(seq)\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    spr_bench = DatasetDict()\n    for split, n in [(\"train\", 500), (\"dev\", 100), (\"test\", 100)]:\n        spr_bench[split] = load_dataset(\n            \"json\", data_files={\"train\": None}, split=\"train\", data=synth(n)\n        )\n\n\ndef tokenize(seq):\n    return seq.strip().split()\n\n\n# ---------------------- Vocabulary -------------------------\nvocab = {\"<PAD>\": 0, \"<MASK>\": 1}\nfor split in spr_bench.values():\n    for seq in split[\"sequence\"]:\n        for tok in tokenize(seq):\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\nvocab_size = len(vocab)\nmask_id = vocab[\"<MASK>\"]\nprint(\"Vocab size:\", vocab_size)\n\n\n# ---------------------- Metrics ----------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wi if yt == yp else 0 for wi, yt, yp in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# --------------------- Datasets ----------------------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def _augment(self, toks, p=0.15):\n        out = [t for t in toks if random.random() >= p]\n        if not out:\n            out = [random.choice(toks)]\n        return out\n\n    def __getitem__(self, idx):\n        toks = tokenize(self.seqs[idx])\n        return self._augment(toks), self._augment(toks)\n\n\nclass SPRClassifierDataset(Dataset):\n    def __init__(self, hf_ds):\n        self.seqs = hf_ds[\"sequence\"]\n        self.labels = hf_ds[\"label\"]\n\n    def __len__(self):\n        return len(self.seqs)\n\n    def __getitem__(self, idx):\n        return tokenize(self.seqs[idx]), self.labels[idx], self.seqs[idx]\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n\n    def encode(tok_list):\n        ids = [\n            torch.tensor([vocab[t] for t in toks], dtype=torch.long)\n            for toks in tok_list\n        ]\n        lens = [len(i) for i in ids]\n        ids = pad_sequence(ids, batch_first=True, padding_value=0)\n        return ids.to(device), torch.tensor(lens, dtype=torch.long).to(device)\n\n    ids1, len1 = encode(v1)\n    ids2, len2 = encode(v2)\n    return {\"ids1\": ids1, \"len1\": len1, \"ids2\": ids2, \"len2\": len2}\n\n\ndef collate_classifier(batch):\n    toks, labels, raw_seq = zip(*batch)\n    ids = [torch.tensor([vocab[t] for t in t], dtype=torch.long) for t in toks]\n    lens = [len(i) for i in ids]\n    ids = pad_sequence(ids, batch_first=True, padding_value=0).to(device)\n    return {\n        \"ids\": ids,\n        \"len\": torch.tensor(lens, dtype=torch.long).to(device),\n        \"label\": torch.tensor(labels, dtype=torch.long).to(device),\n        \"sequence\": raw_seq,\n    }\n\n\n# ---------------------- Model ------------------------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab, emb_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(len(vocab), emb_dim, padding_idx=0)\n        self.gru = nn.GRU(emb_dim, hidden, batch_first=True, bidirectional=True)\n        self.proj = nn.Linear(hidden * 2, hidden)\n\n    def forward(self, ids, lens):\n        x = self.emb(ids)\n        packed = pack_padded_sequence(\n            x, lens.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)\n        h = torch.cat([h[-2], h[-1]], dim=1)\n        return self.proj(h)\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(encoder.proj.out_features, num_classes)\n\n    def forward(self, ids, lens):\n        return self.head(self.encoder(ids, lens))\n\n\n# ---------------- Contrastive loss -------------------------\ndef nt_xent_loss(z1, z2, temp=0.5):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    N = z1.size(0)\n    z = torch.cat([z1, z2], dim=0)\n    sim = torch.matmul(z, z.T) / temp\n    mask = torch.eye(2 * N, dtype=torch.bool, device=z.device)\n    sim.masked_fill_(mask, -9e15)\n    targets = torch.arange(N, 2 * N, device=z.device)\n    logits_12 = sim[:N, N:]\n    logits_21 = sim[N:, :N]\n    denom_12 = torch.logsumexp(sim[:N], dim=1)\n    denom_21 = torch.logsumexp(sim[N:], dim=1)\n    loss = (-logits_12.diag() + denom_12 + -logits_21.diag() + denom_21).mean() * 0.5\n    return loss\n\n\n# ---------------- Experiment container ---------------------\nexperiment_data = {\"pretrain_epochs\": {\"SPR_BENCH\": {}}}\n\n# ------------- Hyperparameter values to try ----------------\nepoch_settings = [2, 4, 6, 8, 10]\n\nfor pretrain_epochs in epoch_settings:\n    print(f\"\\n=== Running experiment with pretrain_epochs={pretrain_epochs} ===\")\n    run_dict = {\n        \"losses\": {\"pretrain\": [], \"train\": [], \"val\": []},\n        \"metrics\": {\"SWA\": [], \"CWA\": [], \"SCHM\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    # Dataloaders (fresh shuffle each run)\n    pretrain_loader = DataLoader(\n        SPRContrastiveDataset(spr_bench[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_contrastive,\n    )\n    train_loader = DataLoader(\n        SPRClassifierDataset(spr_bench[\"train\"]),\n        batch_size=128,\n        shuffle=True,\n        collate_fn=collate_classifier,\n    )\n    dev_loader = DataLoader(\n        SPRClassifierDataset(spr_bench[\"dev\"]),\n        batch_size=256,\n        shuffle=False,\n        collate_fn=collate_classifier,\n    )\n\n    # Model instantiation\n    encoder = Encoder(vocab).to(device)\n    clf_model = Classifier(\n        encoder, num_classes=len(set(spr_bench[\"train\"][\"label\"]))\n    ).to(device)\n\n    # -------- Contrastive pre-training ----------\n    optimizer_pt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n    for ep in range(1, pretrain_epochs + 1):\n        encoder.train()\n        epoch_loss = 0.0\n        for batch in pretrain_loader:\n            optimizer_pt.zero_grad()\n            z1 = encoder(batch[\"ids1\"], batch[\"len1\"])\n            z2 = encoder(batch[\"ids2\"], batch[\"len2\"])\n            loss = nt_xent_loss(z1, z2)\n            loss.backward()\n            optimizer_pt.step()\n            epoch_loss += loss.item() * batch[\"ids1\"].size(0)\n        epoch_loss /= len(pretrain_loader.dataset)\n        run_dict[\"losses\"][\"pretrain\"].append(epoch_loss)\n        print(f\"  Pretrain epoch {ep}/{pretrain_epochs} loss={epoch_loss:.4f}\")\n\n    # --------------- Fine-tuning ----------------\n    optimizer_ft = torch.optim.Adam(clf_model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n    ft_epochs = 3\n    for ep in range(1, ft_epochs + 1):\n        # train\n        clf_model.train()\n        running_loss = 0.0\n        for batch in train_loader:\n            optimizer_ft.zero_grad()\n            logits = clf_model(batch[\"ids\"], batch[\"len\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer_ft.step()\n            running_loss += loss.item() * batch[\"ids\"].size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        run_dict[\"losses\"][\"train\"].append(train_loss)\n        # evaluate\n        clf_model.eval()\n        val_loss = 0.0\n        all_pred = []\n        all_true = []\n        all_seq = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                logits = clf_model(batch[\"ids\"], batch[\"len\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss += loss.item() * batch[\"ids\"].size(0)\n                preds = logits.argmax(1).cpu().tolist()\n                all_pred.extend(preds)\n                all_true.extend(batch[\"label\"].cpu().tolist())\n                all_seq.extend(batch[\"sequence\"])\n        val_loss /= len(dev_loader.dataset)\n        run_dict[\"losses\"][\"val\"].append(val_loss)\n        swa = shape_weighted_accuracy(all_seq, all_true, all_pred)\n        cwa = color_weighted_accuracy(all_seq, all_true, all_pred)\n        schm = 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n        run_dict[\"metrics\"][\"SWA\"].append(swa)\n        run_dict[\"metrics\"][\"CWA\"].append(cwa)\n        run_dict[\"metrics\"][\"SCHM\"].append(schm)\n        print(\n            f\"  FT epoch {ep}/{ft_epochs} train_loss={train_loss:.4f} val_loss={val_loss:.4f} | SWA={swa:.3f} CWA={cwa:.3f} SCHM={schm:.3f}\"\n        )\n\n    # store final preds/gt from last epoch\n    run_dict[\"predictions\"] = all_pred\n    run_dict[\"ground_truth\"] = all_true\n    experiment_data[\"pretrain_epochs\"][\"SPR_BENCH\"][str(pretrain_epochs)] = run_dict\n\n    # plot loss curves for this run\n    plt.figure()\n    plt.plot(run_dict[\"losses\"][\"train\"], label=\"train\")\n    plt.plot(run_dict[\"losses\"][\"val\"], label=\"val\")\n    plt.title(f\"FT Loss (pretrain_epochs={pretrain_epochs})\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"loss_curve_ep{pretrain_epochs}.png\"))\n    plt.close()\n\n    # free memory\n    del encoder, clf_model, optimizer_pt, optimizer_ft\n    torch.cuda.empty_cache()\n    gc.collect()\n\n# --------------- Save experiment data ----------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment data and plots to ./working/\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating synthetic toy\ndata.', '\\n', 'Traceback (most recent call last):\\n  File \"runfile.py\", line 83,\nin <module>\\n    spr_bench[split] = load_dataset(\\n\n^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 2062, in load_dataset\\n    builder_instance =\nload_dataset_builder(\\n                       ^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1782, in load_dataset_builder\\n\ndataset_module = dataset_module_factory(\\n\n^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1497, in dataset_module_factory\\n\n).get_module()\\n      ^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 913, in get_module\\n    data_files =\nDataFilesDict.from_patterns(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\nFile \"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 690, in from_patterns\\n    else\nDataFilesList.from_patterns(\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 583, in from_patterns\\n\nresolve_pattern(\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 346, in resolve_pattern\\n    elif\nis_local_path(pattern):\\n         ^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/utils/file_utils.py\", line 84, in is_local_path\\n    return\nurlparse(url_or_filename).scheme == \"\" or\nos.path.ismount(urlparse(url_or_filename).scheme + \":/\")\\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~\\nTypeError: can\\'t concat str to\nbytes\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 20000 examples [00:00,\n467563.75 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 575603.01\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 709756.16\nexamples/s]', '\\n', 'Loaded dataset from', ' ', '/home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size =', ' ', '18', '\\n', '\\n=============\nFine-tune LR = 1.0e-03 =============', '\\n', '  Pretrain  ep1: loss=5.2713',\n'\\n', '  Pretrain  ep2: loss=4.8909', '\\n', '  Finetune ep1: train=0.2706\nval=0.1666 | SWA=0.950 CWA=0.948 SCHM=0.949', '\\n', '  Finetune ep2:\ntrain=0.0952 val=0.0434 | SWA=0.990 CWA=0.990 SCHM=0.990', '\\n', '  Finetune\nep3: train=0.0330 val=0.0156 | SWA=0.995 CWA=0.996 SCHM=0.995', '\\n',\n'\\n============= Fine-tune LR = 5.0e-04 =============', '\\n', '  Pretrain  ep1:\nloss=5.2713', '\\n', '  Pretrain  ep2: loss=4.8909', '\\n', '  Finetune ep1:\ntrain=0.3331 val=0.1763 | SWA=0.947 CWA=0.944 SCHM=0.945', '\\n', '  Finetune\nep2: train=0.1553 val=0.1428 | SWA=0.958 CWA=0.956 SCHM=0.957', '\\n', '\nFinetune ep3: train=0.1121 val=0.0701 | SWA=0.983 CWA=0.983 SCHM=0.983', '\\n',\n'\\n============= Fine-tune LR = 3.0e-04 =============', '\\n', '  Pretrain  ep1:\nloss=5.2713', '\\n', '  Pretrain  ep2: loss=4.8909', '\\n', '  Finetune ep1:\ntrain=0.4003 val=0.1963 | SWA=0.938 CWA=0.935 SCHM=0.936', '\\n', '  Finetune\nep2: train=0.1737 val=0.1617 | SWA=0.954 CWA=0.952 SCHM=0.953', '\\n', '\nFinetune ep3: train=0.1501 val=0.1460 | SWA=0.960 CWA=0.959 SCHM=0.959', '\\n',\n'\\n============= Fine-tune LR = 1.0e-04 =============', '\\n', '  Pretrain  ep1:\nloss=5.2713', '\\n', '  Pretrain  ep2: loss=4.8909', '\\n', '  Finetune ep1:\ntrain=0.6038 val=0.4032 | SWA=0.829 CWA=0.823 SCHM=0.826', '\\n', '  Finetune\nep2: train=0.2812 val=0.2193 | SWA=0.928 CWA=0.924 SCHM=0.926', '\\n', '\nFinetune ep3: train=0.1972 val=0.1839 | SWA=0.942 CWA=0.939 SCHM=0.940', '\\n',\n'Saved logs & plots to', ' ', '/home/zxl240011/AI-Scientist-v2/experiments/2025-\n08-15_22-24-43_context_aware_contrastive_learning_attempt_0/0-\nrun/process_ForkProcess-11/working', '\\n', 'Execution time: 21 seconds seconds\n(time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 395455.89\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 541773.75\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 700627.08\nexamples/s]', '\\n', 'Loaded data from /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size:', ' ', '18', '\\n', '\\n=== Running\nexperiment with pretrain_epochs=2 ===', '\\n', '  Pretrain epoch 1/2\nloss=4.0418', '\\n', '  Pretrain epoch 2/2 loss=4.0178', '\\n', '  FT epoch 1/3\ntrain_loss=0.1954 val_loss=0.1197 | SWA=0.966 CWA=0.964 SCHM=0.965', '\\n', '  FT\nepoch 2/3 train_loss=0.0517 val_loss=0.0222 | SWA=0.994 CWA=0.995 SCHM=0.994',\n'\\n', '  FT epoch 3/3 train_loss=0.0152 val_loss=0.0112 | SWA=0.997 CWA=0.998\nSCHM=0.997', '\\n', '\\n=== Running experiment with pretrain_epochs=4 ===', '\\n',\n'  Pretrain epoch 1/4 loss=4.0387', '\\n', '  Pretrain epoch 2/4 loss=4.0166',\n'\\n', '  Pretrain epoch 3/4 loss=4.0127', '\\n', '  Pretrain epoch 4/4\nloss=4.0134', '\\n', '  FT epoch 1/3 train_loss=0.1910 val_loss=0.1038 |\nSWA=0.970 CWA=0.969 SCHM=0.969', '\\n', '  FT epoch 2/3 train_loss=0.0479\nval_loss=0.0165 | SWA=0.993 CWA=0.993 SCHM=0.993', '\\n', '  FT epoch 3/3\ntrain_loss=0.0106 val_loss=0.0127 | SWA=0.995 CWA=0.995 SCHM=0.995', '\\n',\n'\\n=== Running experiment with pretrain_epochs=6 ===', '\\n', '  Pretrain epoch\n1/6 loss=4.0394', '\\n', '  Pretrain epoch 2/6 loss=4.0214', '\\n', '  Pretrain\nepoch 3/6 loss=4.0164', '\\n', '  Pretrain epoch 4/6 loss=4.0101', '\\n', '\nPretrain epoch 5/6 loss=4.0104', '\\n', '  Pretrain epoch 6/6 loss=4.0115', '\\n',\n'  FT epoch 1/3 train_loss=0.1891 val_loss=0.1088 | SWA=0.965 CWA=0.964\nSCHM=0.965', '\\n', '  FT epoch 2/3 train_loss=0.0465 val_loss=0.0184 | SWA=0.992\nCWA=0.993 SCHM=0.992', '\\n', '  FT epoch 3/3 train_loss=0.0101 val_loss=0.0060 |\nSWA=0.998 CWA=0.999 SCHM=0.999', '\\n', '\\n=== Running experiment with\npretrain_epochs=8 ===', '\\n', '  Pretrain epoch 1/8 loss=4.0439', '\\n', '\nPretrain epoch 2/8 loss=4.0162', '\\n', '  Pretrain epoch 3/8 loss=4.0157', '\\n',\n'  Pretrain epoch 4/8 loss=4.0128', '\\n', '  Pretrain epoch 5/8 loss=4.0087',\n'\\n', '  Pretrain epoch 6/8 loss=4.0084', '\\n', '  Pretrain epoch 7/8\nloss=4.0099', '\\n', '  Pretrain epoch 8/8 loss=4.0036', '\\n', '  FT epoch 1/3\ntrain_loss=0.1913 val_loss=0.0911 | SWA=0.976 CWA=0.977 SCHM=0.976', '\\n', '  FT\nepoch 2/3 train_loss=0.0391 val_loss=0.0177 | SWA=0.995 CWA=0.995 SCHM=0.995',\n'\\n', '  FT epoch 3/3 train_loss=0.0088 val_loss=0.0114 | SWA=0.996 CWA=0.996\nSCHM=0.996', '\\n', '\\n=== Running experiment with pretrain_epochs=10 ===', '\\n',\n'  Pretrain epoch 1/10 loss=4.0433', '\\n', '  Pretrain epoch 2/10 loss=4.0201',\n'\\n', '  Pretrain epoch 3/10 loss=4.0163', '\\n', '  Pretrain epoch 4/10\nloss=4.0120', '\\n', '  Pretrain epoch 5/10 loss=4.0079', '\\n', '  Pretrain epoch\n6/10 loss=4.0100', '\\n', '  Pretrain epoch 7/10 loss=4.0091', '\\n', '  Pretrain\nepoch 8/10 loss=4.0085', '\\n', '  Pretrain epoch 9/10 loss=4.0059', '\\n', '\nPretrain epoch 10/10 loss=4.0024', '\\n', '  FT epoch 1/3 train_loss=0.1581\nval_loss=0.0585 | SWA=0.988 CWA=0.989 SCHM=0.988', '\\n', '  FT epoch 2/3\ntrain_loss=0.0255 val_loss=0.0125 | SWA=0.996 CWA=0.996 SCHM=0.996', '\\n', '  FT\nepoch 3/3 train_loss=0.0049 val_loss=0.0087 | SWA=0.997 CWA=0.997 SCHM=0.997',\n'\\n', '\\nSaved experiment data and plots to ./working/', '\\n', 'Execution time:\na minute seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found, generating synthetic\ndata.', '\\n', 'Traceback (most recent call last):\\n  File \"runfile.py\", line 56,\nin <module>\\n    spr_bench[split] = load_dataset(\\n\n^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 2062, in load_dataset\\n    builder_instance =\nload_dataset_builder(\\n                       ^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1782, in load_dataset_builder\\n\ndataset_module = dataset_module_factory(\\n\n^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1497, in dataset_module_factory\\n\n).get_module()\\n      ^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 913, in get_module\\n    data_files =\nDataFilesDict.from_patterns(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\nFile \"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 690, in from_patterns\\n    else\nDataFilesList.from_patterns(\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 583, in from_patterns\\n\nresolve_pattern(\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 346, in resolve_pattern\\n    elif\nis_local_path(pattern):\\n         ^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/utils/file_utils.py\", line 84, in is_local_path\\n    return\nurlparse(url_or_filename).scheme == \"\" or\nos.path.ismount(urlparse(url_or_filename).scheme + \":/\")\\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~\\nTypeError: can\\'t concat str to\nbytes\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'SPR_BENCH not found \u2013 generating synthetic toy\ndata.', '\\n', 'Vocabulary size = 17', '\\n', 'Pre-train epoch 1/2: loss=4.0856',\n'\\n', 'Pre-train epoch 2/2: loss=4.0120', '\\n', 'Epoch 1: train_loss=0.7185\nval_loss=0.6880 SWA=0.550 CWA=0.546 ACS=0.793 SCHM=0.548', '\\n', 'Epoch 2:\ntrain_loss=0.6787 val_loss=0.6832 SWA=0.573 CWA=0.568 ACS=0.793 SCHM=0.570',\n'\\n', 'Epoch 3: train_loss=0.6705 val_loss=0.6886 SWA=0.558 CWA=0.554 ACS=0.753\nSCHM=0.556', '\\n', 'Epoch 4: train_loss=0.6468 val_loss=0.7007 SWA=0.528\nCWA=0.516 ACS=0.693 SCHM=0.522', '\\n', 'Epoch 5: train_loss=0.6360\nval_loss=0.7069 SWA=0.542 CWA=0.534 ACS=0.720 SCHM=0.538', '\\n', 'Early stopping\ntriggered.', '\\n', 'Training complete. Artifacts saved to ./working/', '\\n',\n'Execution time: 3 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 326810.63\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 653114.92\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 818097.49\nexamples/s]', '\\n', 'Loaded data from /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size = 18', '\\n', '[WD=0.0] Pretrain epoch\n1: 5.2542', '\\n', '[WD=0.0] Pretrain epoch 2: 4.8936', '\\n', '[WD=0.0] FT epoch\n1: train=0.2613 val=0.1775 | SWA=0.951 CWA=0.949 SCHM=0.950', '\\n', '[WD=0.0] FT\nepoch 2: train=0.1038 val=0.0522 | SWA=0.987 CWA=0.987 SCHM=0.987', '\\n',\n'[WD=0.0] FT epoch 3: train=0.0387 val=0.0291 | SWA=0.992 CWA=0.993 SCHM=0.992',\n'\\n', '[WD=1e-05] Pretrain epoch 1: 5.2295', '\\n', '[WD=1e-05] Pretrain epoch 2:\n4.8796', '\\n', '[WD=1e-05] FT epoch 1: train=0.2179 val=0.0844 | SWA=0.975\nCWA=0.974 SCHM=0.975', '\\n', '[WD=1e-05] FT epoch 2: train=0.0616 val=0.0400 |\nSWA=0.988 CWA=0.988 SCHM=0.988', '\\n', '[WD=1e-05] FT epoch 3: train=0.0307\nval=0.0283 | SWA=0.991 CWA=0.991 SCHM=0.991', '\\n', '[WD=0.0001] Pretrain epoch\n1: 5.2553', '\\n', '[WD=0.0001] Pretrain epoch 2: 4.9188', '\\n', '[WD=0.0001] FT\nepoch 1: train=0.2987 val=0.1717 | SWA=0.951 CWA=0.948 SCHM=0.950', '\\n',\n'[WD=0.0001] FT epoch 2: train=0.1119 val=0.0473 | SWA=0.986 CWA=0.987\nSCHM=0.987', '\\n', '[WD=0.0001] FT epoch 3: train=0.0390 val=0.0218 | SWA=0.993\nCWA=0.993 SCHM=0.993', '\\n', '[WD=0.001] Pretrain epoch 1: 5.1845', '\\n',\n'[WD=0.001] Pretrain epoch 2: 4.9233', '\\n', '[WD=0.001] FT epoch 1:\ntrain=0.2445 val=0.1941 | SWA=0.949 CWA=0.948 SCHM=0.948', '\\n', '[WD=0.001] FT\nepoch 2: train=0.1140 val=0.0655 | SWA=0.981 CWA=0.981 SCHM=0.981', '\\n',\n'[WD=0.001] FT epoch 3: train=0.0552 val=0.0487 | SWA=0.988 CWA=0.987\nSCHM=0.987', '\\n', 'Saved experiment data and plots in ./working/', '\\n',\n'Execution time: 22 seconds seconds (time limit is 30 minutes).']", "['Using device:', ' ', 'cuda', '\\n', 'SPR_BENCH not found, creating synthetic\ndataset.', '\\n', 'Traceback (most recent call last):\\n  File \"runfile.py\", line\n80, in <module>\\n    spr_bench[split] = load_dataset(\\n\n^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 2062, in load_dataset\\n    builder_instance =\nload_dataset_builder(\\n                       ^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1782, in load_dataset_builder\\n\ndataset_module = dataset_module_factory(\\n\n^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1497, in dataset_module_factory\\n\n).get_module()\\n      ^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 913, in get_module\\n    data_files =\nDataFilesDict.from_patterns(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\nFile \"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 690, in from_patterns\\n    else\nDataFilesList.from_patterns(\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 583, in from_patterns\\n\nresolve_pattern(\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 346, in resolve_pattern\\n    elif\nis_local_path(pattern):\\n         ^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/utils/file_utils.py\", line 84, in is_local_path\\n    return\nurlparse(url_or_filename).scheme == \"\" or\nos.path.ismount(urlparse(url_or_filename).scheme + \":/\")\\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~\\nTypeError: can\\'t concat str to\nbytes\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Device:', ' ', 'cuda', '\\n', 'Dataset not found, creating tiny synthetic.',\n'\\n', 'Traceback (most recent call last):\\n  File \"runfile.py\", line 76, in\n<module>\\n    spr_bench[split] = load_dataset(\\n\n^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 2062, in load_dataset\\n    builder_instance =\nload_dataset_builder(\\n                       ^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1782, in load_dataset_builder\\n\ndataset_module = dataset_module_factory(\\n\n^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1497, in dataset_module_factory\\n\n).get_module()\\n      ^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 913, in get_module\\n    data_files =\nDataFilesDict.from_patterns(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\nFile \"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 690, in from_patterns\\n    else\nDataFilesList.from_patterns(\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 583, in from_patterns\\n\nresolve_pattern(\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 346, in resolve_pattern\\n    elif\nis_local_path(pattern):\\n         ^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/utils/file_utils.py\", line 84, in is_local_path\\n    return\nurlparse(url_or_filename).scheme == \"\" or\nos.path.ismount(urlparse(url_or_filename).scheme + \":/\")\\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~\\nTypeError: can\\'t concat str to\nbytes\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded data from /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size:', ' ', '18', '\\n', '\\n=== Running\nexperiment with pretrain_epochs=2 ===', '\\n', '  Pretrain epoch 1/2\nloss=4.0424', '\\n', '  Pretrain epoch 2/2 loss=4.0243', '\\n', '  FT epoch 1/3\ntrain_loss=0.1930 val_loss=0.1405 | SWA=0.958 CWA=0.956 SCHM=0.957', '\\n', '  FT\nepoch 2/3 train_loss=0.0573 val_loss=0.0239 | SWA=0.993 CWA=0.993 SCHM=0.993',\n'\\n', '  FT epoch 3/3 train_loss=0.0144 val_loss=0.0074 | SWA=0.997 CWA=0.997\nSCHM=0.997', '\\n', '\\n=== Running experiment with pretrain_epochs=4 ===', '\\n',\n'  Pretrain epoch 1/4 loss=4.0427', '\\n', '  Pretrain epoch 2/4 loss=4.0199',\n'\\n', '  Pretrain epoch 3/4 loss=4.0210', '\\n', '  Pretrain epoch 4/4\nloss=4.0133', '\\n', '  FT epoch 1/3 train_loss=0.1876 val_loss=0.0958 |\nSWA=0.974 CWA=0.974 SCHM=0.974', '\\n', '  FT epoch 2/3 train_loss=0.0420\nval_loss=0.0178 | SWA=0.994 CWA=0.995 SCHM=0.994', '\\n', '  FT epoch 3/3\ntrain_loss=0.0113 val_loss=0.0093 | SWA=0.997 CWA=0.997 SCHM=0.997', '\\n',\n'\\n=== Running experiment with pretrain_epochs=6 ===', '\\n', '  Pretrain epoch\n1/6 loss=4.0375', '\\n', '  Pretrain epoch 2/6 loss=4.0200', '\\n', '  Pretrain\nepoch 3/6 loss=4.0175', '\\n', '  Pretrain epoch 4/6 loss=4.0138', '\\n', '\nPretrain epoch 5/6 loss=4.0124', '\\n', '  Pretrain epoch 6/6 loss=4.0084', '\\n',\n'  FT epoch 1/3 train_loss=0.1873 val_loss=0.0893 | SWA=0.968 CWA=0.969\nSCHM=0.969', '\\n', '  FT epoch 2/3 train_loss=0.0331 val_loss=0.0234 | SWA=0.993\nCWA=0.994 SCHM=0.994', '\\n', '  FT epoch 3/3 train_loss=0.0097 val_loss=0.0084 |\nSWA=0.998 CWA=0.998 SCHM=0.998', '\\n', '\\n=== Running experiment with\npretrain_epochs=8 ===', '\\n', '  Pretrain epoch 1/8 loss=4.0384', '\\n', '\nPretrain epoch 2/8 loss=4.0159', '\\n', '  Pretrain epoch 3/8 loss=4.0197', '\\n',\n'  Pretrain epoch 4/8 loss=4.0109', '\\n', '  Pretrain epoch 5/8 loss=4.0086',\n'\\n', '  Pretrain epoch 6/8 loss=4.0120', '\\n', '  Pretrain epoch 7/8\nloss=4.0062', '\\n', '  Pretrain epoch 8/8 loss=4.0067', '\\n', '  FT epoch 1/3\ntrain_loss=0.1697 val_loss=0.0549 | SWA=0.984 CWA=0.984 SCHM=0.984', '\\n', '  FT\nepoch 2/3 train_loss=0.0302 val_loss=0.0194 | SWA=0.994 CWA=0.995 SCHM=0.994',\n'\\n', '  FT epoch 3/3 train_loss=0.0066 val_loss=0.0057 | SWA=0.997 CWA=0.998\nSCHM=0.998', '\\n', '\\n=== Running experiment with pretrain_epochs=10 ===', '\\n',\n'  Pretrain epoch 1/10 loss=4.0385', '\\n', '  Pretrain epoch 2/10 loss=4.0176',\n'\\n', '  Pretrain epoch 3/10 loss=4.0151', '\\n', '  Pretrain epoch 4/10\nloss=4.0128', '\\n', '  Pretrain epoch 5/10 loss=4.0113', '\\n', '  Pretrain epoch\n6/10 loss=4.0100', '\\n', '  Pretrain epoch 7/10 loss=4.0088', '\\n', '  Pretrain\nepoch 8/10 loss=4.0095', '\\n', '  Pretrain epoch 9/10 loss=4.0060', '\\n', '\nPretrain epoch 10/10 loss=4.0056', '\\n', '  FT epoch 1/3 train_loss=0.1612\nval_loss=0.0475 | SWA=0.984 CWA=0.985 SCHM=0.985', '\\n', '  FT epoch 2/3\ntrain_loss=0.0218 val_loss=0.0107 | SWA=0.996 CWA=0.996 SCHM=0.996', '\\n', '  FT\nepoch 3/3 train_loss=0.0035 val_loss=0.0045 | SWA=0.999 CWA=0.998 SCHM=0.999',\n'\\n', '\\nSaved experiment data and plots to ./working/', '\\n', 'Execution time:\na minute seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Loaded data from /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size:', ' ', '18', '\\n', '\\n=== Running\nexperiment with pretrain_epochs=2 ===', '\\n', '  Pretrain epoch 1/2\nloss=4.0459', '\\n', '  Pretrain epoch 2/2 loss=4.0195', '\\n', '  FT epoch 1/3\ntrain_loss=0.1833 val_loss=0.0982 | SWA=0.967 CWA=0.967 SCHM=0.967', '\\n', '  FT\nepoch 2/3 train_loss=0.0393 val_loss=0.0128 | SWA=0.996 CWA=0.996 SCHM=0.996',\n'\\n', '  FT epoch 3/3 train_loss=0.0087 val_loss=0.0102 | SWA=0.996 CWA=0.997\nSCHM=0.996', '\\n', '\\n=== Running experiment with pretrain_epochs=4 ===', '\\n',\n'  Pretrain epoch 1/4 loss=4.0429', '\\n', '  Pretrain epoch 2/4 loss=4.0192',\n'\\n', '  Pretrain epoch 3/4 loss=4.0164', '\\n', '  Pretrain epoch 4/4\nloss=4.0124', '\\n', '  FT epoch 1/3 train_loss=0.1907 val_loss=0.1049 |\nSWA=0.967 CWA=0.966 SCHM=0.967', '\\n', '  FT epoch 2/3 train_loss=0.0463\nval_loss=0.0169 | SWA=0.996 CWA=0.996 SCHM=0.996', '\\n', '  FT epoch 3/3\ntrain_loss=0.0105 val_loss=0.0087 | SWA=0.997 CWA=0.997 SCHM=0.997', '\\n',\n'\\n=== Running experiment with pretrain_epochs=6 ===', '\\n', '  Pretrain epoch\n1/6 loss=4.0460', '\\n', '  Pretrain epoch 2/6 loss=4.0156', '\\n', '  Pretrain\nepoch 3/6 loss=4.0159', '\\n', '  Pretrain epoch 4/6 loss=4.0117', '\\n', '\nPretrain epoch 5/6 loss=4.0099', '\\n', '  Pretrain epoch 6/6 loss=4.0071', '\\n',\n'  FT epoch 1/3 train_loss=0.1816 val_loss=0.0583 | SWA=0.983 CWA=0.983\nSCHM=0.983', '\\n', '  FT epoch 2/3 train_loss=0.0303 val_loss=0.0159 | SWA=0.996\nCWA=0.995 SCHM=0.995', '\\n', '  FT epoch 3/3 train_loss=0.0049 val_loss=0.0055 |\nSWA=0.998 CWA=0.998 SCHM=0.998', '\\n', '\\n=== Running experiment with\npretrain_epochs=8 ===', '\\n', '  Pretrain epoch 1/8 loss=4.0425', '\\n', '\nPretrain epoch 2/8 loss=4.0173', '\\n', '  Pretrain epoch 3/8 loss=4.0169', '\\n',\n'  Pretrain epoch 4/8 loss=4.0140', '\\n', '  Pretrain epoch 5/8 loss=4.0133',\n'\\n', '  Pretrain epoch 6/8 loss=4.0095', '\\n', '  Pretrain epoch 7/8\nloss=4.0071', '\\n', '  Pretrain epoch 8/8 loss=4.0030', '\\n', '  FT epoch 1/3\ntrain_loss=0.1871 val_loss=0.0835 | SWA=0.975 CWA=0.975 SCHM=0.975', '\\n', '  FT\nepoch 2/3 train_loss=0.0376 val_loss=0.0113 | SWA=0.998 CWA=0.998 SCHM=0.998',\n'\\n', '  FT epoch 3/3 train_loss=0.0067 val_loss=0.0071 | SWA=0.997 CWA=0.997\nSCHM=0.997', '\\n', '\\n=== Running experiment with pretrain_epochs=10 ===', '\\n',\n'  Pretrain epoch 1/10 loss=4.0398', '\\n', '  Pretrain epoch 2/10 loss=4.0170',\n'\\n', '  Pretrain epoch 3/10 loss=4.0149', '\\n', '  Pretrain epoch 4/10\nloss=4.0111', '\\n', '  Pretrain epoch 5/10 loss=4.0115', '\\n', '  Pretrain epoch\n6/10 loss=4.0071', '\\n', '  Pretrain epoch 7/10 loss=4.0094', '\\n', '  Pretrain\nepoch 8/10 loss=4.0016', '\\n', '  Pretrain epoch 9/10 loss=4.0091', '\\n', '\nPretrain epoch 10/10 loss=4.0028', '\\n', '  FT epoch 1/3 train_loss=0.1672\nval_loss=0.0430 | SWA=0.988 CWA=0.989 SCHM=0.988', '\\n', '  FT epoch 2/3\ntrain_loss=0.0203 val_loss=0.0083 | SWA=0.998 CWA=0.998 SCHM=0.998', '\\n', '  FT\nepoch 3/3 train_loss=0.0045 val_loss=0.0058 | SWA=0.998 CWA=0.998 SCHM=0.998',\n'\\n', '\\nSaved experiment data and plots to ./working/', '\\n', 'Execution time:\na minute seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 447980.18\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 671239.00\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 624170.96\nexamples/s]', '\\n', 'Loaded data from /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size:', ' ', '18', '\\n', '\\n=== Running\nexperiment with pretrain_epochs=2 ===', '\\n', '  Pretrain epoch 1/2\nloss=4.0378', '\\n', '  Pretrain epoch 2/2 loss=4.0200', '\\n', '  FT epoch 1/3\ntrain_loss=0.1994 val_loss=0.1011 | SWA=0.974 CWA=0.972 SCHM=0.973', '\\n', '  FT\nepoch 2/3 train_loss=0.0473 val_loss=0.0294 | SWA=0.993 CWA=0.993 SCHM=0.993',\n'\\n', '  FT epoch 3/3 train_loss=0.0132 val_loss=0.0113 | SWA=0.998 CWA=0.998\nSCHM=0.998', '\\n', '\\n=== Running experiment with pretrain_epochs=4 ===', '\\n',\n'  Pretrain epoch 1/4 loss=4.0421', '\\n', '  Pretrain epoch 2/4 loss=4.0197',\n'\\n', '  Pretrain epoch 3/4 loss=4.0170', '\\n', '  Pretrain epoch 4/4\nloss=4.0143', '\\n', '  FT epoch 1/3 train_loss=0.1880 val_loss=0.0857 |\nSWA=0.976 CWA=0.975 SCHM=0.976', '\\n', '  FT epoch 2/3 train_loss=0.0428\nval_loss=0.0193 | SWA=0.996 CWA=0.996 SCHM=0.996', '\\n', '  FT epoch 3/3\ntrain_loss=0.0102 val_loss=0.0086 | SWA=0.996 CWA=0.997 SCHM=0.996', '\\n',\n'\\n=== Running experiment with pretrain_epochs=6 ===', '\\n', '  Pretrain epoch\n1/6 loss=4.0417', '\\n', '  Pretrain epoch 2/6 loss=4.0213', '\\n', '  Pretrain\nepoch 3/6 loss=4.0137', '\\n', '  Pretrain epoch 4/6 loss=4.0128', '\\n', '\nPretrain epoch 5/6 loss=4.0089', '\\n', '  Pretrain epoch 6/6 loss=4.0075', '\\n',\n'  FT epoch 1/3 train_loss=0.1654 val_loss=0.0547 | SWA=0.983 CWA=0.981\nSCHM=0.982', '\\n', '  FT epoch 2/3 train_loss=0.0388 val_loss=0.0170 | SWA=0.995\nCWA=0.995 SCHM=0.995', '\\n', '  FT epoch 3/3 train_loss=0.0116 val_loss=0.0046 |\nSWA=0.998 CWA=0.999 SCHM=0.998', '\\n', '\\n=== Running experiment with\npretrain_epochs=8 ===', '\\n', '  Pretrain epoch 1/8 loss=4.0406', '\\n', '\nPretrain epoch 2/8 loss=4.0176', '\\n', '  Pretrain epoch 3/8 loss=4.0137', '\\n',\n'  Pretrain epoch 4/8 loss=4.0081', '\\n', '  Pretrain epoch 5/8 loss=4.0101',\n'\\n', '  Pretrain epoch 6/8 loss=4.0094', '\\n', '  Pretrain epoch 7/8\nloss=4.0120', '\\n', '  Pretrain epoch 8/8 loss=4.0079', '\\n', '  FT epoch 1/3\ntrain_loss=0.1681 val_loss=0.0714 | SWA=0.979 CWA=0.980 SCHM=0.980', '\\n', '  FT\nepoch 2/3 train_loss=0.0319 val_loss=0.0102 | SWA=0.998 CWA=0.998 SCHM=0.998',\n'\\n', '  FT epoch 3/3 train_loss=0.0048 val_loss=0.0037 | SWA=0.999 CWA=0.999\nSCHM=0.999', '\\n', '\\n=== Running experiment with pretrain_epochs=10 ===', '\\n',\n'  Pretrain epoch 1/10 loss=4.0419', '\\n', '  Pretrain epoch 2/10 loss=4.0157',\n'\\n', '  Pretrain epoch 3/10 loss=4.0113', '\\n', '  Pretrain epoch 4/10\nloss=4.0141', '\\n', '  Pretrain epoch 5/10 loss=4.0099', '\\n', '  Pretrain epoch\n6/10 loss=4.0053', '\\n', '  Pretrain epoch 7/10 loss=4.0092', '\\n', '  Pretrain\nepoch 8/10 loss=4.0050', '\\n', '  Pretrain epoch 9/10 loss=4.0057', '\\n', '\nPretrain epoch 10/10 loss=4.0082', '\\n', '  FT epoch 1/3 train_loss=0.1679\nval_loss=0.0754 | SWA=0.975 CWA=0.975 SCHM=0.975', '\\n', '  FT epoch 2/3\ntrain_loss=0.0215 val_loss=0.0115 | SWA=0.997 CWA=0.997 SCHM=0.997', '\\n', '  FT\nepoch 3/3 train_loss=0.0032 val_loss=0.0048 | SWA=0.999 CWA=0.999 SCHM=0.999',\n'\\n', '\\nSaved experiment data and plots to ./working/', '\\n', 'Execution time:\na minute seconds (time limit is 30 minutes).']", ""], "analysis": ["The execution failed due to a TypeError in the synthetic data generation\nprocess. Specifically, in the `load_dataset` function call, the error occurs\nwhen concatenating a string and bytes in the `is_local_path` function. This is\nlikely due to an improper handling of the `data_files` parameter when synthetic\ndata is being passed. To fix this, ensure that the `data_files` parameter in\n`load_dataset` is correctly formatted and does not inadvertently mix string and\nbyte types. Additionally, verify that the synthetic data generation logic is\nproperly integrated with the `load_dataset` function.", "", "", "The execution failed due to a TypeError in the synthetic data generation\nfallback. Specifically, in the 'load_dataset' call for synthetic data creation,\nthe 'data_files' parameter was set to None, which caused the error. The\n'data_files' parameter expects a valid file path or pattern, and passing None\nled to a 'TypeError: can't concat str to bytes'.  Proposed Fix: 1. Replace the\n'data_files' parameter with a valid JSON string or file containing the synthetic\ndata. 2. Modify the 'load_dataset' call for synthetic data to directly use the\ngenerated data dictionary, rather than setting 'data_files' to None. This can be\ndone by using the 'Dataset.from_dict()' method to create the dataset directly\nfrom the synthetic data dictionary.", "The execution of the training script was successful without any bugs. The script\nutilized synthetic data for training since the SPR_BENCH dataset was not found.\nThe pre-training and fine-tuning phases ran as expected, with early stopping\ntriggered after the 5th epoch due to no improvement in validation loss. Metrics\nsuch as Shape-Weighted Accuracy (SWA), Color-Weighted Accuracy (CWA),\nAugmentation Consistency Score (ACS), and Schema Score (SCHM) were calculated\nand showed reasonable values. Artifacts such as the loss curve and best model\nwere saved successfully.", "", "The execution failed due to a TypeError in the synthetic dataset creation\nprocess. Specifically, the error occurred in the `load_dataset` function when\ntrying to create a dataset from synthetic data. The issue lies in the\n`data_files` parameter being set to `{\"train\": None}` in the `load_dataset`\ncall, which is not valid. Additionally, the error traceback indicates a problem\nwhen attempting to concatenate a string with bytes in the `is_local_path`\nfunction.   To fix this issue, replace the `data_files` parameter with valid\nJSON data directly in the `load_dataset` call. Instead of providing `{\"train\":\nNone}`, pass the synthetic dataset directly using the `data` parameter (e.g.,\n`data=synth(n)`). This ensures that the dataset is properly loaded from the\nsynthetic data dictionary.", "The execution failed due to a TypeError in the 'is_local_path' function from the\n'datasets' library. Specifically, the error occurred when attempting to\nconcatenate a string to a byte object while resolving dataset file paths. This\nissue arises because the 'urlparse' function outputs a string, but the code\nattempts to concatenate it with a byte object.  To fix this issue, ensure that\nall components being concatenated are of the same type. You can modify the\nproblematic line in the 'datasets' library code as follows:  Replace: ```python\nos.path.ismount(urlparse(url_or_filename).scheme + \":/\") ``` With: ```python\nos.path.ismount(urlparse(url_or_filename).scheme + \":/\") if\nisinstance(urlparse(url_or_filename).scheme, str) else\nos.path.ismount(urlparse(url_or_filename).scheme.decode() + \":/\") ```\nAlternatively, check if the 'datasets' library has an updated version that\nresolves this bug and update the library using pip.", "The execution of the training script was successful, and there were no bugs or\nfailures observed. The script ran multiple experiments with different\npretraining epochs and fine-tuning phases. The output logs showed consistent\nimprovements in the metrics (Shape-Weighted Accuracy, Color-Weighted Accuracy,\nand Schema Score) as the training progressed. All data was saved successfully,\nand the execution completed within the time limit. No issues were detected.", "The execution completed successfully without any bugs. The code ran multiple\nexperiments with varying pretraining epochs (2, 4, 6, 8, 10) and logged the\nresults, including losses and evaluation metrics (SWA, CWA, SCHM). The results\nshowed consistent improvements in metrics as epochs increased, with the highest\nperformance achieved at pretraining epochs 6 and above. The experiment data and\nplots were saved successfully. No issues or errors were observed.", "", ""], "exc_type": ["TypeError", null, null, "TypeError", null, null, "TypeError", "TypeError", null, null, null, null], "exc_info": [{"args": ["can't concat str to bytes"]}, null, null, {"args": ["can't concat str to bytes"]}, null, null, {"args": ["can't concat str to bytes"]}, {"args": ["can't concat str to bytes"]}, null, null, null, null], "exc_stack": [[["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 83, "<module>", "spr_bench[split] = load_dataset("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 2062, "load_dataset", "builder_instance = load_dataset_builder("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1782, "load_dataset_builder", "dataset_module = dataset_module_factory("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1497, "dataset_module_factory", ").get_module()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 913, "get_module", "data_files = DataFilesDict.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 690, "from_patterns", "else DataFilesList.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 583, "from_patterns", "resolve_pattern("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 346, "resolve_pattern", "elif is_local_path(pattern):"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/utils/file_utils.py", 84, "is_local_path", "return urlparse(url_or_filename).scheme == \"\" or os.path.ismount(urlparse(url_or_filename).scheme + \":/\")"]], null, null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 56, "<module>", "spr_bench[split] = load_dataset("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 2062, "load_dataset", "builder_instance = load_dataset_builder("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1782, "load_dataset_builder", "dataset_module = dataset_module_factory("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1497, "dataset_module_factory", ").get_module()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 913, "get_module", "data_files = DataFilesDict.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 690, "from_patterns", "else DataFilesList.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 583, "from_patterns", "resolve_pattern("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 346, "resolve_pattern", "elif is_local_path(pattern):"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/utils/file_utils.py", 84, "is_local_path", "return urlparse(url_or_filename).scheme == \"\" or os.path.ismount(urlparse(url_or_filename).scheme + \":/\")"]], null, null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 80, "<module>", "spr_bench[split] = load_dataset("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 2062, "load_dataset", "builder_instance = load_dataset_builder("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1782, "load_dataset_builder", "dataset_module = dataset_module_factory("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1497, "dataset_module_factory", ").get_module()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 913, "get_module", "data_files = DataFilesDict.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 690, "from_patterns", "else DataFilesList.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 583, "from_patterns", "resolve_pattern("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 346, "resolve_pattern", "elif is_local_path(pattern):"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/utils/file_utils.py", 84, "is_local_path", "return urlparse(url_or_filename).scheme == \"\" or os.path.ismount(urlparse(url_or_filename).scheme + \":/\")"]], [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 76, "<module>", "spr_bench[split] = load_dataset("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 2062, "load_dataset", "builder_instance = load_dataset_builder("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1782, "load_dataset_builder", "dataset_module = dataset_module_factory("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1497, "dataset_module_factory", ").get_module()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 913, "get_module", "data_files = DataFilesDict.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 690, "from_patterns", "else DataFilesList.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 583, "from_patterns", "resolve_pattern("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 346, "resolve_pattern", "elif is_local_path(pattern):"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/utils/file_utils.py", 84, "is_local_path", "return urlparse(url_or_filename).scheme == \"\" or os.path.ismount(urlparse(url_or_filename).scheme + \":/\")"]], null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "pretraining loss", "lower_is_better": true, "description": "Measures the model's loss during pretraining.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 4.8909, "best_value": 4.8909}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Measures the model's loss during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.033, "best_value": 0.033}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the model's loss during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0156, "best_value": 0.0156}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by shape characteristics.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9952, "best_value": 0.9952}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by color characteristics.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9957, "best_value": 0.9957}]}, {"metric_name": "schema harmonic mean", "lower_is_better": false, "description": "Harmonic mean of schema-specific metrics.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9955, "best_value": 0.9955}]}]}, {"metric_names": [{"metric_name": "pretraining loss", "lower_is_better": true, "description": "Loss during the pretraining phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 4.0024, "best_value": 4.0024}]}, {"metric_name": "fine-tuning train loss", "lower_is_better": true, "description": "Loss during the fine-tuning phase on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0049, "best_value": 0.0049}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0087, "best_value": 0.006}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by shape-specific performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9969, "best_value": 0.9985}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by color-specific performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9969, "best_value": 0.9985}]}, {"metric_name": "SCHM score", "lower_is_better": false, "description": "A combined metric score for shape and color-weighted accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9969, "best_value": 0.9985}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value calculated on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.636, "best_value": 0.636}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value calculated on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6832, "best_value": 0.6832}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy weighted by shape features.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5419, "best_value": 0.5419}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "The accuracy weighted by color features.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.5341, "best_value": 0.5341}]}, {"metric_name": "augmentation consistency score", "lower_is_better": false, "description": "The score representing consistency across data augmentations.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.72, "best_value": 0.72}]}, {"metric_name": "shape\u2013color harmonic mean", "lower_is_better": false, "description": "The harmonic mean of shape-weighted and color-weighted accuracies.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.538, "best_value": 0.538}]}]}, {"metric_names": [{"metric_name": "Pretraining Loss", "lower_is_better": true, "description": "Loss during the pretraining phase.", "data": [{"dataset_name": "weight_decay = 0.0", "final_value": 4.8936, "best_value": 4.8936}, {"dataset_name": "weight_decay = 1e-05", "final_value": 4.8796, "best_value": 4.8796}, {"dataset_name": "weight_decay = 0.0001", "final_value": 4.9188, "best_value": 4.9188}, {"dataset_name": "weight_decay = 0.001", "final_value": 4.9233, "best_value": 4.9233}]}, {"metric_name": "Training Loss", "lower_is_better": true, "description": "Loss during the training phase.", "data": [{"dataset_name": "weight_decay = 0.0", "final_value": 0.0387, "best_value": 0.0387}, {"dataset_name": "weight_decay = 1e-05", "final_value": 0.0307, "best_value": 0.0307}, {"dataset_name": "weight_decay = 0.0001", "final_value": 0.039, "best_value": 0.039}, {"dataset_name": "weight_decay = 0.001", "final_value": 0.0552, "best_value": 0.0552}]}, {"metric_name": "Validation Loss", "lower_is_better": true, "description": "Loss during the validation phase.", "data": [{"dataset_name": "weight_decay = 0.0", "final_value": 0.0291, "best_value": 0.0291}, {"dataset_name": "weight_decay = 1e-05", "final_value": 0.0283, "best_value": 0.0283}, {"dataset_name": "weight_decay = 0.0001", "final_value": 0.0218, "best_value": 0.0218}, {"dataset_name": "weight_decay = 0.001", "final_value": 0.0487, "best_value": 0.0487}]}, {"metric_name": "Shape Weighted Accuracy", "lower_is_better": false, "description": "Weighted accuracy for shape classification.", "data": [{"dataset_name": "weight_decay = 0.0", "final_value": 0.992, "best_value": 0.992}, {"dataset_name": "weight_decay = 1e-05", "final_value": 0.9907, "best_value": 0.9907}, {"dataset_name": "weight_decay = 0.0001", "final_value": 0.9928, "best_value": 0.9928}, {"dataset_name": "weight_decay = 0.001", "final_value": 0.9876, "best_value": 0.9876}]}, {"metric_name": "Color Weighted Accuracy", "lower_is_better": false, "description": "Weighted accuracy for color classification.", "data": [{"dataset_name": "weight_decay = 0.0", "final_value": 0.9926, "best_value": 0.9926}, {"dataset_name": "weight_decay = 1e-05", "final_value": 0.991, "best_value": 0.991}, {"dataset_name": "weight_decay = 0.0001", "final_value": 0.9934, "best_value": 0.9934}, {"dataset_name": "weight_decay = 0.001", "final_value": 0.9874, "best_value": 0.9874}]}, {"metric_name": "Schema Harmonic Mean", "lower_is_better": false, "description": "Harmonic mean of schema-related metrics.", "data": [{"dataset_name": "weight_decay = 0.0", "final_value": 0.9923, "best_value": 0.9923}, {"dataset_name": "weight_decay = 1e-05", "final_value": 0.9909, "best_value": 0.9909}, {"dataset_name": "weight_decay = 0.0001", "final_value": 0.9931, "best_value": 0.9931}, {"dataset_name": "weight_decay = 0.001", "final_value": 0.9875, "best_value": 0.9875}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "pretraining loss", "lower_is_better": true, "description": "The loss value during the pretraining phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 4.0056, "best_value": 4.0056}]}, {"metric_name": "fine-tuning train loss", "lower_is_better": true, "description": "The loss value during the fine-tuning training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0035, "best_value": 0.0035}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0045, "best_value": 0.0045}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by the shape of the objects in the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9987, "best_value": 0.9987}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by the color of the objects in the dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9984, "best_value": 0.9984}]}, {"metric_name": "SCHM score", "lower_is_better": false, "description": "A composite score that measures overall performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9985, "best_value": 0.9985}]}]}, {"metric_names": [{"metric_name": "pretraining loss", "lower_is_better": true, "description": "The loss value during the pretraining phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 4.0028, "best_value": 4.0028}]}, {"metric_name": "fine-tuning train loss", "lower_is_better": true, "description": "The loss value during the fine-tuning training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0045, "best_value": 0.0045}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0058, "best_value": 0.0055}]}, {"metric_name": "shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy weighted by shape.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.998, "best_value": 0.998}]}, {"metric_name": "color-weighted accuracy", "lower_is_better": false, "description": "The accuracy weighted by color.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.998, "best_value": 0.998}]}, {"metric_name": "SCHM score", "lower_is_better": false, "description": "The SCHM score achieved.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.998, "best_value": 0.998}]}]}, {"metric_names": [{"metric_name": "Pretraining Loss", "lower_is_better": true, "description": "The loss obtained during pretraining of the model.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 4.0082, "best_value": 4.0075}]}, {"metric_name": "Fine-tuning Train Loss", "lower_is_better": true, "description": "The loss obtained during fine-tuning on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0032, "best_value": 0.0032}]}, {"metric_name": "Validation Loss", "lower_is_better": true, "description": "The loss on the validation dataset during fine-tuning.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0048, "best_value": 0.0037}]}, {"metric_name": "Shape-weighted Accuracy", "lower_is_better": false, "description": "The accuracy weighted by shape-related factors.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9991, "best_value": 0.9991}]}, {"metric_name": "Color-weighted Accuracy", "lower_is_better": false, "description": "The accuracy weighted by color-related factors.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9991, "best_value": 0.9991}]}, {"metric_name": "SCHM Score", "lower_is_better": false, "description": "A combined score evaluating the model's performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9991, "best_value": 0.9991}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, true, false, false, false, false, false, false, false, false, false], "plots": [[], ["../../logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_1.0e-03.png", "../../logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_5.0e-04.png", "../../logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_3.0e-04.png", "../../logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_1.0e-04.png", "../../logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_finetune_loss_curves.png", "../../logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_pretrain_loss_curves.png", "../../logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_SCHM_curves.png", "../../logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_final_SCHM_vs_lr.png", "../../logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_correct_vs_incorrect_lr_1e-03.png"], ["../../logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep2.png", "../../logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep4.png", "../../logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep6.png", "../../logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep8.png", "../../logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep10.png", "../../logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_pretrain_loss.png", "../../logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_finetune_loss.png", "../../logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_CWA_curve.png", "../../logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_SCHM_curve.png"], [], ["../../logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/loss_curve.png", "../../logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_swa_curve.png", "../../logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_cwa_curve.png", "../../logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_acs_curve.png", "../../logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_schm_curve.png"], ["../../logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_0.0.png", "../../logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_1e-05.png", "../../logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_0.0001.png", "../../logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_0.001.png", "../../logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_train_loss_vs_epoch.png", "../../logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_val_loss_vs_epoch.png", "../../logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_SCHM_vs_epoch.png", "../../logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_final_SCHM_bar.png", "../../logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_SWA_vs_CWA_scatter.png"], [], [], ["../../logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep2.png", "../../logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep4.png", "../../logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep6.png", "../../logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep8.png", "../../logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep10.png", "../../logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_pretrain_loss.png", "../../logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_finetune_loss.png", "../../logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_CWA_curve.png", "../../logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_SCHM_curve.png"], ["../../logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep2.png", "../../logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep4.png", "../../logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep6.png", "../../logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep8.png", "../../logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep10.png", "../../logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_pretrain_loss.png", "../../logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_finetune_loss.png", "../../logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_CWA_curve.png", "../../logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_SCHM_curve.png"], ["../../logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep2.png", "../../logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep4.png", "../../logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep6.png", "../../logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep8.png", "../../logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep10.png", "../../logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_pretrain_loss.png", "../../logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_finetune_loss.png", "../../logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_SWA_curve.png", "../../logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_CWA_curve.png", "../../logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_SCHM_curve.png"], ["../../logs/0-run/experiment_results/seed_aggregation_0b0be907f2b340c4a6548459c40a7465/SPR_BENCH_pretrain_loss_aggregated.png", "../../logs/0-run/experiment_results/seed_aggregation_0b0be907f2b340c4a6548459c40a7465/SPR_BENCH_finetune_loss_aggregated.png", "../../logs/0-run/experiment_results/seed_aggregation_0b0be907f2b340c4a6548459c40a7465/SPR_BENCH_SWA_aggregated.png", "../../logs/0-run/experiment_results/seed_aggregation_0b0be907f2b340c4a6548459c40a7465/SPR_BENCH_CWA_aggregated.png", "../../logs/0-run/experiment_results/seed_aggregation_0b0be907f2b340c4a6548459c40a7465/SPR_BENCH_SCHM_aggregated.png"]], "plot_paths": [[], ["experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_1.0e-03.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_5.0e-04.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_3.0e-04.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_1.0e-04.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_finetune_loss_curves.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_pretrain_loss_curves.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_SCHM_curves.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_final_SCHM_vs_lr.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_correct_vs_incorrect_lr_1e-03.png"], ["experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep2.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep4.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep6.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep8.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep10.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_pretrain_loss.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_finetune_loss.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_SWA_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_CWA_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_SCHM_curve.png"], [], ["experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/loss_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_loss_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_swa_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_cwa_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_acs_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_schm_curve.png"], ["experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_0.0.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_1e-05.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_0.0001.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_0.001.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_train_loss_vs_epoch.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_val_loss_vs_epoch.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_SCHM_vs_epoch.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_final_SCHM_bar.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_SWA_vs_CWA_scatter.png"], [], [], ["experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep2.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep4.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep6.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep8.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep10.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_pretrain_loss.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_finetune_loss.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_SWA_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_CWA_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_SCHM_curve.png"], ["experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep2.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep4.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep6.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep8.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep10.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_pretrain_loss.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_finetune_loss.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_SWA_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_CWA_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_SCHM_curve.png"], ["experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep2.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep4.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep6.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep8.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep10.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_pretrain_loss.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_finetune_loss.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_SWA_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_CWA_curve.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_SCHM_curve.png"], ["experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_0b0be907f2b340c4a6548459c40a7465/SPR_BENCH_pretrain_loss_aggregated.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_0b0be907f2b340c4a6548459c40a7465/SPR_BENCH_finetune_loss_aggregated.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_0b0be907f2b340c4a6548459c40a7465/SPR_BENCH_SWA_aggregated.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_0b0be907f2b340c4a6548459c40a7465/SPR_BENCH_CWA_aggregated.png", "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_0b0be907f2b340c4a6548459c40a7465/SPR_BENCH_SCHM_aggregated.png"]], "plot_analyses": [[], [{"analysis": "This plot shows the loss curves for training and validation at a learning rate of 1e-03. The training loss decreases steadily, indicating proper learning. Validation loss also decreases but at a slightly slower rate, suggesting that the model is generalizing well without overfitting.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_1.0e-03.png"}, {"analysis": "This plot shows the loss curves for training and validation at a learning rate of 5e-04. Both training and validation losses decrease steadily, but the validation loss is slightly higher than the training loss. This indicates good generalization, but the smaller learning rate slows convergence.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_5.0e-04.png"}, {"analysis": "This plot shows the loss curves for training and validation at a learning rate of 3e-04. The training loss decreases sharply, while the validation loss decreases at a slower rate and remains higher than the training loss. This suggests that the learning rate is too small to achieve optimal convergence within the given epochs.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_3.0e-04.png"}, {"analysis": "This plot shows the loss curves for training and validation at a learning rate of 1e-04. The training loss decreases steadily, but the validation loss shows a slower rate of decrease and remains significantly higher than the training loss. This learning rate might be too small for effective model training.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/loss_curve_lr_1.0e-04.png"}, {"analysis": "This plot compares fine-tuning loss curves for various learning rates. The learning rate of 1e-03 shows the fastest convergence for both training and validation losses. Lower learning rates (5e-04, 3e-04, 1e-04) converge more slowly and have higher validation losses, indicating slower learning and potential underfitting.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_finetune_loss_curves.png"}, {"analysis": "This plot shows the pre-training contrastive loss for various learning rates. All learning rates exhibit a steady decrease in loss, indicating effective learning during pre-training. The differences between learning rates are minimal, suggesting that contrastive pre-training is less sensitive to learning rate variations.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_pretrain_loss_curves.png"}, {"analysis": "This plot shows the SCHM metric over epochs for various learning rates. The learning rate of 1e-03 achieves the highest SCHM score consistently, followed by 5e-04 and 3e-04. The learning rate of 1e-04 lags behind, indicating that higher learning rates are more effective for this metric.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_SCHM_curves.png"}, {"analysis": "This plot shows the final-epoch SCHM scores for different fine-tuning learning rates. The scores are very close across all learning rates, with a slight advantage for 1e-03 and 5e-04. This suggests that while all learning rates perform well, 1e-03 is slightly more optimal for fine-tuning.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_final_SCHM_vs_lr.png"}, {"analysis": "This plot shows the prediction quality for a learning rate of 1e-03. The majority of predictions are correct, with very few incorrect predictions, indicating that this learning rate achieves high accuracy and generalization on the validation set.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_802b095ac47b42baad6b915240aebad0_proc_2989518/SPR_BENCH_correct_vs_incorrect_lr_1e-03.png"}], [{"analysis": "This plot shows the fine-tuning loss for both training and validation datasets with 2 pretraining epochs. Both training and validation losses decrease consistently, indicating effective learning. However, the gap between training and validation losses is minimal, suggesting that the model is not overfitting at this stage.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep2.png"}, {"analysis": "This plot shows the fine-tuning loss for both training and validation datasets with 4 pretraining epochs. The losses decrease more rapidly compared to 2 pretraining epochs, and the validation loss closely follows the training loss. This indicates improved generalization and effective pretraining.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep4.png"}, {"analysis": "This plot shows the fine-tuning loss for both training and validation datasets with 6 pretraining epochs. The training and validation losses decrease further, and the validation loss aligns closely with the training loss. This suggests that increasing pretraining epochs enhances the model's ability to generalize.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep6.png"}, {"analysis": "This plot shows the fine-tuning loss for both training and validation datasets with 8 pretraining epochs. The losses are further reduced, and the validation loss continues to align closely with the training loss. This indicates that the model benefits from additional pretraining epochs without overfitting.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep8.png"}, {"analysis": "This plot shows the fine-tuning loss for both training and validation datasets with 10 pretraining epochs. Both losses decrease significantly, and the validation loss is almost identical to the training loss. This suggests that 10 pretraining epochs result in the most effective learning and generalization so far.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/loss_curve_ep10.png"}, {"analysis": "This plot depicts the pretraining loss across different numbers of pretraining epochs. The loss decreases consistently with increasing pretraining epochs, indicating that the pretraining process effectively optimizes the model parameters. The diminishing returns in loss reduction at higher epochs suggest an optimal range for pretraining epochs.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_pretrain_loss.png"}, {"analysis": "This plot compares the fine-tuning loss for training and validation datasets across different numbers of pretraining epochs. The losses decrease consistently across all pretraining configurations, with higher pretraining epochs resulting in lower losses. This highlights the positive impact of extensive pretraining on fine-tuning performance.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_finetune_loss.png"}, {"analysis": "This plot shows the Shape-Weighted Accuracy (SWA) across fine-tuning epochs for different pretraining configurations. Higher pretraining epochs lead to better SWA, with 10 pretraining epochs achieving the highest accuracy. This indicates that extensive pretraining enhances the model's ability to capture shape-related patterns.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_SWA_curve.png"}, {"analysis": "This plot shows the Color-Weighted Accuracy (CWA) across fine-tuning epochs for different pretraining configurations. Similar to SWA, higher pretraining epochs result in better CWA, with 10 pretraining epochs achieving the best performance. This suggests that the model benefits from extensive pretraining in recognizing color-related patterns.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_CWA_curve.png"}, {"analysis": "This plot shows the Schema Score (SCHM) across fine-tuning epochs for different pretraining configurations. The trend is consistent with SWA and CWA, where higher pretraining epochs lead to better schema recognition. The results highlight the importance of pretraining in improving the model's schema-related reasoning capabilities.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_479d9bad55604ae6b69aad9d4d40ac72_proc_2989519/SPR_BENCH_SCHM_curve.png"}], [], [{"analysis": "The training loss shows a consistent decrease across epochs, indicating that the model is learning effectively from the training data. However, the validation loss exhibits an increasing trend after the second epoch, which suggests potential overfitting. This implies that the model is not generalizing well to unseen data after a certain point in training. Early stopping or regularization techniques should be considered to address this issue.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/loss_curve.png"}, {"analysis": "This plot confirms the patterns observed earlier: a steady decline in training loss and a rise in validation loss after the second epoch. The divergence between training and validation losses indicates overfitting, and further adjustments to hyperparameters, such as reducing the learning rate or implementing early stopping, might help mitigate this issue.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_loss_curve.png"}, {"analysis": "The shape-weighted accuracy metric initially improves and peaks at the second epoch, but then declines steadily, reaching a minimum at the fourth epoch before showing slight recovery. This pattern aligns with the overfitting observed in the loss curves. The decline in this metric highlights the model's deteriorating ability to generalize to different shape varieties in the SPR task.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_swa_curve.png"}, {"analysis": "The color-weighted accuracy follows a similar trend to the shape-weighted accuracy, with an initial increase, peaking at the second epoch, followed by a steady decline and slight recovery. This indicates that the model initially learns to generalize well to color variations but struggles to maintain this performance as training progresses, further supporting the overfitting hypothesis.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_cwa_curve.png"}, {"analysis": "The augmentation consistency metric remains stable for the first two epochs but then declines sharply, reaching a minimum at the fourth epoch before a slight recovery. This suggests that the model's ability to handle augmented data diminishes over time, possibly due to overfitting to the original data distribution.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_acs_curve.png"}, {"analysis": "The SCHM (harmonic mean) metric, which combines shape-weighted and color-weighted accuracies, peaks at the second epoch and follows a similar decline and recovery pattern as the individual metrics. This reinforces the observation that the model's overall performance deteriorates after the second epoch, likely due to overfitting.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b011240f2e92474a9978255968b9a909_proc_2989517/SPR_BENCH_schm_curve.png"}], [{"analysis": "The loss curve for weight decay = 0.0 shows a steady decline for both training and validation losses over epochs. However, the validation loss is consistently lower than the training loss, which might indicate underfitting or overly simplistic regularization settings.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_0.0.png"}, {"analysis": "With weight decay = 1e-05, the training and validation losses decrease more sharply compared to the previous setting. This suggests that a small weight decay improves the generalization of the model, as evidenced by the lower validation loss.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_1e-05.png"}, {"analysis": "The loss curve for weight decay = 0.0001 demonstrates further improvement in both training and validation losses. The validation loss is particularly low, implying that this weight decay value may be optimal for balancing regularization and model complexity.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_0.0001.png"}, {"analysis": "For weight decay = 0.001, the training and validation losses are slightly higher compared to weight decay = 0.0001, suggesting that this higher regularization value may be slightly restrictive for the model's learning capacity.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/loss_curve_wd_0.001.png"}, {"analysis": "The consolidated plot for training loss across different weight decay values shows that weight decay = 0.0001 achieves the lowest training loss, followed closely by weight decay = 1e-05. This indicates that moderate weight decay values are more effective in minimizing training loss.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_train_loss_vs_epoch.png"}, {"analysis": "The validation loss plot highlights that weight decay = 0.0001 achieves the lowest validation loss, closely followed by weight decay = 1e-05. This aligns with the observation that moderate weight decay values lead to better generalization.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_val_loss_vs_epoch.png"}, {"analysis": "The SCHM metric plot reveals that all weight decay values result in near-perfect scores, with weight decay = 0.0001 slightly outperforming others. This suggests that the choice of weight decay has minimal impact on this specific metric, but weight decay = 0.0001 still provides a slight advantage.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_SCHM_vs_epoch.png"}, {"analysis": "The bar plot for final SCHM metric by weight decay confirms that all weight decay values result in comparable final SCHM scores. This reinforces the minimal impact of weight decay on this metric.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_final_SCHM_bar.png"}, {"analysis": "The scatter plot for final SWA vs. CWA shows that weight decay = 0.0001 achieves the highest scores for both metrics, followed by weight decay = 1e-05 and weight decay = 0.0. Weight decay = 0.001 lags behind, indicating that moderate weight decay values are more effective for these metrics.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_793d4df5195e48d9a3030244f3f1f0e4_proc_2989520/SPR_SWA_vs_CWA_scatter.png"}], [], [], [{"analysis": "The plot shows the fine-tuning loss for both training and validation datasets over 2 epochs, with pretraining epochs set to 2. The loss decreases consistently for both datasets, indicating effective learning. However, the validation loss is slightly lower than the training loss, which could suggest a well-generalizing model or potential underfitting due to limited training duration.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep2.png"}, {"analysis": "The plot depicts fine-tuning loss for 2 epochs with pretraining epochs set to 4. Both training and validation losses decrease further compared to the previous case, suggesting that additional pretraining epochs improve the model's initialization and learning capability. The gap between training and validation loss remains minimal, indicating stable generalization.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep4.png"}, {"analysis": "This plot shows fine-tuning loss for 2 epochs with 6 pretraining epochs. The losses for both training and validation datasets continue to decrease, with a more pronounced reduction in validation loss. This suggests that increased pretraining epochs contribute to better feature extraction and generalization.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep6.png"}, {"analysis": "The plot illustrates fine-tuning loss for 2 epochs with 8 pretraining epochs. The training and validation losses are the lowest observed so far, with a minimal gap between them. This indicates that the model benefits significantly from extended pretraining, resulting in improved generalization and convergence.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep8.png"}, {"analysis": "The plot demonstrates fine-tuning loss for 2 epochs with 10 pretraining epochs. The losses for both datasets reach their lowest values, with a negligible gap between training and validation loss. This suggests optimal learning and generalization, with diminishing returns from additional pretraining epochs.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/loss_curve_ep10.png"}, {"analysis": "This plot shows the pretraining loss across different pretraining epochs (2, 4, 6, 8, and 10). The loss decreases consistently as the number of pretraining epochs increases, with diminishing returns observed after 6 epochs. This suggests that while pretraining improves feature extraction, its benefits plateau with excessive epochs.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_pretrain_loss.png"}, {"analysis": "The plot compares fine-tuning loss for training and validation datasets across different pretraining epochs. Loss decreases consistently with fine-tuning epochs, and models pretrained for longer epochs exhibit lower loss values. This highlights the advantage of extended pretraining for improved fine-tuning performance.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_finetune_loss.png"}, {"analysis": "The plot depicts Shape-Weighted Accuracy across fine-tuning epochs for models pretrained for different epochs. Accuracy increases with fine-tuning epochs, with higher pretraining epochs resulting in better performance. This shows that extended pretraining improves the model's ability to capture shape-related features.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_SWA_curve.png"}, {"analysis": "This plot shows Color-Weighted Accuracy across fine-tuning epochs for various pretraining epochs. Accuracy improves with fine-tuning epochs, and models with more pretraining epochs achieve higher accuracy. This indicates that extended pretraining enhances the model's ability to capture color-related features.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_CWA_curve.png"}, {"analysis": "The plot illustrates Schema Score across fine-tuning epochs for different pretraining epochs. The scores increase with fine-tuning, with models pretrained for more epochs achieving higher scores. This demonstrates that extended pretraining improves the model's ability to understand and generalize schema patterns.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/SPR_BENCH_SCHM_curve.png"}], [{"analysis": "This plot illustrates the fine-tuning loss for both training and validation sets with pretraining epochs set to 2. The validation loss decreases consistently and converges well with the training loss, suggesting that the model generalizes well. However, the gap between training and validation loss indicates potential for further optimization.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep2.png"}, {"analysis": "This plot shows the fine-tuning loss for pretraining epochs set to 4. The validation loss decreases more rapidly and converges closely with the training loss compared to the previous configuration, indicating improved generalization and better utilization of the pretrained weights.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep4.png"}, {"analysis": "Here, the fine-tuning loss for pretraining epochs set to 6 is presented. The validation loss aligns even more closely with the training loss, suggesting that the additional pretraining epochs contribute positively to the model's ability to generalize.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep6.png"}, {"analysis": "This plot depicts the fine-tuning loss for pretraining epochs set to 8. The validation loss continues to decrease and converge with the training loss, but the improvement over the 6-epoch configuration is less pronounced, indicating diminishing returns from additional pretraining epochs.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep8.png"}, {"analysis": "This plot represents the fine-tuning loss for pretraining epochs set to 10. The validation loss shows marginal improvement over the 8-epoch configuration, confirming that further pretraining beyond this point yields minimal gains in generalization.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/loss_curve_ep10.png"}, {"analysis": "This plot compares the pretraining loss across different numbers of pretraining epochs. The loss decreases consistently across all configurations, with diminishing returns observed after 6 epochs. This suggests that 6-8 pretraining epochs may be optimal for balancing computational cost and performance.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_pretrain_loss.png"}, {"analysis": "This plot compares fine-tuning losses for training and validation sets across different pretraining epochs. Configurations with higher pretraining epochs (6, 8, 10) show better convergence and alignment between training and validation losses, indicating improved generalization.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_finetune_loss.png"}, {"analysis": "This plot shows Shape-Weighted Accuracy (SWA) across fine-tuning epochs for different pretraining configurations. Higher pretraining epochs (8 and 10) result in slightly better SWA, but the gains plateau after 6 epochs, suggesting diminishing returns.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_SWA_curve.png"}, {"analysis": "This plot displays Color-Weighted Accuracy (CWA) across fine-tuning epochs for different pretraining configurations. Similar to SWA, configurations with higher pretraining epochs (8 and 10) achieve marginally better CWA, but the improvement levels off after 6 epochs.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_CWA_curve.png"}, {"analysis": "This plot illustrates Schema Score (SCHM) across fine-tuning epochs for different pretraining configurations. Higher pretraining epochs (8 and 10) yield slightly better SCHM, but the improvement diminishes after 6 epochs, aligning with trends observed in SWA and CWA.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/SPR_BENCH_SCHM_curve.png"}], [{"analysis": "This plot depicts the fine-tuning loss for training and validation data when the pretraining epochs are set to 2. Both the training and validation loss decrease rapidly and converge to near-zero values within two epochs. The validation loss is consistently lower than the training loss, indicating no signs of overfitting. However, the rapid convergence might suggest potential underfitting or insufficient training epochs for capturing complex patterns.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep2.png"}, {"analysis": "This plot shows the fine-tuning loss for training and validation data with pretraining epochs set to 4. The loss curves exhibit similar trends as the previous plot, with both training and validation losses decreasing rapidly to near-zero values. The slightly lower starting loss values compared to the previous plot indicate that additional pretraining epochs improve the initialization for fine-tuning.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep4.png"}, {"analysis": "This plot illustrates the fine-tuning loss for pretraining epochs set to 6. The loss curves continue to show a consistent decrease, with validation loss remaining lower than training loss. The slightly lower loss values compared to previous plots suggest improved initialization from extended pretraining, potentially leading to better generalization.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep6.png"}, {"analysis": "This plot demonstrates the fine-tuning loss for pretraining epochs set to 8. The loss curves show a consistent pattern of rapid convergence to near-zero values, with validation loss remaining below training loss. The results suggest that increasing pretraining epochs further enhances initialization quality, as evidenced by the slightly reduced starting loss values.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep8.png"}, {"analysis": "This plot presents the fine-tuning loss for pretraining epochs set to 10. The trends remain consistent with previous plots, showing rapid convergence of both training and validation losses to near-zero values. The results indicate that while increasing pretraining epochs improves initialization, the marginal gains in loss reduction diminish beyond 8 epochs.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/loss_curve_ep10.png"}, {"analysis": "This plot compares pretraining loss across different pretraining epochs (2, 4, 6, 8, and 10). The loss decreases consistently with more pretraining epochs, but the rate of improvement diminishes after 6 epochs. The slight oscillations in loss values for higher epochs might indicate diminishing returns or overfitting during pretraining.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_pretrain_loss.png"}, {"analysis": "This plot compares fine-tuning loss for training and validation data across different pretraining epochs. Loss values decrease consistently for both training and validation sets as pretraining epochs increase. The validation loss remains consistently lower than the training loss, suggesting no overfitting. However, the marginal improvement in loss reduction diminishes for pretraining epochs beyond 8.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_finetune_loss.png"}, {"analysis": "This plot illustrates the Shape-Weighted Accuracy (SWA) across fine-tuning epochs for different pretraining epochs. SWA improves consistently with more pretraining epochs, with pretraining epochs of 8 and 10 yielding the highest accuracies. The results indicate that extended pretraining enhances the model's ability to capture shape-related features.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_SWA_curve.png"}, {"analysis": "This plot shows the Color-Weighted Accuracy (CWA) across fine-tuning epochs for different pretraining epochs. Similar to SWA, CWA improves with more pretraining epochs, with the highest accuracies observed for 8 and 10 pretraining epochs. The results suggest that extended pretraining improves the model's ability to capture color-related features.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_CWA_curve.png"}, {"analysis": "This plot depicts the Schema Score (SCHM) across fine-tuning epochs for different pretraining epochs. The SCHM metric follows a trend similar to SWA and CWA, with higher pretraining epochs (8 and 10) achieving the best scores. This indicates that extended pretraining enhances the model's ability to generalize to schema-related tasks.", "plot_path": "experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/SPR_BENCH_SCHM_curve.png"}], []], "vlm_feedback_summary": ["[]", "The plots provide valuable insights into the impact of learning rate on model\nperformance. A learning rate of 1e-03 consistently outperforms others across\nvarious metrics, showing faster convergence, higher SCHM scores, and better\nprediction quality. Lower learning rates result in slower convergence and\nslightly reduced performance.", "The provided plots effectively demonstrate the impact of varying pretraining\nepochs on fine-tuning performance metrics. Increasing the number of pretraining\nepochs consistently improves the model's ability to generalize and recognize\npatterns, as evidenced by reduced losses and enhanced accuracy metrics (SWA,\nCWA, and SCHM). The results validate the hypothesis that extensive pretraining\nbenefits the SPR task.", "[]", "The plots reveal a consistent pattern of overfitting, as evidenced by the\ndivergence between training and validation losses and the decline in performance\nmetrics after the second epoch. While the model initially shows promising\nimprovements in accuracy and consistency metrics, these gains are not sustained,\nsuggesting the need for early stopping, regularization, or hyperparameter\nadjustments to improve generalization.", "The analysis indicates that weight decay = 0.0001 provides the best balance\nbetween training loss, validation loss, and performance metrics such as SWA and\nCWA. The SCHM metric is less sensitive to weight decay values, showing near-\nperfect scores across all settings. Moderate weight decay values (0.0001 and\n1e-05) are recommended for achieving optimal performance.", "[]", "[]", "The plots collectively demonstrate that extended pretraining epochs lead to\nbetter feature extraction and generalization, as evidenced by lower training and\nvalidation losses, and higher accuracy metrics (SWA, CWA, and SCHM). Fine-tuning\nperformance improves consistently with increased pretraining, though benefits\nplateau after a certain point (around 6-8 epochs). This indicates that\npretraining plays a crucial role in initializing the model effectively for the\nSPR task.", "The plots provide clear insights into the impact of varying pretraining epochs\non fine-tuning loss, validation loss, and key metrics (SWA, CWA, SCHM).\nConfigurations with 6-8 pretraining epochs appear to be optimal, as they balance\ncomputational cost with performance improvements. Beyond 8 epochs, the gains are\nnegligible, indicating diminishing returns.", "The plots provide valuable insights into the impact of pretraining epochs on\nfine-tuning performance. Extended pretraining improves initialization, leading\nto better generalization and higher accuracy metrics (SWA, CWA, SCHM). However,\nthe marginal gains diminish beyond 8 pretraining epochs, suggesting a saturation\npoint for pretraining benefits.", "[]"], "exec_time": [0.7781765460968018, 21.80320429801941, 74.50191688537598, 0.8750278949737549, 3.8722853660583496, 22.861886978149414, 0.6366972923278809, 0.6051251888275146, 75.19113755226135, 72.23285174369812, 75.52839064598083, null], "exec_time_feedback": ["", "", "", "Implementation works but runs too quickly (1.24 minutes).We have up to 60\nminutes available for each experiment.Make sure to scale up the experiment by\nincreasing the number of epochs, using a larger model, or working with bigger\ndatasets.Given that the current execution time is {exec_time_minutes:.2f}\nminutes, think about how changing the number of epochs to run, or using a larger\nmodel, or working with bigger datasets to runwill affect the execution time, and\nmake sure to scale up the experiment accordingly.", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [[], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], [], ["[]"], ["[\"weight_decay=0.0001\"", "\"weight_decay=1e-05\"]"], [], [], ["['SPR_BENCH']"], ["['SPR_BENCH']"], ["['SPR_BENCH']"], []], "plot_code": [null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    runs = experiment_data[\"learning_rate\"][\"SPR_BENCH\"][\"runs\"]\n    lrs = [r[\"lr_ft\"] for r in runs]\n\n    # ---------- 1. Fine-tune loss curves ----------\n    try:\n        plt.figure()\n        for r, lr in zip(runs, lrs):\n            plt.plot(r[\"losses\"][\"train\"], label=f\"{lr:.0e} train\")\n            plt.plot(r[\"losses\"][\"val\"], label=f\"{lr:.0e} val\", ls=\"--\")\n        plt.title(\"SPR_BENCH: Fine-tune Loss Curves\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_finetune_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating plot finetune loss: {e}\")\n        plt.close()\n\n    # ---------- 2. Pre-train loss curves ----------\n    try:\n        plt.figure()\n        for r, lr in zip(runs, lrs):\n            plt.plot(r[\"losses\"][\"pretrain\"], label=f\"{lr:.0e}\")\n        plt.title(\"SPR_BENCH: Pre-train Contrastive Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"NT-Xent Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_pretrain_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating plot pretrain loss: {e}\")\n        plt.close()\n\n    # ---------- 3. SCHM curves ----------\n    try:\n        plt.figure()\n        for r, lr in zip(runs, lrs):\n            plt.plot(r[\"metrics\"][\"SCHM\"], label=f\"{lr:.0e}\")\n        plt.title(\"SPR_BENCH: SCHM Metric over Epochs\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SCHM\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_SCHM_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating plot SCHM curves: {e}\")\n        plt.close()\n\n    # ---------- 4. Final SCHM vs LR ----------\n    try:\n        final_schm = [r[\"metrics\"][\"SCHM\"][-1] for r in runs]\n        plt.figure()\n        plt.bar([f\"{lr:.0e}\" for lr in lrs], final_schm, color=\"skyblue\")\n        plt.title(\"SPR_BENCH: Final-Epoch SCHM vs Learning-Rate\")\n        plt.xlabel(\"Fine-tune Learning-Rate\")\n        plt.ylabel(\"SCHM\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_final_SCHM_vs_lr.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating plot SCHM vs lr: {e}\")\n        plt.close()\n\n    # ---------- 5. Correct / Incorrect for best LR ----------\n    try:\n        best_idx = int(np.argmax([r[\"metrics\"][\"SCHM\"][-1] for r in runs]))\n        best_run = runs[best_idx]\n        preds = np.array(best_run[\"predictions\"])\n        truth = np.array(best_run[\"ground_truth\"])\n        correct = (preds == truth).sum()\n        incorrect = len(preds) - correct\n        plt.figure()\n        plt.bar([\"Correct\", \"Incorrect\"], [correct, incorrect], color=[\"green\", \"red\"])\n        plt.title(f\"SPR_BENCH: Prediction Quality (LR={lrs[best_idx]:.0e})\")\n        fname = os.path.join(\n            working_dir, f\"SPR_BENCH_correct_vs_incorrect_lr_{lrs[best_idx]:.0e}.png\"\n        )\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating plot correctness: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nruns_dict = experiment_data.get(\"pretrain_epochs\", {}).get(\"SPR_BENCH\", {})\nrun_keys = sorted(runs_dict.keys(), key=lambda x: int(x))  # e.g. ['2','4','6',...]\n\n\n# Helper to pick colors/linestyles that fit within default palette even for many lines\ndef _style(idx):\n    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n    return colors[idx % len(colors)], \"-\" if idx < len(colors) else \"--\"\n\n\n# ---------- 1. Pre-training loss curves ----------\ntry:\n    plt.figure()\n    for i, k in enumerate(run_keys):\n        losses = runs_dict[k][\"losses\"].get(\"pretrain\", [])\n        c, ls = _style(i)\n        plt.plot(\n            range(1, len(losses) + 1), losses, label=f\"PT={k}\", color=c, linestyle=ls\n        )\n    plt.title(\"SPR_BENCH: Pre-training Loss vs Epochs\")\n    plt.xlabel(\"Pre-training Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_pretrain_loss.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating pre-training loss plot: {e}\")\n    plt.close()\n\n# ---------- 2. Fine-tuning loss curves ----------\ntry:\n    plt.figure()\n    for i, k in enumerate(run_keys):\n        losses_train = runs_dict[k][\"losses\"].get(\"train\", [])\n        losses_val = runs_dict[k][\"losses\"].get(\"val\", [])\n        c, _ = _style(i)\n        plt.plot(\n            range(1, len(losses_train) + 1),\n            losses_train,\n            color=c,\n            linestyle=\"-\",\n            label=f\"Train (PT={k})\",\n        )\n        plt.plot(\n            range(1, len(losses_val) + 1),\n            losses_val,\n            color=c,\n            linestyle=\"--\",\n            label=f\"Val (PT={k})\",\n        )\n    plt.title(\"SPR_BENCH: Fine-tuning Loss (Train vs Val)\")\n    plt.xlabel(\"Fine-tuning Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend(ncol=2, fontsize=\"small\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_finetune_loss.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating fine-tuning loss plot: {e}\")\n    plt.close()\n\n\n# ---------- Metric plotting helper ----------\ndef plot_metric(metric_name, file_suffix):\n    try:\n        plt.figure()\n        for i, k in enumerate(run_keys):\n            vals = runs_dict[k][\"metrics\"].get(metric_name, [])\n            c, ls = _style(i)\n            plt.plot(\n                range(1, len(vals) + 1),\n                vals,\n                label=f\"{metric_name} (PT={k})\",\n                color=c,\n                linestyle=ls,\n            )\n        plt.title(f\"SPR_BENCH: {metric_name} across Fine-tuning Epochs\")\n        plt.xlabel(\"Fine-tuning Epoch\")\n        plt.ylabel(metric_name)\n        plt.legend(fontsize=\"small\")\n        fname = os.path.join(working_dir, f\"SPR_BENCH_{file_suffix}.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating {metric_name} plot: {e}\")\n        plt.close()\n\n\n# ---------- 3-5. Metric curves ----------\nplot_metric(\"SWA\", \"SWA_curve\")\nplot_metric(\"CWA\", \"CWA_curve\")\nplot_metric(\"SCHM\", \"SCHM_curve\")\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# mandatory working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------- load data -----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    data = experiment_data[\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data = None\n\nif data:\n    epochs = np.array(data[\"epochs\"])\n    train_loss = np.array(data[\"losses\"][\"train\"])\n    val_loss = np.array(data[\"losses\"][\"val\"])\n    swa = np.array(data[\"metrics\"][\"SWA\"])\n    cwa = np.array(data[\"metrics\"][\"CWA\"])\n    acs = np.array(data[\"metrics\"][\"ACS\"])\n    schm = np.array(data[\"metrics\"][\"SCHM\"])\n\n    # pick best epoch (lowest val loss)\n    best_idx = int(val_loss.argmin()) if len(val_loss) else -1\n    if best_idx >= 0:\n        print(\n            f\"Best epoch: {epochs[best_idx]} | SWA={swa[best_idx]:.3f} \"\n            f\"CWA={cwa[best_idx]:.3f} ACS={acs[best_idx]:.3f} SCHM={schm[best_idx]:.3f}\"\n        )\n\n    # ---------------- plots -----------------\n    plot_specs = [\n        (\n            \"loss_curve\",\n            \"Train vs Validation Loss\",\n            epochs,\n            [train_loss, val_loss],\n            [\"Train\", \"Validation\"],\n        ),\n        (\"swa_curve\", \"Shape-Weighted Accuracy\", epochs, [swa], [\"SWA\"]),\n        (\"cwa_curve\", \"Color-Weighted Accuracy\", epochs, [cwa], [\"CWA\"]),\n        (\"acs_curve\", \"Augmentation Consistency\", epochs, [acs], [\"ACS\"]),\n        (\"schm_curve\", \"SCHM (Harmonic Mean)\", epochs, [schm], [\"SCHM\"]),\n    ]\n\n    for name, title, x, ys, labels in plot_specs[:5]:\n        try:\n            plt.figure()\n            for y, lab in zip(ys, labels):\n                plt.plot(x, y, label=lab)\n            plt.title(f\"SPR_BENCH {title}\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(title.split()[0])\n            if len(labels) > 1:\n                plt.legend()\n            fname = f\"SPR_BENCH_{name}.png\"\n            plt.savefig(os.path.join(working_dir, fname))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating {name}: {e}\")\n            plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nwd_dict = experiment_data.get(\"weight_decay\", {})\ntags = list(wd_dict.keys())\n\n\n# helper to get arrays\ndef arr(tag, field, sub):\n    return np.asarray(wd_dict[tag][field][sub])\n\n\n# 1) TRAIN LOSSES ---------------------------------------------------\ntry:\n    plt.figure()\n    for tag in tags:\n        plt.plot(arr(tag, \"losses\", \"train\"), label=f\"wd={tag}\")\n    plt.title(\"SPR: Train Loss vs Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_train_loss_vs_epoch.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating train-loss plot: {e}\")\n    plt.close()\n\n# 2) VAL LOSSES -----------------------------------------------------\ntry:\n    plt.figure()\n    for tag in tags:\n        plt.plot(arr(tag, \"losses\", \"val\"), label=f\"wd={tag}\")\n    plt.title(\"SPR: Validation Loss vs Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_val_loss_vs_epoch.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating val-loss plot: {e}\")\n    plt.close()\n\n# 3) SCHM over epochs ----------------------------------------------\ntry:\n    plt.figure()\n    for tag in tags:\n        plt.plot(arr(tag, \"metrics\", \"SCHM\"), label=f\"wd={tag}\")\n    plt.title(\"SPR: SCHM Metric vs Epoch\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"SCHM\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_SCHM_vs_epoch.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SCHM-epoch plot: {e}\")\n    plt.close()\n\n# 4) Final SCHM bar -------------------------------------------------\ntry:\n    plt.figure()\n    final_schm = [arr(t, \"metrics\", \"SCHM\")[-1] for t in tags]\n    plt.bar(tags, final_schm, color=\"skyblue\")\n    plt.title(\"SPR: Final SCHM by Weight Decay\")\n    plt.xlabel(\"Weight Decay\")\n    plt.ylabel(\"Final SCHM\")\n    fname = os.path.join(working_dir, \"SPR_final_SCHM_bar.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final SCHM bar: {e}\")\n    plt.close()\n\n# 5) SWA vs CWA scatter --------------------------------------------\ntry:\n    plt.figure()\n    swa = [arr(t, \"metrics\", \"SWA\")[-1] for t in tags]\n    cwa = [arr(t, \"metrics\", \"CWA\")[-1] for t in tags]\n    plt.scatter(swa, cwa)\n    for s, c, t in zip(swa, cwa, tags):\n        plt.text(s, c, t)\n    plt.title(\"SPR: Final SWA vs CWA (Weight Decay tags)\")\n    plt.xlabel(\"SWA\")\n    plt.ylabel(\"CWA\")\n    fname = os.path.join(working_dir, \"SPR_SWA_vs_CWA_scatter.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SWA-CWA scatter: {e}\")\n    plt.close()\n\n# --------- quick textual summary -------------\nfor tag in tags:\n    print(f\"wd={tag} | Final SCHM={arr(tag,'metrics','SCHM')[-1]:.3f}\")\n", null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nruns_dict = experiment_data.get(\"pretrain_epochs\", {}).get(\"SPR_BENCH\", {})\nrun_keys = sorted(runs_dict.keys(), key=lambda x: int(x))  # e.g. ['2','4','6',...]\n\n\n# Helper to pick colors/linestyles that fit within default palette even for many lines\ndef _style(idx):\n    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n    return colors[idx % len(colors)], \"-\" if idx < len(colors) else \"--\"\n\n\n# ---------- 1. Pre-training loss curves ----------\ntry:\n    plt.figure()\n    for i, k in enumerate(run_keys):\n        losses = runs_dict[k][\"losses\"].get(\"pretrain\", [])\n        c, ls = _style(i)\n        plt.plot(\n            range(1, len(losses) + 1), losses, label=f\"PT={k}\", color=c, linestyle=ls\n        )\n    plt.title(\"SPR_BENCH: Pre-training Loss vs Epochs\")\n    plt.xlabel(\"Pre-training Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_pretrain_loss.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating pre-training loss plot: {e}\")\n    plt.close()\n\n# ---------- 2. Fine-tuning loss curves ----------\ntry:\n    plt.figure()\n    for i, k in enumerate(run_keys):\n        losses_train = runs_dict[k][\"losses\"].get(\"train\", [])\n        losses_val = runs_dict[k][\"losses\"].get(\"val\", [])\n        c, _ = _style(i)\n        plt.plot(\n            range(1, len(losses_train) + 1),\n            losses_train,\n            color=c,\n            linestyle=\"-\",\n            label=f\"Train (PT={k})\",\n        )\n        plt.plot(\n            range(1, len(losses_val) + 1),\n            losses_val,\n            color=c,\n            linestyle=\"--\",\n            label=f\"Val (PT={k})\",\n        )\n    plt.title(\"SPR_BENCH: Fine-tuning Loss (Train vs Val)\")\n    plt.xlabel(\"Fine-tuning Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend(ncol=2, fontsize=\"small\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_finetune_loss.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating fine-tuning loss plot: {e}\")\n    plt.close()\n\n\n# ---------- Metric plotting helper ----------\ndef plot_metric(metric_name, file_suffix):\n    try:\n        plt.figure()\n        for i, k in enumerate(run_keys):\n            vals = runs_dict[k][\"metrics\"].get(metric_name, [])\n            c, ls = _style(i)\n            plt.plot(\n                range(1, len(vals) + 1),\n                vals,\n                label=f\"{metric_name} (PT={k})\",\n                color=c,\n                linestyle=ls,\n            )\n        plt.title(f\"SPR_BENCH: {metric_name} across Fine-tuning Epochs\")\n        plt.xlabel(\"Fine-tuning Epoch\")\n        plt.ylabel(metric_name)\n        plt.legend(fontsize=\"small\")\n        fname = os.path.join(working_dir, f\"SPR_BENCH_{file_suffix}.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating {metric_name} plot: {e}\")\n        plt.close()\n\n\n# ---------- 3-5. Metric curves ----------\nplot_metric(\"SWA\", \"SWA_curve\")\nplot_metric(\"CWA\", \"CWA_curve\")\nplot_metric(\"SCHM\", \"SCHM_curve\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nruns_dict = experiment_data.get(\"pretrain_epochs\", {}).get(\"SPR_BENCH\", {})\nrun_keys = sorted(runs_dict.keys(), key=lambda x: int(x))  # e.g. ['2','4','6',...]\n\n\n# Helper to pick colors/linestyles that fit within default palette even for many lines\ndef _style(idx):\n    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n    return colors[idx % len(colors)], \"-\" if idx < len(colors) else \"--\"\n\n\n# ---------- 1. Pre-training loss curves ----------\ntry:\n    plt.figure()\n    for i, k in enumerate(run_keys):\n        losses = runs_dict[k][\"losses\"].get(\"pretrain\", [])\n        c, ls = _style(i)\n        plt.plot(\n            range(1, len(losses) + 1), losses, label=f\"PT={k}\", color=c, linestyle=ls\n        )\n    plt.title(\"SPR_BENCH: Pre-training Loss vs Epochs\")\n    plt.xlabel(\"Pre-training Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_pretrain_loss.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating pre-training loss plot: {e}\")\n    plt.close()\n\n# ---------- 2. Fine-tuning loss curves ----------\ntry:\n    plt.figure()\n    for i, k in enumerate(run_keys):\n        losses_train = runs_dict[k][\"losses\"].get(\"train\", [])\n        losses_val = runs_dict[k][\"losses\"].get(\"val\", [])\n        c, _ = _style(i)\n        plt.plot(\n            range(1, len(losses_train) + 1),\n            losses_train,\n            color=c,\n            linestyle=\"-\",\n            label=f\"Train (PT={k})\",\n        )\n        plt.plot(\n            range(1, len(losses_val) + 1),\n            losses_val,\n            color=c,\n            linestyle=\"--\",\n            label=f\"Val (PT={k})\",\n        )\n    plt.title(\"SPR_BENCH: Fine-tuning Loss (Train vs Val)\")\n    plt.xlabel(\"Fine-tuning Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend(ncol=2, fontsize=\"small\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_finetune_loss.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating fine-tuning loss plot: {e}\")\n    plt.close()\n\n\n# ---------- Metric plotting helper ----------\ndef plot_metric(metric_name, file_suffix):\n    try:\n        plt.figure()\n        for i, k in enumerate(run_keys):\n            vals = runs_dict[k][\"metrics\"].get(metric_name, [])\n            c, ls = _style(i)\n            plt.plot(\n                range(1, len(vals) + 1),\n                vals,\n                label=f\"{metric_name} (PT={k})\",\n                color=c,\n                linestyle=ls,\n            )\n        plt.title(f\"SPR_BENCH: {metric_name} across Fine-tuning Epochs\")\n        plt.xlabel(\"Fine-tuning Epoch\")\n        plt.ylabel(metric_name)\n        plt.legend(fontsize=\"small\")\n        fname = os.path.join(working_dir, f\"SPR_BENCH_{file_suffix}.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating {metric_name} plot: {e}\")\n        plt.close()\n\n\n# ---------- 3-5. Metric curves ----------\nplot_metric(\"SWA\", \"SWA_curve\")\nplot_metric(\"CWA\", \"CWA_curve\")\nplot_metric(\"SCHM\", \"SCHM_curve\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nruns_dict = experiment_data.get(\"pretrain_epochs\", {}).get(\"SPR_BENCH\", {})\nrun_keys = sorted(runs_dict.keys(), key=lambda x: int(x))  # e.g. ['2','4','6',...]\n\n\n# Helper to pick colors/linestyles that fit within default palette even for many lines\ndef _style(idx):\n    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n    return colors[idx % len(colors)], \"-\" if idx < len(colors) else \"--\"\n\n\n# ---------- 1. Pre-training loss curves ----------\ntry:\n    plt.figure()\n    for i, k in enumerate(run_keys):\n        losses = runs_dict[k][\"losses\"].get(\"pretrain\", [])\n        c, ls = _style(i)\n        plt.plot(\n            range(1, len(losses) + 1), losses, label=f\"PT={k}\", color=c, linestyle=ls\n        )\n    plt.title(\"SPR_BENCH: Pre-training Loss vs Epochs\")\n    plt.xlabel(\"Pre-training Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_pretrain_loss.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating pre-training loss plot: {e}\")\n    plt.close()\n\n# ---------- 2. Fine-tuning loss curves ----------\ntry:\n    plt.figure()\n    for i, k in enumerate(run_keys):\n        losses_train = runs_dict[k][\"losses\"].get(\"train\", [])\n        losses_val = runs_dict[k][\"losses\"].get(\"val\", [])\n        c, _ = _style(i)\n        plt.plot(\n            range(1, len(losses_train) + 1),\n            losses_train,\n            color=c,\n            linestyle=\"-\",\n            label=f\"Train (PT={k})\",\n        )\n        plt.plot(\n            range(1, len(losses_val) + 1),\n            losses_val,\n            color=c,\n            linestyle=\"--\",\n            label=f\"Val (PT={k})\",\n        )\n    plt.title(\"SPR_BENCH: Fine-tuning Loss (Train vs Val)\")\n    plt.xlabel(\"Fine-tuning Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend(ncol=2, fontsize=\"small\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_finetune_loss.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating fine-tuning loss plot: {e}\")\n    plt.close()\n\n\n# ---------- Metric plotting helper ----------\ndef plot_metric(metric_name, file_suffix):\n    try:\n        plt.figure()\n        for i, k in enumerate(run_keys):\n            vals = runs_dict[k][\"metrics\"].get(metric_name, [])\n            c, ls = _style(i)\n            plt.plot(\n                range(1, len(vals) + 1),\n                vals,\n                label=f\"{metric_name} (PT={k})\",\n                color=c,\n                linestyle=ls,\n            )\n        plt.title(f\"SPR_BENCH: {metric_name} across Fine-tuning Epochs\")\n        plt.xlabel(\"Fine-tuning Epoch\")\n        plt.ylabel(metric_name)\n        plt.legend(fontsize=\"small\")\n        fname = os.path.join(working_dir, f\"SPR_BENCH_{file_suffix}.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating {metric_name} plot: {e}\")\n        plt.close()\n\n\n# ---------- 3-5. Metric curves ----------\nplot_metric(\"SWA\", \"SWA_curve\")\nplot_metric(\"CWA\", \"CWA_curve\")\nplot_metric(\"SCHM\", \"SCHM_curve\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- basic setup ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- list of experiment files ----------\nexperiment_data_path_list = [\n    \"experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f8d17a8453644807b6265ed7a71263a1_proc_2989518/experiment_data.npy\",\n    \"experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6f8aa4ef9909408695ee9fcd5dde0c78_proc_2989519/experiment_data.npy\",\n    \"experiments/2025-08-15_22-24-43_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_df5bbf6cd848448fa6cc106d80343911_proc_2989517/experiment_data.npy\",\n]\n\n# ---------- load all experiments ----------\nall_experiment_data = []\ntry:\n    for p in experiment_data_path_list:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p)\n        exp_data = np.load(full_path, allow_pickle=True).item()\n        all_experiment_data.append(exp_data)\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\ndataset_name = \"SPR_BENCH\"\n\n\n# ---------- helper functions ----------\ndef _style(idx):\n    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n    return colors[idx % len(colors)], \"-\" if idx < len(colors) else \"--\"\n\n\ndef _collect_across_runs(key_level_3, subsection):\n    \"\"\"\n    key_level_3 : e.g. 'losses' or 'metrics'\n    subsection  : e.g. 'pretrain', 'train', 'val', 'SWA'...\n    returns dict: {PT_k : [run1_arr, run2_arr, ...]}\n    \"\"\"\n    out = {}\n    for exp in all_experiment_data:\n        try:\n            pt_dict = exp.get(\"pretrain_epochs\", {}).get(dataset_name, {})\n            for k, info in pt_dict.items():\n                arr = info.get(key_level_3, {}).get(subsection, [])\n                if arr:\n                    out.setdefault(k, []).append(np.asarray(arr))\n        except Exception:\n            continue\n    return out\n\n\ndef _mean_sem(list_of_arrays):\n    # cut to shortest run length\n    min_len = min(len(a) for a in list_of_arrays)\n    arr = np.stack([a[:min_len] for a in list_of_arrays], axis=0)  # (n_runs, T)\n    mean = arr.mean(axis=0)\n    sem = arr.std(axis=0, ddof=1) / np.sqrt(arr.shape[0])\n    return mean, sem\n\n\n# ---------- aggregated plots ----------\n# 1. Pre-training loss\ntry:\n    plt.figure()\n    data_dict = _collect_across_runs(\"losses\", \"pretrain\")\n    for i, k in enumerate(sorted(data_dict.keys(), key=lambda x: int(x))):\n        mean, sem = _mean_sem(data_dict[k])\n        xs = np.arange(1, len(mean) + 1)\n        c, ls = _style(i)\n        plt.plot(xs, mean, color=c, linestyle=ls, label=f\"PT={k} mean\")\n        plt.fill_between(xs, mean - sem, mean + sem, color=c, alpha=0.25)\n    plt.title(\"SPR_BENCH: Pre-training Loss (mean \u00b1 SEM)\")\n    plt.xlabel(\"Pre-training Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend(fontsize=\"small\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_pretrain_loss_aggregated.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated pre-training loss plot: {e}\")\n    plt.close()\n\n# 2. Fine-tuning loss (train+val)\ntry:\n    plt.figure()\n    train_dict = _collect_across_runs(\"losses\", \"train\")\n    val_dict = _collect_across_runs(\"losses\", \"val\")\n    for i, k in enumerate(sorted(train_dict.keys(), key=lambda x: int(x))):\n        if k not in val_dict:\n            continue\n        # train\n        mean_t, sem_t = _mean_sem(train_dict[k])\n        xs = np.arange(1, len(mean_t) + 1)\n        c, _ = _style(i)\n        plt.plot(xs, mean_t, color=c, linestyle=\"-\", label=f\"Train PT={k}\")\n        plt.fill_between(xs, mean_t - sem_t, mean_t + sem_t, color=c, alpha=0.20)\n        # val\n        mean_v, sem_v = _mean_sem(val_dict[k])\n        plt.plot(xs, mean_v, color=c, linestyle=\"--\", label=f\"Val PT={k}\")\n        plt.fill_between(xs, mean_v - sem_v, mean_v + sem_v, color=c, alpha=0.10)\n    plt.title(\"SPR_BENCH: Fine-tuning Loss (mean \u00b1 SEM)\")\n    plt.xlabel(\"Fine-tuning Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend(fontsize=\"small\", ncol=2)\n    fname = os.path.join(working_dir, \"SPR_BENCH_finetune_loss_aggregated.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated fine-tuning loss plot: {e}\")\n    plt.close()\n\n# 3-5. Metrics\nfor metric in [\"SWA\", \"CWA\", \"SCHM\"]:\n    try:\n        plt.figure()\n        m_dict = _collect_across_runs(\"metrics\", metric)\n        for i, k in enumerate(sorted(m_dict.keys(), key=lambda x: int(x))):\n            mean, sem = _mean_sem(m_dict[k])\n            xs = np.arange(1, len(mean) + 1)\n            c, ls = _style(i)\n            plt.plot(xs, mean, color=c, linestyle=ls, label=f\"PT={k} mean\")\n            plt.fill_between(xs, mean - sem, mean + sem, color=c, alpha=0.25)\n            # record final value for console\n            if xs[-1] == len(mean):\n                print(f\"{metric} final mean PT={k}: {mean[-1]:.4f} \u00b1 {sem[-1]:.4f}\")\n        plt.title(f\"SPR_BENCH: {metric} (mean \u00b1 SEM)\")\n        plt.xlabel(\"Fine-tuning Epoch\")\n        plt.ylabel(metric)\n        plt.legend(fontsize=\"small\")\n        fname = os.path.join(working_dir, f\"SPR_BENCH_{metric}_aggregated.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated {metric} plot: {e}\")\n        plt.close()\n"], "plot_plan": [null, "We first load the saved NumPy dictionary, pull out every run under learning_rate\u2192SPR_BENCH, and gather per-run arrays: lr value, pre-train loss (2 epochs), fine-tune train/val loss (3 epochs each), per-epoch metrics (SWA, CWA, SCHM), plus the final prediction lists.  \nFive figures are produced (each in its own try-except): (1) fine-tune train/val loss curves for every learning-rate, (2) pre-train loss curves, (3) SCHM curves over epochs, (4) bar chart of final-epoch SCHM versus learning-rate, (5) correctness breakdown (bars for correct/incorrect counts) for the best-performing learning-rate.  \nAll plots are titled with the dataset name and a clear subtitle and are saved to working_dir using descriptive filenames.  \nA maximum of five figures keeps the output compact while still covering optimisation behaviour and final quality.  \nBasic matplotlib is used; figures are always closed even on error.  \nThe code starts with the required imports and constructs working_dir, ensuring it exists.  \nFinally, each plot is written to PNG and nothing is simulated\u2014everything comes directly from experiment_data.npy.", "We will first load experiment_data.npy from the working directory and extract the dictionary stored inside. From it we gather the list of runs (different pre-training epoch settings) then, for each run, obtain arrays for pre-training losses, fine-tuning train/validation losses and the three metrics (SWA, CWA, SCHM). We aggregate these so we can overlay several runs on the same figure, keeping the number of plots \u2264 5. In total we will create five figures: (1) pre-training loss curves, (2) fine-tuning train/val loss curves, and (3-5) one figure for each metric across fine-tuning epochs. Every figure is wrapped in its own try-except block, uses a clear title referencing SPR_BENCH, employs descriptive subtitles where helpful, and is saved to working_dir with informative filenames. We respect the requirement to plot only existing data, close every figure in both normal and error cases, and refrain from drawing more than one figure per metric type. Finally, the script prints confirmation statements indicating where each plot was saved.", null, "We will load the saved experiment_data.npy, extract the \u2018SPR_BENCH\u2019 entry and pull out the epoch list, loss lists (train / val) and the four evaluation metrics recorded during fine-tuning (SWA, CWA, ACS, SCHM). Five separate plots will be produced: one loss curve and one curve for each metric across epochs, each wrapped in its own try-except block to comply with the plotting guideline. All figures are saved under descriptive names into the mandatory working directory and closed immediately afterwards. After loading the arrays we also locate the epoch that achieved the best validation loss, retrieve the corresponding metric values and print them so the user can see the final evaluation. We keep the code concise, begin with the required imports, and create working_dir if it is missing. Only data already stored in experiment_data.npy are used\u2014nothing is fabricated. Finally, the script prints the chosen best epoch and its metric values so that downstream checks can verify correctness.", "We first load experiment_data.npy, which contains results for four weight-decay settings keyed as strings. For every tag we extract epoch-level \u201ctrain\u201d and \u201cval\u201d losses and the three metrics (SWA, CWA, SCHM). We then build at most five figures: (1) an aggregated \u201ctrain loss vs epoch\u201d curve with one line per weight-decay; (2) the corresponding \u201cvalidation loss vs epoch\u201d; (3) a multi-line plot of SCHM over epochs; (4) a bar chart comparing the final epoch\u2019s SCHM for each weight-decay; and (5) a scatter plot of the final SWA vs CWA to see trade-offs. Each plot is wrapped in its own try/except so errors do not stop the script and figures are always closed. All plots are saved to working_dir with descriptive filenames that include the dataset name (here \u201cSPR\u201d) and plot type. No synthetic data are created\u2014everything is read directly from experiment_data.npy. Finally, we print the final SCHM values to give a quick textual summary.", null, null, null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": ["fine_tune_epochs", "learning_rate", "pretrain_epochs", "batch_size", null, "weight_decay (L2 regularization factor applied in Adam optimizer)", "contrastive_temperature", "dropout_rate", null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["", "The script will load the NumPy file from the \u201cworking\u201d directory, iterate\nthrough every stored run for each dataset, and aggregate the most informative\nvalues\u2014minimum losses and maximum evaluation scores\u2014across all epochs and\nlearning-rate trials. It then prints the dataset name followed by clearly\nlabeled best metrics so you can quickly see the strongest performance achieved\nin the sweep.", "The solution loads the saved NumPy dictionary, iterates through each dataset\n(here \u201cSPR_BENCH\u201d) and every hyper-parameter run stored under it, and prints the\nfinal values of all recorded metrics and losses. For clarity, each printed line\nexplicitly names the metric (e.g., \u201cfinal validation loss,\u201d \u201cfinal shape-\nweighted accuracy\u201d) before its value. The code follows the required structure:\nit is entirely at global scope, executes immediately, and produces no plots.", "", "The script will immediately load the saved NumPy dictionary from the working\ndirectory, iterate over every dataset it contains, and print a concise summary\nof key results.   For each dataset it prints the final training loss, the best\n(minimum) validation loss, and the final recorded values of shape-weighted\naccuracy, color-weighted accuracy, augmentation consistency score, and the\nshape\u2013color harmonic mean.   Metric names are spelled out clearly, and no plots\nare produced.", "The solution loads the saved NumPy file, iterates over every weight-decay\n\u201cdataset\u201d stored in the experiment dictionary, and prints the best (minimum for\nlosses, maximum for accuracies) value of every recorded metric. Each output line\nexplicitly names both the dataset (weight-decay value) and the metric so the\nresults are unambiguous.", "", "", "The solution loads the saved NumPy dictionary, iterates through each dataset\n(here \u201cSPR_BENCH\u201d) and every hyper-parameter run stored under it, and prints the\nfinal values of all recorded metrics and losses. For clarity, each printed line\nexplicitly names the metric (e.g., \u201cfinal validation loss,\u201d \u201cfinal shape-\nweighted accuracy\u201d) before its value. The code follows the required structure:\nit is entirely at global scope, executes immediately, and produces no plots.", "The solution loads the saved NumPy dictionary, iterates through each dataset\n(here \u201cSPR_BENCH\u201d) and every hyper-parameter run stored under it, and prints the\nfinal values of all recorded metrics and losses. For clarity, each printed line\nexplicitly names the metric (e.g., \u201cfinal validation loss,\u201d \u201cfinal shape-\nweighted accuracy\u201d) before its value. The code follows the required structure:\nit is entirely at global scope, executes immediately, and produces no plots.", "The solution loads the saved NumPy dictionary, iterates through each dataset\n(here \u201cSPR_BENCH\u201d) and every hyper-parameter run stored under it, and prints the\nfinal values of all recorded metrics and losses. For clarity, each printed line\nexplicitly names the metric (e.g., \u201cfinal validation loss,\u201d \u201cfinal shape-\nweighted accuracy\u201d) before its value. The code follows the required structure:\nit is entirely at global scope, executes immediately, and produces no plots.", ""], "parse_metrics_code": ["", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# Load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------\n# Helper to update best (min or max) values\ndef update_best(current_best, candidate, mode=\"min\"):\n    if mode == \"min\":\n        return candidate if candidate < current_best else current_best\n    if mode == \"max\":\n        return candidate if candidate > current_best else current_best\n    raise ValueError(\"mode must be 'min' or 'max'\")\n\n\n# -------------------------------------------------\n# Iterate through datasets and collect best metrics\nfor dataset_name, dataset_info in experiment_data[\"learning_rate\"].items():\n    runs = dataset_info[\"runs\"]\n\n    # Initialize best trackers\n    best_pretrain_loss = float(\"inf\")\n    best_training_loss = float(\"inf\")\n    best_validation_loss = float(\"inf\")\n    best_swa = -float(\"inf\")\n    best_cwa = -float(\"inf\")\n    best_schm = -float(\"inf\")\n\n    # Loop over all runs and epochs\n    for run in runs:\n        best_pretrain_loss = update_best(\n            best_pretrain_loss, min(run[\"losses\"][\"pretrain\"]), mode=\"min\"\n        )\n        best_training_loss = update_best(\n            best_training_loss, min(run[\"losses\"][\"train\"]), mode=\"min\"\n        )\n        best_validation_loss = update_best(\n            best_validation_loss, min(run[\"losses\"][\"val\"]), mode=\"min\"\n        )\n        best_swa = update_best(best_swa, max(run[\"metrics\"][\"SWA\"]), mode=\"max\")\n        best_cwa = update_best(best_cwa, max(run[\"metrics\"][\"CWA\"]), mode=\"max\")\n        best_schm = update_best(best_schm, max(run[\"metrics\"][\"SCHM\"]), mode=\"max\")\n\n    # -------------------------------------------------\n    # Print results for this dataset\n    print(f\"\\nDataset: {dataset_name}\")\n    print(f\"Lowest pretraining loss: {best_pretrain_loss:.4f}\")\n    print(f\"Lowest training loss: {best_training_loss:.4f}\")\n    print(f\"Lowest validation loss: {best_validation_loss:.4f}\")\n    print(f\"Best shape weighted accuracy: {best_swa:.4f}\")\n    print(f\"Best color weighted accuracy: {best_cwa:.4f}\")\n    print(f\"Best schema harmonic mean: {best_schm:.4f}\")\n", "import os\nimport numpy as np\n\n# -------- Locate and load the experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# -------- Parse and print the final metrics ------------\nfor dataset_name, runs in experiment_data.get(\"pretrain_epochs\", {}).items():\n    print(f\"\\nDataset: {dataset_name}\")\n    for run_key, run_dict in runs.items():\n        print(f\"Pretraining epochs: {run_key}\")\n\n        # Losses\n        final_pretrain_loss = (\n            run_dict[\"losses\"][\"pretrain\"][-1]\n            if run_dict[\"losses\"][\"pretrain\"]\n            else None\n        )\n        final_train_loss = (\n            run_dict[\"losses\"][\"train\"][-1] if run_dict[\"losses\"][\"train\"] else None\n        )\n        final_val_loss = (\n            run_dict[\"losses\"][\"val\"][-1] if run_dict[\"losses\"][\"val\"] else None\n        )\n\n        if final_pretrain_loss is not None:\n            print(f\"final pretraining loss: {final_pretrain_loss:.4f}\")\n        if final_train_loss is not None:\n            print(f\"final fine-tuning train loss: {final_train_loss:.4f}\")\n        if final_val_loss is not None:\n            print(f\"final validation loss: {final_val_loss:.4f}\")\n\n        # Metrics\n        final_swa = (\n            run_dict[\"metrics\"][\"SWA\"][-1] if run_dict[\"metrics\"][\"SWA\"] else None\n        )\n        final_cwa = (\n            run_dict[\"metrics\"][\"CWA\"][-1] if run_dict[\"metrics\"][\"CWA\"] else None\n        )\n        final_schm = (\n            run_dict[\"metrics\"][\"SCHM\"][-1] if run_dict[\"metrics\"][\"SCHM\"] else None\n        )\n\n        if final_swa is not None:\n            print(f\"final shape-weighted accuracy: {final_swa:.4f}\")\n        if final_cwa is not None:\n            print(f\"final color-weighted accuracy: {final_cwa:.4f}\")\n        if final_schm is not None:\n            print(f\"final SCHM score: {final_schm:.4f}\")\n\n        print(\"-\" * 40)\n", "", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# Locate and load the saved experiment dictionary\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------------------------------------------------------------------\n# Helper map for prettier metric names\npretty_metric_names = {\n    \"SWA\": \"shape-weighted accuracy\",\n    \"CWA\": \"color-weighted accuracy\",\n    \"ACS\": \"augmentation consistency score\",\n    \"SCHM\": \"shape\u2013color harmonic mean\",\n}\n\n# ---------------------------------------------------------------------\n# Iterate through datasets and print the requested information\nfor dataset_name, data in experiment_data.items():\n    print(dataset_name)  # dataset header\n\n    # Training and validation losses\n    train_losses = data[\"losses\"].get(\"train\", [])\n    val_losses = data[\"losses\"].get(\"val\", [])\n\n    if train_losses:\n        print(f\"final train loss: {train_losses[-1]:.4f}\")\n    if val_losses:\n        print(f\"best validation loss: {min(val_losses):.4f}\")\n\n    # Other metrics\n    for key, pretty_name in pretty_metric_names.items():\n        metric_values = data[\"metrics\"].get(key, [])\n        if metric_values:\n            print(f\"final {pretty_name}: {metric_values[-1]:.4f}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# Locate and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------\n# Helper to choose best value (min for losses, max for accuracies)\ndef best(values, minimize=True):\n    return min(values) if minimize else max(values)\n\n\n# -------------------------------------------------\n# Iterate over each \u201cdataset\u201d (weight-decay configuration) and report metrics\nfor wd_tag, data in experiment_data[\"weight_decay\"].items():\n    print(f\"Dataset: weight_decay = {wd_tag}\")\n    # Losses\n    print(\n        f\"  Best pretraining loss: {best(data['losses']['pretrain'], minimize=True):.4f}\"\n    )\n    print(f\"  Best training loss: {best(data['losses']['train'], minimize=True):.4f}\")\n    print(f\"  Best validation loss: {best(data['losses']['val'], minimize=True):.4f}\")\n    # Accuracies / metrics (maximize)\n    print(\n        f\"  Best shape weighted accuracy: {best(data['metrics']['SWA'], minimize=False):.4f}\"\n    )\n    print(\n        f\"  Best color weighted accuracy: {best(data['metrics']['CWA'], minimize=False):.4f}\"\n    )\n    print(\n        f\"  Best schema harmonic mean: {best(data['metrics']['SCHM'], minimize=False):.4f}\"\n    )\n    print()  # Blank line for readability\n", "", "", "import os\nimport numpy as np\n\n# -------- Locate and load the experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# -------- Parse and print the final metrics ------------\nfor dataset_name, runs in experiment_data.get(\"pretrain_epochs\", {}).items():\n    print(f\"\\nDataset: {dataset_name}\")\n    for run_key, run_dict in runs.items():\n        print(f\"Pretraining epochs: {run_key}\")\n\n        # Losses\n        final_pretrain_loss = (\n            run_dict[\"losses\"][\"pretrain\"][-1]\n            if run_dict[\"losses\"][\"pretrain\"]\n            else None\n        )\n        final_train_loss = (\n            run_dict[\"losses\"][\"train\"][-1] if run_dict[\"losses\"][\"train\"] else None\n        )\n        final_val_loss = (\n            run_dict[\"losses\"][\"val\"][-1] if run_dict[\"losses\"][\"val\"] else None\n        )\n\n        if final_pretrain_loss is not None:\n            print(f\"final pretraining loss: {final_pretrain_loss:.4f}\")\n        if final_train_loss is not None:\n            print(f\"final fine-tuning train loss: {final_train_loss:.4f}\")\n        if final_val_loss is not None:\n            print(f\"final validation loss: {final_val_loss:.4f}\")\n\n        # Metrics\n        final_swa = (\n            run_dict[\"metrics\"][\"SWA\"][-1] if run_dict[\"metrics\"][\"SWA\"] else None\n        )\n        final_cwa = (\n            run_dict[\"metrics\"][\"CWA\"][-1] if run_dict[\"metrics\"][\"CWA\"] else None\n        )\n        final_schm = (\n            run_dict[\"metrics\"][\"SCHM\"][-1] if run_dict[\"metrics\"][\"SCHM\"] else None\n        )\n\n        if final_swa is not None:\n            print(f\"final shape-weighted accuracy: {final_swa:.4f}\")\n        if final_cwa is not None:\n            print(f\"final color-weighted accuracy: {final_cwa:.4f}\")\n        if final_schm is not None:\n            print(f\"final SCHM score: {final_schm:.4f}\")\n\n        print(\"-\" * 40)\n", "import os\nimport numpy as np\n\n# -------- Locate and load the experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# -------- Parse and print the final metrics ------------\nfor dataset_name, runs in experiment_data.get(\"pretrain_epochs\", {}).items():\n    print(f\"\\nDataset: {dataset_name}\")\n    for run_key, run_dict in runs.items():\n        print(f\"Pretraining epochs: {run_key}\")\n\n        # Losses\n        final_pretrain_loss = (\n            run_dict[\"losses\"][\"pretrain\"][-1]\n            if run_dict[\"losses\"][\"pretrain\"]\n            else None\n        )\n        final_train_loss = (\n            run_dict[\"losses\"][\"train\"][-1] if run_dict[\"losses\"][\"train\"] else None\n        )\n        final_val_loss = (\n            run_dict[\"losses\"][\"val\"][-1] if run_dict[\"losses\"][\"val\"] else None\n        )\n\n        if final_pretrain_loss is not None:\n            print(f\"final pretraining loss: {final_pretrain_loss:.4f}\")\n        if final_train_loss is not None:\n            print(f\"final fine-tuning train loss: {final_train_loss:.4f}\")\n        if final_val_loss is not None:\n            print(f\"final validation loss: {final_val_loss:.4f}\")\n\n        # Metrics\n        final_swa = (\n            run_dict[\"metrics\"][\"SWA\"][-1] if run_dict[\"metrics\"][\"SWA\"] else None\n        )\n        final_cwa = (\n            run_dict[\"metrics\"][\"CWA\"][-1] if run_dict[\"metrics\"][\"CWA\"] else None\n        )\n        final_schm = (\n            run_dict[\"metrics\"][\"SCHM\"][-1] if run_dict[\"metrics\"][\"SCHM\"] else None\n        )\n\n        if final_swa is not None:\n            print(f\"final shape-weighted accuracy: {final_swa:.4f}\")\n        if final_cwa is not None:\n            print(f\"final color-weighted accuracy: {final_cwa:.4f}\")\n        if final_schm is not None:\n            print(f\"final SCHM score: {final_schm:.4f}\")\n\n        print(\"-\" * 40)\n", "import os\nimport numpy as np\n\n# -------- Locate and load the experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# -------- Parse and print the final metrics ------------\nfor dataset_name, runs in experiment_data.get(\"pretrain_epochs\", {}).items():\n    print(f\"\\nDataset: {dataset_name}\")\n    for run_key, run_dict in runs.items():\n        print(f\"Pretraining epochs: {run_key}\")\n\n        # Losses\n        final_pretrain_loss = (\n            run_dict[\"losses\"][\"pretrain\"][-1]\n            if run_dict[\"losses\"][\"pretrain\"]\n            else None\n        )\n        final_train_loss = (\n            run_dict[\"losses\"][\"train\"][-1] if run_dict[\"losses\"][\"train\"] else None\n        )\n        final_val_loss = (\n            run_dict[\"losses\"][\"val\"][-1] if run_dict[\"losses\"][\"val\"] else None\n        )\n\n        if final_pretrain_loss is not None:\n            print(f\"final pretraining loss: {final_pretrain_loss:.4f}\")\n        if final_train_loss is not None:\n            print(f\"final fine-tuning train loss: {final_train_loss:.4f}\")\n        if final_val_loss is not None:\n            print(f\"final validation loss: {final_val_loss:.4f}\")\n\n        # Metrics\n        final_swa = (\n            run_dict[\"metrics\"][\"SWA\"][-1] if run_dict[\"metrics\"][\"SWA\"] else None\n        )\n        final_cwa = (\n            run_dict[\"metrics\"][\"CWA\"][-1] if run_dict[\"metrics\"][\"CWA\"] else None\n        )\n        final_schm = (\n            run_dict[\"metrics\"][\"SCHM\"][-1] if run_dict[\"metrics\"][\"SCHM\"] else None\n        )\n\n        if final_swa is not None:\n            print(f\"final shape-weighted accuracy: {final_swa:.4f}\")\n        if final_cwa is not None:\n            print(f\"final color-weighted accuracy: {final_cwa:.4f}\")\n        if final_schm is not None:\n            print(f\"final SCHM score: {final_schm:.4f}\")\n\n        print(\"-\" * 40)\n", ""], "parse_term_out": ["", "['\\nDataset: SPR_BENCH', '\\n', 'Lowest pretraining loss: 4.8909', '\\n', 'Lowest\ntraining loss: 0.0330', '\\n', 'Lowest validation loss: 0.0156', '\\n', 'Best\nshape weighted accuracy: 0.9952', '\\n', 'Best color weighted accuracy: 0.9957',\n'\\n', 'Best schema harmonic mean: 0.9955', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'Pretraining epochs: 2', '\\n', 'final pretraining\nloss: 4.0178', '\\n', 'final fine-tuning train loss: 0.0152', '\\n', 'final\nvalidation loss: 0.0112', '\\n', 'final shape-weighted accuracy: 0.9974', '\\n',\n'final color-weighted accuracy: 0.9976', '\\n', 'final SCHM score: 0.9975', '\\n',\n'----------------------------------------', '\\n', 'Pretraining epochs: 4', '\\n',\n'final pretraining loss: 4.0134', '\\n', 'final fine-tuning train loss: 0.0106',\n'\\n', 'final validation loss: 0.0127', '\\n', 'final shape-weighted accuracy:\n0.9952', '\\n', 'final color-weighted accuracy: 0.9953', '\\n', 'final SCHM score:\n0.9952', '\\n', '----------------------------------------', '\\n', 'Pretraining\nepochs: 6', '\\n', 'final pretraining loss: 4.0115', '\\n', 'final fine-tuning\ntrain loss: 0.0101', '\\n', 'final validation loss: 0.0060', '\\n', 'final shape-\nweighted accuracy: 0.9985', '\\n', 'final color-weighted accuracy: 0.9985', '\\n',\n'final SCHM score: 0.9985', '\\n', '----------------------------------------',\n'\\n', 'Pretraining epochs: 8', '\\n', 'final pretraining loss: 4.0036', '\\n',\n'final fine-tuning train loss: 0.0088', '\\n', 'final validation loss: 0.0114',\n'\\n', 'final shape-weighted accuracy: 0.9960', '\\n', 'final color-weighted\naccuracy: 0.9962', '\\n', 'final SCHM score: 0.9961', '\\n',\n'----------------------------------------', '\\n', 'Pretraining epochs: 10',\n'\\n', 'final pretraining loss: 4.0024', '\\n', 'final fine-tuning train loss:\n0.0049', '\\n', 'final validation loss: 0.0087', '\\n', 'final shape-weighted\naccuracy: 0.9969', '\\n', 'final color-weighted accuracy: 0.9969', '\\n', 'final\nSCHM score: 0.9969', '\\n', '----------------------------------------', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "", "['SPR_BENCH', '\\n', 'final train loss: 0.6360', '\\n', 'best validation loss:\n0.6832', '\\n', 'final shape-weighted accuracy: 0.5419', '\\n', 'final color-\nweighted accuracy: 0.5341', '\\n', 'final augmentation consistency score:\n0.7200', '\\n', 'final shape\u2013color harmonic mean: 0.5380', '\\n', 'Execution time:\na moment seconds (time limit is 30 minutes).']", "['Dataset: weight_decay = 0.0', '\\n', '  Best pretraining loss: 4.8936', '\\n', '\nBest training loss: 0.0387', '\\n', '  Best validation loss: 0.0291', '\\n', '\nBest shape weighted accuracy: 0.9920', '\\n', '  Best color weighted accuracy:\n0.9926', '\\n', '  Best schema harmonic mean: 0.9923', '\\n', '\\n', 'Dataset:\nweight_decay = 1e-05', '\\n', '  Best pretraining loss: 4.8796', '\\n', '  Best\ntraining loss: 0.0307', '\\n', '  Best validation loss: 0.0283', '\\n', '  Best\nshape weighted accuracy: 0.9907', '\\n', '  Best color weighted accuracy:\n0.9910', '\\n', '  Best schema harmonic mean: 0.9909', '\\n', '\\n', 'Dataset:\nweight_decay = 0.0001', '\\n', '  Best pretraining loss: 4.9188', '\\n', '  Best\ntraining loss: 0.0390', '\\n', '  Best validation loss: 0.0218', '\\n', '  Best\nshape weighted accuracy: 0.9928', '\\n', '  Best color weighted accuracy:\n0.9934', '\\n', '  Best schema harmonic mean: 0.9931', '\\n', '\\n', 'Dataset:\nweight_decay = 0.001', '\\n', '  Best pretraining loss: 4.9233', '\\n', '  Best\ntraining loss: 0.0552', '\\n', '  Best validation loss: 0.0487', '\\n', '  Best\nshape weighted accuracy: 0.9876', '\\n', '  Best color weighted accuracy:\n0.9874', '\\n', '  Best schema harmonic mean: 0.9875', '\\n', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "", "", "['\\nDataset: SPR_BENCH', '\\n', 'Pretraining epochs: 2', '\\n', 'final pretraining\nloss: 4.0243', '\\n', 'final fine-tuning train loss: 0.0144', '\\n', 'final\nvalidation loss: 0.0074', '\\n', 'final shape-weighted accuracy: 0.9969', '\\n',\n'final color-weighted accuracy: 0.9972', '\\n', 'final SCHM score: 0.9971', '\\n',\n'----------------------------------------', '\\n', 'Pretraining epochs: 4', '\\n',\n'final pretraining loss: 4.0133', '\\n', 'final fine-tuning train loss: 0.0113',\n'\\n', 'final validation loss: 0.0093', '\\n', 'final shape-weighted accuracy:\n0.9969', '\\n', 'final color-weighted accuracy: 0.9969', '\\n', 'final SCHM score:\n0.9969', '\\n', '----------------------------------------', '\\n', 'Pretraining\nepochs: 6', '\\n', 'final pretraining loss: 4.0084', '\\n', 'final fine-tuning\ntrain loss: 0.0097', '\\n', 'final validation loss: 0.0084', '\\n', 'final shape-\nweighted accuracy: 0.9983', '\\n', 'final color-weighted accuracy: 0.9983', '\\n',\n'final SCHM score: 0.9983', '\\n', '----------------------------------------',\n'\\n', 'Pretraining epochs: 8', '\\n', 'final pretraining loss: 4.0067', '\\n',\n'final fine-tuning train loss: 0.0066', '\\n', 'final validation loss: 0.0057',\n'\\n', 'final shape-weighted accuracy: 0.9974', '\\n', 'final color-weighted\naccuracy: 0.9976', '\\n', 'final SCHM score: 0.9975', '\\n',\n'----------------------------------------', '\\n', 'Pretraining epochs: 10',\n'\\n', 'final pretraining loss: 4.0056', '\\n', 'final fine-tuning train loss:\n0.0035', '\\n', 'final validation loss: 0.0045', '\\n', 'final shape-weighted\naccuracy: 0.9987', '\\n', 'final color-weighted accuracy: 0.9984', '\\n', 'final\nSCHM score: 0.9985', '\\n', '----------------------------------------', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'Pretraining epochs: 2', '\\n', 'final pretraining\nloss: 4.0195', '\\n', 'final fine-tuning train loss: 0.0087', '\\n', 'final\nvalidation loss: 0.0102', '\\n', 'final shape-weighted accuracy: 0.9964', '\\n',\n'final color-weighted accuracy: 0.9966', '\\n', 'final SCHM score: 0.9965', '\\n',\n'----------------------------------------', '\\n', 'Pretraining epochs: 4', '\\n',\n'final pretraining loss: 4.0124', '\\n', 'final fine-tuning train loss: 0.0105',\n'\\n', 'final validation loss: 0.0087', '\\n', 'final shape-weighted accuracy:\n0.9965', '\\n', 'final color-weighted accuracy: 0.9969', '\\n', 'final SCHM score:\n0.9967', '\\n', '----------------------------------------', '\\n', 'Pretraining\nepochs: 6', '\\n', 'final pretraining loss: 4.0071', '\\n', 'final fine-tuning\ntrain loss: 0.0049', '\\n', 'final validation loss: 0.0055', '\\n', 'final shape-\nweighted accuracy: 0.9980', '\\n', 'final color-weighted accuracy: 0.9980', '\\n',\n'final SCHM score: 0.9980', '\\n', '----------------------------------------',\n'\\n', 'Pretraining epochs: 8', '\\n', 'final pretraining loss: 4.0030', '\\n',\n'final fine-tuning train loss: 0.0067', '\\n', 'final validation loss: 0.0071',\n'\\n', 'final shape-weighted accuracy: 0.9974', '\\n', 'final color-weighted\naccuracy: 0.9975', '\\n', 'final SCHM score: 0.9975', '\\n',\n'----------------------------------------', '\\n', 'Pretraining epochs: 10',\n'\\n', 'final pretraining loss: 4.0028', '\\n', 'final fine-tuning train loss:\n0.0045', '\\n', 'final validation loss: 0.0058', '\\n', 'final shape-weighted\naccuracy: 0.9980', '\\n', 'final color-weighted accuracy: 0.9980', '\\n', 'final\nSCHM score: 0.9980', '\\n', '----------------------------------------', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'Pretraining epochs: 2', '\\n', 'final pretraining\nloss: 4.0200', '\\n', 'final fine-tuning train loss: 0.0132', '\\n', 'final\nvalidation loss: 0.0113', '\\n', 'final shape-weighted accuracy: 0.9976', '\\n',\n'final color-weighted accuracy: 0.9977', '\\n', 'final SCHM score: 0.9976', '\\n',\n'----------------------------------------', '\\n', 'Pretraining epochs: 4', '\\n',\n'final pretraining loss: 4.0143', '\\n', 'final fine-tuning train loss: 0.0102',\n'\\n', 'final validation loss: 0.0086', '\\n', 'final shape-weighted accuracy:\n0.9963', '\\n', 'final color-weighted accuracy: 0.9966', '\\n', 'final SCHM score:\n0.9965', '\\n', '----------------------------------------', '\\n', 'Pretraining\nepochs: 6', '\\n', 'final pretraining loss: 4.0075', '\\n', 'final fine-tuning\ntrain loss: 0.0116', '\\n', 'final validation loss: 0.0046', '\\n', 'final shape-\nweighted accuracy: 0.9984', '\\n', 'final color-weighted accuracy: 0.9985', '\\n',\n'final SCHM score: 0.9985', '\\n', '----------------------------------------',\n'\\n', 'Pretraining epochs: 8', '\\n', 'final pretraining loss: 4.0079', '\\n',\n'final fine-tuning train loss: 0.0048', '\\n', 'final validation loss: 0.0037',\n'\\n', 'final shape-weighted accuracy: 0.9989', '\\n', 'final color-weighted\naccuracy: 0.9988', '\\n', 'final SCHM score: 0.9989', '\\n',\n'----------------------------------------', '\\n', 'Pretraining epochs: 10',\n'\\n', 'final pretraining loss: 4.0082', '\\n', 'final fine-tuning train loss:\n0.0032', '\\n', 'final validation loss: 0.0048', '\\n', 'final shape-weighted\naccuracy: 0.9991', '\\n', 'final color-weighted accuracy: 0.9991', '\\n', 'final\nSCHM score: 0.9991', '\\n', '----------------------------------------', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
