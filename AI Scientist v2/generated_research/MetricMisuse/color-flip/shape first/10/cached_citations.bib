
% The foundational work on SimCLR (Chen et al., 2020), demonstrating the effectiveness of contrastive learning in self-supervised visual representation learning. This is relevant for summarizing the existing literature on contrastive learning and serves as a basis for the proposed context-aware contrastive learning method in this study. It will be cited in the section discussing contrastive learning and its enhancements.
@article{chakraborty2020gsimclrsc,
 author = {Souradip Chakraborty and A. R. Gosthipaty and Sayak Paul},
 booktitle = {2020 International Conference on Data Mining Workshops (ICDMW)},
 journal = {2020 International Conference on Data Mining Workshops (ICDMW)},
 pages = {912-916},
 title = {G-SimCLR: Self-Supervised Contrastive Learning with Guided Projection via Pseudo Labelling},
 year = {2020}
}

% This paper discusses the challenges of symbolic reasoning, particularly focusing on generalization and interpretable methods, using a systematic abductive reasoning model. It is relevant as it provides a foundational understanding of the limitations and potential of symbolic reasoning approaches, which the proposed context-aware contrastive learning method aims to address. It should be cited in the section discussing symbolic reasoning and its challenges to highlight the research gap the study addresses.
@article{sun2025systematicar,
 author = {Zhong-Hua Sun and Rui Zhang and Zonglei Zhen and Da-Hui Wang and Yong-Jie Li and Xiaohong Wan and Hongzhi You},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Systematic Abductive Reasoning via Diverse Relation Representations in Vector-symbolic Architecture},
 volume = {abs/2501.11896},
 year = {2025}
}

% Paper 1 discusses similarity-guided diffusion models for contrastive learning, leveraging semantically consistent noise and context-aware augmentation, which aligns well with the proposed enhancements for symbolic sequences. Paper 3 explores decomposition-based data augmentation for semi-supervised contrastive learning in time series, providing transferable insights for designing augmentation techniques for symbolic tasks. These should be cited in the section discussing advanced data augmentation and denoising techniques in contrastive learning.
@inproceedings{choi2025similarityguideddf,
 author = {Jinkyeong Choi and Yejin Noh and Donghyeon Park},
 title = {Similarity-Guided Diffusion for Contrastive Sequential Recommendation},
 year = {2025}
}

@article{kim2024semisupervisedcl,
 author = {Dokyun Kim and Sukhyun Cho and Heewoong Chae and Jonghun Park and Jaeseok Huh},
 booktitle = {Intelligent Data Analysis},
 journal = {Intelligent Data Analysis},
 pages = {94 - 115},
 title = {Semi-supervised contrastive learning with decomposition-based data augmentation for time series classification},
 volume = {29},
 year = {2024}
}
