\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{himabindu2023neurosymbolicai,bortolotti2024anb}
\citation{chen2020asf,moseley2024polyclcc}
\citation{shi2022enhancingsc,sheng2025explicitie}
\citation{goodfellow2016deep,himabindu2023neurosymbolicai}
\citation{bortolotti2024anb}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Method}{1}{section.3}\protected@file@percent }
\newlabel{fig:baseline_a}{{1(a)}{2}{Subfigure 1(a)}{subfigure.1.1}{}}
\newlabel{fig:baseline_a@cref}{{[subfigure][1][1]1(a)}{[1][2][]2}}
\newlabel{sub@fig:baseline_a}{{(a)}{2}{Subfigure 1(a)\relax }{subfigure.1.1}{}}
\newlabel{fig:baseline_b}{{1(b)}{2}{Subfigure 1(b)}{subfigure.1.2}{}}
\newlabel{fig:baseline_b@cref}{{[subfigure][2][1]1(b)}{[1][2][]2}}
\newlabel{sub@fig:baseline_b}{{(b)}{2}{Subfigure 1(b)\relax }{subfigure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Sample baseline metrics on SPR. (a) Cross-entropy loss vs. epoch. (b) Validation SCWA curves. SCWA is a combined measure for shape- and color-weighted accuracy.}}{2}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Baseline Loss Curves}}}{2}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Baseline Validation SCWA}}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:research_a}{{2(a)}{2}{Subfigure 2(a)}{subfigure.2.1}{}}
\newlabel{fig:research_a@cref}{{[subfigure][1][2]2(a)}{[1][2][]2}}
\newlabel{sub@fig:research_a}{{(a)}{2}{Subfigure 2(a)\relax }{subfigure.2.1}{}}
\newlabel{fig:research_b}{{2(b)}{2}{Subfigure 2(b)}{subfigure.2.2}{}}
\newlabel{fig:research_b@cref}{{[subfigure][2][2]2(b)}{[1][2][]2}}
\newlabel{sub@fig:research_b}{{(b)}{2}{Subfigure 2(b)\relax }{subfigure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Research-phase results. (a) Pre-training contrastive loss decreases steadily. (b) Final test metrics: SWA $>$ 65.0\%, CWA $<$ 70.0\%.}}{2}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Contrastive Pre-training Loss}}}{2}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Test Metrics Summary}}}{2}{figure.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{2}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{2}{section.5}\protected@file@percent }
\bibdata{iclr2025}
\bibcite{goodfellow2016deep}{{1}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, Courville, and Bengio}}}
\bibstyle{iclr2025}
\newlabel{sec:appendix}{{5}{3}{\LARGE Supplementary Material}{section*.2}{}}
\newlabel{sec:appendix@cref}{{[section][5][]5}{[1][3][]3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Train vs.\ validation loss curves for contrastive fine-tuning. The validation loss remains higher than training, suggesting moderate overfitting.}}{3}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Validation metrics (accuracy and ACA) during contrastive fine-tuning. Accuracy stabilizes while ACA varies, indicating uneven improvement in certain attribute classes.}}{4}{figure.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Ablation study: no-pretraining scenario. Performance degrades on color-based tasks without contrastive initialization.}}{4}{figure.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Ablation study: MLM-based pre-training versus contrastive pre-training. MLM alone offers minimal gains for color-specific patterns.}}{4}{figure.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Frozen-encoder fine-tuning ablation. Fixing encoder weights hampers generalization, emphasizing the need for end-to-end training.}}{5}{figure.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Masking-only augmentation ablation. Removing shuffling further reduces color performance.}}{5}{figure.8}\protected@file@percent }
\gdef \@abspage@last{5}
