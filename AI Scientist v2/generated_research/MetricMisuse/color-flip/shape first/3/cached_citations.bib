
% This paper introduces SimCLR, a foundational framework for contrastive learning, emphasizing the importance of augmentation strategies, nonlinear transformations, and batch sizes. It is highly relevant to the proposed context-aware contrastive learning framework and should be cited in the related work section to support the methodological foundation of the study.
@article{chen2020asf,
 author = {Ting Chen and Simon Kornblith and Mohammad Norouzi and Geoffrey E. Hinton},
 booktitle = {International Conference on Machine Learning},
 journal = {ArXiv},
 title = {A Simple Framework for Contrastive Learning of Visual Representations},
 volume = {abs/2002.05709},
 year = {2020}
}

% This paper discusses the integration of symbolic reasoning with deep learning, addressing challenges like reliance on labeled data, generalization, and noise robustness. It is highly relevant for providing background and highlighting research gaps in the symbolic reasoning domain, particularly in motivating the use of contrastive learning for symbolic tasks. This citation should be included in the 'Symbolic Reasoning' section of the related work to contextualize the challenges addressed by the proposed method.
@conference{himabindu2023neurosymbolicai,
 author = {Modi Himabindu and Revathi V and Manish Gupta and Ajay Rana and Pradeep Kumar Chandra and H. S. Abdulaali},
 booktitle = {IEEE Uttar Pradesh Section International Conference on Electrical, Computer and Electronics Engineering},
 journal = {2023 10th IEEE Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)},
 pages = {1587-1592},
 title = {Neuro-Symbolic AI: Integrating Symbolic Reasoning with Deep Learning},
 volume = {10},
 year = {2023}
}

% The paper 'A Neuro-Symbolic Benchmark Suite for Concept Quality and Reasoning Shortcuts' introduces rsbench, a benchmark suite for evaluating reasoning tasks and addressing reasoning shortcuts in neuro-symbolic models. It is relevant for providing context on benchmarking challenges in symbolic reasoning and can be cited in the 'Related Work' section to emphasize the importance of benchmarks like SPR_BENCH for evaluating symbolic pattern recognition systems.
@article{bortolotti2024anb,
 author = {Samuele Bortolotti and Emanuele Marconato and Tommaso Carraro and Paolo Morettin and Emile van Krieken and Antonio Vergari and Stefano Teso and Andrea Passerini},
 booktitle = {Neural Information Processing Systems},
 title = {A Neuro-Symbolic Benchmark Suite for Concept Quality and Reasoning Shortcuts},
 year = {2024}
}

% This paper introduces a contrastive learning model enhanced with denoising networks to eliminate noise in sequences, enabling better representation learning for sequential recommendation tasks. The denoising techniques discussed are directly relevant to the proposed context-aware contrastive learning framework in this study, which aims to improve feature representations for symbolic sequences. This citation will be included in the 'Related Work' section to substantiate the use of denoising as a strategy for improving contrastive learning in symbolic tasks.
@article{sheng2025explicitie,
 author = {Jinfang Sheng and Xuhao Zhang and Bin Wang},
 booktitle = {Scientific Reports},
 journal = {Scientific Reports},
 title = {Explicit intent enhanced contrastive learning with denoising networks for sequential recommendation},
 volume = {15},
 year = {2025}
}

% This paper discusses soft data augmentation strategies, including dynamic masking and replacing of tokens, tailored for sequence-level tasks. It is relevant to our study as it aligns with our focus on using context-preserving augmentations like token shuffling and masking for symbolic sequences. This citation should be included in the 'Related Work' section to support the methodological choices for data augmentation in the proposed framework.
@article{shi2022enhancingsc,
 author = {Ensheng Shi and Wenchao Gub and Yanlin Wang and Lun Du and Hongyu Zhang and Shi Han and Dongmei Zhang and Hongbin Sun},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Enhancing Semantic Code Search with Multimodal Contrastive Learning and Soft Data Augmentation},
 volume = {abs/2204.03293},
 year = {2022}
}

% This paper introduces a context-aware self-supervised contrastive learning framework for medical image segmentation, demonstrating the utility of leveraging inherent relationships and context-aware discriminant features. Its methodology aligns with the proposed approach of enhancing symbolic pattern recognition with context-aware contrastive learning. This citation will be included in the 'Related Work' section to substantiate the use of context-aware contrastive methods for improving task-specific performance.
@article{moseley2024polyclcc,
 author = {Aaron Moseley and Abdullah-Al-Zubaer Imran},
 booktitle = {IEEE International Symposium on Biomedical Imaging},
 journal = {2024 IEEE International Symposium on Biomedical Imaging (ISBI)},
 pages = {1-4},
 title = {Polycl: Context-Aware Contrastive Learning for Image Segmentation},
 year = {2024}
}
