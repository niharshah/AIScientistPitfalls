<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[4, 11], [4, 10], [4, 8], [4, 9]], "layout": [[0.0, 0.0], [0.14285714285714285, 0.0], [0.2857142857142857, 0.0], [0.42857142857142855, 0.0], [0.5714285714285714, 0.0], [0.7142857142857143, 0.0], [0.8571428571428571, 0.0], [1.0, 0.0], [0.35714285714285715, 1.0], [0.5, 1.0], [0.6428571428571429, 1.0], [0.7857142857142857, 1.0]], "plan": ["Hyperparam tuning name: num_epochs. Below is an updated script that trains a\nfresh Bi-LSTM for several epoch budgets (6, 12 and 18) and records the resulting\nlosses/metrics for each run inside\nexperiment_data['num_epochs']['SPR_BENCH'][<epoch_budget>]. Everything else\n(dataset handling, model, saving to experiment_data.npy) remains unchanged.", "Hyperparam tuning name: learning_rate. We keep the original preprocessing/data-\nloading unchanged, but wrap the model construction, optimizer, and training loop\ninside a function that we call for each candidate learning-rate (3e-4, 1e-3,\n3e-3).   For every run we train the Bi-LSTM for six epochs, log train/validation\nlosses and the three task metrics, then store the results in an experiment_data\ndictionary under the top-level key \"learning_rate\" \u2192 str(lr).   After finishing\nthe sweep we dump the whole dictionary to working/experiment_data.npy so that\nall curves can be plotted later.   The rest of the code is identical to the\nbaseline; we only added a loop over lr values and a quick GPU-memory cleanup\nbetween runs.", "Hyperparam tuning name: batch_size. Below is a compact implementation that loops\nover four training mini-batch sizes (64, 128, 256, 512), trains a fresh Bi-LSTM\nfor six epochs each, evaluates on the dev split every epoch and stores every\nplottable artifact into the required experiment_data dictionary before saving it\nto \u201cexperiment_data.npy\u201d.", "Hyperparam tuning name: dropout_rate. We add a dropout layer after the embedding\nand after the BiLSTM, expose its probability as dropout_rate, and iterate over\nthe grid [0.0, 0.2, 0.3, 0.5].   For every rate a fresh model is trained (6\nepochs) and evaluated; losses, metrics and predictions are stored in\nexperiment_data under the key 'dropout_rate' \u2192 'SPR_BENCH' \u2192 'p={rate}'.\nFinally the whole container is saved to experiment_data.npy.", "Hyperparam tuning name: hidden_size (LSTM hidden dimension). We keep the\noriginal data\u2010loading, metrics and training loop, but wrap the whole training\nprocedure in a function that we call for every candidate hidden_size (64, 128,\n256, 512).   For every run we create a fresh Bi-LSTM whose hidden dimension is\nset to the current value, train for six epochs, validate after each epoch and\nstore losses/metrics/predictions inside experiment_data using the hierarchy\nexperiment_data['hidden_size'][<size>]['SPR_BENCH'].   When all sweeps finish\nthe aggregated experiment_data dictionary is saved as \u201cexperiment_data.npy\u201d,\nallowing later analysis or plotting.   Nothing else about the original pipeline\nis changed, so the script remains self-contained and directly executable.", "Hyperparam tuning name: embedding_dim. We sweep four embedding sizes (32 / 64 /\n128 / 256), rebuild the Bi-LSTM for each value, train for six epochs with the\nsame optimiser and data loaders, and store every run under a separate key in the\nexperiment_data dictionary (e.g. \u201cemb_dim_32\u201d \u2192 \u201cSPR_BENCH\u201d \u2192 metrics / losses\n\u2026).   The remainder of the pipeline (data loading, vocabulary, evaluation\nmetrics, saving with np.save) stays unchanged, ensuring the script is fully\nself-contained and immediately executable.", "Hyperparam tuning name: weight_decay (L2 regularization coefficient). We loop\nover five weight-decay values, rebuild a fresh Bi-LSTM and Adam optimizer for\neach value, train for a small fixed number of epochs, evaluate on the dev set\nevery epoch and collect the same losses/metrics as the baseline.   Results for\nevery run are stored in\nexperiment_data[\"weight_decay\"][\"SPR_BENCH\"][f\"wd_{value}\"] so that downstream\nscripts can easily compare curves.   At the end all data are dumped into\nworking/experiment_data.npy exactly once.   The rest of the pipeline (dataset\nloading, vocabulary, model definition, training loop) is the unchanged baseline\ncode.", "Hyperparam tuning name: gradient_clipping_max_norm. The solution runs the\noriginal Bi-LSTM experiment five times, each with a different global gradient-\nclipping maximum norm (0 \u21d2 no clipping, 0.5, 1, 2, 5).   For every setting it\nre-initialises the model, optimizer and RNG seeds, performs the full 6-epoch\ntraining loop, applies `torch.nn.utils.clip_grad_norm_` when the chosen value is\n>0, records losses and HWA metrics, and finally stores everything in a single\n`experiment_data.npy` file organised under the key `gradient_clipping_max_norm`.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, numpy as np, torch, torch.nn as nn, random, math, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- reproducibility ----------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# ---------- working directory & device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- locate SPR_BENCH ----------\ndef find_spr_bench() -> pathlib.Path:\n    candidates = []\n    env_path = os.environ.get(\"SPR_DATA_PATH\")\n    if env_path:\n        candidates.append(env_path)\n    candidates += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in candidates:\n        pth = pathlib.Path(p).expanduser()\n        if p and pth.joinpath(\"train.csv\").exists():\n            return pth.resolve()\n    raise FileNotFoundError(\"SPR_BENCH not found.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ---------- helper: load SPR_BENCH ----------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\nspr = load_spr_bench(DATA_PATH)\n\n# ---------- build vocabulary ----------\nall_tokens = {tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split()}\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq):\n    return [token2id[t] for t in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size={vocab_size}, num_classes={num_classes}\")\n\n\n# ---------- metrics ----------\ndef count_shape_variety(sequence):\n    return len({tok[0] for tok in sequence.split() if tok})\n\n\ndef count_color_variety(sequence):\n    return len({tok[1] for tok in sequence.split() if len(tok) > 1})\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0\n\n\n# ---------- PyTorch dataset ----------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.enc = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.enc[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(x[\"input_ids\"]) for x in batch)\n    ids, lab, raw = [], [], []\n    for itm in batch:\n        seq = itm[\"input_ids\"]\n        pad = maxlen - len(seq)\n        if pad:\n            seq = torch.cat([seq, torch.full((pad,), PAD_ID, dtype=torch.long)])\n        ids.append(seq)\n        lab.append(itm[\"label\"])\n        raw.append(itm[\"raw_seq\"])\n    return {\"input_ids\": torch.stack(ids), \"label\": torch.stack(lab), \"raw_seq\": raw}\n\n\ntrain_loader_full = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader_full = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ---------- model ----------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], 1)\n        return self.fc(out)\n\n\n# ---------- hyper-parameter tuning (num_epochs) ----------\nEPOCH_LIST = [6, 12, 18]\n\nexperiment_data = {\"num_epochs\": {\"SPR_BENCH\": {}}}\n\n\ndef train_for_epochs(num_epochs: int):\n    model = BiLSTMClassifier(vocab_size, num_cls=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    run_data = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for ep in range(1, num_epochs + 1):\n        # train\n        model.train()\n        tot_loss = 0\n        n = 0\n        for batch in train_loader_full:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optim.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optim.step()\n            tot_loss += loss.item()\n            n += 1\n        train_loss = tot_loss / n\n        run_data[\"losses\"][\"train\"].append((ep, train_loss))\n\n        # val\n        model.eval()\n        vtot = 0\n        vn = 0\n        preds, labels, raw = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader_full:\n                batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                vtot += loss.item()\n                vn += 1\n                p = logits.argmax(-1).cpu().tolist()\n                l = batch[\"label\"].cpu().tolist()\n                preds.extend(p)\n                labels.extend(l)\n                raw.extend(batch[\"raw_seq\"])\n        val_loss = vtot / vn\n        run_data[\"losses\"][\"val\"].append((ep, val_loss))\n        swa = shape_weighted_accuracy(raw, labels, preds)\n        cwa = color_weighted_accuracy(raw, labels, preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        run_data[\"metrics\"][\"val\"].append((ep, swa, cwa, hwa))\n        run_data[\"predictions\"], run_data[\"ground_truth\"] = preds, labels\n        print(\n            f\"[{num_epochs} ep run] Epoch {ep}: train_loss={train_loss:.4f} \"\n            f\"val_loss={val_loss:.4f} HWA={hwa:.4f}\"\n        )\n    return run_data\n\n\nfor ep_budget in EPOCH_LIST:\n    experiment_data[\"num_epochs\"][\"SPR_BENCH\"][ep_budget] = train_for_epochs(ep_budget)\n\n# ---------- save ----------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved experiment data to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, random, math, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------- experiment data container ----------\nexperiment_data = {\"learning_rate\": {}}\n\n# ---------- working directory & device ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- locate SPR_BENCH ---------------------\ndef find_spr_bench() -> pathlib.Path:\n    candidates = []\n    env_path = os.environ.get(\"SPR_DATA_PATH\")\n    if env_path:\n        candidates.append(env_path)\n    candidates += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in candidates:\n        if p and pathlib.Path(p).expanduser().joinpath(\"train.csv\").exists():\n            return pathlib.Path(p).expanduser().resolve()\n    raise FileNotFoundError(\n        \"Could not find SPR_BENCH dataset. \"\n        \"Set environment variable SPR_DATA_PATH or place the folder next to this script.\"\n    )\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ---------- helper: load SPR_BENCH --------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\n# ---------- load dataset ------------------------\nspr = load_spr_bench(DATA_PATH)\n\n# ---------- build vocabulary -------------------\nall_tokens = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq: str):\n    return [token2id[tok] for tok in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size = {vocab_size},  num_classes = {num_classes}\")\n\n\n# ---------- PyTorch Dataset --------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.encoded = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.encoded[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(item[\"input_ids\"]) for item in batch)\n    input_ids, labels, raw = [], [], []\n    for item in batch:\n        seq = item[\"input_ids\"]\n        pad_len = maxlen - len(seq)\n        if pad_len:\n            seq = torch.cat([seq, torch.full((pad_len,), PAD_ID, dtype=torch.long)])\n        input_ids.append(seq)\n        labels.append(item[\"label\"])\n        raw.append(item[\"raw_seq\"])\n    return {\n        \"input_ids\": torch.stack(input_ids),\n        \"label\": torch.stack(labels),\n        \"raw_seq\": raw,\n    }\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ---------- model definition -------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], dim=1)\n        return self.fc(out)\n\n\n# ---------- training function ------------------\ndef run_experiment(lr_value: float, epochs: int = 6):\n    print(f\"\\n=== Starting run with learning rate = {lr_value} ===\")\n    model = BiLSTMClassifier(vocab_size, num_cls=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr_value)\n\n    log = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, epochs + 1):\n        # training\n        model.train()\n        total_loss, n_batch = 0.0, 0\n        for batch in train_loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            n_batch += 1\n        train_loss = total_loss / n_batch\n        log[\"losses\"][\"train\"].append((epoch, train_loss))\n\n        # validation\n        model.eval()\n        val_loss_tot, nb = 0.0, 0\n        all_preds, all_labels, all_seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss_tot += loss.item()\n                nb += 1\n                preds = logits.argmax(-1).cpu().tolist()\n                labels = batch[\"label\"].cpu().tolist()\n                all_preds.extend(preds)\n                all_labels.extend(labels)\n                all_seqs.extend(batch[\"raw_seq\"])\n        val_loss = val_loss_tot / nb\n        log[\"losses\"][\"val\"].append((epoch, val_loss))\n        swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n        cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        log[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n        log[\"predictions\"], log[\"ground_truth\"] = all_preds, all_labels\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f} \"\n            f\"SWA={swa:.4f}  CWA={cwa:.4f}  HWA={hwa:.4f}\"\n        )\n\n    # move log to global container\n    experiment_data[\"learning_rate\"][str(lr_value)] = log\n    # clean up\n    del model, optimizer, criterion\n    torch.cuda.empty_cache()\n\n\n# ---------- hyperparameter sweep ---------------\nfor lr in [3e-4, 1e-3, 3e-3]:\n    run_experiment(lr_value=lr, epochs=6)\n\n# ---------- save experiment data ---------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment data to {os.path.join(working_dir, 'experiment_data.npy')}\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, random, math, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n\n# ------------------- utility --------------------\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n\nset_seed()\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\ndef find_spr_bench() -> pathlib.Path:\n    candidates = [\n        os.environ.get(\"SPR_DATA_PATH\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in candidates:\n        if p and pathlib.Path(p).expanduser().joinpath(\"train.csv\").exists():\n            return pathlib.Path(p).expanduser().resolve()\n    raise FileNotFoundError(\"SPR_BENCH not found.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ----------------- load dataset -----------------\ndef load_spr_bench(root) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\nspr = load_spr_bench(DATA_PATH)\n\n# ----------------- vocabulary -------------------\nall_tokens = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq: str):\n    return [token2id[t] for t in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size={vocab_size}, num_classes={num_classes}\")\n\n\n# ------------------ dataset ---------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.encoded = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.encoded[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(b[\"input_ids\"]) for b in batch)\n    pad = lambda t: (\n        torch.cat([t, torch.full((maxlen - len(t),), PAD_ID, dtype=torch.long)])\n        if len(t) < maxlen\n        else t\n    )\n    return {\n        \"input_ids\": torch.stack([pad(b[\"input_ids\"]) for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\nds_train = SPRTorchSet(spr[\"train\"])\nds_dev = SPRTorchSet(spr[\"dev\"])\n\n\n# ------------- metrics helpers ------------------\ndef count_shape_variety(seq):\n    return len(set(tok[0] for tok in seq.strip().split() if tok))\n\n\ndef count_color_variety(seq):\n    return len(set(tok[1] for tok in seq.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return (\n        sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / sum(w)\n        if sum(w) > 0\n        else 0.0\n    )\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return (\n        sum(wi for wi, t, p in zip(w, y_true, y_pred) if t == p) / sum(w)\n        if sum(w) > 0\n        else 0.0\n    )\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if swa + cwa > 0 else 0.0\n\n\n# ------------------- model ----------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], 1)\n        return self.fc(out)\n\n\n# -------------- hyperparameter sweep ------------\nBATCH_SIZES = [64, 128, 256, 512]\nEPOCHS = 6\nexperiment_data = {\"batch_size\": {\"SPR_BENCH\": {}}}\n\nfor bs in BATCH_SIZES:\n    print(f\"\\n=== Training with batch_size={bs} ===\")\n    train_loader = DataLoader(\n        ds_train, batch_size=bs, shuffle=True, collate_fn=collate_fn\n    )\n    dev_loader = DataLoader(\n        ds_dev, batch_size=512, shuffle=False, collate_fn=collate_fn\n    )\n\n    model = BiLSTMClassifier(vocab_size, num_cls=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    exp = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        model.train()\n        total_loss = 0.0\n        n_batch = 0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            n_batch += 1\n        train_loss = total_loss / n_batch\n        exp[\"losses\"][\"train\"].append((epoch, train_loss))\n\n        model.eval()\n        val_loss_tot = 0.0\n        nb = 0\n        all_preds, all_labels, all_seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss_tot += loss.item()\n                nb += 1\n                preds = logits.argmax(-1).cpu().tolist()\n                labels = batch[\"label\"].cpu().tolist()\n                all_preds.extend(preds)\n                all_labels.extend(labels)\n                all_seqs.extend(batch[\"raw_seq\"])\n        val_loss = val_loss_tot / nb\n        exp[\"losses\"][\"val\"].append((epoch, val_loss))\n\n        swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n        cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        exp[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n\n    exp[\"predictions\"] = all_preds\n    exp[\"ground_truth\"] = all_labels\n    experiment_data[\"batch_size\"][\"SPR_BENCH\"][str(bs)] = exp\n\n# ----------------- save results -----------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, random, math, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ------------- reproducibility -----------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# ------------- working dir / device -----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------- locate SPR_BENCH ---------------\ndef find_spr_bench() -> pathlib.Path:\n    cand = []\n    env_path = os.environ.get(\"SPR_DATA_PATH\")\n    if env_path:\n        cand.append(env_path)\n    cand += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in cand:\n        if p and pathlib.Path(p).expanduser().joinpath(\"train.csv\").exists():\n            return pathlib.Path(p).expanduser().resolve()\n    raise FileNotFoundError(\"SPR_BENCH dataset not found.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ------------- helpers & metrics --------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_shape_variety(seq):\n    return len(set(t[0] for t in seq.strip().split() if t))\n\n\ndef count_color_variety(seq):\n    return len(set(t[1] for t in seq.strip().split() if len(t) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\n# ------------- load dataset -------------------\nspr = load_spr_bench(DATA_PATH)\n\n# ------------- vocab --------------------------\nall_tokens = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq: str):\n    return [token2id[t] for t in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size={vocab_size}, num_classes={num_classes}\")\n\n\n# ------------- torch Dataset ------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.enc = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.enc[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(b[\"input_ids\"]) for b in batch)\n    inputs, labels, raw = [], [], []\n    for b in batch:\n        seq = b[\"input_ids\"]\n        if maxlen - len(seq):\n            seq = torch.cat(\n                [seq, torch.full((maxlen - len(seq),), PAD_ID, dtype=torch.long)]\n            )\n        inputs.append(seq)\n        labels.append(b[\"label\"])\n        raw.append(b[\"raw_seq\"])\n    return {\n        \"input_ids\": torch.stack(inputs),\n        \"label\": torch.stack(labels),\n        \"raw_seq\": raw,\n    }\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ------------- model with dropout -------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128, num_cls=2, dropout=0.0):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.emb_dp = nn.Dropout(dropout)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.out_dp = nn.Dropout(dropout)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.emb_dp(self.embed(x))\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], dim=1)\n        out = self.out_dp(out)\n        return self.fc(out)\n\n\n# ------------- experiment container -----------\nexperiment_data = {\"dropout_rate\": {\"SPR_BENCH\": {}}}\n\n# ------------- hyperparameter grid ------------\ndropout_grid = [0.0, 0.2, 0.3, 0.5]\nEPOCHS = 6\n\nfor p in dropout_grid:\n    print(f\"\\n=== Training with dropout_rate={p} ===\")\n    model = BiLSTMClassifier(vocab_size, num_cls=num_classes, dropout=p).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    exp_rec = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        # ---- train ----\n        model.train()\n        total_loss = 0.0\n        n_batch = 0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            n_batch += 1\n        train_loss = total_loss / n_batch\n        exp_rec[\"losses\"][\"train\"].append((epoch, train_loss))\n\n        # ---- validation ----\n        model.eval()\n        val_loss_tot = 0.0\n        nb = 0\n        all_preds, all_labels, all_seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: (v.to(device) if torch.is_tensor(v) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss_tot += loss.item()\n                nb += 1\n                preds = logits.argmax(-1).cpu().tolist()\n                labels = batch[\"label\"].cpu().tolist()\n                all_preds.extend(preds)\n                all_labels.extend(labels)\n                all_seqs.extend(batch[\"raw_seq\"])\n        val_loss = val_loss_tot / nb\n        exp_rec[\"losses\"][\"val\"].append((epoch, val_loss))\n\n        swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n        cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        exp_rec[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n        exp_rec[\"predictions\"] = all_preds\n        exp_rec[\"ground_truth\"] = all_labels\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n\n    experiment_data[\"dropout_rate\"][\"SPR_BENCH\"][f\"p={p}\"] = exp_rec\n\n# ------------- save data ----------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment data to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, random\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ----------------- reproducibility -----------------\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed_all(0)\n\n# ----------------- working dir & device ------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------- locate SPR_BENCH ----------------\ndef find_spr_bench() -> pathlib.Path:\n    candidates, env_path = [], os.environ.get(\"SPR_DATA_PATH\")\n    if env_path:\n        candidates.append(env_path)\n    candidates += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in candidates:\n        fp = pathlib.Path(p).expanduser()\n        if fp.joinpath(\"train.csv\").exists():\n            return fp.resolve()\n    raise FileNotFoundError(\"SPR_BENCH dataset not found.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ----------------- metrics helpers -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\n# ----------------- load dataset --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\nspr = load_spr_bench(DATA_PATH)\n\n# ----------------- vocabulary ----------------------\nall_tokens = set(tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq: str):\n    return [token2id[t] for t in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size={vocab_size}, num_classes={num_classes}\")\n\n\n# ----------------- Torch dataset ------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.enc = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.enc[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(b[\"input_ids\"]) for b in batch)\n    ids, labels, raw = [], [], []\n    for it in batch:\n        seq = it[\"input_ids\"]\n        if pad := maxlen - len(seq):\n            seq = torch.cat([seq, torch.full((pad,), PAD_ID, dtype=torch.long)])\n        ids.append(seq)\n        labels.append(it[\"label\"])\n        raw.append(it[\"raw_seq\"])\n    return {\"input_ids\": torch.stack(ids), \"label\": torch.stack(labels), \"raw_seq\": raw}\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ----------------- model --------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim, hidden, num_cls):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], dim=1)\n        return self.fc(out)\n\n\n# ----------------- experiment container -----------\nexperiment_data = {\"hidden_size\": {}}\n\n\n# ----------------- training procedure ------------\ndef run_experiment(hidden_size, epochs=6):\n    model = BiLSTMClassifier(\n        vocab_size, emb_dim=64, hidden=hidden_size, num_cls=num_classes\n    ).to(device)\n    crit = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    store = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for epoch in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        tot_loss = 0\n        nb = 0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            opt.zero_grad()\n            logit = model(batch[\"input_ids\"])\n            loss = crit(logit, batch[\"label\"])\n            loss.backward()\n            opt.step()\n            tot_loss += loss.item()\n            nb += 1\n        tr_loss = tot_loss / nb\n        store[\"losses\"][\"train\"].append((epoch, tr_loss))\n        # ---- validate ----\n        model.eval()\n        vloss = 0\n        nb = 0\n        preds, labels, seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logit = model(batch[\"input_ids\"])\n                loss = crit(logit, batch[\"label\"])\n                vloss += loss.item()\n                nb += 1\n                p = logit.argmax(-1).cpu().tolist()\n                l = batch[\"label\"].cpu().tolist()\n                preds.extend(p)\n                labels.extend(l)\n                seqs.extend(batch[\"raw_seq\"])\n        v_loss = vloss / nb\n        store[\"losses\"][\"val\"].append((epoch, v_loss))\n        swa = shape_weighted_accuracy(seqs, labels, preds)\n        cwa = color_weighted_accuracy(seqs, labels, preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        store[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n        if epoch == epochs:\n            store[\"predictions\"] = preds\n            store[\"ground_truth\"] = labels\n        print(\n            f\"[hidden={hidden_size}] Epoch{epoch} \"\n            f\"train_loss={tr_loss:.4f} val_loss={v_loss:.4f} \"\n            f\"SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n    return store\n\n\n# ----------------- hyperparameter sweep ----------\nfor hs in [64, 128, 256, 512]:\n    experiment_data[\"hidden_size\"][hs] = {\"SPR_BENCH\": run_experiment(hs)}\n\n# ----------------- save --------------------------\nnp.save(\n    os.path.join(working_dir, \"experiment_data.npy\"), experiment_data, allow_pickle=True\n)\nprint(f\"Saved experiment data to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, random, math, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ---------------------- reproducibility ----------------------\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(0)\n\n# --------------- working directory & device ------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------- locate SPR_BENCH ---------------------------\ndef find_spr_bench() -> pathlib.Path:\n    cand = [\n        os.environ.get(\"SPR_DATA_PATH\"),\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in cand:\n        if p and pathlib.Path(p).expanduser().joinpath(\"train.csv\").exists():\n            return pathlib.Path(p).expanduser().resolve()\n    raise FileNotFoundError(\"SPR_BENCH dataset not found.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ---------------- helper: load SPR_BENCH ---------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(f):\n        return load_dataset(\n            \"csv\", data_files=str(root / f), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\nspr = load_spr_bench(DATA_PATH)\n\n\n# ---------------- misc metric helpers ------------------------\ndef count_shape_variety(seq: str):\n    return len(set(t[0] for t in seq.split() if t))\n\n\ndef count_color_variety(seq: str):\n    return len(set(t[1] for t in seq.split() if len(t) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\n# ------------------- vocabulary ------------------------------\nall_tokens = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq: str):\n    return [token2id[t] for t in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size={vocab_size}, classes={num_classes}\")\n\n\n# ----------------- dataset & dataloader ----------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.enc = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.enc[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(b[\"input_ids\"]) for b in batch)\n    pad = lambda x: (\n        torch.cat([x, torch.full((maxlen - len(x),), PAD_ID, dtype=torch.long)])\n        if len(x) < maxlen\n        else x\n    )\n    return {\n        \"input_ids\": torch.stack([pad(b[\"input_ids\"]) for b in batch]),\n        \"label\": torch.stack([b[\"label\"] for b in batch]),\n        \"raw_seq\": [b[\"raw_seq\"] for b in batch],\n    }\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# -------------------- model def --------------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab, emb_dim, hidden=128, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lens = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lens, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], 1)\n        return self.fc(out)\n\n\n# -------------------- hyper-parameter sweep --------------------\nEPOCHS = 6\nembed_dims = [32, 64, 128, 256]\nexperiment_data = {}\nfor ed in embed_dims:\n    tag = f\"emb_dim_{ed}\"\n    experiment_data[tag] = {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n    # fresh model/optim\n    model = BiLSTMClassifier(vocab_size, emb_dim=ed, num_cls=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    for epoch in range(1, EPOCHS + 1):\n        # ---- train ----\n        model.train()\n        tot_loss = 0.0\n        nb = 0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item()\n            nb += 1\n        tr_loss = tot_loss / nb\n        experiment_data[tag][\"SPR_BENCH\"][\"losses\"][\"train\"].append((epoch, tr_loss))\n        # ---- validate ----\n        model.eval()\n        v_loss = 0.0\n        nb = 0\n        preds = []\n        labels = []\n        seqs = []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: (v.to(device) if torch.is_tensor(v) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                v_loss += loss.item()\n                nb += 1\n                p = logits.argmax(-1).cpu().tolist()\n                l = batch[\"label\"].cpu().tolist()\n                preds.extend(p)\n                labels.extend(l)\n                seqs.extend(batch[\"raw_seq\"])\n        v_loss /= nb\n        swa = shape_weighted_accuracy(seqs, labels, preds)\n        cwa = color_weighted_accuracy(seqs, labels, preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        experiment_data[tag][\"SPR_BENCH\"][\"losses\"][\"val\"].append((epoch, v_loss))\n        experiment_data[tag][\"SPR_BENCH\"][\"metrics\"][\"val\"].append(\n            (epoch, swa, cwa, hwa)\n        )\n        experiment_data[tag][\"SPR_BENCH\"][\"predictions\"] = preds\n        experiment_data[tag][\"SPR_BENCH\"][\"ground_truth\"] = labels\n        print(\n            f\"[{tag}] Ep{epoch}: tr_loss={tr_loss:.4f} val_loss={v_loss:.4f} \"\n            f\"SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n\n# ------------------ save all experiment data ------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data.\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, random, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n\n# ---------------- misc utils --------------------\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n\nset_seed()\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------- find SPR_BENCH ----------------\ndef find_spr_bench() -> pathlib.Path:\n    cand = []\n    if os.environ.get(\"SPR_DATA_PATH\"):\n        cand.append(os.environ[\"SPR_DATA_PATH\"])\n    cand += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in cand:\n        if p and pathlib.Path(p).expanduser().joinpath(\"train.csv\").exists():\n            return pathlib.Path(p).expanduser().resolve()\n    raise FileNotFoundError(\"SPR_BENCH dataset not found.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ---------------- load dataset -----------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\nspr = load_spr_bench(DATA_PATH)\n\n# ---------------- vocabulary --------------------\nall_tokens = set()\nfor ex in spr[\"train\"]:\n    all_tokens.update(ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size={vocab_size}  num_classes={num_classes}\")\n\n\ndef encode(seq: str):\n    return [token2id[t] for t in seq.split()]\n\n\n# -------------- metrics helpers ----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) else 0.0\n\n\n# ---------------- torch dataset ----------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.encoded = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.encoded[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(x[\"input_ids\"]) for x in batch)\n    ids, lbls, raws = [], [], []\n    for item in batch:\n        seq = item[\"input_ids\"]\n        pad = maxlen - len(seq)\n        if pad:\n            seq = torch.cat([seq, torch.full((pad,), PAD_ID, dtype=torch.long)])\n        ids.append(seq)\n        lbls.append(item[\"label\"])\n        raws.append(item[\"raw_seq\"])\n    return {\n        \"input_ids\": torch.stack(ids),\n        \"label\": torch.stack(lbls),\n        \"raw_seq\": raws,\n    }\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ---------------- model ------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128, num_cls=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        feat = torch.cat([h_n[-2], h_n[-1]], dim=1)\n        return self.fc(feat)\n\n\n# ------------- experiment container -------------\nexperiment_data = {\"weight_decay\": {\"SPR_BENCH\": {}}}\n\n# ------------- training over weight decay -------\nEPOCHS = 6\nweight_decays = [0.0, 1e-5, 1e-4, 1e-3, 1e-2]\n\nfor wd in weight_decays:\n    print(f\"\\n=== Training with weight_decay={wd} ===\")\n    run_key = f\"wd_{wd}\"\n    exp_run = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    model = BiLSTMClassifier(vocab_size, num_cls=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=wd)\n\n    for epoch in range(1, EPOCHS + 1):\n        # ---- train ----\n        model.train()\n        tot_loss, nb = 0.0, 0\n        for batch in train_loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item()\n            nb += 1\n        train_loss = tot_loss / nb\n        exp_run[\"losses\"][\"train\"].append((epoch, train_loss))\n\n        # ---- validation ----\n        model.eval()\n        v_tot, v_nb = 0.0, 0\n        all_preds, all_lbls, all_seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                v_tot += loss.item()\n                v_nb += 1\n                preds = logits.argmax(-1).cpu().tolist()\n                lbls = batch[\"label\"].cpu().tolist()\n                all_preds.extend(preds)\n                all_lbls.extend(lbls)\n                all_seqs.extend(batch[\"raw_seq\"])\n        val_loss = v_tot / v_nb\n        exp_run[\"losses\"][\"val\"].append((epoch, val_loss))\n\n        swa = shape_weighted_accuracy(all_seqs, all_lbls, all_preds)\n        cwa = color_weighted_accuracy(all_seqs, all_lbls, all_preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        exp_run[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n\n        if epoch == EPOCHS:  # store predictions once\n            exp_run[\"predictions\"] = all_preds\n            exp_run[\"ground_truth\"] = all_lbls\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n            f\"SWA={swa:.4f}  CWA={cwa:.4f}  HWA={hwa:.4f}\"\n        )\n\n    experiment_data[\"weight_decay\"][\"SPR_BENCH\"][run_key] = exp_run\n\n    # free memory for next run\n    del model, optimizer, criterion\n    torch.cuda.empty_cache()\n\n# ------------- save experiment data -------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment data to {os.path.join(working_dir, 'experiment_data.npy')}\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, random, math, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n\n# ----------------- helpers & seeds -----------------\ndef set_seed(s):\n    random.seed(s)\n    np.random.seed(s)\n    torch.manual_seed(s)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(s)\n\n\n# ----------------- working dir ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\ndef find_spr_bench() -> pathlib.Path:\n    cand = [os.environ.get(\"SPR_DATA_PATH\")] + [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in cand:\n        if p and pathlib.Path(p).expanduser().joinpath(\"train.csv\").exists():\n            return pathlib.Path(p).expanduser().resolve()\n    raise FileNotFoundError(\"SPR_BENCH not found.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ----------------- dataset utils -------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef count_shape_variety(seq):\n    return len(set(t[0] for t in seq.split() if t))\n\n\ndef count_color_variety(seq):\n    return len(set(t[1] for t in seq.split() if len(t) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    return sum(wt for wt, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    return sum(wt for wt, t, p in zip(w, y_true, y_pred) if t == p) / max(sum(w), 1)\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\nspr = load_spr_bench(DATA_PATH)\n\n# vocab\nall_tokens = set(tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq):\n    return [token2id[t] for t in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size={vocab_size}, num_classes={num_classes}\")\n\n\n# torch dataset\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_split):\n        self.seqs = hf_split[\"sequence\"]\n        self.labels = hf_split[\"label\"]\n        self.enc = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, i):\n        return dict(\n            input_ids=torch.tensor(self.enc[i], dtype=torch.long),\n            label=torch.tensor(self.labels[i], dtype=torch.long),\n            raw_seq=self.seqs[i],\n        )\n\n\ndef collate_fn(batch):\n    maxlen = max(len(it[\"input_ids\"]) for it in batch)\n    ids, labels, raw = [], [], []\n    for it in batch:\n        seq = it[\"input_ids\"]\n        if len(seq) < maxlen:\n            seq = torch.cat(\n                [seq, torch.full((maxlen - len(seq),), PAD_ID, dtype=torch.long)]\n            )\n        ids.append(seq)\n        labels.append(it[\"label\"])\n        raw.append(it[\"raw_seq\"])\n    return dict(input_ids=torch.stack(ids), label=torch.stack(labels), raw_seq=raw)\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# model\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=64, hidden=128, num_cls=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.emb(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], 1)\n        return self.fc(out)\n\n\n# ----------------- experiment container -----------\nCLIP_VALS = [0, 0.5, 1, 2, 5]\nexperiment_data = {\"gradient_clipping_max_norm\": {}}\n\nEPOCHS = 6\nfor clip_idx, clip_val in enumerate(CLIP_VALS):\n    print(f\"\\n=== Training with clip_val={clip_val} ===\")\n    set_seed(42 + clip_idx)\n    model = BiLSTMClassifier(vocab_size, num_cls=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    exp_cur = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for epoch in range(1, EPOCHS + 1):\n        # --- train ---\n        model.train()\n        total_loss = 0\n        n_batch = 0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()\n            }\n            optimizer.zero_grad()\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss.backward()\n            if clip_val > 0:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_val)\n            optimizer.step()\n            total_loss += loss.item()\n            n_batch += 1\n        train_loss = total_loss / n_batch\n        exp_cur[\"losses\"][\"train\"].append((epoch, train_loss))\n\n        # --- val ---\n        model.eval()\n        val_loss_tot = 0\n        nb = 0\n        all_preds, all_labels, all_seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: (v.to(device) if torch.is_tensor(v) else v)\n                    for k, v in batch.items()\n                }\n                logits = model(batch[\"input_ids\"])\n                loss = criterion(logits, batch[\"label\"])\n                val_loss_tot += loss.item()\n                nb += 1\n                preds = logits.argmax(-1).cpu().tolist()\n                labels = batch[\"label\"].cpu().tolist()\n                all_preds.extend(preds)\n                all_labels.extend(labels)\n                all_seqs.extend(batch[\"raw_seq\"])\n        val_loss = val_loss_tot / nb\n        exp_cur[\"losses\"][\"val\"].append((epoch, val_loss))\n\n        swa = shape_weighted_accuracy(all_seqs, all_labels, all_preds)\n        cwa = color_weighted_accuracy(all_seqs, all_labels, all_preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        exp_cur[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n        exp_cur[\"predictions\"] = all_preds\n        exp_cur[\"ground_truth\"] = all_labels\n\n        print(\n            f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n\n    experiment_data[\"gradient_clipping_max_norm\"][str(clip_val)] = exp_cur\n\n# ---------------- save all ------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, numpy as np, torch, torch.nn as nn, random\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ----------------- reproducibility -----------------\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed_all(0)\n\n# ----------------- working dir & device ------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------- locate SPR_BENCH ----------------\ndef find_spr_bench() -> pathlib.Path:\n    candidates, env_path = [], os.environ.get(\"SPR_DATA_PATH\")\n    if env_path:\n        candidates.append(env_path)\n    candidates += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in candidates:\n        fp = pathlib.Path(p).expanduser()\n        if fp.joinpath(\"train.csv\").exists():\n            return fp.resolve()\n    raise FileNotFoundError(\"SPR_BENCH dataset not found.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ----------------- metrics helpers -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\n# ----------------- load dataset --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\nspr = load_spr_bench(DATA_PATH)\n\n# ----------------- vocabulary ----------------------\nall_tokens = set(tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq: str):\n    return [token2id[t] for t in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size={vocab_size}, num_classes={num_classes}\")\n\n\n# ----------------- Torch dataset ------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.enc = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.enc[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(b[\"input_ids\"]) for b in batch)\n    ids, labels, raw = [], [], []\n    for it in batch:\n        seq = it[\"input_ids\"]\n        if pad := maxlen - len(seq):\n            seq = torch.cat([seq, torch.full((pad,), PAD_ID, dtype=torch.long)])\n        ids.append(seq)\n        labels.append(it[\"label\"])\n        raw.append(it[\"raw_seq\"])\n    return {\"input_ids\": torch.stack(ids), \"label\": torch.stack(labels), \"raw_seq\": raw}\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ----------------- model --------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim, hidden, num_cls):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], dim=1)\n        return self.fc(out)\n\n\n# ----------------- experiment container -----------\nexperiment_data = {\"hidden_size\": {}}\n\n\n# ----------------- training procedure ------------\ndef run_experiment(hidden_size, epochs=6):\n    model = BiLSTMClassifier(\n        vocab_size, emb_dim=64, hidden=hidden_size, num_cls=num_classes\n    ).to(device)\n    crit = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    store = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for epoch in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        tot_loss = 0\n        nb = 0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            opt.zero_grad()\n            logit = model(batch[\"input_ids\"])\n            loss = crit(logit, batch[\"label\"])\n            loss.backward()\n            opt.step()\n            tot_loss += loss.item()\n            nb += 1\n        tr_loss = tot_loss / nb\n        store[\"losses\"][\"train\"].append((epoch, tr_loss))\n        # ---- validate ----\n        model.eval()\n        vloss = 0\n        nb = 0\n        preds, labels, seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logit = model(batch[\"input_ids\"])\n                loss = crit(logit, batch[\"label\"])\n                vloss += loss.item()\n                nb += 1\n                p = logit.argmax(-1).cpu().tolist()\n                l = batch[\"label\"].cpu().tolist()\n                preds.extend(p)\n                labels.extend(l)\n                seqs.extend(batch[\"raw_seq\"])\n        v_loss = vloss / nb\n        store[\"losses\"][\"val\"].append((epoch, v_loss))\n        swa = shape_weighted_accuracy(seqs, labels, preds)\n        cwa = color_weighted_accuracy(seqs, labels, preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        store[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n        if epoch == epochs:\n            store[\"predictions\"] = preds\n            store[\"ground_truth\"] = labels\n        print(\n            f\"[hidden={hidden_size}] Epoch{epoch} \"\n            f\"train_loss={tr_loss:.4f} val_loss={v_loss:.4f} \"\n            f\"SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n    return store\n\n\n# ----------------- hyperparameter sweep ----------\nfor hs in [64, 128, 256, 512]:\n    experiment_data[\"hidden_size\"][hs] = {\"SPR_BENCH\": run_experiment(hs)}\n\n# ----------------- save --------------------------\nnp.save(\n    os.path.join(working_dir, \"experiment_data.npy\"), experiment_data, allow_pickle=True\n)\nprint(f\"Saved experiment data to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, numpy as np, torch, torch.nn as nn, random\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ----------------- reproducibility -----------------\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed_all(0)\n\n# ----------------- working dir & device ------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------- locate SPR_BENCH ----------------\ndef find_spr_bench() -> pathlib.Path:\n    candidates, env_path = [], os.environ.get(\"SPR_DATA_PATH\")\n    if env_path:\n        candidates.append(env_path)\n    candidates += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in candidates:\n        fp = pathlib.Path(p).expanduser()\n        if fp.joinpath(\"train.csv\").exists():\n            return fp.resolve()\n    raise FileNotFoundError(\"SPR_BENCH dataset not found.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ----------------- metrics helpers -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\n# ----------------- load dataset --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\nspr = load_spr_bench(DATA_PATH)\n\n# ----------------- vocabulary ----------------------\nall_tokens = set(tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq: str):\n    return [token2id[t] for t in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size={vocab_size}, num_classes={num_classes}\")\n\n\n# ----------------- Torch dataset ------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.enc = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.enc[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(b[\"input_ids\"]) for b in batch)\n    ids, labels, raw = [], [], []\n    for it in batch:\n        seq = it[\"input_ids\"]\n        if pad := maxlen - len(seq):\n            seq = torch.cat([seq, torch.full((pad,), PAD_ID, dtype=torch.long)])\n        ids.append(seq)\n        labels.append(it[\"label\"])\n        raw.append(it[\"raw_seq\"])\n    return {\"input_ids\": torch.stack(ids), \"label\": torch.stack(labels), \"raw_seq\": raw}\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ----------------- model --------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim, hidden, num_cls):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], dim=1)\n        return self.fc(out)\n\n\n# ----------------- experiment container -----------\nexperiment_data = {\"hidden_size\": {}}\n\n\n# ----------------- training procedure ------------\ndef run_experiment(hidden_size, epochs=6):\n    model = BiLSTMClassifier(\n        vocab_size, emb_dim=64, hidden=hidden_size, num_cls=num_classes\n    ).to(device)\n    crit = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    store = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for epoch in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        tot_loss = 0\n        nb = 0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            opt.zero_grad()\n            logit = model(batch[\"input_ids\"])\n            loss = crit(logit, batch[\"label\"])\n            loss.backward()\n            opt.step()\n            tot_loss += loss.item()\n            nb += 1\n        tr_loss = tot_loss / nb\n        store[\"losses\"][\"train\"].append((epoch, tr_loss))\n        # ---- validate ----\n        model.eval()\n        vloss = 0\n        nb = 0\n        preds, labels, seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logit = model(batch[\"input_ids\"])\n                loss = crit(logit, batch[\"label\"])\n                vloss += loss.item()\n                nb += 1\n                p = logit.argmax(-1).cpu().tolist()\n                l = batch[\"label\"].cpu().tolist()\n                preds.extend(p)\n                labels.extend(l)\n                seqs.extend(batch[\"raw_seq\"])\n        v_loss = vloss / nb\n        store[\"losses\"][\"val\"].append((epoch, v_loss))\n        swa = shape_weighted_accuracy(seqs, labels, preds)\n        cwa = color_weighted_accuracy(seqs, labels, preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        store[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n        if epoch == epochs:\n            store[\"predictions\"] = preds\n            store[\"ground_truth\"] = labels\n        print(\n            f\"[hidden={hidden_size}] Epoch{epoch} \"\n            f\"train_loss={tr_loss:.4f} val_loss={v_loss:.4f} \"\n            f\"SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n    return store\n\n\n# ----------------- hyperparameter sweep ----------\nfor hs in [64, 128, 256, 512]:\n    experiment_data[\"hidden_size\"][hs] = {\"SPR_BENCH\": run_experiment(hs)}\n\n# ----------------- save --------------------------\nnp.save(\n    os.path.join(working_dir, \"experiment_data.npy\"), experiment_data, allow_pickle=True\n)\nprint(f\"Saved experiment data to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, pathlib, numpy as np, torch, torch.nn as nn, random\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\n\n# ----------------- reproducibility -----------------\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed_all(0)\n\n# ----------------- working dir & device ------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------- locate SPR_BENCH ----------------\ndef find_spr_bench() -> pathlib.Path:\n    candidates, env_path = [], os.environ.get(\"SPR_DATA_PATH\")\n    if env_path:\n        candidates.append(env_path)\n    candidates += [\n        \"./SPR_BENCH\",\n        \"../SPR_BENCH\",\n        \"../../SPR_BENCH\",\n        \"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\",\n    ]\n    for p in candidates:\n        fp = pathlib.Path(p).expanduser()\n        if fp.joinpath(\"train.csv\").exists():\n            return fp.resolve()\n    raise FileNotFoundError(\"SPR_BENCH dataset not found.\")\n\n\nDATA_PATH = find_spr_bench()\nprint(f\"Found SPR_BENCH at: {DATA_PATH}\")\n\n\n# ----------------- metrics helpers -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.strip().split() if tok))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.strip().split() if len(tok) > 1))\n\n\ndef shape_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef color_weighted_accuracy(seqs, y_true, y_pred):\n    w = [count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) > 0 else 0.0\n\n\ndef harmonic_weighted_accuracy(swa, cwa):\n    return 2 * swa * cwa / (swa + cwa) if (swa + cwa) > 0 else 0.0\n\n\n# ----------------- load dataset --------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(csv):\n        return load_dataset(\n            \"csv\", data_files=str(root / csv), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\nspr = load_spr_bench(DATA_PATH)\n\n# ----------------- vocabulary ----------------------\nall_tokens = set(tok for ex in spr[\"train\"] for tok in ex[\"sequence\"].split())\ntoken2id = {tok: i + 1 for i, tok in enumerate(sorted(all_tokens))}\nPAD_ID = 0\nvocab_size = len(token2id) + 1\n\n\ndef encode(seq: str):\n    return [token2id[t] for t in seq.split()]\n\n\nnum_classes = len(set(spr[\"train\"][\"label\"]))\nprint(f\"Vocab size={vocab_size}, num_classes={num_classes}\")\n\n\n# ----------------- Torch dataset ------------------\nclass SPRTorchSet(Dataset):\n    def __init__(self, split):\n        self.seqs = split[\"sequence\"]\n        self.labels = split[\"label\"]\n        self.enc = [encode(s) for s in self.seqs]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.enc[idx], dtype=torch.long),\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n            \"raw_seq\": self.seqs[idx],\n        }\n\n\ndef collate_fn(batch):\n    maxlen = max(len(b[\"input_ids\"]) for b in batch)\n    ids, labels, raw = [], [], []\n    for it in batch:\n        seq = it[\"input_ids\"]\n        if pad := maxlen - len(seq):\n            seq = torch.cat([seq, torch.full((pad,), PAD_ID, dtype=torch.long)])\n        ids.append(seq)\n        labels.append(it[\"label\"])\n        raw.append(it[\"raw_seq\"])\n    return {\"input_ids\": torch.stack(ids), \"label\": torch.stack(labels), \"raw_seq\": raw}\n\n\ntrain_loader = DataLoader(\n    SPRTorchSet(spr[\"train\"]), batch_size=128, shuffle=True, collate_fn=collate_fn\n)\ndev_loader = DataLoader(\n    SPRTorchSet(spr[\"dev\"]), batch_size=256, shuffle=False, collate_fn=collate_fn\n)\n\n\n# ----------------- model --------------------------\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim, hidden, num_cls):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_ID)\n        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden * 2, num_cls)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        lengths = (x != PAD_ID).sum(1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths, batch_first=True, enforce_sorted=False\n        )\n        _, (h_n, _) = self.lstm(packed)\n        out = torch.cat([h_n[-2], h_n[-1]], dim=1)\n        return self.fc(out)\n\n\n# ----------------- experiment container -----------\nexperiment_data = {\"hidden_size\": {}}\n\n\n# ----------------- training procedure ------------\ndef run_experiment(hidden_size, epochs=6):\n    model = BiLSTMClassifier(\n        vocab_size, emb_dim=64, hidden=hidden_size, num_cls=num_classes\n    ).to(device)\n    crit = nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    store = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for epoch in range(1, epochs + 1):\n        # ---- train ----\n        model.train()\n        tot_loss = 0\n        nb = 0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            opt.zero_grad()\n            logit = model(batch[\"input_ids\"])\n            loss = crit(logit, batch[\"label\"])\n            loss.backward()\n            opt.step()\n            tot_loss += loss.item()\n            nb += 1\n        tr_loss = tot_loss / nb\n        store[\"losses\"][\"train\"].append((epoch, tr_loss))\n        # ---- validate ----\n        model.eval()\n        vloss = 0\n        nb = 0\n        preds, labels, seqs = [], [], []\n        with torch.no_grad():\n            for batch in dev_loader:\n                batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                logit = model(batch[\"input_ids\"])\n                loss = crit(logit, batch[\"label\"])\n                vloss += loss.item()\n                nb += 1\n                p = logit.argmax(-1).cpu().tolist()\n                l = batch[\"label\"].cpu().tolist()\n                preds.extend(p)\n                labels.extend(l)\n                seqs.extend(batch[\"raw_seq\"])\n        v_loss = vloss / nb\n        store[\"losses\"][\"val\"].append((epoch, v_loss))\n        swa = shape_weighted_accuracy(seqs, labels, preds)\n        cwa = color_weighted_accuracy(seqs, labels, preds)\n        hwa = harmonic_weighted_accuracy(swa, cwa)\n        store[\"metrics\"][\"val\"].append((epoch, swa, cwa, hwa))\n        if epoch == epochs:\n            store[\"predictions\"] = preds\n            store[\"ground_truth\"] = labels\n        print(\n            f\"[hidden={hidden_size}] Epoch{epoch} \"\n            f\"train_loss={tr_loss:.4f} val_loss={v_loss:.4f} \"\n            f\"SWA={swa:.4f} CWA={cwa:.4f} HWA={hwa:.4f}\"\n        )\n    return store\n\n\n# ----------------- hyperparameter sweep ----------\nfor hs in [64, 128, 256, 512]:\n    experiment_data[\"hidden_size\"][hs] = {\"SPR_BENCH\": run_experiment(hs)}\n\n# ----------------- save --------------------------\nnp.save(\n    os.path.join(working_dir, \"experiment_data.npy\"), experiment_data, allow_pickle=True\n)\nprint(f\"Saved experiment data to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 504217.01\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 573886.11\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 690738.78\nexamples/s]', '\\n', 'Vocab size=17, num_classes=2', '\\n', '[6 ep run] Epoch 1:\ntrain_loss=0.1947 val_loss=0.0646 HWA=0.9806', '\\n', '[6 ep run] Epoch 2:\ntrain_loss=0.0401 val_loss=0.0212 HWA=0.9966', '\\n', '[6 ep run] Epoch 3:\ntrain_loss=0.0145 val_loss=0.0094 HWA=0.9978', '\\n', '[6 ep run] Epoch 4:\ntrain_loss=0.0064 val_loss=0.0061 HWA=0.9996', '\\n', '[6 ep run] Epoch 5:\ntrain_loss=0.0023 val_loss=0.0030 HWA=0.9991', '\\n', '[6 ep run] Epoch 6:\ntrain_loss=0.0008 val_loss=0.0017 HWA=0.9996', '\\n', '[12 ep run] Epoch 1:\ntrain_loss=0.1913 val_loss=0.0762 HWA=0.9806', '\\n', '[12 ep run] Epoch 2:\ntrain_loss=0.0430 val_loss=0.0264 HWA=0.9922', '\\n', '[12 ep run] Epoch 3:\ntrain_loss=0.0148 val_loss=0.0103 HWA=0.9973', '\\n', '[12 ep run] Epoch 4:\ntrain_loss=0.0071 val_loss=0.0074 HWA=0.9983', '\\n', '[12 ep run] Epoch 5:\ntrain_loss=0.0029 val_loss=0.0037 HWA=0.9993', '\\n', '[12 ep run] Epoch 6:\ntrain_loss=0.0009 val_loss=0.0025 HWA=0.9993', '\\n', '[12 ep run] Epoch 7:\ntrain_loss=0.0006 val_loss=0.0023 HWA=0.9993', '\\n', '[12 ep run] Epoch 8:\ntrain_loss=0.0003 val_loss=0.0020 HWA=0.9991', '\\n', '[12 ep run] Epoch 9:\ntrain_loss=0.0002 val_loss=0.0017 HWA=0.9996', '\\n', '[12 ep run] Epoch 10:\ntrain_loss=0.0002 val_loss=0.0016 HWA=0.9995', '\\n', '[12 ep run] Epoch 11:\ntrain_loss=0.0001 val_loss=0.0017 HWA=0.9993', '\\n', '[12 ep run] Epoch 12:\ntrain_loss=0.0001 val_loss=0.0016 HWA=0.9993', '\\n', '[18 ep run] Epoch 1:\ntrain_loss=0.1973 val_loss=0.0647 HWA=0.9837', '\\n', '[18 ep run] Epoch 2:\ntrain_loss=0.0445 val_loss=0.0350 HWA=0.9918', '\\n', '[18 ep run] Epoch 3:\ntrain_loss=0.0160 val_loss=0.0119 HWA=0.9950', '\\n', '[18 ep run] Epoch 4:\ntrain_loss=0.0048 val_loss=0.0035 HWA=0.9992', '\\n', '[18 ep run] Epoch 5:\ntrain_loss=0.0012 val_loss=0.0022 HWA=0.9992', '\\n', '[18 ep run] Epoch 6:\ntrain_loss=0.0006 val_loss=0.0019 HWA=0.9994', '\\n', '[18 ep run] Epoch 7:\ntrain_loss=0.0004 val_loss=0.0016 HWA=0.9996', '\\n', '[18 ep run] Epoch 8:\ntrain_loss=0.0003 val_loss=0.0016 HWA=0.9996', '\\n', '[18 ep run] Epoch 9:\ntrain_loss=0.0002 val_loss=0.0014 HWA=0.9996', '\\n', '[18 ep run] Epoch 10:\ntrain_loss=0.0001 val_loss=0.0012 HWA=0.9998', '\\n', '[18 ep run] Epoch 11:\ntrain_loss=0.0001 val_loss=0.0015 HWA=0.9993', '\\n', '[18 ep run] Epoch 12:\ntrain_loss=0.0001 val_loss=0.0014 HWA=0.9993', '\\n', '[18 ep run] Epoch 13:\ntrain_loss=0.0001 val_loss=0.0013 HWA=0.9993', '\\n', '[18 ep run] Epoch 14:\ntrain_loss=0.0001 val_loss=0.0013 HWA=0.9993', '\\n', '[18 ep run] Epoch 15:\ntrain_loss=0.0001 val_loss=0.0012 HWA=0.9996', '\\n', '[18 ep run] Epoch 16:\ntrain_loss=0.0000 val_loss=0.0011 HWA=0.9993', '\\n', '[18 ep run] Epoch 17:\ntrain_loss=0.0000 val_loss=0.0010 HWA=0.9996', '\\n', '[18 ep run] Epoch 18:\ntrain_loss=0.0000 val_loss=0.0010 HWA=0.9998', '\\n', 'Saved experiment data to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_02-30-\n16_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n10/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 536630.50\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 333882.92\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 453786.58\nexamples/s]', '\\n', 'Vocab size = 17,  num_classes = 2', '\\n', '\\n=== Starting\nrun with learning rate = 0.0003 ===', '\\n', 'Epoch 1: train_loss=0.3417\nval_loss=0.1639 SWA=0.9575  CWA=0.9555  HWA=0.9565', '\\n', 'Epoch 2:\ntrain_loss=0.1404  val_loss=0.1296 SWA=0.9616  CWA=0.9600  HWA=0.9608', '\\n',\n'Epoch 3: train_loss=0.0922  val_loss=0.0701 SWA=0.9799  CWA=0.9794\nHWA=0.9796', '\\n', 'Epoch 4: train_loss=0.0558  val_loss=0.0438 SWA=0.9884\nCWA=0.9880  HWA=0.9882', '\\n', 'Epoch 5: train_loss=0.0388  val_loss=0.0329\nSWA=0.9915  CWA=0.9914  HWA=0.9915', '\\n', 'Epoch 6: train_loss=0.0269\nval_loss=0.0253 SWA=0.9919  CWA=0.9921  HWA=0.9920', '\\n', '\\n=== Starting run\nwith learning rate = 0.001 ===', '\\n', 'Epoch 1: train_loss=0.1885\nval_loss=0.0736 SWA=0.9753  CWA=0.9749  HWA=0.9751', '\\n', 'Epoch 2:\ntrain_loss=0.0481  val_loss=0.0325 SWA=0.9899  CWA=0.9904  HWA=0.9902', '\\n',\n'Epoch 3: train_loss=0.0181  val_loss=0.0114 SWA=0.9960  CWA=0.9963\nHWA=0.9962', '\\n', 'Epoch 4: train_loss=0.0051  val_loss=0.0038 SWA=0.9995\nCWA=0.9996  HWA=0.9996', '\\n', 'Epoch 5: train_loss=0.0016  val_loss=0.0022\nSWA=0.9992  CWA=0.9992  HWA=0.9992', '\\n', 'Epoch 6: train_loss=0.0008\nval_loss=0.0014 SWA=0.9999  CWA=0.9998  HWA=0.9999', '\\n', '\\n=== Starting run\nwith learning rate = 0.003 ===', '\\n', 'Epoch 1: train_loss=0.1272\nval_loss=0.0286 SWA=0.9927  CWA=0.9935  HWA=0.9931', '\\n', 'Epoch 2:\ntrain_loss=0.0162  val_loss=0.0153 SWA=0.9944  CWA=0.9952  HWA=0.9948', '\\n',\n'Epoch 3: train_loss=0.0044  val_loss=0.0018 SWA=1.0000  CWA=1.0000\nHWA=1.0000', '\\n', 'Epoch 4: train_loss=0.0005  val_loss=0.0006 SWA=1.0000\nCWA=1.0000  HWA=1.0000', '\\n', 'Epoch 5: train_loss=0.0002  val_loss=0.0005\nSWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n', 'Epoch 6: train_loss=0.0001\nval_loss=0.0003 SWA=1.0000  CWA=1.0000  HWA=1.0000', '\\n', '\\nSaved experiment\ndata to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_02-30-\n16_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n11/working/experiment_data.npy', '\\n', 'Execution time: 14 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 545494.08\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 500704.80\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 613327.87\nexamples/s]', '\\n', 'Vocab size=17, num_classes=2', '\\n', '\\n=== Training with\nbatch_size=64 ===', '\\n', 'Epoch 1: train_loss=0.1406 val_loss=0.0373 SWA=0.9896\nCWA=0.9901 HWA=0.9898', '\\n', 'Epoch 2: train_loss=0.0216 val_loss=0.0118\nSWA=0.9977 CWA=0.9982 HWA=0.9979', '\\n', 'Epoch 3: train_loss=0.0068\nval_loss=0.0048 SWA=0.9980 CWA=0.9981 HWA=0.9981', '\\n', 'Epoch 4:\ntrain_loss=0.0013 val_loss=0.0017 SWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n',\n'Epoch 5: train_loss=0.0004 val_loss=0.0012 SWA=0.9995 CWA=0.9996 HWA=0.9996',\n'\\n', 'Epoch 6: train_loss=0.0002 val_loss=0.0009 SWA=0.9995 CWA=0.9996\nHWA=0.9996', '\\n', '\\n=== Training with batch_size=128 ===', '\\n', 'Epoch 1:\ntrain_loss=0.1913 val_loss=0.0764 SWA=0.9809 CWA=0.9803 HWA=0.9806', '\\n',\n'Epoch 2: train_loss=0.0430 val_loss=0.0266 SWA=0.9919 CWA=0.9926 HWA=0.9922',\n'\\n', 'Epoch 3: train_loss=0.0148 val_loss=0.0103 SWA=0.9971 CWA=0.9974\nHWA=0.9973', '\\n', 'Epoch 4: train_loss=0.0071 val_loss=0.0074 SWA=0.9981\nCWA=0.9984 HWA=0.9983', '\\n', 'Epoch 5: train_loss=0.0029 val_loss=0.0037\nSWA=0.9993 CWA=0.9993 HWA=0.9993', '\\n', 'Epoch 6: train_loss=0.0009\nval_loss=0.0025 SWA=0.9993 CWA=0.9993 HWA=0.9993', '\\n', '\\n=== Training with\nbatch_size=256 ===', '\\n', 'Epoch 1: train_loss=0.2833 val_loss=0.1332\nSWA=0.9622 CWA=0.9599 HWA=0.9611', '\\n', 'Epoch 2: train_loss=0.0792\nval_loss=0.0490 SWA=0.9880 CWA=0.9885 HWA=0.9882', '\\n', 'Epoch 3:\ntrain_loss=0.0284 val_loss=0.0190 SWA=0.9945 CWA=0.9952 HWA=0.9949', '\\n',\n'Epoch 4: train_loss=0.0137 val_loss=0.0116 SWA=0.9973 CWA=0.9974 HWA=0.9974',\n'\\n', 'Epoch 5: train_loss=0.0071 val_loss=0.0079 SWA=0.9984 CWA=0.9986\nHWA=0.9985', '\\n', 'Epoch 6: train_loss=0.0034 val_loss=0.0039 SWA=0.9988\nCWA=0.9990 HWA=0.9989', '\\n', '\\n=== Training with batch_size=512 ===', '\\n',\n'Epoch 1: train_loss=0.3542 val_loss=0.1694 SWA=0.9515 CWA=0.9495 HWA=0.9505',\n'\\n', 'Epoch 2: train_loss=0.1459 val_loss=0.1228 SWA=0.9634 CWA=0.9611\nHWA=0.9623', '\\n', 'Epoch 3: train_loss=0.0905 val_loss=0.0630 SWA=0.9823\nCWA=0.9826 HWA=0.9824', '\\n', 'Epoch 4: train_loss=0.0483 val_loss=0.0386\nSWA=0.9885 CWA=0.9886 HWA=0.9885', '\\n', 'Epoch 5: train_loss=0.0314\nval_loss=0.0264 SWA=0.9928 CWA=0.9932 HWA=0.9930', '\\n', 'Epoch 6:\ntrain_loss=0.0209 val_loss=0.0168 SWA=0.9956 CWA=0.9955 HWA=0.9956', '\\n',\n'Saved experiment data to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-16_02-30-\n16_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n12/working/experiment_data.npy', '\\n', 'Execution time: 20 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 307116.40\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 582445.15\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 631102.02\nexamples/s]', '\\n', 'Vocab size=17, num_classes=2', '\\n', '\\n=== Training with\ndropout_rate=0.0 ===', '\\n', 'Epoch 1: train_loss=0.1947 val_loss=0.0646\nSWA=0.9808 CWA=0.9805 HWA=0.9806', '\\n', 'Epoch 2: train_loss=0.0401\nval_loss=0.0212 SWA=0.9962 CWA=0.9969 HWA=0.9966', '\\n', 'Epoch 3:\ntrain_loss=0.0145 val_loss=0.0094 SWA=0.9977 CWA=0.9979 HWA=0.9978', '\\n',\n'Epoch 4: train_loss=0.0064 val_loss=0.0061 SWA=0.9995 CWA=0.9996 HWA=0.9996',\n'\\n', 'Epoch 5: train_loss=0.0023 val_loss=0.0030 SWA=0.9991 CWA=0.9992\nHWA=0.9991', '\\n', 'Epoch 6: train_loss=0.0008 val_loss=0.0017 SWA=0.9995\nCWA=0.9996 HWA=0.9996', '\\n', '\\n=== Training with dropout_rate=0.2 ===', '\\n',\n'Epoch 1: train_loss=0.2216 val_loss=0.0863 SWA=0.9755 CWA=0.9755 HWA=0.9755',\n'\\n', 'Epoch 2: train_loss=0.0746 val_loss=0.0395 SWA=0.9867 CWA=0.9870\nHWA=0.9868', '\\n', 'Epoch 3: train_loss=0.0412 val_loss=0.0214 SWA=0.9923\nCWA=0.9930 HWA=0.9927', '\\n', 'Epoch 4: train_loss=0.0254 val_loss=0.0112\nSWA=0.9958 CWA=0.9965 HWA=0.9962', '\\n', 'Epoch 5: train_loss=0.0144\nval_loss=0.0118 SWA=0.9960 CWA=0.9963 HWA=0.9962', '\\n', 'Epoch 6:\ntrain_loss=0.0101 val_loss=0.0047 SWA=0.9977 CWA=0.9981 HWA=0.9979', '\\n',\n'\\n=== Training with dropout_rate=0.3 ===', '\\n', 'Epoch 1: train_loss=0.2566\nval_loss=0.1123 SWA=0.9641 CWA=0.9619 HWA=0.9630', '\\n', 'Epoch 2:\ntrain_loss=0.0950 val_loss=0.0424 SWA=0.9862 CWA=0.9862 HWA=0.9862', '\\n',\n'Epoch 3: train_loss=0.0510 val_loss=0.0228 SWA=0.9924 CWA=0.9934 HWA=0.9929',\n'\\n', 'Epoch 4: train_loss=0.0323 val_loss=0.0219 SWA=0.9912 CWA=0.9918\nHWA=0.9915', '\\n', 'Epoch 5: train_loss=0.0226 val_loss=0.0113 SWA=0.9960\nCWA=0.9968 HWA=0.9964', '\\n', 'Epoch 6: train_loss=0.0156 val_loss=0.0093\nSWA=0.9958 CWA=0.9965 HWA=0.9961', '\\n', '\\n=== Training with dropout_rate=0.5\n===', '\\n', 'Epoch 1: train_loss=0.2870 val_loss=0.1531 SWA=0.9502 CWA=0.9482\nHWA=0.9492', '\\n', 'Epoch 2: train_loss=0.1545 val_loss=0.0818 SWA=0.9732\nCWA=0.9731 HWA=0.9731', '\\n', 'Epoch 3: train_loss=0.1030 val_loss=0.0515\nSWA=0.9834 CWA=0.9836 HWA=0.9835', '\\n', 'Epoch 4: train_loss=0.0762\nval_loss=0.0452 SWA=0.9847 CWA=0.9846 HWA=0.9846', '\\n', 'Epoch 5:\ntrain_loss=0.0576 val_loss=0.0251 SWA=0.9907 CWA=0.9913 HWA=0.9910', '\\n',\n'Epoch 6: train_loss=0.0423 val_loss=0.0218 SWA=0.9913 CWA=0.9919 HWA=0.9916',\n'\\n', '\\nSaved experiment data to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-16_02-30-\n16_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n13/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size=17, num_classes=2', '\\n',\n'[hidden=64] Epoch1 train_loss=0.2265 val_loss=0.0937 SWA=0.9748 CWA=0.9740\nHWA=0.9744', '\\n', '[hidden=64] Epoch2 train_loss=0.0586 val_loss=0.0338\nSWA=0.9904 CWA=0.9907 HWA=0.9906', '\\n', '[hidden=64] Epoch3 train_loss=0.0239\nval_loss=0.0178 SWA=0.9944 CWA=0.9948 HWA=0.9946', '\\n', '[hidden=64] Epoch4\ntrain_loss=0.0116 val_loss=0.0102 SWA=0.9970 CWA=0.9971 HWA=0.9971', '\\n',\n'[hidden=64] Epoch5 train_loss=0.0050 val_loss=0.0070 SWA=0.9977 CWA=0.9976\nHWA=0.9976', '\\n', '[hidden=64] Epoch6 train_loss=0.0028 val_loss=0.0041\nSWA=0.9985 CWA=0.9986 HWA=0.9986', '\\n', '[hidden=128] Epoch1 train_loss=0.2140\nval_loss=0.1051 SWA=0.9639 CWA=0.9628 HWA=0.9634', '\\n', '[hidden=128] Epoch2\ntrain_loss=0.0582 val_loss=0.0295 SWA=0.9931 CWA=0.9932 HWA=0.9932', '\\n',\n'[hidden=128] Epoch3 train_loss=0.0191 val_loss=0.0151 SWA=0.9973 CWA=0.9975\nHWA=0.9974', '\\n', '[hidden=128] Epoch4 train_loss=0.0063 val_loss=0.0039\nSWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=128] Epoch5 train_loss=0.0025\nval_loss=0.0024 SWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=128] Epoch6\ntrain_loss=0.0009 val_loss=0.0014 SWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n',\n'[hidden=256] Epoch1 train_loss=0.1758 val_loss=0.0526 SWA=0.9804 CWA=0.9809\nHWA=0.9806', '\\n', '[hidden=256] Epoch2 train_loss=0.0304 val_loss=0.0154\nSWA=0.9951 CWA=0.9959 HWA=0.9955', '\\n', '[hidden=256] Epoch3 train_loss=0.0090\nval_loss=0.0047 SWA=0.9986 CWA=0.9989 HWA=0.9988', '\\n', '[hidden=256] Epoch4\ntrain_loss=0.0034 val_loss=0.0144 SWA=0.9949 CWA=0.9950 HWA=0.9950', '\\n',\n'[hidden=256] Epoch5 train_loss=0.0038 val_loss=0.0015 SWA=0.9995 CWA=0.9997\nHWA=0.9996', '\\n', '[hidden=256] Epoch6 train_loss=0.0003 val_loss=0.0011\nSWA=0.9998 CWA=0.9999 HWA=0.9998', '\\n', '[hidden=512] Epoch1 train_loss=0.1562\nval_loss=0.0579 SWA=0.9832 CWA=0.9832 HWA=0.9832', '\\n', '[hidden=512] Epoch2\ntrain_loss=0.0429 val_loss=0.0266 SWA=0.9935 CWA=0.9941 HWA=0.9938', '\\n',\n'[hidden=512] Epoch3 train_loss=0.0142 val_loss=0.0072 SWA=0.9978 CWA=0.9979\nHWA=0.9979', '\\n', '[hidden=512] Epoch4 train_loss=0.0033 val_loss=0.0021\nSWA=0.9996 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=512] Epoch5 train_loss=0.0005\nval_loss=0.0007 SWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n', '[hidden=512] Epoch6\ntrain_loss=0.0002 val_loss=0.0006 SWA=1.0000 CWA=1.0000 HWA=1.0000', '\\n',\n'Saved experiment data to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-\n16_02-30-16_context_aware_contrastive_learning_attempt_0/0-\nrun/process_ForkProcess-11/working/experiment_data.npy', '\\n', 'Execution time:\na minute seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size=17, classes=2', '\\n', '[emb_dim_32]\nEp1: tr_loss=0.2422 val_loss=0.1409 SWA=0.9611 CWA=0.9588 HWA=0.9600', '\\n',\n'[emb_dim_32] Ep2: tr_loss=0.0904 val_loss=0.0537 SWA=0.9828 CWA=0.9833\nHWA=0.9830', '\\n', '[emb_dim_32] Ep3: tr_loss=0.0386 val_loss=0.0230 SWA=0.9918\nCWA=0.9922 HWA=0.9920', '\\n', '[emb_dim_32] Ep4: tr_loss=0.0216 val_loss=0.0171\nSWA=0.9938 CWA=0.9944 HWA=0.9941', '\\n', '[emb_dim_32] Ep5: tr_loss=0.0110\nval_loss=0.0103 SWA=0.9959 CWA=0.9960 HWA=0.9959', '\\n', '[emb_dim_32] Ep6:\ntr_loss=0.0049 val_loss=0.0039 SWA=0.9989 CWA=0.9991 HWA=0.9990', '\\n',\n'[emb_dim_64] Ep1: tr_loss=0.2064 val_loss=0.1063 SWA=0.9651 CWA=0.9636\nHWA=0.9643', '\\n', '[emb_dim_64] Ep2: tr_loss=0.0593 val_loss=0.0280 SWA=0.9926\nCWA=0.9933 HWA=0.9930', '\\n', '[emb_dim_64] Ep3: tr_loss=0.0185 val_loss=0.0154\nSWA=0.9952 CWA=0.9958 HWA=0.9955', '\\n', '[emb_dim_64] Ep4: tr_loss=0.0089\nval_loss=0.0098 SWA=0.9962 CWA=0.9970 HWA=0.9966', '\\n', '[emb_dim_64] Ep5:\ntr_loss=0.0031 val_loss=0.0035 SWA=0.9988 CWA=0.9990 HWA=0.9989', '\\n',\n'[emb_dim_64] Ep6: tr_loss=0.0011 val_loss=0.0040 SWA=0.9980 CWA=0.9983\nHWA=0.9982', '\\n', '[emb_dim_128] Ep1: tr_loss=0.1526 val_loss=0.0393 SWA=0.9851\nCWA=0.9854 HWA=0.9853', '\\n', '[emb_dim_128] Ep2: tr_loss=0.0217 val_loss=0.0096\nSWA=0.9981 CWA=0.9985 HWA=0.9983', '\\n', '[emb_dim_128] Ep3: tr_loss=0.0050\nval_loss=0.0030 SWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', '[emb_dim_128] Ep4:\ntr_loss=0.0013 val_loss=0.0016 SWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n',\n'[emb_dim_128] Ep5: tr_loss=0.0005 val_loss=0.0012 SWA=0.9998 CWA=0.9998\nHWA=0.9998', '\\n', '[emb_dim_128] Ep6: tr_loss=0.0003 val_loss=0.0010 SWA=0.9998\nCWA=0.9998 HWA=0.9998', '\\n', '[emb_dim_256] Ep1: tr_loss=0.1357 val_loss=0.0409\nSWA=0.9916 CWA=0.9925 HWA=0.9921', '\\n', '[emb_dim_256] Ep2: tr_loss=0.0188\nval_loss=0.0109 SWA=0.9974 CWA=0.9980 HWA=0.9977', '\\n', '[emb_dim_256] Ep3:\ntr_loss=0.0062 val_loss=0.0034 SWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n',\n'[emb_dim_256] Ep4: tr_loss=0.0012 val_loss=0.0020 SWA=0.9998 CWA=0.9998\nHWA=0.9998', '\\n', '[emb_dim_256] Ep5: tr_loss=0.0005 val_loss=0.0018 SWA=0.9998\nCWA=0.9998 HWA=0.9998', '\\n', '[emb_dim_256] Ep6: tr_loss=0.0003 val_loss=0.0016\nSWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n', 'Saved experiment data.', '\\n',\n'Execution time: 16 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size=17  num_classes=2', '\\n', '\\n===\nTraining with weight_decay=0.0 ===', '\\n', 'Epoch 1: train_loss=0.1947\nval_loss=0.0646  SWA=0.9808  CWA=0.9805  HWA=0.9806', '\\n', 'Epoch 2:\ntrain_loss=0.0401  val_loss=0.0212  SWA=0.9962  CWA=0.9969  HWA=0.9966', '\\n',\n'Epoch 3: train_loss=0.0145  val_loss=0.0094  SWA=0.9977  CWA=0.9979\nHWA=0.9978', '\\n', 'Epoch 4: train_loss=0.0064  val_loss=0.0061  SWA=0.9995\nCWA=0.9996  HWA=0.9996', '\\n', 'Epoch 5: train_loss=0.0023  val_loss=0.0030\nSWA=0.9991  CWA=0.9992  HWA=0.9991', '\\n', 'Epoch 6: train_loss=0.0008\nval_loss=0.0017  SWA=0.9995  CWA=0.9996  HWA=0.9996', '\\n', '\\n=== Training with\nweight_decay=1e-05 ===', '\\n', 'Epoch 1: train_loss=0.1917  val_loss=0.0762\nSWA=0.9811  CWA=0.9805  HWA=0.9808', '\\n', 'Epoch 2: train_loss=0.0434\nval_loss=0.0268  SWA=0.9919  CWA=0.9926  HWA=0.9922', '\\n', 'Epoch 3:\ntrain_loss=0.0152  val_loss=0.0106  SWA=0.9969  CWA=0.9973  HWA=0.9971', '\\n',\n'Epoch 4: train_loss=0.0073  val_loss=0.0080  SWA=0.9986  CWA=0.9988\nHWA=0.9987', '\\n', 'Epoch 5: train_loss=0.0029  val_loss=0.0043  SWA=0.9993\nCWA=0.9993  HWA=0.9993', '\\n', 'Epoch 6: train_loss=0.0011  val_loss=0.0026\nSWA=0.9993  CWA=0.9993  HWA=0.9993', '\\n', '\\n=== Training with\nweight_decay=0.0001 ===', '\\n', 'Epoch 1: train_loss=0.2131  val_loss=0.0724\nSWA=0.9767  CWA=0.9761  HWA=0.9764', '\\n', 'Epoch 2: train_loss=0.0410\nval_loss=0.0217  SWA=0.9949  CWA=0.9954  HWA=0.9952', '\\n', 'Epoch 3:\ntrain_loss=0.0165  val_loss=0.0118  SWA=0.9966  CWA=0.9971  HWA=0.9969', '\\n',\n'Epoch 4: train_loss=0.0093  val_loss=0.0090  SWA=0.9972  CWA=0.9974\nHWA=0.9973', '\\n', 'Epoch 5: train_loss=0.0045  val_loss=0.0077  SWA=0.9984\nCWA=0.9985  HWA=0.9985', '\\n', 'Epoch 6: train_loss=0.0031  val_loss=0.0028\nSWA=0.9995  CWA=0.9996  HWA=0.9996', '\\n', '\\n=== Training with\nweight_decay=0.001 ===', '\\n', 'Epoch 1: train_loss=0.2185  val_loss=0.0962\nSWA=0.9705  CWA=0.9696  HWA=0.9701', '\\n', 'Epoch 2: train_loss=0.0737\nval_loss=0.0606  SWA=0.9843  CWA=0.9842  HWA=0.9843', '\\n', 'Epoch 3:\ntrain_loss=0.0606  val_loss=0.0562  SWA=0.9854  CWA=0.9851  HWA=0.9852', '\\n',\n'Epoch 4: train_loss=0.0523  val_loss=0.0582  SWA=0.9843  CWA=0.9847\nHWA=0.9845', '\\n', 'Epoch 5: train_loss=0.0467  val_loss=0.0428  SWA=0.9887\nCWA=0.9888  HWA=0.9887', '\\n', 'Epoch 6: train_loss=0.0414  val_loss=0.0370\nSWA=0.9891  CWA=0.9892  HWA=0.9891', '\\n', '\\n=== Training with\nweight_decay=0.01 ===', '\\n', 'Epoch 1: train_loss=0.2916  val_loss=0.2044\nSWA=0.9476  CWA=0.9447  HWA=0.9462', '\\n', 'Epoch 2: train_loss=0.1949\nval_loss=0.1865  SWA=0.9519  CWA=0.9497  HWA=0.9508', '\\n', 'Epoch 3:\ntrain_loss=0.1746  val_loss=0.1644  SWA=0.9554  CWA=0.9528  HWA=0.9541', '\\n',\n'Epoch 4: train_loss=0.1580  val_loss=0.1591  SWA=0.9598  CWA=0.9573\nHWA=0.9586', '\\n', 'Epoch 5: train_loss=0.1520  val_loss=0.1583  SWA=0.9642\nCWA=0.9616  HWA=0.9629', '\\n', 'Epoch 6: train_loss=0.1512  val_loss=0.1529\nSWA=0.9619  CWA=0.9594  HWA=0.9606', '\\n', '\\nSaved experiment data to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_02-30-\n16_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n10/working/experiment_data.npy', '\\n', 'Execution time: 21 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size=17, num_classes=2', '\\n', '\\n===\nTraining with clip_val=0 ===', '\\n', 'Epoch 1: train_loss=0.1947 val_loss=0.0646\nSWA=0.9808 CWA=0.9805 HWA=0.9806', '\\n', 'Epoch 2: train_loss=0.0401\nval_loss=0.0212 SWA=0.9962 CWA=0.9969 HWA=0.9966', '\\n', 'Epoch 3:\ntrain_loss=0.0145 val_loss=0.0094 SWA=0.9977 CWA=0.9979 HWA=0.9978', '\\n',\n'Epoch 4: train_loss=0.0064 val_loss=0.0061 SWA=0.9995 CWA=0.9996 HWA=0.9996',\n'\\n', 'Epoch 5: train_loss=0.0023 val_loss=0.0030 SWA=0.9991 CWA=0.9992\nHWA=0.9991', '\\n', 'Epoch 6: train_loss=0.0008 val_loss=0.0017 SWA=0.9995\nCWA=0.9996 HWA=0.9996', '\\n', '\\n=== Training with clip_val=0.5 ===', '\\n',\n'Epoch 1: train_loss=0.1855 val_loss=0.0744 SWA=0.9820 CWA=0.9825 HWA=0.9822',\n'\\n', 'Epoch 2: train_loss=0.0444 val_loss=0.0323 SWA=0.9922 CWA=0.9929\nHWA=0.9925', '\\n', 'Epoch 3: train_loss=0.0208 val_loss=0.0123 SWA=0.9957\nCWA=0.9960 HWA=0.9959', '\\n', 'Epoch 4: train_loss=0.0092 val_loss=0.0076\nSWA=0.9983 CWA=0.9984 HWA=0.9983', '\\n', 'Epoch 5: train_loss=0.0032\nval_loss=0.0032 SWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', 'Epoch 6:\ntrain_loss=0.0008 val_loss=0.0025 SWA=0.9994 CWA=0.9994 HWA=0.9994', '\\n',\n'\\n=== Training with clip_val=1 ===', '\\n', 'Epoch 1: train_loss=0.2019\nval_loss=0.0744 SWA=0.9763 CWA=0.9766 HWA=0.9765', '\\n', 'Epoch 2:\ntrain_loss=0.0489 val_loss=0.0274 SWA=0.9926 CWA=0.9932 HWA=0.9929', '\\n',\n'Epoch 3: train_loss=0.0193 val_loss=0.0118 SWA=0.9969 CWA=0.9974 HWA=0.9971',\n'\\n', 'Epoch 4: train_loss=0.0081 val_loss=0.0070 SWA=0.9991 CWA=0.9992\nHWA=0.9992', '\\n', 'Epoch 5: train_loss=0.0028 val_loss=0.0032 SWA=0.9993\nCWA=0.9995 HWA=0.9994', '\\n', 'Epoch 6: train_loss=0.0010 val_loss=0.0018\nSWA=0.9993 CWA=0.9994 HWA=0.9993', '\\n', '\\n=== Training with clip_val=2 ===',\n'\\n', 'Epoch 1: train_loss=0.1995 val_loss=0.0749 SWA=0.9795 CWA=0.9792\nHWA=0.9794', '\\n', 'Epoch 2: train_loss=0.0515 val_loss=0.0334 SWA=0.9903\nCWA=0.9907 HWA=0.9905', '\\n', 'Epoch 3: train_loss=0.0234 val_loss=0.0145\nSWA=0.9967 CWA=0.9968 HWA=0.9968', '\\n', 'Epoch 4: train_loss=0.0073\nval_loss=0.0109 SWA=0.9965 CWA=0.9970 HWA=0.9967', '\\n', 'Epoch 5:\ntrain_loss=0.0030 val_loss=0.0029 SWA=0.9991 CWA=0.9993 HWA=0.9992', '\\n',\n'Epoch 6: train_loss=0.0008 val_loss=0.0023 SWA=0.9993 CWA=0.9994 HWA=0.9993',\n'\\n', '\\n=== Training with clip_val=5 ===', '\\n', 'Epoch 1: train_loss=0.1966\nval_loss=0.0782 SWA=0.9731 CWA=0.9729 HWA=0.9730', '\\n', 'Epoch 2:\ntrain_loss=0.0518 val_loss=0.0382 SWA=0.9908 CWA=0.9907 HWA=0.9907', '\\n',\n'Epoch 3: train_loss=0.0243 val_loss=0.0194 SWA=0.9954 CWA=0.9959 HWA=0.9956',\n'\\n', 'Epoch 4: train_loss=0.0093 val_loss=0.0077 SWA=0.9984 CWA=0.9985\nHWA=0.9985', '\\n', 'Epoch 5: train_loss=0.0030 val_loss=0.0034 SWA=0.9985\nCWA=0.9985 HWA=0.9985', '\\n', 'Epoch 6: train_loss=0.0009 val_loss=0.0021\nSWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_02-30-\n16_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n13/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size=17, num_classes=2', '\\n',\n'[hidden=64] Epoch1 train_loss=0.2265 val_loss=0.0937 SWA=0.9748 CWA=0.9740\nHWA=0.9744', '\\n', '[hidden=64] Epoch2 train_loss=0.0586 val_loss=0.0338\nSWA=0.9904 CWA=0.9907 HWA=0.9906', '\\n', '[hidden=64] Epoch3 train_loss=0.0239\nval_loss=0.0178 SWA=0.9944 CWA=0.9948 HWA=0.9946', '\\n', '[hidden=64] Epoch4\ntrain_loss=0.0116 val_loss=0.0102 SWA=0.9970 CWA=0.9971 HWA=0.9971', '\\n',\n'[hidden=64] Epoch5 train_loss=0.0050 val_loss=0.0070 SWA=0.9977 CWA=0.9976\nHWA=0.9976', '\\n', '[hidden=64] Epoch6 train_loss=0.0028 val_loss=0.0041\nSWA=0.9985 CWA=0.9986 HWA=0.9986', '\\n', '[hidden=128] Epoch1 train_loss=0.2140\nval_loss=0.1051 SWA=0.9639 CWA=0.9628 HWA=0.9634', '\\n', '[hidden=128] Epoch2\ntrain_loss=0.0582 val_loss=0.0295 SWA=0.9931 CWA=0.9932 HWA=0.9932', '\\n',\n'[hidden=128] Epoch3 train_loss=0.0191 val_loss=0.0151 SWA=0.9973 CWA=0.9975\nHWA=0.9974', '\\n', '[hidden=128] Epoch4 train_loss=0.0063 val_loss=0.0039\nSWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=128] Epoch5 train_loss=0.0025\nval_loss=0.0024 SWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=128] Epoch6\ntrain_loss=0.0009 val_loss=0.0014 SWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n',\n'[hidden=256] Epoch1 train_loss=0.1758 val_loss=0.0526 SWA=0.9804 CWA=0.9809\nHWA=0.9806', '\\n', '[hidden=256] Epoch2 train_loss=0.0304 val_loss=0.0154\nSWA=0.9951 CWA=0.9959 HWA=0.9955', '\\n', '[hidden=256] Epoch3 train_loss=0.0090\nval_loss=0.0047 SWA=0.9986 CWA=0.9989 HWA=0.9988', '\\n', '[hidden=256] Epoch4\ntrain_loss=0.0034 val_loss=0.0144 SWA=0.9949 CWA=0.9950 HWA=0.9950', '\\n',\n'[hidden=256] Epoch5 train_loss=0.0038 val_loss=0.0015 SWA=0.9995 CWA=0.9997\nHWA=0.9996', '\\n', '[hidden=256] Epoch6 train_loss=0.0003 val_loss=0.0011\nSWA=0.9998 CWA=0.9999 HWA=0.9998', '\\n', '[hidden=512] Epoch1 train_loss=0.1562\nval_loss=0.0579 SWA=0.9832 CWA=0.9832 HWA=0.9832', '\\n', '[hidden=512] Epoch2\ntrain_loss=0.0429 val_loss=0.0266 SWA=0.9935 CWA=0.9941 HWA=0.9938', '\\n',\n'[hidden=512] Epoch3 train_loss=0.0142 val_loss=0.0072 SWA=0.9978 CWA=0.9979\nHWA=0.9979', '\\n', '[hidden=512] Epoch4 train_loss=0.0033 val_loss=0.0021\nSWA=0.9996 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=512] Epoch5 train_loss=0.0005\nval_loss=0.0007 SWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n', '[hidden=512] Epoch6\ntrain_loss=0.0002 val_loss=0.0006 SWA=1.0000 CWA=1.0000 HWA=1.0000', '\\n',\n'Saved experiment data to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-\n16_02-30-16_context_aware_contrastive_learning_attempt_0/0-\nrun/process_ForkProcess-12/working/experiment_data.npy', '\\n', 'Execution time:\na minute seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size=17, num_classes=2', '\\n',\n'[hidden=64] Epoch1 train_loss=0.2265 val_loss=0.0937 SWA=0.9748 CWA=0.9740\nHWA=0.9744', '\\n', '[hidden=64] Epoch2 train_loss=0.0586 val_loss=0.0338\nSWA=0.9904 CWA=0.9907 HWA=0.9906', '\\n', '[hidden=64] Epoch3 train_loss=0.0239\nval_loss=0.0178 SWA=0.9944 CWA=0.9948 HWA=0.9946', '\\n', '[hidden=64] Epoch4\ntrain_loss=0.0116 val_loss=0.0102 SWA=0.9970 CWA=0.9971 HWA=0.9971', '\\n',\n'[hidden=64] Epoch5 train_loss=0.0050 val_loss=0.0070 SWA=0.9977 CWA=0.9976\nHWA=0.9976', '\\n', '[hidden=64] Epoch6 train_loss=0.0028 val_loss=0.0041\nSWA=0.9985 CWA=0.9986 HWA=0.9986', '\\n', '[hidden=128] Epoch1 train_loss=0.2140\nval_loss=0.1051 SWA=0.9639 CWA=0.9628 HWA=0.9634', '\\n', '[hidden=128] Epoch2\ntrain_loss=0.0582 val_loss=0.0295 SWA=0.9931 CWA=0.9932 HWA=0.9932', '\\n',\n'[hidden=128] Epoch3 train_loss=0.0191 val_loss=0.0151 SWA=0.9973 CWA=0.9975\nHWA=0.9974', '\\n', '[hidden=128] Epoch4 train_loss=0.0063 val_loss=0.0039\nSWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=128] Epoch5 train_loss=0.0025\nval_loss=0.0024 SWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=128] Epoch6\ntrain_loss=0.0009 val_loss=0.0014 SWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n',\n'[hidden=256] Epoch1 train_loss=0.1758 val_loss=0.0526 SWA=0.9804 CWA=0.9809\nHWA=0.9806', '\\n', '[hidden=256] Epoch2 train_loss=0.0304 val_loss=0.0154\nSWA=0.9951 CWA=0.9959 HWA=0.9955', '\\n', '[hidden=256] Epoch3 train_loss=0.0090\nval_loss=0.0047 SWA=0.9986 CWA=0.9989 HWA=0.9988', '\\n', '[hidden=256] Epoch4\ntrain_loss=0.0034 val_loss=0.0144 SWA=0.9949 CWA=0.9950 HWA=0.9950', '\\n',\n'[hidden=256] Epoch5 train_loss=0.0038 val_loss=0.0015 SWA=0.9995 CWA=0.9997\nHWA=0.9996', '\\n', '[hidden=256] Epoch6 train_loss=0.0003 val_loss=0.0011\nSWA=0.9998 CWA=0.9999 HWA=0.9998', '\\n', '[hidden=512] Epoch1 train_loss=0.1562\nval_loss=0.0579 SWA=0.9832 CWA=0.9832 HWA=0.9832', '\\n', '[hidden=512] Epoch2\ntrain_loss=0.0429 val_loss=0.0266 SWA=0.9935 CWA=0.9941 HWA=0.9938', '\\n',\n'[hidden=512] Epoch3 train_loss=0.0142 val_loss=0.0072 SWA=0.9978 CWA=0.9979\nHWA=0.9979', '\\n', '[hidden=512] Epoch4 train_loss=0.0033 val_loss=0.0021\nSWA=0.9996 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=512] Epoch5 train_loss=0.0005\nval_loss=0.0007 SWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n', '[hidden=512] Epoch6\ntrain_loss=0.0002 val_loss=0.0006 SWA=1.0000 CWA=1.0000 HWA=1.0000', '\\n',\n'Saved experiment data to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-\n16_02-30-16_context_aware_contrastive_learning_attempt_0/0-\nrun/process_ForkProcess-10/working/experiment_data.npy', '\\n', 'Execution time:\n18 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at: /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Vocab size=17, num_classes=2', '\\n',\n'[hidden=64] Epoch1 train_loss=0.2265 val_loss=0.0937 SWA=0.9748 CWA=0.9740\nHWA=0.9744', '\\n', '[hidden=64] Epoch2 train_loss=0.0586 val_loss=0.0338\nSWA=0.9904 CWA=0.9907 HWA=0.9906', '\\n', '[hidden=64] Epoch3 train_loss=0.0239\nval_loss=0.0178 SWA=0.9944 CWA=0.9948 HWA=0.9946', '\\n', '[hidden=64] Epoch4\ntrain_loss=0.0116 val_loss=0.0102 SWA=0.9970 CWA=0.9971 HWA=0.9971', '\\n',\n'[hidden=64] Epoch5 train_loss=0.0050 val_loss=0.0070 SWA=0.9977 CWA=0.9976\nHWA=0.9976', '\\n', '[hidden=64] Epoch6 train_loss=0.0028 val_loss=0.0041\nSWA=0.9985 CWA=0.9986 HWA=0.9986', '\\n', '[hidden=128] Epoch1 train_loss=0.2140\nval_loss=0.1051 SWA=0.9639 CWA=0.9628 HWA=0.9634', '\\n', '[hidden=128] Epoch2\ntrain_loss=0.0582 val_loss=0.0295 SWA=0.9931 CWA=0.9932 HWA=0.9932', '\\n',\n'[hidden=128] Epoch3 train_loss=0.0191 val_loss=0.0151 SWA=0.9973 CWA=0.9975\nHWA=0.9974', '\\n', '[hidden=128] Epoch4 train_loss=0.0063 val_loss=0.0039\nSWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=128] Epoch5 train_loss=0.0025\nval_loss=0.0024 SWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=128] Epoch6\ntrain_loss=0.0009 val_loss=0.0014 SWA=0.9995 CWA=0.9996 HWA=0.9996', '\\n',\n'[hidden=256] Epoch1 train_loss=0.1758 val_loss=0.0526 SWA=0.9804 CWA=0.9809\nHWA=0.9806', '\\n', '[hidden=256] Epoch2 train_loss=0.0304 val_loss=0.0154\nSWA=0.9951 CWA=0.9959 HWA=0.9955', '\\n', '[hidden=256] Epoch3 train_loss=0.0090\nval_loss=0.0047 SWA=0.9986 CWA=0.9989 HWA=0.9988', '\\n', '[hidden=256] Epoch4\ntrain_loss=0.0034 val_loss=0.0144 SWA=0.9949 CWA=0.9950 HWA=0.9950', '\\n',\n'[hidden=256] Epoch5 train_loss=0.0038 val_loss=0.0015 SWA=0.9995 CWA=0.9997\nHWA=0.9996', '\\n', '[hidden=256] Epoch6 train_loss=0.0003 val_loss=0.0011\nSWA=0.9998 CWA=0.9999 HWA=0.9998', '\\n', '[hidden=512] Epoch1 train_loss=0.1562\nval_loss=0.0579 SWA=0.9832 CWA=0.9832 HWA=0.9832', '\\n', '[hidden=512] Epoch2\ntrain_loss=0.0429 val_loss=0.0266 SWA=0.9935 CWA=0.9941 HWA=0.9938', '\\n',\n'[hidden=512] Epoch3 train_loss=0.0142 val_loss=0.0072 SWA=0.9978 CWA=0.9979\nHWA=0.9979', '\\n', '[hidden=512] Epoch4 train_loss=0.0033 val_loss=0.0021\nSWA=0.9996 CWA=0.9996 HWA=0.9996', '\\n', '[hidden=512] Epoch5 train_loss=0.0005\nval_loss=0.0007 SWA=0.9998 CWA=0.9998 HWA=0.9998', '\\n', '[hidden=512] Epoch6\ntrain_loss=0.0002 val_loss=0.0006 SWA=1.0000 CWA=1.0000 HWA=1.0000', '\\n',\n'Saved experiment data to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-\n16_02-30-16_context_aware_contrastive_learning_attempt_0/0-\nrun/process_ForkProcess-11/working/experiment_data.npy', '\\n', 'Execution time:\n19 seconds seconds (time limit is 30 minutes).']", ""], "analysis": ["", "", "", "", "", "", "", "", "The training script executed successfully without any bugs. The model was\ntrained with varying hidden sizes (64, 128, 256, 512) for 6 epochs each. The\nmetrics (SWA, CWA, HWA) consistently improved across epochs, and the final\nhidden size (512) achieved perfect accuracy (SWA=1.0000, CWA=1.0000,\nHWA=1.0000). The experiment data was saved correctly. No issues were detected.", "", "The training script executed successfully without any bugs. The experiments were\nconducted with different hidden sizes, and the results were logged\nappropriately. The metrics, including Shape-Weighted Accuracy (SWA), Color-\nWeighted Accuracy (CWA), and Harmonic-Weighted Accuracy (HWA), improved\nconsistently across epochs for all hidden sizes. The results were saved to a\nfile for further analysis. Execution time was well within the limit.", ""], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The final loss value achieved during training.", "data": [{"dataset_name": "SPR_BENCH (num_epochs = 6)", "final_value": 0.0008, "best_value": 0.0008}, {"dataset_name": "SPR_BENCH (num_epochs = 12)", "final_value": 0.0001, "best_value": 0.0001}, {"dataset_name": "SPR_BENCH (num_epochs = 18)", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The best loss value achieved on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH (num_epochs = 6)", "final_value": 0.0017, "best_value": 0.0017}, {"dataset_name": "SPR_BENCH (num_epochs = 12)", "final_value": 0.0016, "best_value": 0.0016}, {"dataset_name": "SPR_BENCH (num_epochs = 18)", "final_value": 0.001, "best_value": 0.001}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "The best shape weighted accuracy achieved on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH (num_epochs = 6)", "final_value": 0.9995, "best_value": 0.9995}, {"dataset_name": "SPR_BENCH (num_epochs = 12)", "final_value": 0.9995, "best_value": 0.9995}, {"dataset_name": "SPR_BENCH (num_epochs = 18)", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "The best color weighted accuracy achieved on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH (num_epochs = 6)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (num_epochs = 12)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (num_epochs = 18)", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "harmonic weighted accuracy", "lower_is_better": false, "description": "The best harmonic weighted accuracy achieved on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH (num_epochs = 6)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (num_epochs = 12)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (num_epochs = 18)", "final_value": 0.9998, "best_value": 0.9998}]}]}, {"metric_names": [{"metric_name": "Training loss", "lower_is_better": true, "description": "The minimum training loss achieved during the training process.", "data": [{"dataset_name": "learning_rate = 0.0003", "final_value": 0.0269, "best_value": 0.0269}, {"dataset_name": "learning_rate = 0.001", "final_value": 0.0008, "best_value": 0.0008}, {"dataset_name": "learning_rate = 0.003", "final_value": 0.0001, "best_value": 0.0001}]}, {"metric_name": "Validation loss", "lower_is_better": true, "description": "The minimum validation loss achieved during the training process.", "data": [{"dataset_name": "learning_rate = 0.0003", "final_value": 0.0253, "best_value": 0.0253}, {"dataset_name": "learning_rate = 0.001", "final_value": 0.0014, "best_value": 0.0014}, {"dataset_name": "learning_rate = 0.003", "final_value": 0.0003, "best_value": 0.0003}]}, {"metric_name": "Validation shape-weighted accuracy", "lower_is_better": false, "description": "The maximum validation shape-weighted accuracy achieved during the training process.", "data": [{"dataset_name": "learning_rate = 0.0003", "final_value": 0.9919, "best_value": 0.9919}, {"dataset_name": "learning_rate = 0.001", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "learning_rate = 0.003", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Validation color-weighted accuracy", "lower_is_better": false, "description": "The maximum validation color-weighted accuracy achieved during the training process.", "data": [{"dataset_name": "learning_rate = 0.0003", "final_value": 0.9921, "best_value": 0.9921}, {"dataset_name": "learning_rate = 0.001", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "learning_rate = 0.003", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Validation harmonic-weighted accuracy", "lower_is_better": false, "description": "The maximum validation harmonic-weighted accuracy achieved during the training process.", "data": [{"dataset_name": "learning_rate = 0.0003", "final_value": 0.992, "best_value": 0.992}, {"dataset_name": "learning_rate = 0.001", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "learning_rate = 0.003", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value calculated on the training dataset, indicating how well the model fits the training data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0002, "best_value": 0.0002}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value calculated on the validation dataset, indicating how well the model generalizes.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0009, "best_value": 0.0009}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "The accuracy metric weighted by shape on the validation dataset, indicating the model's performance in recognizing shapes.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "The accuracy metric weighted by color on the validation dataset, indicating the model's performance in recognizing colors.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "validation harmonic-weighted accuracy", "lower_is_better": false, "description": "The accuracy metric weighted harmonically on the validation dataset, indicating overall balanced performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value computed from the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0423, "best_value": 0.0008}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value computed from the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0218, "best_value": 0.0017}]}, {"metric_name": "validation shape-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by shape for the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9913, "best_value": 0.9995}]}, {"metric_name": "validation color-weighted accuracy", "lower_is_better": false, "description": "Accuracy metric weighted by color for the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9919, "best_value": 0.9996}]}, {"metric_name": "validation harmonic-weighted accuracy", "lower_is_better": false, "description": "Harmonic mean of shape-weighted and color-weighted accuracies for the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9916, "best_value": 0.9996}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The final training loss achieved during execution.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.0028, "best_value": 0.0028}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.0009, "best_value": 0.0009}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.0003, "best_value": 0.0003}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 0.0002, "best_value": 0.0002}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The final validation loss achieved during execution.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.0041, "best_value": 0.0041}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.0014, "best_value": 0.0014}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.0011, "best_value": 0.0011}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 0.0006, "best_value": 0.0006}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "The final shape weighted accuracy achieved during execution.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9985, "best_value": 0.9985}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9995, "best_value": 0.9995}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "The final color weighted accuracy achieved during execution.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9986, "best_value": 0.9986}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "harmonic weighted accuracy", "lower_is_better": false, "description": "The final harmonic weighted accuracy achieved during execution.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9986, "best_value": 0.9986}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss during training, indicating how well the model fits the training data.", "data": [{"dataset_name": "SPR_BENCH_emb_dim_32", "final_value": 0.0049, "best_value": 0.0049}, {"dataset_name": "SPR_BENCH_emb_dim_64", "final_value": 0.0011, "best_value": 0.0011}, {"dataset_name": "SPR_BENCH_emb_dim_128", "final_value": 0.0003, "best_value": 0.0003}, {"dataset_name": "SPR_BENCH_emb_dim_256", "final_value": 0.0003, "best_value": 0.0003}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss on the validation dataset, used to evaluate the model's performance.", "data": [{"dataset_name": "SPR_BENCH_emb_dim_32", "final_value": 0.0039, "best_value": 0.0039}, {"dataset_name": "SPR_BENCH_emb_dim_64", "final_value": 0.004, "best_value": 0.004}, {"dataset_name": "SPR_BENCH_emb_dim_128", "final_value": 0.001, "best_value": 0.001}, {"dataset_name": "SPR_BENCH_emb_dim_256", "final_value": 0.0016, "best_value": 0.0016}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "Shape-weighted accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH_emb_dim_32", "final_value": 0.9989, "best_value": 0.9989}, {"dataset_name": "SPR_BENCH_emb_dim_64", "final_value": 0.998, "best_value": 0.998}, {"dataset_name": "SPR_BENCH_emb_dim_128", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH_emb_dim_256", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "Color-weighted accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH_emb_dim_32", "final_value": 0.9991, "best_value": 0.9991}, {"dataset_name": "SPR_BENCH_emb_dim_64", "final_value": 0.9983, "best_value": 0.9983}, {"dataset_name": "SPR_BENCH_emb_dim_128", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH_emb_dim_256", "final_value": 0.9998, "best_value": 0.9998}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "Harmonic-weighted accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH_emb_dim_32", "final_value": 0.999, "best_value": 0.999}, {"dataset_name": "SPR_BENCH_emb_dim_64", "final_value": 0.9982, "best_value": 0.9982}, {"dataset_name": "SPR_BENCH_emb_dim_128", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH_emb_dim_256", "final_value": 0.9998, "best_value": 0.9998}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.151242, "best_value": 0.000836}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.152883, "best_value": 0.001699}]}, {"metric_name": "validation Shape-Weighted Accuracy", "lower_is_better": false, "description": "The shape-weighted accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.96419, "best_value": 0.999535}]}, {"metric_name": "validation Color-Weighted Accuracy", "lower_is_better": false, "description": "The color-weighted accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.961625, "best_value": 0.999573}]}, {"metric_name": "validation Harmonic-Weighted Accuracy", "lower_is_better": false, "description": "The harmonic-weighted accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.962906, "best_value": 0.999554}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value calculated on the training dataset.", "data": [{"dataset_name": "gradient_clipping_max_norm=0", "final_value": 0.000836, "best_value": 0.000836}, {"dataset_name": "gradient_clipping_max_norm=0.5", "final_value": 0.000796, "best_value": 0.000796}, {"dataset_name": "gradient_clipping_max_norm=1", "final_value": 0.000954, "best_value": 0.000954}, {"dataset_name": "gradient_clipping_max_norm=2", "final_value": 0.000811, "best_value": 0.000811}, {"dataset_name": "gradient_clipping_max_norm=5", "final_value": 0.000941, "best_value": 0.000941}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value calculated on the validation dataset.", "data": [{"dataset_name": "gradient_clipping_max_norm=0", "final_value": 0.001699, "best_value": 0.001699}, {"dataset_name": "gradient_clipping_max_norm=0.5", "final_value": 0.002526, "best_value": 0.002526}, {"dataset_name": "gradient_clipping_max_norm=1", "final_value": 0.001784, "best_value": 0.001784}, {"dataset_name": "gradient_clipping_max_norm=2", "final_value": 0.002346, "best_value": 0.002346}, {"dataset_name": "gradient_clipping_max_norm=5", "final_value": 0.002051, "best_value": 0.002051}]}, {"metric_name": "validation shape weighted accuracy", "lower_is_better": false, "description": "The weighted accuracy for shape predictions on the validation dataset.", "data": [{"dataset_name": "gradient_clipping_max_norm=0", "final_value": 0.999535, "best_value": 0.999535}, {"dataset_name": "gradient_clipping_max_norm=0.5", "final_value": 0.999361, "best_value": 0.999361}, {"dataset_name": "gradient_clipping_max_norm=1", "final_value": 0.999302, "best_value": 0.999302}, {"dataset_name": "gradient_clipping_max_norm=2", "final_value": 0.999302, "best_value": 0.999302}, {"dataset_name": "gradient_clipping_max_norm=5", "final_value": 0.999535, "best_value": 0.999535}]}, {"metric_name": "validation color weighted accuracy", "lower_is_better": false, "description": "The weighted accuracy for color predictions on the validation dataset.", "data": [{"dataset_name": "gradient_clipping_max_norm=0", "final_value": 0.999573, "best_value": 0.999573}, {"dataset_name": "gradient_clipping_max_norm=0.5", "final_value": 0.99939, "best_value": 0.99939}, {"dataset_name": "gradient_clipping_max_norm=1", "final_value": 0.99939, "best_value": 0.99939}, {"dataset_name": "gradient_clipping_max_norm=2", "final_value": 0.99939, "best_value": 0.99939}, {"dataset_name": "gradient_clipping_max_norm=5", "final_value": 0.999634, "best_value": 0.999634}]}, {"metric_name": "validation harmonic weighted accuracy", "lower_is_better": false, "description": "The harmonic weighted accuracy calculated on the validation dataset.", "data": [{"dataset_name": "gradient_clipping_max_norm=0", "final_value": 0.999554, "best_value": 0.999554}, {"dataset_name": "gradient_clipping_max_norm=0.5", "final_value": 0.999375, "best_value": 0.999375}, {"dataset_name": "gradient_clipping_max_norm=1", "final_value": 0.999346, "best_value": 0.999346}, {"dataset_name": "gradient_clipping_max_norm=2", "final_value": 0.999346, "best_value": 0.999346}, {"dataset_name": "gradient_clipping_max_norm=5", "final_value": 0.999584, "best_value": 0.999584}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The final loss value during training.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.0028, "best_value": 0.0028}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.0009, "best_value": 0.0009}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.0003, "best_value": 0.0003}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 0.0002, "best_value": 0.0002}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The final loss value during validation.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.0041, "best_value": 0.0041}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.0014, "best_value": 0.0014}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.0011, "best_value": 0.0011}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 0.0006, "best_value": 0.0006}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "The accuracy metric weighted by shape features.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9985, "best_value": 0.9985}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9995, "best_value": 0.9995}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "The accuracy metric weighted by color features.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9986, "best_value": 0.9986}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "harmonic weighted accuracy", "lower_is_better": false, "description": "The accuracy metric weighted harmonically across features.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9986, "best_value": 0.9986}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "This metric represents the loss during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.0028, "best_value": 0.0028}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.0009, "best_value": 0.0009}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.0003, "best_value": 0.0003}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 0.0002, "best_value": 0.0002}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "This metric represents the loss during validation. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.0041, "best_value": 0.0041}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.0014, "best_value": 0.0014}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.0011, "best_value": 0.0011}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 0.0006, "best_value": 0.0006}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "This metric measures the weighted accuracy for shape classification. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9985, "best_value": 0.9985}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9995, "best_value": 0.9995}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "This metric measures the weighted accuracy for color classification. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9986, "best_value": 0.9986}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "harmonic weighted accuracy", "lower_is_better": false, "description": "This metric measures the harmonic weighted accuracy. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9986, "best_value": 0.9986}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating the model's error on the training dataset.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.0028, "best_value": 0.0028}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.0009, "best_value": 0.0009}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.0003, "best_value": 0.0003}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 0.0002, "best_value": 0.0002}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, indicating the model's error on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.0041, "best_value": 0.0041}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.0014, "best_value": 0.0014}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.0011, "best_value": 0.0011}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 0.0006, "best_value": 0.0006}]}, {"metric_name": "shape weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by shape features.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9985, "best_value": 0.9985}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9995, "best_value": 0.9995}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "color weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by color features.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9986, "best_value": 0.9986}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "harmonic weighted accuracy", "lower_is_better": false, "description": "Accuracy weighted by harmonic features.", "data": [{"dataset_name": "SPR_BENCH (hidden size = 64)", "final_value": 0.9986, "best_value": 0.9986}, {"dataset_name": "SPR_BENCH (hidden size = 128)", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "SPR_BENCH (hidden size = 256)", "final_value": 0.9998, "best_value": 0.9998}, {"dataset_name": "SPR_BENCH (hidden size = 512)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, true, false, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_a4b716d7e472413598bf36fc151be539_proc_3099456/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_a4b716d7e472413598bf36fc151be539_proc_3099456/SPR_BENCH_hwa_curves.png"], ["../../logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_loss_curves_lr0.0003.png", "../../logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_loss_curves_lr0.001.png", "../../logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_loss_curves_lr0.003.png", "../../logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_metric_curves_lr0.0003.png", "../../logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_metric_curves_lr0.001.png", "../../logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_metric_curves_lr0.003.png", "../../logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_HWA_comparison.png", "../../logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_best_HWA_bar.png"], ["../../logs/0-run/experiment_results/experiment_772afb88db524e34a011470642292815_proc_3099458/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_772afb88db524e34a011470642292815_proc_3099458/SPR_BENCH_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_772afb88db524e34a011470642292815_proc_3099458/SPR_BENCH_final_hwa_bar.png"], ["../../logs/0-run/experiment_results/experiment_6ba65a5270a14d6a8fc7f6cdef4f65fa_proc_3099459/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_6ba65a5270a14d6a8fc7f6cdef4f65fa_proc_3099459/SPR_BENCH_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_6ba65a5270a14d6a8fc7f6cdef4f65fa_proc_3099459/SPR_BENCH_final_hwa.png"], ["../../logs/0-run/experiment_results/experiment_ed93b5240f074db1b3b8551e7df1174c_proc_3099457/SPR_BENCH_loss_curves_hidden_sizes.png", "../../logs/0-run/experiment_results/experiment_ed93b5240f074db1b3b8551e7df1174c_proc_3099457/SPR_BENCH_hwa_curves_hidden_sizes.png", "../../logs/0-run/experiment_results/experiment_ed93b5240f074db1b3b8551e7df1174c_proc_3099457/SPR_BENCH_final_hwa_bar.png"], ["../../logs/0-run/experiment_results/experiment_4b26d29dde0f4edc80abb2e04402e1f1_proc_3099458/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_4b26d29dde0f4edc80abb2e04402e1f1_proc_3099458/SPR_BENCH_HWA_over_epochs.png", "../../logs/0-run/experiment_results/experiment_4b26d29dde0f4edc80abb2e04402e1f1_proc_3099458/SPR_BENCH_final_HWA_bar.png"], ["../../logs/0-run/experiment_results/experiment_7c7c347607d8447c9cbb0e222147edc9_proc_3099456/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_7c7c347607d8447c9cbb0e222147edc9_proc_3099456/SPR_BENCH_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_7c7c347607d8447c9cbb0e222147edc9_proc_3099456/SPR_BENCH_final_hwa_vs_wd.png"], ["../../logs/0-run/experiment_results/experiment_7a2f6173297a4e109edf67fa2be97a96_proc_3099459/spr_bench_loss_curves.png", "../../logs/0-run/experiment_results/experiment_7a2f6173297a4e109edf67fa2be97a96_proc_3099459/spr_bench_hwa_curves.png", "../../logs/0-run/experiment_results/experiment_7a2f6173297a4e109edf67fa2be97a96_proc_3099459/spr_bench_final_hwa_bar.png"], ["../../logs/0-run/experiment_results/experiment_930038a9ae014668b759b437fdca3e7c_proc_3099458/SPR_BENCH_loss_curves_hidden_sizes.png", "../../logs/0-run/experiment_results/experiment_930038a9ae014668b759b437fdca3e7c_proc_3099458/SPR_BENCH_hwa_curves_hidden_sizes.png", "../../logs/0-run/experiment_results/experiment_930038a9ae014668b759b437fdca3e7c_proc_3099458/SPR_BENCH_final_hwa_bar.png"], ["../../logs/0-run/experiment_results/experiment_f20704230f6d40cebfde3e31579e8f5e_proc_3099456/SPR_BENCH_loss_curves_hidden_sizes.png", "../../logs/0-run/experiment_results/experiment_f20704230f6d40cebfde3e31579e8f5e_proc_3099456/SPR_BENCH_hwa_curves_hidden_sizes.png", "../../logs/0-run/experiment_results/experiment_f20704230f6d40cebfde3e31579e8f5e_proc_3099456/SPR_BENCH_final_hwa_bar.png"], ["../../logs/0-run/experiment_results/experiment_ca25c2f21e3f4767a4586b917ec76994_proc_3099457/SPR_BENCH_loss_curves_hidden_sizes.png", "../../logs/0-run/experiment_results/experiment_ca25c2f21e3f4767a4586b917ec76994_proc_3099457/SPR_BENCH_hwa_curves_hidden_sizes.png", "../../logs/0-run/experiment_results/experiment_ca25c2f21e3f4767a4586b917ec76994_proc_3099457/SPR_BENCH_final_hwa_bar.png"], ["../../logs/0-run/experiment_results/seed_aggregation_8baf5aa372d448dab18999c2afb1a0b5/SPR_BENCH_loss_curves_mean_se.png", "../../logs/0-run/experiment_results/seed_aggregation_8baf5aa372d448dab18999c2afb1a0b5/SPR_BENCH_hwa_curves_mean_se.png", "../../logs/0-run/experiment_results/seed_aggregation_8baf5aa372d448dab18999c2afb1a0b5/SPR_BENCH_final_hwa_bar_mean_se.png"]], "plot_paths": [["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a4b716d7e472413598bf36fc151be539_proc_3099456/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a4b716d7e472413598bf36fc151be539_proc_3099456/SPR_BENCH_hwa_curves.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_loss_curves_lr0.0003.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_loss_curves_lr0.001.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_loss_curves_lr0.003.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_metric_curves_lr0.0003.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_metric_curves_lr0.001.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_metric_curves_lr0.003.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_HWA_comparison.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_best_HWA_bar.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_772afb88db524e34a011470642292815_proc_3099458/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_772afb88db524e34a011470642292815_proc_3099458/SPR_BENCH_hwa_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_772afb88db524e34a011470642292815_proc_3099458/SPR_BENCH_final_hwa_bar.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6ba65a5270a14d6a8fc7f6cdef4f65fa_proc_3099459/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6ba65a5270a14d6a8fc7f6cdef4f65fa_proc_3099459/SPR_BENCH_hwa_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6ba65a5270a14d6a8fc7f6cdef4f65fa_proc_3099459/SPR_BENCH_final_hwa.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ed93b5240f074db1b3b8551e7df1174c_proc_3099457/SPR_BENCH_loss_curves_hidden_sizes.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ed93b5240f074db1b3b8551e7df1174c_proc_3099457/SPR_BENCH_hwa_curves_hidden_sizes.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ed93b5240f074db1b3b8551e7df1174c_proc_3099457/SPR_BENCH_final_hwa_bar.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_4b26d29dde0f4edc80abb2e04402e1f1_proc_3099458/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_4b26d29dde0f4edc80abb2e04402e1f1_proc_3099458/SPR_BENCH_HWA_over_epochs.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_4b26d29dde0f4edc80abb2e04402e1f1_proc_3099458/SPR_BENCH_final_HWA_bar.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7c7c347607d8447c9cbb0e222147edc9_proc_3099456/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7c7c347607d8447c9cbb0e222147edc9_proc_3099456/SPR_BENCH_hwa_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7c7c347607d8447c9cbb0e222147edc9_proc_3099456/SPR_BENCH_final_hwa_vs_wd.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7a2f6173297a4e109edf67fa2be97a96_proc_3099459/spr_bench_loss_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7a2f6173297a4e109edf67fa2be97a96_proc_3099459/spr_bench_hwa_curves.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7a2f6173297a4e109edf67fa2be97a96_proc_3099459/spr_bench_final_hwa_bar.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_930038a9ae014668b759b437fdca3e7c_proc_3099458/SPR_BENCH_loss_curves_hidden_sizes.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_930038a9ae014668b759b437fdca3e7c_proc_3099458/SPR_BENCH_hwa_curves_hidden_sizes.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_930038a9ae014668b759b437fdca3e7c_proc_3099458/SPR_BENCH_final_hwa_bar.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f20704230f6d40cebfde3e31579e8f5e_proc_3099456/SPR_BENCH_loss_curves_hidden_sizes.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f20704230f6d40cebfde3e31579e8f5e_proc_3099456/SPR_BENCH_hwa_curves_hidden_sizes.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f20704230f6d40cebfde3e31579e8f5e_proc_3099456/SPR_BENCH_final_hwa_bar.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ca25c2f21e3f4767a4586b917ec76994_proc_3099457/SPR_BENCH_loss_curves_hidden_sizes.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ca25c2f21e3f4767a4586b917ec76994_proc_3099457/SPR_BENCH_hwa_curves_hidden_sizes.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ca25c2f21e3f4767a4586b917ec76994_proc_3099457/SPR_BENCH_final_hwa_bar.png"], ["experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_8baf5aa372d448dab18999c2afb1a0b5/SPR_BENCH_loss_curves_mean_se.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_8baf5aa372d448dab18999c2afb1a0b5/SPR_BENCH_hwa_curves_mean_se.png", "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_8baf5aa372d448dab18999c2afb1a0b5/SPR_BENCH_final_hwa_bar_mean_se.png"]], "plot_analyses": [[{"analysis": "The training and validation loss curves show a consistent decrease across all epoch configurations (6, 12, and 18 epochs). The losses converge close to zero by the end of the training period, indicating that the model is effectively learning the task without signs of underfitting or overfitting. The similarity between training and validation loss curves suggests that the model generalizes well to unseen data. Increasing the number of epochs slightly improves the convergence behavior, but the gains diminish after 12 epochs, as the losses for 12 and 18 epochs are nearly identical.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a4b716d7e472413598bf36fc151be539_proc_3099456/SPR_BENCH_loss_curves.png"}, {"analysis": "The validation harmonic weighted accuracy (HWA) improves rapidly within the first few epochs and stabilizes close to 1.0 for all configurations. While the 6-epoch configuration reaches near-optimal performance quickly, the 12-epoch and 18-epoch configurations provide slightly more stable and consistent results. This suggests that while fewer epochs are sufficient for high performance, additional epochs can help maintain stability and robustness in the validation accuracy. The diminishing returns beyond 12 epochs align with the convergence observed in the loss curves.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_a4b716d7e472413598bf36fc151be539_proc_3099456/SPR_BENCH_hwa_curves.png"}], [{"analysis": "The loss curves for a learning rate of 0.0003 indicate steady convergence. Both training and validation losses decrease consistently over 6 epochs, with no signs of overfitting. The validation loss closely follows the training loss, suggesting good generalization.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_loss_curves_lr0.0003.png"}, {"analysis": "The loss curves for a learning rate of 0.001 show faster convergence compared to 0.0003. Both training and validation losses decrease sharply and plateau by the 4th epoch. There is no overfitting observed, as the validation loss remains aligned with the training loss.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_loss_curves_lr0.001.png"}, {"analysis": "The loss curves for a learning rate of 0.003 indicate very rapid convergence, with both training and validation losses reaching near-zero by the 3rd epoch. While this suggests the model learns effectively, the lack of further validation loss improvement beyond the 3rd epoch might indicate potential overfitting or saturation.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_loss_curves_lr0.003.png"}, {"analysis": "The weighted accuracy metrics (SWA, CWA, HWA) for a learning rate of 0.0003 show consistent improvement over the epochs, reaching values close to 1.0 by the 6th epoch. This indicates strong performance and generalization across all weighted accuracy metrics.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_metric_curves_lr0.0003.png"}, {"analysis": "The weighted accuracy metrics for a learning rate of 0.001 demonstrate even faster improvement compared to 0.0003, achieving near-perfect accuracy by the 4th epoch. The alignment of SWA, CWA, and HWA further confirms robust model performance.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_metric_curves_lr0.001.png"}, {"analysis": "The weighted accuracy metrics for a learning rate of 0.003 show rapid improvement, reaching near-perfect values by the 3rd epoch. While the performance is excellent, the lack of improvement after the 3rd epoch might suggest a potential risk of overfitting or saturation.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_metric_curves_lr0.003.png"}, {"analysis": "The HWA comparison across learning rates illustrates that all three learning rates (0.0003, 0.001, and 0.003) achieve similar peak HWA values close to 1.0. However, the higher learning rates (0.001 and 0.003) converge faster, with 0.003 reaching its peak by the 3rd epoch.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_HWA_comparison.png"}, {"analysis": "The bar chart comparing the best HWA per learning rate shows that all three learning rates achieve the same maximum HWA of 1.0. This suggests that while the learning rate influences the speed of convergence, the final performance is similar across the tested rates.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3672c0043ce94320857b974d017aa64d_proc_3099457/SPR_BENCH_best_HWA_bar.png"}], [{"analysis": "This plot shows the training and validation loss for different batch sizes (64, 128, 256, 512) across epochs. Smaller batch sizes (e.g., 64 and 128) exhibit faster convergence in validation loss during the early epochs, suggesting that they allow the model to learn more effectively initially. However, all batch sizes reach a similar loss level by the end of training, indicating that the choice of batch size has little impact on the final performance in terms of cross-entropy loss. Larger batch sizes (e.g., 512) show slower initial convergence, which may be due to reduced gradient updates per epoch.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_772afb88db524e34a011470642292815_proc_3099458/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot demonstrates the validation harmonic weighted accuracy (HWA) for different batch sizes over epochs. Smaller batch sizes (64 and 128) achieve higher HWA earlier in training, indicating that they facilitate faster learning. However, by the final epochs, all batch sizes converge to similar levels of HWA, with minor differences. Batch size 64 appears to consistently achieve slightly better accuracy across epochs, suggesting it might be the optimal choice for maximizing HWA.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_772afb88db524e34a011470642292815_proc_3099458/SPR_BENCH_hwa_curves.png"}, {"analysis": "This plot summarizes the final harmonic weighted accuracy (HWA) achieved for each batch size at the last epoch. All batch sizes (64, 128, 256, 512) achieve nearly identical final HWA values, indicating that the batch size does not significantly impact the final performance of the model in terms of HWA. This suggests that while smaller batch sizes may improve early training dynamics, the final accuracy is robust to batch size variations.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_772afb88db524e34a011470642292815_proc_3099458/SPR_BENCH_final_hwa_bar.png"}], [{"analysis": "The plot shows the training and validation loss for different dropout rates (p=0.0, 0.2, 0.3, 0.5) over six epochs. Lower dropout rates (p=0.0 and p=0.2) consistently result in lower validation losses, indicating better generalization. Higher dropout rates (p=0.3 and p=0.5) show slower convergence and higher validation losses, suggesting reduced model capacity and potential underfitting. The training losses for all dropout rates decrease steadily, but the gap between training and validation loss widens for higher dropout rates, further confirming underfitting at these settings.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6ba65a5270a14d6a8fc7f6cdef4f65fa_proc_3099459/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot illustrates the harmonic weighted accuracy (HWA) across epochs for different dropout rates. The dropout rate of p=0.0 achieves the highest HWA consistently, followed by p=0.2 and p=0.3, while p=0.5 lags behind. The results suggest that lower dropout rates (p=0.0 and p=0.2) allow the model to better capture the patterns in the data, resulting in higher accuracy. The slower improvement and lower final accuracy for p=0.5 indicate that excessive regularization hampers the model's ability to learn effectively.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6ba65a5270a14d6a8fc7f6cdef4f65fa_proc_3099459/SPR_BENCH_hwa_curves.png"}, {"analysis": "This bar chart summarizes the final harmonic weighted accuracy (HWA) achieved at the end of training for each dropout rate. The dropout rate of p=0.0 achieves perfect accuracy (1.000), while the accuracy decreases slightly as the dropout rate increases (p=0.2: 0.998, p=0.3: 0.996, p=0.5: 0.992). This confirms that higher dropout rates introduce excessive regularization, which slightly reduces the model's performance.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_6ba65a5270a14d6a8fc7f6cdef4f65fa_proc_3099459/SPR_BENCH_final_hwa.png"}], [{"analysis": "The plot shows the training and validation loss curves for different hidden sizes (64, 128, 256, 512). As the hidden size increases, the training loss decreases more rapidly and stabilizes at a lower value, indicating better model capacity to fit the data. However, the validation loss for all hidden sizes follows a similar trend and converges to comparable levels, suggesting that increasing the hidden size does not lead to overfitting within the tested range. This behavior indicates that the model benefits from larger hidden sizes in terms of training efficiency but does not necessarily overfit the validation data.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ed93b5240f074db1b3b8551e7df1174c_proc_3099457/SPR_BENCH_loss_curves_hidden_sizes.png"}, {"analysis": "This plot shows the harmonic weighted accuracy (HWA) across epochs for different hidden sizes. Models with larger hidden sizes (128, 256, 512) achieve higher accuracy faster, reflecting their ability to learn more effectively from the data. However, the differences in final accuracy at epoch 6 are minimal, indicating that while larger hidden sizes accelerate convergence, they do not significantly enhance the final performance. Hidden size 256 appears to provide a good balance between convergence speed and final accuracy.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ed93b5240f074db1b3b8551e7df1174c_proc_3099457/SPR_BENCH_hwa_curves_hidden_sizes.png"}, {"analysis": "This bar chart compares the final harmonic weighted accuracy (HWA) across different hidden sizes. All hidden sizes achieve nearly identical performance, with only marginal differences observed. This result suggests that increasing the hidden size beyond 128 does not yield significant performance benefits for the SPR task, and smaller hidden sizes may be preferred for computational efficiency.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ed93b5240f074db1b3b8551e7df1174c_proc_3099457/SPR_BENCH_final_hwa_bar.png"}], [{"analysis": "This plot compares training and validation cross-entropy loss for different embedding dimensions (32, 64, 128, 256). Across all configurations, the training loss decreases steadily and converges by epoch 6, indicating effective learning. Validation loss follows a similar trend, suggesting good generalization. Larger embedding dimensions (128 and 256) show slightly faster convergence and lower final loss values, which may indicate their better capacity for capturing the symbolic sequence patterns.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_4b26d29dde0f4edc80abb2e04402e1f1_proc_3099458/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot shows the progression of validation harmonic-weighted accuracy (HWA) for different embedding dimensions across epochs. All configurations demonstrate rapid improvement in the initial epochs, with larger embedding dimensions (128 and 256) achieving near-perfect accuracy by epoch 3. This suggests that larger embeddings are more effective in learning the task-specific features, leading to better performance.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_4b26d29dde0f4edc80abb2e04402e1f1_proc_3099458/SPR_BENCH_HWA_over_epochs.png"}, {"analysis": "This plot summarizes the final harmonic-weighted accuracy (HWA) achieved by each embedding dimension. All configurations reach near-perfect accuracy, with minimal differences among them. This indicates that while larger embedding dimensions may converge faster, all tested dimensions are capable of achieving excellent performance on this task.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_4b26d29dde0f4edc80abb2e04402e1f1_proc_3099458/SPR_BENCH_final_HWA_bar.png"}], [{"analysis": "The training and validation loss plots show that smaller weight decay values (0.0, 1e-5, 0.0001) lead to faster convergence and lower loss values, indicating better generalization and training stability. Higher weight decay values (0.001, 0.01) result in slower convergence and higher loss, suggesting over-regularization.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7c7c347607d8447c9cbb0e222147edc9_proc_3099456/SPR_BENCH_loss_curves.png"}, {"analysis": "The harmonic weighted accuracy (HWA) plot shows that smaller weight decay values (0.0, 1e-5, 0.0001) achieve near-perfect accuracy by epoch 3, while larger weight decay values (0.001, 0.01) lag in performance, with 0.01 showing the slowest improvement.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7c7c347607d8447c9cbb0e222147edc9_proc_3099456/SPR_BENCH_hwa_curves.png"}, {"analysis": "The final HWA bar plot indicates that the smallest weight decay values (0.0, 1e-5, 0.0001) yield the highest final accuracy, with diminishing performance as weight decay increases. This confirms that minimal weight decay is optimal for this task.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7c7c347607d8447c9cbb0e222147edc9_proc_3099456/SPR_BENCH_final_hwa_vs_wd.png"}], [{"analysis": "The first plot shows the training and validation loss trends across epochs for different gradient clipping thresholds. All configurations converge quickly, with a significant drop in loss after the first epoch. The curves for training and validation loss are closely aligned, indicating no overfitting. The gradient clipping value does not appear to have a significant impact on the convergence behavior or final loss values, as all configurations achieve near-zero loss by the final epoch.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7a2f6173297a4e109edf67fa2be97a96_proc_3099459/spr_bench_loss_curves.png"}, {"analysis": "The second plot illustrates the validation harmonic weighted accuracy (HWA) across epochs for different gradient clipping thresholds. All configurations show a consistent improvement in HWA, with rapid gains in the first two epochs and slower improvements afterward. Gradient clipping values of 0 and 0.5 achieve slightly faster convergence to peak accuracy, but the differences are minimal. By the final epoch, all configurations reach nearly identical HWA values, suggesting that gradient clipping has a limited impact on overall accuracy.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7a2f6173297a4e109edf67fa2be97a96_proc_3099459/spr_bench_hwa_curves.png"}, {"analysis": "The third plot summarizes the final harmonic weighted accuracy (HWA) achieved by each gradient clipping threshold. The bars indicate that all configurations achieve comparable final HWA values, with minor differences that are not statistically significant. This reinforces the observation that gradient clipping does not substantially influence the final performance of the model in this experiment.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_7a2f6173297a4e109edf67fa2be97a96_proc_3099459/spr_bench_final_hwa_bar.png"}], [{"analysis": "The plot shows the training and validation loss curves for different hidden sizes (hs=64, 128, 256, 512). All configurations demonstrate rapid convergence within the first two epochs, with the validation loss closely following the training loss, indicating minimal overfitting. Larger hidden sizes (256, 512) achieve slightly lower final validation losses compared to smaller hidden sizes, suggesting better representation capacity and generalization for these configurations.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_930038a9ae014668b759b437fdca3e7c_proc_3099458/SPR_BENCH_loss_curves_hidden_sizes.png"}, {"analysis": "This plot illustrates the Harmonic Weighted Accuracy (HWA) across epochs for different hidden sizes. All configurations show an increasing trend in HWA, converging to near-perfect accuracy by the 5th or 6th epoch. Larger hidden sizes (256, 512) achieve higher HWA earlier in training, indicating faster learning and better performance. However, the differences in final accuracy across hidden sizes are minor, suggesting diminishing returns for increasing hidden size beyond a certain point.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_930038a9ae014668b759b437fdca3e7c_proc_3099458/SPR_BENCH_hwa_curves_hidden_sizes.png"}, {"analysis": "The bar chart compares the final Harmonic Weighted Accuracy (HWA) at the last epoch for different hidden sizes. All hidden sizes achieve near-perfect HWA, with minimal variation between them. This indicates that while larger hidden sizes may lead to faster convergence, the final performance is largely consistent across all configurations, suggesting that the model's capacity is sufficient even at smaller hidden sizes.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_930038a9ae014668b759b437fdca3e7c_proc_3099458/SPR_BENCH_final_hwa_bar.png"}], [{"analysis": "This plot shows the training and validation loss trends for various hidden sizes (hs=64, 128, 256, 512). All configurations demonstrate rapid convergence, with losses decreasing significantly within the first two epochs and stabilizing by epoch 6. Larger hidden sizes (hs=256 and hs=512) achieve slightly lower validation loss compared to smaller sizes, indicating better generalization. However, the differences between hidden sizes are relatively minor after convergence, suggesting diminishing returns for larger hidden sizes in terms of loss reduction.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f20704230f6d40cebfde3e31579e8f5e_proc_3099456/SPR_BENCH_loss_curves_hidden_sizes.png"}, {"analysis": "This plot illustrates the harmonic weighted accuracy (HWA) trends across epochs for different hidden sizes. All configurations achieve high HWA values, with larger hidden sizes (hs=256 and hs=512) consistently performing slightly better than smaller sizes. Notably, hs=128 and hs=256 show an early peak in HWA, but hs=512 maintains a more stable improvement over epochs. This suggests that larger hidden sizes may contribute to more consistent performance improvements during training.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f20704230f6d40cebfde3e31579e8f5e_proc_3099456/SPR_BENCH_hwa_curves_hidden_sizes.png"}, {"analysis": "This plot compares the final harmonic weighted accuracy (HWA) achieved at the last epoch for different hidden sizes. All configurations achieve near-perfect HWA, with only marginal differences between them. Hidden sizes hs=256 and hs=512 slightly outperform smaller sizes, but the overall performance is very close across all configurations, indicating that the model is robust to variations in hidden size when evaluated at the final epoch.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f20704230f6d40cebfde3e31579e8f5e_proc_3099456/SPR_BENCH_final_hwa_bar.png"}], [{"analysis": "This plot illustrates the training and validation loss trends for different hidden sizes (64, 128, 256, 512) across 6 epochs. All configurations show a rapid reduction in both training and validation loss within the first two epochs, indicating effective learning during this initial phase. The losses stabilize by epoch 4, suggesting convergence. Larger hidden sizes (e.g., 512 and 256) achieve slightly lower validation losses compared to smaller hidden sizes (e.g., 64), implying better generalization capability. However, the differences are marginal, indicating that increasing hidden size beyond a certain point may yield diminishing returns.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ca25c2f21e3f4767a4586b917ec76994_proc_3099457/SPR_BENCH_loss_curves_hidden_sizes.png"}, {"analysis": "This plot presents the Harmonic Weighted Accuracy (HWA) as a function of epochs for different hidden sizes. The HWA improves consistently across all configurations, with larger hidden sizes (256 and 512) achieving marginally higher accuracy. The accuracy trends for hidden sizes 256 and 512 are nearly identical, suggesting that further increasing the hidden size beyond 256 may not significantly enhance performance. The smaller hidden sizes (64 and 128) exhibit slightly slower convergence but eventually reach competitive HWA values.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ca25c2f21e3f4767a4586b917ec76994_proc_3099457/SPR_BENCH_hwa_curves_hidden_sizes.png"}, {"analysis": "This bar chart summarizes the final Harmonic Weighted Accuracy (HWA) at the end of training for different hidden sizes. All configurations achieve nearly identical final HWA values, with only minor differences. This indicates that while larger hidden sizes may improve convergence speed and slightly enhance intermediate performance, the final performance is not significantly affected by the choice of hidden size within the tested range.", "plot_path": "experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ca25c2f21e3f4767a4586b917ec76994_proc_3099457/SPR_BENCH_final_hwa_bar.png"}], []], "vlm_feedback_summary": ["The plots indicate effective training with rapid convergence and high\nperformance on the validation set. The model generalizes well, and increasing\nepochs beyond 12 yields diminishing returns. Both loss and accuracy metrics\nsuggest the model is well-optimized for the task.", "The provided plots demonstrate the impact of different learning rates on\ntraining dynamics and performance metrics. All learning rates lead to excellent\nfinal performance, with faster convergence observed for higher rates. There is\nno significant overfitting, but the rapid convergence of the highest learning\nrate (0.003) may warrant further investigation to ensure robustness.", "The analysis highlights that smaller batch sizes (64 and 128) lead to faster\nconvergence in training and validation loss, as well as higher harmonic weighted\naccuracy (HWA) early in training. However, all batch sizes converge to similar\nfinal performance levels in terms of loss and HWA. This suggests that while\nsmaller batch sizes may be advantageous for faster initial learning, the final\nmodel performance is largely unaffected by the choice of batch size.", "The provided plots effectively illustrate the impact of different dropout rates\non training loss, validation loss, and harmonic weighted accuracy (HWA). Lower\ndropout rates (p=0.0 and p=0.2) consistently outperform higher dropout rates\n(p=0.3 and p=0.5), demonstrating better generalization and accuracy. Excessive\ndropout leads to underfitting, as evidenced by slower convergence, higher\nvalidation losses, and reduced HWA.", "The plots effectively demonstrate the impact of hidden size on training dynamics\nand final performance. Larger hidden sizes accelerate convergence but do not\nsignificantly improve final accuracy, suggesting diminishing returns for\nincreasing hidden size beyond a certain point. The results highlight the\nimportance of balancing model complexity with computational efficiency.", "The plots reveal that larger embedding dimensions (128 and 256) lead to faster\nconvergence and slightly better performance in terms of loss reduction and HWA.\nHowever, all configurations ultimately achieve near-perfect accuracy, suggesting\nthat the model is robust across different embedding sizes.", "The results demonstrate that smaller weight decay values are more effective for\nthe SPR task, leading to faster convergence, lower loss, and higher accuracy.\nLarger weight decay values cause over-regularization, negatively impacting\nperformance.", "The plots indicate that gradient clipping thresholds have minimal impact on both\nloss convergence and final harmonic weighted accuracy. All configurations\nperform similarly, suggesting that the choice of gradient clipping value is not\ncritical for this task.", "The received plots provide insightful comparisons of training dynamics,\nvalidation performance, and final metrics across different hidden sizes. Larger\nhidden sizes demonstrate faster convergence and slightly better validation loss,\nbut the final accuracy is consistent across all configurations, indicating\ndiminishing returns for increasing hidden size.", "The experimental results indicate that the model performs well across all tested\nhidden sizes, with larger hidden sizes (hs=256 and hs=512) showing slight\nadvantages in terms of validation loss and harmonic weighted accuracy (HWA).\nHowever, the differences are minimal, suggesting that smaller hidden sizes can\nalso achieve competitive performance while potentially reducing computational\ncosts. The results highlight the robustness of the proposed method and its\nability to generalize effectively across different configurations.", "The plots provide clear insights into the impact of hidden size on training\ndynamics and final performance. Larger hidden sizes improve convergence speed\nand slightly enhance intermediate performance, but the final accuracy\ndifferences are negligible. This suggests that hidden size tuning should balance\ncomputational cost and performance gains.", "[]"], "exec_time": [98.74943542480469, 14.28923749923706, 20.54981803894043, 63.893603801727295, 68.76684832572937, 16.4753098487854, 21.106078147888184, 78.64371824264526, 70.7955470085144, 18.88352632522583, 19.02448010444641, null], "exec_time_feedback": ["", "", "", "Implementation works but runs too quickly (0.24 minutes).We have up to 60\nminutes available for each experiment.Make sure to scale up the experiment by\nincreasing the number of epochs, using a larger model, or working with bigger\ndatasets.Given that the current execution time is {exec_time_minutes:.2f}\nminutes, think about how changing the number of epochs to run, or using a larger\nmodel, or working with bigger datasets to runwill affect the execution time, and\nmake sure to scale up the experiment accordingly.", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load experiment data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# Helper: safely get nested dict values\ndef get_nested(dic, keys, default=None):\n    for k in keys:\n        dic = dic.get(k, {})\n    return dic or default\n\n\nspr_runs = get_nested(experiment_data, [\"num_epochs\", \"SPR_BENCH\"], {})\n\n# --------- Plot 1: Loss curves ----------\ntry:\n    plt.figure()\n    for budget, run in spr_runs.items():\n        train = np.array(run[\"losses\"][\"train\"])  # (epoch, loss)\n        val = np.array(run[\"losses\"][\"val\"])\n        if train.size:\n            plt.plot(train[:, 0], train[:, 1], label=f\"{budget}ep-train\")\n        if val.size:\n            plt.plot(val[:, 0], val[:, 1], \"--\", label=f\"{budget}ep-val\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# --------- Plot 2: Harmonic Weighted Accuracy ----------\ntry:\n    plt.figure()\n    for budget, run in spr_runs.items():\n        met = np.array(run[\"metrics\"][\"val\"])  # (epoch, swa, cwa, hwa)\n        if met.size:\n            plt.plot(met[:, 0], met[:, 3], label=f\"{budget}ep\")\n    plt.title(\"SPR_BENCH: Validation Harmonic Weighted Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"HWA\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA plot: {e}\")\n    plt.close()\n\n# --------- Print best HWA for each budget ----------\nfor budget, run in spr_runs.items():\n    met = np.array(run[\"metrics\"][\"val\"])\n    best_hwa = float(met[:, 3].max()) if met.size else float(\"nan\")\n    print(f\"Best HWA for {budget} epochs: {best_hwa:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is None:\n    exit()\n\nlr_logs = experiment_data.get(\"learning_rate\", {})\nlrs = sorted(lr_logs.keys(), key=float)\n\nbest_hwa = {}\n# -------- plot 1: loss curves per lr -----------\nfor lr in lrs:\n    log = lr_logs[lr]\n    try:\n        epochs_tr, tr_loss = zip(*log[\"losses\"][\"train\"])\n        epochs_val, val_loss = zip(*log[\"losses\"][\"val\"])\n        plt.figure()\n        plt.plot(epochs_tr, tr_loss, label=\"Train Loss\")\n        plt.plot(epochs_val, val_loss, label=\"Validation Loss\")\n        plt.title(f\"SPR_BENCH Loss Curves (lr={lr})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        fname = f\"SPR_BENCH_loss_curves_lr{lr}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for lr={lr}: {e}\")\n        plt.close()\n\n# -------- plot 2: metric curves per lr ---------\nfor lr in lrs:\n    log = lr_logs[lr]\n    try:\n        ep, swa, cwa, hwa = zip(*log[\"metrics\"][\"val\"])\n        best_hwa[lr] = max(hwa)\n        plt.figure()\n        plt.plot(ep, swa, label=\"SWA\")\n        plt.plot(ep, cwa, label=\"CWA\")\n        plt.plot(ep, hwa, label=\"HWA\")\n        plt.title(f\"SPR_BENCH Weighted Accuracies (lr={lr})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        fname = f\"SPR_BENCH_metric_curves_lr{lr}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric plot for lr={lr}: {e}\")\n        plt.close()\n\n# -------- plot 3: HWA comparison ---------------\ntry:\n    plt.figure()\n    for lr in lrs:\n        ep, _, _, hwa = zip(*lr_logs[lr][\"metrics\"][\"val\"])\n        plt.plot(ep, hwa, label=f\"lr={lr}\")\n    plt.title(\"SPR_BENCH HWA Comparison Across Learning Rates\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"HWA\")\n    plt.legend()\n    fname = \"SPR_BENCH_HWA_comparison.png\"\n    plt.savefig(os.path.join(working_dir, fname))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA comparison plot: {e}\")\n    plt.close()\n\n# -------- plot 4: Best HWA bar chart -----------\ntry:\n    plt.figure()\n    plt.bar(range(len(best_hwa)), [best_hwa[k] for k in lrs], tick_label=lrs)\n    plt.title(\"SPR_BENCH Best HWA per Learning Rate\")\n    plt.xlabel(\"Learning Rate\")\n    plt.ylabel(\"Best HWA\")\n    fname = \"SPR_BENCH_best_HWA_bar.png\"\n    plt.savefig(os.path.join(working_dir, fname))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating best HWA bar chart: {e}\")\n    plt.close()\n\n# -------- print summary ------------------------\nfor lr in lrs:\n    print(f'Best HWA for lr={lr}: {best_hwa.get(lr, \"N/A\"):.4f}')\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# prepare working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    sweep = experiment_data.get(\"batch_size\", {}).get(\"SPR_BENCH\", {})\n    batch_sizes = sorted([int(bs) for bs in sweep.keys()])\n    # containers for final metrics\n    final_hwa = {}\n\n    # ------------ 1) loss curves -------------\n    try:\n        plt.figure()\n        for bs in batch_sizes:\n            bs_str = str(bs)\n            train = sweep[bs_str][\"losses\"][\"train\"]  # [(epoch, loss), ...]\n            val = sweep[bs_str][\"losses\"][\"val\"]\n            epochs_t, losses_t = zip(*train)\n            epochs_v, losses_v = zip(*val)\n            plt.plot(epochs_t, losses_t, linestyle=\"-\", label=f\"train bs={bs}\")\n            plt.plot(epochs_v, losses_v, linestyle=\"--\", label=f\"val bs={bs}\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH: Training vs Validation Loss\\nBatch Size Sweep\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve plot: {e}\")\n        plt.close()\n\n    # ------------ 2) validation HWA curves -------------\n    try:\n        plt.figure()\n        for bs in batch_sizes:\n            bs_str = str(bs)\n            metrics = sweep[bs_str][\"metrics\"][\"val\"]  # [(epoch, swa, cwa, hwa), ...]\n            epochs, _, _, hwas = zip(*metrics)\n            plt.plot(epochs, hwas, label=f\"HWA bs={bs}\")\n            # store final epoch hwa\n            final_hwa[bs] = hwas[-1]\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Harmonic Weighted Accuracy\")\n        plt.title(\"SPR_BENCH: Validation HWA\\nBatch Size Sweep\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating HWA curve plot: {e}\")\n        plt.close()\n\n    # ------------ 3) final HWA per batch size -------------\n    try:\n        plt.figure()\n        bs_list = list(final_hwa.keys())\n        hwa_vals = [final_hwa[bs] for bs in bs_list]\n        plt.bar([str(bs) for bs in bs_list], hwa_vals, color=\"skyblue\")\n        plt.xlabel(\"Batch Size\")\n        plt.ylabel(\"Final Epoch HWA\")\n        plt.title(\"SPR_BENCH: Final Harmonic Weighted Accuracy\\nvs Batch Size\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_final_hwa_bar.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating final HWA bar plot: {e}\")\n        plt.close()\n\n    # ------------ print summary -------------\n    print(\"Final HWA by batch size:\")\n    for bs in batch_sizes:\n        print(f\"  bs={bs}: HWA={final_hwa.get(bs, 'N/A'):.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# --------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# --------- load data -------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nds_key = \"SPR_BENCH\"\nroot = experiment_data.get(\"dropout_rate\", {}).get(ds_key, {})\n\n\n# Helper to pull a series\ndef tuple_to_arrays(tuples, idx_val=1):\n    xs, ys = zip(*[(t[0], t[idx_val]) for t in tuples]) if tuples else ([], [])\n    return np.array(xs), np.array(ys)\n\n\n# 1) Loss curves ---------------------------------------------------------------\ntry:\n    plt.figure()\n    for p_key, rec in root.items():\n        xs_t, ys_t = tuple_to_arrays(rec[\"losses\"][\"train\"])\n        xs_v, ys_v = tuple_to_arrays(rec[\"losses\"][\"val\"])\n        plt.plot(xs_t, ys_t, label=f\"{p_key} Train\")\n        plt.plot(xs_v, ys_v, linestyle=\"--\", label=f\"{p_key} Val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(f\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# 2) HWA over epochs -----------------------------------------------------------\ntry:\n    plt.figure()\n    for p_key, rec in root.items():\n        xs, hwa = tuple_to_arrays(rec[\"metrics\"][\"val\"], idx_val=3)\n        plt.plot(xs, hwa, marker=\"o\", label=p_key)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: HWA vs Epoch for Different Dropouts\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curve plot: {e}\")\n    plt.close()\n\n# 3) Final-epoch HWA bar chart -------------------------------------------------\ntry:\n    plt.figure()\n    p_keys, final_hwa = [], []\n    for p_key, rec in root.items():\n        if rec[\"metrics\"][\"val\"]:\n            p_keys.append(p_key)\n            final_hwa.append(rec[\"metrics\"][\"val\"][-1][3])\n    plt.bar(p_keys, final_hwa, color=\"skyblue\")\n    plt.ylabel(\"Final-Epoch HWA\")\n    plt.title(\"SPR_BENCH: Final HWA by Dropout Setting\")\n    for i, v in enumerate(final_hwa):\n        plt.text(i, v, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_hwa.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar chart: {e}\")\n    plt.close()\n\n# ------------- summary ------------------------\nif final_hwa:\n    best_idx = int(np.argmax(final_hwa))\n    print(f\"Best dropout = {p_keys[best_idx]} with HWA={final_hwa[best_idx]:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------- load data -----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nhidden_dict = experiment_data.get(\"hidden_size\", {})\nif not hidden_dict:\n    print(\"No hidden_size data found.\")\n    exit()\n\n# -------------- collect statistics ----------\nlosses = {}  # {hs: {'train': (ep, val), 'val': (ep, val)}}\nmetrics_hwa = {}  # {hs: [(ep, hwa)]}\nfinal_hwa = {}  # {hs: hwa}\nfor hs, result in hidden_dict.items():\n    rec = result.get(\"SPR_BENCH\", {})\n    tr_loss = rec.get(\"losses\", {}).get(\"train\", [])\n    val_loss = rec.get(\"losses\", {}).get(\"val\", [])\n    hwa = [(e, h) for e, _, _, h in rec.get(\"metrics\", {}).get(\"val\", [])]\n    if tr_loss and val_loss and hwa:\n        losses[hs] = {\"train\": tr_loss, \"val\": val_loss}\n        metrics_hwa[hs] = hwa\n        final_hwa[hs] = hwa[-1][1]\n\n# ---------------- plot losses ---------------\ntry:\n    plt.figure()\n    for hs, lv in sorted(losses.items()):\n        ep_t, val_t = zip(*lv[\"train\"])\n        ep_v, val_v = zip(*lv[\"val\"])\n        plt.plot(ep_t, val_t, label=f\"train hs={hs}\")\n        plt.plot(ep_v, val_v, linestyle=\"--\", label=f\"val hs={hs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss (Hidden-Size Sweep)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves_hidden_sizes.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---------------- plot HWA curves -----------\ntry:\n    plt.figure()\n    for hs, arr in sorted(metrics_hwa.items()):\n        ep, hwa = zip(*arr)\n        plt.plot(ep, hwa, label=f\"hs={hs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: HWA Curves Across Hidden Sizes\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves_hidden_sizes.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curves: {e}\")\n    plt.close()\n\n# --------------- bar chart final HWA -------\ntry:\n    plt.figure()\n    h_sizes, h_vals = zip(*sorted(final_hwa.items()))\n    plt.bar([str(h) for h in h_sizes], h_vals, color=\"skyblue\")\n    plt.xlabel(\"Hidden Size\")\n    plt.ylabel(\"Final-Epoch HWA\")\n    plt.title(\"SPR_BENCH: Final Harmonic Weighted Accuracy by Hidden Size\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_hwa_bar.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar chart: {e}\")\n    plt.close()\n\n# --------------- print summary --------------\nprint(\"Final-epoch HWA per hidden size:\")\nfor hs, hwa in sorted(final_hwa.items()):\n    print(f\"  hidden={hs:>3}: HWA={hwa:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Load saved experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ntags = sorted(\n    experiment_data.keys(), key=lambda x: int(x.split(\"_\")[-1])\n)  # emb_dim_32 -> 32\n\n# Figure 1: Train vs Val loss across emb dims\ntry:\n    plt.figure()\n    for tag in tags:\n        train = experiment_data[tag][\"SPR_BENCH\"][\"losses\"][\"train\"]\n        val = experiment_data[tag][\"SPR_BENCH\"][\"losses\"][\"val\"]\n        epochs_t, loss_t = zip(*train)\n        epochs_v, loss_v = zip(*val)\n        plt.plot(epochs_t, loss_t, \"--\", label=f\"{tag}-train\")\n        plt.plot(epochs_v, loss_v, \"-\", label=f\"{tag}-val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# Figure 2: Validation metrics (HWA) over epochs\ntry:\n    plt.figure()\n    for tag in tags:\n        metrics = experiment_data[tag][\"SPR_BENCH\"][\"metrics\"][\"val\"]\n        epochs, swa, cwa, hwa = zip(*metrics)\n        plt.plot(epochs, hwa, label=f\"{tag}-HWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: Validation HWA across Epochs\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_HWA_over_epochs.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA over epochs plot: {e}\")\n    plt.close()\n\n# Figure 3: Final-epoch HWA bar chart\ntry:\n    plt.figure()\n    hw_vals = []\n    for tag in tags:\n        metrics = experiment_data[tag][\"SPR_BENCH\"][\"metrics\"][\"val\"]\n        hw = metrics[-1][-1]  # last epoch HWA\n        hw_vals.append(hw)\n    plt.bar(tags, hw_vals)\n    plt.ylabel(\"Final HWA\")\n    plt.title(\"SPR_BENCH: Final Harmonic Weighted Accuracy by Embedding Dimension\")\n    plt.xticks(rotation=45)\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_HWA_bar.png\")\n    plt.savefig(fname, bbox_inches=\"tight\")\n    plt.close()\n    # Print summary\n    print(\"Final HWA per embedding dimension:\")\n    for tag, val in zip(tags, hw_vals):\n        print(f\"{tag}: {val:.4f}\")\nexcept Exception as e:\n    print(f\"Error creating final HWA bar plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------- load experiment data -----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nwd_data = experiment_data.get(\"weight_decay\", {}).get(\"SPR_BENCH\", {})\nweight_decays = sorted(float(k.split(\"_\")[1]) for k in wd_data)\n\nfinal_hwa = {}  # store for summary print\n\n# --------------- 1) loss curves -------------------------\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n    for run_key, run in wd_data.items():\n        epochs, tr_loss = zip(*run[\"losses\"][\"train\"])\n        _, va_loss = zip(*run[\"losses\"][\"val\"])\n        label = run_key.split(\"_\")[1]\n        axes[0].plot(epochs, tr_loss, label=f\"wd={label}\")\n        axes[1].plot(epochs, va_loss, label=f\"wd={label}\")\n    axes[0].set_title(\"Train Loss\")\n    axes[1].set_title(\"Validation Loss\")\n    for ax in axes:\n        ax.set_xlabel(\"Epoch\")\n        ax.set_ylabel(\"Loss\")\n        ax.legend(fontsize=8)\n    fig.suptitle(\"SPR_BENCH Loss Curves (Left: Train, Right: Val)\")\n    plt.tight_layout()\n    path = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# --------------- 2) HWA curves --------------------------\ntry:\n    plt.figure(figsize=(5, 4))\n    for run_key, run in wd_data.items():\n        epochs, swa, cwa, hwa = zip(*run[\"metrics\"][\"val\"])\n        label = run_key.split(\"_\")[1]\n        plt.plot(epochs, hwa, marker=\"o\", label=f\"wd={label}\")\n        final_hwa[label] = hwa[-1]\n    plt.title(\"SPR_BENCH Harmonic Weighted Accuracy over Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"HWA\")\n    plt.legend(fontsize=8)\n    plt.tight_layout()\n    path = os.path.join(working_dir, \"SPR_BENCH_hwa_curves.png\")\n    plt.savefig(path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curves: {e}\")\n    plt.close()\n\n# --------------- 3) final HWA vs weight_decay -----------\ntry:\n    labels = sorted(final_hwa.keys(), key=lambda x: float(x))\n    values = [final_hwa[k] for k in labels]\n    plt.figure(figsize=(6, 4))\n    plt.bar(labels, values, color=\"skyblue\")\n    plt.title(\"SPR_BENCH Final Epoch HWA vs Weight Decay\")\n    plt.xlabel(\"Weight Decay\")\n    plt.ylabel(\"Final HWA\")\n    plt.tight_layout()\n    path = os.path.join(working_dir, \"SPR_BENCH_final_hwa_vs_wd.png\")\n    plt.savefig(path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar chart: {e}\")\n    plt.close()\n\n# ------------------- summary print ----------------------\nif final_hwa:\n    print(\"Final epoch HWA per weight decay:\")\n    for wd in labels:\n        print(f\"  weight_decay={wd}: HWA={final_hwa[wd]:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load data ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nclip_dict = experiment_data.get(\"gradient_clipping_max_norm\", {})\n\n\n# helper to pull curves\ndef curve(vals, idx):\n    return [v[idx] for v in vals]  # idx: 1 for loss, 1/2/3 for metrics\n\n\ncolors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"]\nclip_keys = sorted(clip_dict.keys(), key=float)[:5]  # at most 5\n\n# ---------- 1) loss curves ----------\ntry:\n    plt.figure(figsize=(6, 4))\n    for c, key in zip(colors, clip_keys):\n        epochs, tr_loss = zip(*clip_dict[key][\"losses\"][\"train\"])\n        _, val_loss = zip(*clip_dict[key][\"losses\"][\"val\"])\n        plt.plot(epochs, tr_loss, c=c, ls=\"-\", label=f\"train clip={key}\")\n        plt.plot(epochs, val_loss, c=c, ls=\"--\", label=f\"val clip={key}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\n        \"SPR_BENCH \u2013 Loss vs. Epochs\\nLeft: Training (solid), Right: Validation (dashed)\"\n    )\n    plt.legend(fontsize=7)\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"spr_bench_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---------- 2) validation HWA curves ----------\ntry:\n    plt.figure(figsize=(6, 4))\n    for c, key in zip(colors, clip_keys):\n        epochs = [v[0] for v in clip_dict[key][\"metrics\"][\"val\"]]\n        hwa = [v[3] for v in clip_dict[key][\"metrics\"][\"val\"]]\n        plt.plot(epochs, hwa, c=c, label=f\"clip={key}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Acc\")\n    plt.title(\"SPR_BENCH \u2013 Validation HWA Across Epochs\")\n    plt.legend(fontsize=7)\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"spr_bench_hwa_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curves: {e}\")\n    plt.close()\n\n# ---------- 3) final-epoch HWA bar chart ----------\nfinal_hwa = []\nfor key in clip_keys:\n    final_hwa.append(clip_dict[key][\"metrics\"][\"val\"][-1][3])\n\ntry:\n    plt.figure(figsize=(5, 3))\n    plt.bar(clip_keys, final_hwa, color=colors[: len(clip_keys)])\n    plt.xlabel(\"Gradient Clip Max-Norm\")\n    plt.ylabel(\"Final Epoch HWA\")\n    plt.title(\"SPR_BENCH \u2013 Final Harmonic Weighted Accuracy by Clip Value\")\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"spr_bench_final_hwa_bar.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar: {e}\")\n    plt.close()\n\n# ---------- print summary ----------\nprint(\"Final-epoch HWA:\")\nfor k, h in zip(clip_keys, final_hwa):\n    print(f\"  clip={k:>4}: HWA={h:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------- load data -----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nhidden_dict = experiment_data.get(\"hidden_size\", {})\nif not hidden_dict:\n    print(\"No hidden_size data found.\")\n    exit()\n\n# -------------- collect statistics ----------\nlosses = {}  # {hs: {'train': (ep, val), 'val': (ep, val)}}\nmetrics_hwa = {}  # {hs: [(ep, hwa)]}\nfinal_hwa = {}  # {hs: hwa}\nfor hs, result in hidden_dict.items():\n    rec = result.get(\"SPR_BENCH\", {})\n    tr_loss = rec.get(\"losses\", {}).get(\"train\", [])\n    val_loss = rec.get(\"losses\", {}).get(\"val\", [])\n    hwa = [(e, h) for e, _, _, h in rec.get(\"metrics\", {}).get(\"val\", [])]\n    if tr_loss and val_loss and hwa:\n        losses[hs] = {\"train\": tr_loss, \"val\": val_loss}\n        metrics_hwa[hs] = hwa\n        final_hwa[hs] = hwa[-1][1]\n\n# ---------------- plot losses ---------------\ntry:\n    plt.figure()\n    for hs, lv in sorted(losses.items()):\n        ep_t, val_t = zip(*lv[\"train\"])\n        ep_v, val_v = zip(*lv[\"val\"])\n        plt.plot(ep_t, val_t, label=f\"train hs={hs}\")\n        plt.plot(ep_v, val_v, linestyle=\"--\", label=f\"val hs={hs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss (Hidden-Size Sweep)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves_hidden_sizes.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---------------- plot HWA curves -----------\ntry:\n    plt.figure()\n    for hs, arr in sorted(metrics_hwa.items()):\n        ep, hwa = zip(*arr)\n        plt.plot(ep, hwa, label=f\"hs={hs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: HWA Curves Across Hidden Sizes\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves_hidden_sizes.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curves: {e}\")\n    plt.close()\n\n# --------------- bar chart final HWA -------\ntry:\n    plt.figure()\n    h_sizes, h_vals = zip(*sorted(final_hwa.items()))\n    plt.bar([str(h) for h in h_sizes], h_vals, color=\"skyblue\")\n    plt.xlabel(\"Hidden Size\")\n    plt.ylabel(\"Final-Epoch HWA\")\n    plt.title(\"SPR_BENCH: Final Harmonic Weighted Accuracy by Hidden Size\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_hwa_bar.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar chart: {e}\")\n    plt.close()\n\n# --------------- print summary --------------\nprint(\"Final-epoch HWA per hidden size:\")\nfor hs, hwa in sorted(final_hwa.items()):\n    print(f\"  hidden={hs:>3}: HWA={hwa:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------- load data -----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nhidden_dict = experiment_data.get(\"hidden_size\", {})\nif not hidden_dict:\n    print(\"No hidden_size data found.\")\n    exit()\n\n# -------------- collect statistics ----------\nlosses = {}  # {hs: {'train': (ep, val), 'val': (ep, val)}}\nmetrics_hwa = {}  # {hs: [(ep, hwa)]}\nfinal_hwa = {}  # {hs: hwa}\nfor hs, result in hidden_dict.items():\n    rec = result.get(\"SPR_BENCH\", {})\n    tr_loss = rec.get(\"losses\", {}).get(\"train\", [])\n    val_loss = rec.get(\"losses\", {}).get(\"val\", [])\n    hwa = [(e, h) for e, _, _, h in rec.get(\"metrics\", {}).get(\"val\", [])]\n    if tr_loss and val_loss and hwa:\n        losses[hs] = {\"train\": tr_loss, \"val\": val_loss}\n        metrics_hwa[hs] = hwa\n        final_hwa[hs] = hwa[-1][1]\n\n# ---------------- plot losses ---------------\ntry:\n    plt.figure()\n    for hs, lv in sorted(losses.items()):\n        ep_t, val_t = zip(*lv[\"train\"])\n        ep_v, val_v = zip(*lv[\"val\"])\n        plt.plot(ep_t, val_t, label=f\"train hs={hs}\")\n        plt.plot(ep_v, val_v, linestyle=\"--\", label=f\"val hs={hs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss (Hidden-Size Sweep)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves_hidden_sizes.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---------------- plot HWA curves -----------\ntry:\n    plt.figure()\n    for hs, arr in sorted(metrics_hwa.items()):\n        ep, hwa = zip(*arr)\n        plt.plot(ep, hwa, label=f\"hs={hs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: HWA Curves Across Hidden Sizes\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves_hidden_sizes.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curves: {e}\")\n    plt.close()\n\n# --------------- bar chart final HWA -------\ntry:\n    plt.figure()\n    h_sizes, h_vals = zip(*sorted(final_hwa.items()))\n    plt.bar([str(h) for h in h_sizes], h_vals, color=\"skyblue\")\n    plt.xlabel(\"Hidden Size\")\n    plt.ylabel(\"Final-Epoch HWA\")\n    plt.title(\"SPR_BENCH: Final Harmonic Weighted Accuracy by Hidden Size\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_hwa_bar.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar chart: {e}\")\n    plt.close()\n\n# --------------- print summary --------------\nprint(\"Final-epoch HWA per hidden size:\")\nfor hs, hwa in sorted(final_hwa.items()):\n    print(f\"  hidden={hs:>3}: HWA={hwa:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------- load data -----------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nhidden_dict = experiment_data.get(\"hidden_size\", {})\nif not hidden_dict:\n    print(\"No hidden_size data found.\")\n    exit()\n\n# -------------- collect statistics ----------\nlosses = {}  # {hs: {'train': (ep, val), 'val': (ep, val)}}\nmetrics_hwa = {}  # {hs: [(ep, hwa)]}\nfinal_hwa = {}  # {hs: hwa}\nfor hs, result in hidden_dict.items():\n    rec = result.get(\"SPR_BENCH\", {})\n    tr_loss = rec.get(\"losses\", {}).get(\"train\", [])\n    val_loss = rec.get(\"losses\", {}).get(\"val\", [])\n    hwa = [(e, h) for e, _, _, h in rec.get(\"metrics\", {}).get(\"val\", [])]\n    if tr_loss and val_loss and hwa:\n        losses[hs] = {\"train\": tr_loss, \"val\": val_loss}\n        metrics_hwa[hs] = hwa\n        final_hwa[hs] = hwa[-1][1]\n\n# ---------------- plot losses ---------------\ntry:\n    plt.figure()\n    for hs, lv in sorted(losses.items()):\n        ep_t, val_t = zip(*lv[\"train\"])\n        ep_v, val_v = zip(*lv[\"val\"])\n        plt.plot(ep_t, val_t, label=f\"train hs={hs}\")\n        plt.plot(ep_v, val_v, linestyle=\"--\", label=f\"val hs={hs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss (Hidden-Size Sweep)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves_hidden_sizes.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ---------------- plot HWA curves -----------\ntry:\n    plt.figure()\n    for hs, arr in sorted(metrics_hwa.items()):\n        ep, hwa = zip(*arr)\n        plt.plot(ep, hwa, label=f\"hs={hs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: HWA Curves Across Hidden Sizes\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves_hidden_sizes.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating HWA curves: {e}\")\n    plt.close()\n\n# --------------- bar chart final HWA -------\ntry:\n    plt.figure()\n    h_sizes, h_vals = zip(*sorted(final_hwa.items()))\n    plt.bar([str(h) for h in h_sizes], h_vals, color=\"skyblue\")\n    plt.xlabel(\"Hidden Size\")\n    plt.ylabel(\"Final-Epoch HWA\")\n    plt.title(\"SPR_BENCH: Final Harmonic Weighted Accuracy by Hidden Size\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_hwa_bar.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar chart: {e}\")\n    plt.close()\n\n# --------------- print summary --------------\nprint(\"Final-epoch HWA per hidden size:\")\nfor hs, hwa in sorted(final_hwa.items()):\n    print(f\"  hidden={hs:>3}: HWA={hwa:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- set up output dir ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load all experiment_data.npy -----------\nexperiment_data_path_list = [\n    \"experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_930038a9ae014668b759b437fdca3e7c_proc_3099458/experiment_data.npy\",\n    \"experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f20704230f6d40cebfde3e31579e8f5e_proc_3099456/experiment_data.npy\",\n    \"experiments/2025-08-16_02-30-16_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ca25c2f21e3f4767a4586b917ec76994_proc_3099457/experiment_data.npy\",\n]\n\nall_experiment_data = []\nfor exp_path in experiment_data_path_list:\n    try:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), exp_path)\n        exp_data = np.load(full_path, allow_pickle=True).item()\n        all_experiment_data.append(exp_data)\n    except Exception as e:\n        print(f\"Error loading experiment data from {exp_path}: {e}\")\n\nif not all_experiment_data:\n    print(\"No experiment data loaded; exiting.\")\n    exit()\n\n# ---------- aggregate statistics across runs ----------\nagg = {}  # {hs: {'tr': {ep: [v]}, 'val': {ep:[v]}, 'hwa': {ep:[v]}}}\n\nfor run in all_experiment_data:\n    for hs, result in run.get(\"hidden_size\", {}).items():\n        rec = result.get(\"SPR_BENCH\", {})\n        tr_loss = rec.get(\"losses\", {}).get(\"train\", [])\n        val_loss = rec.get(\"losses\", {}).get(\"val\", [])\n        hwa_vals = [(e, h) for e, _, _, h in rec.get(\"metrics\", {}).get(\"val\", [])]\n\n        if not (tr_loss and val_loss and hwa_vals):\n            continue  # skip incomplete runs\n\n        hs_dict = agg.setdefault(hs, {\"tr\": {}, \"val\": {}, \"hwa\": {}})\n        for ep, v in tr_loss:\n            hs_dict[\"tr\"].setdefault(ep, []).append(v)\n        for ep, v in val_loss:\n            hs_dict[\"val\"].setdefault(ep, []).append(v)\n        for ep, h in hwa_vals:\n            hs_dict[\"hwa\"].setdefault(ep, []).append(h)\n\n# sort hidden sizes for consistent plotting\nsorted_hs = sorted(agg.keys())\n\n\n# helper to compute mean and se arrays\ndef mean_se(dic):\n    eps = sorted(dic.keys())\n    vals = [dic[ep] for ep in eps]\n    mean = np.array([np.mean(v) for v in vals])\n    se = np.array([np.std(v, ddof=1) / np.sqrt(len(v)) for v in vals])\n    return np.array(eps), mean, se\n\n\n# ---------- plot 1: loss curves mean \u00b1 SE -------------\ntry:\n    plt.figure()\n    for hs in sorted_hs:\n        ep_tr, mu_tr, se_tr = mean_se(agg[hs][\"tr\"])\n        ep_val, mu_val, se_val = mean_se(agg[hs][\"val\"])\n        plt.plot(ep_tr, mu_tr, label=f\"train hs={hs}\")\n        plt.fill_between(ep_tr, mu_tr - se_tr, mu_tr + se_tr, alpha=0.2)\n        plt.plot(ep_val, mu_val, linestyle=\"--\", label=f\"val hs={hs}\")\n        plt.fill_between(ep_val, mu_val - se_val, mu_val + se_val, alpha=0.2)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Mean \u00b1 SE Loss (Hidden-Size Sweep)\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves_mean_se.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated loss plot: {e}\")\n    plt.close()\n\n# ---------- plot 2: HWA curves mean \u00b1 SE -------------\ntry:\n    plt.figure()\n    for hs in sorted_hs:\n        ep_hwa, mu_hwa, se_hwa = mean_se(agg[hs][\"hwa\"])\n        plt.plot(ep_hwa, mu_hwa, label=f\"hs={hs}\")\n        plt.fill_between(ep_hwa, mu_hwa - se_hwa, mu_hwa + se_hwa, alpha=0.2)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Harmonic Weighted Accuracy\")\n    plt.title(\"SPR_BENCH: Mean \u00b1 SE HWA Curves\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_hwa_curves_mean_se.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated HWA plot: {e}\")\n    plt.close()\n\n# ---------- plot 3: final HWA bar w/ error -------------\ntry:\n    plt.figure()\n    hs_labels, means, ses = [], [], []\n    for hs in sorted_hs:\n        # final epoch assumed to be max key\n        final_ep = max(agg[hs][\"hwa\"].keys())\n        vals = agg[hs][\"hwa\"][final_ep]\n        hs_labels.append(str(hs))\n        means.append(np.mean(vals))\n        ses.append(np.std(vals, ddof=1) / np.sqrt(len(vals)))\n    x = np.arange(len(hs_labels))\n    plt.bar(x, means, yerr=ses, capsize=5, color=\"skyblue\")\n    plt.xticks(x, hs_labels)\n    plt.xlabel(\"Hidden Size\")\n    plt.ylabel(\"Final-Epoch HWA\")\n    plt.title(\"SPR_BENCH: Final HWA by Hidden Size (Mean \u00b1 SE)\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_final_hwa_bar_mean_se.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final HWA bar chart: {e}\")\n    plt.close()\n\n# ---------- textual summary ----------------\nprint(\"Final-epoch HWA (mean \u00b1 SE) per hidden size:\")\nfor hs, label in zip(sorted_hs, hs_labels):\n    m, s = means[hs_labels.index(label)], ses[hs_labels.index(label)]\n    print(f\"  hidden={hs:>3}: {m:.4f} \u00b1 {s:.4f}\")\n"], "plot_plan": ["We load the saved experiment_data.npy, which stores results for the SPR_BENCH dataset under three different epoch budgets (6, 12, 18). For each budget we extract the epoch-indexed training and validation losses as well as the validation shape-, color- and harmonic-weighted accuracies. To keep the number of figures \u2264 5 we overlay curves from all budgets in two separate plots: one for losses (train vs. val) and one for harmonic weighted accuracy. Each plotting routine is wrapped in its own try-except so that failures don\u2019t stop subsequent plots, and every figure is saved to working_dir with descriptive names and then closed. The script begins with the required imports and creation of working_dir. After plotting, we compute and print the best harmonic weighted accuracy achieved for every epoch budget so users can quickly compare configurations. All code relies solely on data present in experiment_data.npy, avoiding any fabricated values. The entire flow is concise and should run end-to-end in any environment where the original training script was executed.", "We load experiment_data.npy, iterate over the three learning-rate sublogs, and extract lists of epochs, training losses, validation losses, and the three validation metrics (SWA, CWA, HWA). A first pair of plots shows loss curves and metric curves per learning rate, each saving one figure per curve type. Then we create a combined comparison plot of HWA vs. epoch for all learning rates, and finally a bar chart summarising the best (highest) HWA achieved by each rate so users can quickly spot the best hyper-parameter. Each plotting routine is wrapped in its own try-except block, figures are titled/described clearly, saved under descriptive names containing \u201cSPR_BENCH\u201d, and closed afterwards. While iterating we also compute and print the best HWA per learning rate so the script outputs a concise numeric summary to stdout. All plotting is limited to the data present; if anything is missing, the corresponding plot is skipped gracefully. The whole script fits in a single, concise block and follows the required import/working_dir pattern.", "We load experiment_data.npy, extract per-epoch training/validation losses and harmonic weighted accuracy (HWA) for every batch size in the SPR_BENCH sweep, and collect the final-epoch HWA values. Three figures are produced: (1) combined training and validation loss curves vs. epoch with different colors/styles for each batch size, (2) validation HWA vs. epoch for each batch size, and (3) a bar chart of final-epoch HWA across batch sizes. Each plot is wrapped in its own try-except block, titled clearly, saved to working_dir with descriptive filenames, and closed afterwards. The code ensures working_dir exists, only plots data present in the file, limits the total number of figures to three, and prints a small summary table of final HWA values. Basic matplotlib is used without custom styles, and no synthetic data are created.", "We will load experiment_data.npy, iterate over the four dropout settings recorded for the SPR_BENCH dataset, and extract (epoch, value) tuples for train/validation loss as well as harmonic-weighted accuracy (HWA). Three concise plots will be generated: (1) a multi-line chart of training vs. validation loss for every dropout value, (2) a multi-line chart of HWA over epochs for every dropout value, and (3) a bar chart comparing the final-epoch HWA across the dropout grid. Each figure is wrapped in its own try-except so that failures in one plot don\u2019t affect the others, and every figure is saved to working_dir with informative filenames that include the dataset and the plot type. We cap the visuals at these three plots to stay within the five-figure guideline. After plotting, we also compute and print the best dropout rate based on the highest final-epoch HWA. All figures are closed explicitly to free resources. No synthetic data are introduced\u2014everything is read directly from the supplied NumPy dictionary. The solution adheres to the provided plotting and code-style constraints.", "We first load experiment_data.npy, retrieve the hidden-size sweep results, and for each hidden size gather (epoch, value) tuples of training/validation loss and validation (SWA, CWA, HWA).  To keep the number of plots \u22645, we aggregate all hidden sizes into three figures: 1) training and validation loss curves, 2) HWA curves, and 3) a bar chart of the final-epoch HWA, making sure each figure has a clear title specifying dataset and contents.  Every figure creation is wrapped in its own try-except block; on success the figure is saved to working_dir with descriptive filenames and then closed, while on failure we report the error and still close the figure.  After plotting we also print out a compact table of the final HWA for each hidden size so users can quickly see the quantitative results.  Only data loaded from experiment_data.npy are used\u2014no synthetic values are generated.  Basic matplotlib functions are sufficient, avoiding any custom styles.  The code obeys the prescribed import order and ensures working_dir exists before saving.  Finally, figures are saved in PNG format and explicitly closed to free resources.", "We will load experiment_data.npy, iterate over each emb_dim tag, and extract epoch-wise train/val losses and validation metrics. Figure 1 plots training vs validation loss for all embedding sizes on a single graph so we can compare convergence behaviour. Figure 2 plots the three validation metrics (SWA, CWA, HWA) across epochs, again overlaying all embedding sizes; to keep things readable we focus on HWA for the main comparison but still include the other two in lighter colours. Figure 3 is a bar chart of the final-epoch HWA per embedding size, clearly showing which dimensionality performs best. Each plot is wrapped in its own try-except block, saved under a descriptive name that includes \u201cSPR_BENCH\u201d, and the figure is closed afterwards. We also print the final HWA values so they appear in the notebook log. Only data that already exists in experiment_data.npy is used, and we limit ourselves to these three figures, satisfying the \u22645-figure requirement. The resulting PNG files are placed inside the working directory created earlier. All plotting uses basic matplotlib defaults with clear titles and axis labels.", "We load the saved experiment_data, extract per-epoch losses and metrics for each weight-decay setting, and prepare three concise visualizations: (1) side-by-side train/validation loss curves, (2) harmonic weighted accuracy (HWA) curves, and (3) a bar chart of final-epoch HWA versus weight decay. Each figure is wrapped in a separate try-except block, titled clearly, saved to working_dir with descriptive filenames, and closed afterwards. We plot all available epochs (only six) and all five weight-decay runs, staying within the \u22645-figure guideline. After plotting, we print a small summary table of the final HWA for quick reference. Everything relies solely on data present in experiment_data.npy and basic matplotlib functionality.", "We will load the saved experiment_data.npy, iterate over the five gradient-clipping settings, and extract (epoch, value) tuples for training loss, validation loss, and validation weighted accuracies (SWA, CWA, HWA). Three plots will be produced, each wrapped in its own try-except: (1) training vs. validation loss curves overlayed for all clipping values, (2) validation HWA curves for all clipping values, and (3) a bar chart of the final-epoch HWA for every clipping value. All plots are titled, reference the SPR_BENCH dataset, and saved into working_dir with descriptive filenames. After plotting, the script prints a small table of the final HWA so it is easy to see the best setting. Figures are always closed whether or not an error occurs.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": ["num_epochs", "learning_rate", "batch_size", "dropout_rate", "hidden_size (LSTM hidden dimension)", "embedding_dim", "weight_decay (L2 regularization coefficient)", "gradient_clipping_max_norm", null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["The script will (1) locate the working directory, (2) load the saved NumPy\ndictionary, (3) iterate over the single dataset (\u201cSPR_BENCH\u201d) and its different\nepoch-budget runs, (4) pick the final training loss plus the best (lowest)\nvalidation loss and the best (highest) validation\u2010time shape-weighted, color-\nweighted and harmonic-weighted accuracies, and (5) print them using explicit\nmetric names. All logic is executed at top level so the file runs immediately\nwhen executed.", "The solution will load the saved numpy dictionary, iterate over each learning-\nrate run, and compute either the best (min for losses, max for accuracies) or,\nwhen appropriate, the final epoch\u2019s value. It then prints the dataset name\n(here, each learning-rate run) followed by clearly labelled metrics. All code\nexecutes immediately at import time and respects the structure of the saved log.", "Below is a compact script that (1) finds the saved experiment file, (2) loads\nit, (3) scans every batch-size configuration recorded for each dataset, and (4)\nprints the final training/validation losses together with the best validation\nSWA, CWA and HWA obtained during training. It respects the original data\nstructure and prints explicit, self-descriptive metric names for easy reading.", "The script will load experiment_data.npy from the \u201cworking\u201d directory, convert\nthe numpy object back to a regular Python dict, and traverse its nested\nstructure (hyper-parameter \u2192 dataset \u2192 configuration).   For every dataset (here\nonly \u201cSPR_BENCH\u201d) and every dropout configuration, it collects the last recorded\nentry for each list of losses and validation metrics, interpreting these as the\nfinal values.   It then prints the dataset name once, followed by each\nconfiguration and clearly-labeled final metrics such as \u201cTraining loss,\u201d\n\u201cValidation loss,\u201d \u201cValidation shape-weighted accuracy,\u201d etc.   The code sits\nentirely at global scope so it executes immediately when run, without any\nspecial entry point or plotting.", "Below is a small utility that immediately loads the saved numpy dictionary,\niterates over every hidden-size/ dataset combination, and prints the final\nvalues recorded for training loss, validation loss, shape-weighted accuracy,\ncolor-weighted accuracy, and harmonic-weighted accuracy. Each block of outputs\nis prefixed with the dataset name so the numbers are easy to associate with the\ncorrect data split.", "The script will locate the \u201cworking\u201d directory, load the serialized\n`experiment_data.npy` dictionary, and iterate through each embedding-dimension\nexperiment.   For every experiment it will:   \u2022 select the final epoch\u2019s values\nfor train loss, validation loss, and the three validation accuracies (SWA, CWA,\nHWA);   \u2022 print the dataset name (\u201cSPR_BENCH\u201d) once for each experiment,\nfollowed by clearly-labelled metric lines that include the experiment tag so the\nreader can distinguish between embedding dimensions.   The code executes\nimmediately at import time and contains no `if __name__ == \"__main__\":` guard.", "We will load experiment_data.npy from the working directory, iterate over the\nstored datasets and weight-decay runs, and, for every run, print the minimum\ntraining loss, minimum validation loss, and the best (maximum) validation\nShape-, Color-, and Harmonic-Weighted Accuracies observed across epochs. Each\ndataset name and every metric name is printed explicitly.", "The script will load the saved NumPy file, iterate over every gradient-clipping\nsetting (treated here as separate \u201cdatasets\u201d), grab the last recorded entry for\neach tracked quantity (training loss, validation loss, and the three validation\naccuracies), and print them with explicit, self-describing labels. It obeys all\nstructural constraints by keeping code at module scope, executing immediately,\nand producing only textual output\u2014no figures.", "Below is a small utility that immediately loads the saved numpy dictionary,\niterates over every hidden-size/ dataset combination, and prints the final\nvalues recorded for training loss, validation loss, shape-weighted accuracy,\ncolor-weighted accuracy, and harmonic-weighted accuracy. Each block of outputs\nis prefixed with the dataset name so the numbers are easy to associate with the\ncorrect data split.", "Below is a small utility that immediately loads the saved numpy dictionary,\niterates over every hidden-size/ dataset combination, and prints the final\nvalues recorded for training loss, validation loss, shape-weighted accuracy,\ncolor-weighted accuracy, and harmonic-weighted accuracy. Each block of outputs\nis prefixed with the dataset name so the numbers are easy to associate with the\ncorrect data split.", "Below is a small utility that immediately loads the saved numpy dictionary,\niterates over every hidden-size/ dataset combination, and prints the final\nvalues recorded for training loss, validation loss, shape-weighted accuracy,\ncolor-weighted accuracy, and harmonic-weighted accuracy. Each block of outputs\nis prefixed with the dataset name so the numbers are easy to associate with the\ncorrect data split.", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ---------- locate and load ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\n\n# ---------- iterate & print ----------\nfor dataset_name, runs in experiment_data[\"num_epochs\"].items():\n    # runs is a dict keyed by epoch budget (6, 12, 18, \u2026)\n    for ep_budget, run_data in runs.items():\n        print(f\"{dataset_name} (num_epochs = {ep_budget})\")\n\n        # losses -------------------------------------------------------------\n        train_losses = run_data[\"losses\"][\"train\"]  # list of (epoch, loss)\n        val_losses = run_data[\"losses\"][\"val\"]  # list of (epoch, loss)\n        final_train_loss = train_losses[-1][1]\n        best_val_loss = min(val_losses, key=lambda x: x[1])[1]\n\n        # metrics ------------------------------------------------------------\n        # list of (epoch, swa, cwa, hwa) \u2013 choose entry with best (highest) hwa\n        val_metrics = run_data[\"metrics\"][\"val\"]\n        best_by_hwa = max(val_metrics, key=lambda x: x[3])  # x[3] is hwa\n        _, best_swa, best_cwa, best_hwa = best_by_hwa\n\n        print(f\"final training loss: {final_train_loss:.4f}\")\n        print(f\"best validation loss: {best_val_loss:.4f}\")\n        print(f\"best shape weighted accuracy (validation): {best_swa:.4f}\")\n        print(f\"best color weighted accuracy (validation): {best_cwa:.4f}\")\n        print(f\"best harmonic weighted accuracy (validation): {best_hwa:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# ---------- locate experiment file ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_path = os.path.join(working_dir, \"experiment_data.npy\")\nassert os.path.exists(exp_path), f\"File not found: {exp_path}\"\n\n# ---------- load data ----------\nexperiment_data = np.load(exp_path, allow_pickle=True).item()\nlr_runs = experiment_data.get(\"learning_rate\", {})\n\n\ndef best_value(values, mode=\"min\"):\n    \"\"\"Return the best scalar from a list of (epoch, value) tuples.\"\"\"\n    if not values:\n        return None\n    # extract only the scalar numbers\n    vals = [v for _, v in values]\n    return min(vals) if mode == \"min\" else max(vals)\n\n\n# ---------- iterate and print ----------\nfor lr_str, log in lr_runs.items():\n    print(f\"Dataset: learning_rate = {lr_str}\")\n\n    # losses\n    train_losses = log[\"losses\"].get(\"train\", [])\n    val_losses = log[\"losses\"].get(\"val\", [])\n\n    best_train_loss = best_value(train_losses, mode=\"min\")\n    best_val_loss = best_value(val_losses, mode=\"min\")\n\n    if best_train_loss is not None:\n        print(f\"Training loss (minimum): {best_train_loss:.4f}\")\n    if best_val_loss is not None:\n        print(f\"Validation loss (minimum): {best_val_loss:.4f}\")\n\n    # validation metrics: (epoch, swa, cwa, hwa)\n    val_metrics = log[\"metrics\"].get(\"val\", [])\n    if val_metrics:\n        # separate each metric column\n        swa_vals = [tpl[1] for tpl in val_metrics]\n        cwa_vals = [tpl[2] for tpl in val_metrics]\n        hwa_vals = [tpl[3] for tpl in val_metrics]\n\n        print(f\"Validation shape-weighted accuracy (maximum): {max(swa_vals):.4f}\")\n        print(f\"Validation color-weighted accuracy (maximum): {max(cwa_vals):.4f}\")\n        print(f\"Validation harmonic-weighted accuracy (maximum): {max(hwa_vals):.4f}\")\n\n    # separator for readability\n    print()\n", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# locate and load the saved experiment dictionary\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# -------------------------------------------------\n# extract and print metrics\n# -------------------------------------------------\nfor hyperparam_name, datasets in experiment_data.items():  # 'batch_size'\n    for dataset_name, configs in datasets.items():  # 'SPR_BENCH'\n        print(f\"\\nDataset: {dataset_name}\")\n        for config_key, exp in configs.items():  # '64', '128', ...\n            # final losses\n            final_train_loss = exp[\"losses\"][\"train\"][-1][1]\n            final_val_loss = exp[\"losses\"][\"val\"][-1][1]\n\n            # best validation weighted-accuracy metrics (use max HWA epoch)\n            best_epoch_entry = max(\n                exp[\"metrics\"][\"val\"], key=lambda t: t[3]\n            )  # (epoch, swa, cwa, hwa)\n            best_swa, best_cwa, best_hwa = (\n                best_epoch_entry[1],\n                best_epoch_entry[2],\n                best_epoch_entry[3],\n            )\n\n            print(f\"\\n  Configuration: batch size = {config_key}\")\n            print(f\"    Final training loss: {final_train_loss:.4f}\")\n            print(f\"    Final validation loss: {final_val_loss:.4f}\")\n            print(f\"    Best validation shape-weighted accuracy: {best_swa:.4f}\")\n            print(f\"    Best validation color-weighted accuracy: {best_cwa:.4f}\")\n            print(f\"    Best validation harmonic-weighted accuracy: {best_hwa:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load the saved results ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ---------- iterate and report ----------\nfor hp_name, datasets in experiment_data.items():  # e.g. \"dropout_rate\"\n    for dataset_name, configs in datasets.items():  # e.g. \"SPR_BENCH\"\n        print(f\"\\nDataset: {dataset_name}\")\n        for cfg_key, record in configs.items():  # e.g. \"p=0.2\"\n            # fetch final (last) values\n            final_train_loss = record[\"losses\"][\"train\"][-1][1]  # (epoch, value)\n            final_val_loss = record[\"losses\"][\"val\"][-1][1]\n            final_swa = record[\"metrics\"][\"val\"][-1][1]  # tuple: (epoch, swa, cwa, hwa)\n            final_cwa = record[\"metrics\"][\"val\"][-1][2]\n            final_hwa = record[\"metrics\"][\"val\"][-1][3]\n\n            # print with clear labels\n            print(f\"\\n  Configuration ({hp_name} = {cfg_key.split('=')[1]}):\")\n            print(f\"    Training loss: {final_train_loss:.4f}\")\n            print(f\"    Validation loss: {final_val_loss:.4f}\")\n            print(f\"    Validation shape-weighted accuracy: {final_swa:.4f}\")\n            print(f\"    Validation color-weighted accuracy: {final_cwa:.4f}\")\n            print(f\"    Validation harmonic-weighted accuracy: {final_hwa:.4f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load the experiment results\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# Traverse the structure and print the requested statistics\n# ------------------------------------------------------------------\nhidden_dict = experiment_data.get(\"hidden_size\", {})\n\nfor hidden_size, dataset_results in hidden_dict.items():\n    # dataset_results is a dict like {'SPR_BENCH': store}\n    for dataset_name, store in dataset_results.items():\n        print(f\"{dataset_name} (hidden size = {hidden_size})\")\n\n        # -------- losses ---------\n        train_losses = store[\"losses\"][\"train\"]  # list of (epoch, loss)\n        val_losses = store[\"losses\"][\"val\"]  # list of (epoch, loss)\n        final_train_loss = train_losses[-1][1]\n        final_val_loss = val_losses[-1][1]\n\n        # -------- metrics --------\n        # Each element: (epoch, swa, cwa, hwa)\n        val_metrics = store[\"metrics\"][\"val\"]\n        final_swa = val_metrics[-1][1]\n        final_cwa = val_metrics[-1][2]\n        final_hwa = val_metrics[-1][3]\n\n        # -------- printing --------\n        print(f\"final training loss: {final_train_loss:.4f}\")\n        print(f\"final validation loss: {final_val_loss:.4f}\")\n        print(f\"final shape weighted accuracy: {final_swa:.4f}\")\n        print(f\"final color weighted accuracy: {final_cwa:.4f}\")\n        print(f\"final harmonic weighted accuracy: {final_hwa:.4f}\")\n        print()  # blank line for readability\n", "import os\nimport numpy as np\n\n# ------------------- locate and load experiment data -------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexp_file = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(exp_file, allow_pickle=True).item()\n\n# ------------------- extract & print metrics ---------------------------\nfor tag, results in experiment_data.items():\n    bench = results[\"SPR_BENCH\"]\n\n    # retrieve final recorded values\n    final_train_loss = bench[\"losses\"][\"train\"][-1][1]  # (epoch, value)\n    final_val_loss = bench[\"losses\"][\"val\"][-1][1]\n\n    final_epoch, final_swa, final_cwa, final_hwa = bench[\"metrics\"][\"val\"][-1]\n\n    # print dataset header\n    print(\"SPR_BENCH\")\n\n    # print clearly-labelled metrics\n    print(f\"{tag} - train loss: {final_train_loss:.4f}\")\n    print(f\"{tag} - validation loss: {final_val_loss:.4f}\")\n    print(f\"{tag} - validation shape weighted accuracy: {final_swa:.4f}\")\n    print(f\"{tag} - validation color weighted accuracy: {final_cwa:.4f}\")\n    print(f\"{tag} - validation harmonic weighted accuracy: {final_hwa:.4f}\")\n    print()  # blank line between experiments\n", "import os\nimport numpy as np\n\n# ---------------- load experiment data -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------- helper functions ---------------------\ndef _min_loss(loss_tuples):\n    \"\"\"Return the minimum loss value from a list of (epoch, loss) tuples.\"\"\"\n    return min(loss_tuples, key=lambda x: x[1])[1]\n\n\ndef _max_metric(metric_tuples, idx):\n    \"\"\"Return the maximum metric value (by index) from a list of tuples.\"\"\"\n    return max(metric_tuples, key=lambda x: x[idx])[idx]\n\n\n# ---------------- iterate and report -------------------\nfor setting_name, datasets in experiment_data.items():  # e.g. \"weight_decay\"\n    for dataset_name, runs in datasets.items():  # e.g. \"SPR_BENCH\"\n        print(f\"Dataset: {dataset_name}\")\n        for run_key, run_data in runs.items():  # e.g. \"wd_0.0001\"\n            train_losses = run_data[\"losses\"][\"train\"]  # [(epoch, loss), ...]\n            val_losses = run_data[\"losses\"][\"val\"]\n            val_metrics = run_data[\"metrics\"][\"val\"]  # [(epoch, swa, cwa, hwa), ...]\n\n            min_train_loss = _min_loss(train_losses)\n            min_val_loss = _min_loss(val_losses)\n\n            best_swa = _max_metric(val_metrics, 1)  # index 1 -> swa\n            best_cwa = _max_metric(val_metrics, 2)  # index 2 -> cwa\n            best_hwa = _max_metric(val_metrics, 3)  # index 3 -> hwa\n\n            print(f\"  Run: {run_key}\")\n            print(f\"    Minimum training loss: {min_train_loss:.6f}\")\n            print(f\"    Minimum validation loss: {min_val_loss:.6f}\")\n            print(f\"    Best validation Shape-Weighted Accuracy: {best_swa:.6f}\")\n            print(f\"    Best validation Color-Weighted Accuracy: {best_cwa:.6f}\")\n            print(f\"    Best validation Harmonic-Weighted Accuracy: {best_hwa:.6f}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------\n# Locate and load the experiment data\n# -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------\n# Helper to fetch the last element of a list safely\n# -------------------------------------------------\ndef last_or_none(lst):\n    \"\"\"Return the last element of a non-empty list, else None.\"\"\"\n    return lst[-1] if lst else None\n\n\n# -------------------------------------------------\n# Extract and print metrics\n# -------------------------------------------------\nclip_results = experiment_data.get(\"gradient_clipping_max_norm\", {})\n\nfor clip_val, exp_cur in clip_results.items():\n    print(f\"Dataset: gradient_clipping_max_norm={clip_val}\")\n\n    # Losses\n    final_train_loss = last_or_none(exp_cur[\"losses\"].get(\"train\", []))\n    final_val_loss = last_or_none(exp_cur[\"losses\"].get(\"val\", []))\n\n    if final_train_loss is not None:\n        _, train_loss_value = final_train_loss\n        print(f\"  final training loss: {train_loss_value:.6f}\")\n\n    if final_val_loss is not None:\n        _, val_loss_value = final_val_loss\n        print(f\"  final validation loss: {val_loss_value:.6f}\")\n\n    # Validation weighted accuracies\n    final_val_metrics = last_or_none(exp_cur[\"metrics\"].get(\"val\", []))\n    if final_val_metrics is not None:\n        _, swa, cwa, hwa = final_val_metrics\n        print(f\"  final validation shape_weighted_accuracy: {swa:.6f}\")\n        print(f\"  final validation color_weighted_accuracy: {cwa:.6f}\")\n        print(f\"  final validation harmonic_weighted_accuracy: {hwa:.6f}\")\n\n    # Blank line for readability between datasets\n    print()\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load the experiment results\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# Traverse the structure and print the requested statistics\n# ------------------------------------------------------------------\nhidden_dict = experiment_data.get(\"hidden_size\", {})\n\nfor hidden_size, dataset_results in hidden_dict.items():\n    # dataset_results is a dict like {'SPR_BENCH': store}\n    for dataset_name, store in dataset_results.items():\n        print(f\"{dataset_name} (hidden size = {hidden_size})\")\n\n        # -------- losses ---------\n        train_losses = store[\"losses\"][\"train\"]  # list of (epoch, loss)\n        val_losses = store[\"losses\"][\"val\"]  # list of (epoch, loss)\n        final_train_loss = train_losses[-1][1]\n        final_val_loss = val_losses[-1][1]\n\n        # -------- metrics --------\n        # Each element: (epoch, swa, cwa, hwa)\n        val_metrics = store[\"metrics\"][\"val\"]\n        final_swa = val_metrics[-1][1]\n        final_cwa = val_metrics[-1][2]\n        final_hwa = val_metrics[-1][3]\n\n        # -------- printing --------\n        print(f\"final training loss: {final_train_loss:.4f}\")\n        print(f\"final validation loss: {final_val_loss:.4f}\")\n        print(f\"final shape weighted accuracy: {final_swa:.4f}\")\n        print(f\"final color weighted accuracy: {final_cwa:.4f}\")\n        print(f\"final harmonic weighted accuracy: {final_hwa:.4f}\")\n        print()  # blank line for readability\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load the experiment results\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# Traverse the structure and print the requested statistics\n# ------------------------------------------------------------------\nhidden_dict = experiment_data.get(\"hidden_size\", {})\n\nfor hidden_size, dataset_results in hidden_dict.items():\n    # dataset_results is a dict like {'SPR_BENCH': store}\n    for dataset_name, store in dataset_results.items():\n        print(f\"{dataset_name} (hidden size = {hidden_size})\")\n\n        # -------- losses ---------\n        train_losses = store[\"losses\"][\"train\"]  # list of (epoch, loss)\n        val_losses = store[\"losses\"][\"val\"]  # list of (epoch, loss)\n        final_train_loss = train_losses[-1][1]\n        final_val_loss = val_losses[-1][1]\n\n        # -------- metrics --------\n        # Each element: (epoch, swa, cwa, hwa)\n        val_metrics = store[\"metrics\"][\"val\"]\n        final_swa = val_metrics[-1][1]\n        final_cwa = val_metrics[-1][2]\n        final_hwa = val_metrics[-1][3]\n\n        # -------- printing --------\n        print(f\"final training loss: {final_train_loss:.4f}\")\n        print(f\"final validation loss: {final_val_loss:.4f}\")\n        print(f\"final shape weighted accuracy: {final_swa:.4f}\")\n        print(f\"final color weighted accuracy: {final_cwa:.4f}\")\n        print(f\"final harmonic weighted accuracy: {final_hwa:.4f}\")\n        print()  # blank line for readability\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# Locate and load the experiment results\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# Traverse the structure and print the requested statistics\n# ------------------------------------------------------------------\nhidden_dict = experiment_data.get(\"hidden_size\", {})\n\nfor hidden_size, dataset_results in hidden_dict.items():\n    # dataset_results is a dict like {'SPR_BENCH': store}\n    for dataset_name, store in dataset_results.items():\n        print(f\"{dataset_name} (hidden size = {hidden_size})\")\n\n        # -------- losses ---------\n        train_losses = store[\"losses\"][\"train\"]  # list of (epoch, loss)\n        val_losses = store[\"losses\"][\"val\"]  # list of (epoch, loss)\n        final_train_loss = train_losses[-1][1]\n        final_val_loss = val_losses[-1][1]\n\n        # -------- metrics --------\n        # Each element: (epoch, swa, cwa, hwa)\n        val_metrics = store[\"metrics\"][\"val\"]\n        final_swa = val_metrics[-1][1]\n        final_cwa = val_metrics[-1][2]\n        final_hwa = val_metrics[-1][3]\n\n        # -------- printing --------\n        print(f\"final training loss: {final_train_loss:.4f}\")\n        print(f\"final validation loss: {final_val_loss:.4f}\")\n        print(f\"final shape weighted accuracy: {final_swa:.4f}\")\n        print(f\"final color weighted accuracy: {final_cwa:.4f}\")\n        print(f\"final harmonic weighted accuracy: {final_hwa:.4f}\")\n        print()  # blank line for readability\n", ""], "parse_term_out": ["['SPR_BENCH (num_epochs = 6)', '\\n', 'final training loss: 0.0008', '\\n', 'best\nvalidation loss: 0.0017', '\\n', 'best shape weighted accuracy (validation):\n0.9995', '\\n', 'best color weighted accuracy (validation): 0.9996', '\\n', 'best\nharmonic weighted accuracy (validation): 0.9996\\n', '\\n', 'SPR_BENCH (num_epochs\n= 12)', '\\n', 'final training loss: 0.0001', '\\n', 'best validation loss:\n0.0016', '\\n', 'best shape weighted accuracy (validation): 0.9995', '\\n', 'best\ncolor weighted accuracy (validation): 0.9996', '\\n', 'best harmonic weighted\naccuracy (validation): 0.9996\\n', '\\n', 'SPR_BENCH (num_epochs = 18)', '\\n',\n'final training loss: 0.0000', '\\n', 'best validation loss: 0.0010', '\\n', 'best\nshape weighted accuracy (validation): 0.9998', '\\n', 'best color weighted\naccuracy (validation): 0.9998', '\\n', 'best harmonic weighted accuracy\n(validation): 0.9998\\n', '\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']", "['Dataset: learning_rate = 0.0003', '\\n', 'Training loss (minimum): 0.0269',\n'\\n', 'Validation loss (minimum): 0.0253', '\\n', 'Validation shape-weighted\naccuracy (maximum): 0.9919', '\\n', 'Validation color-weighted accuracy\n(maximum): 0.9921', '\\n', 'Validation harmonic-weighted accuracy (maximum):\n0.9920', '\\n', '\\n', 'Dataset: learning_rate = 0.001', '\\n', 'Training loss\n(minimum): 0.0008', '\\n', 'Validation loss (minimum): 0.0014', '\\n', 'Validation\nshape-weighted accuracy (maximum): 0.9999', '\\n', 'Validation color-weighted\naccuracy (maximum): 0.9998', '\\n', 'Validation harmonic-weighted accuracy\n(maximum): 0.9999', '\\n', '\\n', 'Dataset: learning_rate = 0.003', '\\n',\n'Training loss (minimum): 0.0001', '\\n', 'Validation loss (minimum): 0.0003',\n'\\n', 'Validation shape-weighted accuracy (maximum): 1.0000', '\\n', 'Validation\ncolor-weighted accuracy (maximum): 1.0000', '\\n', 'Validation harmonic-weighted\naccuracy (maximum): 1.0000', '\\n', '\\n', 'Execution time: a moment seconds (time\nlimit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', '\\n  Configuration: batch size = 64', '\\n', '\nFinal training loss: 0.0002', '\\n', '    Final validation loss: 0.0009', '\\n', '\nBest validation shape-weighted accuracy: 0.9998', '\\n', '    Best validation\ncolor-weighted accuracy: 0.9998', '\\n', '    Best validation harmonic-weighted\naccuracy: 0.9998', '\\n', '\\n  Configuration: batch size = 128', '\\n', '    Final\ntraining loss: 0.0009', '\\n', '    Final validation loss: 0.0025', '\\n', '\nBest validation shape-weighted accuracy: 0.9993', '\\n', '    Best validation\ncolor-weighted accuracy: 0.9993', '\\n', '    Best validation harmonic-weighted\naccuracy: 0.9993', '\\n', '\\n  Configuration: batch size = 256', '\\n', '    Final\ntraining loss: 0.0034', '\\n', '    Final validation loss: 0.0039', '\\n', '\nBest validation shape-weighted accuracy: 0.9988', '\\n', '    Best validation\ncolor-weighted accuracy: 0.9990', '\\n', '    Best validation harmonic-weighted\naccuracy: 0.9989', '\\n', '\\n  Configuration: batch size = 512', '\\n', '    Final\ntraining loss: 0.0209', '\\n', '    Final validation loss: 0.0168', '\\n', '\nBest validation shape-weighted accuracy: 0.9956', '\\n', '    Best validation\ncolor-weighted accuracy: 0.9955', '\\n', '    Best validation harmonic-weighted\naccuracy: 0.9956', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', '\\n  Configuration (dropout_rate = 0.0):', '\\n',\n'    Training loss: 0.0008', '\\n', '    Validation loss: 0.0017', '\\n', '\nValidation shape-weighted accuracy: 0.9995', '\\n', '    Validation color-\nweighted accuracy: 0.9996', '\\n', '    Validation harmonic-weighted accuracy:\n0.9996', '\\n', '\\n  Configuration (dropout_rate = 0.2):', '\\n', '    Training\nloss: 0.0101', '\\n', '    Validation loss: 0.0047', '\\n', '    Validation shape-\nweighted accuracy: 0.9977', '\\n', '    Validation color-weighted accuracy:\n0.9981', '\\n', '    Validation harmonic-weighted accuracy: 0.9979', '\\n', '\\n\nConfiguration (dropout_rate = 0.3):', '\\n', '    Training loss: 0.0156', '\\n', '\nValidation loss: 0.0093', '\\n', '    Validation shape-weighted accuracy:\n0.9958', '\\n', '    Validation color-weighted accuracy: 0.9965', '\\n', '\nValidation harmonic-weighted accuracy: 0.9961', '\\n', '\\n  Configuration\n(dropout_rate = 0.5):', '\\n', '    Training loss: 0.0423', '\\n', '    Validation\nloss: 0.0218', '\\n', '    Validation shape-weighted accuracy: 0.9913', '\\n', '\nValidation color-weighted accuracy: 0.9919', '\\n', '    Validation harmonic-\nweighted accuracy: 0.9916', '\\n', 'Execution time: a moment seconds (time limit\nis 30 minutes).']", "['SPR_BENCH (hidden size = 64)', '\\n', 'final training loss: 0.0028', '\\n',\n'final validation loss: 0.0041', '\\n', 'final shape weighted accuracy: 0.9985',\n'\\n', 'final color weighted accuracy: 0.9986', '\\n', 'final harmonic weighted\naccuracy: 0.9986', '\\n', '\\n', 'SPR_BENCH (hidden size = 128)', '\\n', 'final\ntraining loss: 0.0009', '\\n', 'final validation loss: 0.0014', '\\n', 'final\nshape weighted accuracy: 0.9995', '\\n', 'final color weighted accuracy: 0.9996',\n'\\n', 'final harmonic weighted accuracy: 0.9996', '\\n', '\\n', 'SPR_BENCH (hidden\nsize = 256)', '\\n', 'final training loss: 0.0003', '\\n', 'final validation loss:\n0.0011', '\\n', 'final shape weighted accuracy: 0.9998', '\\n', 'final color\nweighted accuracy: 0.9999', '\\n', 'final harmonic weighted accuracy: 0.9998',\n'\\n', '\\n', 'SPR_BENCH (hidden size = 512)', '\\n', 'final training loss:\n0.0002', '\\n', 'final validation loss: 0.0006', '\\n', 'final shape weighted\naccuracy: 1.0000', '\\n', 'final color weighted accuracy: 1.0000', '\\n', 'final\nharmonic weighted accuracy: 1.0000', '\\n', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['SPR_BENCH', '\\n', 'emb_dim_32 - train loss: 0.0049', '\\n', 'emb_dim_32 -\nvalidation loss: 0.0039', '\\n', 'emb_dim_32 - validation shape weighted\naccuracy: 0.9989', '\\n', 'emb_dim_32 - validation color weighted accuracy:\n0.9991', '\\n', 'emb_dim_32 - validation harmonic weighted accuracy: 0.9990',\n'\\n', '\\n', 'SPR_BENCH', '\\n', 'emb_dim_64 - train loss: 0.0011', '\\n',\n'emb_dim_64 - validation loss: 0.0040', '\\n', 'emb_dim_64 - validation shape\nweighted accuracy: 0.9980', '\\n', 'emb_dim_64 - validation color weighted\naccuracy: 0.9983', '\\n', 'emb_dim_64 - validation harmonic weighted accuracy:\n0.9982', '\\n', '\\n', 'SPR_BENCH', '\\n', 'emb_dim_128 - train loss: 0.0003',\n'\\n', 'emb_dim_128 - validation loss: 0.0010', '\\n', 'emb_dim_128 - validation\nshape weighted accuracy: 0.9998', '\\n', 'emb_dim_128 - validation color weighted\naccuracy: 0.9998', '\\n', 'emb_dim_128 - validation harmonic weighted accuracy:\n0.9998', '\\n', '\\n', 'SPR_BENCH', '\\n', 'emb_dim_256 - train loss: 0.0003',\n'\\n', 'emb_dim_256 - validation loss: 0.0016', '\\n', 'emb_dim_256 - validation\nshape weighted accuracy: 0.9998', '\\n', 'emb_dim_256 - validation color weighted\naccuracy: 0.9998', '\\n', 'emb_dim_256 - validation harmonic weighted accuracy:\n0.9998', '\\n', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Dataset: SPR_BENCH', '\\n', '  Run: wd_0.0', '\\n', '    Minimum training loss:\n0.000836', '\\n', '    Minimum validation loss: 0.001699', '\\n', '    Best\nvalidation Shape-Weighted Accuracy: 0.999535', '\\n', '    Best validation Color-\nWeighted Accuracy: 0.999573', '\\n', '    Best validation Harmonic-Weighted\nAccuracy: 0.999554', '\\n', '  Run: wd_1e-05', '\\n', '    Minimum training loss:\n0.001051', '\\n', '    Minimum validation loss: 0.002615', '\\n', '    Best\nvalidation Shape-Weighted Accuracy: 0.999302', '\\n', '    Best validation Color-\nWeighted Accuracy: 0.999329', '\\n', '    Best validation Harmonic-Weighted\nAccuracy: 0.999316', '\\n', '  Run: wd_0.0001', '\\n', '    Minimum training loss:\n0.003060', '\\n', '    Minimum validation loss: 0.002785', '\\n', '    Best\nvalidation Shape-Weighted Accuracy: 0.999535', '\\n', '    Best validation Color-\nWeighted Accuracy: 0.999573', '\\n', '    Best validation Harmonic-Weighted\nAccuracy: 0.999554', '\\n', '  Run: wd_0.001', '\\n', '    Minimum training loss:\n0.041361', '\\n', '    Minimum validation loss: 0.036965', '\\n', '    Best\nvalidation Shape-Weighted Accuracy: 0.989071', '\\n', '    Best validation Color-\nWeighted Accuracy: 0.989201', '\\n', '    Best validation Harmonic-Weighted\nAccuracy: 0.989136', '\\n', '  Run: wd_0.01', '\\n', '    Minimum training loss:\n0.151242', '\\n', '    Minimum validation loss: 0.152883', '\\n', '    Best\nvalidation Shape-Weighted Accuracy: 0.964190', '\\n', '    Best validation Color-\nWeighted Accuracy: 0.961625', '\\n', '    Best validation Harmonic-Weighted\nAccuracy: 0.962906', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['Dataset: gradient_clipping_max_norm=0', '\\n', '  final training loss:\n0.000836', '\\n', '  final validation loss: 0.001699', '\\n', '  final validation\nshape_weighted_accuracy: 0.999535', '\\n', '  final validation\ncolor_weighted_accuracy: 0.999573', '\\n', '  final validation\nharmonic_weighted_accuracy: 0.999554', '\\n', '\\n', 'Dataset:\ngradient_clipping_max_norm=0.5', '\\n', '  final training loss: 0.000796', '\\n',\n'  final validation loss: 0.002526', '\\n', '  final validation\nshape_weighted_accuracy: 0.999361', '\\n', '  final validation\ncolor_weighted_accuracy: 0.999390', '\\n', '  final validation\nharmonic_weighted_accuracy: 0.999375', '\\n', '\\n', 'Dataset:\ngradient_clipping_max_norm=1', '\\n', '  final training loss: 0.000954', '\\n', '\nfinal validation loss: 0.001784', '\\n', '  final validation\nshape_weighted_accuracy: 0.999302', '\\n', '  final validation\ncolor_weighted_accuracy: 0.999390', '\\n', '  final validation\nharmonic_weighted_accuracy: 0.999346', '\\n', '\\n', 'Dataset:\ngradient_clipping_max_norm=2', '\\n', '  final training loss: 0.000811', '\\n', '\nfinal validation loss: 0.002346', '\\n', '  final validation\nshape_weighted_accuracy: 0.999302', '\\n', '  final validation\ncolor_weighted_accuracy: 0.999390', '\\n', '  final validation\nharmonic_weighted_accuracy: 0.999346', '\\n', '\\n', 'Dataset:\ngradient_clipping_max_norm=5', '\\n', '  final training loss: 0.000941', '\\n', '\nfinal validation loss: 0.002051', '\\n', '  final validation\nshape_weighted_accuracy: 0.999535', '\\n', '  final validation\ncolor_weighted_accuracy: 0.999634', '\\n', '  final validation\nharmonic_weighted_accuracy: 0.999584', '\\n', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['SPR_BENCH (hidden size = 64)', '\\n', 'final training loss: 0.0028', '\\n',\n'final validation loss: 0.0041', '\\n', 'final shape weighted accuracy: 0.9985',\n'\\n', 'final color weighted accuracy: 0.9986', '\\n', 'final harmonic weighted\naccuracy: 0.9986', '\\n', '\\n', 'SPR_BENCH (hidden size = 128)', '\\n', 'final\ntraining loss: 0.0009', '\\n', 'final validation loss: 0.0014', '\\n', 'final\nshape weighted accuracy: 0.9995', '\\n', 'final color weighted accuracy: 0.9996',\n'\\n', 'final harmonic weighted accuracy: 0.9996', '\\n', '\\n', 'SPR_BENCH (hidden\nsize = 256)', '\\n', 'final training loss: 0.0003', '\\n', 'final validation loss:\n0.0011', '\\n', 'final shape weighted accuracy: 0.9998', '\\n', 'final color\nweighted accuracy: 0.9999', '\\n', 'final harmonic weighted accuracy: 0.9998',\n'\\n', '\\n', 'SPR_BENCH (hidden size = 512)', '\\n', 'final training loss:\n0.0002', '\\n', 'final validation loss: 0.0006', '\\n', 'final shape weighted\naccuracy: 1.0000', '\\n', 'final color weighted accuracy: 1.0000', '\\n', 'final\nharmonic weighted accuracy: 1.0000', '\\n', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['SPR_BENCH (hidden size = 64)', '\\n', 'final training loss: 0.0028', '\\n',\n'final validation loss: 0.0041', '\\n', 'final shape weighted accuracy: 0.9985',\n'\\n', 'final color weighted accuracy: 0.9986', '\\n', 'final harmonic weighted\naccuracy: 0.9986', '\\n', '\\n', 'SPR_BENCH (hidden size = 128)', '\\n', 'final\ntraining loss: 0.0009', '\\n', 'final validation loss: 0.0014', '\\n', 'final\nshape weighted accuracy: 0.9995', '\\n', 'final color weighted accuracy: 0.9996',\n'\\n', 'final harmonic weighted accuracy: 0.9996', '\\n', '\\n', 'SPR_BENCH (hidden\nsize = 256)', '\\n', 'final training loss: 0.0003', '\\n', 'final validation loss:\n0.0011', '\\n', 'final shape weighted accuracy: 0.9998', '\\n', 'final color\nweighted accuracy: 0.9999', '\\n', 'final harmonic weighted accuracy: 0.9998',\n'\\n', '\\n', 'SPR_BENCH (hidden size = 512)', '\\n', 'final training loss:\n0.0002', '\\n', 'final validation loss: 0.0006', '\\n', 'final shape weighted\naccuracy: 1.0000', '\\n', 'final color weighted accuracy: 1.0000', '\\n', 'final\nharmonic weighted accuracy: 1.0000', '\\n', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['SPR_BENCH (hidden size = 64)', '\\n', 'final training loss: 0.0028', '\\n',\n'final validation loss: 0.0041', '\\n', 'final shape weighted accuracy: 0.9985',\n'\\n', 'final color weighted accuracy: 0.9986', '\\n', 'final harmonic weighted\naccuracy: 0.9986', '\\n', '\\n', 'SPR_BENCH (hidden size = 128)', '\\n', 'final\ntraining loss: 0.0009', '\\n', 'final validation loss: 0.0014', '\\n', 'final\nshape weighted accuracy: 0.9995', '\\n', 'final color weighted accuracy: 0.9996',\n'\\n', 'final harmonic weighted accuracy: 0.9996', '\\n', '\\n', 'SPR_BENCH (hidden\nsize = 256)', '\\n', 'final training loss: 0.0003', '\\n', 'final validation loss:\n0.0011', '\\n', 'final shape weighted accuracy: 0.9998', '\\n', 'final color\nweighted accuracy: 0.9999', '\\n', 'final harmonic weighted accuracy: 0.9998',\n'\\n', '\\n', 'SPR_BENCH (hidden size = 512)', '\\n', 'final training loss:\n0.0002', '\\n', 'final validation loss: 0.0006', '\\n', 'final shape weighted\naccuracy: 1.0000', '\\n', 'final color weighted accuracy: 1.0000', '\\n', 'final\nharmonic weighted accuracy: 1.0000', '\\n', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
