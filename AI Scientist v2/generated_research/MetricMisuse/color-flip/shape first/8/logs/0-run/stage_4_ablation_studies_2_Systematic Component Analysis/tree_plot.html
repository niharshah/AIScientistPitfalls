<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[1, 4], [4, 8]], "layout": [[0.0, 0.0], [0.1111111111111111, 0.0], [0.2222222222222222, 0.0], [0.3333333333333333, 0.0], [0.1111111111111111, 0.5], [0.4444444444444444, 0.0], [0.5555555555555556, 0.0], [0.6666666666666666, 0.0], [0.1111111111111111, 1.0], [0.7777777777777778, 0.0], [0.8888888888888888, 0.0], [1.0, 0.0]], "plan": ["Ablation name: Remove Projection Head (\u201cNo-Proj\u201d Ablation). Below is a compact\nre-write of the original script that runs the \u201cNo-Proj\u201d ablation only\n(projection head removed, classifier resized to 96 d).  Results are logged under\nexperiment_data['no_proj']['SPR_BENCH'] and saved to working/experiment_data.npy\nexactly as required.", "Ablation name: No-Position-Embedding. We recreate the original pipeline but swap\nthe encoder for a No-Position-Embedding variant whose forward pass feeds pure\ntoken embeddings into the Transformer (self-attention alone must now model\norder).  Contrastive pre-training and CCWA fine-tuning remain unchanged so we\ncan directly compare with the baseline.  All bookkeeping is placed under the\nablation key \u201cNoPos\u201d and saved to experiment_data.npy exactly as required.", "Ablation name: Freeze-Encoder (No-Fine-Tune). We pre-train the encoder exactly\nas in the baseline, then freeze every encoder parameter (requires_grad = False)\nand only train the final linear layer. The optimizer therefore receives\nclf.fc.parameters() only. During fine-tuning we keep the encoder in eval mode to\ndisable dropout-like behaviour, but gradients still flow to the classifier. All\nmetrics, losses and other artefacts are logged under an experiment_data\ndictionary keyed by the ablation name \u201cFreezeEncoder\u201d and finally saved to\nworking/experiment_data.npy.", "Ablation name: No-Pretraining (Supervised-Only). We keep the full\ndata/utility/model pipeline from the baseline but entirely delete the SimCLR\ncontrastive-pre-training stage.   The encoder is now initialized randomly and\ntrained only with supervised cross-entropy, reusing the exact fine-tuning loop.\nAll logs are stored under the ablation key \u201cno_pretrain\u201d following the required\nexperiment_data structure and saved to working/experiment_data.npy.", "The original experiment logged the weighted-accuracy metric under the obsolete\nname \u200b\u201cCCWA\u201d, so all downstream analysis modules that expected \u201cCAWA\u201d silently\nreceived an empty list.   I add a correct Complexity-Adjusted Weighted Accuracy\n(CAWA) function, record both train and validation CAWA each epoch, and rename\nevery occurrence of the metric key accordingly.   While touching the metric\ncode, I also harden the SimCLR loss by masking the diagonal with a very large\nnegative value (-9e15) to avoid numerical overflow.   Everything is now saved in\nexperiment_data and printed every epoch so later stages can read the expected\nCAWA values without crashing.", "Ablation name: No-Augmentation-Contrastive. We implement the \u201cNo-Augmentation-\nContrastive\u201d ablation by replacing the augmentation pipeline with an identity\ntransform: both contrastive \u201cviews\u201d are the untouched, token-encoded sequence.\nEverything else (datasets, model, training, logging and saving) is kept\nidentical to the baseline. The results are stored under the ablation key\n\u201cNoAugContrastive\u201d.", "Ablation name: CLS-POOL ONLY. The CLS-POOL ONLY ablation removes the\nAdaptiveAvgPool1d layer and prepends a dedicated \u201c<CLS>\u201d token to every\nsequence. During the forward pass we use the hidden state of this first position\n(h[:,0,:]) as the entire sequence representation. This change is implemented by\n(1) adding \u201c<CLS>\u201d to the vocabulary and modifying the encoder, (2) altering the\nencode/augmentation routines to insert the CLS token, and (3) changing the\nexperiment_data key to \u201cCLS_POOL_ONLY\u201d. All other training, evaluation, and\nlogging code remain identical.", "Ablation name: No-Transformer-Encoder (Embedding-Only). Below is an ablation run\nthat sets nlayers = 0, so the encoder consists of token/position embeddings,\npooling, and projection head only\u2014no self-attention blocks. All bookkeeping\nfollows the instructed `experiment_data` format and is saved to\n`experiment_data.npy`.", "A steep fine-tuning learning-rate on the already pre-trained encoder was causing\nthe network to diverge in the last epochs.   The fix keeps the encoder frozen\nfor a warm-up period, then unfreezes it with a much smaller learning-rate and a\nscheduler; this stabilises optimisation and prevents the late-epoch collapse.\nThe script below adds: (1) warm-up freezing, (2) two parameter groups\n(classifier lr = 2e-3, encoder lr = 5e-4), (3) a ReduceLROnPlateau scheduler\nwith patience, (4) early-stopping, while keeping all GPU-handling, metric\ntracking and saving logic compliant with the given guidelines.", "Ablation name: BiLSTM-Encoder. Here is the BiLSTM ablation: we keep the same\ndata pipeline, SimCLR pre-training and linear probe fine-tuning, but replace the\nTransformer encoder with a multi-layer bidirectional LSTM that produces the same\nhidden dimensionality before the 128-d projection head. This lets us isolate the\nbenefit of self-attention vs. any contextual encoder. All bookkeeping is saved\nunder the ablation key \u201cBiLSTM\u201d.", "Ablation name: Fixed-Sinusoidal-Position-Embedding. Below is the single-file\nprogram that keeps every pipeline component unchanged except that the learnable\n`nn.Parameter` positional embedding is replaced by the fixed sinusoidal encoding\n(non-trainable) described in the original Transformer paper.", "Ablation name: Mask-Only Augmentation (Structure-Preserving). The ablation\nrequires changing the contrastive pre-training views so that they are generated\nexclusively through 15 % random masking while keeping token order and sentence\nlength untouched. All other pipeline components (data handling, model, training,\nevaluation, logging) remain as in the baseline. The experiment_data dictionary\nis now keyed by the ablation name (\u2018mask_only_structure_preserving\u2019) and the\ndataset name (\u2018SPR_BENCH\u2019) so results are saved to the mandatory\n\u2018experiment_data.npy\u2019. The code below is fully self-contained and executable."], "code": ["# ---------------- No-Proj ablation: full, runnable script --------------------\nimport os, random, math, pathlib, datetime, numpy as np, torch, warnings\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nwarnings.filterwarnings(\"ignore\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n# ------------------------- folders ------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# ---------------------- SPR benchmark loader --------------------------------\ndef load_spr_bench(root: pathlib.Path):\n    from datasets import load_dataset\n\n    def _load(fname):  # every csv is its own split\n        return load_dataset(\n            \"csv\", data_files=str(root / fname), split=\"train\", cache_dir=\".cache_dsets\"\n        )\n\n    return {\n        \"train\": _load(\"train.csv\"),\n        \"dev\": _load(\"dev.csv\"),\n        \"test\": _load(\"test.csv\"),\n    }\n\n\ndef try_load_spr():\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(\"Found SPR_BENCH at\", p)\n            return load_spr_bench(p)\n    return None\n\n\nreal_dset = try_load_spr()\n# --------------------- synthetic fallback -----------------------------------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif real_dset is None:\n    print(\"Using synthetic data\")\n    real_dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n\n# ------------------------- CCWA metric --------------------------------------\ndef count_shape_variety(s):\n    return len({tok[0] for tok in s.split() if tok})\n\n\ndef count_color_variety(s):\n    return len({tok[1] for tok in s.split() if len(tok) > 1})\n\n\ndef ccwa_metric(seqs, ytrue, ypred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    return (\n        sum(wi if t == p else 0 for wi, t, p in zip(w, ytrue, ypred)) / sum(w)\n        if sum(w)\n        else 0.0\n    )\n\n\n# ---------------------------- vocab -----------------------------------------\nPAD, UNK, MASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(rows):\n    vocab = set()\n    [vocab.update(r[\"sequence\"].split()) for r in rows]\n    itos = [PAD, UNK, MASK] + sorted(vocab)\n    stoi = {t: i for i, t in enumerate(itos)}\n    return stoi, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size, len_max = len(stoi), 20\n\n\ndef encode(seq):\n    ids = [stoi.get(t, stoi[UNK]) for t in seq.split()][:len_max]\n    ids += [stoi[PAD]] * (len_max - len(ids))\n    return ids\n\n\n# -------------------------- datasets ----------------------------------------\nclass ContrastiveSPR(Dataset):\n    def __init__(s, rows):\n        s.rows = rows\n\n    def _aug(s, ids):\n        toks = [t for t in ids if t != stoi[PAD]]\n        if random.random() < 0.3 and len(toks) > 1:\n            toks.pop(random.randrange(len(toks)))\n        if random.random() < 0.3 and len(toks) > 2:\n            i = random.randrange(len(toks) - 1)\n            toks[i], toks[i + 1] = toks[i + 1], toks[i]\n        if random.random() < 0.3:\n            toks += random.sample(toks, k=1)\n        toks = [stoi[MASK] if random.random() < 0.15 else t for t in toks]\n        return torch.tensor(encode(\" \".join(itos[t] for t in toks)), dtype=torch.long)\n\n    def __len__(s):\n        return len(s.rows)\n\n    def __getitem__(s, i):\n        ids = torch.tensor(encode(s.rows[i][\"sequence\"]), dtype=torch.long)\n        return {\"v1\": s._aug(ids), \"v2\": s._aug(ids)}\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(s, rows):\n        s.rows = rows\n\n    def __len__(s):\n        return len(s.rows)\n\n    def __getitem__(s, i):\n        r = s.rows[i]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# ----------------------- No-Proj encoder ------------------------------------\nclass TransEncoder(nn.Module):\n    def __init__(s, vocab, d_model=96, nhead=6, nlayers=3):\n        super().__init__()\n        s.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        s.pos = nn.Parameter(torch.randn(len_max, d_model))\n        layer = nn.TransformerEncoderLayer(\n            d_model, nhead, 4 * d_model, batch_first=True\n        )\n        s.tr = nn.TransformerEncoder(layer, nlayers)\n        s.pool = nn.AdaptiveAvgPool1d(1)\n        # NO projection head here (ablation)\n\n    def forward(s, x):\n        x = s.emb(x.to(device)) + s.pos[: x.size(1)].unsqueeze(0)\n        h = s.tr(x)  # B,L,D\n        h = s.pool(h.transpose(1, 2)).squeeze(-1)  # B,D\n        return torch.tanh(h)  # B,96\n\n\nclass Classifier(nn.Module):\n    def __init__(s, enc, n_cls):\n        super().__init__()\n        s.enc = enc\n        s.fc = nn.Linear(96, n_cls)\n\n    def forward(s, x):\n        return s.fc(s.enc(x))\n\n\n# --------------------- SimCLR loss ------------------------------------------\ndef simclr_loss(z1, z2, temp=0.5):\n    B = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    z = nn.functional.normalize(z, 1)\n    sim = torch.mm(z, z.T) / temp\n    sim.masked_fill_(torch.eye(2 * B, dtype=torch.bool, device=z.device), -1e9)\n    target = (torch.arange(2 * B, device=z.device) + B) % (2 * B)\n    return nn.functional.cross_entropy(sim, target)\n\n\n# ------------------------ dataloaders ---------------------------------------\nB_PRE, B_FT = 256, 256\npre_dl = DataLoader(\n    ContrastiveSPR(real_dset[\"train\"]), batch_size=B_PRE, shuffle=True, drop_last=True\n)\ntrain_dl = DataLoader(SupervisedSPR(real_dset[\"train\"]), batch_size=B_FT, shuffle=True)\ndev_dl = DataLoader(SupervisedSPR(real_dset[\"dev\"]), batch_size=B_FT)\n\n# ------------------------ bookkeeping dict ----------------------------------\nexperiment_data = {\n    \"no_proj\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_CCWA\": [], \"val_CCWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n# ---------------------- training pipeline -----------------------------------\nencoder = TransEncoder(vocab_size).to(device)\nopt_pre = torch.optim.Adam(encoder.parameters(), 1e-3)\nfor ep in range(1, 7):\n    encoder.train()\n    run = 0.0\n    for b in pre_dl:\n        loss = simclr_loss(encoder(b[\"v1\"]), encoder(b[\"v2\"]))\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        run += loss.item()\n    print(f\"[Pre] epoch {ep}: loss {run/len(pre_dl):.4f}\")\n\nclf = Classifier(encoder, len(set(r[\"label\"] for r in real_dset[\"train\"]))).to(device)\nopt_ft = torch.optim.Adam(clf.parameters(), 2e-3)\ncrit = nn.CrossEntropyLoss()\n\n\ndef evaluate(m, dl):\n    m.eval()\n    preds, gts, seqs, loss = [], [], [], 0.0\n    with torch.no_grad():\n        for bt in dl:\n            ids, lab = bt[\"ids\"].to(device), bt[\"label\"].to(device)\n            log = m(ids)\n            loss += crit(log, lab).item()\n            preds += log.argmax(1).cpu().tolist()\n            gts += lab.cpu().tolist()\n            seqs += bt[\"seq\"]\n    return loss / len(dl), ccwa_metric(seqs, gts, preds), preds, gts\n\n\nfor ep in range(1, 11):\n    clf.train()\n    run = 0.0\n    steps = 0\n    for bt in train_dl:\n        ids, lab = bt[\"ids\"].to(device), bt[\"label\"].to(device)\n        loss = crit(clf(ids), lab)\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        run += loss.item()\n        steps += 1\n    tr_loss = run / steps\n    val_loss, ccwa, pred, gt = evaluate(clf, dev_dl)\n    ts = datetime.datetime.now().isoformat()\n    ed = experiment_data[\"no_proj\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(tr_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train_CCWA\"].append(None)\n    ed[\"metrics\"][\"val_CCWA\"].append(ccwa)\n    ed[\"predictions\"].append(pred)\n    ed[\"ground_truth\"].append(gt)\n    ed[\"timestamps\"].append(ts)\n    print(f\"[FT] ep {ep}: train {tr_loss:.4f} | val {val_loss:.4f} | CCWA {ccwa:.4f}\")\n\n# ------------------------ save ----------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# ---------------- No-Position-Embedding ablation experiment -----------------\nimport os, random, math, pathlib, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ---------- mandatory working directory ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device -------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- helper to load benchmark -------------------------\ndef load_spr_bench(root: pathlib.Path):\n    try:\n        from datasets import load_dataset\n    except ImportError:\n        import subprocess, sys\n\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"datasets\"])\n        from datasets import load_dataset\n\n    def _load(csv_name):  # each csv is an entire split\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {\n        \"train\": _load(\"train.csv\"),\n        \"dev\": _load(\"dev.csv\"),\n        \"test\": _load(\"test.csv\"),\n    }\n\n\ndef try_load_spr():\n    for cand in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (cand / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at {cand}\")\n            return load_spr_bench(cand)\n    return None\n\n\nreal_dset = try_load_spr()\n\n# -------------- synthetic fallback ---------------------------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif real_dset is None:\n    print(\"Real data not found \u2013 using synthetic fallback.\")\n    real_dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n# -------------- CCWA metric ----------------------------------\nPAD, UNK, MASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef ccwa_metric(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# -------------- vocabulary -----------------------------------\ndef build_vocab(rows):\n    vocab = set()\n    for r in rows:\n        vocab.update(r[\"sequence\"].split())\n    itos = [PAD, UNK, MASK] + sorted(vocab)\n    return {t: i for i, t in enumerate(itos)}, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size, MAX_LEN = len(stoi), 20\n\n\ndef encode(seq):\n    ids = [stoi.get(tok, stoi[UNK]) for tok in seq.split()][:MAX_LEN]\n    ids += [stoi[PAD]] * (MAX_LEN - len(ids))\n    return ids\n\n\n# -------------- datasets -------------------------------------\nclass ContrastiveSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def _augment(self, ids):\n        toks = [t for t in ids if t != stoi[PAD]]\n        if random.random() < 0.3 and len(toks) > 1:\n            toks.pop(random.randrange(len(toks)))  # deletion\n        if random.random() < 0.3 and len(toks) > 2:\n            i = random.randrange(len(toks) - 1)\n            toks[i], toks[i + 1] = toks[i + 1], toks[i]  # swap\n        if random.random() < 0.3:\n            toks += random.sample(toks, k=1)  # dup\n        toks = [stoi[MASK] if random.random() < 0.15 else t for t in toks]  # mask\n        return torch.tensor(encode(\" \".join(itos[t] for t in toks)), dtype=torch.long)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        base_ids = torch.tensor(encode(self.rows[idx][\"sequence\"]), dtype=torch.long)\n        return {\"view1\": self._augment(base_ids), \"view2\": self._augment(base_ids)}\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# -------------- No-Position TransEncoder ---------------------\nclass TransEncoderNoPos(nn.Module):\n    def __init__(self, vocab, d_model=96, nhead=6, nlayers=3):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=4 * d_model, batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(enc_layer, nlayers)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(d_model, 128)\n\n    def forward(self, x):\n        h = self.transformer(self.emb(x.to(device)))  # <-- no positional term added\n        h = self.pool(h.transpose(1, 2)).squeeze(-1)\n        return torch.tanh(self.proj(h))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, n_cls):\n        super().__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(128, n_cls)\n\n    def forward(self, x):\n        return self.fc(self.encoder(x))\n\n\n# -------------- SimCLR loss ----------------------------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    B = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    z = nn.functional.normalize(z, dim=1)\n    sim = z @ z.T / temperature\n    sim.masked_fill_(torch.eye(2 * B, dtype=torch.bool, device=z.device), -1e9)\n    positives = (torch.arange(2 * B, device=z.device) + B) % (2 * B)\n    return nn.functional.cross_entropy(sim, positives)\n\n\n# -------------- bookkeeping dict ------------------------------\nexperiment_data = {\n    \"NoPos\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_CCWA\": [], \"val_CCWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n# -------------- data loaders ---------------------------------\nBATCH_PRE, BATCH_FT = 256, 256\npre_dl = DataLoader(\n    ContrastiveSPR(real_dset[\"train\"]),\n    batch_size=BATCH_PRE,\n    shuffle=True,\n    drop_last=True,\n)\ntrain_dl = DataLoader(\n    SupervisedSPR(real_dset[\"train\"]), batch_size=BATCH_FT, shuffle=True\n)\ndev_dl = DataLoader(SupervisedSPR(real_dset[\"dev\"]), batch_size=BATCH_FT, shuffle=False)\n\n# -------------- pre-training ---------------------------------\nencoder = TransEncoderNoPos(vocab_size).to(device)\nopt_pre = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nPRE_EPOCHS = 6\nfor ep in range(1, PRE_EPOCHS + 1):\n    encoder.train()\n    running = 0.0\n    for batch in pre_dl:\n        v1, v2 = batch[\"view1\"].to(device), batch[\"view2\"].to(device)\n        loss = simclr_loss(encoder(v1), encoder(v2))\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        running += loss.item()\n    print(f\"Pre-train epoch {ep}: contrastive_loss={running/len(pre_dl):.4f}\")\n\n# -------------- fine-tuning ----------------------------------\nn_classes = len(set(r[\"label\"] for r in real_dset[\"train\"]))\nclf = Classifier(encoder, n_classes).to(device)\nopt_ft = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\nFT_EPOCHS = 10\n\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, gts, seqs, loss_acc = [], [], [], 0.0\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss_acc += loss.item()\n            preds.extend(logits.argmax(1).cpu().tolist())\n            gts.extend(batch[\"label\"].cpu().tolist())\n            seqs.extend(batch[\"seq\"])\n    return loss_acc / len(loader), ccwa_metric(seqs, gts, preds), preds, gts\n\n\nfor ep in range(1, FT_EPOCHS + 1):\n    clf.train()\n    tr_loss, steps = 0.0, 0\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        loss = criterion(clf(batch[\"ids\"]), batch[\"label\"])\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        tr_loss += loss.item()\n        steps += 1\n    tr_loss /= steps\n    val_loss, val_ccwa, val_pred, val_gt = evaluate(clf, dev_dl)\n    ts = datetime.datetime.now().isoformat()\n\n    exp = experiment_data[\"NoPos\"][\"SPR_BENCH\"]\n    exp[\"losses\"][\"train\"].append(tr_loss)\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"train_CCWA\"].append(None)\n    exp[\"metrics\"][\"val_CCWA\"].append(val_ccwa)\n    exp[\"predictions\"].append(val_pred)\n    exp[\"ground_truth\"].append(val_gt)\n    exp[\"timestamps\"].append(ts)\n\n    print(\n        f\"Epoch {ep}: train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} | CCWA={val_ccwa:.4f}\"\n    )\n\n# -------------- save -----------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved all metrics to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "# ------------------------------ Freeze-Encoder Ablation ---------------------------------\nimport os, random, math, pathlib, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ---------- mandatory working directory -------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device ----------------------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- helpers to load original benchmark ------------------------------------------\ndef load_spr_bench(root: pathlib.Path):\n    try:\n        from datasets import load_dataset\n    except ImportError:\n        import subprocess, sys\n\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"datasets\"])\n        from datasets import load_dataset\n\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {\n        \"train\": _load(\"train.csv\"),\n        \"dev\": _load(\"dev.csv\"),\n        \"test\": _load(\"test.csv\"),\n    }\n\n\ndef try_load_spr():\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at {p}\")\n            return load_spr_bench(p)\n    return None\n\n\nreal_dset = try_load_spr()\n\n# ---------- synthetic fallback -----------------------------------------------------------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif real_dset is None:\n    print(\"Real data not found \u2013 using synthetic fallback.\")\n    real_dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n\n# ---------- CCWA metric -----------------------------------------------------------------\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef ccwa_metric(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    corr = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# ---------- vocabulary ------------------------------------------------------------------\nPAD, UNK, MASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(rows):\n    vocab = set()\n    for r in rows:\n        vocab.update(r[\"sequence\"].split())\n    itos = [PAD, UNK, MASK] + sorted(vocab)\n    return {t: i for i, t in enumerate(itos)}, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size, MAX_LEN = len(stoi), 20\n\n\ndef encode(seq: str):\n    ids = [stoi.get(tok, stoi[UNK]) for tok in seq.split()][:MAX_LEN]\n    ids += [stoi[PAD]] * (MAX_LEN - len(ids))\n    return ids\n\n\n# ---------- datasets --------------------------------------------------------------------\nclass ContrastiveSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def _augment(self, ids):\n        toks = [t for t in ids if t != stoi[PAD]]\n        if random.random() < 0.3 and len(toks) > 1:\n            toks.pop(random.randrange(len(toks)))\n        if random.random() < 0.3 and len(toks) > 2:\n            i = random.randrange(len(toks) - 1)\n            toks[i], toks[i + 1] = toks[i + 1], toks[i]\n        if random.random() < 0.3:\n            toks += random.sample(toks, k=1)\n        toks = [stoi[MASK] if random.random() < 0.15 else t for t in toks]\n        return torch.tensor(encode(\" \".join(itos[t] for t in toks)), dtype=torch.long)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        base = torch.tensor(encode(self.rows[idx][\"sequence\"]), dtype=torch.long)\n        return {\"view1\": self._augment(base), \"view2\": self._augment(base)}\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# ---------- model -----------------------------------------------------------------------\nclass TransEncoder(nn.Module):\n    def __init__(self, vocab, d_model=96, nhead=6, nlayers=3):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        self.pos = nn.Parameter(torch.randn(MAX_LEN, d_model))\n        layer = nn.TransformerEncoderLayer(\n            d_model, nhead, 4 * d_model, batch_first=True\n        )\n        self.tr = nn.TransformerEncoder(layer, nlayers)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(d_model, 128)\n\n    def forward(self, x):\n        x = self.emb(x.to(device)) + self.pos[: x.size(1)].unsqueeze(0)\n        h = self.tr(x)\n        h = self.pool(h.transpose(1, 2)).squeeze(-1)\n        return torch.tanh(self.proj(h))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, n_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        return self.fc(self.encoder(x))\n\n\n# ---------- InfoNCE loss ---------------------------------------------------------------\ndef simclr_loss(z1, z2, temp=0.5):\n    B = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    z = nn.functional.normalize(z, dim=1)\n    sim = torch.matmul(z, z.T) / temp\n    sim.masked_fill_(torch.eye(2 * B, device=z.device, dtype=torch.bool), -1e9)\n    pos = (torch.arange(2 * B, device=z.device) + B) % (2 * B)\n    return nn.functional.cross_entropy(sim, pos)\n\n\n# ---------- bookkeeping dict -----------------------------------------------------------\nexperiment_data = {\n    \"FreezeEncoder\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_CCWA\": [], \"val_CCWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n# ---------- data loaders ---------------------------------------------------------------\nBATCH_PRE = 256\nBATCH_FT = 256\npre_dl = DataLoader(\n    ContrastiveSPR(real_dset[\"train\"]),\n    batch_size=BATCH_PRE,\n    shuffle=True,\n    drop_last=True,\n)\ntrain_dl = DataLoader(\n    SupervisedSPR(real_dset[\"train\"]), batch_size=BATCH_FT, shuffle=True\n)\ndev_dl = DataLoader(SupervisedSPR(real_dset[\"dev\"]), batch_size=BATCH_FT, shuffle=False)\n\n# ---------- contrastive pre-training ----------------------------------------------------\nencoder = TransEncoder(vocab_size).to(device)\nopt_pre = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nPRE_EPOCHS = 6\nfor ep in range(1, PRE_EPOCHS + 1):\n    encoder.train()\n    run = 0.0\n    for b in pre_dl:\n        v1, v2 = b[\"view1\"].to(device), b[\"view2\"].to(device)\n        loss = simclr_loss(encoder(v1), encoder(v2))\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        run += loss.item()\n    print(f\"Pre-train epoch {ep}: loss={run/len(pre_dl):.4f}\")\n\n# ---------- build classifier & freeze encoder -------------------------------------------\nn_classes = len(set(r[\"label\"] for r in real_dset[\"train\"]))\nclf = Classifier(encoder, n_classes).to(device)\n\n# freeze\nfor p in clf.encoder.parameters():\n    p.requires_grad = False\nclf.encoder.eval()  # keep in eval mode\n\nopt_ft = torch.optim.Adam(clf.fc.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\nFT_EPOCHS = 10\n\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, gts, seqs, ls = [], [], [], 0.0\n    with torch.no_grad():\n        for b in loader:\n            ids = b[\"ids\"].to(device)\n            lbl = b[\"label\"].to(device)\n            logits = model(ids)\n            loss = criterion(logits, lbl)\n            ls += loss.item()\n            preds.extend(logits.argmax(1).cpu().tolist())\n            gts.extend(lbl.cpu().tolist())\n            seqs.extend(b[\"seq\"])\n    return ls / len(loader), ccwa_metric(seqs, gts, preds), preds, gts\n\n\n# ---------- fine-tuning (linear probe) --------------------------------------------------\nfor ep in range(1, FT_EPOCHS + 1):\n    clf.train()\n    train_loss, steps = 0.0, 0\n    for b in train_dl:\n        ids = b[\"ids\"].to(device)\n        lbl = b[\"label\"].to(device)\n        loss = criterion(clf(ids), lbl)\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        train_loss += loss.item()\n        steps += 1\n    train_loss /= steps\n    val_loss, val_ccwa, val_preds, val_gt = evaluate(clf, dev_dl)\n    ts = datetime.datetime.now().isoformat()\n\n    # log\n    exp = experiment_data[\"FreezeEncoder\"][\"SPR_BENCH\"]\n    exp[\"losses\"][\"train\"].append(train_loss)\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"train_CCWA\"].append(None)\n    exp[\"metrics\"][\"val_CCWA\"].append(val_ccwa)\n    exp[\"predictions\"].append(val_preds)\n    exp[\"ground_truth\"].append(val_gt)\n    exp[\"timestamps\"].append(ts)\n\n    print(\n        f\"Epoch {ep}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CCWA={val_ccwa:.4f}\"\n    )\n\n# ---------- save results ---------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved metrics to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "# -------------------------------------------------------------\n# No-Pretraining (Supervised-Only) Ablation\n# -------------------------------------------------------------\nimport os, random, math, pathlib, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ---------- mandatory working directory ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device -------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- helper : load real benchmark if available --------\ndef load_spr_bench(root: pathlib.Path):\n    try:\n        from datasets import load_dataset\n    except ImportError:\n        import subprocess, sys\n\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"datasets\"])\n        from datasets import load_dataset\n\n    def _ld(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {\"train\": _ld(\"train.csv\"), \"dev\": _ld(\"dev.csv\"), \"test\": _ld(\"test.csv\")}\n\n\ndef try_load_spr():\n    for root in (\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ):\n        if (root / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at {root}\")\n            return load_spr_bench(root)\n    return None\n\n\nreal_dset = try_load_spr()\n\n# ---------- synthetic fallback --------------------------------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif real_dset is None:\n    print(\"Real data not found \u2013 using synthetic fallback.\")\n    real_dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n\n# ---------- CCWA metric --------------------------------------\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef ccwa_metric(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    c = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) else 0.0\n\n\n# ---------- vocabulary ---------------------------------------\nPAD, UNK, MASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(rows):\n    vocab = set()\n    for r in rows:\n        vocab.update(r[\"sequence\"].split())\n    itos = [PAD, UNK, MASK] + sorted(vocab)\n    return {t: i for i, t in enumerate(itos)}, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size, MAX_LEN = len(stoi), 20\n\n\ndef encode(seq: str):\n    ids = [stoi.get(tok, stoi[UNK]) for tok in seq.split()][:MAX_LEN]\n    ids += [stoi[PAD]] * (MAX_LEN - len(ids))\n    return ids\n\n\n# ---------- datasets -----------------------------------------\nclass SupervisedSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# ---------- model --------------------------------------------\nclass TransEncoder(nn.Module):\n    def __init__(self, vocab, d_model=96, nhead=6, nlayers=3):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        self.pos = nn.Parameter(torch.randn(MAX_LEN, d_model))\n        enc = nn.TransformerEncoderLayer(d_model, nhead, 4 * d_model, batch_first=True)\n        self.transformer = nn.TransformerEncoder(enc, nlayers)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(d_model, 128)\n\n    def forward(self, x):\n        x = self.emb(x.to(device)) + self.pos[: x.size(1)].unsqueeze(0)\n        h = self.transformer(x)\n        h = self.pool(h.transpose(1, 2)).squeeze(-1)\n        return torch.tanh(self.proj(h))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, n_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        return self.fc(self.encoder(x))\n\n\n# ---------- loaders ------------------------------------------\nBATCH = 256\ntrain_ds = SupervisedSPR(real_dset[\"train\"])\ndev_ds = SupervisedSPR(real_dset[\"dev\"])\ntrain_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\ndev_dl = DataLoader(dev_ds, batch_size=BATCH, shuffle=False)\n\n# ---------- experiment bookkeeping ---------------------------\nexperiment_data = {\n    \"no_pretrain\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_CCWA\": [], \"val_CCWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n# ---------- supervised training ------------------------------\nencoder = TransEncoder(vocab_size).to(device)  # random init, no pretrain\nn_classes = len(set(r[\"label\"] for r in real_dset[\"train\"]))\nclf = Classifier(encoder, n_classes).to(device)\nopt = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\nEPOCHS = 10\n\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, gts, seqs, loss_tot = [], [], [], 0.0\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss_tot += loss.item()\n            preds.extend(logits.argmax(1).cpu().tolist())\n            gts.extend(batch[\"label\"].cpu().tolist())\n            seqs.extend(batch[\"seq\"])\n    return loss_tot / len(loader), ccwa_metric(seqs, gts, preds), preds, gts\n\n\nfor ep in range(1, EPOCHS + 1):\n    clf.train()\n    tr_loss, steps = 0.0, 0\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        loss = criterion(clf(batch[\"ids\"]), batch[\"label\"])\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        tr_loss += loss.item()\n        steps += 1\n    tr_loss /= steps\n\n    val_loss, val_ccwa, val_preds, val_gt = evaluate(clf, dev_dl)\n    timestamp = datetime.datetime.now().isoformat()\n\n    # log\n    bench = experiment_data[\"no_pretrain\"][\"SPR_BENCH\"]\n    bench[\"losses\"][\"train\"].append(tr_loss)\n    bench[\"losses\"][\"val\"].append(val_loss)\n    bench[\"metrics\"][\"train_CCWA\"].append(None)\n    bench[\"metrics\"][\"val_CCWA\"].append(val_ccwa)\n    bench[\"predictions\"].append(val_preds)\n    bench[\"ground_truth\"].append(val_gt)\n    bench[\"timestamps\"].append(timestamp)\n\n    print(\n        f\"Epoch {ep}: train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} | CCWA={val_ccwa:.4f}\"\n    )\n\n# ---------- save ---------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved metrics to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "import os, random, math, pathlib, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ---------------------------------------------------------------------\n# mandatory working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# device handling\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# ---------------------- Data utilities --------------------------------\ndef load_spr_bench(root: pathlib.Path):\n    from datasets import load_dataset\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {\n        \"train\": _load(\"train.csv\"),\n        \"dev\": _load(\"dev.csv\"),\n        \"test\": _load(\"test.csv\"),\n    }\n\n\ndef try_load_spr():\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at {p}\")\n            return load_spr_bench(p)\n    return None\n\n\ndset = try_load_spr()\n\n# ---------------- synthetic fallback if no data ------------------------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif dset is None:\n    print(\"Real SPR_BENCH not found, using synthetic data.\")\n    dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n# ---------------------------------------------------------------------\n# ------------- Complexity-Adjusted Weighted Accuracy ------------------\nPAD, UNK, MASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef cawa_metric(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------------------------------------------------------------------\n# ------------------------ vocabulary ----------------------------------\ndef build_vocab(rows):\n    vocab = set()\n    for r in rows:\n        vocab.update(r[\"sequence\"].split())\n    itos = [PAD, UNK, MASK] + sorted(vocab)\n    return {t: i for i, t in enumerate(itos)}, itos\n\n\nstoi, itos = build_vocab(dset[\"train\"])\nvocab_size, MAX_LEN = len(stoi), 20\n\n\ndef encode(seq: str):\n    ids = [stoi.get(tok, stoi[UNK]) for tok in seq.split()][:MAX_LEN]\n    ids += [stoi[PAD]] * (MAX_LEN - len(ids))\n    return ids\n\n\n# ---------------------------------------------------------------------\n# ----------------------- datasets  ------------------------------------\nclass ContrastiveSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def _augment(self, ids):\n        toks = [t for t in ids if t != stoi[PAD]]\n        if random.random() < 0.3 and len(toks) > 1:\n            toks.pop(random.randrange(len(toks)))\n        if random.random() < 0.3 and len(toks) > 2:\n            i = random.randrange(len(toks) - 1)\n            toks[i], toks[i + 1] = toks[i + 1], toks[i]\n        if random.random() < 0.3:\n            toks += random.sample(toks, k=1)\n        toks = [stoi[MASK] if random.random() < 0.15 else t for t in toks]\n        return torch.tensor(encode(\" \".join(itos[t] for t in toks)), dtype=torch.long)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        base_ids = torch.tensor(encode(self.rows[idx][\"sequence\"]), dtype=torch.long)\n        return {\"view1\": self._augment(base_ids), \"view2\": self._augment(base_ids)}\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# ---------------------------------------------------------------------\n# -------------------- model definitions ------------------------------\nclass TransEncoderNoPos(nn.Module):\n    def __init__(self, vocab, d_model=96, nhead=6, nlayers=3):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=4 * d_model, batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(enc_layer, nlayers)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(d_model, 128)\n\n    def forward(self, x):\n        h = self.transformer(self.emb(x.to(device)))\n        h = self.pool(h.transpose(1, 2)).squeeze(-1)\n        return torch.tanh(self.proj(h))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, n_cls):\n        super().__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(128, n_cls)\n\n    def forward(self, x):\n        return self.fc(self.encoder(x))\n\n\n# ---------------------------------------------------------------------\n# ---------------------- SimCLR loss ----------------------------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    B = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    z = nn.functional.normalize(z, dim=1)\n    sim = z @ z.T / temperature\n    sim.masked_fill_(torch.eye(2 * B, dtype=torch.bool, device=z.device), -9e15)\n    positives = (torch.arange(2 * B, device=z.device) + B) % (2 * B)\n    return nn.functional.cross_entropy(sim, positives)\n\n\n# ---------------------------------------------------------------------\n# --------------------- experiment bookkeeping ------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_CAWA\": [], \"val_CAWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n# ---------------------------------------------------------------------\n# --------------------------- DataLoaders -----------------------------\nBATCH_PRE, BATCH_FT = 256, 256\npre_dl = DataLoader(\n    ContrastiveSPR(dset[\"train\"]), batch_size=BATCH_PRE, shuffle=True, drop_last=True\n)\ntrain_dl = DataLoader(SupervisedSPR(dset[\"train\"]), batch_size=BATCH_FT, shuffle=True)\ndev_dl = DataLoader(SupervisedSPR(dset[\"dev\"]), batch_size=BATCH_FT, shuffle=False)\n\n# ---------------------------------------------------------------------\n# --------------------------- pre-training ----------------------------\nencoder = TransEncoderNoPos(vocab_size).to(device)\nopt_pre = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nPRE_EPOCHS = 6\nfor ep in range(1, PRE_EPOCHS + 1):\n    encoder.train()\n    run = 0.0\n    for batch in pre_dl:\n        v1, v2 = batch[\"view1\"].to(device), batch[\"view2\"].to(device)\n        loss = simclr_loss(encoder(v1), encoder(v2))\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        run += loss.item()\n    print(f\"Pre-train epoch {ep}: contrastive_loss={run/len(pre_dl):.4f}\")\n\n# ---------------------------------------------------------------------\n# --------------------------- fine-tuning -----------------------------\nn_classes = len(set(r[\"label\"] for r in dset[\"train\"]))\nclf = Classifier(encoder, n_classes).to(device)\nopt_ft = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\nFT_EPOCHS = 10\n\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, gts, seqs, loss_acc = [], [], [], 0.0\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss_acc += loss.item()\n            preds.extend(logits.argmax(1).cpu().tolist())\n            gts.extend(batch[\"label\"].cpu().tolist())\n            seqs.extend(batch[\"seq\"])\n    return (loss_acc / len(loader), cawa_metric(seqs, gts, preds), preds, gts)\n\n\nfor ep in range(1, FT_EPOCHS + 1):\n    clf.train()\n    tr_loss, tr_preds, tr_gts, tr_seqs = 0.0, [], [], []\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        logits = clf(batch[\"ids\"])\n        loss = criterion(logits, batch[\"label\"])\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        tr_loss += loss.item()\n        tr_preds.extend(logits.argmax(1).cpu().tolist())\n        tr_gts.extend(batch[\"label\"].cpu().tolist())\n        tr_seqs.extend(batch[\"seq\"])\n    tr_loss /= len(train_dl)\n    train_cawa = cawa_metric(tr_seqs, tr_gts, tr_preds)\n\n    val_loss, val_cawa, val_pred, val_gt = evaluate(clf, dev_dl)\n    ts = datetime.datetime.now().isoformat()\n\n    exp = experiment_data[\"SPR_BENCH\"]\n    exp[\"losses\"][\"train\"].append(tr_loss)\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"train_CAWA\"].append(train_cawa)\n    exp[\"metrics\"][\"val_CAWA\"].append(val_cawa)\n    exp[\"predictions\"].append(val_pred)\n    exp[\"ground_truth\"].append(val_gt)\n    exp[\"timestamps\"].append(ts)\n\n    print(\n        f\"Epoch {ep}: train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} | \"\n        f\"train_CAWA={train_cawa:.4f} | val_CAWA={val_cawa:.4f}\"\n    )\n\n# ---------------------------------------------------------------------\n# --------------------------- save results ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved experiment data to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "# -------------------------------------------------------------\n# No-Augmentation-Contrastive ablation \u2013 complete experiment run\n# -------------------------------------------------------------\nimport os, random, math, pathlib, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ---------- mandatory working directory ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device -------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- utility to (try to) load the real benchmark -------\ndef load_spr_bench(root: pathlib.Path):\n    try:\n        from datasets import load_dataset\n    except ImportError:\n        import subprocess, sys\n\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"datasets\"])\n        from datasets import load_dataset\n\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {\n        \"train\": _load(\"train.csv\"),\n        \"dev\": _load(\"dev.csv\"),\n        \"test\": _load(\"test.csv\"),\n    }\n\n\ndef try_load_spr():\n    for root in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (root / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at {root}\")\n            return load_spr_bench(root)\n    return None\n\n\nreal_dset = try_load_spr()\n\n# ---------- synthetic fallback --------------------------------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif real_dset is None:\n    print(\"Real data not found \u2013 using synthetic fallback.\")\n    real_dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n\n# ---------- CCWA metric helpers -------------------------------\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef ccwa_metric(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------- vocabulary ----------------------------------------\nPAD, UNK, MASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(rows):\n    vocab = set()\n    for r in rows:\n        vocab.update(r[\"sequence\"].split())\n    itos = [PAD, UNK, MASK] + sorted(vocab)\n    stoi = {t: i for i, t in enumerate(itos)}\n    return stoi, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size, MAX_LEN = len(stoi), 20\n\n\ndef encode(seq: str):\n    ids = [stoi.get(tok, stoi[UNK]) for tok in seq.split()][:MAX_LEN]\n    ids += [stoi[PAD]] * (MAX_LEN - len(ids))\n    return ids\n\n\n# ---------- datasets ------------------------------------------\nclass ContrastiveSPR(Dataset):\n    \"\"\"No-augmentation version: both views are identical.\"\"\"\n\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        ids = torch.tensor(encode(self.rows[idx][\"sequence\"]), dtype=torch.long)\n        return {\"view1\": ids, \"view2\": ids.clone()}\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# ---------- model ---------------------------------------------\nclass TransEncoder(nn.Module):\n    def __init__(self, vocab, d_model=96, nhead=6, nlayers=3):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        self.pos = nn.Parameter(torch.randn(MAX_LEN, d_model))\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, 4 * d_model, batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(enc_layer, nlayers)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(d_model, 128)\n\n    def forward(self, x):\n        x = self.emb(x.to(device)) + self.pos[: x.size(1)].unsqueeze(0)\n        h = self.transformer(x)\n        h = self.pool(h.transpose(1, 2)).squeeze(-1)\n        return torch.tanh(self.proj(h))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, n_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        return self.fc(self.encoder(x))\n\n\n# ---------- SimCLR / InfoNCE loss ------------------------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    B = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    z = nn.functional.normalize(z, dim=1)\n    sim = torch.matmul(z, z.T) / temperature\n    mask = torch.eye(2 * B, device=z.device, dtype=torch.bool)\n    sim.masked_fill_(mask, -1e9)\n    pos_idx = (torch.arange(2 * B, device=z.device) + B) % (2 * B)\n    return nn.functional.cross_entropy(sim, pos_idx)\n\n\n# ---------- experiment bookkeeping -----------------------------\nexperiment_data = {\n    \"NoAugContrastive\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_CCWA\": [], \"val_CCWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n# ---------- data loaders --------------------------------------\nBATCH_PRE, BATCH_FT = 256, 256\npre_dl = DataLoader(\n    ContrastiveSPR(real_dset[\"train\"]),\n    batch_size=BATCH_PRE,\n    shuffle=True,\n    drop_last=True,\n)\ntrain_dl = DataLoader(\n    SupervisedSPR(real_dset[\"train\"]), batch_size=BATCH_FT, shuffle=True\n)\ndev_dl = DataLoader(SupervisedSPR(real_dset[\"dev\"]), batch_size=BATCH_FT, shuffle=False)\n\n# ---------- pre-training --------------------------------------\nencoder = TransEncoder(vocab_size).to(device)\nopt_pre, PRE_EPOCHS = torch.optim.Adam(encoder.parameters(), 1e-3), 6\nfor ep in range(1, PRE_EPOCHS + 1):\n    encoder.train()\n    running = 0.0\n    for batch in pre_dl:\n        loss = simclr_loss(\n            encoder(batch[\"view1\"].to(device)), encoder(batch[\"view2\"].to(device))\n        )\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        running += loss.item()\n    print(f\"Pre-train epoch {ep}: contrastive_loss = {running/len(pre_dl):.4f}\")\n\n# ---------- fine-tuning ---------------------------------------\nn_classes = len({r[\"label\"] for r in real_dset[\"train\"]})\nclf, opt_ft = Classifier(encoder, n_classes).to(device), torch.optim.Adam(\n    encoder.parameters(), 2e-3\n)\ncriterion, FT_EPOCHS = nn.CrossEntropyLoss(), 10\n\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, gts, seqs, loss_sum = [], [], [], 0.0\n    with torch.no_grad():\n        for batch in loader:\n            batch_tensor = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch_tensor[\"ids\"])\n            loss = criterion(logits, batch_tensor[\"label\"])\n            loss_sum += loss.item()\n            preds.extend(logits.argmax(1).cpu().tolist())\n            gts.extend(batch_tensor[\"label\"].cpu().tolist())\n            seqs.extend(batch_tensor[\"seq\"])\n    return loss_sum / len(loader), ccwa_metric(seqs, gts, preds), preds, gts\n\n\nfor ep in range(1, FT_EPOCHS + 1):\n    clf.train()\n    train_loss, steps = 0.0, 0\n    for batch in train_dl:\n        bt = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        loss = criterion(clf(bt[\"ids\"]), bt[\"label\"])\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        train_loss += loss.item()\n        steps += 1\n    train_loss /= steps\n\n    val_loss, val_ccwa, val_preds, val_gt = evaluate(clf, dev_dl)\n    ts = datetime.datetime.now().isoformat()\n\n    ed = experiment_data[\"NoAugContrastive\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train_CCWA\"].append(None)\n    ed[\"metrics\"][\"val_CCWA\"].append(val_ccwa)\n    ed[\"predictions\"].append(val_preds)\n    ed[\"ground_truth\"].append(val_gt)\n    ed[\"timestamps\"].append(ts)\n\n    print(\n        f\"Epoch {ep}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CCWA={val_ccwa:.4f}\"\n    )\n\n# ---------- save --------------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved all metrics to {os.path.join(working_dir, 'experiment_data.npy')}\")\n", "# -------------------------------------------------------------\n# CLS-POOL ONLY ablation \u2013 single-file runnable script\n# -------------------------------------------------------------\nimport os, random, math, pathlib, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ---------- mandatory working directory ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device -------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- dataset loader helper ----------------------------\ndef load_spr_bench(root: pathlib.Path):\n    try:\n        from datasets import load_dataset\n    except ImportError:\n        import subprocess, sys\n\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"datasets\"])\n        from datasets import load_dataset\n\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {\n        \"train\": _load(\"train.csv\"),\n        \"dev\": _load(\"dev.csv\"),\n        \"test\": _load(\"test.csv\"),\n    }\n\n\ndef try_load_spr():\n    candidate_roots = [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]\n    for root in candidate_roots:\n        if (root / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at {root}\")\n            return load_spr_bench(root)\n    return None\n\n\nreal_dset = try_load_spr()\n\n# ---------- synthetic fall-back --------------------------------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif real_dset is None:\n    print(\"Real data not found \u2013 using synthetic fallback.\")\n    real_dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n\n# ---------- CCWA metric helpers -------------------------------\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef ccwa_metric(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------- vocabulary & encoding -----------------------------\nPAD, UNK, MASK, CLS = \"<PAD>\", \"<UNK>\", \"<MASK>\", \"<CLS>\"\n\n\ndef build_vocab(rows):\n    vocab = set()\n    for r in rows:\n        vocab.update(r[\"sequence\"].split())\n    itos = [PAD, UNK, MASK, CLS] + sorted(vocab)\n    stoi = {t: i for i, t in enumerate(itos)}\n    return stoi, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size, MAX_LEN = len(stoi), 20  # includes CLS position\n\n\ndef encode(seq: str):\n    toks = [CLS] + seq.split()  # prepend CLS\n    ids = [stoi.get(t, stoi[UNK]) for t in toks][:MAX_LEN]  # truncate\n    ids += [stoi[PAD]] * (MAX_LEN - len(ids))  # pad\n    return ids\n\n\n# ---------- datasets ------------------------------------------\nclass ContrastiveSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def _augment(self, ids_tensor):\n        ids = ids_tensor.tolist()\n        toks = [itos[t] for t in ids if t not in (stoi[PAD], stoi[CLS])]\n        # deletion\n        if random.random() < 0.3 and len(toks) > 1:\n            toks.pop(random.randrange(len(toks)))\n        # swap\n        if random.random() < 0.3 and len(toks) > 2:\n            i = random.randrange(len(toks) - 1)\n            toks[i], toks[i + 1] = toks[i + 1], toks[i]\n        # duplication\n        if random.random() < 0.3 and toks:\n            toks += random.sample(toks, k=1)\n        # random mask\n        toks = [MASK if random.random() < 0.15 else t for t in toks]\n        aug_seq = \" \".join(toks)\n        return torch.tensor(encode(aug_seq), dtype=torch.long)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        base_ids = torch.tensor(encode(self.rows[idx][\"sequence\"]), dtype=torch.long)\n        return {\"view1\": self._augment(base_ids), \"view2\": self._augment(base_ids)}\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# ---------- model ---------------------------------------------\nclass TransEncoder(nn.Module):\n    def __init__(self, vocab, d_model=96, nhead=6, nlayers=3):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        self.pos = nn.Parameter(torch.randn(MAX_LEN, d_model))\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=4 * d_model, batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(enc_layer, nlayers)\n        self.proj = nn.Linear(d_model, 128)\n\n    def forward(self, x):\n        x = self.emb(x.to(device)) + self.pos[: x.size(1)].unsqueeze(0)\n        h = self.transformer(x)\n        cls_emb = h[:, 0, :]  # CLS-POOL ONLY\n        return torch.tanh(self.proj(cls_emb))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, n_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        return self.fc(self.encoder(x))\n\n\n# ---------- SimCLR loss ---------------------------------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    B = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    z = nn.functional.normalize(z, dim=1)\n    sim = torch.matmul(z, z.T) / temperature\n    sim.masked_fill_(torch.eye(2 * B, device=z.device, dtype=torch.bool), -1e9)\n    pos_idx = (torch.arange(2 * B, device=z.device) + B) % (2 * B)\n    return nn.functional.cross_entropy(sim, pos_idx)\n\n\n# ---------- bookkeeping dict ----------------------------------\nexperiment_data = {\n    \"CLS_POOL_ONLY\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_CCWA\": [], \"val_CCWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n# ---------- data loaders --------------------------------------\nBATCH_PRE, BATCH_FT = 256, 256\npre_dl = DataLoader(\n    ContrastiveSPR(real_dset[\"train\"]),\n    batch_size=BATCH_PRE,\n    shuffle=True,\n    drop_last=True,\n)\ntrain_dl = DataLoader(\n    SupervisedSPR(real_dset[\"train\"]), batch_size=BATCH_FT, shuffle=True\n)\ndev_dl = DataLoader(SupervisedSPR(real_dset[\"dev\"]), batch_size=BATCH_FT, shuffle=False)\n\n# ---------- pre-training --------------------------------------\nencoder = TransEncoder(vocab_size).to(device)\nopt_pre = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nfor ep in range(1, 7):\n    encoder.train()\n    running = 0.0\n    for batch in pre_dl:\n        v1, v2 = batch[\"view1\"].to(device), batch[\"view2\"].to(device)\n        loss = simclr_loss(encoder(v1), encoder(v2))\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        running += loss.item()\n    print(f\"Pre-train epoch {ep}: contrastive_loss = {running/len(pre_dl):.4f}\")\n\n# ---------- fine-tuning ---------------------------------------\nn_classes = len({r[\"label\"] for r in real_dset[\"train\"]})\nclf = Classifier(encoder, n_classes).to(device)\nopt_ft = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, gts, seqs, loss_accum = [], [], [], 0.0\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"ids\"])\n            loss_accum += criterion(logits, batch[\"label\"]).item()\n            preds.extend(logits.argmax(1).cpu().tolist())\n            gts.extend(batch[\"label\"].cpu().tolist())\n            seqs.extend(batch[\"seq\"])\n    return loss_accum / len(loader), ccwa_metric(seqs, gts, preds), preds, gts\n\n\nfor ep in range(1, 11):\n    clf.train()\n    train_loss, steps = 0.0, 0\n    for batch in train_dl:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        loss = criterion(clf(batch[\"ids\"]), batch[\"label\"])\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        train_loss += loss.item()\n        steps += 1\n    train_loss /= steps\n\n    val_loss, val_ccwa, val_preds, val_gt = evaluate(clf, dev_dl)\n    ts = datetime.datetime.now().isoformat()\n    ed = experiment_data[\"CLS_POOL_ONLY\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train_CCWA\"].append(None)\n    ed[\"metrics\"][\"val_CCWA\"].append(val_ccwa)\n    ed[\"predictions\"].append(val_preds)\n    ed[\"ground_truth\"].append(val_gt)\n    ed[\"timestamps\"].append(ts)\n    print(\n        f\"Epoch {ep}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CCWA={val_ccwa:.4f}\"\n    )\n\n# ---------- save ----------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved all metrics to {os.path.join(working_dir, 'experiment_data.npy')}\")\n", "# -------------------------------------------------------------\n# Embedding-Only ablation (nlayers = 0) for SPR_BENCH\n# -------------------------------------------------------------\nimport os, random, math, pathlib, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ---------- mandatory working directory ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device -------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- helper: load real benchmark if present -----------\ndef load_spr_bench(root: pathlib.Path):\n    try:\n        from datasets import load_dataset\n    except ImportError:\n        import subprocess, sys\n\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"datasets\"])\n        from datasets import load_dataset\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {\n        \"train\": _load(\"train.csv\"),\n        \"dev\": _load(\"dev.csv\"),\n        \"test\": _load(\"test.csv\"),\n    }\n\n\ndef try_load_spr():\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at {p}\")\n            return load_spr_bench(p)\n    return None\n\n\nreal_dset = try_load_spr()\n\n# ---------- synthetic fallback --------------------------------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif real_dset is None:\n    print(\"Real data not found \u2013 using synthetic fallback.\")\n    real_dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n\n# ---------- CCWA helpers -------------------------------------\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef ccwa_metric(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    corr = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(corr) / sum(w) if sum(w) else 0.0\n\n\n# ---------- vocabulary ---------------------------------------\nPAD, UNK, MASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(rows):\n    vocab = set()\n    for r in rows:\n        vocab.update(r[\"sequence\"].split())\n    itos = [PAD, UNK, MASK] + sorted(vocab)\n    stoi = {t: i for i, t in enumerate(itos)}\n    return stoi, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size = len(stoi)\nMAX_LEN = 20\n\n\ndef encode(seq: str):\n    ids = [stoi.get(tok, stoi[UNK]) for tok in seq.split()][:MAX_LEN]\n    ids += [stoi[PAD]] * (MAX_LEN - len(ids))\n    return ids\n\n\n# ---------- datasets -----------------------------------------\nclass ContrastiveSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def _augment(self, ids):\n        toks = [t for t in ids if t != stoi[PAD]]\n        if random.random() < 0.3 and len(toks) > 1:\n            toks.pop(random.randrange(len(toks)))\n        if random.random() < 0.3 and len(toks) > 2:\n            i = random.randrange(len(toks) - 1)\n            toks[i], toks[i + 1] = toks[i + 1], toks[i]\n        if random.random() < 0.3:\n            toks += random.sample(toks, k=1)\n        toks = [stoi[MASK] if random.random() < 0.15 else t for t in toks]\n        return torch.tensor(encode(\" \".join(itos[t] for t in toks)), dtype=torch.long)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        base = torch.tensor(encode(self.rows[idx][\"sequence\"]), dtype=torch.long)\n        return {\"view1\": self._augment(base), \"view2\": self._augment(base)}\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# ---------- model --------------------------------------------\nclass TransEncoder(nn.Module):\n    def __init__(self, vocab, d_model=96, nhead=6, nlayers=0):  # nlayers=0 for ablation\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        self.pos = nn.Parameter(torch.randn(MAX_LEN, d_model))\n        if nlayers > 0:\n            enc = nn.TransformerEncoderLayer(\n                d_model=d_model,\n                nhead=nhead,\n                dim_feedforward=4 * d_model,\n                batch_first=True,\n            )\n            self.transformer = nn.TransformerEncoder(enc, nlayers)\n        else:\n            self.transformer = nn.Identity()  # Embedding-only path\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(d_model, 128)\n\n    def forward(self, x):\n        x = self.emb(x.to(device)) + self.pos[: x.size(1)].unsqueeze(0)\n        h = self.transformer(x)\n        h = self.pool(h.transpose(1, 2)).squeeze(-1)\n        return torch.tanh(self.proj(h))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, n_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        return self.fc(self.encoder(x))\n\n\n# ---------- SimCLR / InfoNCE loss ----------------------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    B = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    z = nn.functional.normalize(z, dim=1)\n    sim = torch.matmul(z, z.T) / temperature\n    mask = torch.eye(2 * B, device=z.device, dtype=torch.bool)\n    sim.masked_fill_(mask, -1e9)\n    pos = (torch.arange(2 * B, device=z.device) + B) % (2 * B)\n    return nn.functional.cross_entropy(sim, pos)\n\n\n# ---------- bookkeeping --------------------------------------\nablation_name = \"EmbeddingOnly\"\nexperiment_data = {\n    ablation_name: {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_CCWA\": [], \"val_CCWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n# ---------- data loaders -------------------------------------\nBATCH_PRE = 256\nBATCH_FT = 256\npre_dl = DataLoader(\n    ContrastiveSPR(real_dset[\"train\"]),\n    batch_size=BATCH_PRE,\n    shuffle=True,\n    drop_last=True,\n)\ntrain_dl = DataLoader(\n    SupervisedSPR(real_dset[\"train\"]), batch_size=BATCH_FT, shuffle=True\n)\ndev_dl = DataLoader(SupervisedSPR(real_dset[\"dev\"]), batch_size=BATCH_FT, shuffle=False)\n\n# ---------- pre-training -------------------------------------\nencoder = TransEncoder(vocab_size, nlayers=0).to(device)\nopt_pre = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nPRE_EPOCHS = 6\nfor ep in range(1, PRE_EPOCHS + 1):\n    encoder.train()\n    running = 0.0\n    for b in pre_dl:\n        v1, v2 = b[\"view1\"].to(device), b[\"view2\"].to(device)\n        loss = simclr_loss(encoder(v1), encoder(v2))\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        running += loss.item()\n    print(f\"Pre-train epoch {ep}: contrastive_loss={running/len(pre_dl):.4f}\")\n\n# ---------- fine-tuning --------------------------------------\nn_classes = len(set(r[\"label\"] for r in real_dset[\"train\"]))\nclf = Classifier(encoder, n_classes).to(device)\nopt_ft = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\nFT_EPOCHS = 10\n\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, gts, seqs, loss_acc = [], [], [], 0.0\n    with torch.no_grad():\n        for batch in loader:\n            ids = batch[\"ids\"].to(device)\n            labels = batch[\"label\"].to(device)\n            logits = model(ids)\n            loss = criterion(logits, labels)\n            loss_acc += loss.item()\n            preds.extend(logits.argmax(1).cpu().tolist())\n            gts.extend(labels.cpu().tolist())\n            seqs.extend(batch[\"seq\"])\n    return loss_acc / len(loader), ccwa_metric(seqs, gts, preds), preds, gts\n\n\nfor ep in range(1, FT_EPOCHS + 1):\n    clf.train()\n    train_loss, steps = 0.0, 0\n    for batch in train_dl:\n        ids = batch[\"ids\"].to(device)\n        labels = batch[\"label\"].to(device)\n        loss = criterion(clf(ids), labels)\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        train_loss += loss.item()\n        steps += 1\n    train_loss /= steps\n    val_loss, val_ccwa, val_pred, val_gt = evaluate(clf, dev_dl)\n    ts = datetime.datetime.now().isoformat()\n\n    # store\n    exp = experiment_data[ablation_name][\"SPR_BENCH\"]\n    exp[\"losses\"][\"train\"].append(train_loss)\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"train_CCWA\"].append(None)\n    exp[\"metrics\"][\"val_CCWA\"].append(val_ccwa)\n    exp[\"predictions\"].append(val_pred)\n    exp[\"ground_truth\"].append(val_gt)\n    exp[\"timestamps\"].append(ts)\n\n    print(\n        f\"Epoch {ep}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n        f\"CCWA={val_ccwa:.4f}\"\n    )\n\n# ---------- save ---------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved metrics to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "import os, random, math, pathlib, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset\n\n# ---------------------------------------------------------------------\n# mandatory working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------------------------------------------------------------------\n# device handling\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------------------------------------------------------\n# ---------------------- Data utilities --------------------------------\ndef load_spr_bench(root: pathlib.Path):\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {\n        \"train\": _load(\"train.csv\"),\n        \"dev\": _load(\"dev.csv\"),\n        \"test\": _load(\"test.csv\"),\n    }\n\n\ndef try_load_spr():\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at {p}\")\n            return load_spr_bench(p)\n    return None\n\n\ndset = try_load_spr()\n\n# ---------------- synthetic fallback if no data ------------------------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif dset is None:\n    print(\"Real SPR_BENCH not found, using synthetic data.\")\n    dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n# ---------------------------------------------------------------------\n# ------------- Complexity-Adjusted Weighted Accuracy ------------------\nPAD, UNK, MASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef cawa_metric(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------------------------------------------------------------------\n# ------------------------ vocabulary ----------------------------------\ndef build_vocab(rows):\n    vocab = set()\n    for r in rows:\n        vocab.update(r[\"sequence\"].split())\n    itos = [PAD, UNK, MASK] + sorted(vocab)\n    return {t: i for i, t in enumerate(itos)}, itos\n\n\nstoi, itos = build_vocab(dset[\"train\"])\nvocab_size, MAX_LEN = len(stoi), 20\n\n\ndef encode(seq: str):\n    ids = [stoi.get(tok, stoi[UNK]) for tok in seq.split()][:MAX_LEN]\n    ids += [stoi[PAD]] * (MAX_LEN - len(ids))\n    return ids\n\n\n# ---------------------------------------------------------------------\n# ----------------------- datasets  ------------------------------------\nclass ContrastiveSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def _augment(self, ids):\n        toks = [t for t in ids if t != stoi[PAD]]\n        if random.random() < 0.3 and len(toks) > 1:\n            toks.pop(random.randrange(len(toks)))\n        if random.random() < 0.3 and len(toks) > 2:\n            i = random.randrange(len(toks) - 1)\n            toks[i], toks[i + 1] = toks[i + 1], toks[i]\n        if random.random() < 0.3:\n            toks += random.sample(toks, k=1)\n        toks = [stoi[MASK] if random.random() < 0.15 else t for t in toks]\n        return torch.tensor(encode(\" \".join(itos[t] for t in toks)), dtype=torch.long)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        base_ids = torch.tensor(encode(self.rows[idx][\"sequence\"]), dtype=torch.long)\n        return {\"view1\": self._augment(base_ids), \"view2\": self._augment(base_ids)}\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# ---------------------------------------------------------------------\n# -------------------- model definitions ------------------------------\nclass TransEncoderNoPos(nn.Module):\n    def __init__(self, vocab, d_model=96, nhead=6, nlayers=3):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=4 * d_model, batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(enc_layer, nlayers)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(d_model, 128)\n\n    def forward(self, x):\n        h = self.transformer(self.emb(x.to(device)))\n        h = self.pool(h.transpose(1, 2)).squeeze(-1)\n        return torch.tanh(self.proj(h))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, n_cls):\n        super().__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(128, n_cls)\n\n    def forward(self, x):\n        return self.fc(self.encoder(x))\n\n\n# ---------------------------------------------------------------------\n# ---------------------- SimCLR loss ----------------------------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    B = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    z = nn.functional.normalize(z, dim=1)\n    sim = z @ z.T / temperature\n    sim.masked_fill_(torch.eye(2 * B, dtype=torch.bool, device=z.device), -9e15)\n    positives = (torch.arange(2 * B, device=z.device) + B) % (2 * B)\n    return nn.functional.cross_entropy(sim, positives)\n\n\n# ---------------------------------------------------------------------\n# --------------------- experiment bookkeeping ------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_CAWA\": [], \"val_CAWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n# ---------------------------------------------------------------------\n# --------------------------- DataLoaders -----------------------------\nBATCH_PRE, BATCH_FT = 256, 256\npre_dl = DataLoader(\n    ContrastiveSPR(dset[\"train\"]), batch_size=BATCH_PRE, shuffle=True, drop_last=True\n)\ntrain_dl = DataLoader(SupervisedSPR(dset[\"train\"]), batch_size=BATCH_FT, shuffle=True)\ndev_dl = DataLoader(SupervisedSPR(dset[\"dev\"]), batch_size=BATCH_FT, shuffle=False)\n\n# ---------------------------------------------------------------------\n# --------------------------- pre-training ----------------------------\nencoder = TransEncoderNoPos(vocab_size).to(device)\nopt_pre = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nPRE_EPOCHS = 6\nfor ep in range(1, PRE_EPOCHS + 1):\n    encoder.train()\n    run = 0.0\n    for batch in pre_dl:\n        v1, v2 = batch[\"view1\"].to(device), batch[\"view2\"].to(device)\n        loss = simclr_loss(encoder(v1), encoder(v2))\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        run += loss.item()\n    print(f\"Pre-train epoch {ep}: contrastive_loss={run/len(pre_dl):.4f}\")\n\n# ---------------------------------------------------------------------\n# --------------------------- fine-tuning -----------------------------\nn_classes = len(set(r[\"label\"] for r in dset[\"train\"]))\nclf = Classifier(encoder, n_classes).to(device)\n\n# freeze encoder for warm-up\nfor p in clf.encoder.parameters():\n    p.requires_grad = False\nopt_ft = torch.optim.Adam(\n    [\n        {\"params\": clf.fc.parameters(), \"lr\": 2e-3},\n        {\"params\": clf.encoder.parameters(), \"lr\": 5e-4},\n    ]\n)\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    opt_ft, mode=\"min\", factor=0.5, patience=2, verbose=True\n)\ncriterion = nn.CrossEntropyLoss()\nFT_EPOCHS, WARM_EPOCHS, patience, best_val = 20, 2, 4, float(\"inf\")\npatience_ctr = 0\n\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, gts, seqs, loss_acc = [], [], [], 0.0\n    with torch.no_grad():\n        for batch in loader:\n            batch = {\n                k: v.to(device) if isinstance(v, torch.Tensor) else v\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"ids\"])\n            loss = criterion(logits, batch[\"label\"])\n            loss_acc += loss.item()\n            preds.extend(logits.argmax(1).cpu().tolist())\n            gts.extend(batch[\"label\"].cpu().tolist())\n            seqs.extend(batch[\"seq\"])\n    return (loss_acc / len(loader), cawa_metric(seqs, gts, preds), preds, gts)\n\n\nfor ep in range(1, FT_EPOCHS + 1):\n    # unfreeze after warm-up\n    if ep == WARM_EPOCHS + 1:\n        for p in clf.encoder.parameters():\n            p.requires_grad = True\n\n    clf.train()\n    tr_loss, tr_preds, tr_gts, tr_seqs = 0.0, [], [], []\n    for batch in train_dl:\n        batch = {\n            k: v.to(device) if isinstance(v, torch.Tensor) else v\n            for k, v in batch.items()\n        }\n        logits = clf(batch[\"ids\"])\n        loss = criterion(logits, batch[\"label\"])\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        tr_loss += loss.item()\n        tr_preds.extend(logits.argmax(1).cpu().tolist())\n        tr_gts.extend(batch[\"label\"].cpu().tolist())\n        tr_seqs.extend(batch[\"seq\"])\n    tr_loss /= len(train_dl)\n    train_cawa = cawa_metric(tr_seqs, tr_gts, tr_preds)\n\n    val_loss, val_cawa, val_pred, val_gt = evaluate(clf, dev_dl)\n    scheduler.step(val_loss)\n\n    ts = datetime.datetime.now().isoformat()\n    exp = experiment_data[\"SPR_BENCH\"]\n    exp[\"losses\"][\"train\"].append(tr_loss)\n    exp[\"losses\"][\"val\"].append(val_loss)\n    exp[\"metrics\"][\"train_CAWA\"].append(train_cawa)\n    exp[\"metrics\"][\"val_CAWA\"].append(val_cawa)\n    exp[\"predictions\"].append(val_pred)\n    exp[\"ground_truth\"].append(val_gt)\n    exp[\"timestamps\"].append(ts)\n\n    print(\n        f\"Epoch {ep}: train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} | \"\n        f\"train_CAWA={train_cawa:.4f} | val_CAWA={val_cawa:.4f}\"\n    )\n\n    # -------- early stopping ------------\n    if val_loss < best_val - 1e-4:\n        best_val, patience_ctr = val_loss, 0\n    else:\n        patience_ctr += 1\n        if patience_ctr >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n# ---------------------------------------------------------------------\n# --------------------------- save results ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved experiment data to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "# ---------------- BiLSTM encoder ablation study -----------------\nimport os, random, math, pathlib, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ------------------- directories / device ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------- optional SPR benchmark ----------------------\ndef load_spr_bench(root: pathlib.Path):\n    try:\n        from datasets import load_dataset\n    except ImportError:\n        import subprocess, sys\n\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"datasets\"])\n        from datasets import load_dataset\n\n    def _load(csv_name):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {\n        \"train\": _load(\"train.csv\"),\n        \"dev\": _load(\"dev.csv\"),\n        \"test\": _load(\"test.csv\"),\n    }\n\n\ndef try_load_spr():\n    for p in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (p / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at {p}\")\n            return load_spr_bench(p)\n    return None\n\n\nreal_dset = try_load_spr()\n\n# -------------- synthetic fallback if benchmark missing --------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif real_dset is None:\n    print(\"Real data not found \u2013 using synthetic fallback.\")\n    real_dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n\n# ------------------- CCWA metric helpers -----------------------\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef ccwa_metric(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    c = [wt if t == p else 0 for wt, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) else 0.0\n\n\n# ------------------------ vocabulary ---------------------------\nPAD, UNK, MASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(rows):\n    vocab = set()\n    for r in rows:\n        vocab.update(r[\"sequence\"].split())\n    itos = [PAD, UNK, MASK] + sorted(vocab)\n    stoi = {t: i for i, t in enumerate(itos)}\n    return stoi, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size, MAX_LEN = len(stoi), 20\n\n\ndef encode(seq: str):\n    ids = [stoi.get(tok, stoi[UNK]) for tok in seq.split()][:MAX_LEN]\n    ids += [stoi[PAD]] * (MAX_LEN - len(ids))\n    return ids\n\n\n# ------------------------- datasets ----------------------------\nclass ContrastiveSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def _augment(self, ids):\n        toks = [t for t in ids if t != stoi[PAD]]\n        if random.random() < 0.3 and len(toks) > 1:\n            toks.pop(random.randrange(len(toks)))  # deletion\n        if random.random() < 0.3 and len(toks) > 2:  # swap\n            i = random.randrange(len(toks) - 1)\n            toks[i], toks[i + 1] = toks[i + 1], toks[i]\n        if random.random() < 0.3:\n            toks += random.sample(toks, k=1)  # dup\n        toks = [stoi[MASK] if random.random() < 0.15 else t for t in toks]  # mask\n        return torch.tensor(encode(\" \".join(itos[t] for t in toks)), dtype=torch.long)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        base = torch.tensor(encode(self.rows[idx][\"sequence\"]), dtype=torch.long)\n        return {\"view1\": self._augment(base), \"view2\": self._augment(base)}\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# ----------------------- BiLSTM encoder ------------------------\nclass BiLSTMEncoder(nn.Module):\n    def __init__(self, vocab, d_model=96, nlayers=2):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        hidden = d_model // 2\n        self.lstm = nn.LSTM(\n            input_size=d_model,\n            hidden_size=hidden,\n            num_layers=nlayers,\n            batch_first=True,\n            bidirectional=True,\n        )\n        self.proj = nn.Linear(d_model, 128)\n\n    def forward(self, x_ids):\n        mask = (x_ids != stoi[PAD]).to(device)\n        x = self.emb(x_ids.to(device))\n        h, _ = self.lstm(x)  # h: B x T x d_model\n        # length-masked mean pooling\n        h = (h * mask.unsqueeze(-1)).sum(1) / mask.sum(1, keepdim=True).clamp(min=1)\n        return torch.tanh(self.proj(h))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, n_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        return self.fc(self.encoder(x))\n\n\n# ---------------------- SimCLR / InfoNCE -----------------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    B = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    z = nn.functional.normalize(z, dim=1)\n    sim = (z @ z.T) / temperature\n    sim.masked_fill_(torch.eye(2 * B, dtype=torch.bool, device=z.device), -1e9)\n    pos_idx = (torch.arange(2 * B, device=z.device) + B) % (2 * B)\n    return nn.functional.cross_entropy(sim, pos_idx)\n\n\n# -------------------- dataloaders ------------------------------\nBATCH_PRE, BATCH_FT = 256, 256\npre_ds = ContrastiveSPR(real_dset[\"train\"])\ntrain_ds, dev_ds = SupervisedSPR(real_dset[\"train\"]), SupervisedSPR(real_dset[\"dev\"])\npre_dl = DataLoader(pre_ds, batch_size=BATCH_PRE, shuffle=True, drop_last=True)\ntrain_dl = DataLoader(train_ds, batch_size=BATCH_FT, shuffle=True)\ndev_dl = DataLoader(dev_ds, batch_size=BATCH_FT, shuffle=False)\n\n# ------------------ experiment bookkeeping --------------------\nexperiment_data = {\n    \"BiLSTM\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_CCWA\": [], \"val_CCWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n# -------------------- contrastive pre-training -----------------\nencoder = BiLSTMEncoder(vocab_size).to(device)\nopt_pre = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nfor ep in range(1, 7):\n    encoder.train()\n    running = 0.0\n    for batch in pre_dl:\n        loss = simclr_loss(\n            encoder(batch[\"view1\"].to(device)), encoder(batch[\"view2\"].to(device))\n        )\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        running += loss.item()\n    print(f\"Pre-train epoch {ep}: contrastive_loss={running/len(pre_dl):.4f}\")\n\n# ---------------------- supervised fine-tune -------------------\nn_classes = len({r[\"label\"] for r in real_dset[\"train\"]})\nclf = Classifier(encoder, n_classes).to(device)\nopt_ft = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, gts, seqs, loss_sum = [], [], [], 0.0\n    with torch.no_grad():\n        for batch in loader:\n            ids, label = batch[\"ids\"].to(device), batch[\"label\"].to(device)\n            logits = model(ids)\n            loss = criterion(logits, label)\n            loss_sum += loss.item()\n            preds += logits.argmax(1).cpu().tolist()\n            gts += label.cpu().tolist()\n            seqs += batch[\"seq\"]\n    return loss_sum / len(loader), ccwa_metric(seqs, gts, preds), preds, gts\n\n\nfor ep in range(1, 11):\n    clf.train()\n    train_loss, steps = 0.0, 0\n    for batch in train_dl:\n        ids, label = batch[\"ids\"].to(device), batch[\"label\"].to(device)\n        loss = criterion(clf(ids), label)\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        train_loss += loss.item()\n        steps += 1\n    train_loss /= steps\n    val_loss, val_ccwa, val_preds, val_gt = evaluate(clf, dev_dl)\n    ts = datetime.datetime.now().isoformat()\n    ed = experiment_data[\"BiLSTM\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train_CCWA\"].append(None)\n    ed[\"metrics\"][\"val_CCWA\"].append(val_ccwa)\n    ed[\"predictions\"].append(val_preds)\n    ed[\"ground_truth\"].append(val_gt)\n    ed[\"timestamps\"].append(ts)\n    print(\n        f\"Epoch {ep}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CCWA={val_ccwa:.4f}\"\n    )\n\n# -------------------------- save --------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved metrics to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "# -------------------------------------------------------------\n# Context-aware contrastive learning \u2013 Fixed-Sinusoidal-Position-Embedding ablation\n# -------------------------------------------------------------\nimport os, random, math, pathlib, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ---------- mandatory working directory ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device -------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- utility to (try to) load the real benchmark -------\ndef load_spr_bench(root: pathlib.Path):\n    try:\n        from datasets import load_dataset\n    except ImportError:\n        import subprocess, sys\n\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"datasets\"])\n        from datasets import load_dataset\n\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {\n        \"train\": _load(\"train.csv\"),\n        \"dev\": _load(\"dev.csv\"),\n        \"test\": _load(\"test.csv\"),\n    }\n\n\ndef try_load_spr():\n    for root in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (root / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at {root}\")\n            return load_spr_bench(root)\n    return None\n\n\nreal_dset = try_load_spr()\n\n# ---------- synthetic fall-back (larger than before) ----------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif real_dset is None:\n    print(\"Real data not found \u2013 using synthetic fallback.\")\n    real_dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n\n# ---------- CCWA metric helpers --------------------------------\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef ccwa_metric(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) else 0.0\n\n\n# ---------- vocabulary ----------------------------------------\nPAD, UNK, MASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(rows):\n    vocab = set()\n    for r in rows:\n        vocab.update(r[\"sequence\"].split())\n    itos = [PAD, UNK, MASK] + sorted(vocab)\n    return {t: i for i, t in enumerate(itos)}, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size, MAX_LEN = len(stoi), 20\n\n\ndef encode(seq: str):\n    ids = [stoi.get(tok, stoi[UNK]) for tok in seq.split()][:MAX_LEN]\n    ids += [stoi[PAD]] * (MAX_LEN - len(ids))\n    return ids\n\n\n# ---------- datasets ------------------------------------------\nclass ContrastiveSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def _augment(self, ids):\n        toks = [t for t in ids if t != stoi[PAD]]\n        if random.random() < 0.3 and len(toks) > 1:\n            toks.pop(random.randrange(len(toks)))\n        if random.random() < 0.3 and len(toks) > 2:\n            i = random.randrange(len(toks) - 1)\n            toks[i], toks[i + 1] = toks[i + 1], toks[i]\n        if random.random() < 0.3:\n            toks += random.sample(toks, k=1)\n        toks = [stoi[MASK] if random.random() < 0.15 else t for t in toks]\n        return torch.tensor(encode(\" \".join(itos[t] for t in toks)), dtype=torch.long)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        base_ids = torch.tensor(encode(self.rows[idx][\"sequence\"]), dtype=torch.long)\n        return {\"view1\": self._augment(base_ids), \"view2\": self._augment(base_ids)}\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# ---------- model with fixed sinusoidal position embedding -----\ndef build_sin_pos(max_len: int, d_model: int):\n    pe = torch.zeros(max_len, d_model)\n    pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n    div_term = torch.exp(\n        torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n    )\n    pe[:, 0::2] = torch.sin(pos * div_term)\n    pe[:, 1::2] = torch.cos(pos * div_term)\n    return pe\n\n\nclass TransEncoder(nn.Module):\n    def __init__(self, vocab, d_model=96, nhead=6, nlayers=3):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        self.register_buffer(\"pos\", build_sin_pos(MAX_LEN, d_model))  # not trainable\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=4 * d_model, batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(enc_layer, nlayers)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(d_model, 128)\n\n    def forward(self, x):\n        x = self.emb(x.to(device)) + self.pos[: x.size(1)].unsqueeze(0)\n        h = self.transformer(x)\n        h = self.pool(h.transpose(1, 2)).squeeze(-1)\n        return torch.tanh(self.proj(h))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, n_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        return self.fc(self.encoder(x))\n\n\n# ---------- SimCLR / InfoNCE loss -----------------------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    B = z1.size(0)\n    z = torch.cat([z1, z2], dim=0)\n    z = nn.functional.normalize(z, dim=1)\n    sim = torch.matmul(z, z.T) / temperature\n    sim.masked_fill_(torch.eye(2 * B, device=z.device, dtype=torch.bool), -1e9)\n    positives = (torch.arange(2 * B, device=z.device) + B) % (2 * B)\n    return nn.functional.cross_entropy(sim, positives)\n\n\n# ---------- bookkeeping dict ----------------------------------\nexperiment_data = {\n    \"FixedSinPE\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_CCWA\": [], \"val_CCWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n# ---------- data loaders --------------------------------------\nBATCH_PRE, BATCH_FT = 256, 256\npre_dl = DataLoader(\n    ContrastiveSPR(real_dset[\"train\"]),\n    batch_size=BATCH_PRE,\n    shuffle=True,\n    drop_last=True,\n)\ntrain_dl = DataLoader(\n    SupervisedSPR(real_dset[\"train\"]), batch_size=BATCH_FT, shuffle=True\n)\ndev_dl = DataLoader(SupervisedSPR(real_dset[\"dev\"]), batch_size=BATCH_FT, shuffle=False)\n\n# ---------- pre-training --------------------------------------\nencoder = TransEncoder(vocab_size).to(device)\nopt_pre = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nfor ep in range(1, 7):\n    encoder.train()\n    running = 0.0\n    for batch in pre_dl:\n        loss = simclr_loss(\n            encoder(batch[\"view1\"].to(device)), encoder(batch[\"view2\"].to(device))\n        )\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        running += loss.item()\n    print(f\"Pre-train epoch {ep}: contrastive_loss = {running/len(pre_dl):.4f}\")\n\n# ---------- fine-tuning ---------------------------------------\nn_classes = len({r[\"label\"] for r in real_dset[\"train\"]})\nclf = Classifier(encoder, n_classes).to(device)\nopt_ft = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, gts, seqs, loss_acc = [], [], [], 0.0\n    with torch.no_grad():\n        for batch in loader:\n            ids = batch[\"ids\"].to(device)\n            labels = batch[\"label\"].to(device)\n            logits = model(ids)\n            loss_acc += criterion(logits, labels).item()\n            preds.extend(logits.argmax(1).cpu().tolist())\n            gts.extend(labels.cpu().tolist())\n            seqs.extend(batch[\"seq\"])\n    return loss_acc / len(loader), ccwa_metric(seqs, gts, preds), preds, gts\n\n\nfor ep in range(1, 11):\n    clf.train()\n    train_loss, steps = 0.0, 0\n    for batch in train_dl:\n        ids = batch[\"ids\"].to(device)\n        labels = batch[\"label\"].to(device)\n        loss = criterion(clf(ids), labels)\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        train_loss += loss.item()\n        steps += 1\n    train_loss /= steps\n    val_loss, val_ccwa, val_preds, val_gt = evaluate(clf, dev_dl)\n    ts = datetime.datetime.now().isoformat()\n    ed = experiment_data[\"FixedSinPE\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train_CCWA\"].append(None)\n    ed[\"metrics\"][\"val_CCWA\"].append(val_ccwa)\n    ed[\"predictions\"].append(val_preds)\n    ed[\"ground_truth\"].append(val_gt)\n    ed[\"timestamps\"].append(ts)\n    print(\n        f\"Epoch {ep}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CCWA={val_ccwa:.4f}\"\n    )\n\n# ---------- save ----------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved metrics to {os.path.join(working_dir,'experiment_data.npy')}\")\n", "# -------------------------------------------------------------\n# Mask-Only Augmentation (Structure-Preserving) \u2013 ablation run\n# -------------------------------------------------------------\nimport os, random, math, pathlib, datetime, numpy as np, torch, sys\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ---------- mandatory working directory ----------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- device -------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------- helper to load the real SPR benchmark ------------\ndef load_spr_bench(root: pathlib.Path):\n    try:\n        from datasets import load_dataset\n    except ImportError:\n        import subprocess\n\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"datasets\"])\n        from datasets import load_dataset\n\n    def _load(csv_name: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / csv_name),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return {\n        \"train\": _load(\"train.csv\"),\n        \"dev\": _load(\"dev.csv\"),\n        \"test\": _load(\"test.csv\"),\n    }\n\n\ndef try_load_spr():\n    for root in [\n        pathlib.Path(\"./SPR_BENCH\"),\n        pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH\"),\n    ]:\n        if (root / \"train.csv\").exists():\n            print(f\"Found SPR_BENCH at {root}\")\n            return load_spr_bench(root)\n    return None\n\n\nreal_dset = try_load_spr()\n\n# ---------- synthetic fall-back --------------------------------\nshapes, colors = list(\"RSTUVWXYZ\"), list(\"ABCDEFGH\")\n\n\ndef rnd_token():\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef rnd_seq():\n    return \" \".join(rnd_token() for _ in range(random.randint(4, 12)))\n\n\ndef make_split(n):\n    return [\n        {\"id\": i, \"sequence\": rnd_seq(), \"label\": random.randint(0, 3)}\n        for i in range(n)\n    ]\n\n\nif real_dset is None:\n    print(\"Real data not found \u2013 using synthetic fallback.\")\n    real_dset = {\n        \"train\": make_split(6000),\n        \"dev\": make_split(1200),\n        \"test\": make_split(1200),\n    }\n\n\n# ---------- CCWA metric helpers -------------------------------\ndef count_shape_variety(seq):\n    return len({tok[0] for tok in seq.split() if tok})\n\n\ndef count_color_variety(seq):\n    return len({tok[1] for tok in seq.split() if len(tok) > 1})\n\n\ndef ccwa_metric(seqs, y_true, y_pred):\n    w = [count_shape_variety(s) + count_color_variety(s) for s in seqs]\n    c = [wi if t == p else 0 for wi, t, p in zip(w, y_true, y_pred)]\n    return sum(c) / sum(w) if sum(w) else 0.0\n\n\n# ---------- vocabulary ----------------------------------------\nPAD, UNK, MASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(rows):\n    vocab = set()\n    for r in rows:\n        vocab.update(r[\"sequence\"].split())\n    itos = [PAD, UNK, MASK] + sorted(vocab)\n    return {t: i for i, t in enumerate(itos)}, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size, len_max = len(stoi), 20\n\n\ndef encode(seq: str):\n    ids = [stoi.get(t, stoi[UNK]) for t in seq.split()][:len_max]\n    ids += [stoi[PAD]] * (len_max - len(ids))\n    return ids\n\n\n# ---------- datasets ------------------------------------------\nclass ContrastiveSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def _augment(self, ids):\n        toks = [t for t in ids if t != stoi[PAD]]  # keep PAD free area\n        toks = [\n            stoi[MASK] if random.random() < 0.15 else t for t in toks\n        ]  # ONLY masking\n        aug_seq = \" \".join(itos[t] for t in toks)\n        return torch.tensor(encode(aug_seq), dtype=torch.long)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        base = torch.tensor(encode(self.rows[idx][\"sequence\"]), dtype=torch.long)\n        return {\"view1\": self._augment(base), \"view2\": self._augment(base)}\n\n\nclass SupervisedSPR(Dataset):\n    def __init__(self, rows):\n        self.rows = rows\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return {\n            \"ids\": torch.tensor(encode(r[\"sequence\"]), dtype=torch.long),\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"seq\": r[\"sequence\"],\n        }\n\n\n# ---------- model ---------------------------------------------\nclass TransEncoder(nn.Module):\n    def __init__(self, vocab, d_model=96, nhead=6, nlayers=3):\n        super().__init__()\n        self.emb = nn.Embedding(vocab, d_model, padding_idx=0)\n        self.pos = nn.Parameter(torch.randn(len_max, d_model))\n        layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=4 * d_model, batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(layer, nlayers)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(d_model, 128)\n\n    def forward(self, x):\n        x = self.emb(x.to(device)) + self.pos[: x.size(1)].unsqueeze(0)\n        h = self.transformer(x)\n        h = self.pool(h.transpose(1, 2)).squeeze(-1)\n        return torch.tanh(self.proj(h))\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, n_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.fc = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        return self.fc(self.encoder(x))\n\n\n# ---------- SimCLR / InfoNCE loss ------------------------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    B = z1.size(0)\n    z = torch.cat([z1, z2], 0)\n    z = nn.functional.normalize(z, dim=1)\n    sim = torch.matmul(z, z.T) / temperature\n    sim.masked_fill_(torch.eye(2 * B, dtype=torch.bool, device=z.device), -1e9)\n    pos_idx = (torch.arange(2 * B, device=z.device) + B) % (2 * B)\n    return nn.functional.cross_entropy(sim, pos_idx)\n\n\n# ---------- bookkeeping dict -----------------------------------\nexperiment_data = {\n    \"mask_only_structure_preserving\": {\n        \"SPR_BENCH\": {\n            \"metrics\": {\"train_CCWA\": [], \"val_CCWA\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n            \"timestamps\": [],\n        }\n    }\n}\n\n# ---------- dataloaders ---------------------------------------\nBATCH_PRE, BATCH_FT = 256, 256\npre_dl = DataLoader(\n    ContrastiveSPR(real_dset[\"train\"]),\n    batch_size=BATCH_PRE,\n    shuffle=True,\n    drop_last=True,\n)\ntrain_dl = DataLoader(\n    SupervisedSPR(real_dset[\"train\"]), batch_size=BATCH_FT, shuffle=True\n)\ndev_dl = DataLoader(SupervisedSPR(real_dset[\"dev\"]), batch_size=BATCH_FT, shuffle=False)\n\n# ---------- pre-training --------------------------------------\nencoder = TransEncoder(vocab_size).to(device)\nopt_pre = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nPRE_EPOCHS = 6\nfor ep in range(1, PRE_EPOCHS + 1):\n    encoder.train()\n    running = 0.0\n    for batch in pre_dl:\n        v1, v2 = batch[\"view1\"].to(device), batch[\"view2\"].to(device)\n        loss = simclr_loss(encoder(v1), encoder(v2))\n        opt_pre.zero_grad()\n        loss.backward()\n        opt_pre.step()\n        running += loss.item()\n    print(f\"Pre-train epoch {ep}: contrastive_loss={running/len(pre_dl):.4f}\")\n\n# ---------- fine-tuning ---------------------------------------\nn_classes = len(set(r[\"label\"] for r in real_dset[\"train\"]))\nclf = Classifier(encoder, n_classes).to(device)\nopt_ft = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\nFT_EPOCHS = 10\n\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, gts, seqs, loss_acc = [], [], [], 0.0\n    with torch.no_grad():\n        for batch in loader:\n            ids = batch[\"ids\"].to(device)\n            labels = batch[\"label\"].to(device)\n            logits = model(ids)\n            loss = criterion(logits, labels)\n            loss_acc += loss.item()\n            preds.extend(logits.argmax(1).cpu().tolist())\n            gts.extend(labels.cpu().tolist())\n            seqs.extend(batch[\"seq\"])\n    return loss_acc / len(loader), ccwa_metric(seqs, gts, preds), preds, gts\n\n\nfor ep in range(1, FT_EPOCHS + 1):\n    clf.train()\n    train_loss, steps = 0.0, 0\n    for batch in train_dl:\n        ids = batch[\"ids\"].to(device)\n        labels = batch[\"label\"].to(device)\n        loss = criterion(clf(ids), labels)\n        opt_ft.zero_grad()\n        loss.backward()\n        opt_ft.step()\n        train_loss += loss.item()\n        steps += 1\n    train_loss /= steps\n    val_loss, val_ccwa, val_preds, val_gt = evaluate(clf, dev_dl)\n    ts = datetime.datetime.now().isoformat()\n    ed = experiment_data[\"mask_only_structure_preserving\"][\"SPR_BENCH\"]\n    ed[\"losses\"][\"train\"].append(train_loss)\n    ed[\"losses\"][\"val\"].append(val_loss)\n    ed[\"metrics\"][\"train_CCWA\"].append(None)\n    ed[\"metrics\"][\"val_CCWA\"].append(val_ccwa)\n    ed[\"predictions\"].append(val_preds)\n    ed[\"ground_truth\"].append(val_gt)\n    ed[\"timestamps\"].append(ts)\n    print(\n        f\"Epoch {ep}: train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | CCWA={val_ccwa:.4f}\"\n    )\n\n# ---------- save ----------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"Saved all metrics to {os.path.join(working_dir,'experiment_data.npy')}\")\n"], "term_out": ["['Device:', ' ', 'cuda', '\\n', 'Found SPR_BENCH at', ' ', '/home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 480645.40\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 709816.21\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 790393.85\nexamples/s]', '\\n', '[Pre] epoch 1: loss 6.1906', '\\n', '[Pre] epoch 2: loss\n6.1407', '\\n', '[Pre] epoch 3: loss 6.1068', '\\n', '[Pre] epoch 4: loss 6.0904',\n'\\n', '[Pre] epoch 5: loss 6.0636', '\\n', '[Pre] epoch 6: loss 6.0581', '\\n',\n'[FT] ep 1: train 0.6678 | val 0.6233 | CCWA 0.6340', '\\n', '[FT] ep 2: train\n0.4712 | val 0.2517 | CCWA 0.9148', '\\n', '[FT] ep 3: train 0.2319 | val 0.2067\n| CCWA 0.9343', '\\n', '[FT] ep 4: train 0.2181 | val 0.2087 | CCWA 0.9315',\n'\\n', '[FT] ep 5: train 0.2073 | val 0.1926 | CCWA 0.9385', '\\n', '[FT] ep 6:\ntrain 0.1845 | val 0.1735 | CCWA 0.9459', '\\n', '[FT] ep 7: train 0.1715 | val\n0.1757 | CCWA 0.9471', '\\n', '[FT] ep 8: train 0.1538 | val 0.1457 | CCWA\n0.9570', '\\n', '[FT] ep 9: train 0.1434 | val 0.1569 | CCWA 0.9553', '\\n', '[FT]\nep 10: train 0.1388 | val 0.1465 | CCWA 0.9601', '\\n', 'Saved metrics to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n20/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 362603.22\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 519791.80\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 572820.19\nexamples/s]', '\\n', 'Pre-train epoch 1: contrastive_loss=4.9293', '\\n', 'Pre-\ntrain epoch 2: contrastive_loss=4.8577', '\\n', 'Pre-train epoch 3:\ncontrastive_loss=4.8504', '\\n', 'Pre-train epoch 4: contrastive_loss=4.8390',\n'\\n', 'Pre-train epoch 5: contrastive_loss=4.8441', '\\n', 'Pre-train epoch 6:\ncontrastive_loss=4.8393', '\\n', 'Epoch 1: train_loss=0.2954 | val_loss=0.1806 |\nCCWA=0.9415', '\\n', 'Epoch 2: train_loss=0.1822 | val_loss=0.1712 |\nCCWA=0.9461', '\\n', 'Epoch 3: train_loss=0.1729 | val_loss=0.1847 |\nCCWA=0.9431', '\\n', 'Epoch 4: train_loss=0.1767 | val_loss=0.1670 |\nCCWA=0.9461', '\\n', 'Epoch 5: train_loss=0.1692 | val_loss=0.1701 |\nCCWA=0.9461', '\\n', 'Epoch 6: train_loss=0.1707 | val_loss=0.1787 |\nCCWA=0.9457', '\\n', 'Epoch 7: train_loss=0.1928 | val_loss=0.1938 |\nCCWA=0.9328', '\\n', 'Epoch 8: train_loss=0.1778 | val_loss=0.1689 |\nCCWA=0.9461', '\\n', 'Epoch 9: train_loss=0.1697 | val_loss=0.1690 |\nCCWA=0.9461', '\\n', 'Epoch 10: train_loss=0.1673 | val_loss=0.1662 |\nCCWA=0.9461', '\\n', 'Saved all metrics to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n21/working/experiment_data.npy', '\\n', 'Execution time: 54 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 403643.89\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 504754.02\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 607315.64\nexamples/s]', '\\n', 'Pre-train epoch 1: loss=5.0429', '\\n', 'Pre-train epoch 2:\nloss=4.8785', '\\n', 'Pre-train epoch 3: loss=4.8527', '\\n', 'Pre-train epoch 4:\nloss=4.8450', '\\n', 'Pre-train epoch 5: loss=4.8413', '\\n', 'Pre-train epoch 6:\nloss=4.8353', '\\n', 'Epoch 1: train_loss=0.5337 | val_loss=0.5014 |\nCCWA=0.7521', '\\n', 'Epoch 2: train_loss=0.4980 | val_loss=0.4897 |\nCCWA=0.7647', '\\n', 'Epoch 3: train_loss=0.4881 | val_loss=0.4825 |\nCCWA=0.7716', '\\n', 'Epoch 4: train_loss=0.4774 | val_loss=0.4771 |\nCCWA=0.7755', '\\n', 'Epoch 5: train_loss=0.4719 | val_loss=0.4709 |\nCCWA=0.7784', '\\n', 'Epoch 6: train_loss=0.4678 | val_loss=0.4635 |\nCCWA=0.7904', '\\n', 'Epoch 7: train_loss=0.4611 | val_loss=0.4599 |\nCCWA=0.7854', '\\n', 'Epoch 8: train_loss=0.4587 | val_loss=0.4571 |\nCCWA=0.7921', '\\n', 'Epoch 9: train_loss=0.4545 | val_loss=0.4543 |\nCCWA=0.7930', '\\n', 'Epoch 10: train_loss=0.4508 | val_loss=0.4514 |\nCCWA=0.7992', '\\n', 'Saved metrics to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n22/working/experiment_data.npy', '\\n', 'Execution time: 52 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 20000 examples [00:00, 456090.99\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 5000 examples [00:00, 584034.76\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 10000 examples [00:00, 574176.79\nexamples/s]', '\\n', 'Epoch 1: train_loss=0.3408 | val_loss=0.2020 |\nCCWA=0.9373', '\\n', 'Epoch 2: train_loss=0.1481 | val_loss=0.1381 |\nCCWA=0.9637', '\\n', 'Epoch 3: train_loss=0.1230 | val_loss=0.1321 |\nCCWA=0.9640', '\\n', 'Epoch 4: train_loss=0.1153 | val_loss=0.1174 |\nCCWA=0.9701', '\\n', 'Epoch 5: train_loss=0.1064 | val_loss=0.0944 |\nCCWA=0.9750', '\\n', 'Epoch 6: train_loss=0.0895 | val_loss=0.0885 |\nCCWA=0.9722', '\\n', 'Epoch 7: train_loss=0.0807 | val_loss=0.0822 |\nCCWA=0.9743', '\\n', 'Epoch 8: train_loss=0.0734 | val_loss=0.0618 |\nCCWA=0.9821', '\\n', 'Epoch 9: train_loss=0.0637 | val_loss=0.0961 |\nCCWA=0.9673', '\\n', 'Epoch 10: train_loss=0.0540 | val_loss=0.0330 |\nCCWA=0.9885', '\\n', 'Saved metrics to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n23/working/experiment_data.npy', '\\n', 'Execution time: 28 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Pre-train epoch 1: contrastive_loss=4.9256',\n'\\n', 'Pre-train epoch 2: contrastive_loss=4.8619', '\\n', 'Pre-train epoch 3:\ncontrastive_loss=4.8460', '\\n', 'Pre-train epoch 4: contrastive_loss=4.8466',\n'\\n', 'Pre-train epoch 5: contrastive_loss=4.8384', '\\n', 'Pre-train epoch 6:\ncontrastive_loss=4.8421', '\\n', 'Epoch 1: train_loss=0.2895 | val_loss=0.1744 |\ntrain_CAWA=0.8774 | val_CAWA=0.9464', '\\n', 'Epoch 2: train_loss=0.1776 |\nval_loss=0.1798 | train_CAWA=0.9440 | val_CAWA=0.9412', '\\n', 'Epoch 3:\ntrain_loss=0.2016 | val_loss=0.1729 | train_CAWA=0.9331 | val_CAWA=0.9458',\n'\\n', 'Epoch 4: train_loss=0.1691 | val_loss=0.1646 | train_CAWA=0.9454 |\nval_CAWA=0.9461', '\\n', 'Epoch 5: train_loss=0.1690 | val_loss=0.1680 |\ntrain_CAWA=0.9460 | val_CAWA=0.9461', '\\n', 'Epoch 6: train_loss=0.1673 |\nval_loss=0.1801 | train_CAWA=0.9460 | val_CAWA=0.9461', '\\n', 'Epoch 7:\ntrain_loss=0.1669 | val_loss=0.1658 | train_CAWA=0.9460 | val_CAWA=0.9461',\n'\\n', 'Epoch 8: train_loss=0.1653 | val_loss=0.1669 | train_CAWA=0.9459 |\nval_CAWA=0.9463', '\\n', 'Epoch 9: train_loss=0.1695 | val_loss=0.1719 |\ntrain_CAWA=0.9449 | val_CAWA=0.9456', '\\n', 'Epoch 10: train_loss=0.1802 |\nval_loss=0.4692 | train_CAWA=0.9399 | val_CAWA=0.8918', '\\n', 'Saved experiment\ndata to /home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n21/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Pre-train epoch 1: contrastive_loss = 4.6331',\n'\\n', 'Pre-train epoch 2: contrastive_loss = 4.4431', '\\n', 'Pre-train epoch 3:\ncontrastive_loss = 4.4166', '\\n', 'Pre-train epoch 4: contrastive_loss =\n4.3945', '\\n', 'Pre-train epoch 5: contrastive_loss = 4.3810', '\\n', 'Pre-train\nepoch 6: contrastive_loss = 4.3677', '\\n', 'Epoch 1: train_loss=0.1926 |\nval_loss=0.1174 | CCWA=0.9612', '\\n', 'Epoch 2: train_loss=0.1218 |\nval_loss=0.0984 | CCWA=0.9678', '\\n', 'Epoch 3: train_loss=0.0741 |\nval_loss=0.0410 | CCWA=0.9902', '\\n', 'Epoch 4: train_loss=0.0436 |\nval_loss=0.0406 | CCWA=0.9880', '\\n', 'Epoch 5: train_loss=0.0367 |\nval_loss=0.1274 | CCWA=0.9513', '\\n', 'Epoch 6: train_loss=0.0280 |\nval_loss=0.0282 | CCWA=0.9933', '\\n', 'Epoch 7: train_loss=0.0251 |\nval_loss=0.0290 | CCWA=0.9930', '\\n', 'Epoch 8: train_loss=0.0224 |\nval_loss=0.0312 | CCWA=0.9925', '\\n', 'Epoch 9: train_loss=0.0415 |\nval_loss=0.0433 | CCWA=0.9891', '\\n', 'Epoch 10: train_loss=0.0304 |\nval_loss=0.0342 | CCWA=0.9916', '\\n', 'Saved all metrics to /home/zxl240011/AI-S\ncientist-v2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n23/working/experiment_data.npy', '\\n', 'Execution time: 36 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Pre-train epoch 1: contrastive_loss = 5.1393',\n'\\n', 'Pre-train epoch 2: contrastive_loss = 4.9431', '\\n', 'Pre-train epoch 3:\ncontrastive_loss = 4.9100', '\\n', 'Pre-train epoch 4: contrastive_loss =\n4.8915', '\\n', 'Pre-train epoch 5: contrastive_loss = 4.8775', '\\n', 'Pre-train\nepoch 6: contrastive_loss = 4.8627', '\\n', 'Epoch 1: train_loss=0.2081 |\nval_loss=0.1491 | CCWA=0.9558', '\\n', 'Epoch 2: train_loss=0.1375 |\nval_loss=0.1363 | CCWA=0.9626', '\\n', 'Epoch 3: train_loss=0.1286 |\nval_loss=0.1181 | CCWA=0.9684', '\\n', 'Epoch 4: train_loss=0.1144 |\nval_loss=0.1052 | CCWA=0.9687', '\\n', 'Epoch 5: train_loss=0.1007 |\nval_loss=0.0897 | CCWA=0.9746', '\\n', 'Epoch 6: train_loss=0.0898 |\nval_loss=0.1083 | CCWA=0.9667', '\\n', 'Epoch 7: train_loss=0.0850 |\nval_loss=0.0862 | CCWA=0.9710', '\\n', 'Epoch 8: train_loss=0.0615 |\nval_loss=0.0569 | CCWA=0.9840', '\\n', 'Epoch 9: train_loss=0.0564 |\nval_loss=0.0376 | CCWA=0.9898', '\\n', 'Epoch 10: train_loss=0.0348 |\nval_loss=0.0548 | CCWA=0.9861', '\\n', 'Saved all metrics to /home/zxl240011/AI-S\ncientist-v2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n22/working/experiment_data.npy', '\\n', 'Execution time: 37 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Pre-train epoch 1: contrastive_loss=5.0393',\n'\\n', 'Pre-train epoch 2: contrastive_loss=4.8586', '\\n', 'Pre-train epoch 3:\ncontrastive_loss=4.8488', '\\n', 'Pre-train epoch 4: contrastive_loss=4.8521',\n'\\n', 'Pre-train epoch 5: contrastive_loss=4.8484', '\\n', 'Pre-train epoch 6:\ncontrastive_loss=4.8456', '\\n', 'Epoch 1: train_loss=0.5520 | val_loss=0.5344 |\nCCWA=0.7665', '\\n', 'Epoch 2: train_loss=0.5214 | val_loss=0.5232 |\nCCWA=0.7613', '\\n', 'Epoch 3: train_loss=0.5202 | val_loss=0.5209 |\nCCWA=0.7589', '\\n', 'Epoch 4: train_loss=0.5190 | val_loss=0.5259 |\nCCWA=0.7747', '\\n', 'Epoch 5: train_loss=0.5166 | val_loss=0.5222 |\nCCWA=0.7689', '\\n', 'Epoch 6: train_loss=0.5090 | val_loss=0.4978 |\nCCWA=0.7594', '\\n', 'Epoch 7: train_loss=0.4854 | val_loss=0.4699 |\nCCWA=0.7772', '\\n', 'Epoch 8: train_loss=0.4354 | val_loss=0.3873 |\nCCWA=0.8152', '\\n', 'Epoch 9: train_loss=0.3430 | val_loss=0.2966 |\nCCWA=0.9005', '\\n', 'Epoch 10: train_loss=0.2822 | val_loss=0.2676 |\nCCWA=0.9121', '\\n', 'Saved metrics to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n20/working/experiment_data.npy', '\\n', 'Execution time: 55 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Pre-train epoch 1: contrastive_loss=4.9290',\n'\\n', 'Pre-train epoch 2: contrastive_loss=4.8614', '\\n', 'Pre-train epoch 3:\ncontrastive_loss=4.8491', '\\n', 'Pre-train epoch 4: contrastive_loss=4.8469',\n'\\n', 'Pre-train epoch 5: contrastive_loss=4.8449', '\\n', 'Pre-train epoch 6:\ncontrastive_loss=4.8401', '\\n', 'Epoch 1: train_loss=0.5695 | val_loss=0.5389 |\ntrain_CAWA=0.6918 | val_CAWA=0.7131', '\\n', 'Epoch 2: train_loss=0.5396 |\nval_loss=0.5296 | train_CAWA=0.7136 | val_CAWA=0.7224', '\\n', 'Epoch 3:\ntrain_loss=0.3415 | val_loss=0.1940 | train_CAWA=0.8497 | val_CAWA=0.9393',\n'\\n', 'Epoch 4: train_loss=0.1827 | val_loss=0.1725 | train_CAWA=0.9410 |\nval_CAWA=0.9452', '\\n', 'Epoch 5: train_loss=0.1715 | val_loss=0.1708 |\ntrain_CAWA=0.9446 | val_CAWA=0.9428', '\\n', 'Epoch 6: train_loss=0.1714 |\nval_loss=0.1754 | train_CAWA=0.9438 | val_CAWA=0.9461', '\\n', 'Epoch 7:\ntrain_loss=0.1655 | val_loss=0.1671 | train_CAWA=0.9454 | val_CAWA=0.9461',\n'\\n', 'Epoch 8: train_loss=0.1654 | val_loss=0.1699 | train_CAWA=0.9453 |\nval_CAWA=0.9456', '\\n', 'Epoch 9: train_loss=0.1648 | val_loss=0.1681 |\ntrain_CAWA=0.9459 | val_CAWA=0.9459', '\\n', 'Epoch 10: train_loss=0.1628 |\nval_loss=0.1675 | train_CAWA=0.9455 | val_CAWA=0.9455', '\\n', 'Epoch 11:\ntrain_loss=0.1602 | val_loss=0.1658 | train_CAWA=0.9459 | val_CAWA=0.9457',\n'\\n', 'Epoch 12: train_loss=0.1584 | val_loss=0.1719 | train_CAWA=0.9459 |\nval_CAWA=0.9459', '\\n', 'Epoch 13: train_loss=0.1610 | val_loss=0.1668 |\ntrain_CAWA=0.9459 | val_CAWA=0.9454', '\\n', 'Epoch 14: train_loss=0.1579 |\nval_loss=0.1709 | train_CAWA=0.9460 | val_CAWA=0.9448', '\\n', 'Epoch 15:\ntrain_loss=0.1571 | val_loss=0.1673 | train_CAWA=0.9467 | val_CAWA=0.9461',\n'\\n', 'Early stopping triggered.', '\\n', 'Saved experiment data to\n/home/zxl240011/AI-Scientist-v2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n23/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Pre-train epoch 1: contrastive_loss=5.0003',\n'\\n', 'Pre-train epoch 2: contrastive_loss=4.8398', '\\n', 'Pre-train epoch 3:\ncontrastive_loss=4.8323', '\\n', 'Pre-train epoch 4: contrastive_loss=4.8251',\n'\\n', 'Pre-train epoch 5: contrastive_loss=4.8238', '\\n', 'Pre-train epoch 6:\ncontrastive_loss=4.8212', '\\n', 'Epoch 1: train_loss=0.2167 | val_loss=0.1278 |\nCCWA=0.9617', '\\n', 'Epoch 2: train_loss=0.0831 | val_loss=0.0623 |\nCCWA=0.9799', '\\n', 'Epoch 3: train_loss=0.0294 | val_loss=0.0170 |\nCCWA=0.9941', '\\n', 'Epoch 4: train_loss=0.0174 | val_loss=0.0093 |\nCCWA=0.9976', '\\n', 'Epoch 5: train_loss=0.0036 | val_loss=0.0023 |\nCCWA=0.9990', '\\n', 'Epoch 6: train_loss=0.0020 | val_loss=0.0036 |\nCCWA=0.9990', '\\n', 'Epoch 7: train_loss=0.0024 | val_loss=0.0141 |\nCCWA=0.9964', '\\n', 'Epoch 8: train_loss=0.0033 | val_loss=0.0009 |\nCCWA=0.9998', '\\n', 'Epoch 9: train_loss=0.0001 | val_loss=0.0011 |\nCCWA=0.9996', '\\n', 'Epoch 10: train_loss=0.0000 | val_loss=0.0013 |\nCCWA=0.9996', '\\n', 'Saved metrics to', ' ', '/home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n21/working/experiment_data.npy', '\\n', 'Execution time: 47 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Pre-train epoch 1: contrastive_loss = 5.0155',\n'\\n', 'Pre-train epoch 2: contrastive_loss = 4.8596', '\\n', 'Pre-train epoch 3:\ncontrastive_loss = 4.8462', '\\n', 'Pre-train epoch 4: contrastive_loss =\n4.8450', '\\n', 'Pre-train epoch 5: contrastive_loss = 4.8351', '\\n', 'Pre-train\nepoch 6: contrastive_loss = 4.8300', '\\n', 'Epoch 1: train_loss=0.2273 |\nval_loss=0.1507 | CCWA=0.9521', '\\n', 'Epoch 2: train_loss=0.1387 |\nval_loss=0.1175 | CCWA=0.9637', '\\n', 'Epoch 3: train_loss=0.0861 |\nval_loss=0.0346 | CCWA=0.9905', '\\n', 'Epoch 4: train_loss=0.0463 |\nval_loss=0.2499 | CCWA=0.9318', '\\n', 'Epoch 5: train_loss=0.0968 |\nval_loss=0.0809 | CCWA=0.9732', '\\n', 'Epoch 6: train_loss=0.0502 |\nval_loss=0.0760 | CCWA=0.9819', '\\n', 'Epoch 7: train_loss=0.0539 |\nval_loss=0.0720 | CCWA=0.9756', '\\n', 'Epoch 8: train_loss=0.0435 |\nval_loss=0.0569 | CCWA=0.9860', '\\n', 'Epoch 9: train_loss=0.0487 |\nval_loss=0.0753 | CCWA=0.9796', '\\n', 'Epoch 10: train_loss=0.0675 |\nval_loss=0.0550 | CCWA=0.9864', '\\n', 'Saved metrics to /home/zxl240011/AI-Scien\ntist-v2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n22/working/experiment_data.npy', '\\n', 'Execution time: 54 seconds seconds (time\nlimit is 30 minutes).']", "['Using device: cuda', '\\n', 'Found SPR_BENCH at /home/zxl240011/AI-\nScientist-v2/SPR_BENCH', '\\n', 'Pre-train epoch 1: contrastive_loss=4.9487',\n'\\n', 'Pre-train epoch 2: contrastive_loss=4.7761', '\\n', 'Pre-train epoch 3:\ncontrastive_loss=4.7552', '\\n', 'Pre-train epoch 4: contrastive_loss=4.7306',\n'\\n', 'Pre-train epoch 5: contrastive_loss=4.7148', '\\n', 'Pre-train epoch 6:\ncontrastive_loss=4.7008', '\\n', 'Epoch 1: train_loss=0.1863 | val_loss=0.1486 |\nCCWA=0.9543', '\\n', 'Epoch 2: train_loss=0.1393 | val_loss=0.1147 |\nCCWA=0.9655', '\\n', 'Epoch 3: train_loss=0.0746 | val_loss=0.0413 |\nCCWA=0.9892', '\\n', 'Epoch 4: train_loss=0.0439 | val_loss=0.0519 |\nCCWA=0.9861', '\\n', 'Epoch 5: train_loss=0.0511 | val_loss=0.0752 |\nCCWA=0.9798', '\\n', 'Epoch 6: train_loss=0.0610 | val_loss=0.0533 |\nCCWA=0.9868', '\\n', 'Epoch 7: train_loss=0.0480 | val_loss=0.0292 |\nCCWA=0.9923', '\\n', 'Epoch 8: train_loss=0.0321 | val_loss=0.0237 |\nCCWA=0.9949', '\\n', 'Epoch 9: train_loss=0.0341 | val_loss=0.0366 |\nCCWA=0.9912', '\\n', 'Epoch 10: train_loss=0.0292 | val_loss=0.0410 |\nCCWA=0.9869', '\\n', 'Saved all metrics to /home/zxl240011/AI-Scientist-\nv2/experiments/2025-08-16_02-31-\n02_context_aware_contrastive_learning_attempt_0/0-run/process_ForkProcess-\n20/working/experiment_data.npy', '\\n', 'Execution time: a minute seconds (time\nlimit is 30 minutes).']"], "analysis": ["", "", "The execution of the training script was successful. The model was pre-trained\nand fine-tuned without issues. The pre-training loss decreased steadily over six\nepochs, indicating effective learning during the contrastive learning phase.\nDuring fine-tuning, both training and validation losses decreased, and the CCWA\nmetric improved consistently, reaching 0.7992 by the 10th epoch. The results\nwere saved successfully, and there were no apparent bugs or errors in the\nimplementation.", "The training script executed successfully without any bugs. The model showed\nconsistent improvement in both training and validation losses, as well as the\nCCWA metric over 10 epochs. The final validation CCWA reached 0.9885, which is a\nstrong performance. Metrics were successfully saved to a file for later\nanalysis. No issues were detected in the implementation or execution.", "The execution output indicates a potential issue with the fine-tuning process.\nWhile the training loss and train_CAWA remain relatively stable, the validation\nloss and val_CAWA show inconsistent behavior, particularly in the later epochs.\nFor example, the validation loss spikes significantly to 0.4692 in the last\nepoch, and the validation CAWA drops to 0.8918, indicating potential overfitting\nor instability in the fine-tuning phase.   To fix this issue: 1. Implement early\nstopping based on validation loss or validation CAWA to prevent overfitting. 2.\nUse a learning rate scheduler to reduce the learning rate dynamically during\ntraining. 3. Regularize the model using dropout or weight decay. 4. Revisit the\ndata augmentation strategy to ensure it aligns well with the fine-tuning task.", "", "", "", "", "", "The execution output shows that the code ran successfully without any errors or\nbugs. The model underwent pre-training and fine-tuning phases, with metrics\nbeing recorded throughout. The CCWA metric improved significantly during\ntraining and achieved high values (e.g., 0.9864), indicating good performance.\nThe experiment data was successfully saved. No issues were observed.", "The execution of the training script completed successfully without any errors\nor bugs. The pre-training and fine-tuning processes ran as expected, with the\nCCWA metric improving over epochs, and all metrics were saved correctly. The\nresults demonstrate good convergence and performance, meeting the sub-stage\ngoals."], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model fits the training data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.138804, "best_value": 0.138804}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset, used to evaluate the model's performance on unseen data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.14569, "best_value": 0.14569}]}, {"metric_name": "validation CCWA", "lower_is_better": false, "description": "The Correctly Classified Weighted Average (CCWA) on the validation dataset, measuring the model's accuracy.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.960051, "best_value": 0.960051}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Measures the performance of the model on the training dataset. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4508, "best_value": 0.4508}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the performance of the model on the validation dataset. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.4514, "best_value": 0.4514}]}, {"metric_name": "validation CCWA", "lower_is_better": false, "description": "Measures the validation CCWA metric for the model. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7992, "best_value": 0.7992}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.054035, "best_value": 0.054035}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error on the validation set. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.033018, "best_value": 0.033018}]}, {"metric_name": "validation CCWA", "lower_is_better": false, "description": "Measures the validation correctness or accuracy. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.98851, "best_value": 0.98851}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures how well the model fits the training data. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1653, "best_value": 0.1653}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures how well the model generalizes to unseen data. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1646, "best_value": 0.1646}]}, {"metric_name": "training CAWA accuracy", "lower_is_better": false, "description": "Represents the accuracy of the model on the training dataset using the CAWA metric. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.946, "best_value": 0.946}]}, {"metric_name": "validation CAWA accuracy", "lower_is_better": false, "description": "Represents the accuracy of the model on the validation dataset using the CAWA metric. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9464, "best_value": 0.9464}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value computed on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.030425, "best_value": 0.030425}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value computed on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.03416, "best_value": 0.03416}]}, {"metric_name": "validation CCWA", "lower_is_better": false, "description": "The CCWA value computed on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.991635, "best_value": 0.991635}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0348, "best_value": 0.0348}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0376, "best_value": 0.0376}]}, {"metric_name": "validation CCWA", "lower_is_better": false, "description": "The CCWA metric during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9898, "best_value": 0.9898}]}]}, {"metric_names": [{"metric_name": "validation ccwa", "lower_is_better": false, "description": "Validation CCWA score.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9121, "best_value": 0.9121}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Training loss value.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.2822, "best_value": 0.2822}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss value.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.2676, "best_value": 0.2676}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training, lower is better.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1571, "best_value": 0.1571}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, lower is better.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1673, "best_value": 0.1673}]}, {"metric_name": "train Complexity-Adjusted Weighted Accuracy (CAWA)", "lower_is_better": false, "description": "The CAWA metric during training, higher is better.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9467, "best_value": 0.9467}]}, {"metric_name": "validation Complexity-Adjusted Weighted Accuracy (CAWA)", "lower_is_better": false, "description": "The CAWA metric during validation, higher is better.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9461, "best_value": 0.9461}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0009, "best_value": 0.0009}]}, {"metric_name": "validation CCWA", "lower_is_better": false, "description": "The CCWA metric on the validation set.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9998, "best_value": 0.9998}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0675, "best_value": 0.0675}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.055, "best_value": 0.055}]}, {"metric_name": "validation CCWA", "lower_is_better": false, "description": "The CCWA score during validation.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9863662072455571, "best_value": 0.9863662072455571}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Loss calculated during the training phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0292, "best_value": 0.0292}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss calculated during the validation phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.041, "best_value": 0.041}]}, {"metric_name": "validation CCWA", "lower_is_better": false, "description": "Validation CCWA metric indicating the performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9869, "best_value": 0.9869}]}]}], "is_best_node": [false, false, false, false, false, false, false, false, false, true, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_CCWA_curve.png", "../../logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_confusion_matrix.png", "../../logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_class_distribution.png"], [], ["../../logs/0-run/experiment_results/experiment_3f98fa0bd2ca4fd8983513b1dfbac998_proc_3104477/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_3f98fa0bd2ca4fd8983513b1dfbac998_proc_3104477/SPR_BENCH_CCWA_curve.png", "../../logs/0-run/experiment_results/experiment_3f98fa0bd2ca4fd8983513b1dfbac998_proc_3104477/SPR_BENCH_class_distribution.png"], ["../../logs/0-run/experiment_results/experiment_d0295c3d739d4afa8ff1bacfb944dc64_proc_3104478/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_d0295c3d739d4afa8ff1bacfb944dc64_proc_3104478/SPR_BENCH_val_CCWA.png", "../../logs/0-run/experiment_results/experiment_d0295c3d739d4afa8ff1bacfb944dc64_proc_3104478/SPR_BENCH_confusion_matrix.png"], [], ["../../logs/0-run/experiment_results/experiment_d6ec740cb2ee4c7d83c132a1660e8e20_proc_3104478/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_d6ec740cb2ee4c7d83c132a1660e8e20_proc_3104478/SPR_BENCH_CCWA_curve.png", "../../logs/0-run/experiment_results/experiment_d6ec740cb2ee4c7d83c132a1660e8e20_proc_3104478/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_d9b15d54b34943589eed5a2ac805396e_proc_3104477/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_d9b15d54b34943589eed5a2ac805396e_proc_3104477/SPR_BENCH_val_CCWA.png", "../../logs/0-run/experiment_results/experiment_d9b15d54b34943589eed5a2ac805396e_proc_3104477/SPR_BENCH_confusion_matrix_final.png"], ["../../logs/0-run/experiment_results/experiment_f7d564c1d4eb40babbf4b8a2a253b998_proc_3104475/SPR_BENCH_EmbeddingOnly_loss_curve.png", "../../logs/0-run/experiment_results/experiment_f7d564c1d4eb40babbf4b8a2a253b998_proc_3104475/SPR_BENCH_EmbeddingOnly_val_CCWA.png"], ["../../logs/0-run/experiment_results/experiment_e18f4d531f674ea280617736a38d049b_proc_3104478/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_e18f4d531f674ea280617736a38d049b_proc_3104478/SPR_BENCH_CAWA_curves.png", "../../logs/0-run/experiment_results/experiment_e18f4d531f674ea280617736a38d049b_proc_3104478/SPR_BENCH_confusion_matrix_last_epoch.png"], ["../../logs/0-run/experiment_results/experiment_ef8833ca3d9a46e099a3738f35705935_proc_3104476/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_ef8833ca3d9a46e099a3738f35705935_proc_3104476/SPR_BENCH_CCWA_curve.png"], ["../../logs/0-run/experiment_results/experiment_1e8f9fe5b8314ff28cb4371c7a3dfced_proc_3104477/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_1e8f9fe5b8314ff28cb4371c7a3dfced_proc_3104477/SPR_BENCH_val_CCWA.png", "../../logs/0-run/experiment_results/experiment_1e8f9fe5b8314ff28cb4371c7a3dfced_proc_3104477/SPR_BENCH_confusion_matrix_epoch_last.png"], ["../../logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_val_CCWA.png", "../../logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_confusion_epoch_1.png", "../../logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_confusion_epoch_10.png"]], "plot_paths": [["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_CCWA_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_confusion_matrix.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_class_distribution.png"], [], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3f98fa0bd2ca4fd8983513b1dfbac998_proc_3104477/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3f98fa0bd2ca4fd8983513b1dfbac998_proc_3104477/SPR_BENCH_CCWA_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3f98fa0bd2ca4fd8983513b1dfbac998_proc_3104477/SPR_BENCH_class_distribution.png"], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d0295c3d739d4afa8ff1bacfb944dc64_proc_3104478/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d0295c3d739d4afa8ff1bacfb944dc64_proc_3104478/SPR_BENCH_val_CCWA.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d0295c3d739d4afa8ff1bacfb944dc64_proc_3104478/SPR_BENCH_confusion_matrix.png"], [], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d6ec740cb2ee4c7d83c132a1660e8e20_proc_3104478/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d6ec740cb2ee4c7d83c132a1660e8e20_proc_3104478/SPR_BENCH_CCWA_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d6ec740cb2ee4c7d83c132a1660e8e20_proc_3104478/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d9b15d54b34943589eed5a2ac805396e_proc_3104477/SPR_BENCH_loss_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d9b15d54b34943589eed5a2ac805396e_proc_3104477/SPR_BENCH_val_CCWA.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d9b15d54b34943589eed5a2ac805396e_proc_3104477/SPR_BENCH_confusion_matrix_final.png"], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f7d564c1d4eb40babbf4b8a2a253b998_proc_3104475/SPR_BENCH_EmbeddingOnly_loss_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f7d564c1d4eb40babbf4b8a2a253b998_proc_3104475/SPR_BENCH_EmbeddingOnly_val_CCWA.png"], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e18f4d531f674ea280617736a38d049b_proc_3104478/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e18f4d531f674ea280617736a38d049b_proc_3104478/SPR_BENCH_CAWA_curves.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e18f4d531f674ea280617736a38d049b_proc_3104478/SPR_BENCH_confusion_matrix_last_epoch.png"], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ef8833ca3d9a46e099a3738f35705935_proc_3104476/SPR_BENCH_loss_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ef8833ca3d9a46e099a3738f35705935_proc_3104476/SPR_BENCH_CCWA_curve.png"], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1e8f9fe5b8314ff28cb4371c7a3dfced_proc_3104477/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1e8f9fe5b8314ff28cb4371c7a3dfced_proc_3104477/SPR_BENCH_val_CCWA.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1e8f9fe5b8314ff28cb4371c7a3dfced_proc_3104477/SPR_BENCH_confusion_matrix_epoch_last.png"], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_loss_curves.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_val_CCWA.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_confusion_epoch_1.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_confusion_epoch_10.png"]], "plot_analyses": [[{"analysis": "The loss curves show a steady decrease in both training and validation loss over the epochs, indicating effective model training and minimal overfitting. The convergence of training and validation loss towards the end suggests a well-regularized model. The rapid initial drop in loss indicates that the model quickly learns meaningful patterns in the data.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_loss_curves.png"}, {"analysis": "The validation CCWA metric increases rapidly during the initial epochs and stabilizes at a high value (~0.95) by epoch 4. This indicates that the model effectively captures the symbolic patterns and achieves strong performance early in training. The stabilization of CCWA demonstrates that the model maintains its performance across epochs without overfitting.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_CCWA_curve.png"}, {"analysis": "The confusion matrix for the last epoch shows a strong diagonal dominance, indicating that the model performs well in correctly classifying both classes. However, there is a slight imbalance in misclassification rates, which could be explored further to ensure fairness across classes.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_confusion_matrix.png"}, {"analysis": "The class distribution plot for the last epoch reveals a slight discrepancy between the ground truth and predicted class counts. While the difference is not substantial, it suggests a minor bias in the model's predictions. This could be addressed by further fine-tuning or adjusting class weights during training.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_14c129223e87422b8d257c297f571571_proc_3104475/SPR_BENCH_class_distribution.png"}], [], [{"analysis": "The training and validation loss curves demonstrate a consistent decline over the epochs, indicating that the model is learning effectively. The convergence of training and validation loss at later epochs suggests that overfitting is minimal, and the model generalizes well to unseen data. The consistent gap between the two curves is small, which is a positive sign of balanced learning.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3f98fa0bd2ca4fd8983513b1dfbac998_proc_3104477/SPR_BENCH_loss_curves.png"}, {"analysis": "The validation CCWA (Color-Weighted Accuracy) improves steadily across the epochs, with the metric stabilizing towards the later epochs. This indicates that the model's ability to handle color-weighted accuracy improves progressively as training proceeds. The stabilization suggests that the model has reached a performance plateau for this metric.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3f98fa0bd2ca4fd8983513b1dfbac998_proc_3104477/SPR_BENCH_CCWA_curve.png"}, {"analysis": "The class distribution comparison between ground truth and predictions at the final epoch shows that the model predictions align closely with the ground truth distribution. This implies that the model is not biased towards any particular class and performs well in predicting both classes. The slight differences in counts between ground truth and predictions are within acceptable limits, indicating good model calibration.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3f98fa0bd2ca4fd8983513b1dfbac998_proc_3104477/SPR_BENCH_class_distribution.png"}], [{"analysis": "The training and validation loss curves show a consistent decrease across epochs, indicating successful learning and convergence of the model. The validation loss closely follows the training loss, suggesting no significant overfitting. The slight fluctuation in validation loss near the end may reflect minor instability but does not seem detrimental to overall performance.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d0295c3d739d4afa8ff1bacfb944dc64_proc_3104478/SPR_BENCH_loss_curves.png"}, {"analysis": "The Validation CCWA (Color-Weighted Accuracy) improves steadily over epochs, achieving a high value close to 0.99 at the final epoch. This trend indicates effective learning and suggests that the model is successfully optimizing for the CCWA metric, which is a key performance indicator for the SPR task.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d0295c3d739d4afa8ff1bacfb944dc64_proc_3104478/SPR_BENCH_val_CCWA.png"}, {"analysis": "The confusion matrix for the final epoch reveals excellent performance, with near-perfect classification for both classes. The model correctly classifies a majority of the samples, with only 59 misclassifications in one class and no errors in the other. This demonstrates a highly effective model, particularly for the SPR_BENCH dataset.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d0295c3d739d4afa8ff1bacfb944dc64_proc_3104478/SPR_BENCH_confusion_matrix.png"}], [], [{"analysis": "The training and validation loss curves show a consistent downward trend initially, indicating effective learning. However, the spike in validation loss around epoch 5 suggests potential overfitting or instability in the model. Post-epoch 5, both losses stabilize, with validation loss remaining slightly above training loss, which is expected in a well-generalized model. The overall low loss values at the end of training demonstrate that the model has learned the task effectively.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d6ec740cb2ee4c7d83c132a1660e8e20_proc_3104478/SPR_BENCH_loss_curves.png"}, {"analysis": "The validation CCWA metric starts at a relatively high value and improves over the first few epochs, peaking at epoch 5. The sharp drop at epoch 6 could indicate an issue with the model's stability or a temporary learning disruption. After this drop, the CCWA quickly recovers and stabilizes near 0.996, reflecting strong performance and consistent predictions across validation data.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d6ec740cb2ee4c7d83c132a1660e8e20_proc_3104478/SPR_BENCH_CCWA_curve.png"}, {"analysis": "The confusion matrix indicates strong classification performance, with the majority of predictions correctly matching the ground truth. The high intensity along the diagonal signifies minimal misclassification, and the overall balance between classes suggests that the model doesn't exhibit significant bias toward any particular class. This supports the conclusion that the model has effectively learned the symbolic patterns in the SPR_BENCH dataset.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d6ec740cb2ee4c7d83c132a1660e8e20_proc_3104478/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The training and validation loss curves show a consistent decrease over the epochs, indicating that the model is learning effectively. The validation loss closely follows the training loss, suggesting that the model generalizes well to unseen data without overfitting. The slight oscillations in loss values after epoch 6 may indicate some sensitivity to hyperparameters or learning rate adjustments, but the overall trend is stable.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d9b15d54b34943589eed5a2ac805396e_proc_3104477/SPR_BENCH_loss_curve.png"}, {"analysis": "The validation CCWA metric remains consistently high, hovering close to 1.0 throughout the epochs. This indicates that the model is highly effective at maintaining color-weighted accuracy, even as training progresses. The stability of this metric suggests that the model's embedding representations are robust and capture the essential features required for the SPR task.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d9b15d54b34943589eed5a2ac805396e_proc_3104477/SPR_BENCH_val_CCWA.png"}, {"analysis": "The confusion matrix from the final epoch demonstrates strong performance, with the majority of predictions being accurate. The high values along the diagonal indicate that the model is successfully classifying most sequences correctly. The relatively low number of misclassifications in the off-diagonal cells further supports the model's robustness and accuracy.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_d9b15d54b34943589eed5a2ac805396e_proc_3104477/SPR_BENCH_confusion_matrix_final.png"}], [{"analysis": "The loss curves show a consistent decline in both training and validation loss over the epochs, indicating that the model is learning effectively. The validation loss is consistently lower than the training loss after epoch 6, which suggests that the model generalizes well to unseen data. The sharp decline in loss after epoch 6 might indicate that the model has captured key patterns in the data, leading to a significant improvement in performance.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f7d564c1d4eb40babbf4b8a2a253b998_proc_3104475/SPR_BENCH_EmbeddingOnly_loss_curve.png"}, {"analysis": "The CCWA metric exhibits a steady increase, particularly after epoch 6, where a sharp rise is observed. This indicates that the model's ability to correctly classify sequences based on color-weighted accuracy improves significantly in the later epochs. The final CCWA value nearing 0.91 demonstrates the model's strong performance, surpassing the baseline of 0.70 mentioned in the research hypothesis. This improvement aligns well with the observed reduction in loss, suggesting that the embeddings generated by the model are becoming more robust and contextually aware as training progresses.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_f7d564c1d4eb40babbf4b8a2a253b998_proc_3104475/SPR_BENCH_EmbeddingOnly_val_CCWA.png"}], [{"analysis": "The loss curves show a rapid decrease in both training and validation loss during the first few epochs, indicating effective learning and convergence. After around epoch 4, the losses stabilize at a low value, with no evidence of overfitting as the validation loss closely tracks the training loss throughout. This suggests that the model is generalizing well to the validation data.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e18f4d531f674ea280617736a38d049b_proc_3104478/SPR_BENCH_loss_curves.png"}, {"analysis": "The CAWA curves indicate a significant improvement in performance during the initial epochs, with both training and validation CAWA rapidly increasing and stabilizing around 0.95. The close alignment between the training and validation curves suggests that the model is not overfitting and is performing consistently across both datasets. The high CAWA values demonstrate the model's effectiveness in capturing the symbolic patterns.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e18f4d531f674ea280617736a38d049b_proc_3104478/SPR_BENCH_CAWA_curves.png"}, {"analysis": "The confusion matrix from the last epoch shows strong performance, with a high number of correct predictions for both classes. Misclassifications are minimal, as indicated by the relatively low off-diagonal values. This confirms that the model is achieving good accuracy and is effective at distinguishing between the two classes.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_e18f4d531f674ea280617736a38d049b_proc_3104478/SPR_BENCH_confusion_matrix_last_epoch.png"}], [{"analysis": "The plot shows the training and validation loss across epochs. Both losses decrease steadily and converge to near-zero values by epoch 6, indicating effective learning and minimal overfitting. The slight fluctuation in validation loss after epoch 6 may suggest minor noise or overfitting, but overall stability is maintained. This suggests that the training process is well-optimized, and the model generalizes effectively to the validation set.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ef8833ca3d9a46e099a3738f35705935_proc_3104476/SPR_BENCH_loss_curve.png"}, {"analysis": "This plot illustrates the Validation CCWA (Color-Weighted Accuracy) over epochs. The score improves rapidly during the initial epochs and reaches near-perfect accuracy (close to 1.0) by epoch 4. The stability of the CCWA score after epoch 4 indicates that the model maintains its performance without significant degradation, demonstrating strong generalization and robustness in recognizing symbolic patterns.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_ef8833ca3d9a46e099a3738f35705935_proc_3104476/SPR_BENCH_CCWA_curve.png"}], [{"analysis": "The training and validation loss curves exhibit an irregular pattern. While the training loss decreases steadily, the validation loss shows a sharp spike around epoch 4 before stabilizing. This could indicate overfitting or instability in the model's learning process during early epochs. The eventual stabilization of validation loss suggests that the model recovers and learns a more generalizable representation after epoch 4.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1e8f9fe5b8314ff28cb4371c7a3dfced_proc_3104477/SPR_BENCH_loss_curves.png"}, {"analysis": "The validation CCWA metric shows an unusual dip at epoch 4, corresponding to the spike in validation loss observed earlier. This indicates a temporary degradation in the model's ability to generalize to validation data. However, the metric recovers quickly and stabilizes near 0.99, demonstrating strong performance in capturing context-aware features for symbolic sequences over successive epochs.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1e8f9fe5b8314ff28cb4371c7a3dfced_proc_3104477/SPR_BENCH_val_CCWA.png"}, {"analysis": "The confusion matrix for the last epoch displays a clear distinction between the two classes, with minimal misclassification. The majority of predictions align with the true labels, indicating that the model achieves high accuracy for the SPR task by the final epoch.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_1e8f9fe5b8314ff28cb4371c7a3dfced_proc_3104477/SPR_BENCH_confusion_matrix_epoch_last.png"}], [{"analysis": "The loss curves show a consistent decrease in both training and validation loss over epochs, with the validation loss reaching a stable point at around epoch 6. This indicates that the model is learning effectively and generalizing well to the validation set. The slight oscillations in training loss after epoch 6 suggest that further fine-tuning might be needed to stabilize the training process. The structure-preserving nature of the mask-only augmentation appears to be effective in maintaining low validation loss.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_loss_curves.png"}, {"analysis": "The validation CCWA metric improves steadily over the epochs, peaking at epoch 8 before slightly declining. This trend suggests that the model is achieving strong performance in capturing color-weighted accuracy, but overfitting might be a concern after epoch 8. The high CCWA values (close to 0.995) demonstrate the model's effectiveness in handling color-related variations in symbolic sequences.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_val_CCWA.png"}, {"analysis": "The confusion matrix for epoch 1 shows a relatively high number of false positives and false negatives, indicating that the model is initially struggling to classify the sequences correctly. However, the diagonal dominance suggests that the model is still making a majority of correct predictions. This implies that the initial training phase is effective but requires further optimization.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_confusion_epoch_1.png"}, {"analysis": "The confusion matrix for epoch 10 shows a significant improvement in classification accuracy, with almost no false negatives and a drastic reduction in false positives compared to epoch 1. This highlights the model's ability to learn and generalize better with more training epochs. The nearly perfect classification at this stage reflects the effectiveness of the training process and the proposed framework.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_8a5aebe42bf54a109056665e72ab5816_proc_3104475/SPR_BENCH_confusion_epoch_10.png"}]], "vlm_feedback_summary": ["The provided plots demonstrate effective model training and validation\nperformance. The decreasing loss curves, high and stable CCWA, and well-\nperforming confusion matrix indicate that the model successfully learns and\ngeneralizes symbolic patterns. Minor issues, such as slight class imbalance in\npredictions, could be addressed to further improve performance.", "[]", "The plots indicate that the model is learning effectively, with training and\nvalidation loss decreasing steadily and validation CCWA improving consistently\nacross epochs. The class distribution comparison suggests balanced predictions\nwith minimal bias. Overall, the results demonstrate a well-performing model with\nstrong generalization capabilities.", "The provided plots demonstrate strong convergence and performance metrics.\nTraining and validation losses decrease consistently, validation CCWA steadily\nimproves, and the confusion matrix shows near-perfect classification. The\nresults indicate that the model is effectively learning and generalizing for the\nSPR task.", "[]", "The plots collectively demonstrate that the model performs well on the SPR_BENCH\ndataset, achieving low loss values and high CCWA. The confusion matrix\ncorroborates these findings by showing minimal misclassification and balanced\nperformance across classes. However, the spike in validation loss and the CCWA\ndrop at epoch 6 highlight potential areas for further investigation, such as\nmodel stability or training dynamics.", "The provided plots indicate that the model exhibits strong learning behavior,\nwith decreasing loss values and consistently high validation CCWA. The confusion\nmatrix confirms accurate classification performance, with minimal\nmisclassifications.", "The plots demonstrate effective learning and generalization. Loss curves\nindicate a significant reduction in both training and validation loss, while the\nCCWA metric shows a substantial improvement, particularly in later epochs. The\nresults suggest that the proposed method is effective in generating robust\nembeddings for the SPR task.", "The plots demonstrate effective learning and generalization, with rapid\nconvergence in loss curves, high and stable CAWA values, and strong\nclassification performance as evidenced by the confusion matrix. The results\nsuggest that the model components are contributing positively to the overall\nperformance.", "The plots indicate effective training with rapid convergence of loss metrics and\nstrong generalization performance, as reflected in near-perfect CCWA scores.", "The plots reveal insights into the model's learning dynamics and performance.\nThe training and validation loss curves highlight a transient instability,\nfollowed by recovery and stabilization. The validation CCWA metric corroborates\nthis pattern, showing strong eventual performance. The confusion matrix confirms\nthe model's high accuracy in classifying symbolic sequences.", "The plots demonstrate effective learning and generalization of the model, with\nsignificant improvements in validation loss, CCWA, and classification accuracy\nover epochs. The results highlight the success of the context-aware contrastive\nlearning framework and the mask-only augmentation technique."], "exec_time": [66.10296964645386, 54.13801693916321, 52.021870136260986, 28.65741801261902, 73.54142379760742, 36.23182678222656, 37.09806847572327, 55.6460657119751, 83.81315016746521, 47.16180348396301, 54.35009741783142, 63.4407479763031], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[\"SPR_BENCH\"]"], [], ["['SPR_BENCH']"], ["['SPR_BENCH']"], [], ["['SPR_BENCH']"], ["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["[\"SPR_BENCH\"]"], ["['dset_key']"]], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nexp = experiment_data.get(\"no_proj\", {}).get(\"SPR_BENCH\", {})\n\nloss_tr = np.array(exp.get(\"losses\", {}).get(\"train\", []), dtype=float)\nloss_val = np.array(exp.get(\"losses\", {}).get(\"val\", []), dtype=float)\nccwa_val = np.array(exp.get(\"metrics\", {}).get(\"val_CCWA\", []), dtype=float)\npred_epochs = exp.get(\"predictions\", [])\ngt_epochs = exp.get(\"ground_truth\", [])\n\nepochs = np.arange(1, len(loss_tr) + 1)\n\n# 1) Loss curves\ntry:\n    plt.figure()\n    plt.plot(epochs, loss_tr, label=\"Train Loss\")\n    plt.plot(epochs, loss_val, label=\"Val Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH Loss Curves\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# 2) CCWA curve\ntry:\n    plt.figure()\n    plt.plot(epochs, ccwa_val, marker=\"o\", color=\"green\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CCWA\")\n    plt.title(\"SPR_BENCH Validation CCWA over Epochs\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_CCWA_curve.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CCWA plot: {e}\")\n    plt.close()\n\n# 3) Confusion matrix for final epoch\ntry:\n    if pred_epochs and gt_epochs:\n        preds = np.array(pred_epochs[-1])\n        gts = np.array(gt_epochs[-1])\n        classes = np.union1d(preds, gts)\n        cm = np.zeros((classes.size, classes.size), dtype=int)\n        for p, g in zip(preds, gts):\n            cm[g == classes, p == classes] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR_BENCH Confusion Matrix (Last Epoch)\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n\n# 4) Class frequency bars (last epoch)\ntry:\n    if pred_epochs and gt_epochs:\n        preds = np.array(pred_epochs[-1])\n        gts = np.array(gt_epochs[-1])\n        classes = np.union1d(preds, gts)\n        pred_counts = [(preds == c).sum() for c in classes]\n        gt_counts = [(gts == c).sum() for c in classes]\n        x = np.arange(len(classes))\n        plt.figure()\n        plt.bar(x - 0.2, gt_counts, width=0.4, label=\"Ground Truth\")\n        plt.bar(x + 0.2, pred_counts, width=0.4, label=\"Predictions\")\n        plt.xticks(x, classes)\n        plt.xlabel(\"Class\")\n        plt.ylabel(\"Count\")\n        plt.title(\n            \"SPR_BENCH Class Distribution (Last Epoch)\\nLeft: Ground Truth, Right: Predictions\"\n        )\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_class_distribution.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating class distribution plot: {e}\")\n    plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# -------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nds_key = \"SPR_BENCH\"\nexp_key = \"FreezeEncoder\"\nexp = experiment_data.get(exp_key, {}).get(ds_key, {})\n\nloss_train = exp.get(\"losses\", {}).get(\"train\", [])\nloss_val = exp.get(\"losses\", {}).get(\"val\", [])\nccwa_val = exp.get(\"metrics\", {}).get(\"val_CCWA\", [])\npreds = exp.get(\"predictions\", [])\ngts = exp.get(\"ground_truth\", [])\n\n# ------------------- Plot 1: Loss curves ---------------------\ntry:\n    plt.figure()\n    epochs = np.arange(1, len(loss_train) + 1)\n    plt.plot(epochs, loss_train, label=\"Train Loss\")\n    plt.plot(epochs, loss_val, label=\"Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"FreezeEncoder on SPR_BENCH\\nTraining vs Validation Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# ------------------- Plot 2: CCWA curve ----------------------\ntry:\n    plt.figure()\n    plt.plot(epochs, ccwa_val, marker=\"o\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CCWA\")\n    plt.ylim(0, 1)\n    plt.title(\"FreezeEncoder on SPR_BENCH\\nValidation CCWA Across Epochs\")\n    fname = os.path.join(working_dir, \"SPR_BENCH_CCWA_curve.png\")\n    plt.savefig(fname)\n    print(f\"Saved {fname}\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CCWA plot: {e}\")\n    plt.close()\n\n# ------------------- Plot 3: Class dist. ---------------------\ntry:\n    if preds and gts:\n        final_preds = np.array(preds[-1])\n        final_gts = np.array(gts[-1])\n        classes = sorted(set(final_gts) | set(final_preds))\n        counts_gt = [np.sum(final_gts == c) for c in classes]\n        counts_pr = [np.sum(final_preds == c) for c in classes]\n\n        x = np.arange(len(classes))\n        width = 0.35\n        plt.figure()\n        plt.bar(x - width / 2, counts_gt, width, label=\"Ground Truth\")\n        plt.bar(x + width / 2, counts_pr, width, label=\"Predictions\")\n        plt.xlabel(\"Class\")\n        plt.ylabel(\"Count\")\n        plt.xticks(x, classes)\n        plt.title(\n            \"FreezeEncoder on SPR_BENCH\\nFinal-Epoch Class Distribution: GT vs Pred\"\n        )\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_class_distribution.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating class distribution plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------ load experiment data ---------------------\ntry:\n    exp = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = {}\n\nbench = exp.get(\"no_pretrain\", {}).get(\"SPR_BENCH\", {})\n\n# ------------------ PLOT 1: loss curves ----------------------\ntry:\n    train_losses = bench.get(\"losses\", {}).get(\"train\", [])\n    val_losses = bench.get(\"losses\", {}).get(\"val\", [])\n    if train_losses and val_losses:\n        epochs = np.arange(1, len(train_losses) + 1)\n        plt.figure()\n        plt.plot(epochs, train_losses, label=\"Train Loss\")\n        plt.plot(epochs, val_losses, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH \u2013 Training vs. Validation Loss\")\n        plt.legend()\n        fn = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fn)\n        print(f\"Saved {fn}\")\n    else:\n        print(\"Loss data missing, skipping loss plot.\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# ------------------ PLOT 2: CCWA metric ----------------------\ntry:\n    val_ccwa = bench.get(\"metrics\", {}).get(\"val_CCWA\", [])\n    if val_ccwa:\n        epochs = np.arange(1, len(val_ccwa) + 1)\n        plt.figure()\n        plt.plot(epochs, val_ccwa, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CCWA\")\n        plt.title(\"SPR_BENCH \u2013 Validation CCWA Across Epochs\")\n        fn = os.path.join(working_dir, \"SPR_BENCH_val_CCWA.png\")\n        plt.savefig(fn)\n        print(f\"Saved {fn}\")\n    else:\n        print(\"CCWA data missing, skipping CCWA plot.\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CCWA plot: {e}\")\n    plt.close()\n\n# ------------------ PLOT 3: confusion matrix -----------------\ntry:\n    preds_all = bench.get(\"predictions\", [])\n    gts_all = bench.get(\"ground_truth\", [])\n    if preds_all and gts_all:\n        preds = preds_all[-1]\n        gts = gts_all[-1]\n        num_classes = len(set(gts) | set(preds))\n        cm = np.zeros((num_classes, num_classes), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted Label\")\n        plt.ylabel(\"True Label\")\n        plt.title(\"SPR_BENCH \u2013 Confusion Matrix (Final Epoch)\")\n        for i in range(num_classes):\n            for j in range(num_classes):\n                plt.text(\n                    j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\", fontsize=8\n                )\n        fn = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\")\n        plt.savefig(fn)\n        print(f\"Saved {fn}\")\n    else:\n        print(\"Prediction data missing, skipping confusion matrix.\")\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# mandatory working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# locate run & dataset safely\nrun_name = \"NoAugContrastive\"\ndset_name = \"SPR_BENCH\"\ned = experiment_data.get(run_name, {}).get(dset_name, {})\n\ntrain_loss = ed.get(\"losses\", {}).get(\"train\", [])\nval_loss = ed.get(\"losses\", {}).get(\"val\", [])\nval_ccwa = ed.get(\"metrics\", {}).get(\"val_CCWA\", [])\npreds_list = ed.get(\"predictions\", [])\ngts_list = ed.get(\"ground_truth\", [])\n\n# 1) Loss curves -------------------------------------------------------------\ntry:\n    if train_loss and val_loss:\n        epochs = np.arange(1, len(train_loss) + 1)\n        plt.figure()\n        plt.plot(epochs, train_loss, label=\"Train Loss\")\n        plt.plot(epochs, val_loss, label=\"Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH: Training vs. Validation Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# 2) CCWA curve --------------------------------------------------------------\ntry:\n    if val_ccwa:\n        epochs = np.arange(1, len(val_ccwa) + 1)\n        plt.figure()\n        plt.plot(epochs, val_ccwa, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CCWA\")\n        plt.title(\"SPR_BENCH: Validation CCWA over Epochs\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_CCWA_curve.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating CCWA plot: {e}\")\n    plt.close()\n\n# 3) Confusion matrix for last epoch ----------------------------------------\ntry:\n    if preds_list and gts_list:\n        preds = np.array(preds_list[-1])\n        gts = np.array(gts_list[-1])\n        n_cls = max(np.max(preds), np.max(gts)) + 1\n        cm = np.zeros((n_cls, n_cls), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n        plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(\"SPR_BENCH: Confusion Matrix (final epoch)\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\"))\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n\n# Print final metric for quick inspection\nif val_ccwa:\n    print(f\"Final validation CCWA: {val_ccwa[-1]:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    exp_path = os.path.join(working_dir, \"experiment_data.npy\")\n    experiment_data = np.load(exp_path, allow_pickle=True).item()\n    ed = experiment_data[\"CLS_POOL_ONLY\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\nepochs = np.arange(1, len(ed[\"losses\"][\"train\"]) + 1)\n\n# 1) Loss curves -------------------------------------------------\ntry:\n    plt.figure()\n    plt.plot(epochs, ed[\"losses\"][\"train\"], label=\"Train Loss\")\n    plt.plot(epochs, ed[\"losses\"][\"val\"], label=\"Val Loss\")\n    plt.title(\"SPR_BENCH \u2013 Training vs Validation Loss\\nLeft: Train, Right: Validation\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.legend()\n    save_path = os.path.join(working_dir, \"SPR_BENCH_loss_curve.png\")\n    plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# 2) CCWA metric -------------------------------------------------\ntry:\n    plt.figure()\n    plt.plot(epochs, ed[\"metrics\"][\"val_CCWA\"], marker=\"o\")\n    plt.title(\"SPR_BENCH \u2013 Validation CCWA over Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CCWA\")\n    plt.ylim(0, 1)\n    save_path = os.path.join(working_dir, \"SPR_BENCH_val_CCWA.png\")\n    plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CCWA plot: {e}\")\n    plt.close()\n\n# 3) Confusion matrix (final epoch) ------------------------------\ntry:\n    preds = np.array(ed[\"predictions\"][-1])\n    labels = np.array(ed[\"ground_truth\"][-1])\n    n_cls = int(max(labels.max(), preds.max()) + 1)\n    cm = np.zeros((n_cls, n_cls), dtype=int)\n    for t, p in zip(labels, preds):\n        cm[t, p] += 1\n\n    plt.figure()\n    im = plt.imshow(cm, cmap=\"Blues\")\n    plt.title(\"SPR_BENCH \u2013 Confusion Matrix (Final Epoch)\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.colorbar(im, fraction=0.046, pad=0.04)\n    # annotate\n    for i in range(n_cls):\n        for j in range(n_cls):\n            plt.text(\n                j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\", fontsize=8\n            )\n    save_path = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix_final.png\")\n    plt.savefig(save_path)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix: {e}\")\n    plt.close()\n\nprint(\"All figures saved to\", working_dir)\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data:\n    exp = experiment_data.get(\"EmbeddingOnly\", {}).get(\"SPR_BENCH\", {})\n    losses = exp.get(\"losses\", {})\n    metrics = exp.get(\"metrics\", {})\n    train_loss = losses.get(\"train\", [])\n    val_loss = losses.get(\"val\", [])\n    val_ccwa = metrics.get(\"val_CCWA\", [])\n\n    # Plot 1: Loss curves\n    try:\n        plt.figure()\n        epochs = range(1, len(train_loss) + 1)\n        plt.plot(epochs, train_loss, label=\"Train Loss\")\n        plt.plot(epochs, val_loss, label=\"Validation Loss\")\n        plt.title(\"SPR_BENCH Loss Curves (EmbeddingOnly)\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_EmbeddingOnly_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve: {e}\")\n        plt.close()\n\n    # Plot 2: Validation CCWA\n    try:\n        plt.figure()\n        plt.plot(epochs, val_ccwa, marker=\"o\")\n        plt.title(\"SPR_BENCH Validation CCWA (EmbeddingOnly)\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CCWA\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_EmbeddingOnly_val_CCWA.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CCWA plot: {e}\")\n        plt.close()\n\n    # Print final metric\n    if val_ccwa:\n        print(f\"Final Validation CCWA: {val_ccwa[-1]:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# mandatory working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------------------------------------------------------ #\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ndataset = \"SPR_BENCH\"\ndata = experiment_data.get(dataset, {})\n\nloss_tr = data.get(\"losses\", {}).get(\"train\", [])\nloss_val = data.get(\"losses\", {}).get(\"val\", [])\ncawa_tr = data.get(\"metrics\", {}).get(\"train_CAWA\", [])\ncawa_val = data.get(\"metrics\", {}).get(\"val_CAWA\", [])\npreds_all = data.get(\"predictions\", [])\ngts_all = data.get(\"ground_truth\", [])\n\n# ------------------------------------------------------------------ #\n# print evaluation metrics\nif cawa_val:\n    print(f\"Final Train CAWA: {cawa_tr[-1]:.4f}\")\n    print(f\"Final Val   CAWA: {cawa_val[-1]:.4f}\")\n    print(f\"Best  Val   CAWA: {max(cawa_val):.4f}\")\n\n# ------------------------------------------------------------------ #\n# Plot 1: Loss curves\ntry:\n    plt.figure()\n    epochs = range(1, len(loss_tr) + 1)\n    plt.plot(epochs, loss_tr, label=\"Train Loss\")\n    plt.plot(epochs, loss_val, label=\"Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(f\"{dataset} Loss Curves\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{dataset}_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# Plot 2: CAWA curves\ntry:\n    plt.figure()\n    epochs = range(1, len(cawa_tr) + 1)\n    plt.plot(epochs, cawa_tr, label=\"Train CAWA\")\n    plt.plot(epochs, cawa_val, label=\"Validation CAWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CAWA\")\n    plt.title(f\"{dataset} CAWA Curves\")\n    plt.legend()\n    fname = os.path.join(working_dir, f\"{dataset}_CAWA_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CAWA curve plot: {e}\")\n    plt.close()\n\n# ------------------------------------------------------------------ #\n# Plot 3: Confusion matrix for last epoch (if data present)\ntry:\n    if preds_all and gts_all:\n        preds = np.array(preds_all[-1])\n        gts = np.array(gts_all[-1])\n        num_cls = max(gts.max(), preds.max()) + 1\n        cm = np.zeros((num_cls, num_cls), dtype=int)\n        for t, p in zip(gts, preds):\n            cm[t, p] += 1\n\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(f\"{dataset} Confusion Matrix (Last Epoch)\")\n        plt.xticks(range(num_cls))\n        plt.yticks(range(num_cls))\n        fname = os.path.join(working_dir, f\"{dataset}_confusion_matrix_last_epoch.png\")\n        plt.savefig(fname)\n        plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n\n# helper to safely fetch nested keys\ndef safe_get(dic, keys, default=None):\n    for k in keys:\n        dic = dic.get(k, {})\n    return dic if dic else default\n\n\n# extract metrics\nloss_train = safe_get(experiment_data, [\"BiLSTM\", \"SPR_BENCH\", \"losses\", \"train\"], [])\nloss_val = safe_get(experiment_data, [\"BiLSTM\", \"SPR_BENCH\", \"losses\", \"val\"], [])\nccwa_val = safe_get(experiment_data, [\"BiLSTM\", \"SPR_BENCH\", \"metrics\", \"val_CCWA\"], [])\n\nepochs = np.arange(1, len(loss_val) + 1)\n\n# 1) train / val loss curve\ntry:\n    plt.figure()\n    if loss_train:\n        plt.plot(epochs, loss_train, label=\"Train Loss\")\n    if loss_val:\n        plt.plot(epochs, loss_val, label=\"Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH: Training vs Validation Loss\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_loss_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve: {e}\")\n    plt.close()\n\n# 2) validation CCWA curve\ntry:\n    plt.figure()\n    if ccwa_val:\n        plt.plot(epochs, ccwa_val, marker=\"o\", label=\"Validation CCWA\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CCWA Score\")\n    plt.title(\"SPR_BENCH: Validation CCWA over Epochs\")\n    plt.legend()\n    plt.tight_layout()\n    fname = os.path.join(working_dir, \"SPR_BENCH_CCWA_curve.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CCWA curve: {e}\")\n    plt.close()\n\n# print summary metrics\nif ccwa_val:\n    print(f\"Best CCWA: {max(ccwa_val):.4f} at epoch {int(np.argmax(ccwa_val)+1)}\")\n    print(f\"Final CCWA: {ccwa_val[-1]:.4f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------ load experiment data ---------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    try:\n        ed = experiment_data[\"FixedSinPE\"][\"SPR_BENCH\"]\n        train_losses = np.array(ed[\"losses\"][\"train\"])\n        val_losses = np.array(ed[\"losses\"][\"val\"])\n        val_ccwa = np.array(ed[\"metrics\"][\"val_CCWA\"])\n        preds_list = ed[\"predictions\"]\n        gts_list = ed[\"ground_truth\"]\n        epochs = np.arange(1, len(train_losses) + 1)\n    except KeyError as e:\n        print(f\"Missing key while parsing data: {e}\")\n        ed, epochs = None, None\n\n# ------------------ Plot 1: loss curves ----------------------\nif ed is not None:\n    try:\n        plt.figure()\n        plt.plot(epochs, train_losses, label=\"Train Loss\")\n        plt.plot(epochs, val_losses, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH \u2013 Training vs Validation Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # ------------------ Plot 2: CCWA metric ----------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, val_ccwa, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"CCWA\")\n        plt.title(\"SPR_BENCH \u2013 Validation CCWA over Epochs\")\n        fname = os.path.join(working_dir, \"SPR_BENCH_val_CCWA.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating CCWA plot: {e}\")\n        plt.close()\n\n    # ------------------ Plot 3: confusion matrix last epoch -----\n    try:\n        y_true = np.array(gts_list[-1])\n        y_pred = np.array(preds_list[-1])\n        classes = np.arange(len(np.unique(np.concatenate([y_true, y_pred]))))\n        cm = np.zeros((len(classes), len(classes)), dtype=int)\n        for t, p in zip(y_true, y_pred):\n            cm[t, p] += 1\n\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im, fraction=0.046, pad=0.04)\n        plt.xlabel(\"Predicted label\")\n        plt.ylabel(\"True label\")\n        plt.title(\"SPR_BENCH \u2013 Confusion Matrix (Last Epoch)\")\n        plt.xticks(classes)\n        plt.yticks(classes)\n        fname = os.path.join(working_dir, \"SPR_BENCH_confusion_matrix_epoch_last.png\")\n        plt.savefig(fname)\n        print(f\"Saved {fname}\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# Navigate keys safely\ntry:\n    exp_key = next(iter(experiment_data.keys()))\n    dset_key = next(iter(experiment_data[exp_key].keys()))\n    ed = experiment_data[exp_key][dset_key]\nexcept Exception as e:\n    print(f\"Error extracting experiment dict: {e}\")\n    ed = {}\n\nepochs = list(range(1, len(ed.get(\"losses\", {}).get(\"train\", [])) + 1))\n\n# Plot 1: train vs val loss\ntry:\n    plt.figure()\n    plt.plot(epochs, ed[\"losses\"][\"train\"], label=\"Train Loss\")\n    plt.plot(epochs, ed[\"losses\"][\"val\"], label=\"Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\n        f\"{dset_key} \u2013 Loss Curves\\nMask-Only Augmentation (Structure-Preserving)\"\n    )\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, f\"{dset_key}_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n    plt.close()\n\n# Plot 2: validation CCWA\ntry:\n    plt.figure()\n    plt.plot(epochs, ed[\"metrics\"][\"val_CCWA\"], marker=\"o\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"CCWA\")\n    plt.title(f\"{dset_key} \u2013 Validation CCWA over Epochs\")\n    plt.savefig(os.path.join(working_dir, f\"{dset_key}_val_CCWA.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating CCWA plot: {e}\")\n    plt.close()\n\n\n# Helper to build confusion matrix\ndef confusion_matrix(gt, pred, n):\n    cm = np.zeros((n, n), dtype=int)\n    for g, p in zip(gt, pred):\n        cm[g, p] += 1\n    return cm\n\n\n# Determine class count\nn_cls = 0\nif ed.get(\"ground_truth\"):\n    n_cls = (\n        max(\n            max(max(g) for g in ed[\"ground_truth\"]),\n            max(max(p) for p in ed[\"predictions\"]),\n        )\n        + 1\n    )\n\n# Plot 3 & 4: confusion matrices for first and last epoch (max 2 figs)\nfor idx, ep in enumerate([0, len(epochs) - 1][:2]):\n    try:\n        gt = ed[\"ground_truth\"][ep]\n        pr = ed[\"predictions\"][ep]\n        cm = confusion_matrix(gt, pr, n_cls)\n        plt.figure()\n        plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar()\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Ground Truth\")\n        plt.title(f\"{dset_key} \u2013 Confusion Matrix (Epoch {ep+1})\")\n        for i in range(n_cls):\n            for j in range(n_cls):\n                plt.text(\n                    j,\n                    i,\n                    cm[i, j],\n                    ha=\"center\",\n                    va=\"center\",\n                    color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n                    fontsize=8,\n                )\n        plt.tight_layout()\n        fname = f\"{dset_key}_confusion_epoch_{ep+1}.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for epoch {ep+1}: {e}\")\n        plt.close()\n"], "plot_plan": ["We will load the saved experiment_data.npy, grab the single experiment (\u201cno_proj\u201d) and its SPR_BENCH entry, and extract the epoch-wise arrays for training loss, validation loss and validation CCWA.  \nA first figure overlays training and validation losses across epochs to show convergence.  \nA second figure plots the CCWA metric over epochs to highlight downstream performance.  \nTo inspect label-level behavior we take the last epoch\u2019s prediction/ground-truth lists, build a confusion matrix, and visualize it with a heat-map; class indices are used because no class names were stored.  \nWe also show class-frequency bar charts for the same epoch to compare prediction distribution versus ground truth distribution.  \nEach plot is wrapped in its own try-except block, saved inside the working/ directory with descriptive filenames that include the dataset and plot type, and the figure is always closed.  \nAll plotting uses only the arrays that already exist in experiment_data.npy, and no synthetic values are fabricated.  \nAt most four figures are produced, satisfying the limit of five.  \nAll code is concise, starts with the required imports and working_dir definition, and prints a short confirmation after saving each plot.", null, "We will load the saved experiment_data.npy, extract the arrays for training loss, validation loss, and validation CCWA for the SPR_BENCH dataset, and build clear line-plots for each metric across epochs.  Each figure is wrapped in its own try-except so that a failure in one plot does not interrupt creation of the others.  We respect the working directory convention and save every figure there, always closing the figure afterwards.  Titles include both the dataset and a subtitle clarifying what is shown.  Because there are only 10 epochs, no sub-sampling is needed to satisfy the \u201c\u2264 5 figures\u201d guideline; we still generate at most three independent plots: (1) loss curves, (2) CCWA curve, and (3) a bar chart comparing class counts of ground-truth vs predictions for the final epoch (giving users intuition about class imbalance or bias).  All data come directly from experiment_data.npy with no fabrication.  The script prints the paths of the saved images so users can locate them easily.  The code is concise, relying solely on standard matplotlib and numpy.", "We will load experiment_data.npy, extract the single benchmark (\u201cno_pretrain \u2192 SPR_BENCH\u201d), then assemble three concise plots: (1) training vs. validation loss across epochs, (2) validation CCWA metric across epochs, and (3) a confusion-matrix style heat-map of ground-truth vs. model predictions for the final epoch. Each plot is wrapped in an independent try-except block so a failure in one will not derail the rest, and all figures are closed after saving. Filenames always contain the dataset name and plot type, e.g. \u201cSPR_BENCH_loss_curves.png\u201d. Titles clearly describe content and add subtitles where helpful. We cap the number of figures at three\u2014well below the limit of five\u2014to avoid clutter. No nonexistent data are fabricated; every plotted value comes directly from the loaded experiment_data structure. Finally the script prints confirmation messages so the user can verify successful execution.", null, "We will first load the serialized experiment_data dictionary and discover the only run recorded: NoAugContrastive on the SPR_BENCH dataset.  From this we extract per-epoch train/val losses (losses[\u2026]), the validation CCWA metric (metrics['val_CCWA']), and the lists of predictions/ground-truth labels stored for each epoch.  Using these series, we prepare three standard plots: (1) training vs. validation loss across epochs, (2) validation CCWA across epochs, and (3) a confusion-matrix heat-map for the final epoch\u2019s predictions.  Each figure is produced in an isolated try-except block, saved inside the working directory with descriptive filenames, and then closed to free memory.  We cap the visualisations at these three figures (\u22645 as required).  After plotting we also print the final epoch\u2019s CCWA so the notebook logs an explicit numerical result.  Only numpy and matplotlib are used in order to stay lightweight and avoid extra dependencies.  The code begins with the mandated imports and creates working_dir if it is missing.", "We will load the saved experiment_data dictionary, extract the arrays containing training/validation loss and the validation\u2010only CCWA metric, and then plot them against epoch indices.  The first figure shows both loss curves together; the second figure shows the CCWA progression.  Because predictions and labels for every epoch are stored, we can build a confusion matrix for the final epoch to visualise model performance\u2014this will be the third figure.  Each plot is wrapped in its own try/except block, saved to working_dir with descriptive filenames that include the dataset and plot type, and all figures are explicitly closed.  We rely solely on matplotlib, numpy and the provided .npy file, and we plot no more than three figures, well under the five-figure limit.  Titles and subtitles clarify content (e.g. \u201cLeft: Train, Right: Validation\u201d where relevant).  No synthetic or missing data are fabricated.  The code adheres to the required header imports, directory handling, and plotting conventions.  Finally, it prints a short confirmation once all figures are generated.", "We will load experiment_data.npy, locate the EmbeddingOnly/SPR_BENCH entry, and extract the per-epoch arrays for train/val losses and val_CCWA. Two separate plots will be produced: (1) a line plot showing train vs. validation loss across epochs, and (2) a line plot of validation CCWA across epochs. Each plot is wrapped in its own try-except block, saved under clear filenames inside the working directory, and the figures are always closed. After plotting we also print the final epoch\u2019s validation CCWA to stdout so the user can quickly see the headline metric. All operations strictly rely on the stored numpy object\u2014no fabricated data are introduced.", "We load the saved experiment_data.npy, extract the lists of training/validation losses and CAWA metrics, and print the final and best CAWA scores for quick inspection. Three plots are created: (1) Loss curves showing train vs. validation loss across epochs, (2) CAWA curves for train vs. validation, and (3) a confusion-matrix heat-map for the last epoch\u2019s validation predictions against ground-truth labels. Each plot is wrapped in its own try-except block, saved to the mandatory working_dir with descriptive filenames, and the figure is properly closed afterwards. Only information stored inside experiment_data.npy is used\u2014no synthetic data are added. We explicitly create working_dir if it doesn\u2019t exist and respect the \u22645-figure rule. All plotting relies solely on vanilla matplotlib without fancy styling, and titles include the dataset name and plot type for clarity. Finally, the script prints the evaluation metrics to stdout so users can read them directly in addition to the saved figures.", "We will load experiment_data.npy, extract the per-epoch arrays for training/validation loss and the validation CCWA metric, and compute the epoch indices. Two separate try-except blocks will create: (1) a line plot comparing training vs. validation loss, and (2) a line plot of validation CCWA. Each figure is titled with the dataset name (\u201cSPR_BENCH\u201d) and a clear subtitle, then saved to working_dir with descriptive filenames. All figures are closed after saving to avoid memory leaks. After plotting we print the best and final CCWA values for quick inspection. No synthetic data is generated\u2014everything comes directly from the loaded file. Up to five plots are permitted but we only need two, so we stay within limits. The code follows all style and saving conventions requested, starting with the mandated imports.", "We will load the saved experiment_data.npy, retrieve the FixedSinPE / SPR_BENCH entry, and extract per-epoch arrays for training loss, validation loss, and CCWA.  \nThree separate plots will be produced, each wrapped in a try-except block: (1) training vs. validation loss over epochs; (2) validation CCWA over epochs; (3) confusion matrix of ground-truth vs. predictions for the last recorded epoch (to give a qualitative view of classifier performance).  \nAll plots use basic matplotlib, carry clear titles/sub-titles, are saved in the working directory with descriptive names, and figures are always closed.  \nWe respect the \u201cmax 5 figures\u201d rule by producing only these three visuals.  \nThe code starts with the required imports, creates working_dir, loads the data safely, generates the plots, and prints a brief confirmation of saved files.", "We load experiment_data.npy, locate the \u201cmask_only_structure_preserving\u2013SPR_BENCH\u201d entry, and pull out epoch-wise arrays for train/val losses and val_CCWA.  With these series we create two line plots: (1) train vs. validation loss, (2) validation CCWA.  Because predictions and ground-truth labels are stored for every epoch, we also build a confusion-matrix heat-map; to keep the figure count low we only visualize the first and last epoch (max = 2 matrices).  Each plot is wrapped in its own try\u2013except block, saved to working_dir with descriptive names, titled clearly, and the figure is always closed.  No data are fabricated\u2014everything comes directly out of experiment_data.npy.  We obey the plotting guidelines: basic matplotlib, explicit titles/subtitles, \u2264 5 figures, and separate figure files.  The script is concise, self-contained, and prints nothing except possible error messages.  Running it inside the same working directory will populate PNG files for easy inspection.  Below is the complete implementation."], "ablation_name": ["Remove Projection Head (\u201cNo-Proj\u201d Ablation)", "No-Position-Embedding", "Freeze-Encoder (No-Fine-Tune)", "No-Pretraining (Supervised-Only)", null, "No-Augmentation-Contrastive", "CLS-POOL ONLY", "No-Transformer-Encoder (Embedding-Only)", null, "BiLSTM-Encoder", "Fixed-Sinusoidal-Position-Embedding", "Mask-Only Augmentation (Structure-Preserving)"], "hyperparam_name": [null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, false, false, false], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false], "parse_metrics_plan": ["The script will locate the working directory, load the serialized\nexperiment_data dictionary, and then iterate through every saved dataset entry.\nFor each dataset it prints the dataset name first, followed by the final\ntraining loss, the best (lowest) validation loss, and the best (highest)\nvalidation CCWA score. Only a single value per metric is shown, satisfying the\n\u201cbest or final\u201d requirement. All logic is executed at the top level so the file\nruns immediately when invoked.", "The script will load the saved NumPy dictionary, iterate through every model and\ndataset it contains, and then examine the lists that store losses and CCWA\nscores. For each metric list it will decide whether \u201cbest\u201d means maximum (for\nCCWA) or minimum (for losses); otherwise it just takes the last value if the\nlist is empty or contains a single element. It prints the dataset name first,\nthen each metric with a clear, descriptive label and the chosen best value. The\ncode is placed at the global scope so it executes immediately when the file is\nrun.", "Below is a short script that immediately loads the saved NumPy file, walks\nthrough every dataset contained in it and prints the best value (minimum for\nlosses, maximum for scores) for each metric. It follows the same nested-\ndictionary structure that the training script used. The code executes at\nimport/run time\u2014no special entry point is required.", "The script will locate the working directory, load the serialized dictionary\nfrom \u201cexperiment_data.npy\u201d, and then iterate through every experiment and\ndataset it contains.   For each dataset it will extract (i) the final training\nloss, (ii) the final validation loss, and (iii) the final validation CCWA score\n(ignoring missing values).   It will then print the dataset name followed by\neach metric name and its corresponding value in a clear, descriptive format.\nAll logic is placed at the global scope so the script executes immediately when\nrun, without relying on a special entry point.", "Below is a compact script that immediately loads the stored results, finds the\nbest (i.e., highest-value for metrics, lowest-value for losses) entry for every\nmetric in every dataset block, and prints them in a clear, labeled form. It\nfollows the original data structure exactly and respects all formatting\nconstraints.", "The script will load the saved numpy dictionary from the working directory,\niterate through every experiment and its datasets, and collect the final entry\nin each logged list (the last epoch). It then prints the dataset name followed\nby clearly-labelled metrics: final training loss, final validation loss, final\nvalidation CCWA, and (when present) the final training CCWA. The code executes\nimmediately on import and follows the structural constraints stated in the\ninstructions.", "The script will load the saved NumPy file from the required working directory,\ntraverse its nested dictionary structure, and for every dataset found will print\nthe dataset name followed by the most relevant value for each stored metric or\nloss. For performance\u2010type metrics (e.g., CCWA) the best (maximum) value is\nshown, whereas for loss values the best (minimum) is reported. Metric names are\nconverted into clear human-readable labels such as \u201ctrain loss\u201d or \u201cvalidation\nCCWA\u201d before printing. The code runs immediately at import time and contains no\nspecial entry-point guard.", "The code will load the experiment_data.npy file from the \u201cworking\u201d directory,\nconvert the numpy object back into a Python dict, and then iterate through every\ndataset stored inside.   For each dataset it will look separately at the\n\u201cmetrics\u201d and \u201closses\u201d sections, discard any None entries, decide whether lower\n(for losses) or higher (for other metrics) is better, and keep only that best\nvalue.   Before printing any numbers the script prints the dataset name,\nfollowed by each metric\u2019s fully-qualified label (e.g. \u201ctraining CCWA score\u201d or\n\u201cvalidation loss\u201d) and its best value rounded to four decimals.   The whole\nscript executes immediately at import time and conforms to the structural\nconstraints (no if __name__ == \"__main__\": block).", "The script will load the saved NumPy dictionary from the working directory,\niterate over every dataset it contains (e.g., \u201cSPR_BENCH\u201d), and then for each\ndataset fetch the stored lists of metrics and losses. It will report the final\nvalue recorded for each metric (e.g., the last epoch\u2019s \u201ctrain_CAWA\u201d, \u201cval_CAWA\u201d,\n\u201ctrain loss\u201d, and \u201cvalidation loss\u201d). Each printout is prefixed with the dataset\nname and a descriptive metric label, complying with the requirement for explicit\nnames. Nothing is wrapped in an `if __name__ == \"__main__\":` guard so the code\nexecutes immediately on run.", "The script will locate the saved experiment_data.npy in the working directory,\nload it as a Python dictionary, and iterate through every stored dataset. For\neach dataset it will look up the lists that hold the tracked losses and CCWA\nscores, compute the \u201cbest\u201d value (minimum for losses, maximum for CCWA), and\nprint those with clear, explicit metric names. Nothing is wrapped in a main-\nguard, so the code runs immediately once executed.", "The script will (1) locate the generated experiment_data.npy inside the working\ndirectory, (2) load it into a dictionary, (3) iterate over every model and\ndataset contained in that dictionary, and (4) print the dataset name followed by\nthe most recent (final-epoch) value for each tracked metric\u2014training loss,\nvalidation loss, training CCWA, and validation CCWA\u2014using explicit, descriptive\nlabels. No plots are created and the code runs immediately on execution.", "The script below loads the saved NumPy dictionary, navigates its nested\nstructure, and prints the final recorded values for each available metric. It\nexplicitly labels both the dataset (\u201cSPR_BENCH\u201d) and each metric (\u201ctraining\nloss,\u201d \u201cvalidation CCWA,\u201d etc.) so the output is unambiguous. Missing or\nundefined metrics are skipped to keep the report clean."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# 0. Locate the working directory and load the saved experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Cannot find experiment_data.npy at {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# ------------------------------------------------------------------\n# 1-3. Iterate over methods and datasets, printing required metrics\n# ------------------------------------------------------------------\nfor method_name, datasets in experiment_data.items():\n    for dataset_name, content in datasets.items():\n        print(dataset_name)  # Dataset header\n\n        # Extract stored arrays/lists\n        train_losses = content.get(\"losses\", {}).get(\"train\", [])\n        val_losses = content.get(\"losses\", {}).get(\"val\", [])\n        val_ccwa = content.get(\"metrics\", {}).get(\"val_CCWA\", [])\n\n        # 4-5. Print best/final metric values with explicit names\n        if train_losses:\n            print(f\"Final training loss: {train_losses[-1]:.6f}\")\n        if val_losses:\n            print(f\"Best validation loss: {min(val_losses):.6f}\")\n        if val_ccwa:\n            print(f\"Best validation CCWA: {max(val_ccwa):.6f}\")\n", "import os\nimport numpy as np\n\n# -------- locate and load the file -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------- helper for pretty names ------------------\ndef pretty(split):\n    mapping = {\n        \"train\": \"training\",\n        \"val\": \"validation\",\n        \"dev\": \"validation\",\n        \"test\": \"test\",\n    }\n    return mapping.get(split, split)\n\n\n# -------- iterate and display ----------------------\nfor model_name, datasets in experiment_data.items():\n    for dataset_name, content in datasets.items():\n        print(f\"\\nDataset: {dataset_name}\")  # requirement #3\n\n        # losses\n        for split, losses in content.get(\"losses\", {}).items():\n            if not losses:\n                continue\n            best_val = min(losses)  # lower is better for loss\n            print(f\"{pretty(split)} loss: {best_val:.4f}\")  # requirement #4\n\n        # metrics\n        for metric_name, values in content.get(\"metrics\", {}).items():\n            if not values:\n                continue\n            # decide best direction\n            best_val = max(values) if \"CCWA\" in metric_name else values[-1]\n            # convert e.g. 'train_CCWA' -> 'training CCWA'\n            split, met = metric_name.split(\"_\", 1)\n            print(f\"{pretty(split)} {met}: {best_val:.4f}\")  # requirement #4\n", "import os\nimport numpy as np\n\n# -------- locate and load ---------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------- helper: decide \u201cbest\u201d ----------------------------------------------------------\ndef best_value(values, higher_is_better=True):\n    \"\"\"Return the best (max or min) non-None value from a list; fall back to last.\"\"\"\n    clean_vals = [v for v in values if v is not None]\n    if not clean_vals:  # all entries were None\n        return None\n    return max(clean_vals) if higher_is_better else min(clean_vals)\n\n\n# -------- iterate and report -------------------------------------------------------------\nfor model_name, datasets in experiment_data.items():  # e.g. \"FreezeEncoder\"\n    for dataset_name, content in datasets.items():  # e.g. \"SPR_BENCH\"\n        print(f\"\\nDataset: {dataset_name}\")\n\n        # Losses -------------------------------------------------------------------------\n        losses = content.get(\"losses\", {})\n        if \"train\" in losses and losses[\"train\"]:\n            val = best_value(losses[\"train\"], higher_is_better=False)\n            print(f\"train loss: {val:.4f}\")\n        if \"val\" in losses and losses[\"val\"]:\n            val = best_value(losses[\"val\"], higher_is_better=False)\n            print(f\"validation loss: {val:.4f}\")\n\n        # Metrics ------------------------------------------------------------------------\n        metrics = content.get(\"metrics\", {})\n        if \"train_CCWA\" in metrics and metrics[\"train_CCWA\"]:\n            val = best_value(metrics[\"train_CCWA\"], higher_is_better=True)\n            if val is not None:\n                print(f\"train CCWA: {val:.4f}\")\n        if \"val_CCWA\" in metrics and metrics[\"val_CCWA\"]:\n            val = best_value(metrics[\"val_CCWA\"], higher_is_better=True)\n            if val is not None:\n                print(f\"validation CCWA: {val:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load --------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper to fetch the last non-None entry --------------------------\ndef last_valid(values, default=None):\n    for v in reversed(values):\n        if v is not None:\n            return v\n    return default\n\n\n# ---------- iterate and print ------------------------------------------------\nfor exp_name, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        print(f\"\\nDataset: {dataset_name}\")\n\n        # losses\n        train_losses = data.get(\"losses\", {}).get(\"train\", [])\n        val_losses = data.get(\"losses\", {}).get(\"val\", [])\n        if train_losses:\n            print(f\"final training loss: {train_losses[-1]:.6f}\")\n        if val_losses:\n            print(f\"final validation loss: {val_losses[-1]:.6f}\")\n\n        # CCWA metrics\n        train_ccwa = data.get(\"metrics\", {}).get(\"train_CCWA\", [])\n        val_ccwa = data.get(\"metrics\", {}).get(\"val_CCWA\", [])\n        if train_ccwa:\n            tv = last_valid(train_ccwa)\n            if tv is not None:\n                print(f\"final training CCWA: {tv:.6f}\")\n        if val_ccwa:\n            vv = last_valid(val_ccwa)\n            if vv is not None:\n                print(f\"final validation CCWA: {vv:.6f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# locate and load the saved file\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# helper to decide whether \u201csmaller-is-better\u201d (loss) or \u201clarger-is-better\u201d (everything else)\ndef best_value(values, key_name):\n    values = np.asarray(values, dtype=float)\n    if \"loss\" in key_name.lower():\n        idx = values.argmin()\n    else:\n        idx = values.argmax()\n    return values[idx]\n\n\n# ---------------------------------------------------------------------\nfor dataset_name, dataset_block in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # ---- losses ----\n    for loss_name, series in dataset_block.get(\"losses\", {}).items():\n        metric_label = (\n            \"best training loss\"\n            if loss_name == \"train\"\n            else (\n                \"best validation loss\"\n                if loss_name == \"val\"\n                else f\"best {loss_name} loss\"\n            )\n        )\n        print(f\"{metric_label}: {best_value(series, 'loss'):.4f}\")\n\n    # ---- other metrics ----\n    for metric_name, series in dataset_block.get(\"metrics\", {}).items():\n        metric_label = (\n            \"best training CAWA accuracy\"\n            if metric_name == \"train_CAWA\"\n            else (\n                \"best validation CAWA accuracy\"\n                if metric_name == \"val_CAWA\"\n                else f\"best {metric_name}\"\n            )\n        )\n        print(f\"{metric_label}: {best_value(series, metric_name):.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load the data -----------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nnpy_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(npy_path, allow_pickle=True).item()\n\n\n# ---------- helper to fetch the last (non-None) element ----------------------\ndef last_valid(lst):\n    \"\"\"Return the last element in `lst` that is not None; otherwise None.\"\"\"\n    for item in reversed(lst):\n        if item is not None:\n            return item\n    return None\n\n\n# ---------- iterate and report ----------------------------------------------\nfor exp_name, exp_content in experiment_data.items():\n    for dset_name, dset_content in exp_content.items():\n        print(f\"\\nDataset: {dset_name}\")  # requirement 3\n\n        # losses\n        train_losses = dset_content[\"losses\"][\"train\"]\n        val_losses = dset_content[\"losses\"][\"val\"]\n        if train_losses:\n            print(f\"final training loss: {train_losses[-1]:.6f}\")  # requirement 4\n        if val_losses:\n            print(f\"final validation loss: {val_losses[-1]:.6f}\")\n\n        # CCWA metrics\n        train_ccwa = last_valid(dset_content[\"metrics\"][\"train_CCWA\"])\n        val_ccwa = last_valid(dset_content[\"metrics\"][\"val_CCWA\"])\n        if train_ccwa is not None:\n            print(f\"final training CCWA: {train_ccwa:.6f}\")\n        if val_ccwa is not None:\n            print(f\"final validation CCWA: {val_ccwa:.6f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load the saved experiment data ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper to prettify metric / loss labels ------------\ndef pretty_label(raw_key):\n    mapping = {\n        \"train\": \"train loss\",\n        \"val\": \"validation loss\",\n        \"train_CCWA\": \"train CCWA\",\n        \"val_CCWA\": \"validation CCWA\",\n    }\n    return mapping.get(raw_key, raw_key.replace(\"_\", \" \"))\n\n\n# ---------- iterate through all stored results -----------------\nfor model_name, datasets in experiment_data.items():  # e.g. \"CLS_POOL_ONLY\"\n    for dataset_name, records in datasets.items():  # e.g. \"SPR_BENCH\"\n        print(f\"Dataset: {dataset_name}\")\n\n        # losses\n        for loss_split, loss_values in records.get(\"losses\", {}).items():\n            if not loss_values:  # empty list guard\n                continue\n            best_loss = min(loss_values)  # lower is better\n            print(f\"{pretty_label(loss_split)}: {best_loss:.4f}\")\n\n        # metrics\n        for metric_key, metric_values in records.get(\"metrics\", {}).items():\n            cleaned = [v for v in metric_values if v is not None]\n            if not cleaned:\n                continue\n            best_metric = max(cleaned)  # higher is better\n            print(f\"{pretty_label(metric_key)}: {best_metric:.4f}\")\n\n        print()  # blank line between datasets\n", "import os\nimport numpy as np\n\n# ----------- locate and load the npy file --------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ----------- helper: decide best value -----------------------\ndef best_value(values, higher_is_better=True):\n    \"\"\"Return best (max or min) from a list, ignoring None.\"\"\"\n    numeric = [v for v in values if v is not None]\n    if not numeric:\n        return None\n    return max(numeric) if higher_is_better else min(numeric)\n\n\n# ----------- iterate and print -------------------------------\nfor ablation_name, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        print(f\"Dataset: {dataset_name}\")\n\n        # Handle metrics (e.g., CCWA scores)\n        for raw_name, values in data.get(\"metrics\", {}).items():\n            hi_better = not (\"loss\" in raw_name.lower())\n            value = best_value(values, higher_is_better=hi_better)\n            if value is None:\n                continue\n\n            # Build a human-readable metric label\n            prefix_map = {\"train\": \"training\", \"val\": \"validation\", \"test\": \"test\"}\n            parts = raw_name.split(\"_\", 1)\n            prefix = prefix_map.get(parts[0], parts[0])\n            suffix = parts[1] if len(parts) > 1 else \"\"\n            label = f\"{prefix} {suffix}\".strip()\n\n            print(f\"{label.capitalize()}: {value:.4f}\")\n\n        # Handle losses\n        for split, values in data.get(\"losses\", {}).items():\n            value = best_value(values, higher_is_better=False)\n            if value is None:\n                continue\n            split_label = {\n                \"train\": \"training\",\n                \"val\": \"validation\",\n                \"test\": \"test\",\n            }.get(split, split)\n            print(f\"{split_label.capitalize()} loss: {value:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------------------------\n# Locate and load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------------------------\n# Helper to print the final value of a list safely\ndef final_value(lst):\n    return lst[-1] if lst else None\n\n\n# ---------------------------------------------------------------------\n# Iterate over datasets and print metrics\nfor dataset_name, data in experiment_data.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    # Losses\n    train_loss_final = final_value(data.get(\"losses\", {}).get(\"train\", []))\n    val_loss_final = final_value(data.get(\"losses\", {}).get(\"val\", []))\n    if train_loss_final is not None:\n        print(f\"train loss: {train_loss_final:.4f}\")\n    if val_loss_final is not None:\n        print(f\"validation loss: {val_loss_final:.4f}\")\n\n    # Metrics\n    train_cawa_final = final_value(data.get(\"metrics\", {}).get(\"train_CAWA\", []))\n    val_cawa_final = final_value(data.get(\"metrics\", {}).get(\"val_CAWA\", []))\n    if train_cawa_final is not None:\n        print(\n            f\"train Complexity-Adjusted Weighted Accuracy (CAWA): {train_cawa_final:.4f}\"\n        )\n    if val_cawa_final is not None:\n        print(\n            f\"validation Complexity-Adjusted Weighted Accuracy (CAWA): {val_cawa_final:.4f}\"\n        )\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate and load the experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# helper to safely fetch a list and return an empty list if missing\n# ------------------------------------------------------------------\ndef _get_list(dct, key1, key2):\n    if key1 in dct and key2 in dct[key1]:\n        return dct[key1][key2]\n    return []\n\n\n# ------------------------------------------------------------------\n# iterate through datasets and print best metrics\n# ------------------------------------------------------------------\nfor model_name, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        print(f\"\\nDataset: {dataset_name}\")\n\n        # losses\n        train_losses = _get_list(data, \"losses\", \"train\")\n        val_losses = _get_list(data, \"losses\", \"val\")\n\n        if train_losses:\n            best_train_loss = min(train_losses)\n            print(f\"Best training loss: {best_train_loss:.4f}\")\n\n        if val_losses:\n            best_val_loss = min(val_losses)\n            print(f\"Best validation loss: {best_val_loss:.4f}\")\n\n        # CCWA metrics\n        train_ccwa = _get_list(data, \"metrics\", \"train_CCWA\")\n        val_ccwa = _get_list(data, \"metrics\", \"val_CCWA\")\n\n        if train_ccwa and any(v is not None for v in train_ccwa):\n            best_train_ccwa = max(v for v in train_ccwa if v is not None)\n            print(f\"Best training CCWA: {best_train_ccWA:.4f}\")\n\n        if val_ccwa:\n            best_val_ccwa = max(val_ccwa)\n            print(f\"Best validation CCWA: {best_val_ccwa:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------- locate and load the saved experiment dictionary ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"experiment_data.npy not found at {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------- helper to fetch the final entry of a metric list ----------\ndef final_or_na(lst):\n    \"\"\"Return last non-None entry in list; if none exists return 'N/A'.\"\"\"\n    for item in reversed(lst):\n        if item is not None:\n            return item\n    return \"N/A\"\n\n\n# ---------- iterate and print metrics ----------\nfor model_name, datasets in experiment_data.items():\n    for dataset_name, ds_data in datasets.items():\n        print(f\"\\nDataset: {dataset_name}\")\n\n        # Losses\n        train_losses = ds_data.get(\"losses\", {}).get(\"train\", [])\n        val_losses = ds_data.get(\"losses\", {}).get(\"val\", [])\n        if train_losses:\n            print(f\"final training loss: {train_losses[-1]:.4f}\")\n        if val_losses:\n            print(f\"final validation loss: {val_losses[-1]:.4f}\")\n\n        # CCWA metrics\n        train_ccwa = ds_data.get(\"metrics\", {}).get(\"train_CCWA\", [])\n        val_ccwa = ds_data.get(\"metrics\", {}).get(\"val_CCWA\", [])\n        train_ccwa_value = final_or_na(train_ccwa)\n        val_ccwa_value = final_or_na(val_ccwa)\n\n        print(f\"final training CCWA: {train_ccwa_value}\")\n        print(f\"final validation CCWA: {val_ccwa_value}\")\n", "import os\nimport numpy as np\n\n# -------------------------------------------------------------\n# locate and load the experiment data\n# -------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------------------------------------------------------------\n# helper to safely fetch the final (last) non-None value\n# -------------------------------------------------------------\ndef get_final(values):\n    \"\"\"Return the last element in `values` that is not None, or None.\"\"\"\n    for v in reversed(values):\n        if v is not None:\n            return v\n    return None\n\n\n# -------------------------------------------------------------\n# iterate through experiments and datasets\n# -------------------------------------------------------------\nfor experiment_name, datasets in experiment_data.items():\n    for dataset_name, data_dict in datasets.items():\n        print(f\"{dataset_name}\")  # dataset header\n\n        # losses\n        train_loss = get_final(data_dict.get(\"losses\", {}).get(\"train\", []))\n        val_loss = get_final(data_dict.get(\"losses\", {}).get(\"val\", []))\n        if train_loss is not None:\n            print(f\"  training loss: {train_loss:.4f}\")\n        if val_loss is not None:\n            print(f\"  validation loss: {val_loss:.4f}\")\n\n        # CCWA metrics\n        train_ccwa = get_final(data_dict.get(\"metrics\", {}).get(\"train_CCWA\", []))\n        val_ccwa = get_final(data_dict.get(\"metrics\", {}).get(\"val_CCWA\", []))\n        if train_ccwa is not None:\n            print(f\"  training CCWA: {train_ccwa:.4f}\")\n        if val_ccwa is not None:\n            print(f\"  validation CCWA: {val_ccwa:.4f}\")\n\n        # spacer between datasets (if more than one)\n        print()\n"], "parse_term_out": ["['SPR_BENCH', '\\n', 'Final training loss: 0.138804', '\\n', 'Best validation\nloss: 0.145690', '\\n', 'Best validation CCWA: 0.960051', '\\n', 'Execution time:\na moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'training loss: 0.1673', '\\n', 'validation loss:\n0.1662', '\\n', 'Traceback (most recent call last):\\n  File \"runfile.py\", line\n39, in <module>\\n    best_val = max(values) if \"CCWA\" in metric_name else\nvalues[-1]\\n               ^^^^^^^^^^^\\nTypeError: \\'>\\' not supported between\ninstances of \\'NoneType\\' and \\'NoneType\\'\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'train loss: 0.4508', '\\n', 'validation loss:\n0.4514', '\\n', 'validation CCWA: 0.7992', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'final training loss: 0.054035', '\\n', 'final\nvalidation loss: 0.033018', '\\n', 'final validation CCWA: 0.988510', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'best training loss: 0.1653', '\\n', 'best\nvalidation loss: 0.1646', '\\n', 'best training CAWA accuracy: 0.9460', '\\n',\n'best validation CAWA accuracy: 0.9464', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'final training loss: 0.030425', '\\n', 'final\nvalidation loss: 0.034160', '\\n', 'final validation CCWA: 0.991635', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', 'train loss: 0.0348', '\\n', 'validation loss:\n0.0376', '\\n', 'validation CCWA: 0.9898', '\\n', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['Dataset: SPR_BENCH', '\\n', 'Validation ccwa: 0.9121', '\\n', 'Training loss:\n0.2822', '\\n', 'Validation loss: 0.2676', '\\n', 'Execution time: a moment\nseconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'train loss: 0.1571', '\\n', 'validation loss:\n0.1673', '\\n', 'train Complexity-Adjusted Weighted Accuracy (CAWA): 0.9467',\n'\\n', 'validation Complexity-Adjusted Weighted Accuracy (CAWA): 0.9461', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'Best training loss: 0.0000', '\\n', 'Best\nvalidation loss: 0.0009', '\\n', 'Best validation CCWA: 0.9998', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'final training loss: 0.0675', '\\n', 'final\nvalidation loss: 0.0550', '\\n', 'final training CCWA: N/A', '\\n', 'final\nvalidation CCWA: 0.9863662072455571', '\\n', 'Execution time: a moment seconds\n(time limit is 30 minutes).']", "['SPR_BENCH', '\\n', '  training loss: 0.0292', '\\n', '  validation loss:\n0.0410', '\\n', '  validation CCWA: 0.9869', '\\n', '\\n', 'Execution time: a\nmoment seconds (time limit is 30 minutes).']"], "parse_exc_type": [null, "TypeError", null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, {"args": ["'>' not supported between instances of 'NoneType' and 'NoneType'"]}, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 39, "<module>", "best_val = max(values) if \"CCWA\" in metric_name else values[-1]"]], null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
