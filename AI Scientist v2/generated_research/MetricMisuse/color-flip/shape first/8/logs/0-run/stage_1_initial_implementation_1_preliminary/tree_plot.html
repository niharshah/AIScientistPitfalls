<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[2, 7], [2, 4], [2, 6], [2, 5]], "layout": [[0.0, 0.0], [0.2857142857142857, 0.0], [0.5714285714285714, 0.0], [0.8571428571428571, 0.0], [0.14285714285714285, 1.0], [0.42857142857142855, 1.0], [0.7142857142857143, 1.0], [1.0, 1.0]], "plan": ["We construct a minimal yet complete baseline: turn each symbolic token (e.g.\n\u201cA1\u201d) into an integer, pad sequences, and train a small bi-directional GRU\nfollowed by a linear classifier with cross-entropy loss.  We read the official\nSPR_BENCH splits (or fall back to a tiny synthetic set if the data folder is\nmissing), build a vocabulary from training data, and create PyTorch\nDataset/Dataloader objects that automatically move tensors to GPU when\navailable.  After every epoch we compute validation loss and the required\nSequence Complexity Weighted Accuracy (SCWA); all metrics, losses, predictions,\nand ground-truth labels are collected in a nested experiment_data dictionary and\nsaved at the end.  This script fulfils the mandatory device handling, DataLoader\nbatching, metric tracking, and result-saving requirements while giving us a\nfirst working model to improve with contrastive pre-training in later stages.", "We will load the SPR_BENCH splits (or generate a tiny synthetic set if the files\nare missing), build a simple vocabulary over tokens, and encode each sequence.\nA Bi-GRU encoder with an embedding layer produces a fixed-length representation.\nPhase-1 self-supervised pre-training uses SimCLR-style contrastive learning:\nevery sequence is turned into two augmented \u201cviews\u201d via random token-drop, and\nthe NT-Xent loss is optimised.   Phase-2 fine-tunes the encoder for\nclassification with a linear head by minimising cross-entropy on the labelled\ntraining set while tracking validation loss and the Sequence-Complexity-\nWeighted-Accuracy (SCWA) metric.   Metrics, losses, predictions and ground-truth\nare stored in the experiment_data dict and saved to\n./working/experiment_data.npy at the end.   All tensors and the model are\nconsistently moved to GPU when available, and training prints validation loss\neach epoch.   The whole script is a single, self-contained file that runs\nimmediately on execution and finishes within the time budget.", "Our initial baseline will build a simple Bi-LSTM encoder that maps tokenized\nsymbolic sequences to fixed-length embeddings.   Step 1: we construct a\nvocabulary from the training split and encode each sequence as a padded list of\ntoken IDs.   Step 2: an unsupervised \u201cview-maker\u201d applies light symbol-level\naugmentations (random token masking, deletion and swapping) to generate two\ncorrelated views of every sequence; the encoder is first trained with an NT-Xent\ncontrastive loss on these view pairs for a few epochs.   Step 3: we attach a\nlinear classification head to the pretrained encoder and fine-tune the whole\nmodel with cross-entropy on the labelled SPR training data while tracking\nvalidation loss and the new Sequence Complexity Weighted Accuracy (SCWA).   Step\n4: after every epoch we print the validation loss and SCWA, then save the full\nhistory in the prescribed experiment_data structure and dump it to\n./working/experiment_data.npy.   All tensors, models and batches are moved to\nGPU when available, and the script is fully self-contained\u2014if the real SPR_BENCH\ndata are absent it automatically synthesises a tiny dummy dataset so the code\nstill runs end-to-end.", "The baseline will load SPR_BENCH with the provided utility, build a simple\nvocabulary of the individual \u201cshape-color\u201d tokens, and encode every sequence\ninto an index list.  A small Bi-GRU encoder with a learnable [CLS] token will\ntransform each sequence into a single embedding, followed by a linear layer for\n10-way classification (the dataset uses labels 0-9).  We train the classifier\nwith cross-entropy for a few epochs, monitoring validation loss and the Sequence\nComplexity Weighted Accuracy (SCWA) metric each epoch.  All tensors, the model\nand the optimizer are moved to GPU when available.  Data, losses, metrics,\npredictions, and ground-truth labels are stored in the experiment_data dict and\nsaved as NumPy files in ./working.  A simple bar plot of SCWA history is also\nproduced and saved.  This delivers a working end-to-end pipeline\u2014from data\npreparation through model training, evaluation, logging and visualization\u2014that\ncan later be extended with contrastive pre-training and more sophisticated\naugmentations.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os, pathlib, random, string, time\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List, Dict\nfrom datasets import load_dataset, DatasetDict\n\n# --------------------------------------------------\n# mandatory work dir + gpu setup\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# --------------------------------------------------\n# helpers copied / adapted from SPR.py\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"] = _load(\"dev.csv\")\n    dset[\"test\"] = _load(\"test.csv\")\n    return dset\n\n\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(token[0] for token in sequence.strip().split() if token))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(token[1] for token in sequence.strip().split() if len(token) > 1))\n\n\ndef scwa(sequences: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_shape_variety(s) * count_color_variety(s) for s in sequences]\n    credited = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(credited) / sum(weights) if sum(weights) > 0 else 0.0\n\n\n# --------------------------------------------------\n# dataset path or synthetic fallback\nDATA_PATH = os.path.join(os.getcwd(), \"SPR_BENCH\")\nhave_real_data = os.path.isdir(DATA_PATH)\nif have_real_data:\n    try:\n        spr_bench = load_spr_bench(pathlib.Path(DATA_PATH))\n    except Exception as e:\n        print(f\"Could not load real dataset ({e}); switching to synthetic.\")\n        have_real_data = False\n\n\n# quick synthetic generator (1000 train / 200 dev / 200 test)\ndef generate_synthetic(num):\n    shapes = list(string.ascii_uppercase[:5])  # A-E\n    colors = list(\"12345\")  # 1-5\n    rows = []\n    for i in range(num):\n        length = random.randint(5, 15)\n        seq = \" \".join(\n            random.choice(shapes) + random.choice(colors) for _ in range(length)\n        )\n        label = random.randint(0, 1)\n        rows.append({\"id\": i, \"sequence\": seq, \"label\": label})\n    return rows\n\n\nif not have_real_data:\n    synthetic = {\n        \"train\": generate_synthetic(1000),\n        \"dev\": generate_synthetic(200),\n        \"test\": generate_synthetic(200),\n    }\n    # convert to HuggingFace DatasetDict for homogeneity\n    from datasets import Dataset\n\n    spr_bench = DatasetDict({k: Dataset.from_list(v) for k, v in synthetic.items()})\n\nprint({k: len(v) for k, v in spr_bench.items()})\n\n# --------------------------------------------------\n# Tokeniser and vocabulary\nPAD, UNK = \"<PAD>\", \"<UNK>\"\n\n\ndef build_vocab(seqs: List[str]) -> Dict[str, int]:\n    vocab = {PAD: 0, UNK: 1}\n    for s in seqs:\n        for tok in s.split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab)\n    return vocab\n\n\nvocab = build_vocab(spr_bench[\"train\"][\"sequence\"])\nprint(f\"Vocab size: {len(vocab)}\")\n\n\ndef encode(seq: str, max_len: int) -> List[int]:\n    ids = [vocab.get(tok, vocab[UNK]) for tok in seq.split()]\n    if len(ids) < max_len:\n        ids += [vocab[PAD]] * (max_len - len(ids))\n    else:\n        ids = ids[:max_len]\n    return ids\n\n\nmax_len = max(len(s.split()) for s in spr_bench[\"train\"][\"sequence\"])\n\n\n# --------------------------------------------------\n# PyTorch Dataset\nclass SPRTorchSet(Dataset):\n    def __init__(self, hf_dataset, max_len):\n        self.seqs = hf_dataset[\"sequence\"]\n        self.labels = hf_dataset[\"label\"]\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        ids = torch.tensor(encode(self.seqs[idx], self.max_len), dtype=torch.long)\n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n        return {\"input_ids\": ids, \"labels\": label, \"raw_seq\": self.seqs[idx]}\n\n\ndef collate_fn(batch):\n    input_ids = torch.stack([b[\"input_ids\"] for b in batch])\n    labels = torch.stack([b[\"labels\"] for b in batch])\n    raw_seq = [b[\"raw_seq\"] for b in batch]\n    return {\n        \"input_ids\": input_ids.to(device),\n        \"labels\": labels.to(device),\n        \"raw_seq\": raw_seq,\n    }\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchSet(spr_bench[\"train\"], max_len),\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=collate_fn,\n)\nval_loader = DataLoader(\n    SPRTorchSet(spr_bench[\"dev\"], max_len),\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=collate_fn,\n)\ntest_loader = DataLoader(\n    SPRTorchSet(spr_bench[\"test\"], max_len),\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=collate_fn,\n)\n\n\n# --------------------------------------------------\n# Model\nclass GRUClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim=64, hidden=128, num_classes=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.gru = nn.GRU(embed_dim, hidden, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden * 2, num_classes)\n\n    def forward(self, x):\n        emb = self.embed(x)\n        _, h = self.gru(emb)\n        h_cat = torch.cat([h[0], h[1]], dim=-1)\n        return self.fc(h_cat)\n\n\nmodel = GRUClassifier(len(vocab)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# --------------------------------------------------\n# experiment data container\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n# --------------------------------------------------\n# training loop\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    model.train()\n    running_loss = 0.0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        output = model(batch[\"input_ids\"])\n        loss = criterion(output, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss = running_loss / len(train_loader.dataset)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n\n    # validation\n    model.eval()\n    val_loss, all_seq, y_true, y_pred = 0.0, [], [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            logits = model(batch[\"input_ids\"])\n            loss = criterion(logits, batch[\"labels\"])\n            val_loss += loss.item() * batch[\"labels\"].size(0)\n            preds = logits.argmax(dim=-1).cpu().tolist()\n            y_pred.extend(preds)\n            y_true.extend(batch[\"labels\"].cpu().tolist())\n            all_seq.extend(batch[\"raw_seq\"])\n    val_loss /= len(val_loader.dataset)\n    scwa_score = scwa(all_seq, y_true, y_pred)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(scwa_score)\n    experiment_data[\"SPR_BENCH\"][\"timestamps\"].append(time.time())\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f} | SCWA = {scwa_score:.4f}\")\n\n# --------------------------------------------------\n# final test evaluation\nmodel.eval()\ntest_seq, gt, pr = [], [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        logits = model(batch[\"input_ids\"])\n        preds = logits.argmax(dim=-1).cpu().tolist()\n        pr.extend(preds)\n        gt.extend(batch[\"labels\"].cpu().tolist())\n        test_seq.extend(batch[\"raw_seq\"])\ntest_scwa = scwa(test_seq, gt, pr)\nprint(f\"Test SCWA: {test_scwa:.4f}\")\n\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = pr\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = gt\nexperiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(\n    None\n)  # placeholder for symmetry\n\n# save everything\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, random, pathlib, time, math\nimport numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import DatasetDict, load_dataset\n\n# -----------------------------------------------------------\n# Mandatory working directory, GPU setup, experiment_data dict\n# -----------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n\n# -----------------------------------------------------------\n# Helper functions supplied in prompt (copied)\n# -----------------------------------------------------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(token[0] for token in sequence.strip().split() if token))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(token[1] for token in sequence.strip().split() if len(token) > 1))\n\n\ndef shape_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_shape_variety(seq) for seq in sequences]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\ndef color_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_color_variety(seq) for seq in sequences]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\ndef sequence_complexity_weighted_accuracy(sequences, y_true, y_pred):\n    weights = [count_shape_variety(s) * count_color_variety(s) for s in sequences]\n    scored = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(scored) / sum(weights) if sum(weights) > 0 else 0.0\n\n\n# -----------------------------------------------------------\n# Dataset loading (with graceful fallback)\n# -----------------------------------------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        train=_load(\"train.csv\"), dev=_load(\"dev.csv\"), test=_load(\"test.csv\")\n    )\n\n\ndef get_dataset():\n    data_path = pathlib.Path(\"SPR_BENCH\")\n    if data_path.exists():\n        try:\n            dset = load_spr_bench(data_path)\n            print(\"Loaded local SPR_BENCH dataset.\")\n            return dset\n        except Exception as e:\n            print(\"Could not load SPR_BENCH, generating synthetic data.\", e)\n    # synthetic tiny dataset\n    random.seed(0)\n\n    def gen(n):\n        shapes = \"\u25b2\u25a0\u25cf\u25c6\".split(\" \")\n        colors = \"r g b y\".split(\" \")\n        seqs, labels = [], []\n        for _ in range(n):\n            l = random.randint(4, 8)\n            seq = \" \".join(\n                random.choice(shapes) + random.choice(colors) for _ in range(l)\n            )\n            seqs.append(seq)\n            labels.append(random.randint(0, 1))\n        return {\"id\": list(range(n)), \"sequence\": seqs, \"label\": labels}\n\n    train = load_dataset(\n        \"json\", data_files={\"train\": [gen(200)]}, field=\"train\", split=\"train\"\n    )\n    dev = load_dataset(\n        \"json\", data_files={\"dev\": [gen(60)]}, field=\"dev\", split=\"train\"\n    )\n    test = load_dataset(\n        \"json\", data_files={\"test\": [gen(60)]}, field=\"test\", split=\"train\"\n    )\n    return DatasetDict(train=train, dev=dev, test=test)\n\n\ndset = get_dataset()\nprint({k: len(v) for k, v in dset.items()})\n\n# -----------------------------------------------------------\n# Vocabulary + encoding utilities\n# -----------------------------------------------------------\nPAD_ID = 0\n\n\ndef build_vocab(sequences):\n    vocab = {}\n    for seq in sequences:\n        for tok in seq.strip().split():\n            if tok not in vocab:\n                vocab[tok] = len(vocab) + 1\n    return vocab\n\n\nvocab = build_vocab(dset[\"train\"][\"sequence\"])\nvocab_size = len(vocab) + 1\nprint(\"Vocab size:\", vocab_size)\n\n\ndef encode(seq):\n    return [vocab[tok] for tok in seq.strip().split() if tok in vocab]\n\n\ndef collate_classification(batch):\n    # sequences, labels, raw_strings\n    encoded = [encode(b[\"sequence\"]) for b in batch]\n    lengths = [len(x) for x in encoded]\n    max_len = max(lengths)\n    padded = [x + [PAD_ID] * (max_len - len(x)) for x in encoded]\n    seq_tensor = torch.tensor(padded, dtype=torch.long)\n    label_tensor = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n    return {\n        \"input_ids\": seq_tensor.to(device),\n        \"labels\": label_tensor.to(device),\n        \"raw_seq\": [b[\"sequence\"] for b in batch],\n    }\n\n\n# -----------------------------------------------------------\n# Augmentation & Contrastive dataset\n# -----------------------------------------------------------\ndef dropout_tokens(tok_ids, p=0.2):\n    if len(tok_ids) == 0:\n        return tok_ids\n    return [t for t in tok_ids if random.random() > p] or tok_ids  # avoid empty\n\n\nclass ContrastiveDataset(Dataset):\n    def __init__(self, sequences):\n        self.sequences = sequences\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, idx):\n        seq = self.sequences[idx]\n        ids = encode(seq)\n        view1 = dropout_tokens(ids, 0.2)\n        view2 = dropout_tokens(ids, 0.2)\n        return torch.tensor(view1, dtype=torch.long), torch.tensor(\n            view2, dtype=torch.long\n        )\n\n\ndef collate_contrastive(batch):\n    v1, v2 = zip(*batch)\n    lens = [len(x) for x in v1 + v2]\n    max_len = max(lens)\n    pad = lambda x: torch.cat([x, torch.zeros(max_len - len(x), dtype=torch.long)])\n    v1p = torch.stack([pad(x) for x in v1]).to(device)\n    v2p = torch.stack([pad(x) for x in v2]).to(device)\n    return {\"view1\": v1p, \"view2\": v2p}\n\n\n# -----------------------------------------------------------\n# Model\n# -----------------------------------------------------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, embed_dim=64, hidden=128):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_ID)\n        self.gru = nn.GRU(embed_dim, hidden, batch_first=True, bidirectional=True)\n\n    def forward(self, x):\n        mask = (x != PAD_ID).unsqueeze(-1)\n        emb = self.embed(x)\n        packed, _ = self.gru(emb)\n        masked = packed * mask\n        sent = masked.sum(1) / (mask.sum(1) + 1e-8)  # mean pooling\n        return sent\n\n\nclass ProjectionHead(nn.Module):\n    def __init__(self, in_dim, out_dim=64):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, out_dim), nn.ReLU(), nn.Linear(out_dim, out_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nclass SPRModel(nn.Module):\n    def __init__(self, vocab_size, num_classes):\n        super().__init__()\n        self.encoder = Encoder(vocab_size)\n        self.proj = ProjectionHead(256, 64)  # 128*2 biGRU\n        self.classifier = nn.Linear(256, num_classes)\n\n    def forward(self, x, mode=\"cls\"):\n        emb = self.encoder(x)\n        if mode == \"contrast\":\n            z = self.proj(emb)\n            return nn.functional.normalize(z, dim=-1)\n        else:\n            return self.classifier(emb)\n\n\n# -----------------------------------------------------------\n# NT-Xent loss\n# -----------------------------------------------------------\ndef nt_xent(z1, z2, temp=0.5):\n    N = z1.size(0)\n    z = torch.cat([z1, z2], dim=0)  # 2N x d\n    sim = torch.mm(z, z.t()) / temp  # cosine sim (normed already)\n    # mask self-similarity\n    mask = torch.eye(2 * N, dtype=torch.bool, device=z.device)\n    sim = sim.masked_fill(mask, -9e15)\n    pos = torch.sum(z1 * z2, dim=1) / temp\n    pos = torch.cat([pos, pos], dim=0)\n    denom = torch.logsumexp(sim, dim=1)\n    loss = -pos + denom\n    return loss.mean()\n\n\n# -----------------------------------------------------------\n# Build loaders\n# -----------------------------------------------------------\nbatch_size_sup = 64\nbatch_size_con = 128\ntrain_sup_loader = DataLoader(\n    dset[\"train\"],\n    batch_size=batch_size_sup,\n    shuffle=True,\n    collate_fn=collate_classification,\n)\nval_loader = DataLoader(\n    dset[\"dev\"],\n    batch_size=batch_size_sup,\n    shuffle=False,\n    collate_fn=collate_classification,\n)\ncon_loader = DataLoader(\n    ContrastiveDataset(dset[\"train\"][\"sequence\"]),\n    batch_size=batch_size_con,\n    shuffle=True,\n    collate_fn=collate_contrastive,\n)\n\nnum_classes = len(set(dset[\"train\"][\"label\"]))\nmodel = SPRModel(vocab_size, num_classes).to(device)\n\n# -----------------------------------------------------------\n# Optimizers\n# -----------------------------------------------------------\npre_optimizer = torch.optim.Adam(\n    list(model.encoder.parameters()) + list(model.proj.parameters()), lr=1e-3\n)\n\n# -----------------------------------------------------------\n# Phase-1 Contrastive Pre-training\n# -----------------------------------------------------------\nepochs_pre = 5\nprint(\"\\n=== Contrastive pre-training ===\")\nfor epoch in range(1, epochs_pre + 1):\n    model.train()\n    total_loss = 0\n    steps = 0\n    for batch in con_loader:\n        z1 = model(batch[\"view1\"], mode=\"contrast\")\n        z2 = model(batch[\"view2\"], mode=\"contrast\")\n        loss = nt_xent(z1, z2)\n        pre_optimizer.zero_grad()\n        loss.backward()\n        pre_optimizer.step()\n        total_loss += loss.item()\n        steps += 1\n    print(f\"Epoch {epoch}: contrastive_loss = {total_loss/steps:.4f}\")\nprint(\"Pre-training finished.\\n\")\n\n# -----------------------------------------------------------\n# Phase-2 Supervised Fine-tuning\n# -----------------------------------------------------------\nft_optimizer = torch.optim.Adam(\n    model.parameters(), lr=1e-3\n)  # create after model on device\ncriterion = nn.CrossEntropyLoss()\nepochs_ft = 5\nprint(\"=== Supervised fine-tuning ===\")\nfor epoch in range(1, epochs_ft + 1):\n    # ---- training ----\n    model.train()\n    train_loss = 0\n    tsteps = 0\n    for batch in train_sup_loader:\n        logits = model(batch[\"input_ids\"], mode=\"cls\")\n        loss = criterion(logits, batch[\"labels\"])\n        ft_optimizer.zero_grad()\n        loss.backward()\n        ft_optimizer.step()\n        train_loss += loss.item()\n        tsteps += 1\n    avg_train_loss = train_loss / tsteps\n    # ---- validation ----\n    model.eval()\n    val_loss = 0\n    vsteps = 0\n    all_preds = []\n    all_labels = []\n    raw_seq = []\n    with torch.no_grad():\n        for batch in val_loader:\n            logits = model(batch[\"input_ids\"], mode=\"cls\")\n            loss = criterion(logits, batch[\"labels\"])\n            val_loss += loss.item()\n            vsteps += 1\n            preds = logits.argmax(-1).cpu().tolist()\n            labels = batch[\"labels\"].cpu().tolist()\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n            raw_seq.extend(batch[\"raw_seq\"])\n    avg_val_loss = val_loss / vsteps\n    scwa = sequence_complexity_weighted_accuracy(raw_seq, all_labels, all_preds)\n    print(f\"Epoch {epoch}: validation_loss = {avg_val_loss:.4f} | SCWA = {scwa:.4f}\")\n    # store metrics\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(avg_train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(avg_val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(scwa)\n    experiment_data[\"SPR_BENCH\"][\"timestamps\"].append(time.time())\n\n# save predictions for last epoch\nexperiment_data[\"SPR_BENCH\"][\"predictions\"] = all_preds\nexperiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_labels\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n", "import os, random, math, time, pathlib, itertools, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List\n\n# ----------------- working dir -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n# ----------------- device -----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------- try loading SPR_BENCH -----------------\ndef try_load_real_dataset():\n    try:\n        from SPR import load_spr_bench  # local util provided by task\n\n        DATA_PATH = pathlib.Path(\"./SPR_BENCH\")\n        if not DATA_PATH.exists():\n            DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        dset = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH.\")\n        return dset\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH: \", e)\n        return None\n\n\nreal_dset = try_load_real_dataset()\n\n\n# ----------------- synthetic fallback -----------------\ndef make_random_token():\n    shapes = [\"R\", \"S\", \"T\", \"U\", \"V\"]\n    colors = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef generate_sequence(min_len=3, max_len=10):\n    return \" \".join(\n        make_random_token() for _ in range(random.randint(min_len, max_len))\n    )\n\n\ndef generate_synthetic_split(n_rows: int):\n    data = []\n    for i in range(n_rows):\n        seq = generate_sequence()\n        label = random.randint(0, 3)\n        data.append({\"id\": i, \"sequence\": seq, \"label\": label})\n    return data\n\n\nif real_dset is None:\n    print(\"Generating synthetic data \u2026\")\n    real_dset = {\n        \"train\": generate_synthetic_split(1000),\n        \"dev\": generate_synthetic_split(200),\n        \"test\": generate_synthetic_split(200),\n    }\n\n\n# ----------------- SCWA metric helpers -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.split()))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.split()))\n\n\ndef scwa_metric(sequences: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_shape_variety(s) * count_color_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\n# ----------------- vocab & encoding -----------------\nPAD, TUNK, TMASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(dataset):\n    vocab = set()\n    for row in dataset:\n        vocab.update(row[\"sequence\"].split())\n    vocab_list = [PAD, TUNK, TMASK] + sorted(vocab)\n    stoi = {tok: i for i, tok in enumerate(vocab_list)}\n    itos = {i: t for t, i in stoi.items()}\n    return stoi, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size = len(stoi)\nprint(\"vocab size:\", vocab_size)\n\n\ndef encode(seq: str, max_len: int):\n    ids = [stoi.get(tok, stoi[TUNK]) for tok in seq.split()][:max_len]\n    if len(ids) < max_len:\n        ids += [stoi[PAD]] * (max_len - len(ids))\n    return ids\n\n\nMAX_LEN = 20\n\n\n# ----------------- datasets -----------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, rows, max_len=MAX_LEN, supervised=False):\n        self.rows = rows\n        self.max_len = max_len\n        self.supervised = supervised\n\n    # augmentations\n    def augment(self, tokens: List[int]):\n        toks = tokens.copy()\n        # random deletion\n        toks = [t for t in toks if t != stoi[PAD]]\n        if len(toks) == 0:\n            toks = [stoi[PAD]]\n        if random.random() < 0.3:\n            del_idx = random.randint(0, len(toks) - 1)\n            del toks[del_idx]\n        # random swap\n        if len(toks) > 1 and random.random() < 0.3:\n            i, j = random.sample(range(len(toks)), 2)\n            toks[i], toks[j] = toks[j], toks[i]\n        # random mask\n        toks = [stoi[TMASK] if random.random() < 0.15 else t for t in toks]\n        return encode(\" \".join(itos[t] for t in toks), self.max_len)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        row = self.rows[idx]\n        ids = encode(row[\"sequence\"], self.max_len)\n        view1 = torch.tensor(self.augment(ids), dtype=torch.long)\n        view2 = torch.tensor(self.augment(ids), dtype=torch.long)\n        if self.supervised:\n            label = torch.tensor(row[\"label\"], dtype=torch.long)\n            return {\n                \"view1\": view1,\n                \"view2\": view2,\n                \"label\": label,\n                \"seq\": row[\"sequence\"],\n            }\n        return {\"view1\": view1, \"view2\": view2, \"seq\": row[\"sequence\"]}\n\n\nclass SPRSupervisedDataset(Dataset):\n    def __init__(self, rows, max_len=MAX_LEN):\n        self.rows = rows\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        row = self.rows[idx]\n        ids = torch.tensor(encode(row[\"sequence\"], self.max_len), dtype=torch.long)\n        label = torch.tensor(row[\"label\"], dtype=torch.long)\n        return {\"ids\": ids, \"label\": label, \"seq\": row[\"sequence\"]}\n\n\n# ----------------- model -----------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, embed_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embed_dim, hidden, batch_first=True, bidirectional=True)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(hidden * 2, 128)\n\n    def forward(self, x):\n        emb = self.emb(x)  # B,L,E\n        h, _ = self.lstm(emb)  # B,L,2H\n        h = h.transpose(1, 2)  # B,2H,L\n        h = self.pool(h).squeeze(-1)  # B,2H\n        z = torch.tanh(self.proj(h))  # B,128\n        return z\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(128, num_classes)\n\n    def forward(self, x):  # x: B,L\n        z = self.encoder(x)  # B,128\n        out = self.head(z)  # B,C\n        return out\n\n\n# ----------------- contrastive loss -----------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    B = z1.size(0)\n    representations = torch.cat([z1, z2], dim=0)  # 2B,D\n    sim_matrix = torch.matmul(representations, representations.T) / temperature\n    mask = torch.eye(2 * B, dtype=torch.bool, device=z1.device)\n    sim_matrix.masked_fill_(mask, -9e15)\n    positives = torch.cat([torch.arange(B, 2 * B), torch.arange(0, B)], dim=0).to(\n        z1.device\n    )\n    loss = nn.functional.cross_entropy(sim_matrix, positives)\n    return loss\n\n\n# ----------------- training params -----------------\nBATCH = 128\nPRE_EPOCHS = 3\nFT_EPOCHS = 5\nNUM_CLASSES = len(set(r[\"label\"] for r in real_dset[\"train\"]))\nprint(\"num classes:\", NUM_CLASSES)\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n# ----------------- dataloaders -----------------\npretrain_ds = SPRContrastiveDataset(real_dset[\"train\"])\npretrain_dl = DataLoader(pretrain_ds, batch_size=BATCH, shuffle=True, drop_last=True)\ntrain_ds_sup = SPRSupervisedDataset(real_dset[\"train\"])\ndev_ds_sup = SPRSupervisedDataset(real_dset[\"dev\"])\ntrain_dl_sup = DataLoader(train_ds_sup, batch_size=BATCH, shuffle=True)\ndev_dl_sup = DataLoader(dev_ds_sup, batch_size=BATCH, shuffle=False)\n\n# ----------------- experiment data dict -----------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_SCWA\": [], \"val_SCWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n# ----------------- pretraining -----------------\nencoder = Encoder(vocab_size).to(device)\nopt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nfor epoch in range(1, PRE_EPOCHS + 1):\n    encoder.train()\n    tot_loss = 0\n    batches = 0\n    for batch in pretrain_dl:\n        v1 = batch[\"view1\"].to(device)\n        v2 = batch[\"view2\"].to(device)\n        z1 = encoder(v1)\n        z2 = encoder(v2)\n        loss = simclr_loss(z1, z2)\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        tot_loss += loss.item()\n        batches += 1\n    print(f\"PreEpoch {epoch}: contrastive_loss = {tot_loss/batches:.4f}\")\n\n# ----------------- fine-tuning -----------------\nclf = Classifier(encoder, NUM_CLASSES).to(device)\nft_opt = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, dataloader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_seqs = []\n    val_loss = 0\n    batches = 0\n    with torch.no_grad():\n        for batch in dataloader:\n            ids = batch[\"ids\"].to(device)\n            labels = batch[\"label\"].to(device)\n            logits = model(ids)\n            loss = criterion(logits, labels)\n            val_loss += loss.item()\n            batches += 1\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seq\"])\n    scwa = scwa_metric(all_seqs, all_labels, all_preds)\n    return val_loss / batches, scwa, all_preds, all_labels, all_seqs\n\n\nfor epoch in range(1, FT_EPOCHS + 1):\n    clf.train()\n    total_loss = 0\n    batches = 0\n    for batch in train_dl_sup:\n        ids = batch[\"ids\"].to(device)\n        labels = batch[\"label\"].to(device)\n        logits = clf(ids)\n        loss = criterion(logits, labels)\n        ft_opt.zero_grad()\n        loss.backward()\n        ft_opt.step()\n        total_loss += loss.item()\n        batches += 1\n    train_loss = total_loss / batches\n    val_loss, val_scwa, preds, labels_true, seqs = evaluate(clf, dev_dl_sup)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f} | SCWA = {val_scwa:.4f}\")\n    # log\n    ts = datetime.datetime.now().isoformat()\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train_SCWA\"].append(None)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_SCWA\"].append(val_scwa)\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = labels_true\n    experiment_data[\"SPR_BENCH\"][\"timestamps\"].append(ts)\n\n# ----------------- save experiment data -----------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to working/experiment_data.npy\")\n", "import os, pathlib, time, numpy as np, torch, torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nfrom datasets import DatasetDict\n\n# ----- working dir -----------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------- GPU / device -------------------------------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# -------- load SPR helper ----------------------------------------------------\n# (Assume SPR.py is in the same directory or PYTHONPATH)\nfrom SPR import load_spr_bench, count_shape_variety, count_color_variety\n\n# -------- dataset path -------------------------------------------------------\nDATA_PATH = pathlib.Path(\"./SPR_BENCH\")  # edit if different\nspr_dsets: DatasetDict = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in spr_dsets.items()})\n\n\n# -------- vocabulary ---------------------------------------------------------\ndef tokenize(seq: str):\n    return seq.strip().split()\n\n\nall_tokens = set()\nfor row in spr_dsets[\"train\"]:\n    all_tokens.update(tokenize(row[\"sequence\"]))\nPAD, CLS, UNK = \"<pad>\", \"<cls>\", \"<unk>\"\nvocab = {PAD: 0, CLS: 1, UNK: 2}\nfor tok in sorted(all_tokens):\n    vocab[tok] = len(vocab)\ninv_vocab = {i: t for t, i in vocab.items()}\nvocab_size = len(vocab)\nprint(f\"Vocab size: {vocab_size}\")\n\n\ndef encode(seq):\n    ids = [vocab[CLS]] + [vocab.get(t, vocab[UNK]) for t in tokenize(seq)]\n    return torch.tensor(ids, dtype=torch.long)\n\n\n# -------- custom dataset wrappers -------------------------------------------\nclass SPRTorchDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_split):\n        self.data = hf_split\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data[idx]\n        return {\n            \"input_ids\": encode(row[\"sequence\"]),\n            \"label\": torch.tensor(row[\"label\"], dtype=torch.long),\n            \"raw_seq\": row[\"sequence\"],\n        }\n\n\ndef collate(batch):\n    input_ids = [b[\"input_ids\"] for b in batch]\n    labels = torch.stack([b[\"label\"] for b in batch])\n    raw_seq = [b[\"raw_seq\"] for b in batch]\n    lens = torch.tensor([len(x) for x in input_ids])\n    padded = nn.utils.rnn.pad_sequence(\n        input_ids, batch_first=True, padding_value=vocab[PAD]\n    )\n    return {\"input_ids\": padded, \"lengths\": lens, \"labels\": labels, \"raw_seq\": raw_seq}\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    SPRTorchDataset(spr_dsets[\"train\"]),\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=collate,\n)\ndev_loader = DataLoader(\n    SPRTorchDataset(spr_dsets[\"dev\"]),\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=collate,\n)\n\n\n# -------- model --------------------------------------------------------------\nclass BiGRUClassifier(nn.Module):\n    def __init__(self, vocab_sz, emb_dim=128, hid_dim=256, n_classes=10):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_sz, emb_dim, padding_idx=vocab[PAD])\n        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hid_dim * 2, n_classes)\n\n    def forward(self, x, lengths):\n        emb = self.emb(x)\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, h = self.gru(packed)  # h: (2, B, hid)\n        h = torch.cat([h[0], h[1]], dim=-1)  # (B, 2*hid)\n        return self.fc(h)\n\n\nmodel = BiGRUClassifier(vocab_size).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n\n\n# -------- metric -------------------------------------------------------------\ndef scwa(seqs, y_true, y_pred):\n    weights = [count_shape_variety(s) * count_color_variety(s) for s in seqs]\n    credited = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(credited) / max(sum(weights), 1)\n\n\n# -------- experiment data dict ----------------------------------------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"epochs\": [],\n    }\n}\n\n# -------- training loop ------------------------------------------------------\nepochs = 5\nfor epoch in range(1, epochs + 1):\n    # ---- train -----\n    model.train()\n    train_loss, train_correct, train_total = 0, 0, 0\n    for batch in train_loader:\n        batch = {\n            k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n            for k, v in batch.items()\n        }\n        optimizer.zero_grad()\n        logits = model(batch[\"input_ids\"], batch[\"lengths\"])\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * batch[\"labels\"].size(0)\n    train_loss /= len(train_loader.dataset)\n    # ---- eval -----\n    model.eval()\n    val_loss = 0\n    all_pred = []\n    all_gt = []\n    all_seq = []\n    with torch.no_grad():\n        for batch in dev_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            logits = model(batch[\"input_ids\"], batch[\"lengths\"])\n            loss = criterion(logits, batch[\"labels\"])\n            val_loss += loss.item() * batch[\"labels\"].size(0)\n            preds = logits.argmax(dim=-1).cpu().tolist()\n            gts = batch[\"labels\"].cpu().tolist()\n            all_pred.extend(preds)\n            all_gt.extend(gts)\n            all_seq.extend(batch[\"raw_seq\"])\n    val_loss /= len(dev_loader.dataset)\n    train_scwa = None  # optional\n    val_scwa = scwa(all_seq, all_gt, all_pred)\n    # ---- logging -----\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}  SCWA = {val_scwa:.4f}\")\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train\"].append(train_scwa)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"].append(val_scwa)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"epochs\"].append(epoch)\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = all_pred\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = all_gt\n\n# -------- save metrics -------------------------------------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n# -------- visualization ------------------------------------------------------\nplt.figure()\nplt.plot(\n    experiment_data[\"SPR_BENCH\"][\"epochs\"],\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val\"],\n    marker=\"o\",\n)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SCWA\")\nplt.title(\"Validation SCWA over epochs\")\nplt.grid(True)\nplt.savefig(os.path.join(working_dir, \"scwa_history.png\"))\nprint(\"Finished. Data saved to working_dir.\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, random, math, time, pathlib, itertools, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List\n\n# ----------------- working dir -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n# ----------------- device -----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------- try loading SPR_BENCH -----------------\ndef try_load_real_dataset():\n    try:\n        from SPR import load_spr_bench  # local util provided by task\n\n        DATA_PATH = pathlib.Path(\"./SPR_BENCH\")\n        if not DATA_PATH.exists():\n            DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        dset = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH.\")\n        return dset\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH: \", e)\n        return None\n\n\nreal_dset = try_load_real_dataset()\n\n\n# ----------------- synthetic fallback -----------------\ndef make_random_token():\n    shapes = [\"R\", \"S\", \"T\", \"U\", \"V\"]\n    colors = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef generate_sequence(min_len=3, max_len=10):\n    return \" \".join(\n        make_random_token() for _ in range(random.randint(min_len, max_len))\n    )\n\n\ndef generate_synthetic_split(n_rows: int):\n    data = []\n    for i in range(n_rows):\n        seq = generate_sequence()\n        label = random.randint(0, 3)\n        data.append({\"id\": i, \"sequence\": seq, \"label\": label})\n    return data\n\n\nif real_dset is None:\n    print(\"Generating synthetic data \u2026\")\n    real_dset = {\n        \"train\": generate_synthetic_split(1000),\n        \"dev\": generate_synthetic_split(200),\n        \"test\": generate_synthetic_split(200),\n    }\n\n\n# ----------------- SCWA metric helpers -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.split()))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.split()))\n\n\ndef scwa_metric(sequences: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_shape_variety(s) * count_color_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\n# ----------------- vocab & encoding -----------------\nPAD, TUNK, TMASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(dataset):\n    vocab = set()\n    for row in dataset:\n        vocab.update(row[\"sequence\"].split())\n    vocab_list = [PAD, TUNK, TMASK] + sorted(vocab)\n    stoi = {tok: i for i, tok in enumerate(vocab_list)}\n    itos = {i: t for t, i in stoi.items()}\n    return stoi, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size = len(stoi)\nprint(\"vocab size:\", vocab_size)\n\n\ndef encode(seq: str, max_len: int):\n    ids = [stoi.get(tok, stoi[TUNK]) for tok in seq.split()][:max_len]\n    if len(ids) < max_len:\n        ids += [stoi[PAD]] * (max_len - len(ids))\n    return ids\n\n\nMAX_LEN = 20\n\n\n# ----------------- datasets -----------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, rows, max_len=MAX_LEN, supervised=False):\n        self.rows = rows\n        self.max_len = max_len\n        self.supervised = supervised\n\n    # augmentations\n    def augment(self, tokens: List[int]):\n        toks = tokens.copy()\n        # random deletion\n        toks = [t for t in toks if t != stoi[PAD]]\n        if len(toks) == 0:\n            toks = [stoi[PAD]]\n        if random.random() < 0.3:\n            del_idx = random.randint(0, len(toks) - 1)\n            del toks[del_idx]\n        # random swap\n        if len(toks) > 1 and random.random() < 0.3:\n            i, j = random.sample(range(len(toks)), 2)\n            toks[i], toks[j] = toks[j], toks[i]\n        # random mask\n        toks = [stoi[TMASK] if random.random() < 0.15 else t for t in toks]\n        return encode(\" \".join(itos[t] for t in toks), self.max_len)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        row = self.rows[idx]\n        ids = encode(row[\"sequence\"], self.max_len)\n        view1 = torch.tensor(self.augment(ids), dtype=torch.long)\n        view2 = torch.tensor(self.augment(ids), dtype=torch.long)\n        if self.supervised:\n            label = torch.tensor(row[\"label\"], dtype=torch.long)\n            return {\n                \"view1\": view1,\n                \"view2\": view2,\n                \"label\": label,\n                \"seq\": row[\"sequence\"],\n            }\n        return {\"view1\": view1, \"view2\": view2, \"seq\": row[\"sequence\"]}\n\n\nclass SPRSupervisedDataset(Dataset):\n    def __init__(self, rows, max_len=MAX_LEN):\n        self.rows = rows\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        row = self.rows[idx]\n        ids = torch.tensor(encode(row[\"sequence\"], self.max_len), dtype=torch.long)\n        label = torch.tensor(row[\"label\"], dtype=torch.long)\n        return {\"ids\": ids, \"label\": label, \"seq\": row[\"sequence\"]}\n\n\n# ----------------- model -----------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, embed_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embed_dim, hidden, batch_first=True, bidirectional=True)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(hidden * 2, 128)\n\n    def forward(self, x):\n        emb = self.emb(x)  # B,L,E\n        h, _ = self.lstm(emb)  # B,L,2H\n        h = h.transpose(1, 2)  # B,2H,L\n        h = self.pool(h).squeeze(-1)  # B,2H\n        z = torch.tanh(self.proj(h))  # B,128\n        return z\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(128, num_classes)\n\n    def forward(self, x):  # x: B,L\n        z = self.encoder(x)  # B,128\n        out = self.head(z)  # B,C\n        return out\n\n\n# ----------------- contrastive loss -----------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    B = z1.size(0)\n    representations = torch.cat([z1, z2], dim=0)  # 2B,D\n    sim_matrix = torch.matmul(representations, representations.T) / temperature\n    mask = torch.eye(2 * B, dtype=torch.bool, device=z1.device)\n    sim_matrix.masked_fill_(mask, -9e15)\n    positives = torch.cat([torch.arange(B, 2 * B), torch.arange(0, B)], dim=0).to(\n        z1.device\n    )\n    loss = nn.functional.cross_entropy(sim_matrix, positives)\n    return loss\n\n\n# ----------------- training params -----------------\nBATCH = 128\nPRE_EPOCHS = 3\nFT_EPOCHS = 5\nNUM_CLASSES = len(set(r[\"label\"] for r in real_dset[\"train\"]))\nprint(\"num classes:\", NUM_CLASSES)\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n# ----------------- dataloaders -----------------\npretrain_ds = SPRContrastiveDataset(real_dset[\"train\"])\npretrain_dl = DataLoader(pretrain_ds, batch_size=BATCH, shuffle=True, drop_last=True)\ntrain_ds_sup = SPRSupervisedDataset(real_dset[\"train\"])\ndev_ds_sup = SPRSupervisedDataset(real_dset[\"dev\"])\ntrain_dl_sup = DataLoader(train_ds_sup, batch_size=BATCH, shuffle=True)\ndev_dl_sup = DataLoader(dev_ds_sup, batch_size=BATCH, shuffle=False)\n\n# ----------------- experiment data dict -----------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_SCWA\": [], \"val_SCWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n# ----------------- pretraining -----------------\nencoder = Encoder(vocab_size).to(device)\nopt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nfor epoch in range(1, PRE_EPOCHS + 1):\n    encoder.train()\n    tot_loss = 0\n    batches = 0\n    for batch in pretrain_dl:\n        v1 = batch[\"view1\"].to(device)\n        v2 = batch[\"view2\"].to(device)\n        z1 = encoder(v1)\n        z2 = encoder(v2)\n        loss = simclr_loss(z1, z2)\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        tot_loss += loss.item()\n        batches += 1\n    print(f\"PreEpoch {epoch}: contrastive_loss = {tot_loss/batches:.4f}\")\n\n# ----------------- fine-tuning -----------------\nclf = Classifier(encoder, NUM_CLASSES).to(device)\nft_opt = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, dataloader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_seqs = []\n    val_loss = 0\n    batches = 0\n    with torch.no_grad():\n        for batch in dataloader:\n            ids = batch[\"ids\"].to(device)\n            labels = batch[\"label\"].to(device)\n            logits = model(ids)\n            loss = criterion(logits, labels)\n            val_loss += loss.item()\n            batches += 1\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seq\"])\n    scwa = scwa_metric(all_seqs, all_labels, all_preds)\n    return val_loss / batches, scwa, all_preds, all_labels, all_seqs\n\n\nfor epoch in range(1, FT_EPOCHS + 1):\n    clf.train()\n    total_loss = 0\n    batches = 0\n    for batch in train_dl_sup:\n        ids = batch[\"ids\"].to(device)\n        labels = batch[\"label\"].to(device)\n        logits = clf(ids)\n        loss = criterion(logits, labels)\n        ft_opt.zero_grad()\n        loss.backward()\n        ft_opt.step()\n        total_loss += loss.item()\n        batches += 1\n    train_loss = total_loss / batches\n    val_loss, val_scwa, preds, labels_true, seqs = evaluate(clf, dev_dl_sup)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f} | SCWA = {val_scwa:.4f}\")\n    # log\n    ts = datetime.datetime.now().isoformat()\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train_SCWA\"].append(None)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_SCWA\"].append(val_scwa)\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = labels_true\n    experiment_data[\"SPR_BENCH\"][\"timestamps\"].append(ts)\n\n# ----------------- save experiment data -----------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to working/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, random, math, time, pathlib, itertools, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List\n\n# ----------------- working dir -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n# ----------------- device -----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------- try loading SPR_BENCH -----------------\ndef try_load_real_dataset():\n    try:\n        from SPR import load_spr_bench  # local util provided by task\n\n        DATA_PATH = pathlib.Path(\"./SPR_BENCH\")\n        if not DATA_PATH.exists():\n            DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        dset = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH.\")\n        return dset\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH: \", e)\n        return None\n\n\nreal_dset = try_load_real_dataset()\n\n\n# ----------------- synthetic fallback -----------------\ndef make_random_token():\n    shapes = [\"R\", \"S\", \"T\", \"U\", \"V\"]\n    colors = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef generate_sequence(min_len=3, max_len=10):\n    return \" \".join(\n        make_random_token() for _ in range(random.randint(min_len, max_len))\n    )\n\n\ndef generate_synthetic_split(n_rows: int):\n    data = []\n    for i in range(n_rows):\n        seq = generate_sequence()\n        label = random.randint(0, 3)\n        data.append({\"id\": i, \"sequence\": seq, \"label\": label})\n    return data\n\n\nif real_dset is None:\n    print(\"Generating synthetic data \u2026\")\n    real_dset = {\n        \"train\": generate_synthetic_split(1000),\n        \"dev\": generate_synthetic_split(200),\n        \"test\": generate_synthetic_split(200),\n    }\n\n\n# ----------------- SCWA metric helpers -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.split()))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.split()))\n\n\ndef scwa_metric(sequences: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_shape_variety(s) * count_color_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\n# ----------------- vocab & encoding -----------------\nPAD, TUNK, TMASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(dataset):\n    vocab = set()\n    for row in dataset:\n        vocab.update(row[\"sequence\"].split())\n    vocab_list = [PAD, TUNK, TMASK] + sorted(vocab)\n    stoi = {tok: i for i, tok in enumerate(vocab_list)}\n    itos = {i: t for t, i in stoi.items()}\n    return stoi, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size = len(stoi)\nprint(\"vocab size:\", vocab_size)\n\n\ndef encode(seq: str, max_len: int):\n    ids = [stoi.get(tok, stoi[TUNK]) for tok in seq.split()][:max_len]\n    if len(ids) < max_len:\n        ids += [stoi[PAD]] * (max_len - len(ids))\n    return ids\n\n\nMAX_LEN = 20\n\n\n# ----------------- datasets -----------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, rows, max_len=MAX_LEN, supervised=False):\n        self.rows = rows\n        self.max_len = max_len\n        self.supervised = supervised\n\n    # augmentations\n    def augment(self, tokens: List[int]):\n        toks = tokens.copy()\n        # random deletion\n        toks = [t for t in toks if t != stoi[PAD]]\n        if len(toks) == 0:\n            toks = [stoi[PAD]]\n        if random.random() < 0.3:\n            del_idx = random.randint(0, len(toks) - 1)\n            del toks[del_idx]\n        # random swap\n        if len(toks) > 1 and random.random() < 0.3:\n            i, j = random.sample(range(len(toks)), 2)\n            toks[i], toks[j] = toks[j], toks[i]\n        # random mask\n        toks = [stoi[TMASK] if random.random() < 0.15 else t for t in toks]\n        return encode(\" \".join(itos[t] for t in toks), self.max_len)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        row = self.rows[idx]\n        ids = encode(row[\"sequence\"], self.max_len)\n        view1 = torch.tensor(self.augment(ids), dtype=torch.long)\n        view2 = torch.tensor(self.augment(ids), dtype=torch.long)\n        if self.supervised:\n            label = torch.tensor(row[\"label\"], dtype=torch.long)\n            return {\n                \"view1\": view1,\n                \"view2\": view2,\n                \"label\": label,\n                \"seq\": row[\"sequence\"],\n            }\n        return {\"view1\": view1, \"view2\": view2, \"seq\": row[\"sequence\"]}\n\n\nclass SPRSupervisedDataset(Dataset):\n    def __init__(self, rows, max_len=MAX_LEN):\n        self.rows = rows\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        row = self.rows[idx]\n        ids = torch.tensor(encode(row[\"sequence\"], self.max_len), dtype=torch.long)\n        label = torch.tensor(row[\"label\"], dtype=torch.long)\n        return {\"ids\": ids, \"label\": label, \"seq\": row[\"sequence\"]}\n\n\n# ----------------- model -----------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, embed_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embed_dim, hidden, batch_first=True, bidirectional=True)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(hidden * 2, 128)\n\n    def forward(self, x):\n        emb = self.emb(x)  # B,L,E\n        h, _ = self.lstm(emb)  # B,L,2H\n        h = h.transpose(1, 2)  # B,2H,L\n        h = self.pool(h).squeeze(-1)  # B,2H\n        z = torch.tanh(self.proj(h))  # B,128\n        return z\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(128, num_classes)\n\n    def forward(self, x):  # x: B,L\n        z = self.encoder(x)  # B,128\n        out = self.head(z)  # B,C\n        return out\n\n\n# ----------------- contrastive loss -----------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    B = z1.size(0)\n    representations = torch.cat([z1, z2], dim=0)  # 2B,D\n    sim_matrix = torch.matmul(representations, representations.T) / temperature\n    mask = torch.eye(2 * B, dtype=torch.bool, device=z1.device)\n    sim_matrix.masked_fill_(mask, -9e15)\n    positives = torch.cat([torch.arange(B, 2 * B), torch.arange(0, B)], dim=0).to(\n        z1.device\n    )\n    loss = nn.functional.cross_entropy(sim_matrix, positives)\n    return loss\n\n\n# ----------------- training params -----------------\nBATCH = 128\nPRE_EPOCHS = 3\nFT_EPOCHS = 5\nNUM_CLASSES = len(set(r[\"label\"] for r in real_dset[\"train\"]))\nprint(\"num classes:\", NUM_CLASSES)\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n# ----------------- dataloaders -----------------\npretrain_ds = SPRContrastiveDataset(real_dset[\"train\"])\npretrain_dl = DataLoader(pretrain_ds, batch_size=BATCH, shuffle=True, drop_last=True)\ntrain_ds_sup = SPRSupervisedDataset(real_dset[\"train\"])\ndev_ds_sup = SPRSupervisedDataset(real_dset[\"dev\"])\ntrain_dl_sup = DataLoader(train_ds_sup, batch_size=BATCH, shuffle=True)\ndev_dl_sup = DataLoader(dev_ds_sup, batch_size=BATCH, shuffle=False)\n\n# ----------------- experiment data dict -----------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_SCWA\": [], \"val_SCWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n# ----------------- pretraining -----------------\nencoder = Encoder(vocab_size).to(device)\nopt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nfor epoch in range(1, PRE_EPOCHS + 1):\n    encoder.train()\n    tot_loss = 0\n    batches = 0\n    for batch in pretrain_dl:\n        v1 = batch[\"view1\"].to(device)\n        v2 = batch[\"view2\"].to(device)\n        z1 = encoder(v1)\n        z2 = encoder(v2)\n        loss = simclr_loss(z1, z2)\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        tot_loss += loss.item()\n        batches += 1\n    print(f\"PreEpoch {epoch}: contrastive_loss = {tot_loss/batches:.4f}\")\n\n# ----------------- fine-tuning -----------------\nclf = Classifier(encoder, NUM_CLASSES).to(device)\nft_opt = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, dataloader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_seqs = []\n    val_loss = 0\n    batches = 0\n    with torch.no_grad():\n        for batch in dataloader:\n            ids = batch[\"ids\"].to(device)\n            labels = batch[\"label\"].to(device)\n            logits = model(ids)\n            loss = criterion(logits, labels)\n            val_loss += loss.item()\n            batches += 1\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seq\"])\n    scwa = scwa_metric(all_seqs, all_labels, all_preds)\n    return val_loss / batches, scwa, all_preds, all_labels, all_seqs\n\n\nfor epoch in range(1, FT_EPOCHS + 1):\n    clf.train()\n    total_loss = 0\n    batches = 0\n    for batch in train_dl_sup:\n        ids = batch[\"ids\"].to(device)\n        labels = batch[\"label\"].to(device)\n        logits = clf(ids)\n        loss = criterion(logits, labels)\n        ft_opt.zero_grad()\n        loss.backward()\n        ft_opt.step()\n        total_loss += loss.item()\n        batches += 1\n    train_loss = total_loss / batches\n    val_loss, val_scwa, preds, labels_true, seqs = evaluate(clf, dev_dl_sup)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f} | SCWA = {val_scwa:.4f}\")\n    # log\n    ts = datetime.datetime.now().isoformat()\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train_SCWA\"].append(None)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_SCWA\"].append(val_scwa)\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = labels_true\n    experiment_data[\"SPR_BENCH\"][\"timestamps\"].append(ts)\n\n# ----------------- save experiment data -----------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to working/experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os, random, math, time, pathlib, itertools, datetime, numpy as np, torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List\n\n# ----------------- working dir -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n# ----------------- device -----------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ----------------- try loading SPR_BENCH -----------------\ndef try_load_real_dataset():\n    try:\n        from SPR import load_spr_bench  # local util provided by task\n\n        DATA_PATH = pathlib.Path(\"./SPR_BENCH\")\n        if not DATA_PATH.exists():\n            DATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\n        dset = load_spr_bench(DATA_PATH)\n        print(\"Loaded real SPR_BENCH.\")\n        return dset\n    except Exception as e:\n        print(\"Could not load real SPR_BENCH: \", e)\n        return None\n\n\nreal_dset = try_load_real_dataset()\n\n\n# ----------------- synthetic fallback -----------------\ndef make_random_token():\n    shapes = [\"R\", \"S\", \"T\", \"U\", \"V\"]\n    colors = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n    return random.choice(shapes) + random.choice(colors)\n\n\ndef generate_sequence(min_len=3, max_len=10):\n    return \" \".join(\n        make_random_token() for _ in range(random.randint(min_len, max_len))\n    )\n\n\ndef generate_synthetic_split(n_rows: int):\n    data = []\n    for i in range(n_rows):\n        seq = generate_sequence()\n        label = random.randint(0, 3)\n        data.append({\"id\": i, \"sequence\": seq, \"label\": label})\n    return data\n\n\nif real_dset is None:\n    print(\"Generating synthetic data \u2026\")\n    real_dset = {\n        \"train\": generate_synthetic_split(1000),\n        \"dev\": generate_synthetic_split(200),\n        \"test\": generate_synthetic_split(200),\n    }\n\n\n# ----------------- SCWA metric helpers -----------------\ndef count_shape_variety(sequence: str) -> int:\n    return len(set(tok[0] for tok in sequence.split()))\n\n\ndef count_color_variety(sequence: str) -> int:\n    return len(set(tok[1] for tok in sequence.split()))\n\n\ndef scwa_metric(sequences: List[str], y_true: List[int], y_pred: List[int]) -> float:\n    weights = [count_shape_variety(s) * count_color_variety(s) for s in sequences]\n    correct = [w if t == p else 0 for w, t, p in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\n# ----------------- vocab & encoding -----------------\nPAD, TUNK, TMASK = \"<PAD>\", \"<UNK>\", \"<MASK>\"\n\n\ndef build_vocab(dataset):\n    vocab = set()\n    for row in dataset:\n        vocab.update(row[\"sequence\"].split())\n    vocab_list = [PAD, TUNK, TMASK] + sorted(vocab)\n    stoi = {tok: i for i, tok in enumerate(vocab_list)}\n    itos = {i: t for t, i in stoi.items()}\n    return stoi, itos\n\n\nstoi, itos = build_vocab(real_dset[\"train\"])\nvocab_size = len(stoi)\nprint(\"vocab size:\", vocab_size)\n\n\ndef encode(seq: str, max_len: int):\n    ids = [stoi.get(tok, stoi[TUNK]) for tok in seq.split()][:max_len]\n    if len(ids) < max_len:\n        ids += [stoi[PAD]] * (max_len - len(ids))\n    return ids\n\n\nMAX_LEN = 20\n\n\n# ----------------- datasets -----------------\nclass SPRContrastiveDataset(Dataset):\n    def __init__(self, rows, max_len=MAX_LEN, supervised=False):\n        self.rows = rows\n        self.max_len = max_len\n        self.supervised = supervised\n\n    # augmentations\n    def augment(self, tokens: List[int]):\n        toks = tokens.copy()\n        # random deletion\n        toks = [t for t in toks if t != stoi[PAD]]\n        if len(toks) == 0:\n            toks = [stoi[PAD]]\n        if random.random() < 0.3:\n            del_idx = random.randint(0, len(toks) - 1)\n            del toks[del_idx]\n        # random swap\n        if len(toks) > 1 and random.random() < 0.3:\n            i, j = random.sample(range(len(toks)), 2)\n            toks[i], toks[j] = toks[j], toks[i]\n        # random mask\n        toks = [stoi[TMASK] if random.random() < 0.15 else t for t in toks]\n        return encode(\" \".join(itos[t] for t in toks), self.max_len)\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        row = self.rows[idx]\n        ids = encode(row[\"sequence\"], self.max_len)\n        view1 = torch.tensor(self.augment(ids), dtype=torch.long)\n        view2 = torch.tensor(self.augment(ids), dtype=torch.long)\n        if self.supervised:\n            label = torch.tensor(row[\"label\"], dtype=torch.long)\n            return {\n                \"view1\": view1,\n                \"view2\": view2,\n                \"label\": label,\n                \"seq\": row[\"sequence\"],\n            }\n        return {\"view1\": view1, \"view2\": view2, \"seq\": row[\"sequence\"]}\n\n\nclass SPRSupervisedDataset(Dataset):\n    def __init__(self, rows, max_len=MAX_LEN):\n        self.rows = rows\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        row = self.rows[idx]\n        ids = torch.tensor(encode(row[\"sequence\"], self.max_len), dtype=torch.long)\n        label = torch.tensor(row[\"label\"], dtype=torch.long)\n        return {\"ids\": ids, \"label\": label, \"seq\": row[\"sequence\"]}\n\n\n# ----------------- model -----------------\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, embed_dim=64, hidden=128):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embed_dim, hidden, batch_first=True, bidirectional=True)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.proj = nn.Linear(hidden * 2, 128)\n\n    def forward(self, x):\n        emb = self.emb(x)  # B,L,E\n        h, _ = self.lstm(emb)  # B,L,2H\n        h = h.transpose(1, 2)  # B,2H,L\n        h = self.pool(h).squeeze(-1)  # B,2H\n        z = torch.tanh(self.proj(h))  # B,128\n        return z\n\n\nclass Classifier(nn.Module):\n    def __init__(self, encoder, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(128, num_classes)\n\n    def forward(self, x):  # x: B,L\n        z = self.encoder(x)  # B,128\n        out = self.head(z)  # B,C\n        return out\n\n\n# ----------------- contrastive loss -----------------\ndef simclr_loss(z1, z2, temperature=0.5):\n    z1 = nn.functional.normalize(z1, dim=1)\n    z2 = nn.functional.normalize(z2, dim=1)\n    B = z1.size(0)\n    representations = torch.cat([z1, z2], dim=0)  # 2B,D\n    sim_matrix = torch.matmul(representations, representations.T) / temperature\n    mask = torch.eye(2 * B, dtype=torch.bool, device=z1.device)\n    sim_matrix.masked_fill_(mask, -9e15)\n    positives = torch.cat([torch.arange(B, 2 * B), torch.arange(0, B)], dim=0).to(\n        z1.device\n    )\n    loss = nn.functional.cross_entropy(sim_matrix, positives)\n    return loss\n\n\n# ----------------- training params -----------------\nBATCH = 128\nPRE_EPOCHS = 3\nFT_EPOCHS = 5\nNUM_CLASSES = len(set(r[\"label\"] for r in real_dset[\"train\"]))\nprint(\"num classes:\", NUM_CLASSES)\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n# ----------------- dataloaders -----------------\npretrain_ds = SPRContrastiveDataset(real_dset[\"train\"])\npretrain_dl = DataLoader(pretrain_ds, batch_size=BATCH, shuffle=True, drop_last=True)\ntrain_ds_sup = SPRSupervisedDataset(real_dset[\"train\"])\ndev_ds_sup = SPRSupervisedDataset(real_dset[\"dev\"])\ntrain_dl_sup = DataLoader(train_ds_sup, batch_size=BATCH, shuffle=True)\ndev_dl_sup = DataLoader(dev_ds_sup, batch_size=BATCH, shuffle=False)\n\n# ----------------- experiment data dict -----------------\nexperiment_data = {\n    \"SPR_BENCH\": {\n        \"metrics\": {\"train_SCWA\": [], \"val_SCWA\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n        \"timestamps\": [],\n    }\n}\n\n# ----------------- pretraining -----------------\nencoder = Encoder(vocab_size).to(device)\nopt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\nfor epoch in range(1, PRE_EPOCHS + 1):\n    encoder.train()\n    tot_loss = 0\n    batches = 0\n    for batch in pretrain_dl:\n        v1 = batch[\"view1\"].to(device)\n        v2 = batch[\"view2\"].to(device)\n        z1 = encoder(v1)\n        z2 = encoder(v2)\n        loss = simclr_loss(z1, z2)\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        tot_loss += loss.item()\n        batches += 1\n    print(f\"PreEpoch {epoch}: contrastive_loss = {tot_loss/batches:.4f}\")\n\n# ----------------- fine-tuning -----------------\nclf = Classifier(encoder, NUM_CLASSES).to(device)\nft_opt = torch.optim.Adam(clf.parameters(), lr=2e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, dataloader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_seqs = []\n    val_loss = 0\n    batches = 0\n    with torch.no_grad():\n        for batch in dataloader:\n            ids = batch[\"ids\"].to(device)\n            labels = batch[\"label\"].to(device)\n            logits = model(ids)\n            loss = criterion(logits, labels)\n            val_loss += loss.item()\n            batches += 1\n            preds = logits.argmax(1).cpu().tolist()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().tolist())\n            all_seqs.extend(batch[\"seq\"])\n    scwa = scwa_metric(all_seqs, all_labels, all_preds)\n    return val_loss / batches, scwa, all_preds, all_labels, all_seqs\n\n\nfor epoch in range(1, FT_EPOCHS + 1):\n    clf.train()\n    total_loss = 0\n    batches = 0\n    for batch in train_dl_sup:\n        ids = batch[\"ids\"].to(device)\n        labels = batch[\"label\"].to(device)\n        logits = clf(ids)\n        loss = criterion(logits, labels)\n        ft_opt.zero_grad()\n        loss.backward()\n        ft_opt.step()\n        total_loss += loss.item()\n        batches += 1\n    train_loss = total_loss / batches\n    val_loss, val_scwa, preds, labels_true, seqs = evaluate(clf, dev_dl_sup)\n    print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f} | SCWA = {val_scwa:.4f}\")\n    # log\n    ts = datetime.datetime.now().isoformat()\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"train\"].append(train_loss)\n    experiment_data[\"SPR_BENCH\"][\"losses\"][\"val\"].append(val_loss)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"train_SCWA\"].append(None)\n    experiment_data[\"SPR_BENCH\"][\"metrics\"][\"val_SCWA\"].append(val_scwa)\n    experiment_data[\"SPR_BENCH\"][\"predictions\"] = preds\n    experiment_data[\"SPR_BENCH\"][\"ground_truth\"] = labels_true\n    experiment_data[\"SPR_BENCH\"][\"timestamps\"].append(ts)\n\n# ----------------- save experiment data -----------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to working/experiment_data.npy\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', \"{'train': 1000, 'dev': 200, 'test': 200}\", '\\n',\n'Vocab size: 27', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 207, in <module>\\n    for batch in train_loader:\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/utils/data/dataloader.py\", line 701, in __next__\\n    data =\nself._next_data()\\n           ^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/utils/data/dataloader.py\", line 757, in _next_data\\n    data =\nself._dataset_fetcher.fetch(index)  # may raise StopIteration\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\\n    data =\nself.dataset.__getitems__(possibly_batched_index)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/arrow_dataset.py\", line 2781, in __getitems__\\n    batch =\nself.__getitem__(keys)\\n            ^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\",\nline 132, in __getitem__\\n    ids = torch.tensor(encode(self.seqs[idx],\nself.max_len), dtype=torch.long)\\n\n~~~~~~~~~^^^^^\\nTypeError: list indices must be integers or slices, not list\\n',\n'Execution time: a second seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 110, in <module>\\n    dset = get_dataset()\\n\n^^^^^^^^^^^^^\\n  File \"runfile.py\", line 98, in get_dataset\\n    train =\nload_dataset(\\n            ^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 2062, in load_dataset\\n    builder_instance =\nload_dataset_builder(\\n                       ^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1782, in load_dataset_builder\\n\ndataset_module = dataset_module_factory(\\n\n^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 1497, in dataset_module_factory\\n\n).get_module()\\n      ^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/load.py\", line 913, in get_module\\n    data_files =\nDataFilesDict.from_patterns(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\nFile \"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 690, in from_patterns\\n    else\nDataFilesList.from_patterns(\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 583, in from_patterns\\n\nresolve_pattern(\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/data_files.py\", line 344, in resolve_pattern\\n    if\nis_relative_path(pattern):\\n       ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/utils/file_utils.py\", line 88, in is_relative_path\\n    return\nurlparse(url_or_filename).scheme == \"\" and not os.path.isabs(url_or_filename)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py\",\nline 394, in urlparse\\n    url, scheme, _coerce_result = _coerce_args(url,\nscheme)\\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py\",\nline 133, in _coerce_args\\n    return _decode_args(args) + (_encode_result,)\\n\n^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py\",\nline 117, in _decode_args\\n    return tuple(x.decode(encoding, errors) if x else\n\\'\\' for x in args)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py\",\nline 117, in <genexpr>\\n    return tuple(x.decode(encoding, errors) if x else\n\\'\\' for x in args)\\n                 ^^^^^^^^\\nAttributeError: \\'dict\\' object\nhas no attribute \\'decode\\'\\n', 'Execution time: a moment seconds (time limit is\n30 minutes).']", "['Using device: cuda', '\\n', 'Could not load real SPR_BENCH: ', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Generating synthetic data \u2026', '\\n', 'vocab size:', ' ',\n'28', '\\n', 'num classes:', ' ', '4', '\\n', 'PreEpoch 1: contrastive_loss =\n4.8968', '\\n', 'PreEpoch 2: contrastive_loss = 4.2440', '\\n', 'PreEpoch 3:\ncontrastive_loss = 4.1400', '\\n', 'Epoch 1: validation_loss = 1.3894 | SCWA =\n0.2530', '\\n', 'Epoch 2: validation_loss = 1.3897 | SCWA = 0.2575', '\\n', 'Epoch\n3: validation_loss = 1.4073 | SCWA = 0.2497', '\\n', 'Epoch 4: validation_loss =\n1.4218 | SCWA = 0.2604', '\\n', 'Epoch 5: validation_loss = 1.4560 | SCWA =\n0.2656', '\\n', 'Saved experiment data to working/experiment_data.npy', '\\n',\n'Execution time: 2 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Traceback (most recent call last):\\n  File\n\"runfile.py\", line 16, in <module>\\n    from SPR import load_spr_bench,\ncount_shape_variety, count_color_variety\\nModuleNotFoundError: No module named\n\\'SPR\\'\\n', 'Execution time: a moment seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Could not load real SPR_BENCH: ', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Generating synthetic data \u2026', '\\n', 'vocab size:', ' ',\n'28', '\\n', 'num classes:', ' ', '4', '\\n', 'PreEpoch 1: contrastive_loss =\n4.9045', '\\n', 'PreEpoch 2: contrastive_loss = 4.2525', '\\n', 'PreEpoch 3:\ncontrastive_loss = 4.1350', '\\n', 'Epoch 1: validation_loss = 1.4020 | SCWA =\n0.1996', '\\n', 'Epoch 2: validation_loss = 1.4065 | SCWA = 0.2398', '\\n', 'Epoch\n3: validation_loss = 1.4305 | SCWA = 0.2456', '\\n', 'Epoch 4: validation_loss =\n1.4357 | SCWA = 0.2620', '\\n', 'Epoch 5: validation_loss = 1.4543 | SCWA =\n0.2522', '\\n', 'Saved experiment data to working/experiment_data.npy', '\\n',\n'Execution time: 3 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Could not load real SPR_BENCH: ', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Generating synthetic data \u2026', '\\n', 'vocab size:', ' ',\n'28', '\\n', 'num classes:', ' ', '4', '\\n', 'PreEpoch 1: contrastive_loss =\n4.8936', '\\n', 'PreEpoch 2: contrastive_loss = 4.2437', '\\n', 'PreEpoch 3:\ncontrastive_loss = 4.1287', '\\n', 'Epoch 1: validation_loss = 1.4125 | SCWA =\n0.2351', '\\n', 'Epoch 2: validation_loss = 1.4024 | SCWA = 0.2531', '\\n', 'Epoch\n3: validation_loss = 1.4231 | SCWA = 0.2369', '\\n', 'Epoch 4: validation_loss =\n1.4439 | SCWA = 0.2253', '\\n', 'Epoch 5: validation_loss = 1.4783 | SCWA =\n0.2377', '\\n', 'Saved experiment data to working/experiment_data.npy', '\\n',\n'Execution time: 2 seconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', 'Could not load real SPR_BENCH: ', ' ', \"No module\nnamed 'SPR'\", '\\n', 'Generating synthetic data \u2026', '\\n', 'vocab size:', ' ',\n'28', '\\n', 'num classes:', ' ', '4', '\\n', 'PreEpoch 1: contrastive_loss =\n4.8942', '\\n', 'PreEpoch 2: contrastive_loss = 4.2382', '\\n', 'PreEpoch 3:\ncontrastive_loss = 4.1432', '\\n', 'Epoch 1: validation_loss = 1.3900 | SCWA =\n0.2418', '\\n', 'Epoch 2: validation_loss = 1.3894 | SCWA = 0.2005', '\\n', 'Epoch\n3: validation_loss = 1.4023 | SCWA = 0.2155', '\\n', 'Epoch 4: validation_loss =\n1.4225 | SCWA = 0.2115', '\\n', 'Epoch 5: validation_loss = 1.4234 | SCWA =\n0.2247', '\\n', 'Saved experiment data to working/experiment_data.npy', '\\n',\n'Execution time: 2 seconds seconds (time limit is 30 minutes).']", ""], "analysis": ["The execution failed due to a TypeError in the `__getitem__` function of the\n`SPRTorchSet` class. Specifically, the issue arises when accessing\n`self.seqs[idx]` because `self.seqs` is a list, but `idx` is being passed as a\nlist instead of a single integer, which is not allowed.   To fix this issue,\nensure that the `idx` parameter in the `__getitem__` method is always an\ninteger. This can be achieved by checking the type of `idx` and handling it\nappropriately. For example, you can add a conditional check to process only\ninteger indices or modify the DataLoader's behavior to pass single indices\ninstead of lists.", "The execution encountered a bug when attempting to load synthetic datasets using\nthe `load_dataset` function. The issue arises from the incorrect use of\n`load_dataset` with a dictionary as the input for `data_files`. Specifically,\nthe error occurs because the `data_files` argument is expected to contain paths\nto files, but the code provides a dictionary containing the synthetic dataset\ndirectly. This leads to an AttributeError when the `urlparse` function tries to\nprocess the dictionary as a URL or file path.  To fix this issue, the synthetic\ndata should be saved to temporary JSON files before calling `load_dataset`. For\nexample, the generated synthetic data can be written to temporary JSON files\nusing Python's `tempfile` module, and the paths to these files can then be\npassed to the `data_files` argument of `load_dataset`. This ensures that\n`load_dataset` receives valid file paths and avoids the AttributeError.", "", "The execution failed due to a `ModuleNotFoundError` for the module 'SPR'. This\nerror indicates that the script could not locate the 'SPR' module. This could be\ndue to the 'SPR.py' file not being in the same directory as the script being\nexecuted, or the PYTHONPATH not being configured correctly.  To fix this issue:\n1. Ensure that the 'SPR.py' file is located in the same directory as the script\nbeing executed, or provide the correct path to the file. 2. If the file is in a\ndifferent directory, add that directory to the PYTHONPATH environment variable\nso that Python can locate the module. 3. Verify the file name and ensure there\nare no typos in 'SPR.py'.  Once these steps are addressed, re-run the script to\nconfirm the issue is resolved.", "", "", "", ""], "exc_type": ["TypeError", "AttributeError", null, "ModuleNotFoundError", null, null, null, null], "exc_info": [{"args": ["list indices must be integers or slices, not list"]}, {"args": ["'dict' object has no attribute 'decode'"], "name": "decode", "obj": "{'id': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], 'sequence': ['\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y', '\u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6b \u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6g', '\u25b2\u25a0\u25cf\u25c6g \u25b2\u25a0\u25cf\u25c6y \u25b2\u25a0\u25cf\u25c6r \u25b2\u25a0\u25cf\u25c6r'], 'label': [0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0]}"}, null, {"args": ["No module named 'SPR'"], "name": "SPR", "msg": "No module named 'SPR'"}, null, null, null, null], "exc_stack": [[["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 207, "<module>", "for batch in train_loader:"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/utils/data/dataloader.py", 701, "__next__", "data = self._next_data()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/utils/data/dataloader.py", 757, "_next_data", "data = self._dataset_fetcher.fetch(index)  # may raise StopIteration"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", 50, "fetch", "data = self.dataset.__getitems__(possibly_batched_index)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/arrow_dataset.py", 2781, "__getitems__", "batch = self.__getitem__(keys)"], ["runfile.py", 132, "__getitem__", "ids = torch.tensor(encode(self.seqs[idx], self.max_len), dtype=torch.long)"]], [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 110, "<module>", "dset = get_dataset()"], ["runfile.py", 98, "get_dataset", "train = load_dataset("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 2062, "load_dataset", "builder_instance = load_dataset_builder("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1782, "load_dataset_builder", "dataset_module = dataset_module_factory("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 1497, "dataset_module_factory", ").get_module()"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/load.py", 913, "get_module", "data_files = DataFilesDict.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 690, "from_patterns", "else DataFilesList.from_patterns("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 583, "from_patterns", "resolve_pattern("], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/data_files.py", 344, "resolve_pattern", "if is_relative_path(pattern):"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/utils/file_utils.py", 88, "is_relative_path", "return urlparse(url_or_filename).scheme == \"\" and not os.path.isabs(url_or_filename)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py", 394, "urlparse", "url, scheme, _coerce_result = _coerce_args(url, scheme)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py", 133, "_coerce_args", "return _decode_args(args) + (_encode_result,)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py", 117, "_decode_args", "return tuple(x.decode(encoding, errors) if x else '' for x in args)"], ["/home/zxl240011/anaconda3/envs/ai_scientist/lib/python3.11/urllib/parse.py", 117, "<genexpr>", "return tuple(x.decode(encoding, errors) if x else '' for x in args)"]], null, [["/home/zxl240011/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 16, "<module>", "from SPR import load_spr_bench, count_shape_variety, count_color_variety"]], null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.337562, "best_value": 1.337562}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error during validation. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.389389, "best_value": 1.389389}]}, {"metric_name": "validation SCWA score", "lower_is_better": false, "description": "Measures the SCWA score during validation. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.265562, "best_value": 0.265562}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.337352, "best_value": 1.337352}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.401969, "best_value": 1.401969}]}, {"metric_name": "validation SCWA score", "lower_is_better": false, "description": "Measures the SCWA score on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.261974, "best_value": 0.261974}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Measures the error rate during training. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.325046, "best_value": 1.325046}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Measures the error rate during validation. Lower values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.402447, "best_value": 1.402447}]}, {"metric_name": "validation SCWA score", "lower_is_better": false, "description": "The SCWA score for validation. Higher values indicate better performance.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.253103, "best_value": 0.253103}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is fitting the training data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.337741, "best_value": 1.337741}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, indicating how well the model is performing on unseen data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 1.389449, "best_value": 1.389449}]}, {"metric_name": "validation SCWA score", "lower_is_better": false, "description": "The SCWA score during validation, measuring performance on unseen data.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.241809, "best_value": 0.241809}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, true, false, false, false, false, false], "plots": [[], [], ["../../logs/0-run/experiment_results/experiment_3de60c0439184beba1524f3cf37fb135_proc_3096397/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_3de60c0439184beba1524f3cf37fb135_proc_3096397/SPR_BENCH_val_SCWA_curve.png", "../../logs/0-run/experiment_results/experiment_3de60c0439184beba1524f3cf37fb135_proc_3096397/SPR_BENCH_confusion_matrix.png"], [], ["../../logs/0-run/experiment_results/experiment_c0ee3e4f8a1e482187a690ec50900bcf_proc_3096398/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_c0ee3e4f8a1e482187a690ec50900bcf_proc_3096398/SPR_BENCH_val_SCWA_curve.png", "../../logs/0-run/experiment_results/experiment_c0ee3e4f8a1e482187a690ec50900bcf_proc_3096398/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_b65da683c6be43b1b2fce20186d6c934_proc_3096395/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_b65da683c6be43b1b2fce20186d6c934_proc_3096395/SPR_BENCH_val_SCWA_curve.png", "../../logs/0-run/experiment_results/experiment_b65da683c6be43b1b2fce20186d6c934_proc_3096395/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_5fa7c7c76a194f05b1250c667257800a_proc_3096396/SPR_BENCH_loss_curve.png", "../../logs/0-run/experiment_results/experiment_5fa7c7c76a194f05b1250c667257800a_proc_3096396/SPR_BENCH_val_SCWA_curve.png", "../../logs/0-run/experiment_results/experiment_5fa7c7c76a194f05b1250c667257800a_proc_3096396/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/seed_aggregation_e2c89a6bc8474b8ebeda66acfa81b434/SPR_BENCH_aggregated_loss_curve.png", "../../logs/0-run/experiment_results/seed_aggregation_e2c89a6bc8474b8ebeda66acfa81b434/SPR_BENCH_aggregated_val_SCWA_curve.png"]], "plot_paths": [[], [], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3de60c0439184beba1524f3cf37fb135_proc_3096397/SPR_BENCH_loss_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3de60c0439184beba1524f3cf37fb135_proc_3096397/SPR_BENCH_val_SCWA_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3de60c0439184beba1524f3cf37fb135_proc_3096397/SPR_BENCH_confusion_matrix.png"], [], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c0ee3e4f8a1e482187a690ec50900bcf_proc_3096398/SPR_BENCH_loss_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c0ee3e4f8a1e482187a690ec50900bcf_proc_3096398/SPR_BENCH_val_SCWA_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c0ee3e4f8a1e482187a690ec50900bcf_proc_3096398/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b65da683c6be43b1b2fce20186d6c934_proc_3096395/SPR_BENCH_loss_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b65da683c6be43b1b2fce20186d6c934_proc_3096395/SPR_BENCH_val_SCWA_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b65da683c6be43b1b2fce20186d6c934_proc_3096395/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_5fa7c7c76a194f05b1250c667257800a_proc_3096396/SPR_BENCH_loss_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_5fa7c7c76a194f05b1250c667257800a_proc_3096396/SPR_BENCH_val_SCWA_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_5fa7c7c76a194f05b1250c667257800a_proc_3096396/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_e2c89a6bc8474b8ebeda66acfa81b434/SPR_BENCH_aggregated_loss_curve.png", "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/seed_aggregation_e2c89a6bc8474b8ebeda66acfa81b434/SPR_BENCH_aggregated_val_SCWA_curve.png"]], "plot_analyses": [[], [], [{"analysis": "The loss curve shows a decreasing trend for the training loss, suggesting that the model is learning from the training data. However, the validation loss increases over epochs, indicating potential overfitting. This implies that the model's generalization capability on unseen data is not improving, which could be addressed by techniques such as regularization, better data augmentation, or early stopping.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3de60c0439184beba1524f3cf37fb135_proc_3096397/SPR_BENCH_loss_curve.png"}, {"analysis": "The SCWA (Shape-Color Weighted Accuracy) on the validation set remains nearly constant throughout the epochs, hovering around a low value (approximately 0.2). This suggests that the model is not effectively learning meaningful patterns in the symbolic sequences to improve its performance. Further investigation into the model architecture, training process, or data preprocessing might be required to address this issue.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3de60c0439184beba1524f3cf37fb135_proc_3096397/SPR_BENCH_val_SCWA_curve.png"}, {"analysis": "The confusion matrix for the validation set indicates that the model struggles with distinguishing between different classes. The diagonal elements, representing correct predictions, are not significantly higher than the off-diagonal values, showing that the model's predictions are not strongly aligned with the ground truth. This could be due to insufficient feature learning or the complexity of the SPR task.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_3de60c0439184beba1524f3cf37fb135_proc_3096397/SPR_BENCH_confusion_matrix.png"}], [], [{"analysis": "This plot shows the cross-entropy loss for both training and validation sets over five epochs. The training loss decreases consistently, indicating that the model is learning from the training data. However, the validation loss increases after the second epoch, suggesting potential overfitting. This could mean that the model is not generalizing well to unseen data, and regularization techniques or adjustments to the training procedure may be necessary.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c0ee3e4f8a1e482187a690ec50900bcf_proc_3096398/SPR_BENCH_loss_curve.png"}, {"analysis": "The SCWA (Shape-Color Weighted Accuracy) on the validation set shows a slight improvement initially but plateaus after the third epoch. The lack of significant improvement suggests that the model struggles to capture the underlying patterns in the data effectively. This could be due to insufficient representation learning or the need for better hyperparameter tuning or feature engineering.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c0ee3e4f8a1e482187a690ec50900bcf_proc_3096398/SPR_BENCH_val_SCWA_curve.png"}, {"analysis": "The confusion matrix highlights the distribution of predictions versus true labels on the validation set. While there is some degree of correct predictions (diagonal elements), the off-diagonal elements indicate misclassifications. The model's performance seems uneven across different classes, suggesting the need for class-specific adjustments or improvements in the training data balance.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c0ee3e4f8a1e482187a690ec50900bcf_proc_3096398/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The loss curve shows a decreasing trend in training loss, indicating that the model is learning the training data effectively. However, the validation loss exhibits an increasing trend, suggesting potential overfitting. This could mean that the model is failing to generalize well to unseen data, and adjustments such as regularization, better hyperparameter tuning, or more diverse data augmentation might be necessary.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b65da683c6be43b1b2fce20186d6c934_proc_3096395/SPR_BENCH_loss_curve.png"}, {"analysis": "The SCWA (Shape and Color Weighted Accuracy) metric on the validation set shows little to no improvement over epochs, with the values remaining relatively low and stable. This indicates that the current model setup or training process is not effectively improving performance in terms of this metric. Further exploration of the model architecture, hyperparameters, or training strategies might be needed to enhance SCWA.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b65da683c6be43b1b2fce20186d6c934_proc_3096395/SPR_BENCH_val_SCWA_curve.png"}, {"analysis": "The confusion matrix for the validation set shows that the model has difficulty distinguishing between certain classes. The diagonal elements, which represent correct predictions, are not dominant, suggesting that the model's classification accuracy is suboptimal. Misclassifications across multiple classes highlight the need for better feature representation or more effective training techniques to improve class separability.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b65da683c6be43b1b2fce20186d6c934_proc_3096395/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "The loss curve shows a decreasing trend in training loss, indicating that the model is learning from the training data. However, the validation loss increases slightly over epochs, suggesting potential overfitting or a lack of generalization to unseen data. This discrepancy should be addressed by considering regularization techniques, hyperparameter tuning, or improved data augmentation strategies.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_5fa7c7c76a194f05b1250c667257800a_proc_3096396/SPR_BENCH_loss_curve.png"}, {"analysis": "The SCWA (Shape and Color Weighted Accuracy) metric on the validation set remains relatively flat over epochs, with slight fluctuations. This indicates that the model's performance on the weighted accuracy metric is not improving significantly during training. This might be due to the model's inability to capture the nuances of the weighted accuracy metric or insufficient learning of the symbolic patterns in the data.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_5fa7c7c76a194f05b1250c667257800a_proc_3096396/SPR_BENCH_val_SCWA_curve.png"}, {"analysis": "The confusion matrix for the validation set shows some degree of misclassification across all classes, with no clear dominance of correct predictions for any specific class. This indicates that the model struggles to differentiate between the symbolic patterns effectively, which could be due to insufficient feature representation or the complexity of the SPR task.", "plot_path": "experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_5fa7c7c76a194f05b1250c667257800a_proc_3096396/SPR_BENCH_confusion_matrix.png"}], []], "vlm_feedback_summary": ["[]", "[]", "The results indicate significant challenges in model generalization and\nperformance on the SPR task. The increasing validation loss and low SCWA suggest\noverfitting and poor learning of meaningful patterns. The confusion matrix\nhighlights difficulties in class differentiation, implying the need for\nimprovements in the training framework, such as enhanced data augmentation,\nbetter regularization, or refined model architecture.", "[]", "The analysis highlights potential overfitting in the model, limited improvement\nin SCWA, and uneven class performance. Recommendations include improving\ngeneralization techniques, enhancing representation learning, and addressing\nclass-specific issues in the dataset.", "The plots indicate challenges in generalization and performance improvement. The\ntraining loss decreases while validation loss increases, suggesting overfitting.\nSCWA remains low and stagnant, and the confusion matrix reveals suboptimal class\nseparability, necessitating further optimization of the model and training\nprocess.", "The plots indicate challenges in model generalization and performance\nimprovement. While the training loss decreases, validation loss increases, and\nSCWA remains stagnant, suggesting potential overfitting and insufficient\nlearning of symbolic patterns. The confusion matrix highlights misclassification\nissues across all classes, emphasizing the need for better feature\nrepresentation and model tuning.", "[]"], "exec_time": [1.9759888648986816, 0.6147053241729736, 2.2030279636383057, 0.4276309013366699, 3.4575517177581787, 2.8395955562591553, 2.6069552898406982, null], "exec_time_feedback": ["", "", "", "", "", "", "", ""], "datasets_successfully_tested": [[], [], ["[]"], [], ["\"\""], ["[]"], ["[]"], []], "plot_code": [null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nfor dset_name, dset_dict in experiment_data.items():\n    losses_tr = dset_dict[\"losses\"][\"train\"]\n    losses_val = dset_dict[\"losses\"][\"val\"]\n    scwa_vals = dset_dict[\"metrics\"][\"val_SCWA\"]\n    preds = np.array(dset_dict.get(\"predictions\", []))\n    gts = np.array(dset_dict.get(\"ground_truth\", []))\n    epochs = np.arange(1, len(losses_tr) + 1)\n\n    # ------------- 1. Loss curve ------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, losses_tr, label=\"Train\")\n        plt.plot(epochs, losses_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dset_name}: Loss Curve\\nTraining vs Validation\")\n        plt.legend()\n        save_name = os.path.join(working_dir, f\"{dset_name}_loss_curve.png\")\n        plt.savefig(save_name)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- 2. SCWA curve ------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, scwa_vals, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SCWA\")\n        plt.ylim(0, 1)\n        plt.title(f\"{dset_name}: Validation SCWA Over Epochs\")\n        save_name = os.path.join(working_dir, f\"{dset_name}_val_SCWA_curve.png\")\n        plt.savefig(save_name)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SCWA curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- 3. Confusion matrix ------------\n    try:\n        if preds.size and gts.size:\n            n_cls = int(max(preds.max(), gts.max())) + 1\n            cm = np.zeros((n_cls, n_cls), dtype=int)\n            for t, p in zip(gts, preds):\n                cm[t, p] += 1\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(f\"{dset_name}: Confusion Matrix (Validation Set)\")\n            plt.xticks(range(n_cls))\n            plt.yticks(range(n_cls))\n            save_name = os.path.join(working_dir, f\"{dset_name}_confusion_matrix.png\")\n            plt.savefig(save_name)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- Print metrics ------------------\n    val_scwa_arr = np.array(scwa_vals, dtype=float)\n    if val_scwa_arr.size:\n        print(\n            f\"{dset_name} \u2013 Final Val SCWA: {val_scwa_arr[-1]:.4f} | \"\n            f\"Best Val SCWA: {np.nanmax(val_scwa_arr):.4f}\"\n        )\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nfor dset_name, dset_dict in experiment_data.items():\n    losses_tr = dset_dict[\"losses\"][\"train\"]\n    losses_val = dset_dict[\"losses\"][\"val\"]\n    scwa_vals = dset_dict[\"metrics\"][\"val_SCWA\"]\n    preds = np.array(dset_dict.get(\"predictions\", []))\n    gts = np.array(dset_dict.get(\"ground_truth\", []))\n    epochs = np.arange(1, len(losses_tr) + 1)\n\n    # ------------- 1. Loss curve ------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, losses_tr, label=\"Train\")\n        plt.plot(epochs, losses_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dset_name}: Loss Curve\\nTraining vs Validation\")\n        plt.legend()\n        save_name = os.path.join(working_dir, f\"{dset_name}_loss_curve.png\")\n        plt.savefig(save_name)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- 2. SCWA curve ------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, scwa_vals, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SCWA\")\n        plt.ylim(0, 1)\n        plt.title(f\"{dset_name}: Validation SCWA Over Epochs\")\n        save_name = os.path.join(working_dir, f\"{dset_name}_val_SCWA_curve.png\")\n        plt.savefig(save_name)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SCWA curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- 3. Confusion matrix ------------\n    try:\n        if preds.size and gts.size:\n            n_cls = int(max(preds.max(), gts.max())) + 1\n            cm = np.zeros((n_cls, n_cls), dtype=int)\n            for t, p in zip(gts, preds):\n                cm[t, p] += 1\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(f\"{dset_name}: Confusion Matrix (Validation Set)\")\n            plt.xticks(range(n_cls))\n            plt.yticks(range(n_cls))\n            save_name = os.path.join(working_dir, f\"{dset_name}_confusion_matrix.png\")\n            plt.savefig(save_name)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- Print metrics ------------------\n    val_scwa_arr = np.array(scwa_vals, dtype=float)\n    if val_scwa_arr.size:\n        print(\n            f\"{dset_name} \u2013 Final Val SCWA: {val_scwa_arr[-1]:.4f} | \"\n            f\"Best Val SCWA: {np.nanmax(val_scwa_arr):.4f}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nfor dset_name, dset_dict in experiment_data.items():\n    losses_tr = dset_dict[\"losses\"][\"train\"]\n    losses_val = dset_dict[\"losses\"][\"val\"]\n    scwa_vals = dset_dict[\"metrics\"][\"val_SCWA\"]\n    preds = np.array(dset_dict.get(\"predictions\", []))\n    gts = np.array(dset_dict.get(\"ground_truth\", []))\n    epochs = np.arange(1, len(losses_tr) + 1)\n\n    # ------------- 1. Loss curve ------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, losses_tr, label=\"Train\")\n        plt.plot(epochs, losses_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dset_name}: Loss Curve\\nTraining vs Validation\")\n        plt.legend()\n        save_name = os.path.join(working_dir, f\"{dset_name}_loss_curve.png\")\n        plt.savefig(save_name)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- 2. SCWA curve ------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, scwa_vals, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SCWA\")\n        plt.ylim(0, 1)\n        plt.title(f\"{dset_name}: Validation SCWA Over Epochs\")\n        save_name = os.path.join(working_dir, f\"{dset_name}_val_SCWA_curve.png\")\n        plt.savefig(save_name)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SCWA curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- 3. Confusion matrix ------------\n    try:\n        if preds.size and gts.size:\n            n_cls = int(max(preds.max(), gts.max())) + 1\n            cm = np.zeros((n_cls, n_cls), dtype=int)\n            for t, p in zip(gts, preds):\n                cm[t, p] += 1\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(f\"{dset_name}: Confusion Matrix (Validation Set)\")\n            plt.xticks(range(n_cls))\n            plt.yticks(range(n_cls))\n            save_name = os.path.join(working_dir, f\"{dset_name}_confusion_matrix.png\")\n            plt.savefig(save_name)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- Print metrics ------------------\n    val_scwa_arr = np.array(scwa_vals, dtype=float)\n    if val_scwa_arr.size:\n        print(\n            f\"{dset_name} \u2013 Final Val SCWA: {val_scwa_arr[-1]:.4f} | \"\n            f\"Best Val SCWA: {np.nanmax(val_scwa_arr):.4f}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nfor dset_name, dset_dict in experiment_data.items():\n    losses_tr = dset_dict[\"losses\"][\"train\"]\n    losses_val = dset_dict[\"losses\"][\"val\"]\n    scwa_vals = dset_dict[\"metrics\"][\"val_SCWA\"]\n    preds = np.array(dset_dict.get(\"predictions\", []))\n    gts = np.array(dset_dict.get(\"ground_truth\", []))\n    epochs = np.arange(1, len(losses_tr) + 1)\n\n    # ------------- 1. Loss curve ------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, losses_tr, label=\"Train\")\n        plt.plot(epochs, losses_val, label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(f\"{dset_name}: Loss Curve\\nTraining vs Validation\")\n        plt.legend()\n        save_name = os.path.join(working_dir, f\"{dset_name}_loss_curve.png\")\n        plt.savefig(save_name)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- 2. SCWA curve ------------------\n    try:\n        plt.figure()\n        plt.plot(epochs, scwa_vals, marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SCWA\")\n        plt.ylim(0, 1)\n        plt.title(f\"{dset_name}: Validation SCWA Over Epochs\")\n        save_name = os.path.join(working_dir, f\"{dset_name}_val_SCWA_curve.png\")\n        plt.savefig(save_name)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SCWA curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- 3. Confusion matrix ------------\n    try:\n        if preds.size and gts.size:\n            n_cls = int(max(preds.max(), gts.max())) + 1\n            cm = np.zeros((n_cls, n_cls), dtype=int)\n            for t, p in zip(gts, preds):\n                cm[t, p] += 1\n            plt.figure()\n            plt.imshow(cm, cmap=\"Blues\")\n            plt.colorbar()\n            plt.xlabel(\"Predicted\")\n            plt.ylabel(\"True\")\n            plt.title(f\"{dset_name}: Confusion Matrix (Validation Set)\")\n            plt.xticks(range(n_cls))\n            plt.yticks(range(n_cls))\n            save_name = os.path.join(working_dir, f\"{dset_name}_confusion_matrix.png\")\n            plt.savefig(save_name)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix for {dset_name}: {e}\")\n        plt.close()\n\n    # ------------- Print metrics ------------------\n    val_scwa_arr = np.array(scwa_vals, dtype=float)\n    if val_scwa_arr.size:\n        print(\n            f\"{dset_name} \u2013 Final Val SCWA: {val_scwa_arr[-1]:.4f} | \"\n            f\"Best Val SCWA: {np.nanmax(val_scwa_arr):.4f}\"\n        )\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# -------------------------------------------------\n# 1. Load all experiment_data dicts\nexperiment_data_path_list = [\n    \"experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_c0ee3e4f8a1e482187a690ec50900bcf_proc_3096398/experiment_data.npy\",\n    \"experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_b65da683c6be43b1b2fce20186d6c934_proc_3096395/experiment_data.npy\",\n    \"experiments/2025-08-16_02-31-02_context_aware_contrastive_learning_attempt_0/logs/0-run/experiment_results/experiment_5fa7c7c76a194f05b1250c667257800a_proc_3096396/experiment_data.npy\",\n]\n\nall_experiment_data = []\ntry:\n    for p in experiment_data_path_list:\n        full_path = os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", \"\"), p)\n        edict = np.load(full_path, allow_pickle=True).item()\n        all_experiment_data.append(edict)\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    all_experiment_data = []\n\n# -------------------------------------------------\n# 2. Aggregate by dataset\ndatasets = {}\nfor run_dict in all_experiment_data:\n    for dset_name, dset_dict in run_dict.items():\n        entry = datasets.setdefault(\n            dset_name,\n            {\n                \"losses_tr\": [],\n                \"losses_val\": [],\n                \"scwa\": [],\n            },\n        )\n        entry[\"losses_tr\"].append(np.asarray(dset_dict[\"losses\"][\"train\"], dtype=float))\n        entry[\"losses_val\"].append(np.asarray(dset_dict[\"losses\"][\"val\"], dtype=float))\n        entry[\"scwa\"].append(np.asarray(dset_dict[\"metrics\"][\"val_SCWA\"], dtype=float))\n\n\n# -------------------------------------------------\n# 3. Helper to trim runs to common length (min length across runs)\ndef stack_and_trim(list_of_1d_arrays):\n    if not list_of_1d_arrays:\n        return np.empty((0, 0))\n    min_len = min(len(a) for a in list_of_1d_arrays)\n    trimmed = np.stack([a[:min_len] for a in list_of_1d_arrays], axis=0)\n    return trimmed  # shape (n_runs, min_len)\n\n\n# -------------------------------------------------\nfor dset_name, dset_data in datasets.items():\n    # ----- Aggregate Loss Curves -----\n    try:\n        tr_mat = stack_and_trim(dset_data[\"losses_tr\"])\n        val_mat = stack_and_trim(dset_data[\"losses_val\"])\n        if tr_mat.size and val_mat.size:\n            epochs = np.arange(1, tr_mat.shape[1] + 1)\n            tr_mean, tr_sem = np.nanmean(tr_mat, axis=0), np.nanstd(\n                tr_mat, axis=0\n            ) / np.sqrt(tr_mat.shape[0])\n            val_mean, val_sem = np.nanmean(val_mat, axis=0), np.nanstd(\n                val_mat, axis=0\n            ) / np.sqrt(val_mat.shape[0])\n\n            plt.figure()\n            plt.plot(epochs, tr_mean, label=\"Train Mean\", color=\"tab:blue\")\n            plt.fill_between(\n                epochs,\n                tr_mean - tr_sem,\n                tr_mean + tr_sem,\n                alpha=0.3,\n                color=\"tab:blue\",\n                label=\"Train \u00b1SEM\",\n            )\n            plt.plot(epochs, val_mean, label=\"Val Mean\", color=\"tab:orange\")\n            plt.fill_between(\n                epochs,\n                val_mean - val_sem,\n                val_mean + val_sem,\n                alpha=0.3,\n                color=\"tab:orange\",\n                label=\"Val \u00b1SEM\",\n            )\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"Cross-Entropy Loss\")\n            plt.title(\n                f\"{dset_name}: Loss Curve (Mean \u00b1 SEM)\\nAggregated over {tr_mat.shape[0]} runs\"\n            )\n            plt.legend()\n            save_name = os.path.join(\n                working_dir, f\"{dset_name}_aggregated_loss_curve.png\"\n            )\n            plt.savefig(save_name)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated loss curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ----- Aggregate SCWA Curves -----\n    try:\n        scwa_mat = stack_and_trim(dset_data[\"scwa\"])\n        if scwa_mat.size:\n            epochs = np.arange(1, scwa_mat.shape[1] + 1)\n            scwa_mean = np.nanmean(scwa_mat, axis=0)\n            scwa_sem = np.nanstd(scwa_mat, axis=0) / np.sqrt(scwa_mat.shape[0])\n\n            plt.figure()\n            plt.plot(\n                epochs, scwa_mean, marker=\"o\", color=\"tab:green\", label=\"Val SCWA Mean\"\n            )\n            plt.fill_between(\n                epochs,\n                scwa_mean - scwa_sem,\n                scwa_mean + scwa_sem,\n                alpha=0.3,\n                color=\"tab:green\",\n                label=\"Val SCWA \u00b1SEM\",\n            )\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"SCWA\")\n            plt.ylim(0, 1)\n            plt.title(\n                f\"{dset_name}: Validation SCWA (Mean \u00b1 SEM)\\nAggregated over {scwa_mat.shape[0]} runs\"\n            )\n            plt.legend()\n            save_name = os.path.join(\n                working_dir, f\"{dset_name}_aggregated_val_SCWA_curve.png\"\n            )\n            plt.savefig(save_name)\n            plt.close()\n    except Exception as e:\n        print(f\"Error creating aggregated SCWA curve for {dset_name}: {e}\")\n        plt.close()\n\n    # ----- Print aggregate metrics -----\n    try:\n        if dset_data[\"scwa\"]:\n            final_vals = [arr[-1] for arr in dset_data[\"scwa\"] if len(arr)]\n            best_vals = [np.nanmax(arr) for arr in dset_data[\"scwa\"] if len(arr)]\n            if final_vals:\n                final_mean = np.nanmean(final_vals)\n                final_sem = np.nanstd(final_vals) / np.sqrt(len(final_vals))\n                best_mean = np.nanmean(best_vals)\n                best_sem = np.nanstd(best_vals) / np.sqrt(len(best_vals))\n                print(\n                    f\"{dset_name}: Final Val SCWA = {final_mean:.4f} \u00b1 {final_sem:.4f} | \"\n                    f\"Best Val SCWA = {best_mean:.4f} \u00b1 {best_sem:.4f} (N={len(final_vals)})\"\n                )\n    except Exception as e:\n        print(f\"Error printing aggregate metrics for {dset_name}: {e}\")\n"], "plot_plan": [null, null, "We first load experiment_data.npy and loop over every dataset inside it (only \u201cSPR_BENCH\u201d here). For each dataset we extract training / validation losses, validation SCWA scores, predictions and ground-truth labels. Three independent plots are produced inside their own try-except blocks: (1) a dual-line plot of training vs. validation loss across epochs, (2) a line plot of the validation SCWA metric, and (3) a heat-map style confusion matrix computed directly from the stored predictions/labels. All figures are titled clearly, saved under descriptive names to working_dir, and the figure objects are always properly closed. After plotting we print the final and best observed validation SCWA so the user can see numerical results immediately. No data are fabricated\u2014everything comes straight from experiment_data.npy, and we limit ourselves to at most three figures (well under the five-figure cap). The code begins with the required imports, creates working_dir if missing, and is kept concise while following every plotting guideline.", null, null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null], "hyperparam_name": [null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, true], "parse_metrics_plan": ["", "", "Below is a compact script that immediately loads working/experiment_data.npy,\nfinds the best (lowest) loss and the best (highest) SCWA score recorded for each\nsplit, and prints them with explicit, descriptive names.", "", "Below is a compact script that immediately loads working/experiment_data.npy,\nfinds the best (lowest) loss and the best (highest) SCWA score recorded for each\nsplit, and prints them with explicit, descriptive names.", "Below is a compact script that immediately loads working/experiment_data.npy,\nfinds the best (lowest) loss and the best (highest) SCWA score recorded for each\nsplit, and prints them with explicit, descriptive names.", "Below is a compact script that immediately loads working/experiment_data.npy,\nfinds the best (lowest) loss and the best (highest) SCWA score recorded for each\nsplit, and prints them with explicit, descriptive names.", ""], "parse_metrics_code": ["", "", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate and load the experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# helper to choose \u201cbest\u201d value:  min for losses, max for scores\n# ------------------------------------------------------------------\ndef best_or_none(values, mode=\"min\"):\n    \"\"\"Return best value according to mode, ignoring None entries.\"\"\"\n    clean = [v for v in values if v is not None]\n    if not clean:\n        return None\n    return min(clean) if mode == \"min\" else max(clean)\n\n\n# ------------------------------------------------------------------\n# iterate over every dataset stored in the npy file and print metrics\n# ------------------------------------------------------------------\nfor ds_name, ds_dict in experiment_data.items():\n    print(f\"\\nDataset: {ds_name}\")\n\n    # losses\n    best_train_loss = best_or_none(ds_dict[\"losses\"].get(\"train\", []), mode=\"min\")\n    best_val_loss = best_or_none(ds_dict[\"losses\"].get(\"val\", []), mode=\"min\")\n\n    # SCWA scores\n    best_train_scwa = best_or_none(ds_dict[\"metrics\"].get(\"train_SCWA\", []), mode=\"max\")\n    best_val_scwa = best_or_none(ds_dict[\"metrics\"].get(\"val_SCWA\", []), mode=\"max\")\n\n    # print results only if they exist\n    if best_train_loss is not None:\n        print(f\"best training loss: {best_train_loss:.6f}\")\n    if best_val_loss is not None:\n        print(f\"best validation loss: {best_val_loss:.6f}\")\n    if best_train_scwa is not None:\n        print(f\"best training SCWA score: {best_train_scwa:.6f}\")\n    if best_val_scwa is not None:\n        print(f\"best validation SCWA score: {best_val_scwa:.6f}\")\n", "", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate and load the experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# helper to choose \u201cbest\u201d value:  min for losses, max for scores\n# ------------------------------------------------------------------\ndef best_or_none(values, mode=\"min\"):\n    \"\"\"Return best value according to mode, ignoring None entries.\"\"\"\n    clean = [v for v in values if v is not None]\n    if not clean:\n        return None\n    return min(clean) if mode == \"min\" else max(clean)\n\n\n# ------------------------------------------------------------------\n# iterate over every dataset stored in the npy file and print metrics\n# ------------------------------------------------------------------\nfor ds_name, ds_dict in experiment_data.items():\n    print(f\"\\nDataset: {ds_name}\")\n\n    # losses\n    best_train_loss = best_or_none(ds_dict[\"losses\"].get(\"train\", []), mode=\"min\")\n    best_val_loss = best_or_none(ds_dict[\"losses\"].get(\"val\", []), mode=\"min\")\n\n    # SCWA scores\n    best_train_scwa = best_or_none(ds_dict[\"metrics\"].get(\"train_SCWA\", []), mode=\"max\")\n    best_val_scwa = best_or_none(ds_dict[\"metrics\"].get(\"val_SCWA\", []), mode=\"max\")\n\n    # print results only if they exist\n    if best_train_loss is not None:\n        print(f\"best training loss: {best_train_loss:.6f}\")\n    if best_val_loss is not None:\n        print(f\"best validation loss: {best_val_loss:.6f}\")\n    if best_train_scwa is not None:\n        print(f\"best training SCWA score: {best_train_scwa:.6f}\")\n    if best_val_scwa is not None:\n        print(f\"best validation SCWA score: {best_val_scwa:.6f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate and load the experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# helper to choose \u201cbest\u201d value:  min for losses, max for scores\n# ------------------------------------------------------------------\ndef best_or_none(values, mode=\"min\"):\n    \"\"\"Return best value according to mode, ignoring None entries.\"\"\"\n    clean = [v for v in values if v is not None]\n    if not clean:\n        return None\n    return min(clean) if mode == \"min\" else max(clean)\n\n\n# ------------------------------------------------------------------\n# iterate over every dataset stored in the npy file and print metrics\n# ------------------------------------------------------------------\nfor ds_name, ds_dict in experiment_data.items():\n    print(f\"\\nDataset: {ds_name}\")\n\n    # losses\n    best_train_loss = best_or_none(ds_dict[\"losses\"].get(\"train\", []), mode=\"min\")\n    best_val_loss = best_or_none(ds_dict[\"losses\"].get(\"val\", []), mode=\"min\")\n\n    # SCWA scores\n    best_train_scwa = best_or_none(ds_dict[\"metrics\"].get(\"train_SCWA\", []), mode=\"max\")\n    best_val_scwa = best_or_none(ds_dict[\"metrics\"].get(\"val_SCWA\", []), mode=\"max\")\n\n    # print results only if they exist\n    if best_train_loss is not None:\n        print(f\"best training loss: {best_train_loss:.6f}\")\n    if best_val_loss is not None:\n        print(f\"best validation loss: {best_val_loss:.6f}\")\n    if best_train_scwa is not None:\n        print(f\"best training SCWA score: {best_train_scwa:.6f}\")\n    if best_val_scwa is not None:\n        print(f\"best validation SCWA score: {best_val_scwa:.6f}\")\n", "import os\nimport numpy as np\n\n# ------------------------------------------------------------------\n# locate and load the experiment data\n# ------------------------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------------------------------------------------------\n# helper to choose \u201cbest\u201d value:  min for losses, max for scores\n# ------------------------------------------------------------------\ndef best_or_none(values, mode=\"min\"):\n    \"\"\"Return best value according to mode, ignoring None entries.\"\"\"\n    clean = [v for v in values if v is not None]\n    if not clean:\n        return None\n    return min(clean) if mode == \"min\" else max(clean)\n\n\n# ------------------------------------------------------------------\n# iterate over every dataset stored in the npy file and print metrics\n# ------------------------------------------------------------------\nfor ds_name, ds_dict in experiment_data.items():\n    print(f\"\\nDataset: {ds_name}\")\n\n    # losses\n    best_train_loss = best_or_none(ds_dict[\"losses\"].get(\"train\", []), mode=\"min\")\n    best_val_loss = best_or_none(ds_dict[\"losses\"].get(\"val\", []), mode=\"min\")\n\n    # SCWA scores\n    best_train_scwa = best_or_none(ds_dict[\"metrics\"].get(\"train_SCWA\", []), mode=\"max\")\n    best_val_scwa = best_or_none(ds_dict[\"metrics\"].get(\"val_SCWA\", []), mode=\"max\")\n\n    # print results only if they exist\n    if best_train_loss is not None:\n        print(f\"best training loss: {best_train_loss:.6f}\")\n    if best_val_loss is not None:\n        print(f\"best validation loss: {best_val_loss:.6f}\")\n    if best_train_scwa is not None:\n        print(f\"best training SCWA score: {best_train_scwa:.6f}\")\n    if best_val_scwa is not None:\n        print(f\"best validation SCWA score: {best_val_scwa:.6f}\")\n", ""], "parse_term_out": ["", "", "['\\nDataset: SPR_BENCH', '\\n', 'best training loss: 1.337562', '\\n', 'best\nvalidation loss: 1.389389', '\\n', 'best validation SCWA score: 0.265562', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "", "['\\nDataset: SPR_BENCH', '\\n', 'best training loss: 1.337352', '\\n', 'best\nvalidation loss: 1.401969', '\\n', 'best validation SCWA score: 0.261974', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'best training loss: 1.325046', '\\n', 'best\nvalidation loss: 1.402447', '\\n', 'best validation SCWA score: 0.253103', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'best training loss: 1.337741', '\\n', 'best\nvalidation loss: 1.389449', '\\n', 'best validation SCWA score: 0.241809', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
