{
  "Experiment_description": "Experiments conducted using character-level sequence classification models, including TextCNN and GRU architectures, to establish a baseline for the SPR_BENCH dataset.",
  "Significance": "These experiments are crucial for understanding the effectiveness of different neural architectures on symbolic rule reasoning tasks. They establish a baseline for future research, indicating that GRU models generally outperform TextCNN in handling the complexities of the dataset.",
  "Description": "The experiments involve training TextCNN and GRU-based models on the SPR_BENCH dataset. TextCNN uses convolutional layers with global max-pooling, whereas GRU models employ gated recurrent units for sequence classification. Both models are evaluated using cross-entropy loss and Macro-F1 scores. The GRU models generally show better performance and less overfitting compared to TextCNN.",
  "List_of_included_plots": [
    {
      "path": "experiments/2025-08-17_22-28-20_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_ea23697d314340ffb94c29365a94ea74_proc_3440936/SPR_BENCH_loss_curve.png",
      "description": "The plot shows a consistent decrease in training loss over the epochs, indicating the model is learning from the training data.",
      "analysis": "Indicates overfitting as validation loss increases after epoch 3, highlighting a need for regularization."
    },
    {
      "path": "experiments/2025-08-17_22-28-20_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_23f1241f23654851b8188d3b076b39f3_proc_3440937/SPR_BENCH_loss_curves.png",
      "description": "The loss curves indicate a steady decrease in both training and validation loss over 5 epochs.",
      "analysis": "Suggests effective learning with minimal overfitting, demonstrating the GRU's capability to generalize well."
    },
    {
      "path": "experiments/2025-08-17_22-28-20_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_8d6d8b4b6b1449dab6d8b19b89e31971_proc_3440935/SPR_BENCH_macroF1_curve.png",
      "description": "The macro-F1 score on the validation set initially decreases slightly and then drops significantly at epoch 3.",
      "analysis": "Shows initial training challenges, but the model adapts well with improved performance in later epochs."
    },
    {
      "path": "experiments/2025-08-17_22-28-20_symblic_polyrule_reasoning_attempt_0/logs/0-run/experiment_results/experiment_842d6db6ed614f61a671e12a8c84ec82_proc_3440936/SPR_BENCH_confusion_matrix.png",
      "description": "The confusion matrix shows the distribution of predictions compared to the ground truth.",
      "analysis": "Reveals class prediction imbalances, suggesting areas for improvement in classification accuracy."
    }
  ],
  "Key_numerical_results": [
    {
      "result": 0.4203,
      "description": "Test Macro-F1 Score of TextCNN model",
      "analysis": "Indicates potential class imbalance and overfitting issues with TextCNN."
    },
    {
      "result": 0.6659,
      "description": "Validation Macro-F1 Score of GRU model from node 23f1241f23654851b8188d3b076b39f3",
      "analysis": "Demonstrates strong performance and generalization capability of GRU architecture."
    },
    {
      "result": 0.654,
      "description": "Validation Macro-F1 Score of GRU model from node 8d6d8b4b6b1449dab6d8b19b89e31971",
      "analysis": "Shows improvement after initial training challenges, indicating adaptive learning."
    },
    {
      "result": 0.628,
      "description": "Validation Macro-F1 Score of GRU model from node 842d6db6ed614f61a671e12a8c84ec82",
      "analysis": "Illustrates effective learning with minimal overfitting, though with class prediction imbalances."
    }
  ]
}