<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [], "layout": [[0.0, 0.0], [0.3333333333333333, 0.0], [0.6666666666666666, 0.0], [1.0, 0.0]], "plan": ["Hyperparam tuning name: num_epochs. We will grid-search the maximum number of\ntraining epochs (10, 20, 30, 40, 50).   For every value we train a fresh model\nwith early-stopping (patience = 5 on validation loss), record per-epoch\nmetrics/losses, and keep the model that attains the highest dev accuracy.\nFinally, we evaluate the selected model on the test split and save all relevant\narrays in experiment_data.npy.", "Hyperparam tuning name: learning_rate. Below we grid-search three learning-rates\n(3e-4, 1e-3, 3e-3).   For each value we re-initialise the logistic-regression\nmodel, train for 10 epochs, evaluate on dev after every epoch, compute rule-\nfidelity with the top-k n-grams, and finally test accuracy.   All plottable data\nare stored under experiment_data['learning_rate_search']['SPR_BENCH'] with one\nsub-dictionary per learning-rate and saved to experiment_data.npy.", "Hyperparam tuning name: batch_size. We add an outer loop that trains a fresh\nlogistic-regression model for each candidate batch size (32, 64, 128, 256, 512).\nFor every setting we collect per-epoch train/validation accuracies, losses and\nrule-fidelity, plus final test predictions.   All results are stored in a single\nexperiment_data dictionary under the key \"batch_size_tuning\" and finally saved\nas experiment_data.npy.", "Hyperparam tuning name: weight_decay (L2 regularization coefficient). We loop\nover several weight-decay values (0, 1e-5, 1e-4, 1e-3), re-initialising the\nlogistic-regression model and Adam optimiser each time with the corresponding\nweight_decay. For every setting we train for 10 epochs, record per-epoch\ntrain/validation accuracy, loss, rule-fidelity, and finally evaluate on the test\nsplit. All results are stored inside\nexperiment_data['weight_decay']['SPR_BENCH'][<decay>] and saved to\nexperiment_data.npy."], "code": ["import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List, Dict\nfrom datasets import DatasetDict, load_dataset\n\n# -------------------- I/O --------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# -------------------- DATA -------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# --------------- n-gram vectoriser -----------------\ndef build_vocab(seqs: List[str]):\n    unis, bis = set(), set()\n    for s in seqs:\n        unis.update(list(s))\n        bis.update([s[i : i + 2] for i in range(len(s) - 1)])\n    vocab = sorted(unis) + sorted(bis)\n    return {tok: i for i, tok in enumerate(vocab)}\n\n\ndef vectorise(seq: str, idx: Dict[str, int]) -> np.ndarray:\n    v = np.zeros(len(idx), dtype=np.float32)\n    for c in seq:\n        if c in idx:\n            v[idx[c]] += 1.0\n    for i in range(len(seq) - 1):\n        bg = seq[i : i + 2]\n        if bg in idx:\n            v[idx[bg]] += 1.0\n    return v\n\n\ntrain_seqs = dsets[\"train\"][\"sequence\"]\nvocab_idx = build_vocab(train_seqs)\nnum_feats = len(vocab_idx)\nprint(\"Feature size:\", num_feats)\n\nlabels = sorted(list(set(dsets[\"train\"][\"label\"])))\nlabel2id = {l: i for i, l in enumerate(labels)}\nnum_classes = len(labels)\nprint(\"Classes:\", labels)\n\n\ndef encode_split(split):\n    X = np.stack([vectorise(s, vocab_idx) for s in dsets[split][\"sequence\"]])\n    y = np.array([label2id[l] for l in dsets[split][\"label\"]], dtype=np.int64)\n    return X, y\n\n\nX_train, y_train = encode_split(\"train\")\nX_dev, y_dev = encode_split(\"dev\")\nX_test, y_test = encode_split(\"test\")\n\n\nclass NgramDataset(Dataset):\n    def __init__(self, X, y):\n        self.X, self.y = X, y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\"x\": torch.from_numpy(self.X[idx]), \"y\": torch.tensor(self.y[idx])}\n\n\nbatch_size = 128\ntrain_loader_full = DataLoader(\n    NgramDataset(X_train, y_train), batch_size=batch_size, shuffle=True\n)\ndev_loader = DataLoader(NgramDataset(X_dev, y_dev), batch_size=batch_size)\ntest_loader = DataLoader(NgramDataset(X_test, y_test), batch_size=batch_size)\n\n\n# -------------------- MODEL ------------------------\nclass LogReg(nn.Module):\n    def __init__(self, in_dim, num_classes):\n        super().__init__()\n        self.linear = nn.Linear(in_dim, num_classes, bias=True)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\ncriterion = nn.CrossEntropyLoss()\n\n\n# --------------- EVALUATION FUNC -------------------\n@torch.no_grad()\ndef evaluate(model, loader):\n    model.eval()\n    total = correct = loss_sum = 0.0\n    all_logits = []\n    for batch in loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = model(batch[\"x\"])\n        loss = criterion(logits, batch[\"y\"])\n        loss_sum += loss.item() * batch[\"y\"].size(0)\n        _, preds = torch.max(logits, 1)\n        correct += (preds == batch[\"y\"]).sum().item()\n        total += batch[\"y\"].size(0)\n        all_logits.append(logits.cpu())\n    return correct / total, loss_sum / total, torch.cat(all_logits)\n\n\n# -------------------- SEARCH -----------------------\nepoch_grid = [10, 20, 30, 40, 50]\npatience = 5\ntop_k = 10\n\nbest_overall_acc = -1.0\nbest_run_data = None\nsearch_val_accs = []\n\nfor max_epochs in epoch_grid:\n    print(f\"\\n=== Training with max_epochs={max_epochs} ===\")\n    model = LogReg(num_feats, num_classes).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n    best_val_loss = float(\"inf\")\n    epochs_no_improve = 0\n\n    run_metrics = {\"train_acc\": [], \"val_acc\": [], \"rule_fidelity\": []}\n    run_losses = {\"train\": [], \"val\": []}\n\n    for epoch in range(1, max_epochs + 1):\n        model.train()\n        running_loss = seen = correct = 0.0\n        for batch in train_loader_full:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optimizer.zero_grad()\n            logits = model(batch[\"x\"])\n            loss = criterion(logits, batch[\"y\"])\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * batch[\"y\"].size(0)\n            _, preds = torch.max(logits, 1)\n            correct += (preds == batch[\"y\"]).sum().item()\n            seen += batch[\"y\"].size(0)\n        train_loss = running_loss / seen\n        train_acc = correct / seen\n\n        val_acc, val_loss, _ = evaluate(model, dev_loader)\n\n        # Rule fidelity\n        W = model.linear.weight.detach().cpu().numpy()\n        b = model.linear.bias.detach().cpu().numpy()\n        W_trunc = np.zeros_like(W)\n        for c in range(num_classes):\n            idxs = np.argsort(-np.abs(W[c]))[:top_k]\n            W_trunc[c, idxs] = W[c, idxs]\n        lin_full = torch.from_numpy((X_dev @ W.T) + b)\n        lin_trunc = torch.from_numpy((X_dev @ W_trunc.T) + b)\n        rule_pred = torch.argmax(lin_trunc, 1)\n        model_pred = torch.argmax(lin_full, 1)\n        rule_fid = (rule_pred == model_pred).float().mean().item()\n\n        run_metrics[\"train_acc\"].append(train_acc)\n        run_metrics[\"val_acc\"].append(val_acc)\n        run_metrics[\"rule_fidelity\"].append(rule_fid)\n        run_losses[\"train\"].append(train_loss)\n        run_losses[\"val\"].append(val_loss)\n\n        print(\n            f\"Epoch {epoch:02d}/{max_epochs} \"\n            f\"train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"train_acc={train_acc:.3f} val_acc={val_acc:.3f} \"\n            f\"rule_fid={rule_fid:.3f}\"\n        )\n\n        # ------ Early stopping ------\n        if val_loss < best_val_loss - 1e-4:\n            best_val_loss = val_loss\n            epochs_no_improve = 0\n            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n            best_epoch = epoch\n        else:\n            epochs_no_improve += 1\n        if epochs_no_improve >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n    # reload best state for this run\n    model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n    best_val_acc, _, _ = evaluate(model, dev_loader)\n    search_val_accs.append(best_val_acc)\n\n    print(f\"Run finished. Best epoch={best_epoch}, best val_acc={best_val_acc:.3f}\")\n\n    if best_val_acc > best_overall_acc:\n        best_overall_acc = best_val_acc\n        best_run_data = {\n            \"model_state\": {k: v.clone() for k, v in best_state.items()},\n            \"metrics\": run_metrics,\n            \"losses\": run_losses,\n            \"max_epochs\": max_epochs,\n            \"best_epoch\": best_epoch,\n        }\n\n# ------------------- FINAL TEST --------------------\nprint(\n    f\"\\nSelecting model from max_epochs={best_run_data['max_epochs']} \"\n    f\"epoch={best_run_data['best_epoch']} with val_acc={best_overall_acc:.3f}\"\n)\nbest_model = LogReg(num_feats, num_classes).to(device)\nbest_model.load_state_dict(\n    {k: v.to(device) for k, v in best_run_data[\"model_state\"].items()}\n)\n\ntest_acc, test_loss, test_logits = evaluate(best_model, test_loader)\nprint(f\"Test_acc={test_acc:.3f} test_loss={test_loss:.4f}\")\n\n# --------------- SAVE EXPERIMENT DATA --------------\nexperiment_data = {\n    \"num_epochs\": {\n        \"SPR_BENCH\": {\n            \"search_vals\": np.array(epoch_grid),\n            \"search_val_accs\": np.array(search_val_accs),\n            \"metrics\": best_run_data[\"metrics\"],\n            \"losses\": best_run_data[\"losses\"],\n            \"predictions\": torch.argmax(test_logits, 1).numpy(),\n            \"ground_truth\": y_test,\n        }\n    }\n}\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List, Dict\nfrom datasets import load_dataset, DatasetDict\n\n# ----------------- EXPERIMENT STORE -----------------\nexperiment_data = {\"learning_rate_search\": {\"SPR_BENCH\": {}}}\n\n# ------------------ SETUP ---------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ------------------- DATA ---------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ------------- N-GRAM VECTORIZER --------------------\ndef build_vocab(seqs: List[str]):\n    unis, bis = set(), set()\n    for s in seqs:\n        unis.update(list(s))\n        bis.update([s[i : i + 2] for i in range(len(s) - 1)])\n    vocab = sorted(list(unis)) + sorted(list(bis))\n    return {tok: i for i, tok in enumerate(vocab)}\n\n\ndef vectorise(seq: str, idx: Dict[str, int]) -> np.ndarray:\n    v = np.zeros(len(idx), dtype=np.float32)\n    for c in seq:\n        if c in idx:\n            v[idx[c]] += 1.0\n    for i in range(len(seq) - 1):\n        bg = seq[i : i + 2]\n        if bg in idx:\n            v[idx[bg]] += 1.0\n    return v\n\n\ntrain_seqs = dsets[\"train\"][\"sequence\"]\nvocab_idx = build_vocab(train_seqs)\nnum_feats = len(vocab_idx)\nprint(\"Feature size:\", num_feats)\n\n# ------------- LABEL ENCODING -----------------------\nlabels = sorted(list(set(dsets[\"train\"][\"label\"])))\nlabel2id = {l: i for i, l in enumerate(labels)}\nnum_classes = len(labels)\nprint(\"Classes:\", labels)\n\n\ndef encode_split(split):\n    X = np.stack([vectorise(s, vocab_idx) for s in dsets[split][\"sequence\"]])\n    y = np.array([label2id[l] for l in dsets[split][\"label\"]], dtype=np.int64)\n    return X, y\n\n\nX_train, y_train = encode_split(\"train\")\nX_dev, y_dev = encode_split(\"dev\")\nX_test, y_test = encode_split(\"test\")\n\n\nclass NgramDataset(Dataset):\n    def __init__(self, X, y):\n        self.X, self.y = X, y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\"x\": torch.from_numpy(self.X[idx]), \"y\": torch.tensor(self.y[idx])}\n\n\nbatch_size = 128\ntrain_ds = NgramDataset(X_train, y_train)\ndev_ds = NgramDataset(X_dev, y_dev)\ntest_ds = NgramDataset(X_test, y_test)\ndev_loader = DataLoader(dev_ds, batch_size=batch_size)\ntest_loader = DataLoader(test_ds, batch_size=batch_size)\n\n\n# ------------------ MODEL --------------------------\nclass LogReg(nn.Module):\n    def __init__(self, in_dim, num_classes):\n        super().__init__()\n        self.linear = nn.Linear(in_dim, num_classes, bias=True)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\ncriterion = nn.CrossEntropyLoss()\n\n\n# ---------------- EVALUATION -----------------------\n@torch.no_grad()\ndef evaluate(model, loader):\n    model.eval()\n    total, correct, loss_sum = 0, 0, 0.0\n    all_logits = []\n    for batch in loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        logits = model(batch[\"x\"])\n        loss = criterion(logits, batch[\"y\"])\n        _, preds = torch.max(logits, 1)\n        total += batch[\"y\"].size(0)\n        correct += (preds == batch[\"y\"]).sum().item()\n        loss_sum += loss.item() * batch[\"y\"].size(0)\n        all_logits.append(logits.cpu())\n    return correct / total, loss_sum / total, torch.cat(all_logits)\n\n\n# ------------- TRAINING PER LEARNING RATE ----------\nlrs = [3e-4, 1e-3, 3e-3]\nepochs = 10\ntop_k = 10\n\nfor lr in lrs:\n    print(f\"\\n=== Training with lr={lr} ===\")\n    model = LogReg(num_feats, num_classes).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    # storage for this lr\n    lr_key = f\"lr_{lr:.0e}\"\n    experiment_data[\"learning_rate_search\"][\"SPR_BENCH\"][lr_key] = {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"rule_fidelity\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": y_test.tolist(),\n    }\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss, correct, seen = 0.0, 0, 0\n        for batch in train_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optimizer.zero_grad()\n            logits = model(batch[\"x\"])\n            loss = criterion(logits, batch[\"y\"])\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * batch[\"y\"].size(0)\n            _, preds = torch.max(logits, 1)\n            correct += (preds == batch[\"y\"]).sum().item()\n            seen += batch[\"y\"].size(0)\n\n        train_loss = running_loss / seen\n        train_acc = correct / seen\n        val_acc, val_loss, _ = evaluate(model, dev_loader)\n\n        # ---- Rule fidelity ----\n        W = model.linear.weight.detach().cpu().numpy()\n        b = model.linear.bias.detach().cpu().numpy()\n        W_trunc = np.zeros_like(W)\n        for c in range(num_classes):\n            idxs = np.argsort(-np.abs(W[c]))[:top_k]\n            W_trunc[c, idxs] = W[c, idxs]\n        lin_full = torch.from_numpy((X_dev @ W.T) + b)\n        lin_trunc = torch.from_numpy((X_dev @ W_trunc.T) + b)\n        rule_fid = (\n            (torch.argmax(lin_trunc, 1) == torch.argmax(lin_full, 1))\n            .float()\n            .mean()\n            .item()\n        )\n\n        # store\n        ed = experiment_data[\"learning_rate_search\"][\"SPR_BENCH\"][lr_key]\n        ed[\"metrics\"][\"train_acc\"].append(train_acc)\n        ed[\"metrics\"][\"val_acc\"].append(val_acc)\n        ed[\"metrics\"][\"rule_fidelity\"].append(rule_fid)\n        ed[\"losses\"][\"train\"].append(train_loss)\n        ed[\"losses\"][\"val\"].append(val_loss)\n\n        print(\n            f\"Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"train_acc={train_acc:.3f} val_acc={val_acc:.3f} rule_fid={rule_fid:.3f}\"\n        )\n\n    # ----- final test for this lr -----\n    test_acc, test_loss, test_logits = evaluate(model, test_loader)\n    ed[\"metrics\"][\"test_acc\"] = test_acc\n    ed[\"losses\"][\"test\"] = test_loss\n    ed[\"predictions\"] = torch.argmax(test_logits, 1).numpy().tolist()\n    print(f\"lr={lr}: Test_acc={test_acc:.3f} Test_loss={test_loss:.4f}\")\n\n# ----------------- SAVE ----------------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List, Dict\nfrom datasets import DatasetDict, load_dataset\n\n# ---------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# -------------- DATA LOADING -----------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# ---------------- n-gram vectoriser ---------------\ndef build_vocab(seqs: List[str]):\n    unis, bis = set(), set()\n    for s in seqs:\n        chars = list(s)\n        unis.update(chars)\n        bis.update([s[i : i + 2] for i in range(len(s) - 1)])\n    vocab = sorted(list(unis)) + sorted(list(bis))\n    return {tok: i for i, tok in enumerate(vocab)}\n\n\ndef vectorise(seq: str, idx: Dict[str, int]) -> np.ndarray:\n    v = np.zeros(len(idx), dtype=np.float32)\n    for c in seq:\n        if c in idx:\n            v[idx[c]] += 1.0\n    for i in range(len(seq) - 1):\n        bg = seq[i : i + 2]\n        if bg in idx:\n            v[idx[bg]] += 1.0\n    return v\n\n\nvocab_idx = build_vocab(dsets[\"train\"][\"sequence\"])\nnum_feats = len(vocab_idx)\nprint(f\"Feature size: {num_feats}\")\n\nlabels = sorted(list(set(dsets[\"train\"][\"label\"])))\nlabel2id = {l: i for i, l in enumerate(labels)}\nnum_classes = len(labels)\nprint(f\"Classes: {labels}\")\n\n\ndef encode_split(split):\n    X = np.stack([vectorise(s, vocab_idx) for s in dsets[split][\"sequence\"]])\n    y = np.array([label2id[l] for l in dsets[split][\"label\"]], dtype=np.int64)\n    return X, y\n\n\nX_train, y_train = encode_split(\"train\")\nX_dev, y_dev = encode_split(\"dev\")\nX_test, y_test = encode_split(\"test\")\n\n\nclass NgramDataset(Dataset):\n    def __init__(self, X, y):\n        self.X, self.y = X, y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\"x\": torch.from_numpy(self.X[idx]), \"y\": torch.tensor(self.y[idx])}\n\n\n# -------------------- MODEL ------------------------\nclass LogReg(nn.Module):\n    def __init__(self, in_dim, num_classes):\n        super().__init__()\n        self.linear = nn.Linear(in_dim, num_classes, bias=True)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# -------------- EXPERIMENT STORE -------------------\nexperiment_data = {\n    \"batch_size_tuning\": {\n        \"SPR_BENCH\": {\n            \"batch_sizes\": [],\n            \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"rule_fidelity\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": y_test,\n        }\n    }\n}\n\n# -------------- TRAIN / EVAL FUNCS -----------------\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    total, correct, loss_sum = 0, 0, 0.0\n    all_logits = []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            logits = model(batch[\"x\"])\n            loss = criterion(logits, batch[\"y\"])\n            preds = logits.argmax(1)\n            total += batch[\"y\"].size(0)\n            correct += (preds == batch[\"y\"]).sum().item()\n            loss_sum += loss.item() * batch[\"y\"].size(0)\n            all_logits.append(logits.cpu())\n    return correct / total, loss_sum / total, torch.cat(all_logits)\n\n\ndef run_one_experiment(batch_size, epochs=10, top_k=10, lr=1e-3):\n    train_loader = DataLoader(\n        NgramDataset(X_train, y_train), batch_size=batch_size, shuffle=True\n    )\n    dev_loader = DataLoader(NgramDataset(X_dev, y_dev), batch_size=batch_size)\n    model = LogReg(num_feats, num_classes).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    for ep in range(1, epochs + 1):\n        model.train()\n        total, correct, loss_sum = 0, 0, 0.0\n        for batch in train_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optimizer.zero_grad()\n            logits = model(batch[\"x\"])\n            loss = criterion(logits, batch[\"y\"])\n            loss.backward()\n            optimizer.step()\n            preds = logits.argmax(1)\n            total += batch[\"y\"].size(0)\n            correct += (preds == batch[\"y\"]).sum().item()\n            loss_sum += loss.item() * batch[\"y\"].size(0)\n        train_acc, train_loss = correct / total, loss_sum / total\n        val_acc, val_loss, _ = evaluate(model, dev_loader)\n        # Rule fidelity\n        W = model.linear.weight.detach().cpu().numpy()\n        b = model.linear.bias.detach().cpu().numpy()\n        W_trunc = np.zeros_like(W)\n        for c in range(num_classes):\n            idxs = np.argsort(-np.abs(W[c]))[:top_k]\n            W_trunc[c, idxs] = W[c, idxs]\n        lin_full = torch.from_numpy((X_dev @ W.T) + b)\n        lin_trunc = torch.from_numpy((X_dev @ W_trunc.T) + b)\n        rule_fid = (lin_full.argmax(1) == lin_trunc.argmax(1)).float().mean().item()\n        # store epoch metrics\n        experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"][\"metrics\"][\n            \"train_acc\"\n        ].append(train_acc)\n        experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"][\"metrics\"][\"val_acc\"].append(\n            val_acc\n        )\n        experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"][\"metrics\"][\n            \"rule_fidelity\"\n        ].append(rule_fid)\n        experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"][\"losses\"][\"train\"].append(\n            train_loss\n        )\n        experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"][\"losses\"][\"val\"].append(\n            val_loss\n        )\n        print(\n            f\"[bs={batch_size}] Epoch {ep}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"train_acc={train_acc:.3f} val_acc={val_acc:.3f} rule_fid={rule_fid:.3f}\"\n        )\n    # final test evaluation\n    test_loader = DataLoader(NgramDataset(X_test, y_test), batch_size=batch_size)\n    test_acc, test_loss, test_logits = evaluate(model, test_loader)\n    print(f\"[bs={batch_size}] Test_acc={test_acc:.3f} test_loss={test_loss:.4f}\")\n    experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"][\"predictions\"].append(\n        test_logits.argmax(1).numpy()\n    )\n    experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"][\"batch_sizes\"].append(batch_size)\n\n\n# -------------- HYPERPARAM SWEEP -------------------\nfor bs in [32, 64, 128, 256, 512]:\n    run_one_experiment(bs)\n\n# ---------------- SAVE RESULTS ---------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os, pathlib, numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List, Dict\nfrom datasets import load_dataset, DatasetDict\n\n# ----------------- EXPERIMENT STORE -----------------\nexperiment_data = {\n    \"weight_decay\": {\"SPR_BENCH\": {}}  # will hold a dict per decay value\n}\n\n# ----------------- DEVICE & WORKDIR -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# ---------------------- DATA ------------------------\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",\n            cache_dir=\".cache_dsets\",\n        )\n\n    return DatasetDict(\n        {\n            \"train\": _load(\"train.csv\"),\n            \"dev\": _load(\"dev.csv\"),\n            \"test\": _load(\"test.csv\"),\n        }\n    )\n\n\nDATA_PATH = pathlib.Path(\"/home/zxl240011/AI-Scientist-v2/SPR_BENCH/\")\ndsets = load_spr_bench(DATA_PATH)\nprint({k: len(v) for k, v in dsets.items()})\n\n\n# --------------- N-GRAM VECTORIZER ------------------\ndef build_vocab(seqs: List[str]):\n    unis, bis = set(), set()\n    for s in seqs:\n        chars = list(s)\n        unis.update(chars)\n        bis.update([s[i : i + 2] for i in range(len(s) - 1)])\n    vocab = sorted(list(unis)) + sorted(list(bis))\n    return {tok: i for i, tok in enumerate(vocab)}\n\n\ndef vectorise(seq: str, idx: Dict[str, int]) -> np.ndarray:\n    v = np.zeros(len(idx), dtype=np.float32)\n    for c in seq:\n        if c in idx:\n            v[idx[c]] += 1.0\n    for i in range(len(seq) - 1):\n        bg = seq[i : i + 2]\n        if bg in idx:\n            v[idx[bg]] += 1.0\n    return v\n\n\nvocab_idx = build_vocab(dsets[\"train\"][\"sequence\"])\nnum_feats = len(vocab_idx)\nprint(f\"Feature size: {num_feats}\")\n\nlabels = sorted(set(dsets[\"train\"][\"label\"]))\nlabel2id = {l: i for i, l in enumerate(labels)}\nnum_classes = len(labels)\nprint(f\"Classes: {labels}\")\n\n\ndef encode_split(split):\n    X = np.stack([vectorise(s, vocab_idx) for s in dsets[split][\"sequence\"]])\n    y = np.array([label2id[l] for l in dsets[split][\"label\"]], dtype=np.int64)\n    return X, y\n\n\nX_train, y_train = encode_split(\"train\")\nX_dev, y_dev = encode_split(\"dev\")\nX_test, y_test = encode_split(\"test\")\n\n\nclass NgramDataset(Dataset):\n    def __init__(self, X, y):\n        self.X, self.y = X, y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\"x\": torch.from_numpy(self.X[idx]), \"y\": torch.tensor(self.y[idx])}\n\n\nbatch_size = 128\ntrain_loader = DataLoader(\n    NgramDataset(X_train, y_train), batch_size=batch_size, shuffle=True\n)\ndev_loader = DataLoader(NgramDataset(X_dev, y_dev), batch_size=batch_size)\ntest_loader = DataLoader(NgramDataset(X_test, y_test), batch_size=batch_size)\n\n\n# -------------------- MODEL ------------------------\nclass LogReg(nn.Module):\n    def __init__(self, in_dim, num_classes):\n        super().__init__()\n        self.linear = nn.Linear(in_dim, num_classes, bias=True)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\ncriterion = nn.CrossEntropyLoss()\n\n\ndef evaluate(model, loader):\n    model.eval()\n    total, correct, loss_sum = 0, 0, 0.0\n    all_logits = []\n    with torch.no_grad():\n        for batch in loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            logits = model(batch[\"x\"])\n            loss = criterion(logits, batch[\"y\"])\n            _, preds = torch.max(logits, 1)\n            total += batch[\"y\"].size(0)\n            correct += (preds == batch[\"y\"]).sum().item()\n            loss_sum += loss.item() * batch[\"y\"].size(0)\n            all_logits.append(logits.cpu())\n    return correct / total, loss_sum / total, torch.cat(all_logits)\n\n\n# ----------------- HYPERPARAM SEARCH ---------------\ndecay_values = [0.0, 1e-5, 1e-4, 1e-3]\nepochs, top_k = 10, 10\n\nfor wd in decay_values:\n    print(f\"\\n=== Training with weight_decay={wd} ===\")\n    model = LogReg(num_feats, num_classes).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=wd)\n    # containers for this run\n    run_store = {\n        \"metrics\": {\"train_acc\": [], \"val_acc\": [], \"rule_fidelity\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": y_test,\n        \"test_acc\": None,\n        \"test_loss\": None,\n    }\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss, correct, seen = 0.0, 0, 0\n        for batch in train_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optimizer.zero_grad()\n            logits = model(batch[\"x\"])\n            loss = criterion(logits, batch[\"y\"])\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * batch[\"y\"].size(0)\n            _, preds = torch.max(logits, 1)\n            correct += (preds == batch[\"y\"]).sum().item()\n            seen += batch[\"y\"].size(0)\n        train_loss = running_loss / seen\n        train_acc = correct / seen\n\n        val_acc, val_loss, val_logits = evaluate(model, dev_loader)\n\n        # ------- Rule Fidelity -------\n        W = model.linear.weight.detach().cpu().numpy()\n        b = model.linear.bias.detach().cpu().numpy()\n        W_trunc = np.zeros_like(W)\n        for c in range(num_classes):\n            idxs = np.argsort(-np.abs(W[c]))[:top_k]\n            W_trunc[c, idxs] = W[c, idxs]\n        lin_full = torch.from_numpy((X_dev @ W.T) + b)\n        lin_trunc = torch.from_numpy((X_dev @ W_trunc.T) + b)\n        rule_pred = torch.argmax(lin_trunc, 1)\n        model_pred = torch.argmax(lin_full, 1)\n        rule_fid = (rule_pred == model_pred).float().mean().item()\n\n        run_store[\"metrics\"][\"train_acc\"].append(train_acc)\n        run_store[\"metrics\"][\"val_acc\"].append(val_acc)\n        run_store[\"metrics\"][\"rule_fidelity\"].append(rule_fid)\n        run_store[\"losses\"][\"train\"].append(train_loss)\n        run_store[\"losses\"][\"val\"].append(val_loss)\n\n        print(\n            f\"Epoch {epoch}: train_acc={train_acc:.3f} val_acc={val_acc:.3f} rule_fid={rule_fid:.3f}\"\n        )\n\n    # ---------- Final Test ----------\n    test_acc, test_loss, test_logits = evaluate(model, test_loader)\n    run_store[\"predictions\"] = torch.argmax(test_logits, 1).numpy()\n    run_store[\"test_acc\"] = test_acc\n    run_store[\"test_loss\"] = test_loss\n    print(f\"Test_acc={test_acc:.3f} test_loss={test_loss:.4f}\")\n\n    experiment_data[\"weight_decay\"][\"SPR_BENCH\"][str(wd)] = run_store\n\n# ----------------- SAVE RESULTS --------------------\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment data to\", os.path.join(working_dir, \"experiment_data.npy\"))\n"], "term_out": ["['Using device:', ' ', 'cuda', '\\n', '\\rGenerating train split: 0 examples\n[00:00, ? examples/s]', '', '\\rGenerating train split: 2000 examples [00:00,\n64967.53 examples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 500 examples [00:00, 91275.77\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 174239.95\nexamples/s]', '\\n', \"{'train': 2000, 'dev': 500, 'test': 1000}\", '\\n', 'Feature\nsize:', ' ', '33', '\\n', 'Classes:', ' ', '[0, 1]', '\\n', '\\n=== Training with\nmax_epochs=10 ===', '\\n', 'Epoch 01/10 train_loss=1.4462 val_loss=0.8908\ntrain_acc=0.549 val_acc=0.588 rule_fid=0.566', '\\n', 'Epoch 02/10\ntrain_loss=0.7264 val_loss=0.8662 train_acc=0.658 val_acc=0.622 rule_fid=0.698',\n'\\n', 'Epoch 03/10 train_loss=0.5713 val_loss=0.7895 train_acc=0.721\nval_acc=0.646 rule_fid=0.594', '\\n', 'Epoch 04/10 train_loss=0.4738\nval_loss=0.7602 train_acc=0.776 val_acc=0.684 rule_fid=0.648', '\\n', 'Epoch\n05/10 train_loss=0.3999 val_loss=0.7416 train_acc=0.821 val_acc=0.696\nrule_fid=0.606', '\\n', 'Epoch 06/10 train_loss=0.3394 val_loss=0.7318\ntrain_acc=0.856 val_acc=0.726 rule_fid=0.656', '\\n', 'Epoch 07/10\ntrain_loss=0.2947 val_loss=0.7316 train_acc=0.883 val_acc=0.746 rule_fid=0.620',\n'\\n', 'Epoch 08/10 train_loss=0.2585 val_loss=0.7345 train_acc=0.911\nval_acc=0.756 rule_fid=0.624', '\\n', 'Epoch 09/10 train_loss=0.2309\nval_loss=0.7401 train_acc=0.930 val_acc=0.762 rule_fid=0.636', '\\n', 'Epoch\n10/10 train_loss=0.2080 val_loss=0.7525 train_acc=0.939 val_acc=0.762\nrule_fid=0.652', '\\n', 'Run finished. Best epoch=7, best val_acc=0.746', '\\n',\n'\\n=== Training with max_epochs=20 ===', '\\n', 'Epoch 01/20 train_loss=1.1909\nval_loss=1.1412 train_acc=0.562 val_acc=0.524 rule_fid=0.632', '\\n', 'Epoch\n02/20 train_loss=0.9015 val_loss=1.0329 train_acc=0.601 val_acc=0.562\nrule_fid=0.442', '\\n', 'Epoch 03/20 train_loss=0.7344 val_loss=0.9379\ntrain_acc=0.668 val_acc=0.592 rule_fid=0.492', '\\n', 'Epoch 04/20\ntrain_loss=0.6007 val_loss=0.8745 train_acc=0.720 val_acc=0.632 rule_fid=0.464',\n'\\n', 'Epoch 05/20 train_loss=0.4908 val_loss=0.8232 train_acc=0.772\nval_acc=0.652 rule_fid=0.472', '\\n', 'Epoch 06/20 train_loss=0.4037\nval_loss=0.7873 train_acc=0.823 val_acc=0.676 rule_fid=0.488', '\\n', 'Epoch\n07/20 train_loss=0.3353 val_loss=0.7717 train_acc=0.854 val_acc=0.698\nrule_fid=0.450', '\\n', 'Epoch 08/20 train_loss=0.2834 val_loss=0.7553\ntrain_acc=0.893 val_acc=0.730 rule_fid=0.474', '\\n', 'Epoch 09/20\ntrain_loss=0.2439 val_loss=0.7527 train_acc=0.917 val_acc=0.746 rule_fid=0.462',\n'\\n', 'Epoch 10/20 train_loss=0.2143 val_loss=0.7528 train_acc=0.932\nval_acc=0.764 rule_fid=0.468', '\\n', 'Epoch 11/20 train_loss=0.1911\nval_loss=0.7583 train_acc=0.948 val_acc=0.768 rule_fid=0.468', '\\n', 'Epoch\n12/20 train_loss=0.1735 val_loss=0.7640 train_acc=0.952 val_acc=0.772\nrule_fid=0.482', '\\n', 'Epoch 13/20 train_loss=0.1600 val_loss=0.7714\ntrain_acc=0.959 val_acc=0.776 rule_fid=0.650', '\\n', 'Epoch 14/20\ntrain_loss=0.1491 val_loss=0.7823 train_acc=0.962 val_acc=0.774 rule_fid=0.670',\n'\\n', 'Early stopping triggered.', '\\n', 'Run finished. Best epoch=9, best\nval_acc=0.746', '\\n', '\\n=== Training with max_epochs=30 ===', '\\n', 'Epoch\n01/30 train_loss=6.4435 val_loss=4.5597 train_acc=0.500 val_acc=0.520\nrule_fid=1.000', '\\n', 'Epoch 02/30 train_loss=3.4144 val_loss=1.7643\ntrain_acc=0.499 val_acc=0.516 rule_fid=0.034', '\\n', 'Epoch 03/30\ntrain_loss=1.2137 val_loss=0.9930 train_acc=0.496 val_acc=0.496 rule_fid=0.724',\n'\\n', 'Epoch 04/30 train_loss=0.9133 val_loss=0.8442 train_acc=0.558\nval_acc=0.556 rule_fid=0.646', '\\n', 'Epoch 05/30 train_loss=0.7004\nval_loss=0.7521 train_acc=0.636 val_acc=0.602 rule_fid=0.488', '\\n', 'Epoch\n06/30 train_loss=0.5867 val_loss=0.7124 train_acc=0.692 val_acc=0.638\nrule_fid=0.552', '\\n', 'Epoch 07/30 train_loss=0.4935 val_loss=0.6889\ntrain_acc=0.753 val_acc=0.670 rule_fid=0.556', '\\n', 'Epoch 08/30\ntrain_loss=0.4245 val_loss=0.6753 train_acc=0.795 val_acc=0.696 rule_fid=0.544',\n'\\n', 'Epoch 09/30 train_loss=0.3700 val_loss=0.6711 train_acc=0.831\nval_acc=0.700 rule_fid=0.562', '\\n', 'Epoch 10/30 train_loss=0.3271\nval_loss=0.6727 train_acc=0.869 val_acc=0.712 rule_fid=0.638', '\\n', 'Epoch\n11/30 train_loss=0.2930 val_loss=0.6768 train_acc=0.891 val_acc=0.730\nrule_fid=0.664', '\\n', 'Epoch 12/30 train_loss=0.2651 val_loss=0.6842\ntrain_acc=0.908 val_acc=0.740 rule_fid=0.670', '\\n', 'Epoch 13/30\ntrain_loss=0.2422 val_loss=0.6921 train_acc=0.921 val_acc=0.746 rule_fid=0.680',\n'\\n', 'Epoch 14/30 train_loss=0.2232 val_loss=0.7034 train_acc=0.932\nval_acc=0.752 rule_fid=0.696', '\\n', 'Early stopping triggered.', '\\n', 'Run\nfinished. Best epoch=9, best val_acc=0.700', '\\n', '\\n=== Training with\nmax_epochs=40 ===', '\\n', 'Epoch 01/40 train_loss=0.7626 val_loss=0.7465\ntrain_acc=0.612 val_acc=0.562 rule_fid=0.364', '\\n', 'Epoch 02/40\ntrain_loss=0.5653 val_loss=0.6861 train_acc=0.694 val_acc=0.622 rule_fid=0.638',\n'\\n', 'Epoch 03/40 train_loss=0.4533 val_loss=0.6396 train_acc=0.791\nval_acc=0.690 rule_fid=0.618', '\\n', 'Epoch 04/40 train_loss=0.3732\nval_loss=0.6200 train_acc=0.855 val_acc=0.732 rule_fid=0.674', '\\n', 'Epoch\n05/40 train_loss=0.3141 val_loss=0.6196 train_acc=0.898 val_acc=0.750\nrule_fid=0.840', '\\n', 'Epoch 06/40 train_loss=0.2727 val_loss=0.6237\ntrain_acc=0.926 val_acc=0.750 rule_fid=0.862', '\\n', 'Epoch 07/40\ntrain_loss=0.2407 val_loss=0.6283 train_acc=0.935 val_acc=0.764 rule_fid=0.818',\n'\\n', 'Epoch 08/40 train_loss=0.2159 val_loss=0.6431 train_acc=0.951\nval_acc=0.762 rule_fid=0.890', '\\n', 'Epoch 09/40 train_loss=0.1977\nval_loss=0.6543 train_acc=0.954 val_acc=0.762 rule_fid=0.608', '\\n', 'Epoch\n10/40 train_loss=0.1830 val_loss=0.6713 train_acc=0.964 val_acc=0.758\nrule_fid=0.806', '\\n', 'Early stopping triggered.', '\\n', 'Run finished. Best\nepoch=5, best val_acc=0.750', '\\n', '\\n=== Training with max_epochs=50 ===',\n'\\n', 'Epoch 01/50 train_loss=2.9416 val_loss=1.4256 train_acc=0.495\nval_acc=0.448 rule_fid=0.762', '\\n', 'Epoch 02/50 train_loss=1.2922\nval_loss=1.1047 train_acc=0.359 val_acc=0.448 rule_fid=0.784', '\\n', 'Epoch\n03/50 train_loss=1.1071 val_loss=0.9257 train_acc=0.401 val_acc=0.484\nrule_fid=0.400', '\\n', 'Epoch 04/50 train_loss=0.9182 val_loss=0.8246\ntrain_acc=0.455 val_acc=0.520 rule_fid=0.460', '\\n', 'Epoch 05/50\ntrain_loss=0.7724 val_loss=0.7486 train_acc=0.539 val_acc=0.572 rule_fid=0.516',\n'\\n', 'Epoch 06/50 train_loss=0.6530 val_loss=0.6948 train_acc=0.623\nval_acc=0.626 rule_fid=0.482', '\\n', 'Epoch 07/50 train_loss=0.5564\nval_loss=0.6566 train_acc=0.705 val_acc=0.666 rule_fid=0.490', '\\n', 'Epoch\n08/50 train_loss=0.4791 val_loss=0.6314 train_acc=0.781 val_acc=0.688\nrule_fid=0.484', '\\n', 'Epoch 09/50 train_loss=0.4186 val_loss=0.6175\ntrain_acc=0.831 val_acc=0.714 rule_fid=0.466', '\\n', 'Epoch 10/50\ntrain_loss=0.3712 val_loss=0.6108 train_acc=0.866 val_acc=0.724 rule_fid=0.444',\n'\\n', 'Epoch 11/50 train_loss=0.3328 val_loss=0.6077 train_acc=0.895\nval_acc=0.728 rule_fid=0.516', '\\n', 'Epoch 12/50 train_loss=0.3024\nval_loss=0.6105 train_acc=0.917 val_acc=0.734 rule_fid=0.526', '\\n', 'Epoch\n13/50 train_loss=0.2777 val_loss=0.6133 train_acc=0.931 val_acc=0.740\nrule_fid=0.544', '\\n', 'Epoch 14/50 train_loss=0.2570 val_loss=0.6174\ntrain_acc=0.943 val_acc=0.748 rule_fid=0.548', '\\n', 'Epoch 15/50\ntrain_loss=0.2410 val_loss=0.6257 train_acc=0.946 val_acc=0.750 rule_fid=0.804',\n'\\n', 'Epoch 16/50 train_loss=0.2261 val_loss=0.6338 train_acc=0.956\nval_acc=0.752 rule_fid=0.814', '\\n', 'Early stopping triggered.', '\\n', 'Run\nfinished. Best epoch=11, best val_acc=0.728', '\\n', '\\nSelecting model from\nmax_epochs=40 epoch=5 with val_acc=0.750', '\\n', 'Test_acc=0.767\ntest_loss=0.5893', '\\n', 'Saved experiment_data.npy', '\\n', 'Execution time: 5\nseconds seconds (time limit is 30 minutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 2000 examples [00:00, 70020.60\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 500 examples [00:00, 67400.03\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 156026.49\nexamples/s]', '\\n', \"{'train': 2000, 'dev': 500, 'test': 1000}\", '\\n', 'Feature\nsize:', ' ', '33', '\\n', 'Classes:', ' ', '[0, 1]', '\\n', '\\n=== Training with\nlr=0.0003 ===', '\\n', 'Epoch 1: train_loss=2.1298 val_loss=1.7832\ntrain_acc=0.503 val_acc=0.518 rule_fid=0.404', '\\n', 'Epoch 2: train_loss=1.3841\nval_loss=1.1866 train_acc=0.531 val_acc=0.538 rule_fid=0.264', '\\n', 'Epoch 3:\ntrain_loss=0.9109 val_loss=0.9272 train_acc=0.588 val_acc=0.542 rule_fid=0.448',\n'\\n', 'Epoch 4: train_loss=0.7339 val_loss=0.8698 train_acc=0.637 val_acc=0.596\nrule_fid=0.538', '\\n', 'Epoch 5: train_loss=0.6738 val_loss=0.8491\ntrain_acc=0.666 val_acc=0.614 rule_fid=0.606', '\\n', 'Epoch 6: train_loss=0.6283\nval_loss=0.8301 train_acc=0.690 val_acc=0.622 rule_fid=0.608', '\\n', 'Epoch 7:\ntrain_loss=0.5872 val_loss=0.8128 train_acc=0.709 val_acc=0.636 rule_fid=0.616',\n'\\n', 'Epoch 8: train_loss=0.5503 val_loss=0.7994 train_acc=0.732 val_acc=0.646\nrule_fid=0.624', '\\n', 'Epoch 9: train_loss=0.5173 val_loss=0.7873\ntrain_acc=0.750 val_acc=0.656 rule_fid=0.632', '\\n', 'Epoch 10:\ntrain_loss=0.4872 val_loss=0.7777 train_acc=0.764 val_acc=0.666 rule_fid=0.648',\n'\\n', 'lr=0.0003: Test_acc=0.637 Test_loss=0.7832', '\\n', '\\n=== Training with\nlr=0.001 ===', '\\n', 'Epoch 1: train_loss=1.1909 val_loss=1.1412 train_acc=0.562\nval_acc=0.524 rule_fid=0.632', '\\n', 'Epoch 2: train_loss=0.9015 val_loss=1.0329\ntrain_acc=0.601 val_acc=0.562 rule_fid=0.442', '\\n', 'Epoch 3: train_loss=0.7344\nval_loss=0.9379 train_acc=0.668 val_acc=0.592 rule_fid=0.492', '\\n', 'Epoch 4:\ntrain_loss=0.6007 val_loss=0.8745 train_acc=0.720 val_acc=0.632 rule_fid=0.464',\n'\\n', 'Epoch 5: train_loss=0.4908 val_loss=0.8232 train_acc=0.772 val_acc=0.652\nrule_fid=0.472', '\\n', 'Epoch 6: train_loss=0.4037 val_loss=0.7873\ntrain_acc=0.823 val_acc=0.676 rule_fid=0.488', '\\n', 'Epoch 7: train_loss=0.3353\nval_loss=0.7717 train_acc=0.854 val_acc=0.698 rule_fid=0.450', '\\n', 'Epoch 8:\ntrain_loss=0.2834 val_loss=0.7553 train_acc=0.893 val_acc=0.730 rule_fid=0.474',\n'\\n', 'Epoch 9: train_loss=0.2439 val_loss=0.7527 train_acc=0.917 val_acc=0.746\nrule_fid=0.462', '\\n', 'Epoch 10: train_loss=0.2143 val_loss=0.7528\ntrain_acc=0.932 val_acc=0.764 rule_fid=0.468', '\\n', 'lr=0.001: Test_acc=0.771\nTest_loss=0.7032', '\\n', '\\n=== Training with lr=0.003 ===', '\\n', 'Epoch 1:\ntrain_loss=4.6969 val_loss=1.0745 train_acc=0.471 val_acc=0.432 rule_fid=0.716',\n'\\n', 'Epoch 2: train_loss=1.3349 val_loss=0.7920 train_acc=0.483 val_acc=0.586\nrule_fid=0.322', '\\n', 'Epoch 3: train_loss=0.6968 val_loss=0.6976\ntrain_acc=0.635 val_acc=0.646 rule_fid=0.768', '\\n', 'Epoch 4: train_loss=0.4314\nval_loss=0.6353 train_acc=0.806 val_acc=0.736 rule_fid=0.706', '\\n', 'Epoch 5:\ntrain_loss=0.3075 val_loss=0.6470 train_acc=0.890 val_acc=0.754 rule_fid=0.846',\n'\\n', 'Epoch 6: train_loss=0.2436 val_loss=0.6743 train_acc=0.931 val_acc=0.758\nrule_fid=0.934', '\\n', 'Epoch 7: train_loss=0.2050 val_loss=0.6964\ntrain_acc=0.947 val_acc=0.764 rule_fid=0.944', '\\n', 'Epoch 8: train_loss=0.1786\nval_loss=0.7250 train_acc=0.958 val_acc=0.762 rule_fid=0.958', '\\n', 'Epoch 9:\ntrain_loss=0.1606 val_loss=0.7481 train_acc=0.968 val_acc=0.770 rule_fid=0.968',\n'\\n', 'Epoch 10: train_loss=0.1475 val_loss=0.7746 train_acc=0.972 val_acc=0.774\nrule_fid=0.960', '\\n', 'lr=0.003: Test_acc=0.776 Test_loss=0.7275', '\\n', 'Saved\nexperiment_data.npy', '\\n', 'Execution time: 4 seconds seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 2000 examples [00:00, 56452.45\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 500 examples [00:00, 137302.08\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 239141.57\nexamples/s]', '\\n', \"{'train': 2000, 'dev': 500, 'test': 1000}\", '\\n', 'Feature\nsize: 33', '\\n', 'Classes: [0, 1]', '\\n', '[bs=32] Epoch 1: train_loss=0.8179\nval_loss=0.7654 train_acc=0.672 val_acc=0.672 rule_fid=0.620', '\\n', '[bs=32]\nEpoch 2: train_loss=0.3520 val_loss=0.7274 train_acc=0.849 val_acc=0.750\nrule_fid=0.608', '\\n', '[bs=32] Epoch 3: train_loss=0.2215 val_loss=0.7551\ntrain_acc=0.932 val_acc=0.768 rule_fid=0.644', '\\n', '[bs=32] Epoch 4:\ntrain_loss=0.1653 val_loss=0.8064 train_acc=0.957 val_acc=0.766 rule_fid=0.744',\n'\\n', '[bs=32] Epoch 5: train_loss=0.1379 val_loss=0.8439 train_acc=0.964\nval_acc=0.770 rule_fid=0.996', '\\n', '[bs=32] Epoch 6: train_loss=0.1183\nval_loss=0.8868 train_acc=0.970 val_acc=0.772 rule_fid=0.946', '\\n', '[bs=32]\nEpoch 7: train_loss=0.1063 val_loss=0.9243 train_acc=0.975 val_acc=0.778\nrule_fid=0.974', '\\n', '[bs=32] Epoch 8: train_loss=0.0976 val_loss=0.9680\ntrain_acc=0.975 val_acc=0.776 rule_fid=0.954', '\\n', '[bs=32] Epoch 9:\ntrain_loss=0.0912 val_loss=1.0051 train_acc=0.978 val_acc=0.778 rule_fid=0.974',\n'\\n', '[bs=32] Epoch 10: train_loss=0.0853 val_loss=1.0527 train_acc=0.979\nval_acc=0.776 rule_fid=0.978', '\\n', '[bs=32] Test_acc=0.780 test_loss=0.9879',\n'\\n', '[bs=64] Epoch 1: train_loss=1.0587 val_loss=1.0451 train_acc=0.595\nval_acc=0.564 rule_fid=0.416', '\\n', '[bs=64] Epoch 2: train_loss=0.6807\nval_loss=0.8821 train_acc=0.694 val_acc=0.628 rule_fid=0.512', '\\n', '[bs=64]\nEpoch 3: train_loss=0.4654 val_loss=0.7992 train_acc=0.781 val_acc=0.674\nrule_fid=0.474', '\\n', '[bs=64] Epoch 4: train_loss=0.3252 val_loss=0.7654\ntrain_acc=0.867 val_acc=0.712 rule_fid=0.464', '\\n', '[bs=64] Epoch 5:\ntrain_loss=0.2422 val_loss=0.7611 train_acc=0.916 val_acc=0.746 rule_fid=0.466',\n'\\n', '[bs=64] Epoch 6: train_loss=0.1922 val_loss=0.7652 train_acc=0.946\nval_acc=0.772 rule_fid=0.472', '\\n', '[bs=64] Epoch 7: train_loss=0.1619\nval_loss=0.7834 train_acc=0.958 val_acc=0.774 rule_fid=0.648', '\\n', '[bs=64]\nEpoch 8: train_loss=0.1437 val_loss=0.7993 train_acc=0.964 val_acc=0.780\nrule_fid=0.940', '\\n', '[bs=64] Epoch 9: train_loss=0.1290 val_loss=0.8253\ntrain_acc=0.971 val_acc=0.776 rule_fid=0.934', '\\n', '[bs=64] Epoch 10:\ntrain_loss=0.1189 val_loss=0.8404 train_acc=0.972 val_acc=0.776 rule_fid=0.866',\n'\\n', '[bs=64] Test_acc=0.780 test_loss=0.7836', '\\n', '[bs=128] Epoch 1:\ntrain_loss=7.3191 val_loss=5.3004 train_acc=0.500 val_acc=0.520 rule_fid=0.970',\n'\\n', '[bs=128] Epoch 2: train_loss=4.2949 val_loss=2.4424 train_acc=0.500\nval_acc=0.518 rule_fid=0.472', '\\n', '[bs=128] Epoch 3: train_loss=1.7210\nval_loss=0.9859 train_acc=0.427 val_acc=0.448 rule_fid=0.572', '\\n', '[bs=128]\nEpoch 4: train_loss=1.0962 val_loss=0.8745 train_acc=0.424 val_acc=0.504\nrule_fid=0.640', '\\n', '[bs=128] Epoch 5: train_loss=0.8345 val_loss=0.7567\ntrain_acc=0.523 val_acc=0.594 rule_fid=0.410', '\\n', '[bs=128] Epoch 6:\ntrain_loss=0.6830 val_loss=0.6960 train_acc=0.616 val_acc=0.630 rule_fid=0.494',\n'\\n', '[bs=128] Epoch 7: train_loss=0.5671 val_loss=0.6626 train_acc=0.703\nval_acc=0.670 rule_fid=0.522', '\\n', '[bs=128] Epoch 8: train_loss=0.4814\nval_loss=0.6437 train_acc=0.763 val_acc=0.706 rule_fid=0.596', '\\n', '[bs=128]\nEpoch 9: train_loss=0.4174 val_loss=0.6348 train_acc=0.816 val_acc=0.724\nrule_fid=0.714', '\\n', '[bs=128] Epoch 10: train_loss=0.3673 val_loss=0.6333\ntrain_acc=0.854 val_acc=0.736 rule_fid=0.748', '\\n', '[bs=128] Test_acc=0.724\ntest_loss=0.6158', '\\n', '[bs=256] Epoch 1: train_loss=1.3827 val_loss=0.9547\ntrain_acc=0.524 val_acc=0.566 rule_fid=0.454', '\\n', '[bs=256] Epoch 2:\ntrain_loss=0.5792 val_loss=0.7044 train_acc=0.722 val_acc=0.662 rule_fid=0.646',\n'\\n', '[bs=256] Epoch 3: train_loss=0.5675 val_loss=0.7448 train_acc=0.710\nval_acc=0.648 rule_fid=0.720', '\\n', '[bs=256] Epoch 4: train_loss=0.5076\nval_loss=0.6628 train_acc=0.751 val_acc=0.676 rule_fid=0.544', '\\n', '[bs=256]\nEpoch 5: train_loss=0.4387 val_loss=0.6702 train_acc=0.806 val_acc=0.702\nrule_fid=0.434', '\\n', '[bs=256] Epoch 6: train_loss=0.4193 val_loss=0.6522\ntrain_acc=0.821 val_acc=0.718 rule_fid=0.458', '\\n', '[bs=256] Epoch 7:\ntrain_loss=0.3839 val_loss=0.6386 train_acc=0.844 val_acc=0.718 rule_fid=0.812',\n'\\n', '[bs=256] Epoch 8: train_loss=0.3595 val_loss=0.6341 train_acc=0.857\nval_acc=0.734 rule_fid=0.866', '\\n', '[bs=256] Epoch 9: train_loss=0.3362\nval_loss=0.6323 train_acc=0.872 val_acc=0.746 rule_fid=0.760', '\\n', '[bs=256]\nEpoch 10: train_loss=0.3167 val_loss=0.6320 train_acc=0.886 val_acc=0.750\nrule_fid=0.750', '\\n', '[bs=256] Test_acc=0.724 test_loss=0.6599', '\\n',\n'[bs=512] Epoch 1: train_loss=2.5865 val_loss=1.9926 train_acc=0.498\nval_acc=0.462 rule_fid=0.978', '\\n', '[bs=512] Epoch 2: train_loss=1.9708\nval_loss=1.4882 train_acc=0.449 val_acc=0.394 rule_fid=0.826', '\\n', '[bs=512]\nEpoch 3: train_loss=1.5866 val_loss=1.2793 train_acc=0.267 val_acc=0.296\nrule_fid=0.592', '\\n', '[bs=512] Epoch 4: train_loss=1.4855 val_loss=1.2714\ntrain_acc=0.187 val_acc=0.356 rule_fid=0.468', '\\n', '[bs=512] Epoch 5:\ntrain_loss=1.4976 val_loss=1.2693 train_acc=0.224 val_acc=0.392 rule_fid=0.406',\n'\\n', '[bs=512] Epoch 6: train_loss=1.4571 val_loss=1.2047 train_acc=0.254\nval_acc=0.378 rule_fid=0.340', '\\n', '[bs=512] Epoch 7: train_loss=1.3566\nval_loss=1.1242 train_acc=0.238 val_acc=0.358 rule_fid=0.432', '\\n', '[bs=512]\nEpoch 8: train_loss=1.2588 val_loss=1.0769 train_acc=0.224 val_acc=0.334\nrule_fid=0.546', '\\n', '[bs=512] Epoch 9: train_loss=1.1937 val_loss=1.0526\ntrain_acc=0.258 val_acc=0.356 rule_fid=0.636', '\\n', '[bs=512] Epoch 10:\ntrain_loss=1.1463 val_loss=1.0186 train_acc=0.292 val_acc=0.362 rule_fid=0.652',\n'\\n', '[bs=512] Test_acc=0.386 test_loss=1.0130', '\\n', 'Saved\nexperiment_data.npy', '\\n', 'Execution time: 5 seconds seconds (time limit is 30\nminutes).']", "['Using device: cuda', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 2000 examples [00:00, 43014.75\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 500 examples [00:00, 128086.00\nexamples/s]', '\\n', '\\rGenerating train split: 0 examples [00:00, ?\nexamples/s]', '', '\\rGenerating train split: 1000 examples [00:00, 203864.29\nexamples/s]', '\\n', \"{'train': 2000, 'dev': 500, 'test': 1000}\", '\\n', 'Feature\nsize: 33', '\\n', 'Classes: [0, 1]', '\\n', '\\n=== Training with weight_decay=0.0\n===', '\\n', 'Epoch 1: train_acc=0.549 val_acc=0.588 rule_fid=0.566', '\\n',\n'Epoch 2: train_acc=0.658 val_acc=0.622 rule_fid=0.698', '\\n', 'Epoch 3:\ntrain_acc=0.721 val_acc=0.646 rule_fid=0.594', '\\n', 'Epoch 4: train_acc=0.776\nval_acc=0.684 rule_fid=0.648', '\\n', 'Epoch 5: train_acc=0.821 val_acc=0.696\nrule_fid=0.606', '\\n', 'Epoch 6: train_acc=0.856 val_acc=0.726 rule_fid=0.656',\n'\\n', 'Epoch 7: train_acc=0.883 val_acc=0.746 rule_fid=0.620', '\\n', 'Epoch 8:\ntrain_acc=0.911 val_acc=0.756 rule_fid=0.624', '\\n', 'Epoch 9: train_acc=0.930\nval_acc=0.762 rule_fid=0.636', '\\n', 'Epoch 10: train_acc=0.939 val_acc=0.762\nrule_fid=0.652', '\\n', 'Test_acc=0.754 test_loss=0.7323', '\\n', '\\n=== Training\nwith weight_decay=1e-05 ===', '\\n', 'Epoch 1: train_acc=0.562 val_acc=0.524\nrule_fid=0.632', '\\n', 'Epoch 2: train_acc=0.601 val_acc=0.562 rule_fid=0.442',\n'\\n', 'Epoch 3: train_acc=0.668 val_acc=0.592 rule_fid=0.492', '\\n', 'Epoch 4:\ntrain_acc=0.720 val_acc=0.632 rule_fid=0.464', '\\n', 'Epoch 5: train_acc=0.772\nval_acc=0.652 rule_fid=0.472', '\\n', 'Epoch 6: train_acc=0.823 val_acc=0.676\nrule_fid=0.488', '\\n', 'Epoch 7: train_acc=0.854 val_acc=0.698 rule_fid=0.450',\n'\\n', 'Epoch 8: train_acc=0.893 val_acc=0.730 rule_fid=0.474', '\\n', 'Epoch 9:\ntrain_acc=0.917 val_acc=0.746 rule_fid=0.462', '\\n', 'Epoch 10: train_acc=0.932\nval_acc=0.764 rule_fid=0.468', '\\n', 'Test_acc=0.771 test_loss=0.7032', '\\n',\n'\\n=== Training with weight_decay=0.0001 ===', '\\n', 'Epoch 1: train_acc=0.500\nval_acc=0.520 rule_fid=0.970', '\\n', 'Epoch 2: train_acc=0.500 val_acc=0.518\nrule_fid=0.472', '\\n', 'Epoch 3: train_acc=0.427 val_acc=0.448 rule_fid=0.572',\n'\\n', 'Epoch 4: train_acc=0.424 val_acc=0.504 rule_fid=0.640', '\\n', 'Epoch 5:\ntrain_acc=0.523 val_acc=0.594 rule_fid=0.410', '\\n', 'Epoch 6: train_acc=0.616\nval_acc=0.630 rule_fid=0.494', '\\n', 'Epoch 7: train_acc=0.703 val_acc=0.670\nrule_fid=0.522', '\\n', 'Epoch 8: train_acc=0.763 val_acc=0.706 rule_fid=0.596',\n'\\n', 'Epoch 9: train_acc=0.816 val_acc=0.724 rule_fid=0.714', '\\n', 'Epoch 10:\ntrain_acc=0.854 val_acc=0.736 rule_fid=0.748', '\\n', 'Test_acc=0.724\ntest_loss=0.6158', '\\n', '\\n=== Training with weight_decay=0.001 ===', '\\n',\n'Epoch 1: train_acc=0.623 val_acc=0.664 rule_fid=0.636', '\\n', 'Epoch 2:\ntrain_acc=0.732 val_acc=0.678 rule_fid=0.550', '\\n', 'Epoch 3: train_acc=0.811\nval_acc=0.718 rule_fid=0.458', '\\n', 'Epoch 4: train_acc=0.848 val_acc=0.734\nrule_fid=0.872', '\\n', 'Epoch 5: train_acc=0.877 val_acc=0.750 rule_fid=0.748',\n'\\n', 'Epoch 6: train_acc=0.902 val_acc=0.766 rule_fid=0.724', '\\n', 'Epoch 7:\ntrain_acc=0.919 val_acc=0.770 rule_fid=0.692', '\\n', 'Epoch 8: train_acc=0.935\nval_acc=0.774 rule_fid=0.692', '\\n', 'Epoch 9: train_acc=0.947 val_acc=0.774\nrule_fid=0.478', '\\n', 'Epoch 10: train_acc=0.956 val_acc=0.776 rule_fid=0.476',\n'\\n', 'Test_acc=0.773 test_loss=0.6587', '\\n', 'Saved experiment data to', ' ',\n'/home/zxl240011/AI-Scientist-v2/experiments/2025-08-17_02-43-\n40_interpretable_neural_rule_learning_attempt_0/0-run/process_ForkProcess-\n13/working/experiment_data.npy', '\\n', 'Execution time: 4 seconds seconds (time\nlimit is 30 minutes).']"], "analysis": ["", "The execution of the training script successfully completed without any errors\nor bugs. The script tested three different learning rates (0.0003, 0.001, and\n0.003) and recorded the training loss, validation loss, training accuracy,\nvalidation accuracy, and rule fidelity for each epoch. The results show that the\nmodel improved in performance as the learning rate increased, with the best\nperformance achieved at a learning rate of 0.003 (Test accuracy = 77.6%). The\nexperiment data was saved successfully for further analysis. No bugs or issues\nwere encountered during the execution.", "", ""], "exc_type": [null, null, null, null], "exc_info": [null, null, null, null], "exc_stack": [null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9635, "best_value": 0.9635}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.764, "best_value": 0.764}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.183, "best_value": 0.183}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6196, "best_value": 0.6196}]}, {"metric_name": "rule fidelity", "lower_is_better": false, "description": "The fidelity of the rules generated by the model.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.89, "best_value": 0.89}]}, {"metric_name": "search validation accuracy", "lower_is_better": false, "description": "The accuracy on the validation dataset during the search phase.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.75, "best_value": 0.75}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "The accuracy of the model on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.767, "best_value": 0.767}]}]}, {"metric_names": [{"metric_name": "Training Accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9715, "best_value": 0.9715}]}, {"metric_name": "Validation Accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.774, "best_value": 0.774}]}, {"metric_name": "Rule Fidelity", "lower_is_better": false, "description": "The fidelity of the rules generated by the model.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.968, "best_value": 0.968}]}, {"metric_name": "Training Loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.1475, "best_value": 0.1475}]}, {"metric_name": "Validation Loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6353, "best_value": 0.6353}]}, {"metric_name": "Test Accuracy", "lower_is_better": false, "description": "The accuracy of the model on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.776, "best_value": 0.776}]}, {"metric_name": "Test Loss", "lower_is_better": true, "description": "The loss of the model on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.7275, "best_value": 0.7275}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "The accuracy of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.979, "best_value": 0.979}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "The accuracy of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.78, "best_value": 0.78}]}, {"metric_name": "rule fidelity", "lower_is_better": false, "description": "The fidelity of the rules generated by the model.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.996, "best_value": 0.996}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "The loss of the model on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.0853, "best_value": 0.0853}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss of the model on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.632, "best_value": 0.632}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "The accuracy of the model on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.78, "best_value": 0.78}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy on the training dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.9555, "best_value": 0.9555}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy on the validation dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.776, "best_value": 0.776}]}, {"metric_name": "rule fidelity", "lower_is_better": false, "description": "Fidelity of the rules generated by the model.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.872, "best_value": 0.97}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Accuracy on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.773, "best_value": 0.773}]}, {"metric_name": "test loss", "lower_is_better": true, "description": "Loss on the test dataset.", "data": [{"dataset_name": "SPR_BENCH", "final_value": 0.6587, "best_value": 0.6158}]}]}], "is_best_node": [false, false, true, false], "plots": [["../../logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_train_val_accuracy.png", "../../logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_train_val_loss.png", "../../logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_rule_fidelity.png", "../../logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_grid_search_val_acc.png", "../../logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_confusion_matrix.png"], ["../../logs/0-run/experiment_results/experiment_543742284f6d42d69ffe47e26911efc1_proc_3204895/SPR_BENCH_accuracy_curves.png", "../../logs/0-run/experiment_results/experiment_543742284f6d42d69ffe47e26911efc1_proc_3204895/SPR_BENCH_loss_curves.png", "../../logs/0-run/experiment_results/experiment_543742284f6d42d69ffe47e26911efc1_proc_3204895/SPR_BENCH_rule_fidelity.png"], ["../../logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_train_val_accuracy.png", "../../logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_train_val_loss.png", "../../logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_rule_fidelity.png", "../../logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_test_accuracy_bar.png"], ["../../logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_val_accuracy_vs_epoch.png", "../../logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_loss_vs_epoch.png", "../../logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_rule_fidelity_vs_epoch.png", "../../logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_test_accuracy_bar.png", "../../logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_confusion_matrix_wd_0.001.png"]], "plot_paths": [["experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_train_val_accuracy.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_train_val_loss.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_rule_fidelity.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_grid_search_val_acc.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_confusion_matrix.png"], ["experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_543742284f6d42d69ffe47e26911efc1_proc_3204895/SPR_BENCH_accuracy_curves.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_543742284f6d42d69ffe47e26911efc1_proc_3204895/SPR_BENCH_loss_curves.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_543742284f6d42d69ffe47e26911efc1_proc_3204895/SPR_BENCH_rule_fidelity.png"], ["experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_train_val_accuracy.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_train_val_loss.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_rule_fidelity.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_test_accuracy_bar.png"], ["experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_val_accuracy_vs_epoch.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_loss_vs_epoch.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_rule_fidelity_vs_epoch.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_test_accuracy_bar.png", "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_confusion_matrix_wd_0.001.png"]], "plot_analyses": [[{"analysis": "The plot shows the training and validation accuracy over 10 epochs. Training accuracy increases steadily, approaching near-perfect accuracy by epoch 10, indicating that the model is learning effectively from the training data. However, validation accuracy plateaus around epoch 6, suggesting diminishing returns in generalization performance. This discrepancy between training and validation accuracy could indicate potential overfitting, where the model is overly specialized in the training data and less effective on unseen data.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_train_val_accuracy.png"}, {"analysis": "The plot depicts the training and validation loss over 10 epochs. Training loss decreases consistently, reflecting effective optimization on the training data. Validation loss, however, stops decreasing around epoch 6 and begins to slightly increase, further supporting the observation of overfitting. This trend suggests that the model's generalization ability may not improve with further training beyond this point.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_train_val_loss.png"}, {"analysis": "This plot illustrates the rule fidelity metric across epochs. Rule fidelity improves significantly until epoch 6, after which it fluctuates. The peak rule fidelity around epochs 6-7 aligns with the plateau observed in validation accuracy. The subsequent drop in rule fidelity suggests that the model may be losing its ability to generate interpretable rules as it continues to train, possibly overfitting to the training data.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_rule_fidelity.png"}, {"analysis": "This plot shows the validation accuracy achieved across different maximum epochs during a grid search. Validation accuracy peaks at 75% for a maximum of 40 epochs but drops sharply for other configurations. The variability in accuracy suggests that the model's performance is sensitive to the number of epochs, and 40 epochs may represent an optimal balance between underfitting and overfitting.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_grid_search_val_acc.png"}, {"analysis": "The confusion matrix for the test set indicates the distribution of true versus predicted labels. The model performs well for the majority class, as evidenced by the high values along the diagonal. However, there may be misclassifications for the minority class, as indicated by the off-diagonal values. This imbalance could be addressed by techniques such as class weighting or data augmentation during training.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_07fa76f7c2c24f39b60cf3471d9ac83b_proc_3204894/SPR_BENCH_confusion_matrix.png"}], [{"analysis": "This plot shows the accuracy trends for different learning rates (3e-04, 1e-03, and 3e-03) over 10 epochs. The learning rate of 3e-03 achieves the highest training and validation accuracy, indicating rapid learning and convergence. However, there is a noticeable gap between training and validation accuracy for this learning rate, suggesting potential overfitting. The learning rate of 1e-03 shows a more balanced trend with moderate accuracy improvements and smaller gaps between training and validation accuracy. The learning rate of 3e-04 demonstrates slower learning and lower accuracy, indicating underfitting.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_543742284f6d42d69ffe47e26911efc1_proc_3204895/SPR_BENCH_accuracy_curves.png"}, {"analysis": "This plot illustrates the cross-entropy loss trends for different learning rates over 10 epochs. The learning rate of 3e-03 achieves the fastest reduction in training loss, but the validation loss plateaus early, reinforcing the possibility of overfitting. The learning rate of 1e-03 shows a consistent reduction in both training and validation loss, indicating better generalization. The learning rate of 3e-04 has the slowest loss reduction, with higher final losses, confirming underfitting.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_543742284f6d42d69ffe47e26911efc1_proc_3204895/SPR_BENCH_loss_curves.png"}, {"analysis": "This plot presents rule fidelity trends for different learning rates over 10 epochs. The learning rate of 3e-03 achieves the highest rule fidelity, indicating strong alignment with the underlying rules. However, its sharp initial fluctuations suggest unstable learning dynamics. The learning rate of 1e-03 shows more stable and consistent improvements in rule fidelity, making it a balanced choice. The learning rate of 3e-04 exhibits the lowest and slowest improvements in rule fidelity, reflecting its underfitting nature.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_543742284f6d42d69ffe47e26911efc1_proc_3204895/SPR_BENCH_rule_fidelity.png"}], [{"analysis": "The plot shows training and validation accuracy trends for different batch sizes. Smaller batch sizes (e.g., 32 and 64) lead to faster convergence and higher accuracy, with batch size 32 achieving nearly 100% training accuracy and over 80% validation accuracy. Larger batch sizes (e.g., 512) result in slower convergence and lower accuracy, suggesting underfitting. Validation accuracy trends indicate that batch sizes 32 and 64 are optimal for this task.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_train_val_accuracy.png"}, {"analysis": "The plot illustrates training and validation loss trends for varying batch sizes. Smaller batch sizes (e.g., 32 and 64) achieve lower loss values faster, indicating better convergence. Larger batch sizes (e.g., 512) exhibit higher loss values and slower reduction, which aligns with underfitting behavior. The loss curves for batch sizes 32 and 64 stabilize around 1.0, suggesting effective learning.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_train_val_loss.png"}, {"analysis": "This plot evaluates rule fidelity across epochs for different batch sizes. Batch size 32 consistently achieves the highest rule fidelity, reaching a value close to 1.0 by epoch 10. Larger batch sizes (e.g., 512) show fluctuating and lower rule fidelity, indicating that smaller batch sizes are better at capturing and representing the underlying rules governing the data.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_rule_fidelity.png"}, {"analysis": "The bar chart compares final test accuracy across different batch sizes. Batch sizes 32 and 64 achieve the highest test accuracy, both nearing 0.8, while batch size 512 performs the worst with a significant drop in accuracy. This reinforces the observation that smaller batch sizes are more effective for this task.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_2f627a07af6a443799e920b73e05dd58_proc_3204896/SPR_BENCH_test_accuracy_bar.png"}], [{"analysis": "The plot shows the validation accuracy trends for different weight decay values (wd) over 10 epochs. The highest validation accuracy is achieved with wd=0.001, indicating that a moderate weight decay value helps the model generalize better. Lower weight decay values (e.g., wd=0.0, wd=1e-05) result in slower accuracy improvement, while wd=0.0001 performs slightly better, but not as well as wd=0.001. This suggests that regularization through weight decay is crucial for this task.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_val_accuracy_vs_epoch.png"}, {"analysis": "This plot compares the training and validation loss for different weight decay values over 10 epochs. All configurations show a rapid decrease in loss in the initial epochs, followed by a plateau. Weight decay of wd=0.001 achieves the lowest validation loss, reinforcing its effectiveness in improving generalization. The gap between training and validation loss narrows for wd=0.001, indicating reduced overfitting.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_loss_vs_epoch.png"}, {"analysis": "The plot highlights the rule fidelity trends across epochs for different weight decay values. Rule fidelity is most stable and consistent for wd=0.001, whereas it fluctuates significantly for lower weight decays, especially wd=0.0001 and wd=0.0. This suggests that higher weight decay values lead to better interpretability by stabilizing rule fidelity.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_rule_fidelity_vs_epoch.png"}, {"analysis": "The bar chart summarizes the final test accuracy for each weight decay value. While all configurations achieve comparable performance, wd=0.001 slightly outperforms others, confirming its superiority in balancing accuracy and generalization.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_test_accuracy_bar.png"}, {"analysis": "The confusion matrix for wd=0.001 reveals the model's performance in classifying the SPR task. High values along the diagonal indicate strong performance in correctly predicting labels, while the off-diagonal elements are relatively low, showing minimal misclassification. This further validates the effectiveness of wd=0.001 as the optimal weight decay value.", "plot_path": "experiments/2025-08-17_02-43-40_interpretable_neural_rule_learning_attempt_0/logs/0-run/experiment_results/experiment_95df43c6e2954239b06c57441e28ed38_proc_3204897/SPR_BENCH_confusion_matrix_wd_0.001.png"}]], "vlm_feedback_summary": ["The plots suggest that the model performs well on training data but shows signs\nof overfitting beyond a certain point (around epoch 6). Validation accuracy and\nrule fidelity metrics plateau or fluctuate, highlighting the need for careful\ntuning of hyperparameters such as the number of epochs and regularization\ntechniques. The confusion matrix reveals potential class imbalance issues that\ncould be addressed to improve overall performance.", "The analysis highlights that while the learning rate of 3e-03 achieves the\nhighest performance metrics, it shows signs of overfitting and unstable learning\ndynamics. The learning rate of 1e-03 offers a balanced trade-off between\nperformance and generalization, making it a more robust choice. The learning\nrate of 3e-04 underperforms across all metrics, indicating underfitting.", "The results suggest that smaller batch sizes (32 and 64) consistently outperform\nlarger batch sizes in terms of accuracy, loss reduction, and rule fidelity.\nThese findings indicate that smaller batch sizes are better suited for the\nSPR_BENCH task, achieving both higher performance and better interpretability.", "The analysis of the plots indicates that wd=0.001 is the optimal weight decay\nvalue for the SPR task. It provides the best balance between validation\naccuracy, loss minimization, rule fidelity, and test accuracy, while also\nreducing overfitting."], "exec_time": [5.6662750244140625, 4.556618690490723, 5.460477352142334, 4.6293723583221436], "exec_time_feedback": ["", "", "", ""], "datasets_successfully_tested": [["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"], ["[\"SPR_BENCH\"]"], ["['SPR_BENCH']"]], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ------------------ load -------------------------\ntry:\n    ed = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    spr = ed[\"num_epochs\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    spr = None\n\nif spr is not None:\n    mtr = spr[\"metrics\"]\n    loss = spr[\"losses\"]\n    search_vals = spr[\"search_vals\"]\n    search_val_accs = spr[\"search_val_accs\"]\n    preds = spr[\"predictions\"]\n    gts = spr[\"ground_truth\"]\n    epochs = np.arange(1, len(mtr[\"train_acc\"]) + 1)\n\n    # 1. accuracy\n    try:\n        plt.figure()\n        plt.plot(epochs, mtr[\"train_acc\"], label=\"Train\")\n        plt.plot(epochs, mtr[\"val_acc\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH: Train vs Validation Accuracy\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_train_val_accuracy.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot: {e}\")\n        plt.close()\n\n    # 2. loss\n    try:\n        plt.figure()\n        plt.plot(epochs, loss[\"train\"], label=\"Train\")\n        plt.plot(epochs, loss[\"val\"], label=\"Validation\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH: Train vs Validation Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_train_val_loss.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # 3. rule fidelity\n    try:\n        plt.figure()\n        plt.plot(epochs, mtr[\"rule_fidelity\"], color=\"green\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Rule Fidelity\")\n        plt.title(\"SPR_BENCH: Rule Fidelity Across Epochs\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_rule_fidelity.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating rule fidelity plot: {e}\")\n        plt.close()\n\n    # 4. grid-search curve\n    try:\n        plt.figure()\n        plt.plot(search_vals, search_val_accs, marker=\"o\")\n        plt.xlabel(\"Max Epochs Tried\")\n        plt.ylabel(\"Dev Accuracy\")\n        plt.title(\"SPR_BENCH: Grid-Search Validation Accuracy\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_grid_search_val_acc.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating search plot: {e}\")\n        plt.close()\n\n    # 5. confusion matrix\n    try:\n        from sklearn.metrics import confusion_matrix\n\n        cm = confusion_matrix(gts, preds)\n        plt.figure()\n        im = plt.imshow(cm, cmap=\"Blues\")\n        plt.colorbar(im)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"True\")\n        plt.title(\"SPR_BENCH: Confusion Matrix (Test Set)\")\n        plt.savefig(os.path.join(working_dir, \"SPR_BENCH_confusion_matrix.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating confusion matrix: {e}\")\n        plt.close()\n\n    # report test accuracy\n    try:\n        test_acc = (preds == gts).mean()\n        print(f\"Test accuracy: {test_acc:.3f}\")\n    except Exception as e:\n        print(f\"Error computing test accuracy: {e}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ---------- paths ----------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# ---------- load ----------\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = None\n\nif experiment_data is not None:\n    spr_data = experiment_data.get(\"learning_rate_search\", {}).get(\"SPR_BENCH\", {})\n    lrs = list(spr_data.keys())[:5]  # safeguard: plot at most 5 curves\n\n    epochs = (\n        len(next(iter(spr_data.values()))[\"metrics\"][\"train_acc\"]) if spr_data else 0\n    )\n    x = np.arange(1, epochs + 1)\n\n    # helper to extract list safely\n    def get_list(d, path):\n        cur = d\n        for p in path:\n            cur = cur.get(p, [])\n        return cur\n\n    # ---------- accuracy ----------\n    try:\n        plt.figure()\n        for lr in lrs:\n            acc_tr = get_list(spr_data[lr], [\"metrics\", \"train_acc\"])\n            acc_val = get_list(spr_data[lr], [\"metrics\", \"val_acc\"])\n            plt.plot(x, acc_tr, label=f\"{lr}-train\")\n            plt.plot(x, acc_val, \"--\", label=f\"{lr}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\"SPR_BENCH Accuracy Curves\\nLearning-Rate Search (Train vs. Val)\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_accuracy_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot: {e}\")\n        plt.close()\n\n    # ---------- loss ----------\n    try:\n        plt.figure()\n        for lr in lrs:\n            loss_tr = get_list(spr_data[lr], [\"losses\", \"train\"])\n            loss_val = get_list(spr_data[lr], [\"losses\", \"val\"])\n            plt.plot(x, loss_tr, label=f\"{lr}-train\")\n            plt.plot(x, loss_val, \"--\", label=f\"{lr}-val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Cross-Entropy Loss\")\n        plt.title(\"SPR_BENCH Loss Curves\\nLearning-Rate Search (Train vs. Val)\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # ---------- rule fidelity ----------\n    try:\n        plt.figure()\n        for lr in lrs:\n            rf = get_list(spr_data[lr], [\"metrics\", \"rule_fidelity\"])\n            plt.plot(x, rf, label=lr)\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Rule Fidelity\")\n        plt.title(\"SPR_BENCH Rule Fidelity Across Epochs\\nLearning-Rate Search\")\n        plt.legend()\n        plt.tight_layout()\n        fname = os.path.join(working_dir, \"SPR_BENCH_rule_fidelity.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating rule fidelity plot: {e}\")\n        plt.close()\n\n    # ---------- print final test accuracy ----------\n    for lr in lrs:\n        test_acc = spr_data[lr][\"metrics\"].get(\"test_acc\", None)\n        if test_acc is not None:\n            print(f\"{lr}: Test Accuracy = {test_acc:.3f}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    exp = experiment_data[\"batch_size_tuning\"][\"SPR_BENCH\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    raise SystemExit\n\nbatch_sizes = exp[\"batch_sizes\"]  # [32, 64, 128, 256, 512]\nn_bs = len(batch_sizes)\nepochs_per = 10\ncolors = plt.cm.viridis(np.linspace(0, 1, n_bs))\n\n\n# helper: slice metric list into [n_bs, epochs_per]\ndef split_metric(lst):\n    return [lst[i * epochs_per : (i + 1) * epochs_per] for i in range(n_bs)]\n\n\ntrain_acc = split_metric(exp[\"metrics\"][\"train_acc\"])\nval_acc = split_metric(exp[\"metrics\"][\"val_acc\"])\ntrain_loss = split_metric(exp[\"losses\"][\"train\"])\nval_loss = split_metric(exp[\"losses\"][\"val\"])\nrule_fid = split_metric(exp[\"metrics\"][\"rule_fidelity\"])\n\n# 1) accuracy curves\ntry:\n    plt.figure()\n    for i, bs in enumerate(batch_sizes):\n        epochs = np.arange(1, epochs_per + 1)\n        plt.plot(\n            epochs, train_acc[i], color=colors[i], linestyle=\"-\", label=f\"Train bs={bs}\"\n        )\n        plt.plot(\n            epochs, val_acc[i], color=colors[i], linestyle=\"--\", label=f\"Val bs={bs}\"\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"SPR_BENCH Training & Validation Accuracy per Epoch\")\n    plt.legend(fontsize=8, ncol=2)\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_train_val_accuracy.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy plot: {e}\")\n    plt.close()\n\n# 2) loss curves\ntry:\n    plt.figure()\n    for i, bs in enumerate(batch_sizes):\n        epochs = np.arange(1, epochs_per + 1)\n        plt.plot(\n            epochs,\n            train_loss[i],\n            color=colors[i],\n            linestyle=\"-\",\n            label=f\"Train bs={bs}\",\n        )\n        plt.plot(\n            epochs, val_loss[i], color=colors[i], linestyle=\"--\", label=f\"Val bs={bs}\"\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Cross-Entropy Loss\")\n    plt.title(\"SPR_BENCH Training & Validation Loss per Epoch\")\n    plt.legend(fontsize=8, ncol=2)\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_train_val_loss.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# 3) rule fidelity curves\ntry:\n    plt.figure()\n    for i, bs in enumerate(batch_sizes):\n        epochs = np.arange(1, epochs_per + 1)\n        plt.plot(epochs, rule_fid[i], color=colors[i], marker=\"o\", label=f\"bs={bs}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Rule Fidelity\")\n    plt.title(\"SPR_BENCH Rule Fidelity per Epoch\")\n    plt.legend(fontsize=8)\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_rule_fidelity.png\"), dpi=150)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating rule fidelity plot: {e}\")\n    plt.close()\n\n# 4) final test accuracy by batch size\ntry:\n    gtruth = np.asarray(exp[\"ground_truth\"])\n    test_accs = []\n    for preds in exp[\"predictions\"]:  # len == n_bs\n        acc = (preds == gtruth).mean()\n        test_accs.append(acc)\n    plt.figure()\n    plt.bar(range(n_bs), test_accs, color=colors)\n    plt.xticks(range(n_bs), batch_sizes)\n    plt.xlabel(\"Batch Size\")\n    plt.ylabel(\"Test Accuracy\")\n    plt.title(\"SPR_BENCH Final Test Accuracy vs Batch Size\")\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_test_accuracy_bar.png\"), dpi=150)\n    plt.close()\n    print({bs: round(acc, 3) for bs, acc in zip(batch_sizes, test_accs)})\nexcept Exception as e:\n    print(f\"Error creating test accuracy plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# ------------------ LOAD DATA ------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nruns = experiment_data.get(\"weight_decay\", {}).get(\"SPR_BENCH\", {})\nif not runs:\n    print(\"No data to plot.\")\n    exit()\n\ndecays = sorted(runs.keys(), key=lambda x: float(x))\nepochs = len(next(iter(runs.values()))[\"metrics\"][\"train_acc\"])\n\n# collect metrics\nval_accs, train_losses, val_losses, rule_fids, test_accs = {}, {}, {}, {}, {}\nfor d in decays:\n    m = runs[d][\"metrics\"]\n    val_accs[d] = m[\"val_acc\"]\n    train_losses[d] = runs[d][\"losses\"][\"train\"]\n    val_losses[d] = runs[d][\"losses\"][\"val\"]\n    rule_fids[d] = m[\"rule_fidelity\"]\n    test_accs[d] = runs[d][\"test_acc\"]\n\nbest_decay = max(test_accs, key=test_accs.get)\nbest_preds = runs[best_decay][\"predictions\"]\ny_true = runs[best_decay][\"ground_truth\"]\nnum_classes = len(np.unique(y_true))\n\n# -------------- PLOTTING -----------------------\n# 1) Validation accuracy curves\ntry:\n    plt.figure()\n    for d in decays:\n        plt.plot(range(1, epochs + 1), val_accs[d], label=f\"wd={d}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Validation Accuracy\")\n    plt.title(\"SPR_BENCH - Validation Accuracy vs Epoch (weight decays)\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_val_accuracy_vs_epoch.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating val-acc plot: {e}\")\n    plt.close()\n\n# 2) Train & validation loss\ntry:\n    plt.figure()\n    for d in decays:\n        plt.plot(\n            range(1, epochs + 1), train_losses[d], linestyle=\"--\", label=f\"Train wd={d}\"\n        )\n        plt.plot(range(1, epochs + 1), val_losses[d], label=f\"Val wd={d}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"SPR_BENCH - Train & Val Loss vs Epoch (weight decays)\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_loss_vs_epoch.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# 3) Rule fidelity\ntry:\n    plt.figure()\n    for d in decays:\n        plt.plot(range(1, epochs + 1), rule_fids[d], label=f\"wd={d}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Rule Fidelity\")\n    plt.title(\"SPR_BENCH - Rule Fidelity vs Epoch (weight decays)\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_rule_fidelity_vs_epoch.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating rule-fidelity plot: {e}\")\n    plt.close()\n\n# 4) Final test accuracies\ntry:\n    plt.figure()\n    plt.bar(range(len(decays)), [test_accs[d] for d in decays], tick_label=decays)\n    plt.ylabel(\"Test Accuracy\")\n    plt.title(\"SPR_BENCH - Final Test Accuracy per Weight Decay\")\n    plt.savefig(os.path.join(working_dir, \"SPR_BENCH_test_accuracy_bar.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating test-acc bar plot: {e}\")\n    plt.close()\n\n# 5) Confusion matrix for best decay\ntry:\n    cm = np.zeros((num_classes, num_classes), dtype=int)\n    for t, p in zip(y_true, best_preds):\n        cm[t, p] += 1\n    plt.figure()\n    plt.imshow(cm, cmap=\"Blues\")\n    plt.colorbar()\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Ground Truth\")\n    plt.title(f\"SPR_BENCH - Confusion Matrix (wd={best_decay})\")\n    plt.savefig(\n        os.path.join(working_dir, f\"SPR_BENCH_confusion_matrix_wd_{best_decay}.png\")\n    )\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating confusion matrix plot: {e}\")\n    plt.close()\n\n# -------- Print numeric summary ----------\nprint(\"=== Final Test Accuracies ===\")\nfor d in decays:\n    print(f\"weight_decay={d}: {test_accs[d]:.4f}\")\n"], "plot_plan": ["We first load experiment_data.npy and safely extract the SPR_BENCH sub-dictionary. From it we read arrays for training/validation accuracy, training/validation loss, rule fidelity (all per epoch for the best run), and the grid-search validation accuracies obtained for each candidate number of epochs. We then create up to five standard figures: (1) training vs validation accuracy; (2) training vs validation loss; (3) rule fidelity across epochs; (4) grid-search curve of max_epochs vs dev accuracy; (5) a confusion-matrix heatmap on the held-out test set, computed from saved predictions and ground-truth. Each figure is wrapped in its own try-except block, saved to working_dir with descriptive names, titled clearly, and the figure is always closed. Finally, we print overall test accuracy after plotting so the user sees the key metric.", "We will load the saved experiment_data.npy, extract per-epoch metrics for every tested learning rate, and generate three line plots: accuracy (train vs. val), loss (train vs. val), and rule-fidelity, each containing one line per learning rate.  For every figure, we place the plotting logic inside a try-except block, add clear titles that mention the dataset (SPR_BENCH) and the plotted quantity, and save the file into working_dir with descriptive names.  After plotting, we close every figure to free resources.  We also print out the final test accuracy for each learning rate so the user can quickly see the quantitative results.  To avoid clutter, we show at most five learning-rate curves (our run only has three).  The code follows the mandated import header and respects all other formatting requirements.  No synthetic data are introduced; everything comes directly from experiment_data.npy.  Finally, we ensure working_dir exists before saving any files.", "We first load experiment_data.npy and recover the list of batch sizes and per-epoch metrics.  Because the training loop stored metrics sequentially (epochs 1-10 for bs1, 11-20 for bs2, \u2026) we slice the metric lists in blocks of 10 epochs and associate each block with its batch size.  Four visualizations are produced: (1) train/validation accuracy per epoch, (2) train/validation loss per epoch, (3) rule fidelity per epoch, and (4) a bar chart of final test accuracy versus batch size (computed on-the-fly from stored predictions and ground-truth).  Each plot is wrapped in a try-except block, uses basic matplotlib, is given a descriptive title, and is saved into working_dir with a meaningful filename.  Only data retrieved from experiment_data.npy are plotted; no values are fabricated.  We cap ourselves at these four figures to remain within the five-figure limit.  All figures are closed after saving to release memory.  The script prints test accuracies so the user sees numerical values alongside the plots.  Finally, the code is concise and self-contained, beginning with the mandated imports and directory setup.", "The script will load the saved experiment_data.npy, iterate through the four weight-decay runs stored under experiment_data['weight_decay']['SPR_BENCH'], and gather per-epoch metrics (train/val accuracy & loss, rule fidelity) plus the final test accuracy and predictions. With these, it will create up to five standard figures: (1) validation accuracy curves across epochs for all decay values, (2) training and validation loss curves, (3) rule-fidelity curves, (4) a bar chart of final test accuracies, and (5) a confusion matrix for the best-performing decay setting. Each figure is wrapped in its own try-except block, titled descriptively, saved to working_dir with dataset and content in the filename, and the figure is always closed. After plotting, the script prints a small summary of test accuracies so users can quickly see the numeric results alongside the saved visuals."], "ablation_name": [null, null, null, null], "hyperparam_name": ["num_epochs", "learning_rate", "batch_size", "weight_decay (L2 regularization coefficient)"], "is_seed_node": [false, false, false, false], "is_seed_agg_node": [false, false, false, false], "parse_metrics_plan": ["The script will load `experiment_data.npy` from the `working` directory, unpack\nthe nested dictionary, and then\u2014for every dataset found (e.g.,\n\u201cSPR_BENCH\u201d)\u2014compute the best value for each stored metric.   For accuracies and\nthe rule-fidelity score, the maximum value is reported; for losses, the minimum\nis reported.   If test predictions and ground-truth labels are present, the\nscript also computes and prints the test accuracy.   Each metric is printed with\nan explicit, descriptive name, and no plots are generated.", "The script will load experiment_data.npy from the working directory, iterate\nthrough each dataset (e.g., \u201cSPR_BENCH\u201d) and each learning\u2010rate run nested\ninside it, pick summary statistics (final training accuracy, best validation\naccuracy, best rule fidelity, final training loss, best validation loss, test\naccuracy, test loss), and print them with explicit metric names. Everything is\nexecuted at the top level so running the file immediately shows the requested\ninformation.", "The script loads the serialized experiment dictionary from the working\ndirectory, drills down into the \u201cbatch_size_tuning\u201d section, and loops over\nevery dataset (e.g., \u201cSPR_BENCH\u201d).   For each dataset it retrieves the stored\nmetric and loss arrays, derives the best value (maximum for accuracies / rule-\nfidelity, minimum for losses), and prints them with clear, descriptive names.\nIf test-set predictions are present, it also evaluates and prints the best test\naccuracy obtained across batch-size runs.   Everything is executed immediately\nat import time\u2014no special entry point or plotting is used.", "The code will load the saved NumPy file from the working directory, convert it\nback to a Python dict, and iterate through its nested structure.   For every\ndataset (e.g., \u201cSPR_BENCH\u201d) it will loop over all weight-decay runs, compute the\nbest value for each metric (max for accuracies and rule fidelity, min for\nlosses), and print them with clear, explicit names such as \u201ctrain accuracy\u201d or\n\u201cvalidation loss.\u201d   The script contains no main-guard, so it executes\nimmediately when run."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# ----------------- LOAD EXPERIMENT DATA -----------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy at {file_path}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ------------------ HELPER FUNCTIONS --------------------\ndef best_value(values, mode=\"max\"):\n    \"\"\"Return best (max or min) value from a list/array.\"\"\"\n    values = np.asarray(values, dtype=float)\n    return np.nanmax(values) if mode == \"max\" else np.nanmin(values)\n\n\ndef print_metric(name, value):\n    \"\"\"Print metric name and value with 4 decimal places (if float).\"\"\"\n    if isinstance(value, float):\n        print(f\"{name}: {value:.4f}\")\n    else:\n        print(f\"{name}: {value}\")\n\n\n# -------------------- MAIN LOGIC ------------------------\nfor dataset_name, data in experiment_data.get(\"num_epochs\", {}).items():\n    print(f\"\\n{dataset_name}\")  # Dataset header\n\n    # Metrics recorded during training of the BEST run\n    metrics = data.get(\"metrics\", {})\n    losses = data.get(\"losses\", {})\n\n    # Training / validation accuracies\n    if \"train_acc\" in metrics:\n        print_metric(\"train accuracy (best)\", best_value(metrics[\"train_acc\"], \"max\"))\n    if \"val_acc\" in metrics:\n        print_metric(\n            \"validation accuracy (best)\", best_value(metrics[\"val_acc\"], \"max\")\n        )\n\n    # Training / validation losses\n    if \"train\" in losses:\n        print_metric(\"train loss (best)\", best_value(losses[\"train\"], \"min\"))\n    if \"val\" in losses:\n        print_metric(\"validation loss (best)\", best_value(losses[\"val\"], \"min\"))\n\n    # Rule fidelity\n    if \"rule_fidelity\" in metrics:\n        print_metric(\n            \"rule fidelity (best)\", best_value(metrics[\"rule_fidelity\"], \"max\")\n        )\n\n    # Search-stage validation accuracies (across different epoch budgets)\n    if \"search_val_accs\" in data:\n        print_metric(\n            \"search validation accuracy (best)\",\n            best_value(data[\"search_val_accs\"], \"max\"),\n        )\n\n    # Test-set accuracy (if predictions and ground truth are present)\n    preds = data.get(\"predictions\")\n    gts = data.get(\"ground_truth\")\n    if preds is not None and gts is not None:\n        test_acc = (preds == gts).mean()\n        print_metric(\"test accuracy\", float(test_acc))\n", "import os\nimport numpy as np\n\n# --------------------- LOAD -------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\nif not os.path.isfile(file_path):\n    raise FileNotFoundError(f\"Could not find experiment_data.npy in {working_dir}\")\n\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# -------------------- PARSE & PRINT -----------------\nlr_root = experiment_data.get(\"learning_rate_search\", {})\n\nfor dataset_name, lr_dict in lr_root.items():  # e.g. \"SPR_BENCH\"\n    print(f\"\\nDataset: {dataset_name}\")\n    for lr_key, run in lr_dict.items():  # e.g. \"lr_3e-04\"\n        metrics = run.get(\"metrics\", {})\n        losses = run.get(\"losses\", {})\n\n        # Accuracy-type metrics: take max; losses: take min; training use final epoch\n        train_acc_final = metrics.get(\"train_acc\", [None])[-1]\n        val_acc_best = max(metrics.get(\"val_acc\", []), default=None)\n        rule_fid_best = max(metrics.get(\"rule_fidelity\", []), default=None)\n        test_acc = metrics.get(\"test_acc\", None)\n\n        train_loss_final = losses.get(\"train\", [None])[-1]\n        val_loss_best = min(losses.get(\"val\", []), default=None)\n        test_loss = losses.get(\"test\", None)\n\n        print(f\"  Learning rate {lr_key.split('_')[-1]}:\")\n        if train_acc_final is not None:\n            print(f\"    final training accuracy: {train_acc_final:.4f}\")\n        if val_acc_best is not None:\n            print(f\"    best validation accuracy: {val_acc_best:.4f}\")\n        if rule_fid_best is not None:\n            print(f\"    best rule fidelity: {rule_fid_best:.4f}\")\n        if train_loss_final is not None:\n            print(f\"    final training loss: {train_loss_final:.4f}\")\n        if val_loss_best is not None:\n            print(f\"    best validation loss: {val_loss_best:.4f}\")\n        if test_acc is not None:\n            print(f\"    test accuracy: {test_acc:.4f}\")\n        if test_loss is not None:\n            print(f\"    test loss: {test_loss:.4f}\")\n", "import os\nimport numpy as np\n\n# -------- Load experiment data --------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# -------- Helper functions --------\ndef best_value(values, higher_is_better=True):\n    \"\"\"Return the best scalar in a list given the optimisation direction.\"\"\"\n    if not values:  # safety check\n        return None\n    return max(values) if higher_is_better else min(values)\n\n\ndef compute_accuracy(preds, gold):\n    return (preds == gold).mean()\n\n\n# -------- Iterate over datasets --------\ntuning_block = experiment_data.get(\"batch_size_tuning\", {})\n\nfor dataset_name, ds_dict in tuning_block.items():\n    print(f\"\\nDataset: {dataset_name}\")\n\n    metrics = ds_dict.get(\"metrics\", {})\n    losses = ds_dict.get(\"losses\", {})\n\n    # Best Training / Validation Accuracy\n    train_acc_best = best_value(metrics.get(\"train_acc\", []), higher_is_better=True)\n    val_acc_best = best_value(metrics.get(\"val_acc\", []), higher_is_better=True)\n    rule_fid_best = best_value(metrics.get(\"rule_fidelity\", []), higher_is_better=True)\n\n    if train_acc_best is not None:\n        print(f\"Best train accuracy: {train_acc_best:.4f}\")\n    if val_acc_best is not None:\n        print(f\"Best validation accuracy: {val_acc_best:.4f}\")\n    if rule_fid_best is not None:\n        print(f\"Best rule fidelity: {rule_fid_best:.4f}\")\n\n    # Best Training / Validation Loss\n    train_loss_best = best_value(losses.get(\"train\", []), higher_is_better=False)\n    val_loss_best = best_value(losses.get(\"val\", []), higher_is_better=False)\n\n    if train_loss_best is not None:\n        print(f\"Best train loss: {train_loss_best:.4f}\")\n    if val_loss_best is not None:\n        print(f\"Best validation loss: {val_loss_best:.4f}\")\n\n    # Test Accuracy (if predictions available)\n    preds_list = ds_dict.get(\"predictions\", [])\n    gold = np.array(ds_dict.get(\"ground_truth\", []))\n    if len(preds_list) > 0 and gold.size > 0:\n        test_accuracies = [compute_accuracy(np.array(p), gold) for p in preds_list]\n        best_test_acc = max(test_accuracies)\n        print(f\"Best test accuracy: {best_test_acc:.4f}\")\n", "import os\nimport numpy as np\n\n# ---------------------------------------------------\n# Locate and load the experiment file\n# ---------------------------------------------------\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n\n# ---------------------------------------------------\n# Helper to decide whether we want min or max\n# ---------------------------------------------------\ndef best_value(values, metric_name):\n    \"\"\"Return the best value: max for accuracies/fidelity, min for losses.\"\"\"\n    if metric_name.endswith((\"acc\", \"accuracy\", \"fidelity\")):\n        return max(values)\n    if metric_name.endswith(\"loss\"):\n        return min(values)\n    return values[-1]  # fallback to final value if unsure\n\n\n# ---------------------------------------------------\n# Iterate over datasets and print metrics\n# ---------------------------------------------------\nfor dataset_name, runs_dict in experiment_data[\"weight_decay\"].items():\n    print(f\"\\nDataset: {dataset_name}\")  # requirement #3\n\n    for wd, run_store in runs_dict.items():\n        print(f\"  weight_decay = {wd}\")  # helpful hyper-param heading\n\n        # Metrics that were tracked per epoch\n        for metric_group, metric_data in run_store.items():\n            if metric_group in (\"metrics\", \"losses\"):\n                for metric_name, history in metric_data.items():\n                    value = best_value(history, metric_name)\n                    pretty = metric_name.replace(\"_\", \" \")\n                    print(f\"    best {pretty}: {value:.4f}\")\n\n        # Final-epoch / single-value metrics\n        print(f\"    final test accuracy: {run_store['test_acc']:.4f}\")\n        print(f\"    final test loss:     {run_store['test_loss']:.4f}\")\n"], "parse_term_out": ["['\\nSPR_BENCH', '\\n', 'train accuracy (best): 0.9635', '\\n', 'validation\naccuracy (best): 0.7640', '\\n', 'train loss (best): 0.1830', '\\n', 'validation\nloss (best): 0.6196', '\\n', 'rule fidelity (best): 0.8900', '\\n', 'search\nvalidation accuracy (best): 0.7500', '\\n', 'test accuracy: 0.7670', '\\n',\n'Execution time: a moment seconds (time limit is 30 minutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  Learning rate 3e-04:', '\\n', '    final\ntraining accuracy: 0.7640', '\\n', '    best validation accuracy: 0.6660', '\\n',\n'    best rule fidelity: 0.6480', '\\n', '    final training loss: 0.4872', '\\n',\n'    best validation loss: 0.7777', '\\n', '    test accuracy: 0.6370', '\\n', '\ntest loss: 0.7832', '\\n', '  Learning rate 1e-03:', '\\n', '    final training\naccuracy: 0.9325', '\\n', '    best validation accuracy: 0.7640', '\\n', '    best\nrule fidelity: 0.6320', '\\n', '    final training loss: 0.2143', '\\n', '    best\nvalidation loss: 0.7527', '\\n', '    test accuracy: 0.7710', '\\n', '    test\nloss: 0.7032', '\\n', '  Learning rate 3e-03:', '\\n', '    final training\naccuracy: 0.9715', '\\n', '    best validation accuracy: 0.7740', '\\n', '    best\nrule fidelity: 0.9680', '\\n', '    final training loss: 0.1475', '\\n', '    best\nvalidation loss: 0.6353', '\\n', '    test accuracy: 0.7760', '\\n', '    test\nloss: 0.7275', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', 'Best train accuracy: 0.9790', '\\n', 'Best\nvalidation accuracy: 0.7800', '\\n', 'Best rule fidelity: 0.9960', '\\n', 'Best\ntrain loss: 0.0853', '\\n', 'Best validation loss: 0.6320', '\\n', 'Best test\naccuracy: 0.7800', '\\n', 'Execution time: a moment seconds (time limit is 30\nminutes).']", "['\\nDataset: SPR_BENCH', '\\n', '  weight_decay = 0.0', '\\n', '    best train\nacc: 0.9385', '\\n', '    best val acc: 0.7620', '\\n', '    best rule fidelity:\n0.6980', '\\n', '    best train: 0.2080', '\\n', '    best val: 0.7525', '\\n', '\nfinal test accuracy: 0.7540', '\\n', '    final test loss:     0.7323', '\\n', '\nweight_decay = 1e-05', '\\n', '    best train acc: 0.9325', '\\n', '    best val\nacc: 0.7640', '\\n', '    best rule fidelity: 0.6320', '\\n', '    best train:\n0.2143', '\\n', '    best val: 0.7528', '\\n', '    final test accuracy: 0.7710',\n'\\n', '    final test loss:     0.7032', '\\n', '  weight_decay = 0.0001', '\\n',\n'    best train acc: 0.8535', '\\n', '    best val acc: 0.7360', '\\n', '    best\nrule fidelity: 0.9700', '\\n', '    best train: 0.3673', '\\n', '    best val:\n0.6333', '\\n', '    final test accuracy: 0.7240', '\\n', '    final test loss:\n0.6158', '\\n', '  weight_decay = 0.001', '\\n', '    best train acc: 0.9555',\n'\\n', '    best val acc: 0.7760', '\\n', '    best rule fidelity: 0.8720', '\\n',\n'    best train: 0.1989', '\\n', '    best val: 0.6589', '\\n', '    final test\naccuracy: 0.7730', '\\n', '    final test loss:     0.6587', '\\n', 'Execution\ntime: a moment seconds (time limit is 30 minutes).']"], "parse_exc_type": [null, null, null, null], "parse_exc_info": [null, null, null, null], "parse_exc_stack": [null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
