
% This paper provides a comparative analysis of LIME and SHAP, two key interpretability methods mentioned in the related work section of the paper. It is relevant for summarizing existing research on post-hoc interpretability techniques and will be cited in the context of discussing existing approaches to interpretable AI.
@article{korade2024unlockingml,
 author = {Deepak Mane Anand Magar Om Khode Sarvesh Koli Komal Bhat Prajwal Korade},
 booktitle = {Journal of Electrical Systems},
 journal = {Journal of Electrical Systems},
 title = {Unlocking Machine Learning Model Decisions: A Comparative Analysis of LIME and SHAP for Enhanced Interpretability},
 year = {2024}
}

% The paper 'Neural Logic Machines' introduces a foundational neural-symbolic architecture for inductive learning and logic reasoning. It is relevant to the related work section when summarizing neural rule learning approaches and serves as an important reference for discussing the limitations and capabilities of such models.
@article{dong2019neurallm,
 author = {Honghua Dong and Jiayuan Mao and Tian Lin and Chong Wang and Lihong Li and Denny Zhou},
 booktitle = {International Conference on Learning Representations},
 journal = {ArXiv},
 title = {Neural Logic Machines},
 volume = {abs/1904.11694},
 year = {2019}
}

% The paper 'Interpretable Neural-Symbolic Concept Reasoning' introduces the Deep Concept Reasoner (DCR), an interpretable concept-based model that builds syntactic rule structures using concept embeddings for semantically-consistent predictions. It is relevant to the related work section when discussing symbolic reasoning models and their limitations, serving as a comparative study for interpretable rule learning approaches.
@article{barbiero2023interpretablenc,
 author = {Pietro Barbiero and Gabriele Ciravegna and Francesco Giannini and Mateo Espinosa Zarlenga and Lucie Charlotte Magister and A. Tonda and Pietro Lio' and F. Precioso and M. Jamnik and G. Marra},
 booktitle = {International Workshop on Neural-Symbolic Learning and Reasoning},
 journal = {ArXiv},
 title = {Interpretable Neural-Symbolic Concept Reasoning},
 volume = {abs/2304.14068},
 year = {2023}
}

% The CLRS-Text Benchmark paper discusses procedurally-generated benchmarks for reasoning tasks, offering insights into synthetic dataset design and evaluation. It is relevant for contextualizing the SPR_BENCH dataset and the broader scope of synthetic reasoning tasks, and will be cited when discussing the dataset and benchmarks for algorithmic reasoning.
@article{markeeva2024theca,
 author = {Larisa Markeeva and Sean McLeish and Borja Ibarz and Wilfried Bounsi and Olga Kozlova and Alex Vitvitskyi and Charles Blundell and Tom Goldstein and Avi Schwarzschild and Petar Velivckovi'c},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {The CLRS-Text Algorithmic Reasoning Language Benchmark},
 volume = {abs/2406.04229},
 year = {2024}
}

% The paper 'Neural Symbolic Logical Rule Learner for Interpretable Learning' introduces the Normal Form Rule Learner (NFRL), a hybrid neuro-symbolic model designed to learn logical rules in Conjunctive Normal Form (CNF) and Disjunctive Normal Form (DNF) for interpretable classification. This work is directly relevant to the related work section, as it explores interpretable rule learning and addresses challenges like gradient vanishing and model flexibility. It will be cited to highlight recent advancements in hybrid neural-symbolic approaches for interpretable rule representation.
@article{wei2024neuralsl,
 author = {Bowen Wei and Ziwei Zhu},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Neural Symbolic Logical Rule Learner for Interpretable Learning},
 volume = {abs/2408.11918},
 year = {2024}
}

% This paper discusses the use of the Decision Tree algorithm as a baseline for interpretable classification tasks, specifically in predicting water potability. It is relevant to the baseline approach described in the experiments of our work, where a shallow decision tree is used to generate interpretable rules. This citation will support the discussion of interpretable machine learning models as baselines for reasoning tasks.
@article{zaky2023performanceao,
 author = {Umar Zaky and Ahmad Naswin and Sumiyatun Sumiyatun and A. Murdiyanto},
 booktitle = {Indonesian Journal of Data and Science},
 journal = {Indonesian Journal of Data and Science},
 title = {Performance Analysis of the Decision Tree Classification Algorithm on the Water Quality and Potability Dataset},
 year = {2023}
}

% The paper 'Neural Networks and Deep Learning: Enhancing AI Through Neural Network Optimization' explores advanced optimization techniques such as gradient descent variants, regularization methods, and learning rate schedulers. These methods are directly relevant to addressing training stability and performance challenges in interpretable neural networks. This work will be cited in the methodology section when discussing optimization strategies for the proposed neural rule learning model.
@article{mehrotra2024neuralna,
 author = {Ravi Mehrotra},
 booktitle = {International Journal of Advanced Research},
 journal = {International Journal of Advanced Research},
 title = {NEURAL NETWORKS AND DEEP LEARNING: ENHANCING AI THROUGH NEURAL NETWORK OPTIMIZATION},
 year = {2024}
}
