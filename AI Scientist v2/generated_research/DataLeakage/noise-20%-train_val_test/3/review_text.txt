{
    "Summary": "This paper investigates overfitting pitfalls in deep learning under real-world deployment conditions, focusing on label smoothing and dropout as partial remedies. The study highlights the limitations of these techniques in addressing overfitting, especially under distributional shifts. The authors conduct experiments on a real-world dataset to showcase these issues.",
    "Strengths": [
        "The paper addresses a practical and relevant issue in deploying deep learning models in real-world scenarios.",
        "The experiments provide an empirical evaluation of label smoothing and dropout under distributional shifts."
    ],
    "Weaknesses": [
        "The paper lacks novelty as it primarily evaluates well-known techniques such as label smoothing and dropout without proposing new methods or ideas.",
        "The methodology is underdeveloped and lacks sufficient detail, making it hard to evaluate the rigor of the experiments.",
        "The results are not substantial or groundbreaking, and the analysis of the findings is superficial.",
        "The writing quality is poor, with missing references, vague statements, and insufficient contextualization of the work within the broader field.",
        "Figures and visualizations, such as confusion matrices, are referenced but not adequately explained or discussed in the main text.",
        "The paper's conclusion is weak, offering no concrete recommendations or meaningful insights beyond the obvious acknowledgment that existing techniques are insufficient."
    ],
    "Originality": 2,
    "Quality": 2,
    "Clarity": 2,
    "Significance": 2,
    "Questions": [
        "How does this work advance the state of the art in addressing overfitting compared to prior studies?",
        "What novel insights or recommendations does this study provide for practitioners?",
        "Can the authors clarify the experimental setup, particularly the dataset used and the nature of the distributional shifts?",
        "Why are references missing for several key claims? For example, the citation '[?]' appears multiple times in the paper."
    ],
    "Limitations": [
        "The paper fails to provide a detailed discussion of its limitations, such as the narrow scope of experiments and the lack of exploration of alternative regularization techniques.",
        "The societal impact of addressing overfitting pitfalls in real-world scenarios is not discussed."
    ],
    "Ethical Concerns": false,
    "Soundness": 2,
    "Presentation": 2,
    "Contribution": 2,
    "Overall": 3,
    "Confidence": 4,
    "Decision": "Reject"
}