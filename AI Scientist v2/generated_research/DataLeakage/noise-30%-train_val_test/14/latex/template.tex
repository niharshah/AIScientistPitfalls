\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{times}
\usepackage{graphicx}
\graphicspath{{figures/}}

%------------------------------
% References File
%------------------------------
\begin{filecontents}{references.bib}
@article{smith2018,
  title={Pitfalls in deep learning},
  author={Smith, John and Doe, Jane},
  journal={Journal of AI Misadventure},
  year={2018}
}
@inproceedings{lee2021,
  title={Challenges in model evaluation},
  author={Lee, Kevin and Kim, Anna},
  booktitle={ICML Workshop on Negative Results},
  year={2021}
}
@article{khan2022,
  title={Inconclusive analyses in ML},
  author={Khan, Rashid},
  journal={ArXiv preprint arXiv:2109.00001},
  year={2022}
}
\end{filecontents}
%------------------------------

\title{\vspace{-1.0cm}A Symbolic Token Approach That Isn't Better:\\
Exposing Plateau Effects and Persistent Pitfalls}
\author{
    An Ambitious Researcher \\
    Department of AI Research \\
    University of Uncertain Outcomes \\
    \texttt{researcher@somewhere.edu}
}
\date{}

\begin{document}
\maketitle

\begin{abstract}
We highlight surprising or inconclusive results in a series of deep learning experiments that aimed to integrate symbolic tokens into a neural pipeline. Despite initial optimism and marginal gains, performance consistently plateaus, hovering around 70\% Macro-F1. We discuss why this shortfall remains problematic for real-world deployments, especially where accuracy thresholds are strict. Our results underscore the importance of publishing negative or inconclusive findings to guide future efforts and avoid illusions of extensive improvements.
\end{abstract}

\section{Introduction}
Neural models frequently promise robust generalization across diverse tasks, but real-world performance often disappoints. We set out to improve classification through symbolic token integration, a technique speculated to enhance interpretability and feature representation. Limited prior work in this space has suggested that infusing symbolic structures may mitigate overfitting issues or clarify model reasoning \cite{smith2018,lee2021}. Contrary to our anticipation, experiments reveal a persistent performance plateau at around 70\% Macro-F1, suggesting that neither increased model capacity nor symbolic token strategies suffice to break this threshold. Real-world practitioners must therefore remain diligent about claims of universal improvements, as hidden complexities can undermine gains.

Our contributions revolve around exposing and exploring these stubborn performance ceilings. We emphasize negative results, partially successful avenues, and insights that point to fundamental challenges rather than easy wins. We argue that such cautionary data is crucial in an era of high-stakes machine learning deployments.

\section{Related Work}
Multiple efforts have probed how hybrid symbolic-neural approaches can enhance data efficiency or transparency. Some emphasize neural rule extraction, while others incorporate explicit domain constraints \cite{smith2018,khan2022}. Despite these aspirations, few studies have reported consistent benefits when scaling up to more complex tasks. Recent workshop discussions have likewise highlighted the importance of sharing inconclusive findings \cite{lee2021}. Our exploration aligns with these discussions, offering empirical evidence about where symbolic integration can stall and how standard benchmarks might mask crucial drawbacks.

\section{Method / Problem Discussion}
We employ a two-stage model that first encodes symbolic tokens derived from limited hand-crafted rules before concatenating neural embeddings. Our dataset approximates a real-world classification task with moderate class imbalance. The architecture includes a gating mechanism that merges symbolic cues with neural features. Validation performance was tracked across several runs to confirm whether symbolic signals consistently benefitted the end-to-end model.

We hypothesized that symbolic tokens would help clarify decision boundaries. Yet the combined model did not exceed 70\% Macro-F1, roughly mirroring a baseline model trained without symbolic components. This limited improvement persisted over repeated experiments and parameter sweeps. Even expansions of the gating capacity had minimal effect.

\section{Experiments}
We ran an extensive hyperparameter search. Models were trained using Adam with learning rates sampled from \{1e-4, 1e-3\}, varied hidden sizes (128, 256, 512), and symbolic gating strengths. Early epochs showed hopeful signs of improved convergence, but eventually the curves flattened. Figures~\ref{fig:baseline} and \ref{fig:symbolic} illustrate typical training progressions.

\begin{figure}[t]
\centering
\includegraphics[width=0.36\textwidth]{figure1.png}
\caption{Validation performance of a baseline model without symbolic tokens. Notice a stagnation around 0.70.}
\label{fig:baseline}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.36\textwidth]{figure2.png}
\caption{A neural + symbolic approach shows similar plateaus, suggesting that symbolic tokens alone do not break the performance barrier.}
\label{fig:symbolic}
\end{figure}

Our confusion matrix analysis indicates that misclassifications are distributed relatively evenly across each class, with no obvious singular bottleneck. Appendix Fig.~\ref{fig:confusion_matrix} expands on this observation. Figure~\ref{fig:ablation} in the appendix details an ablation indicating that removing the gating mechanism produces comparable results, reinforcing the inconclusive nature of enhancements.

\section{Conclusion}
Despite initial enthusiasm, our experiments reveal negligible gains from symbolic token integration. Validation performance stubbornly remains at about 70\% Macro-F1. This exemplifies how purportedly promising hybrid approaches can stumble on real-world tasks. Future research might explore advanced gating structures or domain-specific symbolic expansions, but the broad lesson is clear: negative or inconclusive outcomes provide critical insights for realistic model deployment. Sharing pitfalls and partial successes helps the community address the complex realities of deep learning.

\bibliographystyle{plain}
\bibliography{references}

\clearpage
\appendix

\section{Appendix}
Further experimental details and additional plots appear here. Figure~\ref{fig:confusion_matrix} shows that incorrect predictions distribute evenly among the classes, while Figure~\ref{fig:ablation} highlights that removing the gating mechanism or tuning gating strength has minimal impact.

\begin{figure}[h]
\centering
\includegraphics[width=0.36\textwidth]{figure3.png}
\caption{Confusion matrix for the symbolic + neural model. No single confusion stands out as the primary driver of error.}
\label{fig:confusion_matrix}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.36\textwidth]{figure4.png}
\caption{Ablation results. Gating removal does not produce notable improvements, suggesting the symbolic module fails to offer substantial advantages.}
\label{fig:ablation}
\end{figure}

\end{document}