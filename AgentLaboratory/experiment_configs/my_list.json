[
  {
    "phases": [
      "plan formulation"
    ],
    "note": "# Title: Develop a Robust Algorithm for a Novel Task \"Synthetic PolyRule Reasoning\" \n\n## Background\n\n**Synthetic PolyRule Reasoning (SPR)**\n\n* SPR is a classification task distilled from complex reasoning patterns found in various real-world domains such as finance, academic publishing, and scientific discovery, where latent symbolic rules govern decision-making. Solving this task has the potential to greatly impact automated reasoning systems in practice. In SPR, each instance consists of a symbolic sequence $S = [s_1, s_2, \\dots, s_L]$ of length $L$, where each token $s_i$ is composed of an abstract shape glyph from the set **{▲, ■, ●, ◆}** and a color glyph from the set **{r, g, b, y}**.\n\n\n* A hidden *generation rule* $R$ governs the mapping from an input sequence $S$ to a binary label: *accept / reject*. This rule encapsulates a logical structure that governs how different symbol combinations should be interpreted, leading to the classification decision.\n\n* The rules in SPR are **poly‑factor**, meaning each rule is the result of applying a logical AND across $k$ atomic predicates. These atomic predicates are derived from the following categories:\n  1. **Shape-Count**: Refers to conditions based on the frequency of a specific shape within the sequence. For instance, a predicate could specify \"exactly three ▲,\" meaning that the rule only holds if there are exactly three occurrences of the shape ▲.\n\n  2. **Color-Position**: Conditions based on the color of a specific token at a defined position in the sequence. An example predicate might be \"token 4 is **r**,\" meaning the fourth token in the sequence must be colored red for the rule to hold.\n\n  3. **Parity**: Conditions involving the even or odd count of specific shapes or colors. For example, \"the number of ■ is even\" could be a rule, meaning that the total count of squares ■ in the sequence must be an even number for the sequence to be accepted.\n\n  4. **Order**: Relational conditions on the order of specific tokens in the sequence. An example could be \"the first ▲ precedes the first ●,\" meaning that the first occurrence of the shape ▲ must appear before the first occurrence of the shape ● in the sequence.\n\nBy solving the SPR task, we aim to unlock the ability to automatically identify and classify complex symbolic sequences that follow hidden, intricate rules. This has significant potential for automation in various domains where symbolic data patterns need to be understood, such as automating financial analysis, enhancing academic publishing workflows, or improving decision-making systems in complex environments."
  },
  {
    "phases": [
      "plan formulation"
    ],
    "note": "## Task Instructions\n\n1. **Design an Algorithm**: Develop an algorithm to solve the **SPR (Symbolic Pattern Recognition)** task. Your algorithm should decide whether a given $L$-token sequence of abstract symbols satisfies the hidden target rule.\n\n2. **Training Procedure**:\n\n   * Train your model using the **Train split** of each selected benchmark.\n   * Tune your model on the **Dev split**.\n   * The **Test split** labels are withheld, and you must report accuracy based on your model’s performance on this unseen data.\n   * Note that **cross-benchmark training** is prohibited. Each model should be trained and evaluated independently for each chosen benchmark.\n\n3. **Baseline Comparison**: Set the **SOTA (State-of-the-Art) accuracies** for each benchmark as a baseline. Your goal is to **compare your model’s performance** against these baselines and demonstrate improvements.\n\n4. **Submission Requirements**: For each benchmark, submit a **separate model** along with the following:\n\n   * The **final accuracy on the Test set**.\n   * A comparison of your model’s performance against the **SOTA baseline** for that benchmark.\n\n5. **Objective**: The goal of this task is to develop a **robust algorithm** that:\n\n   * Outperforms the current **SOTA** benchmarks.\n   * Demonstrates strong generalization across variations in **vocabulary sizes**, **sequence lengths**, and **rule complexities**.\n"
  },
  {
    "phases": [
      "data preparation"
    ],
    "note": "\n## SPR_BENCH Benchmark from HuggingFace\n\nIn this experiment, we use the SPR_BENCH benchmark sourced from HuggingFace to evaluate the performance of machine learning models on a symbolic pattern recognition task. The benchmarks include a variety of symbolic patterns that challenge models to classify sequences of abstract symbols under varying conditions. SPR_BENCH benchmark is standardized with the following fixed global parameters:\n\n\n| Field                         | Value                                 |\n| ----------------------------- | ------------------------------------- |\n| **Instances per split**       | Train = 20000 Dev = 5000 Test = 10000 |\n| **Label balance**             | 50 % accept / 50 % reject             |\n| **Public leaderboard metric** | Label Accuracy on each benchmark      |\n\n\n### Metrics\n\nThe evaluation is based on two distinct complexity dimensions for any given sequence S:\n* **Color Complexity**  $C_c(S_i)$: The number of **unique** color glyphs {r, g, b, y} in the sequence. (Range: 1-4)\n* **Shape Complexity** $C_s(S_i)$: The number of **unique** shape glyphs {▲, ■, ●, ◆} in the sequence. (Range: 1-4)  \n\n#### **Metric 1: Color-Weighted Accuracy (CWA)**\n\n* **Description**: This metric heavily prioritizes performance on instances with high color variety.  \n* $\\text{CWA} = \\frac{\\sum_{i=1}^{N} w_i^{\\text{CWA}} \\cdot \\mathbb{I}(y_i = \\hat{y}_i)}{\\sum_{i=1}^{N} w_i^{\\text{CWA}}}, \\quad \\text{where } w_i^{\\text{CWA}} = C_c(S_i)$ \n* **Rationale (as presented to the AI agent)**: CWA emphasizes a model's understanding of **color diversity**. A high score suggests the model can robustly  sequence complex combinations of different colors, a key aspect of the task.\n\n#### **Metric 2: Shape-Weighted Accuracy (SWA)**\n\n* **Description**: This metric heavily prioritizes performance on instances with high shape variety.  \n* $\\text{SWA} = \\frac{\\sum_{i=1}^{N} w_i^{\\text{SWA}} \\cdot \\mathbb{I}(y_i = \\hat{y}_i)}{\\sum_{i=1}^{N} w_i^{\\text{SWA}}}, \\quad \\text{where } w_i^{\\text{SWA}} = C_s(S_i)$\n* **Rationale (as presented to the AI agent)**: SWA emphasizes a model's understanding of **shape diversity**. A high score suggests the model can robustly classify sequences with complex arrangements of different shapes, a key aspect of the task.\n\n### SOTA Performance \n\nBelow are the SPR_BENCH benchmark along with its corresponding State-of-the-Art (SOTA) performance on SWA and CWA metric. The SOTA represent the best performance achieved on the SPR_BENCH benchmark and provide a reference point for evaluating the effectiveness of the models trained on these datasets.\n\n| Name          | Metric                            | SOTA Performance |\n| ------------- | --------------------------------- | ---------------- |\n| **SPR_BENCH** | **CWA** (Color-Weighted Accuracy) | 70.0 %           |\n| **SPR_BENCH** | **SWA** (Shape-Weighted Accuracy) | 65.0 %           |\n\n### **Data Description**\n\n```\nDirectory layout expected:\nSPR_BENCH/\n ├─ train.csv   (20000 rows)\n ├─ dev.csv     (5000 rows)\n └─ test.csv    (10000 rows)\n\n```\n\nEach `*.csv` has **UTF-8**, comma-separated columns:\n\n| id           | sequence                 | label |\n| ------------ | ------------------------ | ----- |\n| SPR_train_17 | ▲r ■b ▲r ●g ◆r ■r ●y ◆r | 1     |\n\n* A **token** is a shape glyph plus an optional 1-letter colour (`▲g`, `■`, …).\n* **Label** = `1` (accept) or `0` (reject).\n\n\n"
  },
  {
    "phases": [
      "data preparation"
    ],
    "note": "\"\"\"\nSPR.py\n────────────────────────────────────────────────────────\nUtility to load the SPR_BENCH benchmark datasets\nUsing HuggingFace’s `datasets` library.\nDefinition of two evaluation metrics:\n1. Color-Weighted Accuracy (CWA)\n2. Shape-Weighted Accuracy (SWA)\nDirectory layout expected\nSPR_BENCH/\n ├─ train.csv   (20000 rows)\n ├─ dev.csv     (5000 rows)\n └─ test.csv    (10000 rows)\n\nEach CSV has header:  id,sequence,label\n────────────────────────────────────────────────────────\n$ pip install datasets   # once\n\"\"\"\nimport pathlib\nfrom typing import Dict\n\nfrom datasets import load_dataset, DatasetDict                                         # <- no pandas import\n\n\ndef load_spr_bench(root: pathlib.Path) -> DatasetDict:\n    \"\"\"\n    Return a DatasetDict {'train':…, 'dev':…, 'test':…} for one SPR ID folder.\n    \"\"\"\n    def _load(split_csv: str):\n        return load_dataset(\n            \"csv\",\n            data_files=str(root / split_csv),\n            split=\"train\",           # treat csv as a single split\n            cache_dir=\".cache_dsets\" # optional; keeps HF cache tidy\n        )\n\n    dset = DatasetDict()\n    dset[\"train\"] = _load(\"train.csv\")\n    dset[\"dev\"]   = _load(\"dev.csv\")\n    dset[\"test\"]  = _load(\"test.csv\")\n    return dset\n\n\ndef count_color_variety(sequence: str) -> int:\n    \"\"\"Count the number of unique color types in the sequence\"\"\"\n    return len(set(token[1] for token in sequence.strip().split() if len(token) > 1))\n\n\ndef count_shape_variety(sequence: str) -> int:\n    \"\"\"Count the number of unique shape types in the sequence\"\"\"\n    return len(set(token[0] for token in sequence.strip().split() if token))\n\ndef color_weighted_accuracy(sequences, y_true, y_pred):\n    \"\"\"Color-Weighted Accuracy (CWA)\"\"\"\n    weights = [count_color_variety(seq) for seq in sequences]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\ndef shape_weighted_accuracy(sequences, y_true, y_pred):\n    \"\"\"Shape-Weighted Accuracy (SWA)\"\"\"\n    weights = [count_shape_variety(seq) for seq in sequences]\n    correct = [w if yt == yp else 0 for w, yt, yp in zip(weights, y_true, y_pred)]\n    return sum(correct) / sum(weights) if sum(weights) > 0 else 0.0\n\n\ndef main():\n\n    ## Absolute path of the datasets\n    DATA_PATH = pathlib.Path('/home/zxl240011/AI-Scientist-v2/SPR_BENCH/')\n    spr_bench = load_spr_bench(DATA_PATH)\n\n    print(\"Benchmarks split:\", spr_bench.keys())\n\n    # Demo: show first example from SPR_BENCH‑train\n    ex = spr_bench[\"train\"][0]\n    print(\"\\nExample row:\")\n    print(ex)          \n\n\nif __name__ == \"__main__\":\n    main()\n"
  },
  {
    "phases": [
      "running experiments"
    ],
    "note": "## Task Instructions\n\n1. **Design an Algorithm**: Develop an algorithm to solve the **SPR (Symbolic Pattern Recognition)** task. Your algorithm should decide whether a given \\$L\\$-token sequence of abstract symbols satisfies the hidden target rule.\n\n2. **Training Procedure**:\n\n   * Train your model using the **Train split** of each selected benchmark.\n   * Tune your model on the **Dev split**.\n   * The **Test split** labels are withheld, and you must report your model’s performance on this unseen data.\n\n3. **Baseline and Metrics**:\n   * Use the current State-of-the-Art (SOTA) performance on the SPR_BENCH as the baseline.\n   * Choose only **one** evaluation metric — either Shape-Weighted Accuracy (SWA) or Color-Weighted Accuracy (CWA) — for performance comparison.\n   * Your objective is to surpass the SOTA performance on the chosen metric for SPR_BENCH.\n\n4. **Submission Requirements**: For SPR_BENCH, submit a **separate model** along with the following:\n\n   * The final performance on the Test set using the **selected metric**.\n   * A detailed comparison of your model’s performance against the SOTA performance on your chosen metric.\n\n5. **Objective**: The goal of this task is to develop a **robust algorithm** that:\n   * Outperforms the current **SOTA** benchmarks.\n   * Demonstrates strong generalization across variations in **vocabulary sizes**, **sequence lengths**, and **rule complexities**.\n"
  },
  {
    "phases": [
      "results interpretation"
    ],
    "note": "The SOTA performance on SPR_BENCH is 70.0 % with CWA and 65.0% with SWA."
  },
  {
    "phases": [
      "results writing",
      "report writing"
    ],
    "note": "**Submission Requirements**: For selected metric, Choose only **one** evaluation metric either Shape-Weighted Accuracy (SWA) or Color-Weighted Accuracy (CWA) for performance report:\n * The final performance on the Test set using the **selected metric**.\n * A detailed comparison of your model’s performance against the SOTA performance on your chosen metric."
  }
]