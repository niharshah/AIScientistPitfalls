
Successfully loaded spr_bench dataset:
DatasetDict({
    train: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 2000
    })
    validation: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 500
    })
    test: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 1000
    })
})

spr_bench train dataset features:
{'id': Value(dtype='string', id=None), 'sequence': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None)}

spr_bench validation dataset features:
{'id': Value(dtype='string', id=None), 'sequence': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None)}

spr_bench test dataset features:
{'id': Value(dtype='string', id=None), 'sequence': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None)}

Successfully loaded boolq dataset:
DatasetDict({
    train: Dataset({
        features: ['question', 'answer', 'passage'],
        num_rows: 9427
    })
    validation: Dataset({
        features: ['question', 'answer', 'passage'],
        num_rows: 3270
    })
})

boolq train dataset features:
{'question': Value(dtype='string', id=None), 'answer': Value(dtype='bool', id=None), 'passage': Value(dtype='string', id=None)}

boolq validation dataset features:
{'question': Value(dtype='string', id=None), 'answer': Value(dtype='bool', id=None), 'passage': Value(dtype='string', id=None)}

Successfully loaded squad_v2 dataset:
DatasetDict({
    train: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 130319
    })
    validation: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 11873
    })
})

squad_v2 train dataset features:
{'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}

squad_v2 validation dataset features:
{'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}

Successfully loaded yelp_polarity dataset:
DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 560000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 38000
    })
})

yelp_polarity train dataset features:
{'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['1', '2'], id=None)}

yelp_polarity test dataset features:
{'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['1', '2'], id=None)}
Epoch 1, Validation Accuracy: 0.5200
Epoch 2, Validation Accuracy: 0.5200
Epoch 3, Validation Accuracy: 0.4800
Epoch 4, Validation Accuracy: 0.4800
Epoch 5, Validation Accuracy: 0.4800
Epoch 6, Validation Accuracy: 0.4800
Epoch 7, Validation Accuracy: 0.4800
Epoch 8, Validation Accuracy: 0.5200
Epoch 9, Validation Accuracy: 0.5200
Epoch 10, Validation Accuracy: 0.4800

Evaluating on the unseen test data to validate model performance.
Test Accuracy: 0.5020
