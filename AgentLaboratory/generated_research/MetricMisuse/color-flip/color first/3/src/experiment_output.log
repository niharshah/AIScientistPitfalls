DatasetDict({
    train: Dataset({
        features: ['id', 'sequence', 'label', 'shape_complexity', 'color_complexity'],
        num_rows: 20000
    })
    dev: Dataset({
        features: ['id', 'sequence', 'label', 'shape_complexity', 'color_complexity'],
        num_rows: 5000
    })
    test: Dataset({
        features: ['id', 'sequence', 'label', 'shape_complexity', 'color_complexity'],
        num_rows: 10000
    })
})
Dataset loaded and complexities computed:
DatasetDict({
    train: Dataset({
        features: ['id', 'sequence', 'label', 'shape_complexity', 'color_complexity', 'token_count'],
        num_rows: 20000
    })
    dev: Dataset({
        features: ['id', 'sequence', 'label', 'shape_complexity', 'color_complexity', 'token_count'],
        num_rows: 5000
    })
    test: Dataset({
        features: ['id', 'sequence', 'label', 'shape_complexity', 'color_complexity', 'token_count'],
        num_rows: 10000
    })
})

Training Experiment: Training Logistic Regression model using features [shape_complexity, color_complexity, token_count].

[Experiment: Training Performance]
This result shows the model's performance on the training split, ensuring that the model can capture at least some non-zero accuracy.
Overall Accuracy on Training set: 0.6156
Shape-Weighted Accuracy (SWA) on Training set: 0.6108
Color-Weighted Accuracy (CWA) on Training set: 0.6224

[Experiment: Dev Performance]
This result shows the model's performance on the development split used for hyperparameter tuning and model selection.
Overall Accuracy on Dev set: 0.5914
Shape-Weighted Accuracy (SWA) on Dev set: 0.5857
Color-Weighted Accuracy (CWA) on Dev set: 0.5904

[Experiment: Test Performance]
This result shows the model's performance on the unseen test data, providing an unbiased evaluation of our model's generalization capability.
Overall Accuracy on Test set: 0.5425
Shape-Weighted Accuracy (SWA) on Test set: 0.5411
Color-Weighted Accuracy (CWA) on Test set: 0.5480

Generated Figure_1.png, showing the histogram distribution of shape complexities in the training set.
Generated Figure_2.png, a scatter plot of token count vs. shape complexity, with labels distinguishing example classes.

All experiments completed. The model surpasses 0% accuracy and the above figures illustrate dataset characteristics and model training insights.
