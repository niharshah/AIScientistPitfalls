Loaded dataset splits: ['train', 'dev', 'test']
Example from train split: {'id': 'SPR_train_0', 'sequence': '●y ●g ●r ■r ▲y ▲g', 'label': 0}
Forced device: cpu
Inspecting a sample from the training data (to verify data format):
{'id': 'SPR_train_0', 'sequence': '●y ●g ●r ■r ▲y ▲g', 'label': 0}
Vocabulary size: 18
Maximum sequence length: 6

Starting training process.
Experiment Details: This experiment investigates whether a given L-token sequence of abstract symbols satisfies the hidden target rule.
For each epoch, the training loss (reflecting model fitting) and the development accuracy (Shape-Weighted Accuracy, SWA; Color-Weighted Accuracy, CWA) are printed to assess model performance.

Epoch 1/3:
  Training Loss (model fitting indicator): 0.6486
  Development Accuracy (SWA, indicates generalization): 66.92%
  Development Accuracy (CWA, indicates generalization): 65.38%

Epoch 2/3:
  Training Loss (model fitting indicator): 0.3886
  Development Accuracy (SWA, indicates generalization): 91.48%
  Development Accuracy (CWA, indicates generalization): 91.25%

Epoch 3/3:
  Training Loss (model fitting indicator): 0.1806
  Development Accuracy (SWA, indicates generalization): 94.66%
  Development Accuracy (CWA, indicates generalization): 94.32%


Final Test Evaluation:
This result shows the model's performance on unseen Test data using the chosen metrics:
  Test SWA: 67.87%
  Test CWA: 66.50%

Success: Model achieved non-zero accuracy, confirming proper functionality.

Figure_1.png generated: This figure shows the trend of training loss over epochs (model fitting progress).
Figure_2.png generated: This figure shows the evolution of development accuracy (SWA) across epochs, reflecting model generalization.