DatasetDict({
    train: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 20000
    })
    dev: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 5000
    })
    test: Dataset({
        features: ['id', 'sequence', 'label'],
        num_rows: 10000
    })
})

Extracting datasets for training, development, and testing:

Preprocessing features for all splits...

Experiment 1: Hyperparameter tuning on the development set.
For DecisionTree max_depth = 3 the Shape-Weighted Accuracy on Dev set is: 65.63 %
For DecisionTree max_depth = 5 the Shape-Weighted Accuracy on Dev set is: 68.89 %
For DecisionTree max_depth = 7 the Shape-Weighted Accuracy on Dev set is: 70.83 %
For DecisionTree max_depth = None the Shape-Weighted Accuracy on Dev set is: 71.28 %

Figure_1.png generated: It displays the development set SWA scores for different max_depth values of the Decision Tree.

Best hyperparameter found: max_depth = None with Dev SWA = 71.28 %

Experiment 2: Training final model on the combined train and dev splits and evaluating on test set.

Final model evaluation on Test set:
Shape-Weighted Accuracy on Test set: 70.91 %

Figure_2.png generated: It presents the confusion matrix of the final model's predictions on the Test set.

All experiments completed successfully. The final test SWA is reported above.
