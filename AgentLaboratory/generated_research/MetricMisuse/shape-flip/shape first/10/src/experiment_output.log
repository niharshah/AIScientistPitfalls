DatasetDict({
    train: Dataset({
        features: ['id', 'sequence', 'label', 'tokens'],
        num_rows: 20000
    })
    dev: Dataset({
        features: ['id', 'sequence', 'label', 'tokens'],
        num_rows: 5000
    })
    test: Dataset({
        features: ['id', 'sequence', 'label', 'tokens'],
        num_rows: 10000
    })
})

Experiment 1: This experiment uses a RandomForestClassifier trained on TF-IDF features extracted from the SPR sequence texts. The objective is to adapt a robust baseline approach and surpass the literature-reported baseline SWA (~60%). The TF-IDF is computed from the pre-tokenized sequences to ensure non-empty vocabulary. Then, standard accuracy and Shape-Weighted Accuracy (SWA) are computed on the development set.

Results on the Dev set:
Standard Accuracy: 71.22%
Shape-Weighted Accuracy (SWA): 67.90%
The model's accuracy is > 0, ensuring that training has proceeded correctly.

Experiment 2: This experiment generates two figures. Figure_1.png visualizes the top 20 TF-IDF features by importance, as determined by the RandomForestClassifier. Figure_2.png compares the baseline SWA (assumed to be 60.0%) from literature with our model's SWA on the development set. These figures provide insights into feature significance and model performance relative to the SOTA benchmark.
Figure_1.png generated: Displays the top 20 TF-IDF feature importances from the RandomForestClassifier.
Figure_2.png generated: Compares baseline SWA (60%) with our model's SWA on the Dev set.

Generating predictions for the Test set (labels are withheld).
First 10 Test set predictions: [1 0 0 0 0 0 0 0 0 0]

All experiments completed. The generated figures (Figure_1.png and Figure_2.png) have been saved, and Test set predictions have been produced.
