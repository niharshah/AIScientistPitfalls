Training sample with computed features:
{'id': 'SPR_train_0', 'sequence': '●y ●g ●r ■r ▲y ▲g', 'label': 0, 'color_variety': 3, 'shape_variety': 3}
Training sample with computed features:
{'id': 'SPR_train_0', 'sequence': '●y ●g ●r ■r ▲y ▲g', 'label': 0, 'color_variety': 3, 'shape_variety': 3}

Starting training of R-NSR model on SPR_BENCH dataset (CPU-only).
This experiment aims to demonstrate joint learning of dense representations with a transformer encoder integrated with a sparse concept extraction layer and symbolic reasoning. The model is trained on 500 examples for 1 epoch.
Epoch [1/1] - Average Loss: 0.7238

=== Evaluation on Dev Set for R-NSR Model ===
This evaluation shows predictions versus ground truth on the Dev set using a threshold of 0.5 on model outputs.
Dev Accuracy: 50.00%

=== Evaluation on Test Set for R-NSR Model ===
This evaluation reports overall Test Accuracy and also computes Color-Weighted Accuracy (CWA) and Shape-Weighted Accuracy (SWA).
The weights are based respectively on the diversity of colors and shapes in each sequence.
Standard Test Accuracy: 56.52%
Color-Weighted Accuracy (CWA): 56.61% (SOTA: 65.0%)
Shape-Weighted Accuracy (SWA): 55.32% (SOTA: 70.0%)

Figures generated: Figure_1.png (Training Loss Curve) and Figure_2.png (R-NSR Test Accuracy Metrics).

Starting Ablation Experiment: Transformer Baseline (without sparse and symbolic reasoning modules).
This experiment uses a standard Transformer encoder model that lacks the sparse extraction and symbolic reasoning layers. It is trained on the same 500 examples for 1 epoch and evaluated on the Test set.
Ablation Epoch [1/1] - Average Loss: 0.6685

=== Evaluation on Test Set for Transformer Baseline (Ablation) ===
Transformer Baseline Test Accuracy: 46.99%

Ablation experiment completed. Figure_3.png (Transformer Baseline Training Loss Curve) generated.
